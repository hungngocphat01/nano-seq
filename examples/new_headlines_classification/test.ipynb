{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from nano_seq.task.classification import ClassificationTask, Config\n",
    "from nano_seq.data.utils import get_encoder_mask\n",
    "from nano_seq.logger import SimpleLogger\n",
    "from nano_seq.trainer import train\n",
    "from nano_seq.data import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ClassificationTask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m task \u001b[38;5;241m=\u001b[39m \u001b[43mClassificationTask\u001b[49m(\n\u001b[1;32m      2\u001b[0m     Config(\n\u001b[1;32m      3\u001b[0m         embed_dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m      4\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m      5\u001b[0m         num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      6\u001b[0m         encoder_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      7\u001b[0m         encoder_dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m,\n\u001b[1;32m      8\u001b[0m         spm_dict_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.vocab\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m         left_pad_src\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m         train_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/train\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m         valid_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/valid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     13\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ClassificationTask' is not defined"
     ]
    }
   ],
   "source": [
    "task = ClassificationTask(\n",
    "    Config(\n",
    "        embed_dims=8,\n",
    "        batch_size=64,\n",
    "        num_heads=2,\n",
    "        encoder_layers=1,\n",
    "        encoder_dropout=0.3,\n",
    "        spm_dict_path=\"model.vocab\",\n",
    "        left_pad_src=False,\n",
    "        train_path=\"data/train\",\n",
    "        valid_path=\"data/valid\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dictionary: 10000it [00:00, 1346831.93it/s]\n"
     ]
    }
   ],
   "source": [
    "dictionary = Dictionary.from_spm(\"model.vocab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dictionary: 10000it [00:00, 1341833.77it/s]\n",
      "Loading dataset: 25757it [00:00, 221514.64it/s]\n",
      "Loading dataset: 2862it [00:00, 212262.80it/s]\n"
     ]
    }
   ],
   "source": [
    "train_iter, valid_iter, model = task.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Step 1 | loss: 1.0220351219177246 | accuracy: 0.515625 \n",
      "Epoch 1 | Step 2 | loss: 0.8908551037311554 | accuracy: 0.5703125 \n",
      "Epoch 1 | Step 3 | loss: 0.8858871658643087 | accuracy: 0.5572916666666666 \n",
      "Epoch 1 | Step 4 | loss: 0.9529382735490799 | accuracy: 0.52734375 \n",
      "Epoch 1 | Step 5 | loss: 0.9827836155891418 | accuracy: 0.521875 \n",
      "Epoch 1 | Step 6 | loss: 0.977374424537023 | accuracy: 0.5182291666666666 \n",
      "Epoch 1 | Step 7 | loss: 0.9905098761831012 | accuracy: 0.515625 \n",
      "Epoch 1 | Step 8 | loss: 0.9916556775569916 | accuracy: 0.513671875 \n",
      "Epoch 1 | Step 9 | loss: 0.9721194704373678 | accuracy: 0.5138888888888888 \n",
      "Epoch 1 | Step 10 | loss: 0.9542454957962037 | accuracy: 0.5140625 \n",
      "Epoch 1 | Step 11 | loss: 0.9506469423120673 | accuracy: 0.5085227272727273 \n",
      "Epoch 1 | Step 12 | loss: 0.9398328016201655 | accuracy: 0.5026041666666666 \n",
      "Epoch 1 | Step 13 | loss: 0.9230034993245051 | accuracy: 0.5060096153846154 \n",
      "Epoch 1 | Step 14 | loss: 0.9095316997596196 | accuracy: 0.5089285714285714 \n",
      "Epoch 1 | Step 15 | loss: 0.9058927098910013 | accuracy: 0.50625 \n",
      "Epoch 1 | Step 16 | loss: 0.9029401764273643 | accuracy: 0.5009765625 \n",
      "Epoch 1 | Step 17 | loss: 0.8935224939795101 | accuracy: 0.5055147058823529 \n",
      "Epoch 1 | Step 18 | loss: 0.8941116597917345 | accuracy: 0.5 \n",
      "Epoch 1 | Step 19 | loss: 0.8878057191246435 | accuracy: 0.5041118421052632 \n",
      "Epoch 1 | Step 20 | loss: 0.8818615585565567 | accuracy: 0.50625 \n",
      "Epoch 1 | Step 21 | loss: 0.8774418688955761 | accuracy: 0.5074404761904762 \n",
      "Epoch 1 | Step 22 | loss: 0.8725151175802405 | accuracy: 0.5063920454545454 \n",
      "Epoch 1 | Step 23 | loss: 0.8743145284445389 | accuracy: 0.501358695652174 \n",
      "Epoch 1 | Step 24 | loss: 0.8698869546254476 | accuracy: 0.5032552083333334 \n",
      "Epoch 1 | Step 25 | loss: 0.868305823802948 | accuracy: 0.503125 \n",
      "Epoch 1 | Step 26 | loss: 0.8632089381034558 | accuracy: 0.5042067307692308 \n",
      "Epoch 1 | Step 27 | loss: 0.8619715880464625 | accuracy: 0.5023148148148149 \n",
      "Epoch 1 | Step 28 | loss: 0.8601153578077044 | accuracy: 0.5022321428571429 \n",
      "Epoch 1 | Step 29 | loss: 0.8553339078508574 | accuracy: 0.5026939655172414 \n",
      "Epoch 1 | Step 30 | loss: 0.8515952269236247 | accuracy: 0.503125 \n",
      "Epoch 1 | Step 31 | loss: 0.8509002116418654 | accuracy: 0.5005040322580646 \n",
      "Epoch 1 | Step 32 | loss: 0.8481579292565584 | accuracy: 0.5000000000000001 \n",
      "Epoch 1 | Step 33 | loss: 0.8449860702861439 | accuracy: 0.500473484848485 \n",
      "Epoch 1 | Step 34 | loss: 0.8414556419148165 | accuracy: 0.5000000000000001 \n",
      "Epoch 1 | Step 35 | loss: 0.8378264546394348 | accuracy: 0.49910714285714297 \n",
      "Epoch 1 | Step 36 | loss: 0.8344580895370908 | accuracy: 0.5013020833333335 \n",
      "Epoch 1 | Step 37 | loss: 0.8348784785012942 | accuracy: 0.5004222972972975 \n",
      "Epoch 1 | Step 38 | loss: 0.8339570352905675 | accuracy: 0.4995888157894739 \n",
      "Epoch 1 | Step 39 | loss: 0.8313005948678042 | accuracy: 0.4987980769230771 \n",
      "Epoch 1 | Step 40 | loss: 0.829179647564888 | accuracy: 0.49804687500000017 \n",
      "Epoch 1 | Step 41 | loss: 0.8276666649957982 | accuracy: 0.4988567073170733 \n",
      "Epoch 1 | Step 42 | loss: 0.8249461338633582 | accuracy: 0.5000000000000002 \n",
      "Epoch 1 | Step 43 | loss: 0.8241421053575915 | accuracy: 0.4989098837209305 \n",
      "Epoch 1 | Step 44 | loss: 0.8217604011297226 | accuracy: 0.5003551136363639 \n",
      "Epoch 1 | Step 45 | loss: 0.8203150245878431 | accuracy: 0.5003472222222225 \n",
      "Epoch 1 | Step 46 | loss: 0.8191262639087179 | accuracy: 0.5010190217391307 \n",
      "Epoch 1 | Step 47 | loss: 0.8168646198637942 | accuracy: 0.5019946808510641 \n",
      "Epoch 1 | Step 48 | loss: 0.8154362042744955 | accuracy: 0.502604166666667 \n",
      "Epoch 1 | Step 49 | loss: 0.813855343935441 | accuracy: 0.5028698979591839 \n",
      "Epoch 1 | Step 50 | loss: 0.8129707515239716 | accuracy: 0.5012500000000002 \n",
      "Epoch 1 | Step 51 | loss: 0.8124774437324673 | accuracy: 0.5003063725490198 \n",
      "Epoch 1 | Step 52 | loss: 0.8099222572950217 | accuracy: 0.5024038461538463 \n",
      "Epoch 1 | Step 53 | loss: 0.8073736721614622 | accuracy: 0.503242924528302 \n",
      "Epoch 1 | Step 54 | loss: 0.8064326776398553 | accuracy: 0.502314814814815 \n",
      "Epoch 1 | Step 55 | loss: 0.8040902137756347 | accuracy: 0.5051136363636366 \n",
      "Epoch 1 | Step 56 | loss: 0.8030512875744275 | accuracy: 0.5047433035714288 \n",
      "Epoch 1 | Step 57 | loss: 0.8012584447860718 | accuracy: 0.5057565789473687 \n",
      "Epoch 1 | Step 58 | loss: 0.79901905409221 | accuracy: 0.5070043103448278 \n",
      "Epoch 1 | Step 59 | loss: 0.7993546370732583 | accuracy: 0.5052966101694918 \n",
      "Epoch 1 | Step 60 | loss: 0.7985991368691127 | accuracy: 0.5046875000000003 \n",
      "Epoch 1 | Step 61 | loss: 0.796278781578189 | accuracy: 0.5069159836065577 \n",
      "Epoch 1 | Step 62 | loss: 0.7951962236435183 | accuracy: 0.5075604838709681 \n",
      "Epoch 1 | Step 63 | loss: 0.7952671817370823 | accuracy: 0.5062003968253972 \n",
      "Epoch 1 | Step 64 | loss: 0.7940643886104226 | accuracy: 0.5073242187500003 \n",
      "Epoch 1 | Step 65 | loss: 0.7927142161589402 | accuracy: 0.5069711538461542 \n",
      "Epoch 1 | Step 66 | loss: 0.7918789693803499 | accuracy: 0.5068655303030306 \n",
      "Epoch 1 | Step 67 | loss: 0.7902744456903258 | accuracy: 0.5072294776119406 \n",
      "Epoch 1 | Step 68 | loss: 0.7887878102414748 | accuracy: 0.508042279411765 \n",
      "Epoch 1 | Step 69 | loss: 0.7873974831207938 | accuracy: 0.509057971014493 \n",
      "Epoch 1 | Step 70 | loss: 0.7864271078790936 | accuracy: 0.509151785714286 \n",
      "Epoch 1 | Step 71 | loss: 0.7842886892842574 | accuracy: 0.5107834507042257 \n",
      "Epoch 1 | Step 72 | loss: 0.7824872343076599 | accuracy: 0.5125868055555559 \n",
      "Epoch 1 | Step 73 | loss: 0.7811507819450064 | accuracy: 0.5136986301369867 \n",
      "Epoch 1 | Step 74 | loss: 0.7797048357692924 | accuracy: 0.5152027027027031 \n",
      "Epoch 1 | Step 75 | loss: 0.7785324136416116 | accuracy: 0.5158333333333337 \n",
      "Epoch 1 | Step 76 | loss: 0.7765486028633619 | accuracy: 0.5178865131578951 \n",
      "Epoch 1 | Step 77 | loss: 0.7762372470521307 | accuracy: 0.5166396103896107 \n",
      "Epoch 1 | Step 78 | loss: 0.7756684735799446 | accuracy: 0.5166266025641029 \n",
      "Epoch 1 | Step 79 | loss: 0.7752074863337263 | accuracy: 0.5164161392405066 \n",
      "Epoch 1 | Step 80 | loss: 0.7747989036142825 | accuracy: 0.5154296875000003 \n",
      "Epoch 1 | Step 81 | loss: 0.7742991072160226 | accuracy: 0.5150462962962966 \n",
      "Epoch 1 | Step 82 | loss: 0.7731149494647979 | accuracy: 0.5161966463414638 \n",
      "Epoch 1 | Step 83 | loss: 0.7725349542606308 | accuracy: 0.516189759036145 \n",
      "Epoch 1 | Step 84 | loss: 0.7720239119870322 | accuracy: 0.516183035714286 \n",
      "Epoch 1 | Step 85 | loss: 0.7714583011234508 | accuracy: 0.5163602941176474 \n",
      "Epoch 1 | Step 86 | loss: 0.7701855059279952 | accuracy: 0.5168968023255818 \n",
      "Epoch 1 | Step 87 | loss: 0.7695260164381443 | accuracy: 0.5168821839080464 \n",
      "Epoch 1 | Step 88 | loss: 0.7696644060991027 | accuracy: 0.5159801136363641 \n",
      "Epoch 1 | Step 89 | loss: 0.7686769540390271 | accuracy: 0.5166783707865173 \n",
      "Epoch 1 | Step 90 | loss: 0.7683577060699462 | accuracy: 0.516493055555556 \n",
      "Epoch 1 | Step 91 | loss: 0.7680657826937162 | accuracy: 0.5156250000000004 \n",
      "Epoch 1 | Step 92 | loss: 0.7671716154917426 | accuracy: 0.5154551630434787 \n",
      "Epoch 1 | Step 93 | loss: 0.7665024444621097 | accuracy: 0.5162970430107532 \n",
      "Epoch 1 | Step 94 | loss: 0.7656295388302905 | accuracy: 0.5169547872340431 \n",
      "Epoch 1 | Step 95 | loss: 0.7654002459425675 | accuracy: 0.5162828947368426 \n",
      "Epoch 1 | Step 96 | loss: 0.7648525883754095 | accuracy: 0.5157877604166672 \n",
      "Epoch 1 | Step 97 | loss: 0.7639357509072294 | accuracy: 0.516913659793815 \n",
      "Epoch 1 | Step 98 | loss: 0.7634303934720098 | accuracy: 0.5167410714285721 \n",
      "Epoch 1 | Step 99 | loss: 0.7624608452874001 | accuracy: 0.51751893939394 \n",
      "Epoch 1 | Step 100 | loss: 0.7621044129133224 | accuracy: 0.5179687500000005 \n",
      "Epoch 1 | Step 101 | loss: 0.7615670449662917 | accuracy: 0.518100247524753 \n",
      "Epoch 1 | Step 102 | loss: 0.7618566260618322 | accuracy: 0.517616421568628 \n",
      "Epoch 1 | Step 103 | loss: 0.7610942414663371 | accuracy: 0.5177487864077674 \n",
      "Epoch 1 | Step 104 | loss: 0.7607427835464478 | accuracy: 0.516977163461539 \n",
      "Epoch 1 | Step 105 | loss: 0.7597174803415935 | accuracy: 0.5180059523809529 \n",
      "Epoch 1 | Step 106 | loss: 0.7587910699394514 | accuracy: 0.5185731132075477 \n",
      "Epoch 1 | Step 107 | loss: 0.7584524422048409 | accuracy: 0.5183995327102809 \n",
      "Epoch 1 | Step 108 | loss: 0.7578466435273489 | accuracy: 0.5186631944444451 \n",
      "Epoch 1 | Step 109 | loss: 0.7576709067055939 | accuracy: 0.5183486238532117 \n",
      "Epoch 1 | Step 110 | loss: 0.7566151781515642 | accuracy: 0.519176136363637 \n",
      "Epoch 1 | Step 111 | loss: 0.7558627912590096 | accuracy: 0.5198479729729736 \n",
      "Epoch 1 | Step 112 | loss: 0.7553885690867901 | accuracy: 0.5200892857142864 \n",
      "Epoch 1 | Step 113 | loss: 0.7546889919095334 | accuracy: 0.5203263274336289 \n",
      "Epoch 1 | Step 114 | loss: 0.7538567985358992 | accuracy: 0.5209703947368427 \n",
      "Epoch 1 | Step 115 | loss: 0.7534485075784766 | accuracy: 0.5210597826086962 \n",
      "Epoch 1 | Step 116 | loss: 0.7532044212365973 | accuracy: 0.5207435344827591 \n",
      "Epoch 1 | Step 117 | loss: 0.7528496506886605 | accuracy: 0.5211004273504278 \n",
      "Epoch 1 | Step 118 | loss: 0.7524967461319293 | accuracy: 0.5210540254237293 \n",
      "Epoch 1 | Step 119 | loss: 0.75223712911125 | accuracy: 0.5208771008403366 \n",
      "Epoch 1 | Step 120 | loss: 0.7518260185917218 | accuracy: 0.5207031250000004 \n",
      "Epoch 1 | Step 121 | loss: 0.7513990796301976 | accuracy: 0.5210485537190086 \n",
      "Epoch 1 | Step 122 | loss: 0.7509633410172384 | accuracy: 0.5208760245901642 \n",
      "Epoch 1 | Step 123 | loss: 0.7504291713722353 | accuracy: 0.5212144308943092 \n",
      "Epoch 1 | Step 124 | loss: 0.7497455621919324 | accuracy: 0.5216733870967745 \n",
      "Epoch 1 | Step 125 | loss: 0.7496132364273072 | accuracy: 0.5218750000000002 \n",
      "Epoch 1 | Step 126 | loss: 0.7492480140829844 | accuracy: 0.5217013888888891 \n",
      "Epoch 1 | Step 127 | loss: 0.7488897658708528 | accuracy: 0.5221456692913388 \n",
      "Epoch 1 | Step 128 | loss: 0.7489331178367138 | accuracy: 0.5212402343750002 \n",
      "Epoch 1 | Step 129 | loss: 0.7486813909323641 | accuracy: 0.5216812015503878 \n",
      "Epoch 1 | Step 130 | loss: 0.7479501403295077 | accuracy: 0.5218750000000002 \n",
      "Epoch 1 | Step 131 | loss: 0.7478255474840412 | accuracy: 0.5213501908396949 \n",
      "Epoch 1 | Step 132 | loss: 0.7480001219294288 | accuracy: 0.52047821969697 \n",
      "Epoch 1 | Step 133 | loss: 0.7477204983395741 | accuracy: 0.5204417293233085 \n",
      "Epoch 1 | Step 134 | loss: 0.7475907922680698 | accuracy: 0.5204057835820898 \n",
      "Epoch 1 | Step 135 | loss: 0.7472622310673749 | accuracy: 0.5202546296296299 \n",
      "Epoch 1 | Step 136 | loss: 0.7467787072939032 | accuracy: 0.520450367647059 \n",
      "Epoch 1 | Step 137 | loss: 0.7463103354412274 | accuracy: 0.5203010948905111 \n",
      "Epoch 1 | Step 138 | loss: 0.746077325033105 | accuracy: 0.5206068840579712 \n",
      "Epoch 1 | Step 139 | loss: 0.746063121359983 | accuracy: 0.520346223021583 \n",
      "Epoch 1 | Step 140 | loss: 0.7456850801195417 | accuracy: 0.5205357142857144 \n",
      "Epoch 1 | Step 141 | loss: 0.7452815432920523 | accuracy: 0.5213874113475179 \n",
      "Epoch 1 | Step 142 | loss: 0.7449814517733077 | accuracy: 0.5220070422535212 \n",
      "Epoch 1 | Step 143 | loss: 0.7444196872777872 | accuracy: 0.5223994755244756 \n",
      "Epoch 1 | Step 144 | loss: 0.7438125126063824 | accuracy: 0.522677951388889 \n",
      "Epoch 1 | Step 145 | loss: 0.7433058874360446 | accuracy: 0.523491379310345 \n",
      "Epoch 1 | Step 146 | loss: 0.7431709962348415 | accuracy: 0.5233304794520549 \n",
      "Epoch 1 | Step 147 | loss: 0.7430854326202756 | accuracy: 0.5229591836734695 \n",
      "Epoch 1 | Step 148 | loss: 0.7425801339181693 | accuracy: 0.5235430743243245 \n",
      "Epoch 1 | Step 149 | loss: 0.7422143076890267 | accuracy: 0.5240142617449666 \n",
      "Epoch 1 | Step 150 | loss: 0.741999564965566 | accuracy: 0.5244791666666667 \n",
      "Epoch 1 | Step 151 | loss: 0.7413224909479255 | accuracy: 0.5254552980132451 \n",
      "Epoch 1 | Step 152 | loss: 0.7411717035268482 | accuracy: 0.5258018092105264 \n",
      "Epoch 1 | Step 153 | loss: 0.7408437167896944 | accuracy: 0.5264501633986929 \n",
      "Epoch 1 | Step 154 | loss: 0.7409334198220984 | accuracy: 0.5260754870129871 \n",
      "Epoch 1 | Step 155 | loss: 0.7405032611662342 | accuracy: 0.5261088709677421 \n",
      "Epoch 1 | Step 156 | loss: 0.740360900377616 | accuracy: 0.526141826923077 \n",
      "Epoch 1 | Step 157 | loss: 0.7398266944156332 | accuracy: 0.5268710191082804 \n",
      "Epoch 1 | Step 158 | loss: 0.7395185160486005 | accuracy: 0.5269976265822786 \n",
      "Epoch 1 | Step 159 | loss: 0.7389301076625129 | accuracy: 0.527613993710692 \n",
      "Epoch 1 | Step 160 | loss: 0.7387104850262405 | accuracy: 0.5279296875000001 \n",
      "Epoch 1 | Step 161 | loss: 0.7384928235356113 | accuracy: 0.5277562111801244 \n",
      "Epoch 1 | Step 162 | loss: 0.7378503120975731 | accuracy: 0.5287422839506175 \n",
      "Epoch 1 | Step 163 | loss: 0.7374053279315037 | accuracy: 0.5292369631901843 \n",
      "Epoch 1 | Step 164 | loss: 0.7372642642841107 | accuracy: 0.5294397865853662 \n",
      "Epoch 1 | Step 165 | loss: 0.7369898492639716 | accuracy: 0.5299242424242427 \n",
      "Epoch 1 | Step 166 | loss: 0.7365993394191007 | accuracy: 0.5299322289156629 \n",
      "Epoch 1 | Step 167 | loss: 0.7359881790098317 | accuracy: 0.5305014970059883 \n",
      "Epoch 1 | Step 168 | loss: 0.7358623203777133 | accuracy: 0.5305989583333336 \n",
      "Epoch 1 | Step 169 | loss: 0.7358180079939803 | accuracy: 0.5303254437869825 \n",
      "Epoch 1 | Step 170 | loss: 0.7353035039761489 | accuracy: 0.530698529411765 \n",
      "Epoch 1 | Step 171 | loss: 0.7349089234195957 | accuracy: 0.5311586257309944 \n",
      "Epoch 1 | Step 172 | loss: 0.7348947843839958 | accuracy: 0.5311591569767444 \n",
      "Epoch 1 | Step 173 | loss: 0.7345119983474646 | accuracy: 0.5315209537572256 \n",
      "Epoch 1 | Step 174 | loss: 0.7341905804886218 | accuracy: 0.5318785919540232 \n",
      "Epoch 1 | Step 175 | loss: 0.7335339546203616 | accuracy: 0.5329464285714288 \n",
      "Epoch 1 | Step 176 | loss: 0.7337400242686275 | accuracy: 0.5327592329545457 \n",
      "Epoch 1 | Step 177 | loss: 0.7335200754262636 | accuracy: 0.5331920903954805 \n",
      "Epoch 1 | Step 178 | loss: 0.7332473745506805 | accuracy: 0.532917837078652 \n",
      "Epoch 1 | Step 179 | loss: 0.7336605773957752 | accuracy: 0.53203561452514 \n",
      "Epoch 1 | Step 180 | loss: 0.7335281312465671 | accuracy: 0.5322048611111115 \n",
      "Epoch 1 | Step 181 | loss: 0.7334233423622936 | accuracy: 0.5325448895027628 \n",
      "Epoch 1 | Step 182 | loss: 0.7332304215038219 | accuracy: 0.53279532967033 \n",
      "Epoch 1 | Step 183 | loss: 0.7328558547900678 | accuracy: 0.5332991803278693 \n",
      "Epoch 1 | Step 184 | loss: 0.7324174402848537 | accuracy: 0.5337126358695656 \n",
      "Epoch 1 | Step 185 | loss: 0.7322710233765682 | accuracy: 0.5333614864864868 \n",
      "Epoch 1 | Step 186 | loss: 0.7319252712111323 | accuracy: 0.533770161290323 \n",
      "Epoch 1 | Step 187 | loss: 0.7315547271845816 | accuracy: 0.5342580213903747 \n",
      "Epoch 1 | Step 188 | loss: 0.7311087710426212 | accuracy: 0.5345744680851068 \n",
      "Epoch 1 | Step 189 | loss: 0.7309535741806034 | accuracy: 0.5346395502645507 \n",
      "Epoch 1 | Step 190 | loss: 0.7307093783428797 | accuracy: 0.5347861842105268 \n",
      "Epoch 1 | Step 191 | loss: 0.7302597620724386 | accuracy: 0.5353403141361261 \n",
      "Epoch 1 | Step 192 | loss: 0.7298759988819562 | accuracy: 0.5357259114583338 \n",
      "Epoch 1 | Step 193 | loss: 0.7297684679994932 | accuracy: 0.5359455958549227 \n",
      "Epoch 1 | Step 194 | loss: 0.7293435292145644 | accuracy: 0.5364851804123716 \n",
      "Epoch 1 | Step 195 | loss: 0.7291565882853975 | accuracy: 0.5366185897435902 \n",
      "Epoch 1 | Step 196 | loss: 0.7289596634859944 | accuracy: 0.5370695153061229 \n",
      "Epoch 1 | Step 197 | loss: 0.7286213790704759 | accuracy: 0.537595177664975 \n",
      "Epoch 1 | Step 198 | loss: 0.7281440222504166 | accuracy: 0.5381155303030306 \n",
      "Epoch 1 | Step 199 | loss: 0.7280861687420603 | accuracy: 0.5379239949748746 \n",
      "Epoch 1 | Step 200 | loss: 0.727797757983208 | accuracy: 0.5381250000000003 \n",
      "Epoch 1 | Step 201 | loss: 0.7275516132810226 | accuracy: 0.5381685323383087 \n",
      "Epoch 1 | Step 202 | loss: 0.7272246677686676 | accuracy: 0.5384436881188122 \n",
      "Epoch 1 | Step 203 | loss: 0.7270172852013501 | accuracy: 0.5387931034482761 \n",
      "Epoch 1 | Step 204 | loss: 0.7269635968932922 | accuracy: 0.5382199754901964 \n",
      "Epoch 1 | Step 205 | loss: 0.7266099045916304 | accuracy: 0.5384146341463418 \n",
      "Epoch 1 | Step 206 | loss: 0.7263118575498898 | accuracy: 0.5385315533980586 \n",
      "Epoch 1 | Step 207 | loss: 0.7263594048034745 | accuracy: 0.5384208937198071 \n",
      "Epoch 1 | Step 208 | loss: 0.7258639364288406 | accuracy: 0.5391376201923079 \n",
      "Epoch 1 | Step 209 | loss: 0.725589212903566 | accuracy: 0.5394736842105265 \n",
      "Epoch 1 | Step 210 | loss: 0.7254445958705178 | accuracy: 0.5395833333333335 \n",
      "Epoch 1 | Step 211 | loss: 0.7250738248440894 | accuracy: 0.539988151658768 \n",
      "Epoch 1 | Step 212 | loss: 0.7250647862564845 | accuracy: 0.5397258254716983 \n",
      "Epoch 1 | Step 213 | loss: 0.7249836401200633 | accuracy: 0.5394659624413147 \n",
      "Epoch 1 | Step 214 | loss: 0.7247231468976104 | accuracy: 0.5394275700934581 \n",
      "Epoch 1 | Step 215 | loss: 0.7245397365370465 | accuracy: 0.5397529069767443 \n",
      "Epoch 1 | Step 216 | loss: 0.724307480785582 | accuracy: 0.5400028935185186 \n",
      "Epoch 1 | Step 217 | loss: 0.7239078753005527 | accuracy: 0.5401065668202766 \n",
      "Epoch 1 | Step 218 | loss: 0.7236573879325064 | accuracy: 0.540352637614679 \n",
      "Epoch 1 | Step 219 | loss: 0.7233086916954008 | accuracy: 0.5408818493150687 \n",
      "Epoch 1 | Step 220 | loss: 0.7231451359662145 | accuracy: 0.5411221590909093 \n",
      "Epoch 1 | Step 221 | loss: 0.722878578831168 | accuracy: 0.5412188914027152 \n",
      "Epoch 1 | Step 222 | loss: 0.7225768064056434 | accuracy: 0.5414555180180183 \n",
      "Epoch 1 | Step 223 | loss: 0.7221023544602333 | accuracy: 0.5420403587443948 \n",
      "Epoch 1 | Step 224 | loss: 0.7217814070837841 | accuracy: 0.5421316964285716 \n",
      "Epoch 1 | Step 225 | loss: 0.7215232104725311 | accuracy: 0.5423611111111113 \n",
      "Epoch 1 | Step 226 | loss: 0.7210059194965702 | accuracy: 0.543003318584071 \n",
      "Epoch 1 | Step 227 | loss: 0.7206411267167149 | accuracy: 0.5435022026431721 \n",
      "Epoch 1 | Step 228 | loss: 0.720239198782988 | accuracy: 0.543996710526316 \n",
      "Epoch 1 | Step 229 | loss: 0.7198731691035644 | accuracy: 0.544350436681223 \n",
      "Epoch 1 | Step 230 | loss: 0.7197178607401643 | accuracy: 0.5445652173913046 \n",
      "Epoch 1 | Step 231 | loss: 0.7193911119456934 | accuracy: 0.5447781385281387 \n",
      "Epoch 1 | Step 232 | loss: 0.719253279782575 | accuracy: 0.5449892241379313 \n",
      "Epoch 1 | Step 233 | loss: 0.7191023570785198 | accuracy: 0.5449302575107299 \n",
      "Epoch 1 | Step 234 | loss: 0.7192199436517864 | accuracy: 0.5442708333333336 \n",
      "Epoch 1 | Step 235 | loss: 0.7191496202286256 | accuracy: 0.5442819148936172 \n",
      "Epoch 1 | Step 236 | loss: 0.7188842758788904 | accuracy: 0.5448225635593222 \n",
      "Epoch 1 | Step 237 | loss: 0.7188843531447626 | accuracy: 0.5445675105485235 \n",
      "Epoch 1 | Step 238 | loss: 0.7187973255870725 | accuracy: 0.5443802521008406 \n",
      "Epoch 1 | Step 239 | loss: 0.7187693146482175 | accuracy: 0.5439984309623433 \n",
      "Epoch 1 | Step 240 | loss: 0.7185758516192439 | accuracy: 0.5443359375000002 \n",
      "Epoch 1 | Step 241 | loss: 0.7185786265060617 | accuracy: 0.5444113070539421 \n",
      "Epoch 1 | Step 242 | loss: 0.718662614911056 | accuracy: 0.5440340909090912 \n",
      "Epoch 1 | Step 243 | loss: 0.7185154324205817 | accuracy: 0.5438528806584364 \n",
      "Epoch 1 | Step 244 | loss: 0.7183091987351905 | accuracy: 0.543801229508197 \n",
      "Epoch 1 | Step 245 | loss: 0.7179587546659978 | accuracy: 0.5441326530612247 \n",
      "Epoch 1 | Step 246 | loss: 0.7178628483438881 | accuracy: 0.5442708333333336 \n",
      "Epoch 1 | Step 247 | loss: 0.7176986030238846 | accuracy: 0.5443446356275305 \n",
      "Epoch 1 | Step 248 | loss: 0.7176781061195561 | accuracy: 0.5443548387096776 \n",
      "Epoch 1 | Step 249 | loss: 0.7178038815896676 | accuracy: 0.5443649598393576 \n",
      "Epoch 1 | Step 250 | loss: 0.7176568148136141 | accuracy: 0.5445000000000002 \n",
      "Epoch 1 | Step 251 | loss: 0.7174957304361809 | accuracy: 0.5445094621513946 \n",
      "Epoch 1 | Step 252 | loss: 0.7174462588533524 | accuracy: 0.5445188492063494 \n",
      "Epoch 1 | Step 253 | loss: 0.7172477728293349 | accuracy: 0.5447751976284587 \n",
      "Epoch 1 | Step 254 | loss: 0.71700589558271 | accuracy: 0.5449064960629924 \n",
      "Epoch 1 | Step 255 | loss: 0.7169380924280955 | accuracy: 0.5454044117647061 \n",
      "Epoch 1 | Step 256 | loss: 0.7169361370615663 | accuracy: 0.5451049804687502 \n",
      "Epoch 1 | Step 257 | loss: 0.7167606339844287 | accuracy: 0.5453550583657589 \n",
      "Epoch 1 | Step 258 | loss: 0.7166919717492986 | accuracy: 0.5453003875968995 \n",
      "Epoch 1 | Step 259 | loss: 0.7164765658525889 | accuracy: 0.5453064671814674 \n",
      "Epoch 1 | Step 260 | loss: 0.7163892363126464 | accuracy: 0.545252403846154 \n",
      "Epoch 1 | Step 261 | loss: 0.7165007157344017 | accuracy: 0.5451388888888891 \n",
      "Epoch 1 | Step 262 | loss: 0.7162930046329063 | accuracy: 0.5453244274809163 \n",
      "Epoch 1 | Step 263 | loss: 0.7161866798147052 | accuracy: 0.54550855513308 \n",
      "Epoch 1 | Step 264 | loss: 0.716018669081457 | accuracy: 0.5456912878787881 \n",
      "Epoch 1 | Step 265 | loss: 0.7158815278197237 | accuracy: 0.5458136792452832 \n",
      "Epoch 1 | Step 266 | loss: 0.7157535900298816 | accuracy: 0.5459938909774438 \n",
      "Epoch 1 | Step 267 | loss: 0.7156183991985823 | accuracy: 0.5461142322097381 \n",
      "Epoch 1 | Step 268 | loss: 0.7154157759983151 | accuracy: 0.5463502798507465 \n",
      "Epoch 1 | Step 269 | loss: 0.7152835857469355 | accuracy: 0.546468401486989 \n",
      "Epoch 1 | Step 270 | loss: 0.714996178282632 | accuracy: 0.5468171296296298 \n",
      "Epoch 1 | Step 271 | loss: 0.714655442871291 | accuracy: 0.5469903136531368 \n",
      "Epoch 1 | Step 272 | loss: 0.7142681678866641 | accuracy: 0.5473920036764708 \n",
      "Epoch 1 | Step 273 | loss: 0.7140105997686423 | accuracy: 0.5477335164835166 \n",
      "Epoch 1 | Step 274 | loss: 0.714016036178074 | accuracy: 0.5475593065693433 \n",
      "Epoch 1 | Step 275 | loss: 0.7140736369653183 | accuracy: 0.5475000000000002 \n",
      "Epoch 1 | Step 276 | loss: 0.7139845665382304 | accuracy: 0.5476675724637683 \n",
      "Epoch 1 | Step 277 | loss: 0.714092023966545 | accuracy: 0.547664711191336 \n",
      "Epoch 1 | Step 278 | loss: 0.7139264769691359 | accuracy: 0.5478866906474822 \n",
      "Epoch 1 | Step 279 | loss: 0.7141374682867401 | accuracy: 0.5474350358422941 \n",
      "Epoch 1 | Step 280 | loss: 0.7138722077012064 | accuracy: 0.5477678571428574 \n",
      "Epoch 1 | Step 281 | loss: 0.7136136350682624 | accuracy: 0.5482095195729539 \n",
      "Epoch 1 | Step 282 | loss: 0.7133979006861966 | accuracy: 0.5487034574468087 \n",
      "Epoch 1 | Step 283 | loss: 0.7133682660837479 | accuracy: 0.5487522084805656 \n",
      "Epoch 1 | Step 284 | loss: 0.7129338956634765 | accuracy: 0.5494058098591551 \n",
      "Epoch 1 | Step 285 | loss: 0.7127404246413919 | accuracy: 0.5495614035087721 \n",
      "Epoch 1 | Step 286 | loss: 0.712540383939143 | accuracy: 0.5497159090909093 \n",
      "Epoch 1 | Step 287 | loss: 0.7124072809667955 | accuracy: 0.5497604529616726 \n",
      "Epoch 1 | Step 288 | loss: 0.7122103435297809 | accuracy: 0.5500759548611113 \n",
      "Epoch 1 | Step 289 | loss: 0.711920907134416 | accuracy: 0.5505514705882355 \n",
      "Epoch 1 | Step 290 | loss: 0.7117395339341002 | accuracy: 0.5504310344827588 \n",
      "Epoch 1 | Step 291 | loss: 0.7114885443264678 | accuracy: 0.5509020618556703 \n",
      "Epoch 1 | Step 292 | loss: 0.7112526669077679 | accuracy: 0.551209332191781 \n",
      "Epoch 1 | Step 293 | loss: 0.7111560771489714 | accuracy: 0.5513545221843006 \n",
      "Epoch 1 | Step 294 | loss: 0.711052096822635 | accuracy: 0.5512329931972793 \n",
      "Epoch 1 | Step 295 | loss: 0.7109253897505293 | accuracy: 0.551430084745763 \n",
      "Epoch 1 | Step 296 | loss: 0.7108325680365436 | accuracy: 0.5513619087837842 \n",
      "Epoch 1 | Step 297 | loss: 0.7106536739201661 | accuracy: 0.5518202861952866 \n",
      "Epoch 1 | Step 298 | loss: 0.7105723997490521 | accuracy: 0.5518561241610742 \n",
      "Epoch 1 | Step 299 | loss: 0.7106286203582154 | accuracy: 0.5515781772575254 \n",
      "Epoch 1 | Step 300 | loss: 0.7106564325094226 | accuracy: 0.551510416666667 \n",
      "Epoch 1 | Step 301 | loss: 0.7106350266260169 | accuracy: 0.5512873754152827 \n",
      "Epoch 1 | Step 302 | loss: 0.7106942727865765 | accuracy: 0.5510658112582785 \n",
      "Epoch 1 | Step 303 | loss: 0.7104963365167677 | accuracy: 0.5512066831683171 \n",
      "Epoch 1 | Step 304 | loss: 0.7103098374056191 | accuracy: 0.5512438322368424 \n",
      "Epoch 1 | Step 305 | loss: 0.7101380588578399 | accuracy: 0.5512295081967216 \n",
      "Epoch 1 | Step 306 | loss: 0.7100364986587976 | accuracy: 0.5514195261437911 \n",
      "Epoch 1 | Step 307 | loss: 0.7098154802275795 | accuracy: 0.55171009771987 \n",
      "Epoch 1 | Step 308 | loss: 0.7095662721178753 | accuracy: 0.5521002435064938 \n",
      "Epoch 1 | Step 309 | loss: 0.7094590411217087 | accuracy: 0.5521338996763757 \n",
      "Epoch 1 | Step 310 | loss: 0.7094273007685143 | accuracy: 0.5522681451612906 \n",
      "Epoch 1 | Step 311 | loss: 0.7093380402138768 | accuracy: 0.55240152733119 \n",
      "Epoch 1 | Step 312 | loss: 0.7092654962952326 | accuracy: 0.5521834935897438 \n",
      "Epoch 1 | Step 313 | loss: 0.7089423784813567 | accuracy: 0.5525159744408948 \n",
      "Epoch 1 | Step 314 | loss: 0.7088185108391348 | accuracy: 0.5528463375796181 \n",
      "Epoch 1 | Step 315 | loss: 0.7088761558608409 | accuracy: 0.5528273809523813 \n",
      "Epoch 1 | Step 316 | loss: 0.7088218548252618 | accuracy: 0.5526602056962028 \n",
      "Epoch 1 | Step 317 | loss: 0.7085237196567312 | accuracy: 0.5530855678233442 \n",
      "Epoch 1 | Step 318 | loss: 0.7084766665719595 | accuracy: 0.5532625786163525 \n",
      "Epoch 1 | Step 319 | loss: 0.7082426832013748 | accuracy: 0.5534384796238248 \n",
      "Epoch 1 | Step 320 | loss: 0.7079636408016091 | accuracy: 0.5538085937500002 \n",
      "Epoch 1 | Step 321 | loss: 0.7078044665194009 | accuracy: 0.5538843457943928 \n",
      "Epoch 1 | Step 322 | loss: 0.7077138094428168 | accuracy: 0.5539596273291928 \n",
      "Epoch 1 | Step 323 | loss: 0.7075206279385575 | accuracy: 0.5542279411764709 \n",
      "Epoch 1 | Step 324 | loss: 0.7074154832480871 | accuracy: 0.5544945987654324 \n",
      "Epoch 1 | Step 325 | loss: 0.707435256517851 | accuracy: 0.5541826923076926 \n",
      "Epoch 1 | Step 326 | loss: 0.7071505646032795 | accuracy: 0.5545916411042947 \n",
      "Epoch 1 | Step 327 | loss: 0.7071143142673952 | accuracy: 0.5545202599388381 \n",
      "Epoch 1 | Step 328 | loss: 0.7071007595556543 | accuracy: 0.5543064024390245 \n",
      "Epoch 1 | Step 329 | loss: 0.706982708267166 | accuracy: 0.5543313069908815 \n",
      "Epoch 1 | Step 330 | loss: 0.706875980442221 | accuracy: 0.5545928030303031 \n",
      "Epoch 1 | Step 331 | loss: 0.7067668772896256 | accuracy: 0.5546638972809669 \n",
      "Epoch 1 | Step 332 | loss: 0.7067386610321257 | accuracy: 0.5546875000000001 \n",
      "Epoch 1 | Step 333 | loss: 0.7067922577485671 | accuracy: 0.5542417417417418 \n",
      "Epoch 1 | Step 334 | loss: 0.7066030446997664 | accuracy: 0.5544535928143713 \n",
      "Epoch 1 | Step 335 | loss: 0.7063654936961278 | accuracy: 0.5547108208955225 \n",
      "Epoch 1 | Step 336 | loss: 0.7061046127762117 | accuracy: 0.554873511904762 \n",
      "Epoch 1 | Step 337 | loss: 0.7059551226279153 | accuracy: 0.5548961424332345 \n",
      "Epoch 1 | Step 338 | loss: 0.7059504289246173 | accuracy: 0.5549648668639054 \n",
      "Epoch 1 | Step 339 | loss: 0.7056108030949374 | accuracy: 0.5554480088495576 \n",
      "Epoch 1 | Step 340 | loss: 0.7054167325005816 | accuracy: 0.5557444852941177 \n",
      "Epoch 1 | Step 341 | loss: 0.7053809985736952 | accuracy: 0.5556726539589443 \n",
      "Epoch 1 | Step 342 | loss: 0.7051893938006021 | accuracy: 0.5557383040935673 \n",
      "Epoch 1 | Step 343 | loss: 0.7050169544734348 | accuracy: 0.5557580174927114 \n",
      "Epoch 1 | Step 344 | loss: 0.7047540699673258 | accuracy: 0.5561864098837209 \n",
      "Epoch 1 | Step 345 | loss: 0.7046217419099121 | accuracy: 0.55625 \n",
      "Epoch 1 | Step 346 | loss: 0.7044818149825746 | accuracy: 0.5563132225433526 \n",
      "Epoch 1 | Step 347 | loss: 0.7043210513653608 | accuracy: 0.5564211095100865 \n",
      "Epoch 1 | Step 348 | loss: 0.7042339325978842 | accuracy: 0.5565283764367817 \n",
      "Epoch 1 | Step 349 | loss: 0.7040382604885925 | accuracy: 0.5567693409742122 \n",
      "Epoch 1 | Step 350 | loss: 0.7038596318449297 | accuracy: 0.556919642857143 \n",
      "Epoch 1 | Step 351 | loss: 0.7037334202701214 | accuracy: 0.5569355413105415 \n",
      "Epoch 1 | Step 352 | loss: 0.70349507406354 | accuracy: 0.5570845170454547 \n",
      "Epoch 1 | Step 353 | loss: 0.7033828496932988 | accuracy: 0.5572769121813033 \n",
      "Epoch 1 | Step 354 | loss: 0.7032686793534774 | accuracy: 0.5574240819209041 \n",
      "Epoch 1 | Step 355 | loss: 0.7032114086016807 | accuracy: 0.5575704225352114 \n",
      "Epoch 1 | Step 356 | loss: 0.7030890950661032 | accuracy: 0.5576720505617978 \n",
      "Epoch 1 | Step 357 | loss: 0.7028061460380132 | accuracy: 0.5580357142857144 \n",
      "Epoch 1 | Step 358 | loss: 0.7025536451925783 | accuracy: 0.5582227653631286 \n",
      "Epoch 1 | Step 359 | loss: 0.702394746472245 | accuracy: 0.5584522980501394 \n",
      "Epoch 1 | Step 360 | loss: 0.7024160881837214 | accuracy: 0.5582899305555558 \n",
      "Epoch 1 | Step 361 | loss: 0.7021037761194229 | accuracy: 0.5589075484764545 \n",
      "Epoch 1 | Step 362 | loss: 0.7018358659678406 | accuracy: 0.5592196132596687 \n",
      "Epoch 1 | Step 363 | loss: 0.7018318427495726 | accuracy: 0.5592716942148762 \n",
      "Epoch 1 | Step 364 | loss: 0.7016049032355408 | accuracy: 0.5592376373626375 \n",
      "Epoch 1 | Step 365 | loss: 0.7015173291506839 | accuracy: 0.5594178082191782 \n",
      "Epoch 1 | Step 366 | loss: 0.7012074959408396 | accuracy: 0.559938524590164 \n",
      "Epoch 1 | Step 367 | loss: 0.7011252552352101 | accuracy: 0.5600732288828338 \n",
      "Epoch 1 | Step 368 | loss: 0.7010996670502689 | accuracy: 0.5599099864130436 \n",
      "Epoch 1 | Step 369 | loss: 0.7010422106680837 | accuracy: 0.5600863821138212 \n",
      "Epoch 1 | Step 370 | loss: 0.701071267514616 | accuracy: 0.5599662162162163 \n",
      "Epoch 1 | Step 371 | loss: 0.7009712033515998 | accuracy: 0.5600993935309975 \n",
      "Epoch 1 | Step 372 | loss: 0.7008493154920563 | accuracy: 0.5601058467741937 \n",
      "Epoch 1 | Step 373 | loss: 0.7007989889814776 | accuracy: 0.5602379356568367 \n",
      "Epoch 1 | Step 374 | loss: 0.7005002093825117 | accuracy: 0.5607453208556152 \n",
      "Epoch 1 | Step 375 | loss: 0.7004285610516872 | accuracy: 0.5606666666666669 \n",
      "Epoch 1 | Step 376 | loss: 0.7003538540386145 | accuracy: 0.5606299867021279 \n",
      "Epoch 1 | Step 377 | loss: 0.7001413168578319 | accuracy: 0.5608421750663133 \n",
      "Epoch 1 | Step 378 | loss: 0.7000930574205193 | accuracy: 0.5607638888888892 \n",
      "Epoch 1 | Step 379 | loss: 0.7000052471274127 | accuracy: 0.5608509234828499 \n",
      "Epoch 1 | Step 380 | loss: 0.6997793352917627 | accuracy: 0.5610197368421056 \n",
      "Epoch 1 | Step 381 | loss: 0.6998923480354275 | accuracy: 0.5609005905511814 \n",
      "Epoch 1 | Step 382 | loss: 0.6996793509777934 | accuracy: 0.5611092931937175 \n",
      "Epoch 1 | Step 383 | loss: 0.6996345871733629 | accuracy: 0.5610721279373371 \n",
      "Epoch 1 | Step 384 | loss: 0.6994922159550097 | accuracy: 0.5611979166666669 \n",
      "Epoch 1 | Step 385 | loss: 0.6994703069909832 | accuracy: 0.5612824675324677 \n",
      "Epoch 1 | Step 386 | loss: 0.6995163987646454 | accuracy: 0.561164183937824 \n",
      "Epoch 1 | Step 387 | loss: 0.6995545658030257 | accuracy: 0.5610868863049097 \n",
      "Epoch 1 | Step 388 | loss: 0.6994691268377703 | accuracy: 0.5611307989690723 \n",
      "Epoch 1 | Step 389 | loss: 0.6995895607612439 | accuracy: 0.5609736503856042 \n",
      "Epoch 1 | Step 390 | loss: 0.6995435404471868 | accuracy: 0.5609775641025642 \n",
      "Epoch 1 | Step 391 | loss: 0.699447848455376 | accuracy: 0.5609015345268543 \n",
      "Epoch 1 | Step 392 | loss: 0.6993265012089093 | accuracy: 0.5609454719387755 \n",
      "Epoch 1 | Step 393 | loss: 0.6991602743551634 | accuracy: 0.5610687022900763 \n",
      "Epoch 1 | Step 394 | loss: 0.6991373164399632 | accuracy: 0.5612706218274112 \n",
      "Epoch 1 | Step 395 | loss: 0.6991125437277788 | accuracy: 0.5613132911392406 \n",
      "Epoch 1 | Step 396 | loss: 0.6988728335409459 | accuracy: 0.5617897727272728 \n",
      "Epoch 1 | Step 397 | loss: 0.6986839771270758 | accuracy: 0.5618702770780857 \n",
      "Epoch 1 | Step 398 | loss: 0.6986627734486188 | accuracy: 0.5618326005025126 \n",
      "Epoch 1 | Step 399 | loss: 0.6985653347538832 | accuracy: 0.5620692355889725 \n",
      "Epoch 1 | Step 400 | loss: 0.6984574505686766 | accuracy: 0.5622265625 \n",
      "Epoch 1 | Step 401 | loss: 0.6983945610517284 | accuracy: 0.5622662094763092 \n",
      "Epoch 1 | Step 402 | loss: 0.6983858283182881 | accuracy: 0.5623445273631841 \n",
      "Epoch 1 | Step 403 | loss: 0.6983000270781984 | accuracy: 0.5624037392381994 \n",
      "Validation | Epoch 1 | Step 403 | accuracy: 0.648221343755722 \n",
      "Epoch 2 | Step 404 | loss: 0.6808139681816101 | accuracy: 0.515625 \n",
      "Epoch 2 | Step 405 | loss: 0.6818113923072815 | accuracy: 0.515625 \n",
      "Epoch 2 | Step 406 | loss: 0.6736008922259012 | accuracy: 0.5677083333333334 \n",
      "Epoch 2 | Step 407 | loss: 0.6633184999227524 | accuracy: 0.6015625 \n",
      "Epoch 2 | Step 408 | loss: 0.6556391239166259 | accuracy: 0.61875 \n",
      "Epoch 2 | Step 409 | loss: 0.6620062390963236 | accuracy: 0.6197916666666666 \n",
      "Epoch 2 | Step 410 | loss: 0.6603489858763558 | accuracy: 0.609375 \n",
      "Epoch 2 | Step 411 | loss: 0.659525454044342 | accuracy: 0.611328125 \n",
      "Epoch 2 | Step 412 | loss: 0.6614873011906942 | accuracy: 0.6041666666666666 \n",
      "Epoch 2 | Step 413 | loss: 0.6609760761260987 | accuracy: 0.6046875 \n",
      "Epoch 2 | Step 414 | loss: 0.6561025760390542 | accuracy: 0.609375 \n",
      "Epoch 2 | Step 415 | loss: 0.6553673843542734 | accuracy: 0.6171875 \n",
      "Epoch 2 | Step 416 | loss: 0.6543938746819129 | accuracy: 0.6153846153846154 \n",
      "Epoch 2 | Step 417 | loss: 0.650235401732581 | accuracy: 0.6227678571428571 \n",
      "Epoch 2 | Step 418 | loss: 0.6518127083778381 | accuracy: 0.6208333333333333 \n",
      "Epoch 2 | Step 419 | loss: 0.6486942954361439 | accuracy: 0.625 \n",
      "Epoch 2 | Step 420 | loss: 0.6457216424100539 | accuracy: 0.6323529411764706 \n",
      "Epoch 2 | Step 421 | loss: 0.6457411448160807 | accuracy: 0.6284722222222222 \n",
      "Epoch 2 | Step 422 | loss: 0.6459324454006395 | accuracy: 0.631578947368421 \n",
      "Epoch 2 | Step 423 | loss: 0.6464759796857834 | accuracy: 0.62890625 \n",
      "Epoch 2 | Step 424 | loss: 0.646088304973784 | accuracy: 0.6264880952380952 \n",
      "Epoch 2 | Step 425 | loss: 0.6445571129972285 | accuracy: 0.6278409090909091 \n",
      "Epoch 2 | Step 426 | loss: 0.6467244702836742 | accuracy: 0.6270380434782609 \n",
      "Epoch 2 | Step 427 | loss: 0.645367294549942 | accuracy: 0.6282552083333334 \n",
      "Epoch 2 | Step 428 | loss: 0.6450247287750244 | accuracy: 0.62875 \n",
      "Epoch 2 | Step 429 | loss: 0.6429009689734533 | accuracy: 0.6328125 \n",
      "Epoch 2 | Step 430 | loss: 0.6440673536724515 | accuracy: 0.6319444444444444 \n",
      "Epoch 2 | Step 431 | loss: 0.6437381974288395 | accuracy: 0.6322544642857143 \n",
      "Epoch 2 | Step 432 | loss: 0.6435037275840496 | accuracy: 0.6325431034482759 \n",
      "Epoch 2 | Step 433 | loss: 0.6414500971635183 | accuracy: 0.6333333333333333 \n",
      "Epoch 2 | Step 434 | loss: 0.6412312619147762 | accuracy: 0.6355846774193549 \n",
      "Epoch 2 | Step 435 | loss: 0.6421090438961983 | accuracy: 0.63720703125 \n",
      "Epoch 2 | Step 436 | loss: 0.6437479149211537 | accuracy: 0.6330492424242424 \n",
      "Epoch 2 | Step 437 | loss: 0.6425236586262199 | accuracy: 0.6364889705882353 \n",
      "Epoch 2 | Step 438 | loss: 0.6434724381991795 | accuracy: 0.6352678571428572 \n",
      "Epoch 2 | Step 439 | loss: 0.6429133829143312 | accuracy: 0.6354166666666666 \n",
      "Epoch 2 | Step 440 | loss: 0.6432767800382666 | accuracy: 0.6355574324324325 \n",
      "Epoch 2 | Step 441 | loss: 0.6436566977124465 | accuracy: 0.6344572368421053 \n",
      "Epoch 2 | Step 442 | loss: 0.6441266613128858 | accuracy: 0.6338141025641025 \n",
      "Epoch 2 | Step 443 | loss: 0.6441993340849876 | accuracy: 0.634375 \n",
      "Epoch 2 | Step 444 | loss: 0.6445924785079026 | accuracy: 0.6330030487804879 \n",
      "Epoch 2 | Step 445 | loss: 0.6436443768796467 | accuracy: 0.6343005952380953 \n",
      "Epoch 2 | Step 446 | loss: 0.6426938758339993 | accuracy: 0.636264534883721 \n",
      "Epoch 2 | Step 447 | loss: 0.6424525786529888 | accuracy: 0.6363636363636365 \n",
      "Epoch 2 | Step 448 | loss: 0.6430052783754137 | accuracy: 0.635763888888889 \n",
      "Epoch 2 | Step 449 | loss: 0.644058100555254 | accuracy: 0.6334918478260871 \n",
      "Epoch 2 | Step 450 | loss: 0.6430539159064598 | accuracy: 0.6356382978723406 \n",
      "Epoch 2 | Step 451 | loss: 0.6427176408469678 | accuracy: 0.6367187500000001 \n",
      "Epoch 2 | Step 452 | loss: 0.6426851688599101 | accuracy: 0.6367984693877552 \n",
      "Epoch 2 | Step 453 | loss: 0.6427642798423768 | accuracy: 0.6368750000000001 \n",
      "Epoch 2 | Step 454 | loss: 0.6430734419355207 | accuracy: 0.6354166666666666 \n",
      "Epoch 2 | Step 455 | loss: 0.6432363413847411 | accuracy: 0.6331129807692307 \n",
      "Epoch 2 | Step 456 | loss: 0.6425097528493631 | accuracy: 0.6344339622641509 \n",
      "Epoch 2 | Step 457 | loss: 0.6422354799729808 | accuracy: 0.6342592592592593 \n",
      "Epoch 2 | Step 458 | loss: 0.6416660265489059 | accuracy: 0.634090909090909 \n",
      "Epoch 2 | Step 459 | loss: 0.6422505250998907 | accuracy: 0.6339285714285714 \n",
      "Epoch 2 | Step 460 | loss: 0.6423420550530419 | accuracy: 0.6334978070175439 \n",
      "Epoch 2 | Step 461 | loss: 0.6423579289995393 | accuracy: 0.6336206896551724 \n",
      "Epoch 2 | Step 462 | loss: 0.6424073132417971 | accuracy: 0.6326800847457628 \n",
      "Epoch 2 | Step 463 | loss: 0.6418780714273454 | accuracy: 0.63359375 \n",
      "Epoch 2 | Step 464 | loss: 0.6414470486953612 | accuracy: 0.6349897540983607 \n",
      "Epoch 2 | Step 465 | loss: 0.6409697609563029 | accuracy: 0.6355846774193549 \n",
      "Epoch 2 | Step 466 | loss: 0.6417998321472653 | accuracy: 0.6341765873015873 \n",
      "Epoch 2 | Step 467 | loss: 0.6409217761829497 | accuracy: 0.634521484375 \n",
      "Epoch 2 | Step 468 | loss: 0.6404732841711779 | accuracy: 0.6360576923076923 \n",
      "Epoch 2 | Step 469 | loss: 0.6397086120013036 | accuracy: 0.6354166666666666 \n",
      "Epoch 2 | Step 470 | loss: 0.6393998763454495 | accuracy: 0.6357276119402985 \n",
      "Epoch 2 | Step 471 | loss: 0.6396000367753647 | accuracy: 0.6353400735294118 \n",
      "Epoch 2 | Step 472 | loss: 0.6396872090256733 | accuracy: 0.6345108695652174 \n",
      "Epoch 2 | Step 473 | loss: 0.6401612784181323 | accuracy: 0.6339285714285714 \n",
      "Epoch 2 | Step 474 | loss: 0.6396061752883482 | accuracy: 0.6344630281690141 \n",
      "Epoch 2 | Step 475 | loss: 0.6394773224989573 | accuracy: 0.6351996527777778 \n",
      "Epoch 2 | Step 476 | loss: 0.6393035250167324 | accuracy: 0.6352739726027398 \n",
      "Epoch 2 | Step 477 | loss: 0.638936348058082 | accuracy: 0.637035472972973 \n",
      "Epoch 2 | Step 478 | loss: 0.6396584510803223 | accuracy: 0.6360416666666667 \n",
      "Epoch 2 | Step 479 | loss: 0.6390660954149145 | accuracy: 0.6356907894736843 \n",
      "Epoch 2 | Step 480 | loss: 0.6386124793585245 | accuracy: 0.6353490259740261 \n",
      "Epoch 2 | Step 481 | loss: 0.6390852423814627 | accuracy: 0.6340144230769231 \n",
      "Epoch 2 | Step 482 | loss: 0.6391397277011147 | accuracy: 0.6333069620253166 \n",
      "Epoch 2 | Step 483 | loss: 0.639096750319004 | accuracy: 0.6326171875000001 \n",
      "Epoch 2 | Step 484 | loss: 0.6391193748992167 | accuracy: 0.6325231481481483 \n",
      "Epoch 2 | Step 485 | loss: 0.6384239989082988 | accuracy: 0.6335746951219513 \n",
      "Epoch 2 | Step 486 | loss: 0.6384042932326536 | accuracy: 0.6342243975903615 \n",
      "Epoch 2 | Step 487 | loss: 0.6379122854698273 | accuracy: 0.6344866071428572 \n",
      "Epoch 2 | Step 488 | loss: 0.6385078878963696 | accuracy: 0.6347426470588237 \n",
      "Epoch 2 | Step 489 | loss: 0.6381204765896465 | accuracy: 0.6351744186046513 \n",
      "Epoch 2 | Step 490 | loss: 0.6379059484635278 | accuracy: 0.6352370689655175 \n",
      "Epoch 2 | Step 491 | loss: 0.638743587515571 | accuracy: 0.6349431818181821 \n",
      "Epoch 2 | Step 492 | loss: 0.6389965307846499 | accuracy: 0.6346558988764048 \n",
      "Epoch 2 | Step 493 | loss: 0.6391112122270797 | accuracy: 0.6342013888888892 \n",
      "Epoch 2 | Step 494 | loss: 0.6390454441636474 | accuracy: 0.6339285714285717 \n",
      "Epoch 2 | Step 495 | loss: 0.6395027967898743 | accuracy: 0.633661684782609 \n",
      "Epoch 2 | Step 496 | loss: 0.6390037216166016 | accuracy: 0.6342405913978497 \n",
      "Epoch 2 | Step 497 | loss: 0.6382362963037289 | accuracy: 0.63530585106383 \n",
      "Epoch 2 | Step 498 | loss: 0.6381857388897948 | accuracy: 0.6353618421052633 \n",
      "Epoch 2 | Step 499 | loss: 0.638012687986096 | accuracy: 0.6355794270833334 \n",
      "Epoch 2 | Step 500 | loss: 0.6381277657046763 | accuracy: 0.635631443298969 \n",
      "Epoch 2 | Step 501 | loss: 0.6384960686673926 | accuracy: 0.635204081632653 \n",
      "Epoch 2 | Step 502 | loss: 0.6382818402666037 | accuracy: 0.6358901515151515 \n",
      "Epoch 2 | Step 503 | loss: 0.6382205814123156 | accuracy: 0.63640625 \n",
      "Epoch 2 | Step 504 | loss: 0.6383953690528873 | accuracy: 0.6358292079207921 \n",
      "Epoch 2 | Step 505 | loss: 0.6388534003613044 | accuracy: 0.6349571078431373 \n",
      "Epoch 2 | Step 506 | loss: 0.6387110335155601 | accuracy: 0.6354672330097088 \n",
      "Epoch 2 | Step 507 | loss: 0.6384260740417703 | accuracy: 0.6359675480769231 \n",
      "Epoch 2 | Step 508 | loss: 0.6380464076995852 | accuracy: 0.6367559523809524 \n",
      "Epoch 2 | Step 509 | loss: 0.637660568052868 | accuracy: 0.6372346698113207 \n",
      "Epoch 2 | Step 510 | loss: 0.6381170003213618 | accuracy: 0.6363901869158879 \n",
      "Epoch 2 | Step 511 | loss: 0.6381768506986126 | accuracy: 0.6368634259259259 \n",
      "Epoch 2 | Step 512 | loss: 0.6380432893376834 | accuracy: 0.6373279816513762 \n",
      "Epoch 2 | Step 513 | loss: 0.637760718844154 | accuracy: 0.6376420454545455 \n",
      "Epoch 2 | Step 514 | loss: 0.6379918176848611 | accuracy: 0.6375281531531531 \n",
      "Epoch 2 | Step 515 | loss: 0.6382158797766484 | accuracy: 0.6372767857142857 \n",
      "Epoch 2 | Step 516 | loss: 0.6380468907609452 | accuracy: 0.6373064159292036 \n",
      "Epoch 2 | Step 517 | loss: 0.6379501270620449 | accuracy: 0.637609649122807 \n",
      "Epoch 2 | Step 518 | loss: 0.6376087629276775 | accuracy: 0.638179347826087 \n",
      "Epoch 2 | Step 519 | loss: 0.637905217964074 | accuracy: 0.6382004310344828 \n",
      "Epoch 2 | Step 520 | loss: 0.6373417759552983 | accuracy: 0.6387553418803419 \n",
      "Epoch 2 | Step 521 | loss: 0.6371197963165027 | accuracy: 0.6394332627118644 \n",
      "Epoch 2 | Step 522 | loss: 0.6375765304605503 | accuracy: 0.6391806722689075 \n",
      "Epoch 2 | Step 523 | loss: 0.6372521698474887 | accuracy: 0.639453125 \n",
      "Epoch 2 | Step 524 | loss: 0.6371874099920606 | accuracy: 0.6394628099173554 \n",
      "Epoch 2 | Step 525 | loss: 0.6370811193692882 | accuracy: 0.639344262295082 \n",
      "Epoch 2 | Step 526 | loss: 0.6370024429104195 | accuracy: 0.6398628048780488 \n",
      "Epoch 2 | Step 527 | loss: 0.637125312320648 | accuracy: 0.6392389112903226 \n",
      "Epoch 2 | Step 528 | loss: 0.637481158256531 | accuracy: 0.638625 \n",
      "Epoch 2 | Step 529 | loss: 0.6376198066605464 | accuracy: 0.6388888888888888 \n",
      "Epoch 2 | Step 530 | loss: 0.6377590002976067 | accuracy: 0.6389025590551181 \n",
      "Epoch 2 | Step 531 | loss: 0.6378537802957001 | accuracy: 0.63916015625 \n",
      "Epoch 2 | Step 532 | loss: 0.6380180448524714 | accuracy: 0.6384447674418605 \n",
      "Epoch 2 | Step 533 | loss: 0.6379666149616243 | accuracy: 0.6381009615384615 \n",
      "Epoch 2 | Step 534 | loss: 0.6382804795075921 | accuracy: 0.6376431297709924 \n",
      "Epoch 2 | Step 535 | loss: 0.6386488621885128 | accuracy: 0.6370738636363636 \n",
      "Epoch 2 | Step 536 | loss: 0.6383163655610912 | accuracy: 0.6378054511278195 \n",
      "Epoch 2 | Step 537 | loss: 0.6382876140857813 | accuracy: 0.6380597014925373 \n",
      "Epoch 2 | Step 538 | loss: 0.6381907295297695 | accuracy: 0.638425925925926 \n",
      "Epoch 2 | Step 539 | loss: 0.6375383243841286 | accuracy: 0.6391314338235294 \n",
      "Epoch 2 | Step 540 | loss: 0.6371777979996954 | accuracy: 0.6393704379562044 \n",
      "Epoch 2 | Step 541 | loss: 0.637206897787426 | accuracy: 0.6396059782608695 \n",
      "Epoch 2 | Step 542 | loss: 0.6371564243337235 | accuracy: 0.6396133093525179 \n",
      "Epoch 2 | Step 543 | loss: 0.6369124029363906 | accuracy: 0.6392857142857142 \n",
      "Epoch 2 | Step 544 | loss: 0.6363443275715445 | accuracy: 0.6398492907801419 \n",
      "Epoch 2 | Step 545 | loss: 0.6359429963877505 | accuracy: 0.6405149647887324 \n",
      "Epoch 2 | Step 546 | loss: 0.635651418379137 | accuracy: 0.640625 \n",
      "Epoch 2 | Step 547 | loss: 0.6348130409088402 | accuracy: 0.6414930555555556 \n",
      "Epoch 2 | Step 548 | loss: 0.6346206110099268 | accuracy: 0.6420258620689655 \n",
      "Epoch 2 | Step 549 | loss: 0.635092274783409 | accuracy: 0.6414811643835616 \n",
      "Epoch 2 | Step 550 | loss: 0.6350279296336533 | accuracy: 0.6417942176870748 \n",
      "Epoch 2 | Step 551 | loss: 0.6347949682055295 | accuracy: 0.6419974662162162 \n",
      "Epoch 2 | Step 552 | loss: 0.6347215019616507 | accuracy: 0.641988255033557 \n",
      "Epoch 2 | Step 553 | loss: 0.6346135675907137 | accuracy: 0.641875 \n",
      "Epoch 2 | Step 554 | loss: 0.6343055055630921 | accuracy: 0.6419701986754967 \n",
      "Epoch 2 | Step 555 | loss: 0.6345568656137118 | accuracy: 0.6419613486842105 \n",
      "Epoch 2 | Step 556 | loss: 0.6345940676389958 | accuracy: 0.641748366013072 \n",
      "Epoch 2 | Step 557 | loss: 0.6344909327370782 | accuracy: 0.6425527597402598 \n",
      "Epoch 2 | Step 558 | loss: 0.6342873134920677 | accuracy: 0.6431451612903226 \n",
      "Epoch 2 | Step 559 | loss: 0.6342322811102259 | accuracy: 0.6430288461538461 \n",
      "Epoch 2 | Step 560 | loss: 0.6338999719376779 | accuracy: 0.6434116242038217 \n",
      "Epoch 2 | Step 561 | loss: 0.6338393107245242 | accuracy: 0.6434928797468354 \n",
      "Epoch 2 | Step 562 | loss: 0.6335196948651249 | accuracy: 0.6436713836477987 \n",
      "Epoch 2 | Step 563 | loss: 0.633492571860552 | accuracy: 0.64384765625 \n",
      "Epoch 2 | Step 564 | loss: 0.633657094854746 | accuracy: 0.6433423913043478 \n",
      "Epoch 2 | Step 565 | loss: 0.6335885752866299 | accuracy: 0.6437114197530864 \n",
      "Epoch 2 | Step 566 | loss: 0.6335478399428855 | accuracy: 0.6438842024539877 \n",
      "Epoch 2 | Step 567 | loss: 0.6336238707711059 | accuracy: 0.6439596036585366 \n",
      "Epoch 2 | Step 568 | loss: 0.6335049997676505 | accuracy: 0.6438446969696969 \n",
      "Epoch 2 | Step 569 | loss: 0.6335669113210888 | accuracy: 0.6438253012048193 \n",
      "Epoch 2 | Step 570 | loss: 0.6332349712977154 | accuracy: 0.6441803892215568 \n",
      "Epoch 2 | Step 571 | loss: 0.6333620931421009 | accuracy: 0.6436941964285714 \n",
      "Epoch 2 | Step 572 | loss: 0.633832114335348 | accuracy: 0.6428439349112426 \n",
      "Epoch 2 | Step 573 | loss: 0.6333013467928943 | accuracy: 0.6433823529411765 \n",
      "Epoch 2 | Step 574 | loss: 0.6330160937811199 | accuracy: 0.6436403508771931 \n",
      "Epoch 2 | Step 575 | loss: 0.633286505244499 | accuracy: 0.6434411337209304 \n",
      "Epoch 2 | Step 576 | loss: 0.6328189497049144 | accuracy: 0.6441473988439308 \n",
      "Epoch 2 | Step 577 | loss: 0.6328724389788747 | accuracy: 0.6442169540229886 \n",
      "Epoch 2 | Step 578 | loss: 0.6326605384690419 | accuracy: 0.6444642857142858 \n",
      "Epoch 2 | Step 579 | loss: 0.6329352506859734 | accuracy: 0.6438210227272728 \n",
      "Epoch 2 | Step 580 | loss: 0.6330176127158987 | accuracy: 0.6439795197740114 \n",
      "Epoch 2 | Step 581 | loss: 0.6331347977177479 | accuracy: 0.643872893258427 \n",
      "Epoch 2 | Step 582 | loss: 0.6339771138223188 | accuracy: 0.6426326815642458 \n",
      "Epoch 2 | Step 583 | loss: 0.633958899312549 | accuracy: 0.6427083333333333 \n",
      "Epoch 2 | Step 584 | loss: 0.6339805985682575 | accuracy: 0.642610497237569 \n",
      "Epoch 2 | Step 585 | loss: 0.6338377326399413 | accuracy: 0.6426854395604396 \n",
      "Epoch 2 | Step 586 | loss: 0.6337691398917649 | accuracy: 0.6426741803278688 \n",
      "Epoch 2 | Step 587 | loss: 0.6336979117730387 | accuracy: 0.6424932065217391 \n",
      "Epoch 2 | Step 588 | loss: 0.6335411957792332 | accuracy: 0.642820945945946 \n",
      "Epoch 2 | Step 589 | loss: 0.6335811922627109 | accuracy: 0.6428091397849462 \n",
      "Epoch 2 | Step 590 | loss: 0.6335654727277907 | accuracy: 0.6429645721925134 \n",
      "Epoch 2 | Step 591 | loss: 0.6333533959819914 | accuracy: 0.6434507978723404 \n",
      "Epoch 2 | Step 592 | loss: 0.6332604913484481 | accuracy: 0.6435185185185185 \n",
      "Epoch 2 | Step 593 | loss: 0.6329518324450442 | accuracy: 0.6434210526315789 \n",
      "Epoch 2 | Step 594 | loss: 0.6326887626298434 | accuracy: 0.6438154450261779 \n",
      "Epoch 2 | Step 595 | loss: 0.6324737345178921 | accuracy: 0.6439615885416666 \n",
      "Epoch 2 | Step 596 | loss: 0.6324789474665191 | accuracy: 0.6440252590673575 \n",
      "Epoch 2 | Step 597 | loss: 0.6321204178726549 | accuracy: 0.6440882731958762 \n",
      "Epoch 2 | Step 598 | loss: 0.6321548140965975 | accuracy: 0.6441506410256409 \n",
      "Epoch 2 | Step 599 | loss: 0.6320211431201622 | accuracy: 0.6444515306122448 \n",
      "Epoch 2 | Step 600 | loss: 0.6317907638356164 | accuracy: 0.644590736040609 \n",
      "Epoch 2 | Step 601 | loss: 0.6312852583148262 | accuracy: 0.645123106060606 \n",
      "Epoch 2 | Step 602 | loss: 0.6314926075575938 | accuracy: 0.644550879396985 \n",
      "Epoch 2 | Step 603 | loss: 0.6315671351552009 | accuracy: 0.64453125 \n",
      "Epoch 2 | Step 604 | loss: 0.6312903062028078 | accuracy: 0.6447450248756219 \n",
      "Epoch 2 | Step 605 | loss: 0.6312994815335414 | accuracy: 0.6448019801980198 \n",
      "Epoch 2 | Step 606 | loss: 0.6309990090102396 | accuracy: 0.6450892857142857 \n",
      "Epoch 2 | Step 607 | loss: 0.631151836584596 | accuracy: 0.6447610294117647 \n",
      "Epoch 2 | Step 608 | loss: 0.630965529418573 | accuracy: 0.6448170731707317 \n",
      "Epoch 2 | Step 609 | loss: 0.6307466657995019 | accuracy: 0.644872572815534 \n",
      "Epoch 2 | Step 610 | loss: 0.631012177409757 | accuracy: 0.6443236714975845 \n",
      "Epoch 2 | Step 611 | loss: 0.6306907162070273 | accuracy: 0.6446814903846154 \n",
      "Epoch 2 | Step 612 | loss: 0.6307465097550569 | accuracy: 0.6446620813397129 \n",
      "Epoch 2 | Step 613 | loss: 0.6307399931408109 | accuracy: 0.6446428571428572 \n",
      "Epoch 2 | Step 614 | loss: 0.6307968432304417 | accuracy: 0.6446238151658767 \n",
      "Epoch 2 | Step 615 | loss: 0.6306671812286916 | accuracy: 0.6446786556603774 \n",
      "Epoch 2 | Step 616 | loss: 0.6306760988325019 | accuracy: 0.644806338028169 \n",
      "Epoch 2 | Step 617 | loss: 0.6304999255688389 | accuracy: 0.6450788551401869 \n",
      "Epoch 2 | Step 618 | loss: 0.6302525326263072 | accuracy: 0.6452761627906977 \n",
      "Epoch 2 | Step 619 | loss: 0.6299870665426606 | accuracy: 0.6454716435185185 \n",
      "Epoch 2 | Step 620 | loss: 0.6299472698418225 | accuracy: 0.6456653225806451 \n",
      "Epoch 2 | Step 621 | loss: 0.6301499629786254 | accuracy: 0.645355504587156 \n",
      "Epoch 2 | Step 622 | loss: 0.6300671917118437 | accuracy: 0.6454052511415526 \n",
      "Epoch 2 | Step 623 | loss: 0.6299601701172914 | accuracy: 0.6455255681818182 \n",
      "Epoch 2 | Step 624 | loss: 0.6301248421496395 | accuracy: 0.6453619909502263 \n",
      "Epoch 2 | Step 625 | loss: 0.6300152048871323 | accuracy: 0.6455518018018018 \n",
      "Epoch 2 | Step 626 | loss: 0.6295082213632728 | accuracy: 0.6460201793721974 \n",
      "Epoch 2 | Step 627 | loss: 0.629465488983052 | accuracy: 0.6458565848214286 \n",
      "Epoch 2 | Step 628 | loss: 0.6292918027771842 | accuracy: 0.6460416666666666 \n",
      "Epoch 2 | Step 629 | loss: 0.6289666018127339 | accuracy: 0.6466399336283186 \n",
      "Epoch 2 | Step 630 | loss: 0.628658097483513 | accuracy: 0.6470264317180616 \n",
      "Epoch 2 | Step 631 | loss: 0.6284028898205672 | accuracy: 0.647203947368421 \n",
      "Epoch 2 | Step 632 | loss: 0.6280471804881199 | accuracy: 0.6477893013100436 \n",
      "Epoch 2 | Step 633 | loss: 0.6279465011928391 | accuracy: 0.6478260869565218 \n",
      "Epoch 2 | Step 634 | loss: 0.6277907459766833 | accuracy: 0.6481331168831169 \n",
      "Epoch 2 | Step 635 | loss: 0.6278097835080376 | accuracy: 0.6480334051724138 \n",
      "Epoch 2 | Step 636 | loss: 0.6278900596205256 | accuracy: 0.6479345493562232 \n",
      "Epoch 2 | Step 637 | loss: 0.6281098000004759 | accuracy: 0.6475026709401709 \n",
      "Epoch 2 | Step 638 | loss: 0.6279821492256001 | accuracy: 0.6475398936170212 \n",
      "Epoch 2 | Step 639 | loss: 0.6278251333762023 | accuracy: 0.647510593220339 \n",
      "Epoch 2 | Step 640 | loss: 0.6278489061045746 | accuracy: 0.6475474683544303 \n",
      "Epoch 2 | Step 641 | loss: 0.627995830123164 | accuracy: 0.6473214285714286 \n",
      "Epoch 2 | Step 642 | loss: 0.6281513187675795 | accuracy: 0.647097280334728 \n",
      "Epoch 2 | Step 643 | loss: 0.6280194292465845 | accuracy: 0.6471354166666666 \n",
      "Epoch 2 | Step 644 | loss: 0.6282329047369263 | accuracy: 0.6468490663900415 \n",
      "Epoch 2 | Step 645 | loss: 0.6285234243909188 | accuracy: 0.6466942148760331 \n",
      "Epoch 2 | Step 646 | loss: 0.6284709928457628 | accuracy: 0.6465406378600823 \n",
      "Epoch 2 | Step 647 | loss: 0.6283548381484921 | accuracy: 0.6467085040983607 \n",
      "Epoch 2 | Step 648 | loss: 0.6280513181978341 | accuracy: 0.646875 \n",
      "Epoch 2 | Step 649 | loss: 0.6280760624544406 | accuracy: 0.6469131097560976 \n",
      "Epoch 2 | Step 650 | loss: 0.6279706035548375 | accuracy: 0.6468243927125507 \n",
      "Epoch 2 | Step 651 | loss: 0.6282412171844513 | accuracy: 0.646484375 \n",
      "Epoch 2 | Step 652 | loss: 0.6287523479346768 | accuracy: 0.6460843373493976 \n",
      "Epoch 2 | Step 653 | loss: 0.6285704088211058 | accuracy: 0.64625 \n",
      "Epoch 2 | Step 654 | loss: 0.6284424363379458 | accuracy: 0.646414342629482 \n",
      "Epoch 2 | Step 655 | loss: 0.6285830554034973 | accuracy: 0.6462673611111112 \n",
      "Epoch 2 | Step 656 | loss: 0.6283437409419786 | accuracy: 0.6464303359683794 \n",
      "Epoch 2 | Step 657 | loss: 0.6282076410890564 | accuracy: 0.6468380905511811 \n",
      "Epoch 2 | Step 658 | loss: 0.6282441209344302 | accuracy: 0.6468137254901961 \n",
      "Epoch 2 | Step 659 | loss: 0.6281212919857352 | accuracy: 0.64697265625 \n",
      "Epoch 2 | Step 660 | loss: 0.6282273558791045 | accuracy: 0.6469479571984436 \n",
      "Epoch 2 | Step 661 | loss: 0.6280983284462329 | accuracy: 0.6470445736434108 \n",
      "Epoch 2 | Step 662 | loss: 0.6280094794785193 | accuracy: 0.6470801158301158 \n",
      "Epoch 2 | Step 663 | loss: 0.6280151133353893 | accuracy: 0.6470552884615385 \n",
      "Epoch 2 | Step 664 | loss: 0.6282582285303722 | accuracy: 0.6469109195402298 \n",
      "Epoch 2 | Step 665 | loss: 0.6281823468117312 | accuracy: 0.6469465648854962 \n",
      "Epoch 2 | Step 666 | loss: 0.6282187879312173 | accuracy: 0.6471007604562737 \n",
      "Epoch 2 | Step 667 | loss: 0.628046140300505 | accuracy: 0.6472537878787878 \n",
      "Epoch 2 | Step 668 | loss: 0.6279599160518285 | accuracy: 0.6472877358490566 \n",
      "Epoch 2 | Step 669 | loss: 0.6279867916627037 | accuracy: 0.6472626879699248 \n",
      "Epoch 2 | Step 670 | loss: 0.6278754468267775 | accuracy: 0.6473548689138576 \n",
      "Epoch 2 | Step 671 | loss: 0.6277276502171558 | accuracy: 0.6475629664179104 \n",
      "Epoch 2 | Step 672 | loss: 0.6278017772617835 | accuracy: 0.6475952602230484 \n",
      "Epoch 2 | Step 673 | loss: 0.6275127861234876 | accuracy: 0.6479166666666667 \n",
      "Epoch 2 | Step 674 | loss: 0.6271185967315166 | accuracy: 0.6482357011070111 \n",
      "Epoch 2 | Step 675 | loss: 0.6267186622409259 | accuracy: 0.6485523897058824 \n",
      "Epoch 2 | Step 676 | loss: 0.6264067907909769 | accuracy: 0.6489239926739927 \n",
      "Epoch 2 | Step 677 | loss: 0.6264323953294405 | accuracy: 0.6488937043795621 \n",
      "Epoch 2 | Step 678 | loss: 0.6267048397931184 | accuracy: 0.6486931818181818 \n",
      "Epoch 2 | Step 679 | loss: 0.6267160028219222 | accuracy: 0.6487205615942029 \n",
      "Epoch 2 | Step 680 | loss: 0.6268203234844689 | accuracy: 0.6486913357400722 \n",
      "Epoch 2 | Step 681 | loss: 0.6265411904389908 | accuracy: 0.6490557553956835 \n",
      "Epoch 2 | Step 682 | loss: 0.6270124307670044 | accuracy: 0.6487455197132617 \n",
      "Epoch 2 | Step 683 | loss: 0.6266981889094623 | accuracy: 0.6489397321428572 \n",
      "Epoch 2 | Step 684 | loss: 0.626718728992014 | accuracy: 0.6489101423487544 \n",
      "Epoch 2 | Step 685 | loss: 0.6264266752182167 | accuracy: 0.6492686170212766 \n",
      "Epoch 2 | Step 686 | loss: 0.6264427476973919 | accuracy: 0.6492932862190812 \n",
      "Epoch 2 | Step 687 | loss: 0.6260901169038152 | accuracy: 0.6497579225352113 \n",
      "Epoch 2 | Step 688 | loss: 0.6259952697837559 | accuracy: 0.6500548245614035 \n",
      "Epoch 2 | Step 689 | loss: 0.6257178675044663 | accuracy: 0.6502950174825175 \n",
      "Epoch 2 | Step 690 | loss: 0.6256247939548423 | accuracy: 0.6504246515679443 \n",
      "Epoch 2 | Step 691 | loss: 0.6254513572073642 | accuracy: 0.6507161458333334 \n",
      "Epoch 2 | Step 692 | loss: 0.6254523008752444 | accuracy: 0.6506812283737025 \n",
      "Epoch 2 | Step 693 | loss: 0.6251908259145141 | accuracy: 0.6507543103448276 \n",
      "Epoch 2 | Step 694 | loss: 0.6250363793160085 | accuracy: 0.6508268900343642 \n",
      "Epoch 2 | Step 695 | loss: 0.6248489326401929 | accuracy: 0.6510595034246576 \n",
      "Epoch 2 | Step 696 | loss: 0.6249951199459945 | accuracy: 0.6509172354948806 \n",
      "Epoch 2 | Step 697 | loss: 0.6248752608591194 | accuracy: 0.6508290816326531 \n",
      "Epoch 2 | Step 698 | loss: 0.6248024544473418 | accuracy: 0.6507944915254237 \n",
      "Epoch 2 | Step 699 | loss: 0.6247352397925141 | accuracy: 0.6508657094594593 \n",
      "Epoch 2 | Step 700 | loss: 0.6244600967124653 | accuracy: 0.6511994949494948 \n",
      "Epoch 2 | Step 701 | loss: 0.6244030432813116 | accuracy: 0.6513213087248321 \n",
      "Epoch 2 | Step 702 | loss: 0.624426828778308 | accuracy: 0.651233277591973 \n",
      "Epoch 2 | Step 703 | loss: 0.624638122717539 | accuracy: 0.6511458333333331 \n",
      "Epoch 2 | Step 704 | loss: 0.6244018858057316 | accuracy: 0.6513185215946841 \n",
      "Epoch 2 | Step 705 | loss: 0.6246056138284944 | accuracy: 0.651076158940397 \n",
      "Epoch 2 | Step 706 | loss: 0.6245454671752725 | accuracy: 0.6511448019801978 \n",
      "Epoch 2 | Step 707 | loss: 0.6244520525399003 | accuracy: 0.6512129934210523 \n",
      "Epoch 2 | Step 708 | loss: 0.6242686910707439 | accuracy: 0.6512807377049178 \n",
      "Epoch 2 | Step 709 | loss: 0.6242448459653289 | accuracy: 0.6512969771241828 \n",
      "Epoch 2 | Step 710 | loss: 0.6240857721151665 | accuracy: 0.6514657980456025 \n",
      "Epoch 2 | Step 711 | loss: 0.6239170486276796 | accuracy: 0.6516335227272726 \n",
      "Epoch 2 | Step 712 | loss: 0.6237979988449982 | accuracy: 0.6516484627831715 \n",
      "Epoch 2 | Step 713 | loss: 0.6236906203531446 | accuracy: 0.6517641129032257 \n",
      "Epoch 2 | Step 714 | loss: 0.6235487064364635 | accuracy: 0.6519795016077169 \n",
      "Epoch 2 | Step 715 | loss: 0.6236033101494493 | accuracy: 0.6517427884615383 \n",
      "Epoch 2 | Step 716 | loss: 0.623310520245244 | accuracy: 0.65200678913738 \n",
      "Epoch 2 | Step 717 | loss: 0.6233908095557216 | accuracy: 0.6519705414012738 \n",
      "Epoch 2 | Step 718 | loss: 0.6235451955643908 | accuracy: 0.6518353174603174 \n",
      "Epoch 2 | Step 719 | loss: 0.6235293755425679 | accuracy: 0.651651503164557 \n",
      "Epoch 2 | Step 720 | loss: 0.6231746799562252 | accuracy: 0.6519617507886435 \n",
      "Epoch 2 | Step 721 | loss: 0.6232899811657716 | accuracy: 0.6517786949685535 \n",
      "Epoch 2 | Step 722 | loss: 0.6230537276656647 | accuracy: 0.6518906739811913 \n",
      "Epoch 2 | Step 723 | loss: 0.6227727336809036 | accuracy: 0.6521484375000001 \n",
      "Epoch 2 | Step 724 | loss: 0.6225758785399318 | accuracy: 0.6524532710280375 \n",
      "Epoch 2 | Step 725 | loss: 0.6225738066323793 | accuracy: 0.652513586956522 \n",
      "Epoch 2 | Step 726 | loss: 0.6223553166300886 | accuracy: 0.6528154024767804 \n",
      "Epoch 2 | Step 727 | loss: 0.6222840650582017 | accuracy: 0.6529224537037038 \n",
      "Epoch 2 | Step 728 | loss: 0.622417228221893 | accuracy: 0.6527403846153847 \n",
      "Epoch 2 | Step 729 | loss: 0.6221542698474015 | accuracy: 0.6528949386503069 \n",
      "Epoch 2 | Step 730 | loss: 0.6221050838811679 | accuracy: 0.6530007645259941 \n",
      "Epoch 2 | Step 731 | loss: 0.6221915336280331 | accuracy: 0.6529153963414636 \n",
      "Epoch 2 | Step 732 | loss: 0.6221968924745598 | accuracy: 0.6530205167173254 \n",
      "Epoch 2 | Step 733 | loss: 0.6221252838770546 | accuracy: 0.6530303030303032 \n",
      "Epoch 2 | Step 734 | loss: 0.6220788157958637 | accuracy: 0.6530400302114805 \n",
      "Epoch 2 | Step 735 | loss: 0.6220640611935809 | accuracy: 0.6530967620481929 \n",
      "Epoch 2 | Step 736 | loss: 0.6221372782289085 | accuracy: 0.6529185435435436 \n",
      "Epoch 2 | Step 737 | loss: 0.6220374417876053 | accuracy: 0.6529285179640719 \n",
      "Epoch 2 | Step 738 | loss: 0.6218518145048795 | accuracy: 0.6531716417910448 \n",
      "Epoch 2 | Step 739 | loss: 0.6215719163772604 | accuracy: 0.6534133184523809 \n",
      "Epoch 2 | Step 740 | loss: 0.6214211303685466 | accuracy: 0.6534681008902077 \n",
      "Epoch 2 | Step 741 | loss: 0.6215360041200759 | accuracy: 0.6536612426035503 \n",
      "Epoch 2 | Step 742 | loss: 0.6211284544967266 | accuracy: 0.6538993362831859 \n",
      "Epoch 2 | Step 743 | loss: 0.6208161094609427 | accuracy: 0.6541819852941176 \n",
      "Epoch 2 | Step 744 | loss: 0.6209056531229326 | accuracy: 0.6540505865102639 \n",
      "Epoch 2 | Step 745 | loss: 0.6207104637260323 | accuracy: 0.6540113304093568 \n",
      "Epoch 2 | Step 746 | loss: 0.6205631941122491 | accuracy: 0.6542000728862974 \n",
      "Epoch 2 | Step 747 | loss: 0.6202347216218014 | accuracy: 0.6546148255813954 \n",
      "Epoch 2 | Step 748 | loss: 0.6201527016750277 | accuracy: 0.6546195652173913 \n",
      "Epoch 2 | Step 749 | loss: 0.620135592587421 | accuracy: 0.6546242774566474 \n",
      "Epoch 2 | Step 750 | loss: 0.6199807639767866 | accuracy: 0.6547640489913544 \n",
      "Epoch 2 | Step 751 | loss: 0.6198711854287945 | accuracy: 0.6547683189655172 \n",
      "Epoch 2 | Step 752 | loss: 0.6196437452447446 | accuracy: 0.6549964183381088 \n",
      "Epoch 2 | Step 753 | loss: 0.6192681671040396 | accuracy: 0.6553571428571429 \n",
      "Epoch 2 | Step 754 | loss: 0.6190963911364898 | accuracy: 0.6554932336182336 \n",
      "Epoch 2 | Step 755 | loss: 0.618873905644498 | accuracy: 0.6556729403409091 \n",
      "Epoch 2 | Step 756 | loss: 0.6187300357028376 | accuracy: 0.6558516288951841 \n",
      "Epoch 2 | Step 757 | loss: 0.6185779180062018 | accuracy: 0.6559410310734464 \n",
      "Epoch 2 | Step 758 | loss: 0.6185868195244962 | accuracy: 0.6560739436619718 \n",
      "Epoch 2 | Step 759 | loss: 0.6184003501293363 | accuracy: 0.65625 \n",
      "Epoch 2 | Step 760 | loss: 0.6179628438976296 | accuracy: 0.6566439075630253 \n",
      "Epoch 2 | Step 761 | loss: 0.6177312365457329 | accuracy: 0.6569046787709498 \n",
      "Epoch 2 | Step 762 | loss: 0.6176718654406765 | accuracy: 0.6569899025069639 \n",
      "Epoch 2 | Step 763 | loss: 0.6177632820275092 | accuracy: 0.6569444444444446 \n",
      "Epoch 2 | Step 764 | loss: 0.6174276454627016 | accuracy: 0.6573753462603878 \n",
      "Epoch 2 | Step 765 | loss: 0.617221453077885 | accuracy: 0.6576312154696132 \n",
      "Epoch 2 | Step 766 | loss: 0.6172646679825687 | accuracy: 0.6577565426997245 \n",
      "Epoch 2 | Step 767 | loss: 0.6169564746893366 | accuracy: 0.6579241071428571 \n",
      "Epoch 2 | Step 768 | loss: 0.6169850024458476 | accuracy: 0.6580051369863013 \n",
      "Epoch 2 | Step 769 | loss: 0.6166827129861693 | accuracy: 0.65838456284153 \n",
      "Epoch 2 | Step 770 | loss: 0.6166352740100681 | accuracy: 0.6583787465940054 \n",
      "Epoch 2 | Step 771 | loss: 0.6166619179041487 | accuracy: 0.6582880434782609 \n",
      "Epoch 2 | Step 772 | loss: 0.6167658746727112 | accuracy: 0.658324864498645 \n",
      "Epoch 2 | Step 773 | loss: 0.6169670618869161 | accuracy: 0.6581503378378378 \n",
      "Epoch 2 | Step 774 | loss: 0.6171280290238618 | accuracy: 0.6580609838274932 \n",
      "Epoch 2 | Step 775 | loss: 0.6171330671797515 | accuracy: 0.6579301075268817 \n",
      "Epoch 2 | Step 776 | loss: 0.6170104970561274 | accuracy: 0.658051273458445 \n",
      "Epoch 2 | Step 777 | loss: 0.6167096262947122 | accuracy: 0.6583806818181818 \n",
      "Epoch 2 | Step 778 | loss: 0.6164820299148558 | accuracy: 0.6585833333333333 \n",
      "Epoch 2 | Step 779 | loss: 0.6162231925954208 | accuracy: 0.6585771276595744 \n",
      "Epoch 2 | Step 780 | loss: 0.6159803756668332 | accuracy: 0.6586952917771883 \n",
      "Epoch 2 | Step 781 | loss: 0.615963117628501 | accuracy: 0.6587301587301587 \n",
      "Epoch 2 | Step 782 | loss: 0.6159286604393124 | accuracy: 0.6588060686015831 \n",
      "Epoch 2 | Step 783 | loss: 0.6156886406634982 | accuracy: 0.6590871710526316 \n",
      "Epoch 2 | Step 784 | loss: 0.6157311277752472 | accuracy: 0.6591617454068242 \n",
      "Epoch 2 | Step 785 | loss: 0.6154554230380431 | accuracy: 0.6593995418848168 \n",
      "Epoch 2 | Step 786 | loss: 0.615440988042647 | accuracy: 0.6594321148825065 \n",
      "Epoch 2 | Step 787 | loss: 0.6155120066056647 | accuracy: 0.6594645182291666 \n",
      "Epoch 2 | Step 788 | loss: 0.6153978168190298 | accuracy: 0.6596590909090909 \n",
      "Epoch 2 | Step 789 | loss: 0.6153744854457637 | accuracy: 0.6597716968911918 \n",
      "Epoch 2 | Step 790 | loss: 0.615395644222427 | accuracy: 0.6596818475452197 \n",
      "Epoch 2 | Step 791 | loss: 0.6154440011560302 | accuracy: 0.6596730025773196 \n",
      "Epoch 2 | Step 792 | loss: 0.6157055483379216 | accuracy: 0.6594232005141388 \n",
      "Epoch 2 | Step 793 | loss: 0.6155471373827028 | accuracy: 0.6595753205128205 \n",
      "Epoch 2 | Step 794 | loss: 0.6154683657619348 | accuracy: 0.6597266624040921 \n",
      "Epoch 2 | Step 795 | loss: 0.6154723226719971 | accuracy: 0.6597576530612245 \n",
      "Epoch 2 | Step 796 | loss: 0.6153115179702524 | accuracy: 0.6599872773536896 \n",
      "Epoch 2 | Step 797 | loss: 0.6152634408873349 | accuracy: 0.6602157360406091 \n",
      "Epoch 2 | Step 798 | loss: 0.615250970140288 | accuracy: 0.660126582278481 \n",
      "Epoch 2 | Step 799 | loss: 0.6148916753855617 | accuracy: 0.6605113636363636 \n",
      "Epoch 2 | Step 800 | loss: 0.6147431849832797 | accuracy: 0.6605793450881612 \n",
      "Epoch 2 | Step 801 | loss: 0.6146730734175772 | accuracy: 0.6605684673366834 \n",
      "Epoch 2 | Step 802 | loss: 0.6146507349826935 | accuracy: 0.6605184837092731 \n",
      "Epoch 2 | Step 803 | loss: 0.6146739158034322 | accuracy: 0.660546875 \n",
      "Epoch 2 | Step 804 | loss: 0.6147388818852619 | accuracy: 0.660458229426434 \n",
      "Epoch 2 | Step 805 | loss: 0.6148874958356219 | accuracy: 0.6604866293532339 \n",
      "Epoch 2 | Step 806 | loss: 0.6147619488813146 | accuracy: 0.6603878774950581 \n",
      "Validation | Epoch 2 | Step 806 | accuracy: 0.7141798423095183 \n",
      "Epoch 3 | Step 807 | loss: 0.6360620856285095 | accuracy: 0.671875 \n",
      "Epoch 3 | Step 808 | loss: 0.6218281090259552 | accuracy: 0.6640625 \n",
      "Epoch 3 | Step 809 | loss: 0.6044672330220541 | accuracy: 0.6770833333333334 \n",
      "Epoch 3 | Step 810 | loss: 0.5900483876466751 | accuracy: 0.68359375 \n",
      "Epoch 3 | Step 811 | loss: 0.5787810444831848 | accuracy: 0.703125 \n",
      "Epoch 3 | Step 812 | loss: 0.5812062422434489 | accuracy: 0.7083333333333334 \n",
      "Epoch 3 | Step 813 | loss: 0.5811662418501717 | accuracy: 0.7008928571428571 \n",
      "Epoch 3 | Step 814 | loss: 0.5826524868607521 | accuracy: 0.703125 \n",
      "Epoch 3 | Step 815 | loss: 0.580594625737932 | accuracy: 0.6961805555555556 \n",
      "Epoch 3 | Step 816 | loss: 0.5828764379024506 | accuracy: 0.696875 \n",
      "Epoch 3 | Step 817 | loss: 0.5794883912259882 | accuracy: 0.6946022727272727 \n",
      "Epoch 3 | Step 818 | loss: 0.577733611067136 | accuracy: 0.69921875 \n",
      "Epoch 3 | Step 819 | loss: 0.5743239338581378 | accuracy: 0.7007211538461539 \n",
      "Epoch 3 | Step 820 | loss: 0.5700198539665767 | accuracy: 0.703125 \n",
      "Epoch 3 | Step 821 | loss: 0.5707263668378194 | accuracy: 0.7020833333333333 \n",
      "Epoch 3 | Step 822 | loss: 0.5666197240352631 | accuracy: 0.705078125 \n",
      "Epoch 3 | Step 823 | loss: 0.5625605968868032 | accuracy: 0.7095588235294118 \n",
      "Epoch 3 | Step 824 | loss: 0.5635201003816392 | accuracy: 0.7074652777777778 \n",
      "Epoch 3 | Step 825 | loss: 0.5630277332506681 | accuracy: 0.7064144736842105 \n",
      "Epoch 3 | Step 826 | loss: 0.5620273023843765 | accuracy: 0.70625 \n",
      "Epoch 3 | Step 827 | loss: 0.560114480200268 | accuracy: 0.7068452380952381 \n",
      "Epoch 3 | Step 828 | loss: 0.5564051609147679 | accuracy: 0.7095170454545454 \n",
      "Epoch 3 | Step 829 | loss: 0.5564347129801045 | accuracy: 0.7092391304347826 \n",
      "Epoch 3 | Step 830 | loss: 0.5541638967891535 | accuracy: 0.7115885416666666 \n",
      "Epoch 3 | Step 831 | loss: 0.5541216456890106 | accuracy: 0.71125 \n",
      "Epoch 3 | Step 832 | loss: 0.5518504736515191 | accuracy: 0.7145432692307693 \n",
      "Epoch 3 | Step 833 | loss: 0.5521828123816737 | accuracy: 0.7158564814814815 \n",
      "Epoch 3 | Step 834 | loss: 0.5490176794784409 | accuracy: 0.7198660714285714 \n",
      "Epoch 3 | Step 835 | loss: 0.5496705698555914 | accuracy: 0.7198275862068966 \n",
      "Epoch 3 | Step 836 | loss: 0.5482193201780319 | accuracy: 0.7192708333333333 \n",
      "Epoch 3 | Step 837 | loss: 0.5481937479588294 | accuracy: 0.7212701612903226 \n",
      "Epoch 3 | Step 838 | loss: 0.5496522737666965 | accuracy: 0.72265625 \n",
      "Epoch 3 | Step 839 | loss: 0.5515353797060071 | accuracy: 0.7206439393939394 \n",
      "Epoch 3 | Step 840 | loss: 0.5497126745827058 | accuracy: 0.7233455882352942 \n",
      "Epoch 3 | Step 841 | loss: 0.548973617383412 | accuracy: 0.7245535714285715 \n",
      "Epoch 3 | Step 842 | loss: 0.5489052012562752 | accuracy: 0.7230902777777778 \n",
      "Epoch 3 | Step 843 | loss: 0.5493015542223647 | accuracy: 0.7225506756756757 \n",
      "Epoch 3 | Step 844 | loss: 0.5496075663127398 | accuracy: 0.7220394736842105 \n",
      "Epoch 3 | Step 845 | loss: 0.5521193765676938 | accuracy: 0.71875 \n",
      "Epoch 3 | Step 846 | loss: 0.5529294855892658 | accuracy: 0.7171875 \n",
      "Epoch 3 | Step 847 | loss: 0.5521864767481641 | accuracy: 0.7179878048780488 \n",
      "Epoch 3 | Step 848 | loss: 0.5518400917450587 | accuracy: 0.71875 \n",
      "Epoch 3 | Step 849 | loss: 0.5515068845693455 | accuracy: 0.7183866279069767 \n",
      "Epoch 3 | Step 850 | loss: 0.5514720928939906 | accuracy: 0.7191051136363636 \n",
      "Epoch 3 | Step 851 | loss: 0.5538754999637604 | accuracy: 0.71875 \n",
      "Epoch 3 | Step 852 | loss: 0.5556092748175496 | accuracy: 0.7163722826086957 \n",
      "Epoch 3 | Step 853 | loss: 0.5547739907782129 | accuracy: 0.7180851063829787 \n",
      "Epoch 3 | Step 854 | loss: 0.554858789468805 | accuracy: 0.7194010416666666 \n",
      "Epoch 3 | Step 855 | loss: 0.554652601480484 | accuracy: 0.7200255102040817 \n",
      "Epoch 3 | Step 856 | loss: 0.5547818547487259 | accuracy: 0.7203125 \n",
      "Epoch 3 | Step 857 | loss: 0.5553218669751111 | accuracy: 0.7196691176470589 \n",
      "Epoch 3 | Step 858 | loss: 0.5559425233648374 | accuracy: 0.7190504807692307 \n",
      "Epoch 3 | Step 859 | loss: 0.5557362566579064 | accuracy: 0.7199292452830188 \n",
      "Epoch 3 | Step 860 | loss: 0.5551799088716508 | accuracy: 0.7199074074074074 \n",
      "Epoch 3 | Step 861 | loss: 0.5547059411352332 | accuracy: 0.7198863636363636 \n",
      "Epoch 3 | Step 862 | loss: 0.5551895621631827 | accuracy: 0.7195870535714286 \n",
      "Epoch 3 | Step 863 | loss: 0.5553917158068272 | accuracy: 0.7198464912280702 \n",
      "Epoch 3 | Step 864 | loss: 0.5560655814820322 | accuracy: 0.7192887931034483 \n",
      "Epoch 3 | Step 865 | loss: 0.5566430056499223 | accuracy: 0.7174258474576272 \n",
      "Epoch 3 | Step 866 | loss: 0.5563229992985725 | accuracy: 0.7184895833333333 \n",
      "Epoch 3 | Step 867 | loss: 0.5554675015269733 | accuracy: 0.7192622950819673 \n",
      "Epoch 3 | Step 868 | loss: 0.5555840956587945 | accuracy: 0.71875 \n",
      "Epoch 3 | Step 869 | loss: 0.5563799942296649 | accuracy: 0.7170138888888888 \n",
      "Epoch 3 | Step 870 | loss: 0.5555437398143113 | accuracy: 0.717041015625 \n",
      "Epoch 3 | Step 871 | loss: 0.5550119166190808 | accuracy: 0.7182692307692308 \n",
      "Epoch 3 | Step 872 | loss: 0.5540383273001873 | accuracy: 0.7189867424242424 \n",
      "Epoch 3 | Step 873 | loss: 0.5539262236943886 | accuracy: 0.71875 \n",
      "Epoch 3 | Step 874 | loss: 0.5537121466854039 | accuracy: 0.7189797794117647 \n",
      "Epoch 3 | Step 875 | loss: 0.554915685152662 | accuracy: 0.7176177536231884 \n",
      "Epoch 3 | Step 876 | loss: 0.5557413318327495 | accuracy: 0.7167410714285715 \n",
      "Epoch 3 | Step 877 | loss: 0.5557403786921166 | accuracy: 0.7167693661971831 \n",
      "Epoch 3 | Step 878 | loss: 0.5556282595627837 | accuracy: 0.7180989583333334 \n",
      "Epoch 3 | Step 879 | loss: 0.554942351906267 | accuracy: 0.7185359589041096 \n",
      "Epoch 3 | Step 880 | loss: 0.554409641269091 | accuracy: 0.7193834459459459 \n",
      "Epoch 3 | Step 881 | loss: 0.5549690465132395 | accuracy: 0.7189583333333334 \n",
      "Epoch 3 | Step 882 | loss: 0.5541847712899509 | accuracy: 0.7193667763157895 \n",
      "Epoch 3 | Step 883 | loss: 0.5536209224880516 | accuracy: 0.7201704545454546 \n",
      "Epoch 3 | Step 884 | loss: 0.5542069165370404 | accuracy: 0.719551282051282 \n",
      "Epoch 3 | Step 885 | loss: 0.5539784880378579 | accuracy: 0.7197389240506329 \n",
      "Epoch 3 | Step 886 | loss: 0.5540211994200945 | accuracy: 0.71953125 \n",
      "Epoch 3 | Step 887 | loss: 0.5533410104704491 | accuracy: 0.720679012345679 \n",
      "Epoch 3 | Step 888 | loss: 0.552457530324052 | accuracy: 0.7214176829268293 \n",
      "Epoch 3 | Step 889 | loss: 0.5519251162747303 | accuracy: 0.7217620481927711 \n",
      "Epoch 3 | Step 890 | loss: 0.5517094546840304 | accuracy: 0.7215401785714286 \n",
      "Epoch 3 | Step 891 | loss: 0.552409852252287 | accuracy: 0.7213235294117647 \n",
      "Epoch 3 | Step 892 | loss: 0.5515560836986054 | accuracy: 0.7222020348837209 \n",
      "Epoch 3 | Step 893 | loss: 0.5514166564091869 | accuracy: 0.7221623563218391 \n",
      "Epoch 3 | Step 894 | loss: 0.5520847402513027 | accuracy: 0.7217684659090909 \n",
      "Epoch 3 | Step 895 | loss: 0.5524504442563217 | accuracy: 0.7219101123595506 \n",
      "Epoch 3 | Step 896 | loss: 0.5528525382280349 | accuracy: 0.721875 \n",
      "Epoch 3 | Step 897 | loss: 0.5522262185484498 | accuracy: 0.7221840659340659 \n",
      "Epoch 3 | Step 898 | loss: 0.5539047776356987 | accuracy: 0.7207880434782609 \n",
      "Epoch 3 | Step 899 | loss: 0.5532760536798866 | accuracy: 0.7209341397849462 \n",
      "Epoch 3 | Step 900 | loss: 0.5524551941359296 | accuracy: 0.7220744680851063 \n",
      "Epoch 3 | Step 901 | loss: 0.5520847336242073 | accuracy: 0.7222039473684211 \n",
      "Epoch 3 | Step 902 | loss: 0.5519868008171518 | accuracy: 0.7223307291666666 \n",
      "Epoch 3 | Step 903 | loss: 0.5520063150174839 | accuracy: 0.7219716494845361 \n",
      "Epoch 3 | Step 904 | loss: 0.5527868054959238 | accuracy: 0.7214604591836735 \n",
      "Epoch 3 | Step 905 | loss: 0.5524554990156733 | accuracy: 0.7214330808080808 \n",
      "Epoch 3 | Step 906 | loss: 0.5520451167225837 | accuracy: 0.72171875 \n",
      "Epoch 3 | Step 907 | loss: 0.5515423780030543 | accuracy: 0.7218440594059405 \n",
      "Epoch 3 | Step 908 | loss: 0.5520204875399084 | accuracy: 0.7213541666666666 \n",
      "Epoch 3 | Step 909 | loss: 0.5520246894035524 | accuracy: 0.7211771844660194 \n",
      "Epoch 3 | Step 910 | loss: 0.5513947531580925 | accuracy: 0.7219050480769231 \n",
      "Epoch 3 | Step 911 | loss: 0.5514233225867862 | accuracy: 0.7223214285714286 \n",
      "Epoch 3 | Step 912 | loss: 0.5503847166052405 | accuracy: 0.7234669811320755 \n",
      "Epoch 3 | Step 913 | loss: 0.5510635660073467 | accuracy: 0.7232768691588785 \n",
      "Epoch 3 | Step 914 | loss: 0.5509947880550667 | accuracy: 0.7232349537037037 \n",
      "Epoch 3 | Step 915 | loss: 0.5508861722202476 | accuracy: 0.7230504587155964 \n",
      "Epoch 3 | Step 916 | loss: 0.5507791297002272 | accuracy: 0.7230113636363636 \n",
      "Epoch 3 | Step 917 | loss: 0.5518558046839259 | accuracy: 0.7225506756756757 \n",
      "Epoch 3 | Step 918 | loss: 0.5522397538380964 | accuracy: 0.7225167410714286 \n",
      "Epoch 3 | Step 919 | loss: 0.5519916225323636 | accuracy: 0.7227599557522124 \n",
      "Epoch 3 | Step 920 | loss: 0.5522183441279228 | accuracy: 0.7225877192982456 \n",
      "Epoch 3 | Step 921 | loss: 0.5519474620404451 | accuracy: 0.7228260869565217 \n",
      "Epoch 3 | Step 922 | loss: 0.5522680272316111 | accuracy: 0.7231950431034483 \n",
      "Epoch 3 | Step 923 | loss: 0.5513295587311443 | accuracy: 0.7236912393162394 \n",
      "Epoch 3 | Step 924 | loss: 0.5510547408613108 | accuracy: 0.7241790254237288 \n",
      "Epoch 3 | Step 925 | loss: 0.5517266843499256 | accuracy: 0.723608193277311 \n",
      "Epoch 3 | Step 926 | loss: 0.5512561557193597 | accuracy: 0.7239583333333334 \n",
      "Epoch 3 | Step 927 | loss: 0.5508897050845721 | accuracy: 0.7241735537190083 \n",
      "Epoch 3 | Step 928 | loss: 0.5510739901515304 | accuracy: 0.7242571721311475 \n",
      "Epoch 3 | Step 929 | loss: 0.5508440997057814 | accuracy: 0.7251016260162602 \n",
      "Epoch 3 | Step 930 | loss: 0.5507144939995581 | accuracy: 0.7249243951612904 \n",
      "Epoch 3 | Step 931 | loss: 0.5506097452640534 | accuracy: 0.7245 \n",
      "Epoch 3 | Step 932 | loss: 0.550267001702672 | accuracy: 0.7247023809523809 \n",
      "Epoch 3 | Step 933 | loss: 0.5504982755409451 | accuracy: 0.7246555118110236 \n",
      "Epoch 3 | Step 934 | loss: 0.5504651160445064 | accuracy: 0.724853515625 \n",
      "Epoch 3 | Step 935 | loss: 0.5506903263487557 | accuracy: 0.7245639534883721 \n",
      "Epoch 3 | Step 936 | loss: 0.550519805917373 | accuracy: 0.725 \n",
      "Epoch 3 | Step 937 | loss: 0.5510159605787001 | accuracy: 0.7242366412213741 \n",
      "Epoch 3 | Step 938 | loss: 0.5516699974735578 | accuracy: 0.7234848484848485 \n",
      "Epoch 3 | Step 939 | loss: 0.5509926627453109 | accuracy: 0.7239191729323309 \n",
      "Epoch 3 | Step 940 | loss: 0.5511257861977192 | accuracy: 0.7241138059701493 \n",
      "Epoch 3 | Step 941 | loss: 0.5511893338627285 | accuracy: 0.7239583333333334 \n",
      "Epoch 3 | Step 942 | loss: 0.5505310226889217 | accuracy: 0.7243795955882353 \n",
      "Epoch 3 | Step 943 | loss: 0.5502908464765897 | accuracy: 0.7249087591240876 \n",
      "Epoch 3 | Step 944 | loss: 0.5505280205305072 | accuracy: 0.7245244565217391 \n",
      "Epoch 3 | Step 945 | loss: 0.5505005447126978 | accuracy: 0.7244829136690647 \n",
      "Epoch 3 | Step 946 | loss: 0.5499374455639294 | accuracy: 0.7247767857142857 \n",
      "Epoch 3 | Step 947 | loss: 0.5494173420659194 | accuracy: 0.7250664893617021 \n",
      "Epoch 3 | Step 948 | loss: 0.5490028413248734 | accuracy: 0.7250220070422535 \n",
      "Epoch 3 | Step 949 | loss: 0.5487918370253557 | accuracy: 0.7253059440559441 \n",
      "Epoch 3 | Step 950 | loss: 0.5476858795930943 | accuracy: 0.7261284722222222 \n",
      "Epoch 3 | Step 951 | loss: 0.547580126852825 | accuracy: 0.7262931034482759 \n",
      "Epoch 3 | Step 952 | loss: 0.5484699376233638 | accuracy: 0.7257063356164385 \n",
      "Epoch 3 | Step 953 | loss: 0.5479615809155162 | accuracy: 0.7264030612244899 \n",
      "Epoch 3 | Step 954 | loss: 0.5477643886933458 | accuracy: 0.7264569256756759 \n",
      "Epoch 3 | Step 955 | loss: 0.5472268244164104 | accuracy: 0.7268246644295304 \n",
      "Epoch 3 | Step 956 | loss: 0.5476082950830462 | accuracy: 0.7262500000000002 \n",
      "Epoch 3 | Step 957 | loss: 0.547339532351652 | accuracy: 0.7265107615894042 \n",
      "Epoch 3 | Step 958 | loss: 0.5479739980870174 | accuracy: 0.7259457236842107 \n",
      "Epoch 3 | Step 959 | loss: 0.5481879483251013 | accuracy: 0.7256944444444446 \n",
      "Epoch 3 | Step 960 | loss: 0.5479348404453949 | accuracy: 0.7263595779220781 \n",
      "Epoch 3 | Step 961 | loss: 0.5476250319711625 | accuracy: 0.7265120967741936 \n",
      "Epoch 3 | Step 962 | loss: 0.5475388010724999 | accuracy: 0.7263621794871795 \n",
      "Epoch 3 | Step 963 | loss: 0.5470240062968748 | accuracy: 0.7265127388535032 \n",
      "Epoch 3 | Step 964 | loss: 0.54696387542954 | accuracy: 0.7264636075949367 \n",
      "Epoch 3 | Step 965 | loss: 0.5466109774772477 | accuracy: 0.726808176100629 \n",
      "Epoch 3 | Step 966 | loss: 0.5469757901504637 | accuracy: 0.7264648437500001 \n",
      "Epoch 3 | Step 967 | loss: 0.5468953272200521 | accuracy: 0.7266110248447206 \n",
      "Epoch 3 | Step 968 | loss: 0.5470518482688034 | accuracy: 0.7261766975308643 \n",
      "Epoch 3 | Step 969 | loss: 0.546948090835583 | accuracy: 0.7265145705521474 \n",
      "Epoch 3 | Step 970 | loss: 0.5467016124507277 | accuracy: 0.7268483231707319 \n",
      "Epoch 3 | Step 971 | loss: 0.5464996000130972 | accuracy: 0.7274621212121214 \n",
      "Epoch 3 | Step 972 | loss: 0.5467774474836258 | accuracy: 0.7273155120481929 \n",
      "Epoch 3 | Step 973 | loss: 0.5464614151480669 | accuracy: 0.7274513473053893 \n",
      "Epoch 3 | Step 974 | loss: 0.5463612182509332 | accuracy: 0.7277715773809524 \n",
      "Epoch 3 | Step 975 | loss: 0.5469654646850903 | accuracy: 0.7273483727810651 \n",
      "Epoch 3 | Step 976 | loss: 0.5461347148698921 | accuracy: 0.728125 \n",
      "Epoch 3 | Step 977 | loss: 0.5458885225636222 | accuracy: 0.7281615497076024 \n",
      "Epoch 3 | Step 978 | loss: 0.5464695802954742 | accuracy: 0.7273800872093024 \n",
      "Epoch 3 | Step 979 | loss: 0.5456400098483688 | accuracy: 0.7278721098265896 \n",
      "Epoch 3 | Step 980 | loss: 0.546015517293722 | accuracy: 0.7274604885057471 \n",
      "Epoch 3 | Step 981 | loss: 0.5455483106204444 | accuracy: 0.7274999999999999 \n",
      "Epoch 3 | Step 982 | loss: 0.5458020662719556 | accuracy: 0.7270951704545454 \n",
      "Epoch 3 | Step 983 | loss: 0.5457318317418721 | accuracy: 0.7274011299435028 \n",
      "Epoch 3 | Step 984 | loss: 0.5458149571767017 | accuracy: 0.7271769662921348 \n",
      "Epoch 3 | Step 985 | loss: 0.5466317777527114 | accuracy: 0.7262569832402235 \n",
      "Epoch 3 | Step 986 | loss: 0.5466982440816035 | accuracy: 0.7262152777777777 \n",
      "Epoch 3 | Step 987 | loss: 0.5467424181943443 | accuracy: 0.7260877071823204 \n",
      "Epoch 3 | Step 988 | loss: 0.546380168952785 | accuracy: 0.7261332417582418 \n",
      "Epoch 3 | Step 989 | loss: 0.5462930298568124 | accuracy: 0.7260075136612022 \n",
      "Epoch 3 | Step 990 | loss: 0.546183149289826 | accuracy: 0.7260529891304348 \n",
      "Epoch 3 | Step 991 | loss: 0.5458413061257958 | accuracy: 0.7266047297297298 \n",
      "Epoch 3 | Step 992 | loss: 0.5457406311586342 | accuracy: 0.7268985215053764 \n",
      "Epoch 3 | Step 993 | loss: 0.5459091021096646 | accuracy: 0.7264371657754011 \n",
      "Epoch 3 | Step 994 | loss: 0.5457612388628598 | accuracy: 0.7266456117021277 \n",
      "Epoch 3 | Step 995 | loss: 0.54562188188235 | accuracy: 0.7266865079365079 \n",
      "Epoch 3 | Step 996 | loss: 0.5451561827408643 | accuracy: 0.7272203947368421 \n",
      "Epoch 3 | Step 997 | loss: 0.5450512092775078 | accuracy: 0.7270124345549738 \n",
      "Epoch 3 | Step 998 | loss: 0.5449975542724136 | accuracy: 0.7268880208333334 \n",
      "Epoch 3 | Step 999 | loss: 0.5451211080032312 | accuracy: 0.726360103626943 \n",
      "Epoch 3 | Step 1000 | loss: 0.5450804113727258 | accuracy: 0.726159793814433 \n",
      "Epoch 3 | Step 1001 | loss: 0.5453023855502792 | accuracy: 0.7259615384615384 \n",
      "Epoch 3 | Step 1002 | loss: 0.5449474400707657 | accuracy: 0.7262436224489796 \n",
      "Epoch 3 | Step 1003 | loss: 0.5447306319844302 | accuracy: 0.7259676395939086 \n",
      "Epoch 3 | Step 1004 | loss: 0.5443547399658148 | accuracy: 0.7262468434343434 \n",
      "Epoch 3 | Step 1005 | loss: 0.5447089853298727 | accuracy: 0.7258165829145728 \n",
      "Epoch 3 | Step 1006 | loss: 0.5448699407279495 | accuracy: 0.72578125 \n",
      "Epoch 3 | Step 1007 | loss: 0.5445587253985716 | accuracy: 0.7259017412935324 \n",
      "Epoch 3 | Step 1008 | loss: 0.544455343396357 | accuracy: 0.7259436881188119 \n",
      "Epoch 3 | Step 1009 | loss: 0.5443260776879167 | accuracy: 0.7259852216748769 \n",
      "Epoch 3 | Step 1010 | loss: 0.5445270878719352 | accuracy: 0.7255667892156863 \n",
      "Epoch 3 | Step 1011 | loss: 0.5443173008721052 | accuracy: 0.7259146341463415 \n",
      "Epoch 3 | Step 1012 | loss: 0.5441613016487328 | accuracy: 0.725879854368932 \n",
      "Epoch 3 | Step 1013 | loss: 0.544410141049952 | accuracy: 0.7254679951690821 \n",
      "Epoch 3 | Step 1014 | loss: 0.5439156445746242 | accuracy: 0.7258112980769231 \n",
      "Epoch 3 | Step 1015 | loss: 0.5440325745555206 | accuracy: 0.7260017942583732 \n",
      "Epoch 3 | Step 1016 | loss: 0.5440985287938802 | accuracy: 0.7258184523809523 \n",
      "Epoch 3 | Step 1017 | loss: 0.5439909442341161 | accuracy: 0.7257849526066351 \n",
      "Epoch 3 | Step 1018 | loss: 0.543978552773314 | accuracy: 0.7258254716981132 \n",
      "Epoch 3 | Step 1019 | loss: 0.5438639001107555 | accuracy: 0.7257922535211268 \n",
      "Epoch 3 | Step 1020 | loss: 0.5438815360871434 | accuracy: 0.7257593457943925 \n",
      "Epoch 3 | Step 1021 | loss: 0.5438969955887909 | accuracy: 0.7258720930232558 \n",
      "Epoch 3 | Step 1022 | loss: 0.5437034879017763 | accuracy: 0.7260561342592593 \n",
      "Epoch 3 | Step 1023 | loss: 0.5440910917273318 | accuracy: 0.7255904377880185 \n",
      "Epoch 3 | Step 1024 | loss: 0.5443616976978585 | accuracy: 0.7254873853211009 \n",
      "Epoch 3 | Step 1025 | loss: 0.5443415271637105 | accuracy: 0.7255279680365296 \n",
      "Epoch 3 | Step 1026 | loss: 0.5443113836375153 | accuracy: 0.7254971590909091 \n",
      "Epoch 3 | Step 1027 | loss: 0.544315065463744 | accuracy: 0.7251838235294118 \n",
      "Epoch 3 | Step 1028 | loss: 0.544540943863156 | accuracy: 0.7248733108108109 \n",
      "Epoch 3 | Step 1029 | loss: 0.544111166834297 | accuracy: 0.7249859865470852 \n",
      "Epoch 3 | Step 1030 | loss: 0.5441000844751089 | accuracy: 0.7251674107142857 \n",
      "Epoch 3 | Step 1031 | loss: 0.5442129397392277 | accuracy: 0.7252777777777778 \n",
      "Epoch 3 | Step 1032 | loss: 0.5439386362523108 | accuracy: 0.7255254424778761 \n",
      "Epoch 3 | Step 1033 | loss: 0.5437213311111353 | accuracy: 0.7256332599118943 \n",
      "Epoch 3 | Step 1034 | loss: 0.5434453508310154 | accuracy: 0.7259457236842105 \n",
      "Epoch 3 | Step 1035 | loss: 0.5430290398379084 | accuracy: 0.72639192139738 \n",
      "Epoch 3 | Step 1036 | loss: 0.5428781300783161 | accuracy: 0.7266304347826087 \n",
      "Epoch 3 | Step 1037 | loss: 0.5425010304172322 | accuracy: 0.7270698051948052 \n",
      "Epoch 3 | Step 1038 | loss: 0.5426414653915788 | accuracy: 0.7267645474137931 \n",
      "Epoch 3 | Step 1039 | loss: 0.5427467658028586 | accuracy: 0.7265289699570815 \n",
      "Epoch 3 | Step 1040 | loss: 0.5431375061599621 | accuracy: 0.7261618589743589 \n",
      "Epoch 3 | Step 1041 | loss: 0.5429755825945676 | accuracy: 0.7261968085106383 \n",
      "Epoch 3 | Step 1042 | loss: 0.5428372221225404 | accuracy: 0.7262976694915254 \n",
      "Epoch 3 | Step 1043 | loss: 0.5429321370295839 | accuracy: 0.7262658227848101 \n",
      "Epoch 3 | Step 1044 | loss: 0.5434422484215573 | accuracy: 0.7261029411764706 \n",
      "Epoch 3 | Step 1045 | loss: 0.5435345904847074 | accuracy: 0.7260067991631799 \n",
      "Epoch 3 | Step 1046 | loss: 0.5434212869654104 | accuracy: 0.7261067708333333 \n",
      "Epoch 3 | Step 1047 | loss: 0.5436783775501731 | accuracy: 0.725816908713693 \n",
      "Epoch 3 | Step 1048 | loss: 0.5439521346456753 | accuracy: 0.7256585743801653 \n",
      "Epoch 3 | Step 1049 | loss: 0.543758089037099 | accuracy: 0.7258873456790124 \n",
      "Epoch 3 | Step 1050 | loss: 0.543578223126834 | accuracy: 0.7262423155737705 \n",
      "Epoch 3 | Step 1051 | loss: 0.5434292377257839 | accuracy: 0.7264668367346939 \n",
      "Epoch 3 | Step 1052 | loss: 0.5432242265319441 | accuracy: 0.7264354674796748 \n",
      "Epoch 3 | Step 1053 | loss: 0.5430754950413341 | accuracy: 0.7266573886639676 \n",
      "Epoch 3 | Step 1054 | loss: 0.5433864073166929 | accuracy: 0.7265625 \n",
      "Epoch 3 | Step 1055 | loss: 0.5438707876636326 | accuracy: 0.7260291164658634 \n",
      "Epoch 3 | Step 1056 | loss: 0.5437968672513966 | accuracy: 0.726 \n",
      "Epoch 3 | Step 1057 | loss: 0.5439244942123675 | accuracy: 0.7259088645418327 \n",
      "Epoch 3 | Step 1058 | loss: 0.5442745802657949 | accuracy: 0.7256944444444444 \n",
      "Epoch 3 | Step 1059 | loss: 0.5439990197010196 | accuracy: 0.725975790513834 \n",
      "Epoch 3 | Step 1060 | loss: 0.5438612806280771 | accuracy: 0.726193405511811 \n",
      "Epoch 3 | Step 1061 | loss: 0.5437536792427891 | accuracy: 0.7262867647058824 \n",
      "Epoch 3 | Step 1062 | loss: 0.5435714815976103 | accuracy: 0.7261962890625 \n",
      "Epoch 3 | Step 1063 | loss: 0.5439429764385821 | accuracy: 0.7259241245136187 \n",
      "Epoch 3 | Step 1064 | loss: 0.5437484809825591 | accuracy: 0.7262596899224806 \n",
      "Epoch 3 | Step 1065 | loss: 0.5437341752429731 | accuracy: 0.726230694980695 \n",
      "Epoch 3 | Step 1066 | loss: 0.5438131675124173 | accuracy: 0.7260216346153846 \n",
      "Epoch 3 | Step 1067 | loss: 0.544161737079365 | accuracy: 0.7257543103448276 \n",
      "Epoch 3 | Step 1068 | loss: 0.5443950428535015 | accuracy: 0.7254890267175572 \n",
      "Epoch 3 | Step 1069 | loss: 0.544563163935912 | accuracy: 0.7254039923954373 \n",
      "Epoch 3 | Step 1070 | loss: 0.5444530981282397 | accuracy: 0.7255563446969697 \n",
      "Epoch 3 | Step 1071 | loss: 0.5444358251004853 | accuracy: 0.7255306603773585 \n",
      "Epoch 3 | Step 1072 | loss: 0.5445236432597157 | accuracy: 0.7253876879699248 \n",
      "Epoch 3 | Step 1073 | loss: 0.5443768727868687 | accuracy: 0.7255969101123596 \n",
      "Epoch 3 | Step 1074 | loss: 0.5444257934369261 | accuracy: 0.7255130597014926 \n",
      "Epoch 3 | Step 1075 | loss: 0.5445718445077707 | accuracy: 0.7254298327137547 \n",
      "Epoch 3 | Step 1076 | loss: 0.5443524148729115 | accuracy: 0.7255787037037038 \n",
      "Epoch 3 | Step 1077 | loss: 0.5439533470301614 | accuracy: 0.7256111623616237 \n",
      "Epoch 3 | Step 1078 | loss: 0.5436110017711628 | accuracy: 0.7255859375000001 \n",
      "Epoch 3 | Step 1079 | loss: 0.5433652018889406 | accuracy: 0.7257898351648353 \n",
      "Epoch 3 | Step 1080 | loss: 0.5432890151103921 | accuracy: 0.7258781934306571 \n",
      "Epoch 3 | Step 1081 | loss: 0.5434284836595712 | accuracy: 0.7259090909090911 \n",
      "Epoch 3 | Step 1082 | loss: 0.5433760060780294 | accuracy: 0.7260529891304349 \n",
      "Epoch 3 | Step 1083 | loss: 0.5435010020483275 | accuracy: 0.7259702166064983 \n",
      "Epoch 3 | Step 1084 | loss: 0.543179839420662 | accuracy: 0.7263376798561152 \n",
      "Epoch 3 | Step 1085 | loss: 0.5437671290076338 | accuracy: 0.7259184587813621 \n",
      "Epoch 3 | Step 1086 | loss: 0.5434416928461624 | accuracy: 0.726060267857143 \n",
      "Epoch 3 | Step 1087 | loss: 0.543576851434131 | accuracy: 0.7257562277580072 \n",
      "Epoch 3 | Step 1088 | loss: 0.5431284874889025 | accuracy: 0.7261192375886526 \n",
      "Epoch 3 | Step 1089 | loss: 0.5432002072620732 | accuracy: 0.7259827738515902 \n",
      "Epoch 3 | Step 1090 | loss: 0.5428018688525955 | accuracy: 0.7261773767605635 \n",
      "Epoch 3 | Step 1091 | loss: 0.542598443595987 | accuracy: 0.7262061403508773 \n",
      "Epoch 3 | Step 1092 | loss: 0.5422652471107207 | accuracy: 0.7263439685314687 \n",
      "Epoch 3 | Step 1093 | loss: 0.5421441306428215 | accuracy: 0.726426393728223 \n",
      "Epoch 3 | Step 1094 | loss: 0.5418144798734126 | accuracy: 0.7268880208333334 \n",
      "Epoch 3 | Step 1095 | loss: 0.5419484287191019 | accuracy: 0.7267517301038062 \n",
      "Epoch 3 | Step 1096 | loss: 0.5417718796894472 | accuracy: 0.7268318965517241 \n",
      "Epoch 3 | Step 1097 | loss: 0.5416921846235745 | accuracy: 0.7269115120274913 \n",
      "Epoch 3 | Step 1098 | loss: 0.5415065461029749 | accuracy: 0.7270440924657533 \n",
      "Epoch 3 | Step 1099 | loss: 0.5418025860403995 | accuracy: 0.7269091296928327 \n",
      "Epoch 3 | Step 1100 | loss: 0.5415934392181387 | accuracy: 0.727093962585034 \n",
      "Epoch 3 | Step 1101 | loss: 0.5414615460371571 | accuracy: 0.7270656779661017 \n",
      "Epoch 3 | Step 1102 | loss: 0.5414478971144642 | accuracy: 0.7271431587837838 \n",
      "Epoch 3 | Step 1103 | loss: 0.5413018700851739 | accuracy: 0.7272727272727273 \n",
      "Epoch 3 | Step 1104 | loss: 0.5413509212284284 | accuracy: 0.7272965604026845 \n",
      "Epoch 3 | Step 1105 | loss: 0.5413813586019756 | accuracy: 0.7270066889632107 \n",
      "Epoch 3 | Step 1106 | loss: 0.5415111063917482 | accuracy: 0.726875 \n",
      "Epoch 3 | Step 1107 | loss: 0.5412351360352732 | accuracy: 0.727107558139535 \n",
      "Epoch 3 | Step 1108 | loss: 0.5415380800401931 | accuracy: 0.7268211920529802 \n",
      "Epoch 3 | Step 1109 | loss: 0.5413799439326376 | accuracy: 0.7268461221122113 \n",
      "Epoch 3 | Step 1110 | loss: 0.541450777924375 | accuracy: 0.7266138980263159 \n",
      "Epoch 3 | Step 1111 | loss: 0.5414081346793258 | accuracy: 0.726690573770492 \n",
      "Epoch 3 | Step 1112 | loss: 0.5413998429681746 | accuracy: 0.7265625000000002 \n",
      "Epoch 3 | Step 1113 | loss: 0.5412841625632996 | accuracy: 0.7265879478827364 \n",
      "Epoch 3 | Step 1114 | loss: 0.5409666917153771 | accuracy: 0.7269176136363639 \n",
      "Epoch 3 | Step 1115 | loss: 0.5408382215160387 | accuracy: 0.7270428802589 \n",
      "Epoch 3 | Step 1116 | loss: 0.5407415320796356 | accuracy: 0.7270161290322583 \n",
      "Epoch 3 | Step 1117 | loss: 0.5405518351260493 | accuracy: 0.7273412379421225 \n",
      "Epoch 3 | Step 1118 | loss: 0.5405645372393808 | accuracy: 0.7270132211538465 \n",
      "Epoch 3 | Step 1119 | loss: 0.5403434599931253 | accuracy: 0.7270866613418534 \n",
      "Epoch 3 | Step 1120 | loss: 0.5406244055480719 | accuracy: 0.7269605891719749 \n",
      "Epoch 3 | Step 1121 | loss: 0.5409289019448421 | accuracy: 0.7266865079365084 \n",
      "Epoch 3 | Step 1122 | loss: 0.5409373314697535 | accuracy: 0.7266119462025321 \n",
      "Epoch 3 | Step 1123 | loss: 0.5404535140900962 | accuracy: 0.7271293375394327 \n",
      "Epoch 3 | Step 1124 | loss: 0.5407237388053034 | accuracy: 0.726906446540881 \n",
      "Epoch 3 | Step 1125 | loss: 0.5404587362814104 | accuracy: 0.7270768025078375 \n",
      "Epoch 3 | Step 1126 | loss: 0.5402622028253977 | accuracy: 0.7272460937500005 \n",
      "Epoch 3 | Step 1127 | loss: 0.5401549642888189 | accuracy: 0.7274143302180691 \n",
      "Epoch 3 | Step 1128 | loss: 0.5402255910709042 | accuracy: 0.7272418478260876 \n",
      "Epoch 3 | Step 1129 | loss: 0.5400872060758046 | accuracy: 0.7273606811145517 \n",
      "Epoch 3 | Step 1130 | loss: 0.5398494098105553 | accuracy: 0.7273823302469141 \n",
      "Epoch 3 | Step 1131 | loss: 0.5399017296387604 | accuracy: 0.7274519230769236 \n",
      "Epoch 3 | Step 1132 | loss: 0.5396536943371315 | accuracy: 0.7275690184049085 \n",
      "Epoch 3 | Step 1133 | loss: 0.5396724080820701 | accuracy: 0.7275898318042818 \n",
      "Epoch 3 | Step 1134 | loss: 0.5399356291788384 | accuracy: 0.7274676067073176 \n",
      "Epoch 3 | Step 1135 | loss: 0.5399377904039752 | accuracy: 0.7275835866261403 \n",
      "Epoch 3 | Step 1136 | loss: 0.5398546318213149 | accuracy: 0.7276515151515157 \n",
      "Epoch 3 | Step 1137 | loss: 0.5399291347881101 | accuracy: 0.7274830060422967 \n",
      "Epoch 3 | Step 1138 | loss: 0.5398847652846075 | accuracy: 0.7275037650602416 \n",
      "Epoch 3 | Step 1139 | loss: 0.5400186658979539 | accuracy: 0.7272897897897904 \n",
      "Epoch 3 | Step 1140 | loss: 0.5397162804168144 | accuracy: 0.7274045658682641 \n",
      "Epoch 3 | Step 1141 | loss: 0.5395794260857713 | accuracy: 0.7275652985074633 \n",
      "Epoch 3 | Step 1142 | loss: 0.5392544783119647 | accuracy: 0.7278645833333339 \n",
      "Epoch 3 | Step 1143 | loss: 0.5391008679696999 | accuracy: 0.7280693620178047 \n",
      "Epoch 3 | Step 1144 | loss: 0.5392115880575408 | accuracy: 0.7280417899408289 \n",
      "Epoch 3 | Step 1145 | loss: 0.5389054354313202 | accuracy: 0.7282448377581126 \n",
      "Epoch 3 | Step 1146 | loss: 0.5387104133472724 | accuracy: 0.728446691176471 \n",
      "Epoch 3 | Step 1147 | loss: 0.5388288890336617 | accuracy: 0.7282807917888567 \n",
      "Epoch 3 | Step 1148 | loss: 0.5386436644353365 | accuracy: 0.7282529239766086 \n",
      "Epoch 3 | Step 1149 | loss: 0.538516726333963 | accuracy: 0.7284529883381928 \n",
      "Epoch 3 | Step 1150 | loss: 0.5381438875960749 | accuracy: 0.7288335755813957 \n",
      "Epoch 3 | Step 1151 | loss: 0.5382003798001055 | accuracy: 0.7288043478260873 \n",
      "Epoch 3 | Step 1152 | loss: 0.5382382442496416 | accuracy: 0.7287301300578038 \n",
      "Epoch 3 | Step 1153 | loss: 0.5381194148695779 | accuracy: 0.7287914265129687 \n",
      "Epoch 3 | Step 1154 | loss: 0.5382551410417448 | accuracy: 0.7286727729885062 \n",
      "Epoch 3 | Step 1155 | loss: 0.5380236456079949 | accuracy: 0.7288681948424073 \n",
      "Epoch 3 | Step 1156 | loss: 0.5377003015790668 | accuracy: 0.7291071428571433 \n",
      "Epoch 3 | Step 1157 | loss: 0.5375101709807362 | accuracy: 0.729300213675214 \n",
      "Epoch 3 | Step 1158 | loss: 0.5373942139135166 | accuracy: 0.7294477982954549 \n",
      "Epoch 3 | Step 1159 | loss: 0.5372510771069243 | accuracy: 0.7295945467422099 \n",
      "Epoch 3 | Step 1160 | loss: 0.5371643556545009 | accuracy: 0.7296963276836161 \n",
      "Epoch 3 | Step 1161 | loss: 0.5371809795708723 | accuracy: 0.729929577464789 \n",
      "Epoch 3 | Step 1162 | loss: 0.5369457876246966 | accuracy: 0.7300298455056183 \n",
      "Epoch 3 | Step 1163 | loss: 0.5365037401350272 | accuracy: 0.7303921568627454 \n",
      "Epoch 3 | Step 1164 | loss: 0.5362966582595303 | accuracy: 0.7307087988826819 \n",
      "Epoch 3 | Step 1165 | loss: 0.5362182361667867 | accuracy: 0.7307625348189418 \n",
      "Epoch 3 | Step 1166 | loss: 0.5363026806877719 | accuracy: 0.7305555555555558 \n",
      "Epoch 3 | Step 1167 | loss: 0.5359938595433644 | accuracy: 0.730825831024931 \n",
      "Epoch 3 | Step 1168 | loss: 0.5358442160306056 | accuracy: 0.731008287292818 \n",
      "Epoch 3 | Step 1169 | loss: 0.5360656520223486 | accuracy: 0.7308453856749314 \n",
      "Epoch 3 | Step 1170 | loss: 0.5358046233490272 | accuracy: 0.7309409340659344 \n",
      "Epoch 3 | Step 1171 | loss: 0.5359004253393982 | accuracy: 0.7309075342465756 \n",
      "Epoch 3 | Step 1172 | loss: 0.5356413525798932 | accuracy: 0.7311731557377052 \n",
      "Epoch 3 | Step 1173 | loss: 0.5358510664600766 | accuracy: 0.7310115803814717 \n",
      "Epoch 3 | Step 1174 | loss: 0.5358394377095543 | accuracy: 0.7308933423913047 \n",
      "Epoch 3 | Step 1175 | loss: 0.5359059913856227 | accuracy: 0.7307757452574529 \n",
      "Epoch 3 | Step 1176 | loss: 0.5362716543513375 | accuracy: 0.7306165540540543 \n",
      "Epoch 3 | Step 1177 | loss: 0.5366118232998244 | accuracy: 0.7303739892183292 \n",
      "Epoch 3 | Step 1178 | loss: 0.5365957277276183 | accuracy: 0.7303007392473121 \n",
      "Epoch 3 | Step 1179 | loss: 0.5365036140338346 | accuracy: 0.7305211126005365 \n",
      "Epoch 3 | Step 1180 | loss: 0.5361841761651525 | accuracy: 0.730823863636364 \n",
      "Epoch 3 | Step 1181 | loss: 0.5359143264293671 | accuracy: 0.7310833333333336 \n",
      "Epoch 3 | Step 1182 | loss: 0.5356418699660199 | accuracy: 0.7312167553191492 \n",
      "Epoch 3 | Step 1183 | loss: 0.5353682986621198 | accuracy: 0.7313909151193637 \n",
      "Epoch 3 | Step 1184 | loss: 0.535518309426686 | accuracy: 0.73119212962963 \n",
      "Epoch 3 | Step 1185 | loss: 0.5355019548952106 | accuracy: 0.731159300791557 \n",
      "Epoch 3 | Step 1186 | loss: 0.5352509660940419 | accuracy: 0.7312500000000003 \n",
      "Epoch 3 | Step 1187 | loss: 0.5351921816666919 | accuracy: 0.7312992125984255 \n",
      "Epoch 3 | Step 1188 | loss: 0.5348521888412104 | accuracy: 0.7315117801047123 \n",
      "Epoch 3 | Step 1189 | loss: 0.5349292486672612 | accuracy: 0.7314376631853788 \n",
      "Epoch 3 | Step 1190 | loss: 0.5351291040424256 | accuracy: 0.731241861979167 \n",
      "Epoch 3 | Step 1191 | loss: 0.535103398871112 | accuracy: 0.7314123376623379 \n",
      "Epoch 3 | Step 1192 | loss: 0.5352186802292116 | accuracy: 0.7314200129533681 \n",
      "Epoch 3 | Step 1193 | loss: 0.5353599123714504 | accuracy: 0.7313872739018091 \n",
      "Epoch 3 | Step 1194 | loss: 0.5354210483198312 | accuracy: 0.7314755154639179 \n",
      "Epoch 3 | Step 1195 | loss: 0.5356977519921593 | accuracy: 0.7312821336760928 \n",
      "Epoch 3 | Step 1196 | loss: 0.5355558778995121 | accuracy: 0.7313701923076926 \n",
      "Epoch 3 | Step 1197 | loss: 0.5355719497136752 | accuracy: 0.7314178388746806 \n",
      "Epoch 3 | Step 1198 | loss: 0.5356366371317784 | accuracy: 0.7313456632653064 \n",
      "Epoch 3 | Step 1199 | loss: 0.535495365773145 | accuracy: 0.731512404580153 \n",
      "Epoch 3 | Step 1200 | loss: 0.5355047027622987 | accuracy: 0.7315196700507617 \n",
      "Epoch 3 | Step 1201 | loss: 0.535530402011509 | accuracy: 0.7314477848101268 \n",
      "Epoch 3 | Step 1202 | loss: 0.5352169036714716 | accuracy: 0.7316524621212124 \n",
      "Epoch 3 | Step 1203 | loss: 0.535055814146695 | accuracy: 0.7316986775818642 \n",
      "Epoch 3 | Step 1204 | loss: 0.5350974174450387 | accuracy: 0.7316268844221109 \n",
      "Epoch 3 | Step 1205 | loss: 0.5351010606551824 | accuracy: 0.7316337719298248 \n",
      "Epoch 3 | Step 1206 | loss: 0.5352131881564851 | accuracy: 0.7316796875000002 \n",
      "Epoch 3 | Step 1207 | loss: 0.5352813556158628 | accuracy: 0.7316084788029928 \n",
      "Epoch 3 | Step 1208 | loss: 0.535580925606376 | accuracy: 0.7314598880597017 \n",
      "Epoch 3 | Step 1209 | loss: 0.5354869288782915 | accuracy: 0.7316128497679834 \n",
      "Validation | Epoch 3 | Step 1209 | accuracy: 0.7554347826675936 \n",
      "Epoch 4 | Step 1210 | loss: 0.5118886828422546 | accuracy: 0.75 \n",
      "Epoch 4 | Step 1211 | loss: 0.5345251858234406 | accuracy: 0.71875 \n",
      "Epoch 4 | Step 1212 | loss: 0.5179670651753744 | accuracy: 0.734375 \n",
      "Epoch 4 | Step 1213 | loss: 0.5149307101964951 | accuracy: 0.734375 \n",
      "Epoch 4 | Step 1214 | loss: 0.5121635675430298 | accuracy: 0.75 \n",
      "Epoch 4 | Step 1215 | loss: 0.5105479955673218 | accuracy: 0.7552083333333334 \n",
      "Epoch 4 | Step 1216 | loss: 0.51332026720047 | accuracy: 0.7544642857142857 \n",
      "Epoch 4 | Step 1217 | loss: 0.5161940008401871 | accuracy: 0.751953125 \n",
      "Epoch 4 | Step 1218 | loss: 0.5112879044479794 | accuracy: 0.75 \n",
      "Epoch 4 | Step 1219 | loss: 0.5134707778692246 | accuracy: 0.7484375 \n",
      "Epoch 4 | Step 1220 | loss: 0.5099425749345259 | accuracy: 0.7528409090909091 \n",
      "Epoch 4 | Step 1221 | loss: 0.5127671311299006 | accuracy: 0.74609375 \n",
      "Epoch 4 | Step 1222 | loss: 0.5093802144894233 | accuracy: 0.7475961538461539 \n",
      "Epoch 4 | Step 1223 | loss: 0.5059489884546825 | accuracy: 0.7488839285714286 \n",
      "Epoch 4 | Step 1224 | loss: 0.5003014405568441 | accuracy: 0.7541666666666667 \n",
      "Epoch 4 | Step 1225 | loss: 0.49316685460507875 | accuracy: 0.7587890625 \n",
      "Epoch 4 | Step 1226 | loss: 0.48833658414728504 | accuracy: 0.7619485294117647 \n",
      "Epoch 4 | Step 1227 | loss: 0.4902404182487064 | accuracy: 0.7630208333333334 \n",
      "Epoch 4 | Step 1228 | loss: 0.4926964201425251 | accuracy: 0.7639802631578947 \n",
      "Epoch 4 | Step 1229 | loss: 0.4904967874288559 | accuracy: 0.76484375 \n",
      "Epoch 4 | Step 1230 | loss: 0.48822984667051406 | accuracy: 0.7671130952380952 \n",
      "Epoch 4 | Step 1231 | loss: 0.48503389819101855 | accuracy: 0.7670454545454546 \n",
      "Epoch 4 | Step 1232 | loss: 0.4829125300697658 | accuracy: 0.7676630434782609 \n",
      "Epoch 4 | Step 1233 | loss: 0.48018411298592883 | accuracy: 0.7682291666666666 \n",
      "Epoch 4 | Step 1234 | loss: 0.48045020818710327 | accuracy: 0.76625 \n",
      "Epoch 4 | Step 1235 | loss: 0.4784462337310498 | accuracy: 0.7650240384615384 \n",
      "Epoch 4 | Step 1236 | loss: 0.4814132738996435 | accuracy: 0.7633101851851852 \n",
      "Epoch 4 | Step 1237 | loss: 0.4786062868578093 | accuracy: 0.7661830357142857 \n",
      "Epoch 4 | Step 1238 | loss: 0.4802973897292696 | accuracy: 0.7661637931034483 \n",
      "Epoch 4 | Step 1239 | loss: 0.4806306064128876 | accuracy: 0.7645833333333333 \n",
      "Epoch 4 | Step 1240 | loss: 0.48211998324240407 | accuracy: 0.7641129032258065 \n",
      "Epoch 4 | Step 1241 | loss: 0.48468396812677383 | accuracy: 0.76318359375 \n",
      "Epoch 4 | Step 1242 | loss: 0.4863401940374663 | accuracy: 0.7613636363636364 \n",
      "Epoch 4 | Step 1243 | loss: 0.48471574047032523 | accuracy: 0.7637867647058824 \n",
      "Epoch 4 | Step 1244 | loss: 0.48367487873349874 | accuracy: 0.7647321428571429 \n",
      "Epoch 4 | Step 1245 | loss: 0.48340852393044365 | accuracy: 0.7647569444444444 \n",
      "Epoch 4 | Step 1246 | loss: 0.4840496762378796 | accuracy: 0.7643581081081081 \n",
      "Epoch 4 | Step 1247 | loss: 0.4841307033049433 | accuracy: 0.7631578947368421 \n",
      "Epoch 4 | Step 1248 | loss: 0.4867412440287761 | accuracy: 0.7596153846153846 \n",
      "Epoch 4 | Step 1249 | loss: 0.48771203085780146 | accuracy: 0.758984375 \n",
      "Epoch 4 | Step 1250 | loss: 0.48641241469034335 | accuracy: 0.760670731707317 \n",
      "Epoch 4 | Step 1251 | loss: 0.48646846342654454 | accuracy: 0.7607886904761904 \n",
      "Epoch 4 | Step 1252 | loss: 0.48582516506660817 | accuracy: 0.7623546511627907 \n",
      "Epoch 4 | Step 1253 | loss: 0.4855253947052089 | accuracy: 0.7627840909090909 \n",
      "Epoch 4 | Step 1254 | loss: 0.4881594081719716 | accuracy: 0.7611111111111111 \n",
      "Epoch 4 | Step 1255 | loss: 0.4908877941577331 | accuracy: 0.7588315217391305 \n",
      "Epoch 4 | Step 1256 | loss: 0.4900774949408592 | accuracy: 0.7599734042553191 \n",
      "Epoch 4 | Step 1257 | loss: 0.49070837410787743 | accuracy: 0.7587890625 \n",
      "Epoch 4 | Step 1258 | loss: 0.48989523795186257 | accuracy: 0.7595663265306123 \n",
      "Epoch 4 | Step 1259 | loss: 0.4906926691532135 | accuracy: 0.7590625 \n",
      "Epoch 4 | Step 1260 | loss: 0.491588830947876 | accuracy: 0.7582720588235294 \n",
      "Epoch 4 | Step 1261 | loss: 0.4922531568087064 | accuracy: 0.7572115384615384 \n",
      "Epoch 4 | Step 1262 | loss: 0.49199245110997614 | accuracy: 0.7576650943396226 \n",
      "Epoch 4 | Step 1263 | loss: 0.4912680376459051 | accuracy: 0.7581018518518519 \n",
      "Epoch 4 | Step 1264 | loss: 0.49058803536675194 | accuracy: 0.7582386363636363 \n",
      "Epoch 4 | Step 1265 | loss: 0.4912249541708401 | accuracy: 0.7583705357142857 \n",
      "Epoch 4 | Step 1266 | loss: 0.4910081870723189 | accuracy: 0.7593201754385965 \n",
      "Epoch 4 | Step 1267 | loss: 0.49193788345517786 | accuracy: 0.7588900862068966 \n",
      "Epoch 4 | Step 1268 | loss: 0.4925429684630895 | accuracy: 0.7579449152542372 \n",
      "Epoch 4 | Step 1269 | loss: 0.4924598867694537 | accuracy: 0.7580729166666667 \n",
      "Epoch 4 | Step 1270 | loss: 0.49202622986230693 | accuracy: 0.7587090163934426 \n",
      "Epoch 4 | Step 1271 | loss: 0.492004951161723 | accuracy: 0.7583165322580645 \n",
      "Epoch 4 | Step 1272 | loss: 0.492718896222493 | accuracy: 0.7579365079365079 \n",
      "Epoch 4 | Step 1273 | loss: 0.4913129289634526 | accuracy: 0.75830078125 \n",
      "Epoch 4 | Step 1274 | loss: 0.49068992000359757 | accuracy: 0.7581730769230769 \n",
      "Epoch 4 | Step 1275 | loss: 0.48939267523360974 | accuracy: 0.7592329545454546 \n",
      "Epoch 4 | Step 1276 | loss: 0.4894527112370107 | accuracy: 0.7590951492537313 \n",
      "Epoch 4 | Step 1277 | loss: 0.48867331489044075 | accuracy: 0.7589613970588235 \n",
      "Epoch 4 | Step 1278 | loss: 0.48991524611694226 | accuracy: 0.7572463768115942 \n",
      "Epoch 4 | Step 1279 | loss: 0.4910485135657447 | accuracy: 0.7560267857142857 \n",
      "Epoch 4 | Step 1280 | loss: 0.4907010793685913 | accuracy: 0.7563820422535211 \n",
      "Epoch 4 | Step 1281 | loss: 0.490686747762892 | accuracy: 0.7575954861111112 \n",
      "Epoch 4 | Step 1282 | loss: 0.4902656021183484 | accuracy: 0.7577054794520548 \n",
      "Epoch 4 | Step 1283 | loss: 0.4899215065949672 | accuracy: 0.7576013513513513 \n",
      "Epoch 4 | Step 1284 | loss: 0.4902005000909169 | accuracy: 0.7572916666666667 \n",
      "Epoch 4 | Step 1285 | loss: 0.48949178229821355 | accuracy: 0.7576069078947368 \n",
      "Epoch 4 | Step 1286 | loss: 0.4890796538297232 | accuracy: 0.7581168831168831 \n",
      "Epoch 4 | Step 1287 | loss: 0.48986685084990966 | accuracy: 0.7576121794871795 \n",
      "Epoch 4 | Step 1288 | loss: 0.4893458919434608 | accuracy: 0.7583069620253164 \n",
      "Epoch 4 | Step 1289 | loss: 0.48952500633895396 | accuracy: 0.7583984375 \n",
      "Epoch 4 | Step 1290 | loss: 0.4890132053398792 | accuracy: 0.7590663580246914 \n",
      "Epoch 4 | Step 1291 | loss: 0.48829131736987974 | accuracy: 0.7597179878048781 \n",
      "Epoch 4 | Step 1292 | loss: 0.4873107470661761 | accuracy: 0.7599774096385542 \n",
      "Epoch 4 | Step 1293 | loss: 0.48733783797139213 | accuracy: 0.7600446428571429 \n",
      "Epoch 4 | Step 1294 | loss: 0.4882871785584618 | accuracy: 0.7590073529411765 \n",
      "Epoch 4 | Step 1295 | loss: 0.4874234833689623 | accuracy: 0.7599927325581395 \n",
      "Epoch 4 | Step 1296 | loss: 0.4872695156212511 | accuracy: 0.7602370689655172 \n",
      "Epoch 4 | Step 1297 | loss: 0.48795661160891707 | accuracy: 0.7602982954545454 \n",
      "Epoch 4 | Step 1298 | loss: 0.4880119598983379 | accuracy: 0.7598314606741573 \n",
      "Epoch 4 | Step 1299 | loss: 0.48842505051030055 | accuracy: 0.759375 \n",
      "Epoch 4 | Step 1300 | loss: 0.48734297300433066 | accuracy: 0.7599587912087912 \n",
      "Epoch 4 | Step 1301 | loss: 0.4893244689573412 | accuracy: 0.7588315217391305 \n",
      "Epoch 4 | Step 1302 | loss: 0.4885557194550832 | accuracy: 0.7594086021505376 \n",
      "Epoch 4 | Step 1303 | loss: 0.4878789817399167 | accuracy: 0.7601396276595744 \n",
      "Epoch 4 | Step 1304 | loss: 0.4873917905907882 | accuracy: 0.7603618421052631 \n",
      "Epoch 4 | Step 1305 | loss: 0.48706964620699483 | accuracy: 0.76025390625 \n",
      "Epoch 4 | Step 1306 | loss: 0.4868382415206162 | accuracy: 0.7607925257731959 \n",
      "Epoch 4 | Step 1307 | loss: 0.4878257625565237 | accuracy: 0.7603635204081632 \n",
      "Epoch 4 | Step 1308 | loss: 0.48726052467269126 | accuracy: 0.7604166666666666 \n",
      "Epoch 4 | Step 1309 | loss: 0.4871239280700684 | accuracy: 0.76046875 \n",
      "Epoch 4 | Step 1310 | loss: 0.48638897957188065 | accuracy: 0.7612933168316832 \n",
      "Epoch 4 | Step 1311 | loss: 0.4873315668573566 | accuracy: 0.7602634803921569 \n",
      "Epoch 4 | Step 1312 | loss: 0.48747512784976404 | accuracy: 0.7598604368932039 \n",
      "Epoch 4 | Step 1313 | loss: 0.48709451808379245 | accuracy: 0.7600661057692307 \n",
      "Epoch 4 | Step 1314 | loss: 0.48743321782066706 | accuracy: 0.7602678571428572 \n",
      "Epoch 4 | Step 1315 | loss: 0.4860302710308219 | accuracy: 0.7613502358490566 \n",
      "Epoch 4 | Step 1316 | loss: 0.486851860429639 | accuracy: 0.7612441588785047 \n",
      "Epoch 4 | Step 1317 | loss: 0.48700800427684077 | accuracy: 0.7612847222222222 \n",
      "Epoch 4 | Step 1318 | loss: 0.48681191730936735 | accuracy: 0.7617545871559633 \n",
      "Epoch 4 | Step 1319 | loss: 0.4864840797402642 | accuracy: 0.7620738636363636 \n",
      "Epoch 4 | Step 1320 | loss: 0.4881273054324829 | accuracy: 0.7615427927927928 \n",
      "Epoch 4 | Step 1321 | loss: 0.4887803199567965 | accuracy: 0.7613002232142857 \n",
      "Epoch 4 | Step 1322 | loss: 0.48893332718747906 | accuracy: 0.761200221238938 \n",
      "Epoch 4 | Step 1323 | loss: 0.4891296559781359 | accuracy: 0.7609649122807017 \n",
      "Epoch 4 | Step 1324 | loss: 0.48845548292864926 | accuracy: 0.7619565217391304 \n",
      "Epoch 4 | Step 1325 | loss: 0.4886977685422733 | accuracy: 0.7623922413793104 \n",
      "Epoch 4 | Step 1326 | loss: 0.48787583525364214 | accuracy: 0.7626869658119658 \n",
      "Epoch 4 | Step 1327 | loss: 0.4878152805869862 | accuracy: 0.762844279661017 \n",
      "Epoch 4 | Step 1328 | loss: 0.4884358374010615 | accuracy: 0.7623424369747899 \n",
      "Epoch 4 | Step 1329 | loss: 0.48808634504675863 | accuracy: 0.762109375 \n",
      "Epoch 4 | Step 1330 | loss: 0.4877465941196631 | accuracy: 0.7622675619834711 \n",
      "Epoch 4 | Step 1331 | loss: 0.48787394385845934 | accuracy: 0.7622950819672131 \n",
      "Epoch 4 | Step 1332 | loss: 0.48764072661477376 | accuracy: 0.7628302845528455 \n",
      "Epoch 4 | Step 1333 | loss: 0.48772984815220677 | accuracy: 0.7629788306451613 \n",
      "Epoch 4 | Step 1334 | loss: 0.48739630579948423 | accuracy: 0.76325 \n",
      "Epoch 4 | Step 1335 | loss: 0.4872822891625147 | accuracy: 0.763640873015873 \n",
      "Epoch 4 | Step 1336 | loss: 0.48806722732040825 | accuracy: 0.7631643700787402 \n",
      "Epoch 4 | Step 1337 | loss: 0.48812321457080543 | accuracy: 0.763427734375 \n",
      "Epoch 4 | Step 1338 | loss: 0.4880728991918786 | accuracy: 0.763202519379845 \n",
      "Epoch 4 | Step 1339 | loss: 0.48822879034739275 | accuracy: 0.7631009615384615 \n",
      "Epoch 4 | Step 1340 | loss: 0.488749832369899 | accuracy: 0.7625238549618321 \n",
      "Epoch 4 | Step 1341 | loss: 0.4892574122006243 | accuracy: 0.7619554924242424 \n",
      "Epoch 4 | Step 1342 | loss: 0.48865311239895065 | accuracy: 0.7622180451127819 \n",
      "Epoch 4 | Step 1343 | loss: 0.48888374108876753 | accuracy: 0.761660447761194 \n",
      "Epoch 4 | Step 1344 | loss: 0.4888946813565713 | accuracy: 0.7616898148148148 \n",
      "Epoch 4 | Step 1345 | loss: 0.488386357531828 | accuracy: 0.7620634191176471 \n",
      "Epoch 4 | Step 1346 | loss: 0.48813116245896276 | accuracy: 0.7623175182481752 \n",
      "Epoch 4 | Step 1347 | loss: 0.4884017800939256 | accuracy: 0.7620018115942029 \n",
      "Epoch 4 | Step 1348 | loss: 0.4884320536105753 | accuracy: 0.7619154676258992 \n",
      "Epoch 4 | Step 1349 | loss: 0.4878708160349301 | accuracy: 0.7623883928571429 \n",
      "Epoch 4 | Step 1350 | loss: 0.4872851010332716 | accuracy: 0.762854609929078 \n",
      "Epoch 4 | Step 1351 | loss: 0.48684457301254 | accuracy: 0.7632042253521126 \n",
      "Epoch 4 | Step 1352 | loss: 0.48677206393722056 | accuracy: 0.7633304195804196 \n",
      "Epoch 4 | Step 1353 | loss: 0.48591085378494525 | accuracy: 0.7638888888888888 \n",
      "Epoch 4 | Step 1354 | loss: 0.485921664484616 | accuracy: 0.7637931034482759 \n",
      "Epoch 4 | Step 1355 | loss: 0.4868877395375134 | accuracy: 0.7631635273972602 \n",
      "Epoch 4 | Step 1356 | loss: 0.48638152285498015 | accuracy: 0.7639243197278912 \n",
      "Epoch 4 | Step 1357 | loss: 0.48602218885679505 | accuracy: 0.7640413851351352 \n",
      "Epoch 4 | Step 1358 | loss: 0.4855039359739163 | accuracy: 0.7647860738255035 \n",
      "Epoch 4 | Step 1359 | loss: 0.485657160282135 | accuracy: 0.7643750000000001 \n",
      "Epoch 4 | Step 1360 | loss: 0.48540605950039745 | accuracy: 0.7643832781456955 \n",
      "Epoch 4 | Step 1361 | loss: 0.4860086458686151 | accuracy: 0.7638774671052634 \n",
      "Epoch 4 | Step 1362 | loss: 0.4861509131839852 | accuracy: 0.763684640522876 \n",
      "Epoch 4 | Step 1363 | loss: 0.48600196548096547 | accuracy: 0.7639001623376626 \n",
      "Epoch 4 | Step 1364 | loss: 0.48564749456221057 | accuracy: 0.7645161290322583 \n",
      "Epoch 4 | Step 1365 | loss: 0.48548174592164844 | accuracy: 0.7647235576923079 \n",
      "Epoch 4 | Step 1366 | loss: 0.48504461908036733 | accuracy: 0.7648288216560513 \n",
      "Epoch 4 | Step 1367 | loss: 0.4848624039677125 | accuracy: 0.7649327531645572 \n",
      "Epoch 4 | Step 1368 | loss: 0.4843889761645839 | accuracy: 0.7650353773584908 \n",
      "Epoch 4 | Step 1369 | loss: 0.48472496289759875 | accuracy: 0.7646484375000002 \n",
      "Epoch 4 | Step 1370 | loss: 0.4844753705196499 | accuracy: 0.7649456521739132 \n",
      "Epoch 4 | Step 1371 | loss: 0.48481494482652643 | accuracy: 0.7646604938271606 \n",
      "Epoch 4 | Step 1372 | loss: 0.4846221197602208 | accuracy: 0.7644746932515338 \n",
      "Epoch 4 | Step 1373 | loss: 0.48448012387607153 | accuracy: 0.764767530487805 \n",
      "Epoch 4 | Step 1374 | loss: 0.48445829496239173 | accuracy: 0.7642992424242425 \n",
      "Epoch 4 | Step 1375 | loss: 0.4849490363554782 | accuracy: 0.7643072289156627 \n",
      "Epoch 4 | Step 1376 | loss: 0.48455361852388895 | accuracy: 0.7645022455089822 \n",
      "Epoch 4 | Step 1377 | loss: 0.4843348301947117 | accuracy: 0.7646019345238095 \n",
      "Epoch 4 | Step 1378 | loss: 0.4850667946084717 | accuracy: 0.7643306213017751 \n",
      "Epoch 4 | Step 1379 | loss: 0.484348871252116 | accuracy: 0.7646139705882353 \n",
      "Epoch 4 | Step 1380 | loss: 0.48431112212047245 | accuracy: 0.7645285087719298 \n",
      "Epoch 4 | Step 1381 | loss: 0.48479855077904327 | accuracy: 0.764171511627907 \n",
      "Epoch 4 | Step 1382 | loss: 0.4838751647513726 | accuracy: 0.7648121387283237 \n",
      "Epoch 4 | Step 1383 | loss: 0.48446173332203396 | accuracy: 0.7649066091954023 \n",
      "Epoch 4 | Step 1384 | loss: 0.48386751106807163 | accuracy: 0.7653571428571428 \n",
      "Epoch 4 | Step 1385 | loss: 0.484142026102001 | accuracy: 0.7650035511363636 \n",
      "Epoch 4 | Step 1386 | loss: 0.48415529306999033 | accuracy: 0.7650953389830508 \n",
      "Epoch 4 | Step 1387 | loss: 0.4840509576743908 | accuracy: 0.7655372191011236 \n",
      "Epoch 4 | Step 1388 | loss: 0.48468660642314887 | accuracy: 0.7649266759776536 \n",
      "Epoch 4 | Step 1389 | loss: 0.4848484906885359 | accuracy: 0.76484375 \n",
      "Epoch 4 | Step 1390 | loss: 0.4848398656805576 | accuracy: 0.7651070441988951 \n",
      "Epoch 4 | Step 1391 | loss: 0.4843917082954239 | accuracy: 0.765367445054945 \n",
      "Epoch 4 | Step 1392 | loss: 0.4842505243306603 | accuracy: 0.7654542349726776 \n",
      "Epoch 4 | Step 1393 | loss: 0.48423734598833584 | accuracy: 0.765625 \n",
      "Epoch 4 | Step 1394 | loss: 0.4839664812023575 | accuracy: 0.7660472972972973 \n",
      "Epoch 4 | Step 1395 | loss: 0.4838742570530984 | accuracy: 0.7659610215053764 \n",
      "Epoch 4 | Step 1396 | loss: 0.4838602110982579 | accuracy: 0.7657085561497327 \n",
      "Epoch 4 | Step 1397 | loss: 0.4837289625342856 | accuracy: 0.7657912234042553 \n",
      "Epoch 4 | Step 1398 | loss: 0.4836466495322172 | accuracy: 0.7658730158730159 \n",
      "Epoch 4 | Step 1399 | loss: 0.4832029424215618 | accuracy: 0.7662828947368421 \n",
      "Epoch 4 | Step 1400 | loss: 0.4832528414526535 | accuracy: 0.7661158376963351 \n",
      "Epoch 4 | Step 1401 | loss: 0.48326881633450586 | accuracy: 0.7661946614583334 \n",
      "Epoch 4 | Step 1402 | loss: 0.48336978372514555 | accuracy: 0.7660297927461139 \n",
      "Epoch 4 | Step 1403 | loss: 0.4834103421452119 | accuracy: 0.7659471649484536 \n",
      "Epoch 4 | Step 1404 | loss: 0.4835078936356765 | accuracy: 0.7660256410256411 \n",
      "Epoch 4 | Step 1405 | loss: 0.4832372969510604 | accuracy: 0.7660235969387755 \n",
      "Epoch 4 | Step 1406 | loss: 0.48296281044858363 | accuracy: 0.7659422588832487 \n",
      "Epoch 4 | Step 1407 | loss: 0.4826611056171282 | accuracy: 0.766177398989899 \n",
      "Epoch 4 | Step 1408 | loss: 0.4829141127703777 | accuracy: 0.7658605527638191 \n",
      "Epoch 4 | Step 1409 | loss: 0.4830438919365406 | accuracy: 0.765625 \n",
      "Epoch 4 | Step 1410 | loss: 0.4826559510397081 | accuracy: 0.7655472636815921 \n",
      "Epoch 4 | Step 1411 | loss: 0.4826832779563299 | accuracy: 0.7655476485148515 \n",
      "Epoch 4 | Step 1412 | loss: 0.4827219224328478 | accuracy: 0.7653940886699507 \n",
      "Epoch 4 | Step 1413 | loss: 0.48290683884246677 | accuracy: 0.7650122549019608 \n",
      "Epoch 4 | Step 1414 | loss: 0.4827868996596918 | accuracy: 0.7650914634146342 \n",
      "Epoch 4 | Step 1415 | loss: 0.4828692119098404 | accuracy: 0.7650182038834952 \n",
      "Epoch 4 | Step 1416 | loss: 0.4833490275530424 | accuracy: 0.7644927536231884 \n",
      "Epoch 4 | Step 1417 | loss: 0.4829418101849464 | accuracy: 0.7647235576923077 \n",
      "Epoch 4 | Step 1418 | loss: 0.48297863072185426 | accuracy: 0.7649521531100478 \n",
      "Epoch 4 | Step 1419 | loss: 0.4827059833776383 | accuracy: 0.7650297619047619 \n",
      "Epoch 4 | Step 1420 | loss: 0.4824674962821165 | accuracy: 0.7650325829383886 \n",
      "Epoch 4 | Step 1421 | loss: 0.48237583673787565 | accuracy: 0.7650353773584906 \n",
      "Epoch 4 | Step 1422 | loss: 0.4822500462823071 | accuracy: 0.7649647887323944 \n",
      "Epoch 4 | Step 1423 | loss: 0.48217820786984167 | accuracy: 0.7651139018691588 \n",
      "Epoch 4 | Step 1424 | loss: 0.48232271144556443 | accuracy: 0.7650436046511628 \n",
      "Epoch 4 | Step 1425 | loss: 0.48219680041074753 | accuracy: 0.7651909722222222 \n",
      "Epoch 4 | Step 1426 | loss: 0.4825989551807878 | accuracy: 0.7647609447004609 \n",
      "Epoch 4 | Step 1427 | loss: 0.4829439911820473 | accuracy: 0.7643348623853211 \n",
      "Epoch 4 | Step 1428 | loss: 0.4831405448042639 | accuracy: 0.7641267123287672 \n",
      "Epoch 4 | Step 1429 | loss: 0.48318574902686207 | accuracy: 0.7641335227272728 \n",
      "Epoch 4 | Step 1430 | loss: 0.4830660395223091 | accuracy: 0.7640695701357466 \n",
      "Epoch 4 | Step 1431 | loss: 0.48344355002716854 | accuracy: 0.7636542792792793 \n",
      "Epoch 4 | Step 1432 | loss: 0.4830107642128863 | accuracy: 0.7638733183856502 \n",
      "Epoch 4 | Step 1433 | loss: 0.4831154600584081 | accuracy: 0.7640206473214286 \n",
      "Epoch 4 | Step 1434 | loss: 0.4832420088185204 | accuracy: 0.7640277777777778 \n",
      "Epoch 4 | Step 1435 | loss: 0.4830962283685144 | accuracy: 0.7641039823008849 \n",
      "Epoch 4 | Step 1436 | loss: 0.4830011704419678 | accuracy: 0.7641795154185022 \n",
      "Epoch 4 | Step 1437 | loss: 0.4827821544910732 | accuracy: 0.7642543859649122 \n",
      "Epoch 4 | Step 1438 | loss: 0.4824114549888794 | accuracy: 0.7646697598253275 \n",
      "Epoch 4 | Step 1439 | loss: 0.48228948505028435 | accuracy: 0.764741847826087 \n",
      "Epoch 4 | Step 1440 | loss: 0.48185244305825337 | accuracy: 0.7651515151515151 \n",
      "Epoch 4 | Step 1441 | loss: 0.48188945548287754 | accuracy: 0.7650862068965517 \n",
      "Epoch 4 | Step 1442 | loss: 0.4819007618232858 | accuracy: 0.7651555793991416 \n",
      "Epoch 4 | Step 1443 | loss: 0.4824194841914707 | accuracy: 0.764823717948718 \n",
      "Epoch 4 | Step 1444 | loss: 0.4822308986744982 | accuracy: 0.7649601063829787 \n",
      "Epoch 4 | Step 1445 | loss: 0.4819823127176802 | accuracy: 0.7651615466101694 \n",
      "Epoch 4 | Step 1446 | loss: 0.48196900242994606 | accuracy: 0.7650975738396625 \n",
      "Epoch 4 | Step 1447 | loss: 0.482473006518949 | accuracy: 0.7649684873949579 \n",
      "Epoch 4 | Step 1448 | loss: 0.48274796901886435 | accuracy: 0.7648404811715481 \n",
      "Epoch 4 | Step 1449 | loss: 0.4828025506188472 | accuracy: 0.7647135416666667 \n",
      "Epoch 4 | Step 1450 | loss: 0.4831724497045224 | accuracy: 0.7643931535269709 \n",
      "Epoch 4 | Step 1451 | loss: 0.4833714293300613 | accuracy: 0.7645273760330579 \n",
      "Epoch 4 | Step 1452 | loss: 0.4832381947050369 | accuracy: 0.7647890946502057 \n",
      "Epoch 4 | Step 1453 | loss: 0.4830042744269136 | accuracy: 0.7649205942622951 \n",
      "Epoch 4 | Step 1454 | loss: 0.48263556361198423 | accuracy: 0.7652423469387755 \n",
      "Epoch 4 | Step 1455 | loss: 0.4825340420976887 | accuracy: 0.765307418699187 \n",
      "Epoch 4 | Step 1456 | loss: 0.4824251233324831 | accuracy: 0.765371963562753 \n",
      "Epoch 4 | Step 1457 | loss: 0.4825798249052417 | accuracy: 0.7652469758064516 \n",
      "Epoch 4 | Step 1458 | loss: 0.4830487140689988 | accuracy: 0.7648719879518072 \n",
      "Epoch 4 | Step 1459 | loss: 0.48288384985923766 | accuracy: 0.765 \n",
      "Epoch 4 | Step 1460 | loss: 0.48313076633856117 | accuracy: 0.7648157370517928 \n",
      "Epoch 4 | Step 1461 | loss: 0.48373888503937496 | accuracy: 0.7645709325396826 \n",
      "Epoch 4 | Step 1462 | loss: 0.48357563751488336 | accuracy: 0.7646986166007905 \n",
      "Epoch 4 | Step 1463 | loss: 0.48350138715871677 | accuracy: 0.764763779527559 \n",
      "Epoch 4 | Step 1464 | loss: 0.4833101301800971 | accuracy: 0.7648897058823529 \n",
      "Epoch 4 | Step 1465 | loss: 0.48322006745729595 | accuracy: 0.76483154296875 \n",
      "Epoch 4 | Step 1466 | loss: 0.48362387212333974 | accuracy: 0.7645306420233463 \n",
      "Epoch 4 | Step 1467 | loss: 0.48344667671724806 | accuracy: 0.7648982558139535 \n",
      "Epoch 4 | Step 1468 | loss: 0.4835910618765474 | accuracy: 0.7647200772200772 \n",
      "Epoch 4 | Step 1469 | loss: 0.48376765079223194 | accuracy: 0.7644230769230769 \n",
      "Epoch 4 | Step 1470 | loss: 0.4840048609793871 | accuracy: 0.7642480842911877 \n",
      "Epoch 4 | Step 1471 | loss: 0.48434523760362436 | accuracy: 0.7638955152671756 \n",
      "Epoch 4 | Step 1472 | loss: 0.484442490701893 | accuracy: 0.7639020912547528 \n",
      "Epoch 4 | Step 1473 | loss: 0.4842833200413169 | accuracy: 0.7641453598484849 \n",
      "Epoch 4 | Step 1474 | loss: 0.48425152594188475 | accuracy: 0.7640330188679245 \n",
      "Epoch 4 | Step 1475 | loss: 0.48451248752443415 | accuracy: 0.7638040413533834 \n",
      "Epoch 4 | Step 1476 | loss: 0.48426981990257006 | accuracy: 0.7639279026217228 \n",
      "Epoch 4 | Step 1477 | loss: 0.48445921602533826 | accuracy: 0.7637010261194029 \n",
      "Epoch 4 | Step 1478 | loss: 0.484519841059433 | accuracy: 0.7638824349442379 \n",
      "Epoch 4 | Step 1479 | loss: 0.48417925117192445 | accuracy: 0.7640046296296297 \n",
      "Epoch 4 | Step 1480 | loss: 0.4837842788203616 | accuracy: 0.7641835793357934 \n",
      "Epoch 4 | Step 1481 | loss: 0.4834466264309252 | accuracy: 0.7643612132352942 \n",
      "Epoch 4 | Step 1482 | loss: 0.4833857505531101 | accuracy: 0.7643658424908425 \n",
      "Epoch 4 | Step 1483 | loss: 0.4833932962730853 | accuracy: 0.7643134124087592 \n",
      "Epoch 4 | Step 1484 | loss: 0.48372238397598266 | accuracy: 0.7642045454545454 \n",
      "Epoch 4 | Step 1485 | loss: 0.4838700480219247 | accuracy: 0.7641530797101449 \n",
      "Epoch 4 | Step 1486 | loss: 0.4840416428414493 | accuracy: 0.7642712093862816 \n",
      "Epoch 4 | Step 1487 | loss: 0.48369461962645005 | accuracy: 0.764613309352518 \n",
      "Epoch 4 | Step 1488 | loss: 0.4843967063452608 | accuracy: 0.7641689068100358 \n",
      "Epoch 4 | Step 1489 | loss: 0.4841042253587927 | accuracy: 0.7645089285714286 \n",
      "Epoch 4 | Step 1490 | loss: 0.4842793066518587 | accuracy: 0.7641792704626335 \n",
      "Epoch 4 | Step 1491 | loss: 0.48398381651293304 | accuracy: 0.7642952127659575 \n",
      "Epoch 4 | Step 1492 | loss: 0.4839933590417195 | accuracy: 0.7642999116607774 \n",
      "Epoch 4 | Step 1493 | loss: 0.4836802843590857 | accuracy: 0.764524647887324 \n",
      "Epoch 4 | Step 1494 | loss: 0.48361035135754366 | accuracy: 0.7644736842105263 \n",
      "Epoch 4 | Step 1495 | loss: 0.4832856136185306 | accuracy: 0.7647508741258742 \n",
      "Epoch 4 | Step 1496 | loss: 0.48312741154577676 | accuracy: 0.7649172473867596 \n",
      "Epoch 4 | Step 1497 | loss: 0.48276187024182743 | accuracy: 0.7651909722222222 \n",
      "Epoch 4 | Step 1498 | loss: 0.4829556187131413 | accuracy: 0.7649762110726643 \n",
      "Epoch 4 | Step 1499 | loss: 0.48288392773989974 | accuracy: 0.7649245689655172 \n",
      "Epoch 4 | Step 1500 | loss: 0.4829013959034202 | accuracy: 0.7648195876288659 \n",
      "Epoch 4 | Step 1501 | loss: 0.4827292603376794 | accuracy: 0.7649828767123287 \n",
      "Epoch 4 | Step 1502 | loss: 0.48304009895275885 | accuracy: 0.7648784129692832 \n",
      "Epoch 4 | Step 1503 | loss: 0.4828723473411028 | accuracy: 0.7649872448979591 \n",
      "Epoch 4 | Step 1504 | loss: 0.4828451675883794 | accuracy: 0.764883474576271 \n",
      "Epoch 4 | Step 1505 | loss: 0.4829632770773527 | accuracy: 0.7647804054054053 \n",
      "Epoch 4 | Step 1506 | loss: 0.4827601984895841 | accuracy: 0.7648358585858583 \n",
      "Epoch 4 | Step 1507 | loss: 0.4827811343957914 | accuracy: 0.7647860738255031 \n",
      "Epoch 4 | Step 1508 | loss: 0.48280232526785555 | accuracy: 0.7646843645484948 \n",
      "Epoch 4 | Step 1509 | loss: 0.4828449781735738 | accuracy: 0.7646874999999999 \n",
      "Epoch 4 | Step 1510 | loss: 0.482652794087052 | accuracy: 0.76484634551495 \n",
      "Epoch 4 | Step 1511 | loss: 0.4828709186307642 | accuracy: 0.7645902317880793 \n",
      "Epoch 4 | Step 1512 | loss: 0.48264774837509633 | accuracy: 0.764645214521452 \n",
      "Epoch 4 | Step 1513 | loss: 0.4827545182289262 | accuracy: 0.7643914473684209 \n",
      "Epoch 4 | Step 1514 | loss: 0.4826847289429336 | accuracy: 0.7642930327868851 \n",
      "Epoch 4 | Step 1515 | loss: 0.48260895050818625 | accuracy: 0.7642973856209149 \n",
      "Epoch 4 | Step 1516 | loss: 0.4826363616346925 | accuracy: 0.7644543973941367 \n",
      "Epoch 4 | Step 1517 | loss: 0.4823296753230033 | accuracy: 0.7646611201298701 \n",
      "Epoch 4 | Step 1518 | loss: 0.48207359020764 | accuracy: 0.7647653721682848 \n",
      "Epoch 4 | Step 1519 | loss: 0.4821572765227287 | accuracy: 0.7645665322580645 \n",
      "Epoch 4 | Step 1520 | loss: 0.4821831380822651 | accuracy: 0.7645699356913184 \n",
      "Epoch 4 | Step 1521 | loss: 0.48222864056244874 | accuracy: 0.7645733173076923 \n",
      "Epoch 4 | Step 1522 | loss: 0.4821107871235369 | accuracy: 0.764576677316294 \n",
      "Epoch 4 | Step 1523 | loss: 0.4824105763131646 | accuracy: 0.7644307324840764 \n",
      "Epoch 4 | Step 1524 | loss: 0.48288660484646995 | accuracy: 0.7641369047619048 \n",
      "Epoch 4 | Step 1525 | loss: 0.48289844780405866 | accuracy: 0.7641416139240507 \n",
      "Epoch 4 | Step 1526 | loss: 0.48232731326521383 | accuracy: 0.764589905362776 \n",
      "Epoch 4 | Step 1527 | loss: 0.4826252930944071 | accuracy: 0.7643474842767296 \n",
      "Epoch 4 | Step 1528 | loss: 0.4825005868572426 | accuracy: 0.7644494514106583 \n",
      "Epoch 4 | Step 1529 | loss: 0.4823021532036364 | accuracy: 0.76455078125 \n",
      "Epoch 4 | Step 1530 | loss: 0.482159567863399 | accuracy: 0.7646514797507789 \n",
      "Epoch 4 | Step 1531 | loss: 0.4824848883085369 | accuracy: 0.7643148291925466 \n",
      "Epoch 4 | Step 1532 | loss: 0.4824379474939577 | accuracy: 0.7643188854489165 \n",
      "Epoch 4 | Step 1533 | loss: 0.48217792882595534 | accuracy: 0.7644193672839507 \n",
      "Epoch 4 | Step 1534 | loss: 0.4823655731861408 | accuracy: 0.7644711538461538 \n",
      "Epoch 4 | Step 1535 | loss: 0.48214452535462526 | accuracy: 0.7644746932515337 \n",
      "Epoch 4 | Step 1536 | loss: 0.48229292053330564 | accuracy: 0.7643826452599388 \n",
      "Epoch 4 | Step 1537 | loss: 0.4826185905897036 | accuracy: 0.7641958841463414 \n",
      "Epoch 4 | Step 1538 | loss: 0.48272158536142856 | accuracy: 0.7642002279635258 \n",
      "Epoch 4 | Step 1539 | loss: 0.48272956185268634 | accuracy: 0.7642045454545454 \n",
      "Epoch 4 | Step 1540 | loss: 0.482834954366223 | accuracy: 0.7639728096676737 \n",
      "Epoch 4 | Step 1541 | loss: 0.48283022597252606 | accuracy: 0.7639777861445782 \n",
      "Epoch 4 | Step 1542 | loss: 0.48292448042749286 | accuracy: 0.7637950450450449 \n",
      "Epoch 4 | Step 1543 | loss: 0.4826680395952956 | accuracy: 0.7640812125748502 \n",
      "Epoch 4 | Step 1544 | loss: 0.48259425821589 | accuracy: 0.7641791044776118 \n",
      "Epoch 4 | Step 1545 | loss: 0.48235177408371654 | accuracy: 0.7643694196428571 \n",
      "Epoch 4 | Step 1546 | loss: 0.4822852302022079 | accuracy: 0.7644195103857567 \n",
      "Epoch 4 | Step 1547 | loss: 0.4824827271100332 | accuracy: 0.7644230769230769 \n",
      "Epoch 4 | Step 1548 | loss: 0.4822168737913655 | accuracy: 0.7647031710914455 \n",
      "Epoch 4 | Step 1549 | loss: 0.4821066472460242 | accuracy: 0.76484375 \n",
      "Epoch 4 | Step 1550 | loss: 0.48222999191703686 | accuracy: 0.7646627565982405 \n",
      "Epoch 4 | Step 1551 | loss: 0.4820805373247604 | accuracy: 0.7646655701754386 \n",
      "Epoch 4 | Step 1552 | loss: 0.48207426453470836 | accuracy: 0.764759475218659 \n",
      "Epoch 4 | Step 1553 | loss: 0.48172899942065395 | accuracy: 0.7650345203488372 \n",
      "Epoch 4 | Step 1554 | loss: 0.48176031682802284 | accuracy: 0.7650815217391305 \n",
      "Epoch 4 | Step 1555 | loss: 0.48185970121725447 | accuracy: 0.7649024566473989 \n",
      "Epoch 4 | Step 1556 | loss: 0.48163076092942647 | accuracy: 0.7649945965417867 \n",
      "Epoch 4 | Step 1557 | loss: 0.48190206186524753 | accuracy: 0.7649066091954023 \n",
      "Epoch 4 | Step 1558 | loss: 0.4816363384696337 | accuracy: 0.7651325214899714 \n",
      "Epoch 4 | Step 1559 | loss: 0.4813467471940177 | accuracy: 0.7653125 \n",
      "Epoch 4 | Step 1560 | loss: 0.4812529265371143 | accuracy: 0.7654024216524217 \n",
      "Epoch 4 | Step 1561 | loss: 0.48114658714356745 | accuracy: 0.7655806107954546 \n",
      "Epoch 4 | Step 1562 | loss: 0.48108008368832533 | accuracy: 0.7657135269121813 \n",
      "Epoch 4 | Step 1563 | loss: 0.480974634572611 | accuracy: 0.7658015536723164 \n",
      "Epoch 4 | Step 1564 | loss: 0.4810460177105917 | accuracy: 0.7658890845070423 \n",
      "Epoch 4 | Step 1565 | loss: 0.48087049928608905 | accuracy: 0.7660200140449438 \n",
      "Epoch 4 | Step 1566 | loss: 0.4804298670685926 | accuracy: 0.7663690476190477 \n",
      "Epoch 4 | Step 1567 | loss: 0.4802066431531693 | accuracy: 0.7667161312849162 \n",
      "Epoch 4 | Step 1568 | loss: 0.4801649693659089 | accuracy: 0.7668436629526463 \n",
      "Epoch 4 | Step 1569 | loss: 0.4802758793036143 | accuracy: 0.7667100694444444 \n",
      "Epoch 4 | Step 1570 | loss: 0.47999767145952027 | accuracy: 0.7667936288088643 \n",
      "Epoch 4 | Step 1571 | loss: 0.479906364122807 | accuracy: 0.7669198895027625 \n",
      "Epoch 4 | Step 1572 | loss: 0.4801140544992505 | accuracy: 0.7667441460055097 \n",
      "Epoch 4 | Step 1573 | loss: 0.47983586951926516 | accuracy: 0.7668698489010989 \n",
      "Epoch 4 | Step 1574 | loss: 0.47994732072908586 | accuracy: 0.7668236301369863 \n",
      "Epoch 4 | Step 1575 | loss: 0.47977057172626747 | accuracy: 0.7669911202185792 \n",
      "Epoch 4 | Step 1576 | loss: 0.4799020075180875 | accuracy: 0.7669448228882834 \n",
      "Epoch 4 | Step 1577 | loss: 0.47987731554262014 | accuracy: 0.7670261548913043 \n",
      "Epoch 4 | Step 1578 | loss: 0.4799389450692226 | accuracy: 0.7669800135501355 \n",
      "Epoch 4 | Step 1579 | loss: 0.4803643262869603 | accuracy: 0.766722972972973 \n",
      "Epoch 4 | Step 1580 | loss: 0.4807522601355118 | accuracy: 0.7665936657681941 \n",
      "Epoch 4 | Step 1581 | loss: 0.4808193120744921 | accuracy: 0.766549059139785 \n",
      "Epoch 4 | Step 1582 | loss: 0.4808888146928424 | accuracy: 0.7666722520107239 \n",
      "Epoch 4 | Step 1583 | loss: 0.4807049771521818 | accuracy: 0.7669201203208557 \n",
      "Epoch 4 | Step 1584 | loss: 0.4803875750700633 | accuracy: 0.7671666666666667 \n",
      "Epoch 4 | Step 1585 | loss: 0.4801140585319793 | accuracy: 0.7672872340425532 \n",
      "Epoch 4 | Step 1586 | loss: 0.47982115280723064 | accuracy: 0.7674071618037135 \n",
      "Epoch 4 | Step 1587 | loss: 0.479974593435015 | accuracy: 0.7671130952380952 \n",
      "Epoch 4 | Step 1588 | loss: 0.4799003953354969 | accuracy: 0.7671916226912929 \n",
      "Epoch 4 | Step 1589 | loss: 0.4796748879708742 | accuracy: 0.7672697368421053 \n",
      "Epoch 4 | Step 1590 | loss: 0.47961968566801916 | accuracy: 0.7673884514435696 \n",
      "Epoch 4 | Step 1591 | loss: 0.47929155740750395 | accuracy: 0.7676701570680629 \n",
      "Epoch 4 | Step 1592 | loss: 0.47930608172329536 | accuracy: 0.7676240208877284 \n",
      "Epoch 4 | Step 1593 | loss: 0.4795426103907327 | accuracy: 0.7674560546875 \n",
      "Epoch 4 | Step 1594 | loss: 0.479507093228303 | accuracy: 0.7676542207792207 \n",
      "Epoch 4 | Step 1595 | loss: 0.4797513294250854 | accuracy: 0.7675680051813472 \n",
      "Epoch 4 | Step 1596 | loss: 0.47991121500653505 | accuracy: 0.7674822351421189 \n",
      "Epoch 4 | Step 1597 | loss: 0.47996956225215776 | accuracy: 0.7675177190721649 \n",
      "Epoch 4 | Step 1598 | loss: 0.48016814025631294 | accuracy: 0.7673120179948586 \n",
      "Epoch 4 | Step 1599 | loss: 0.480107747285794 | accuracy: 0.7673076923076924 \n",
      "Epoch 4 | Step 1600 | loss: 0.4800878389717063 | accuracy: 0.7672234654731458 \n",
      "Epoch 4 | Step 1601 | loss: 0.4801148979791573 | accuracy: 0.767219387755102 \n",
      "Epoch 4 | Step 1602 | loss: 0.4799586429092417 | accuracy: 0.7673743638676844 \n",
      "Epoch 4 | Step 1603 | loss: 0.4800131833038959 | accuracy: 0.7673302664974619 \n",
      "Epoch 4 | Step 1604 | loss: 0.4800528950329068 | accuracy: 0.767246835443038 \n",
      "Epoch 4 | Step 1605 | loss: 0.4798067355095738 | accuracy: 0.7674400252525253 \n",
      "Epoch 4 | Step 1606 | loss: 0.47964513166725486 | accuracy: 0.7675141687657431 \n",
      "Epoch 4 | Step 1607 | loss: 0.4798215647139142 | accuracy: 0.7673523869346733 \n",
      "Epoch 4 | Step 1608 | loss: 0.4798357940108555 | accuracy: 0.7673480576441103 \n",
      "Epoch 4 | Step 1609 | loss: 0.4800060290843248 | accuracy: 0.7672265625 \n",
      "Epoch 4 | Step 1610 | loss: 0.48003560824881764 | accuracy: 0.7673004987531172 \n",
      "Epoch 4 | Step 1611 | loss: 0.4804252429091515 | accuracy: 0.7671019900497512 \n",
      "Epoch 4 | Step 1612 | loss: 0.48036491427173095 | accuracy: 0.7672520750213794 \n",
      "Validation | Epoch 4 | Step 1612 | accuracy: 0.785048171877861 \n",
      "Epoch 5 | Step 1613 | loss: 0.45491620898246765 | accuracy: 0.796875 \n",
      "Epoch 5 | Step 1614 | loss: 0.4906798154115677 | accuracy: 0.7421875 \n",
      "Epoch 5 | Step 1615 | loss: 0.4721218943595886 | accuracy: 0.7604166666666666 \n",
      "Epoch 5 | Step 1616 | loss: 0.46744850277900696 | accuracy: 0.78125 \n",
      "Epoch 5 | Step 1617 | loss: 0.4618838787078857 | accuracy: 0.790625 \n",
      "Epoch 5 | Step 1618 | loss: 0.46772212783495587 | accuracy: 0.7890625 \n",
      "Epoch 5 | Step 1619 | loss: 0.4702647626399994 | accuracy: 0.7834821428571429 \n",
      "Epoch 5 | Step 1620 | loss: 0.47161443531513214 | accuracy: 0.783203125 \n",
      "Epoch 5 | Step 1621 | loss: 0.4651601513226827 | accuracy: 0.7847222222222222 \n",
      "Epoch 5 | Step 1622 | loss: 0.46636387407779695 | accuracy: 0.7859375 \n",
      "Epoch 5 | Step 1623 | loss: 0.46267628398808563 | accuracy: 0.7897727272727273 \n",
      "Epoch 5 | Step 1624 | loss: 0.4644361436367035 | accuracy: 0.7864583333333334 \n",
      "Epoch 5 | Step 1625 | loss: 0.4598590066799751 | accuracy: 0.78125 \n",
      "Epoch 5 | Step 1626 | loss: 0.45621864923409056 | accuracy: 0.7834821428571429 \n",
      "Epoch 5 | Step 1627 | loss: 0.449581374724706 | accuracy: 0.7875 \n",
      "Epoch 5 | Step 1628 | loss: 0.4415625333786011 | accuracy: 0.7958984375 \n",
      "Epoch 5 | Step 1629 | loss: 0.4376298644963433 | accuracy: 0.8005514705882353 \n",
      "Epoch 5 | Step 1630 | loss: 0.437699384159512 | accuracy: 0.7994791666666666 \n",
      "Epoch 5 | Step 1631 | loss: 0.4397734654577155 | accuracy: 0.7993421052631579 \n",
      "Epoch 5 | Step 1632 | loss: 0.4377597287297249 | accuracy: 0.7984375 \n",
      "Epoch 5 | Step 1633 | loss: 0.4351283184119633 | accuracy: 0.7991071428571429 \n",
      "Epoch 5 | Step 1634 | loss: 0.4312354014678435 | accuracy: 0.8018465909090909 \n",
      "Epoch 5 | Step 1635 | loss: 0.4293891476548236 | accuracy: 0.8029891304347826 \n",
      "Epoch 5 | Step 1636 | loss: 0.4272366240620613 | accuracy: 0.8046875 \n",
      "Epoch 5 | Step 1637 | loss: 0.4265518867969513 | accuracy: 0.804375 \n",
      "Epoch 5 | Step 1638 | loss: 0.42625959790669954 | accuracy: 0.8040865384615384 \n",
      "Epoch 5 | Step 1639 | loss: 0.4299122382093359 | accuracy: 0.8015046296296297 \n",
      "Epoch 5 | Step 1640 | loss: 0.4276632240840367 | accuracy: 0.8024553571428571 \n",
      "Epoch 5 | Step 1641 | loss: 0.4278957648523923 | accuracy: 0.8038793103448276 \n",
      "Epoch 5 | Step 1642 | loss: 0.4292728155851364 | accuracy: 0.803125 \n",
      "Epoch 5 | Step 1643 | loss: 0.43040519568227953 | accuracy: 0.8029233870967742 \n",
      "Epoch 5 | Step 1644 | loss: 0.4322986267507076 | accuracy: 0.8017578125 \n",
      "Epoch 5 | Step 1645 | loss: 0.43541785623088025 | accuracy: 0.7992424242424242 \n",
      "Epoch 5 | Step 1646 | loss: 0.43479224250597115 | accuracy: 0.8005514705882353 \n",
      "Epoch 5 | Step 1647 | loss: 0.4338280839579446 | accuracy: 0.8 \n",
      "Epoch 5 | Step 1648 | loss: 0.43412013600269955 | accuracy: 0.7994791666666666 \n",
      "Epoch 5 | Step 1649 | loss: 0.434859620558249 | accuracy: 0.7989864864864865 \n",
      "Epoch 5 | Step 1650 | loss: 0.43399613154561895 | accuracy: 0.7997532894736842 \n",
      "Epoch 5 | Step 1651 | loss: 0.43589592132812893 | accuracy: 0.7972756410256411 \n",
      "Epoch 5 | Step 1652 | loss: 0.43653265908360483 | accuracy: 0.7968750000000001 \n",
      "Epoch 5 | Step 1653 | loss: 0.4354519051749532 | accuracy: 0.7976371951219512 \n",
      "Epoch 5 | Step 1654 | loss: 0.43657438598928 | accuracy: 0.7983630952380952 \n",
      "Epoch 5 | Step 1655 | loss: 0.43649540391079217 | accuracy: 0.7990552325581395 \n",
      "Epoch 5 | Step 1656 | loss: 0.43651262061162427 | accuracy: 0.7986505681818182 \n",
      "Epoch 5 | Step 1657 | loss: 0.43948592609829373 | accuracy: 0.7972222222222223 \n",
      "Epoch 5 | Step 1658 | loss: 0.44304280566132587 | accuracy: 0.7948369565217391 \n",
      "Epoch 5 | Step 1659 | loss: 0.44208191810770237 | accuracy: 0.7955452127659575 \n",
      "Epoch 5 | Step 1660 | loss: 0.4441288361946742 | accuracy: 0.7942708333333334 \n",
      "Epoch 5 | Step 1661 | loss: 0.44290690093624346 | accuracy: 0.7949617346938775 \n",
      "Epoch 5 | Step 1662 | loss: 0.44406945288181304 | accuracy: 0.7946875 \n",
      "Epoch 5 | Step 1663 | loss: 0.4452747591570312 | accuracy: 0.7931985294117647 \n",
      "Epoch 5 | Step 1664 | loss: 0.446688769528499 | accuracy: 0.7917668269230769 \n",
      "Epoch 5 | Step 1665 | loss: 0.44611737244534044 | accuracy: 0.7915683962264151 \n",
      "Epoch 5 | Step 1666 | loss: 0.4457058983820456 | accuracy: 0.7907986111111112 \n",
      "Epoch 5 | Step 1667 | loss: 0.4451105637983842 | accuracy: 0.790340909090909 \n",
      "Epoch 5 | Step 1668 | loss: 0.44615435174533297 | accuracy: 0.7904575892857143 \n",
      "Epoch 5 | Step 1669 | loss: 0.4461013094375008 | accuracy: 0.7911184210526315 \n",
      "Epoch 5 | Step 1670 | loss: 0.44657536518984825 | accuracy: 0.7906788793103449 \n",
      "Epoch 5 | Step 1671 | loss: 0.44727596135462744 | accuracy: 0.7905190677966102 \n",
      "Epoch 5 | Step 1672 | loss: 0.44728758533795676 | accuracy: 0.7908854166666667 \n",
      "Epoch 5 | Step 1673 | loss: 0.44715891314334555 | accuracy: 0.7904713114754098 \n",
      "Epoch 5 | Step 1674 | loss: 0.44715249201943796 | accuracy: 0.790070564516129 \n",
      "Epoch 5 | Step 1675 | loss: 0.4474057720767127 | accuracy: 0.7899305555555556 \n",
      "Epoch 5 | Step 1676 | loss: 0.44582124007865787 | accuracy: 0.79052734375 \n",
      "Epoch 5 | Step 1677 | loss: 0.4449390571850997 | accuracy: 0.7908653846153846 \n",
      "Epoch 5 | Step 1678 | loss: 0.44325228848240594 | accuracy: 0.7919034090909091 \n",
      "Epoch 5 | Step 1679 | loss: 0.44327024114665703 | accuracy: 0.7919776119402985 \n",
      "Epoch 5 | Step 1680 | loss: 0.44287533532170686 | accuracy: 0.7922794117647058 \n",
      "Epoch 5 | Step 1681 | loss: 0.44416767877081165 | accuracy: 0.7916666666666666 \n",
      "Epoch 5 | Step 1682 | loss: 0.44623096414974756 | accuracy: 0.7901785714285714 \n",
      "Epoch 5 | Step 1683 | loss: 0.44562274553406406 | accuracy: 0.7911531690140845 \n",
      "Epoch 5 | Step 1684 | loss: 0.4452892877161503 | accuracy: 0.7918836805555556 \n",
      "Epoch 5 | Step 1685 | loss: 0.44516608608912117 | accuracy: 0.7917380136986302 \n",
      "Epoch 5 | Step 1686 | loss: 0.4452778169432202 | accuracy: 0.7913851351351351 \n",
      "Epoch 5 | Step 1687 | loss: 0.4459335335095723 | accuracy: 0.79125 \n",
      "Epoch 5 | Step 1688 | loss: 0.44544001237342234 | accuracy: 0.7913240131578947 \n",
      "Epoch 5 | Step 1689 | loss: 0.4450629543174397 | accuracy: 0.791801948051948 \n",
      "Epoch 5 | Step 1690 | loss: 0.44617993900409114 | accuracy: 0.7912660256410257 \n",
      "Epoch 5 | Step 1691 | loss: 0.4459444284439087 | accuracy: 0.7915348101265823 \n",
      "Epoch 5 | Step 1692 | loss: 0.4457062005996704 | accuracy: 0.7914062500000001 \n",
      "Epoch 5 | Step 1693 | loss: 0.4455445140232275 | accuracy: 0.7918595679012346 \n",
      "Epoch 5 | Step 1694 | loss: 0.4444859238659463 | accuracy: 0.7923018292682927 \n",
      "Epoch 5 | Step 1695 | loss: 0.44345920667590866 | accuracy: 0.7931099397590361 \n",
      "Epoch 5 | Step 1696 | loss: 0.44330805504605886 | accuracy: 0.7925967261904762 \n",
      "Epoch 5 | Step 1697 | loss: 0.44442659932024337 | accuracy: 0.7922794117647058 \n",
      "Epoch 5 | Step 1698 | loss: 0.4435005243434462 | accuracy: 0.7930595930232558 \n",
      "Epoch 5 | Step 1699 | loss: 0.443328026039847 | accuracy: 0.7931034482758621 \n",
      "Epoch 5 | Step 1700 | loss: 0.4438920739022168 | accuracy: 0.7931463068181818 \n",
      "Epoch 5 | Step 1701 | loss: 0.4437891613231616 | accuracy: 0.7933637640449438 \n",
      "Epoch 5 | Step 1702 | loss: 0.44437779254383514 | accuracy: 0.7925347222222222 \n",
      "Epoch 5 | Step 1703 | loss: 0.44342974516061634 | accuracy: 0.7930975274725275 \n",
      "Epoch 5 | Step 1704 | loss: 0.44608203030150867 | accuracy: 0.7917798913043478 \n",
      "Epoch 5 | Step 1705 | loss: 0.44527009417933805 | accuracy: 0.7925067204301075 \n",
      "Epoch 5 | Step 1706 | loss: 0.44455175355393833 | accuracy: 0.7933843085106383 \n",
      "Epoch 5 | Step 1707 | loss: 0.443782953839553 | accuracy: 0.79375 \n",
      "Epoch 5 | Step 1708 | loss: 0.4433239980911215 | accuracy: 0.7942708333333334 \n",
      "Epoch 5 | Step 1709 | loss: 0.44295822314380373 | accuracy: 0.7942976804123711 \n",
      "Epoch 5 | Step 1710 | loss: 0.4442709200844473 | accuracy: 0.7933673469387755 \n",
      "Epoch 5 | Step 1711 | loss: 0.443484783473641 | accuracy: 0.7935606060606061 \n",
      "Epoch 5 | Step 1712 | loss: 0.4431547975540161 | accuracy: 0.79390625 \n",
      "Epoch 5 | Step 1713 | loss: 0.44272037101264045 | accuracy: 0.7939356435643564 \n",
      "Epoch 5 | Step 1714 | loss: 0.44348406820904973 | accuracy: 0.7931985294117647 \n",
      "Epoch 5 | Step 1715 | loss: 0.44341517362779787 | accuracy: 0.7927791262135923 \n",
      "Epoch 5 | Step 1716 | loss: 0.4433691536004727 | accuracy: 0.7934194711538461 \n",
      "Epoch 5 | Step 1717 | loss: 0.44384943161691937 | accuracy: 0.7934523809523809 \n",
      "Epoch 5 | Step 1718 | loss: 0.4426753897711916 | accuracy: 0.7936320754716981 \n",
      "Epoch 5 | Step 1719 | loss: 0.4434006047026019 | accuracy: 0.7930782710280374 \n",
      "Epoch 5 | Step 1720 | loss: 0.44388112315425166 | accuracy: 0.7931134259259259 \n",
      "Epoch 5 | Step 1721 | loss: 0.4435929418157 | accuracy: 0.7927178899082569 \n",
      "Epoch 5 | Step 1722 | loss: 0.4430537901141427 | accuracy: 0.7931818181818182 \n",
      "Epoch 5 | Step 1723 | loss: 0.4449242965595142 | accuracy: 0.7925112612612613 \n",
      "Epoch 5 | Step 1724 | loss: 0.4455791546830109 | accuracy: 0.7918526785714286 \n",
      "Epoch 5 | Step 1725 | loss: 0.4456724611531317 | accuracy: 0.7914823008849557 \n",
      "Epoch 5 | Step 1726 | loss: 0.4458553921758083 | accuracy: 0.7912554824561403 \n",
      "Epoch 5 | Step 1727 | loss: 0.44508822223414546 | accuracy: 0.7919836956521739 \n",
      "Epoch 5 | Step 1728 | loss: 0.4450693603219657 | accuracy: 0.7922952586206896 \n",
      "Epoch 5 | Step 1729 | loss: 0.44445744386086095 | accuracy: 0.7923344017094017 \n",
      "Epoch 5 | Step 1730 | loss: 0.4445402612120418 | accuracy: 0.7926377118644068 \n",
      "Epoch 5 | Step 1731 | loss: 0.44517725355484905 | accuracy: 0.7921481092436975 \n",
      "Epoch 5 | Step 1732 | loss: 0.4447899570067724 | accuracy: 0.7919270833333333 \n",
      "Epoch 5 | Step 1733 | loss: 0.44410081934337775 | accuracy: 0.7923553719008265 \n",
      "Epoch 5 | Step 1734 | loss: 0.44392037049668737 | accuracy: 0.7923924180327869 \n",
      "Epoch 5 | Step 1735 | loss: 0.4436913416153047 | accuracy: 0.7924288617886179 \n",
      "Epoch 5 | Step 1736 | loss: 0.4440221159208205 | accuracy: 0.7924647177419355 \n",
      "Epoch 5 | Step 1737 | loss: 0.4437156093120575 | accuracy: 0.79275 \n",
      "Epoch 5 | Step 1738 | loss: 0.44374801951741416 | accuracy: 0.7924107142857143 \n",
      "Epoch 5 | Step 1739 | loss: 0.4446591228012025 | accuracy: 0.7919537401574803 \n",
      "Epoch 5 | Step 1740 | loss: 0.44471968594007194 | accuracy: 0.7921142578125 \n",
      "Epoch 5 | Step 1741 | loss: 0.44469562704248944 | accuracy: 0.7921511627906976 \n",
      "Epoch 5 | Step 1742 | loss: 0.4447946800635411 | accuracy: 0.7919471153846154 \n",
      "Epoch 5 | Step 1743 | loss: 0.4452574080183306 | accuracy: 0.7915076335877863 \n",
      "Epoch 5 | Step 1744 | loss: 0.445752123540098 | accuracy: 0.7911931818181818 \n",
      "Epoch 5 | Step 1745 | loss: 0.4451794994056673 | accuracy: 0.7915883458646616 \n",
      "Epoch 5 | Step 1746 | loss: 0.4452037462102833 | accuracy: 0.7916277985074627 \n",
      "Epoch 5 | Step 1747 | loss: 0.44540205266740585 | accuracy: 0.7915509259259259 \n",
      "Epoch 5 | Step 1748 | loss: 0.44503067740622687 | accuracy: 0.7918198529411765 \n",
      "Epoch 5 | Step 1749 | loss: 0.44506803655276334 | accuracy: 0.7918567518248175 \n",
      "Epoch 5 | Step 1750 | loss: 0.4452644873788391 | accuracy: 0.7914402173913043 \n",
      "Epoch 5 | Step 1751 | loss: 0.445095681029258 | accuracy: 0.7914793165467626 \n",
      "Epoch 5 | Step 1752 | loss: 0.4445187374949455 | accuracy: 0.7919642857142857 \n",
      "Epoch 5 | Step 1753 | loss: 0.4441027596909949 | accuracy: 0.792220744680851 \n",
      "Epoch 5 | Step 1754 | loss: 0.44403305544819627 | accuracy: 0.7922535211267606 \n",
      "Epoch 5 | Step 1755 | loss: 0.4440792569747337 | accuracy: 0.7921765734265735 \n",
      "Epoch 5 | Step 1756 | loss: 0.4431732303152481 | accuracy: 0.7926432291666667 \n",
      "Epoch 5 | Step 1757 | loss: 0.4432098374284546 | accuracy: 0.7927801724137932 \n",
      "Epoch 5 | Step 1758 | loss: 0.4441876372654143 | accuracy: 0.7921660958904111 \n",
      "Epoch 5 | Step 1759 | loss: 0.4438081481018844 | accuracy: 0.7924107142857144 \n",
      "Epoch 5 | Step 1760 | loss: 0.44344984921249175 | accuracy: 0.7927576013513514 \n",
      "Epoch 5 | Step 1761 | loss: 0.4429640513938544 | accuracy: 0.7933095637583893 \n",
      "Epoch 5 | Step 1762 | loss: 0.44311736245950056 | accuracy: 0.7929166666666667 \n",
      "Epoch 5 | Step 1763 | loss: 0.4429416474917076 | accuracy: 0.792942880794702 \n",
      "Epoch 5 | Step 1764 | loss: 0.44362307143838775 | accuracy: 0.7921463815789473 \n",
      "Epoch 5 | Step 1765 | loss: 0.4436974264437855 | accuracy: 0.7921772875816994 \n",
      "Epoch 5 | Step 1766 | loss: 0.44343133831953063 | accuracy: 0.7923092532467533 \n",
      "Epoch 5 | Step 1767 | loss: 0.44299732965807753 | accuracy: 0.792641129032258 \n",
      "Epoch 5 | Step 1768 | loss: 0.4425600098493771 | accuracy: 0.79296875 \n",
      "Epoch 5 | Step 1769 | loss: 0.4418879711324241 | accuracy: 0.7936902866242038 \n",
      "Epoch 5 | Step 1770 | loss: 0.441636872631085 | accuracy: 0.793809335443038 \n",
      "Epoch 5 | Step 1771 | loss: 0.44121158797785914 | accuracy: 0.7942216981132075 \n",
      "Epoch 5 | Step 1772 | loss: 0.4416035741567611 | accuracy: 0.79384765625 \n",
      "Epoch 5 | Step 1773 | loss: 0.4413813841268882 | accuracy: 0.7938664596273292 \n",
      "Epoch 5 | Step 1774 | loss: 0.4417734388951901 | accuracy: 0.7936921296296297 \n",
      "Epoch 5 | Step 1775 | loss: 0.44156275205085604 | accuracy: 0.7935199386503068 \n",
      "Epoch 5 | Step 1776 | loss: 0.44116083350850305 | accuracy: 0.7937309451219512 \n",
      "Epoch 5 | Step 1777 | loss: 0.4408612236832127 | accuracy: 0.793844696969697 \n",
      "Epoch 5 | Step 1778 | loss: 0.4416411953518189 | accuracy: 0.7935805722891566 \n",
      "Epoch 5 | Step 1779 | loss: 0.4412500665573302 | accuracy: 0.7941616766467066 \n",
      "Epoch 5 | Step 1780 | loss: 0.44105452352336466 | accuracy: 0.7945498511904762 \n",
      "Epoch 5 | Step 1781 | loss: 0.4417882270714234 | accuracy: 0.7941937869822485 \n",
      "Epoch 5 | Step 1782 | loss: 0.4409981136812882 | accuracy: 0.7948529411764705 \n",
      "Epoch 5 | Step 1783 | loss: 0.4413037477878101 | accuracy: 0.7944078947368421 \n",
      "Epoch 5 | Step 1784 | loss: 0.44191719383694394 | accuracy: 0.7936954941860465 \n",
      "Epoch 5 | Step 1785 | loss: 0.4409075443110713 | accuracy: 0.7945267341040463 \n",
      "Epoch 5 | Step 1786 | loss: 0.4413631131936763 | accuracy: 0.7943606321839081 \n",
      "Epoch 5 | Step 1787 | loss: 0.44071419920240124 | accuracy: 0.7948214285714286 \n",
      "Epoch 5 | Step 1788 | loss: 0.44067249176177103 | accuracy: 0.7947443181818182 \n",
      "Epoch 5 | Step 1789 | loss: 0.4407403502760633 | accuracy: 0.7949329096045198 \n",
      "Epoch 5 | Step 1790 | loss: 0.4406963528207178 | accuracy: 0.7952071629213483 \n",
      "Epoch 5 | Step 1791 | loss: 0.44132214501583367 | accuracy: 0.7947800279329609 \n",
      "Epoch 5 | Step 1792 | loss: 0.44160023397869524 | accuracy: 0.7946180555555555 \n",
      "Epoch 5 | Step 1793 | loss: 0.44174271113964725 | accuracy: 0.7947168508287292 \n",
      "Epoch 5 | Step 1794 | loss: 0.4413344886276747 | accuracy: 0.7952438186813187 \n",
      "Epoch 5 | Step 1795 | loss: 0.4411667077267755 | accuracy: 0.7952527322404371 \n",
      "Epoch 5 | Step 1796 | loss: 0.44116129321248626 | accuracy: 0.7953464673913043 \n",
      "Epoch 5 | Step 1797 | loss: 0.44092196709400894 | accuracy: 0.7955236486486487 \n",
      "Epoch 5 | Step 1798 | loss: 0.4408649488161968 | accuracy: 0.7955309139784946 \n",
      "Epoch 5 | Step 1799 | loss: 0.4409520479447063 | accuracy: 0.7953709893048129 \n",
      "Epoch 5 | Step 1800 | loss: 0.44075222551188564 | accuracy: 0.7955452127659575 \n",
      "Epoch 5 | Step 1801 | loss: 0.4405583452295373 | accuracy: 0.7956349206349206 \n",
      "Epoch 5 | Step 1802 | loss: 0.44003905214761424 | accuracy: 0.7958881578947369 \n",
      "Epoch 5 | Step 1803 | loss: 0.4401570254283425 | accuracy: 0.7954024869109948 \n",
      "Epoch 5 | Step 1804 | loss: 0.44021149647111685 | accuracy: 0.79541015625 \n",
      "Epoch 5 | Step 1805 | loss: 0.4402988546870532 | accuracy: 0.795255829015544 \n",
      "Epoch 5 | Step 1806 | loss: 0.4402349664992892 | accuracy: 0.795264175257732 \n",
      "Epoch 5 | Step 1807 | loss: 0.4403251681572351 | accuracy: 0.795352564102564 \n",
      "Epoch 5 | Step 1808 | loss: 0.4400005337535118 | accuracy: 0.7954400510204082 \n",
      "Epoch 5 | Step 1809 | loss: 0.4397478448557974 | accuracy: 0.7955266497461929 \n",
      "Epoch 5 | Step 1810 | loss: 0.4394306898719132 | accuracy: 0.7956123737373737 \n",
      "Epoch 5 | Step 1811 | loss: 0.4395540265282194 | accuracy: 0.7953831658291457 \n",
      "Epoch 5 | Step 1812 | loss: 0.4396501992642879 | accuracy: 0.7953125 \n",
      "Epoch 5 | Step 1813 | loss: 0.43943708675417725 | accuracy: 0.7953202736318408 \n",
      "Epoch 5 | Step 1814 | loss: 0.4394670432747 | accuracy: 0.7952506188118812 \n",
      "Epoch 5 | Step 1815 | loss: 0.439387286825133 | accuracy: 0.7951816502463054 \n",
      "Epoch 5 | Step 1816 | loss: 0.4395658771197 | accuracy: 0.7950367647058824 \n",
      "Epoch 5 | Step 1817 | loss: 0.43934233653836124 | accuracy: 0.7953506097560976 \n",
      "Epoch 5 | Step 1818 | loss: 0.43939796610943316 | accuracy: 0.7952063106796117 \n",
      "Epoch 5 | Step 1819 | loss: 0.4395455689245951 | accuracy: 0.7950634057971014 \n",
      "Epoch 5 | Step 1820 | loss: 0.43910704323878647 | accuracy: 0.7954477163461539 \n",
      "Epoch 5 | Step 1821 | loss: 0.4391055040097122 | accuracy: 0.7955293062200957 \n",
      "Epoch 5 | Step 1822 | loss: 0.43883530355635136 | accuracy: 0.7956845238095238 \n",
      "Epoch 5 | Step 1823 | loss: 0.4388441680731931 | accuracy: 0.7956161137440758 \n",
      "Epoch 5 | Step 1824 | loss: 0.43890451302505884 | accuracy: 0.7956220518867925 \n",
      "Epoch 5 | Step 1825 | loss: 0.4388695079396028 | accuracy: 0.7955545774647887 \n",
      "Epoch 5 | Step 1826 | loss: 0.4388627297131814 | accuracy: 0.7957797897196262 \n",
      "Epoch 5 | Step 1827 | loss: 0.4389610060425691 | accuracy: 0.7954941860465117 \n",
      "Epoch 5 | Step 1828 | loss: 0.4388437918214886 | accuracy: 0.7955005787037037 \n",
      "Epoch 5 | Step 1829 | loss: 0.43916771914552427 | accuracy: 0.7953629032258065 \n",
      "Epoch 5 | Step 1830 | loss: 0.43955222086622076 | accuracy: 0.794868119266055 \n",
      "Epoch 5 | Step 1831 | loss: 0.4396837380923092 | accuracy: 0.7948772831050228 \n",
      "Epoch 5 | Step 1832 | loss: 0.43968194777315306 | accuracy: 0.7947443181818182 \n",
      "Epoch 5 | Step 1833 | loss: 0.43948670318223765 | accuracy: 0.7947539592760181 \n",
      "Epoch 5 | Step 1834 | loss: 0.43987999091277247 | accuracy: 0.7944115990990991 \n",
      "Epoch 5 | Step 1835 | loss: 0.4394917228831303 | accuracy: 0.7946328475336323 \n",
      "Epoch 5 | Step 1836 | loss: 0.43957288337073147 | accuracy: 0.7946428571428571 \n",
      "Epoch 5 | Step 1837 | loss: 0.43961945374806716 | accuracy: 0.7945138888888889 \n",
      "Epoch 5 | Step 1838 | loss: 0.43957136716462863 | accuracy: 0.7944551991150443 \n",
      "Epoch 5 | Step 1839 | loss: 0.43960801502156355 | accuracy: 0.7946723568281938 \n",
      "Epoch 5 | Step 1840 | loss: 0.4393558585852907 | accuracy: 0.7948876096491229 \n",
      "Epoch 5 | Step 1841 | loss: 0.43894090832060595 | accuracy: 0.7952374454148472 \n",
      "Epoch 5 | Step 1842 | loss: 0.43885193207989565 | accuracy: 0.7953125 \n",
      "Epoch 5 | Step 1843 | loss: 0.43835991801637586 | accuracy: 0.7957251082251082 \n",
      "Epoch 5 | Step 1844 | loss: 0.43841079198594746 | accuracy: 0.7956627155172413 \n",
      "Epoch 5 | Step 1845 | loss: 0.43836544396539606 | accuracy: 0.7957349785407726 \n",
      "Epoch 5 | Step 1846 | loss: 0.43883314741472906 | accuracy: 0.7952724358974359 \n",
      "Epoch 5 | Step 1847 | loss: 0.43864021656361024 | accuracy: 0.7952792553191489 \n",
      "Epoch 5 | Step 1848 | loss: 0.438403285029581 | accuracy: 0.7954846398305084 \n",
      "Epoch 5 | Step 1849 | loss: 0.43826284514197816 | accuracy: 0.7955564345991561 \n",
      "Epoch 5 | Step 1850 | loss: 0.4388253879146415 | accuracy: 0.7954963235294118 \n",
      "Epoch 5 | Step 1851 | loss: 0.43900992955124024 | accuracy: 0.7955674686192469 \n",
      "Epoch 5 | Step 1852 | loss: 0.4390137669940789 | accuracy: 0.7955078125 \n",
      "Epoch 5 | Step 1853 | loss: 0.4394771439405892 | accuracy: 0.7953838174273858 \n",
      "Epoch 5 | Step 1854 | loss: 0.43979160524596844 | accuracy: 0.7955191115702479 \n",
      "Epoch 5 | Step 1855 | loss: 0.43959226284498043 | accuracy: 0.7957175925925926 \n",
      "Epoch 5 | Step 1856 | loss: 0.43931622314648544 | accuracy: 0.7960425204918032 \n",
      "Epoch 5 | Step 1857 | loss: 0.43901681632411715 | accuracy: 0.7963647959183674 \n",
      "Epoch 5 | Step 1858 | loss: 0.4389390079228858 | accuracy: 0.7963033536585366 \n",
      "Epoch 5 | Step 1859 | loss: 0.4387272613251257 | accuracy: 0.7964321862348178 \n",
      "Epoch 5 | Step 1860 | loss: 0.4388531328689667 | accuracy: 0.7961819556451613 \n",
      "Epoch 5 | Step 1861 | loss: 0.43928578531885715 | accuracy: 0.7958082329317269 \n",
      "Epoch 5 | Step 1862 | loss: 0.4390924599170684 | accuracy: 0.7959375 \n",
      "Epoch 5 | Step 1863 | loss: 0.4394178288391386 | accuracy: 0.795816733067729 \n",
      "Epoch 5 | Step 1864 | loss: 0.4400877261918688 | accuracy: 0.7954489087301587 \n",
      "Epoch 5 | Step 1865 | loss: 0.4399156385495257 | accuracy: 0.7955780632411067 \n",
      "Epoch 5 | Step 1866 | loss: 0.43979442682791875 | accuracy: 0.7958907480314961 \n",
      "Epoch 5 | Step 1867 | loss: 0.4396264539045445 | accuracy: 0.7960171568627451 \n",
      "Epoch 5 | Step 1868 | loss: 0.4394600925734266 | accuracy: 0.79608154296875 \n",
      "Epoch 5 | Step 1869 | loss: 0.4398696692769165 | accuracy: 0.7959022373540856 \n",
      "Epoch 5 | Step 1870 | loss: 0.4396732806466346 | accuracy: 0.7962088178294574 \n",
      "Epoch 5 | Step 1871 | loss: 0.4398655789008932 | accuracy: 0.7960907335907336 \n",
      "Epoch 5 | Step 1872 | loss: 0.4400576340464445 | accuracy: 0.795733173076923 \n",
      "Epoch 5 | Step 1873 | loss: 0.4403411785989885 | accuracy: 0.795617816091954 \n",
      "Epoch 5 | Step 1874 | loss: 0.4408266911752351 | accuracy: 0.7952051526717557 \n",
      "Epoch 5 | Step 1875 | loss: 0.44099502815039887 | accuracy: 0.7952115019011406 \n",
      "Epoch 5 | Step 1876 | loss: 0.44083488597111264 | accuracy: 0.7953361742424242 \n",
      "Epoch 5 | Step 1877 | loss: 0.4408445560707236 | accuracy: 0.7953419811320754 \n",
      "Epoch 5 | Step 1878 | loss: 0.44100505785834515 | accuracy: 0.795171522556391 \n",
      "Epoch 5 | Step 1879 | loss: 0.44085901484507295 | accuracy: 0.7952949438202247 \n",
      "Epoch 5 | Step 1880 | loss: 0.4410389190289511 | accuracy: 0.7952425373134329 \n",
      "Epoch 5 | Step 1881 | loss: 0.44112384297147555 | accuracy: 0.7952486059479554 \n",
      "Epoch 5 | Step 1882 | loss: 0.4409201662849496 | accuracy: 0.7952546296296297 \n",
      "Epoch 5 | Step 1883 | loss: 0.4405964214863372 | accuracy: 0.7953759225092251 \n",
      "Epoch 5 | Step 1884 | loss: 0.440324410357896 | accuracy: 0.7954963235294118 \n",
      "Epoch 5 | Step 1885 | loss: 0.4402224652933113 | accuracy: 0.7956158424908425 \n",
      "Epoch 5 | Step 1886 | loss: 0.44024854039188716 | accuracy: 0.7954493613138686 \n",
      "Epoch 5 | Step 1887 | loss: 0.44075933510606935 | accuracy: 0.7951704545454545 \n",
      "Epoch 5 | Step 1888 | loss: 0.4410085657584494 | accuracy: 0.7952332427536232 \n",
      "Epoch 5 | Step 1889 | loss: 0.4411504681790348 | accuracy: 0.795182761732852 \n",
      "Epoch 5 | Step 1890 | loss: 0.44080303470007803 | accuracy: 0.7953574640287769 \n",
      "Epoch 5 | Step 1891 | loss: 0.4414002096353893 | accuracy: 0.7949708781362007 \n",
      "Epoch 5 | Step 1892 | loss: 0.44115049860307143 | accuracy: 0.7952566964285714 \n",
      "Epoch 5 | Step 1893 | loss: 0.44133360784673176 | accuracy: 0.7950400355871886 \n",
      "Epoch 5 | Step 1894 | loss: 0.44097575946902545 | accuracy: 0.7952681737588653 \n",
      "Epoch 5 | Step 1895 | loss: 0.4410076715289072 | accuracy: 0.7953842756183745 \n",
      "Epoch 5 | Step 1896 | loss: 0.4406117630046858 | accuracy: 0.7956095950704225 \n",
      "Epoch 5 | Step 1897 | loss: 0.4405443629674744 | accuracy: 0.7955043859649122 \n",
      "Epoch 5 | Step 1898 | loss: 0.4401974048647847 | accuracy: 0.7956184440559441 \n",
      "Epoch 5 | Step 1899 | loss: 0.44013493173213786 | accuracy: 0.7957317073170732 \n",
      "Epoch 5 | Step 1900 | loss: 0.4397525183028645 | accuracy: 0.7959526909722222 \n",
      "Epoch 5 | Step 1901 | loss: 0.4399122023458712 | accuracy: 0.7957396193771626 \n",
      "Epoch 5 | Step 1902 | loss: 0.4398784907727406 | accuracy: 0.7957974137931034 \n",
      "Epoch 5 | Step 1903 | loss: 0.43995306500044884 | accuracy: 0.7956937285223368 \n",
      "Epoch 5 | Step 1904 | loss: 0.4397803095922078 | accuracy: 0.7956977739726028 \n",
      "Epoch 5 | Step 1905 | loss: 0.440144984591943 | accuracy: 0.7956484641638225 \n",
      "Epoch 5 | Step 1906 | loss: 0.44007555998507 | accuracy: 0.7955994897959183 \n",
      "Epoch 5 | Step 1907 | loss: 0.43993466940976805 | accuracy: 0.7956038135593221 \n",
      "Epoch 5 | Step 1908 | loss: 0.44006295804236384 | accuracy: 0.7956608952702703 \n",
      "Epoch 5 | Step 1909 | loss: 0.43990335079154586 | accuracy: 0.7957175925925926 \n",
      "Epoch 5 | Step 1910 | loss: 0.44002058271993727 | accuracy: 0.795669043624161 \n",
      "Epoch 5 | Step 1911 | loss: 0.43999562405024883 | accuracy: 0.7954640468227424 \n",
      "Epoch 5 | Step 1912 | loss: 0.440007791419824 | accuracy: 0.7953645833333333 \n",
      "Epoch 5 | Step 1913 | loss: 0.43984271709705114 | accuracy: 0.7955772425249168 \n",
      "Epoch 5 | Step 1914 | loss: 0.43998274710399427 | accuracy: 0.795374586092715 \n",
      "Epoch 5 | Step 1915 | loss: 0.4398745894432068 | accuracy: 0.7953279702970295 \n",
      "Epoch 5 | Step 1916 | loss: 0.43992909269505426 | accuracy: 0.7952816611842103 \n",
      "Epoch 5 | Step 1917 | loss: 0.439866602811657 | accuracy: 0.7952868852459014 \n",
      "Epoch 5 | Step 1918 | loss: 0.43976113950115403 | accuracy: 0.7952920751633985 \n",
      "Epoch 5 | Step 1919 | loss: 0.4398543994861628 | accuracy: 0.7952463355048858 \n",
      "Epoch 5 | Step 1920 | loss: 0.4395546933466738 | accuracy: 0.7954545454545453 \n",
      "Epoch 5 | Step 1921 | loss: 0.4392977432139869 | accuracy: 0.795610841423948 \n",
      "Epoch 5 | Step 1922 | loss: 0.4393241727544415 | accuracy: 0.7954637096774192 \n",
      "Epoch 5 | Step 1923 | loss: 0.4393052315980292 | accuracy: 0.795618971061093 \n",
      "Epoch 5 | Step 1924 | loss: 0.4392608775733373 | accuracy: 0.7956229967948716 \n",
      "Epoch 5 | Step 1925 | loss: 0.4391692991073901 | accuracy: 0.7955271565495206 \n",
      "Epoch 5 | Step 1926 | loss: 0.4394738932324063 | accuracy: 0.7954319267515921 \n",
      "Epoch 5 | Step 1927 | loss: 0.4401264748876057 | accuracy: 0.7950892857142855 \n",
      "Epoch 5 | Step 1928 | loss: 0.44023623892778085 | accuracy: 0.7951443829113922 \n",
      "Epoch 5 | Step 1929 | loss: 0.43965673991934356 | accuracy: 0.7956427444794951 \n",
      "Epoch 5 | Step 1930 | loss: 0.4399343860224358 | accuracy: 0.795450078616352 \n",
      "Epoch 5 | Step 1931 | loss: 0.43982326405175426 | accuracy: 0.7953565830721 \n",
      "Epoch 5 | Step 1932 | loss: 0.43962181694805624 | accuracy: 0.7954589843749996 \n",
      "Epoch 5 | Step 1933 | loss: 0.43963102146843885 | accuracy: 0.7956094236760121 \n",
      "Epoch 5 | Step 1934 | loss: 0.43997132481995577 | accuracy: 0.7953707298136642 \n",
      "Epoch 5 | Step 1935 | loss: 0.43992108328054563 | accuracy: 0.7953270123839006 \n",
      "Epoch 5 | Step 1936 | loss: 0.4396380187920582 | accuracy: 0.7954282407407404 \n",
      "Epoch 5 | Step 1937 | loss: 0.43978603949913614 | accuracy: 0.7954807692307689 \n",
      "Epoch 5 | Step 1938 | loss: 0.4396990608035421 | accuracy: 0.7954371165644168 \n",
      "Epoch 5 | Step 1939 | loss: 0.43981855059617886 | accuracy: 0.7952981651376143 \n",
      "Epoch 5 | Step 1940 | loss: 0.44014260799783034 | accuracy: 0.7951600609756094 \n",
      "Epoch 5 | Step 1941 | loss: 0.44025470348114665 | accuracy: 0.795070288753799 \n",
      "Epoch 5 | Step 1942 | loss: 0.4402131794980078 | accuracy: 0.7951704545454542 \n",
      "Epoch 5 | Step 1943 | loss: 0.4403238737691205 | accuracy: 0.7950339879154075 \n",
      "Epoch 5 | Step 1944 | loss: 0.44034720212221146 | accuracy: 0.7950395331325297 \n",
      "Epoch 5 | Step 1945 | loss: 0.44055174447752693 | accuracy: 0.794857357357357 \n",
      "Epoch 5 | Step 1946 | loss: 0.44039846992421294 | accuracy: 0.794956961077844 \n",
      "Epoch 5 | Step 1947 | loss: 0.4402974125164658 | accuracy: 0.7951026119402982 \n",
      "Epoch 5 | Step 1948 | loss: 0.44010781221801326 | accuracy: 0.795154389880952 \n",
      "Epoch 5 | Step 1949 | loss: 0.44006270417827525 | accuracy: 0.795159495548961 \n",
      "Epoch 5 | Step 1950 | loss: 0.44026978164029545 | accuracy: 0.7951645710059169 \n",
      "Epoch 5 | Step 1951 | loss: 0.4399709826373773 | accuracy: 0.7953539823008846 \n",
      "Epoch 5 | Step 1952 | loss: 0.43986288677243623 | accuracy: 0.7953584558823527 \n",
      "Epoch 5 | Step 1953 | loss: 0.43996872519118346 | accuracy: 0.7951796187683281 \n",
      "Epoch 5 | Step 1954 | loss: 0.4398888550829469 | accuracy: 0.7950932017543856 \n",
      "Epoch 5 | Step 1955 | loss: 0.4398129942118253 | accuracy: 0.7953717201166177 \n",
      "Epoch 5 | Step 1956 | loss: 0.43945241771465127 | accuracy: 0.7956031976744182 \n",
      "Epoch 5 | Step 1957 | loss: 0.4394901691139608 | accuracy: 0.7956521739130431 \n",
      "Epoch 5 | Step 1958 | loss: 0.43951419865809427 | accuracy: 0.7955653901734101 \n",
      "Epoch 5 | Step 1959 | loss: 0.43932464452573133 | accuracy: 0.795659221902017 \n",
      "Epoch 5 | Step 1960 | loss: 0.4396539530877409 | accuracy: 0.795528017241379 \n",
      "Epoch 5 | Step 1961 | loss: 0.439396027507618 | accuracy: 0.7956214183381085 \n",
      "Epoch 5 | Step 1962 | loss: 0.4391478271143777 | accuracy: 0.7957142857142854 \n",
      "Epoch 5 | Step 1963 | loss: 0.439093267645931 | accuracy: 0.7958066239316236 \n",
      "Epoch 5 | Step 1964 | loss: 0.4390530255199833 | accuracy: 0.7958984374999997 \n",
      "Epoch 5 | Step 1965 | loss: 0.43901168202543395 | accuracy: 0.795945467422096 \n",
      "Epoch 5 | Step 1966 | loss: 0.438950943323852 | accuracy: 0.7959480932203387 \n",
      "Epoch 5 | Step 1967 | loss: 0.4390399009409085 | accuracy: 0.7960827464788729 \n",
      "Epoch 5 | Step 1968 | loss: 0.4389688703283835 | accuracy: 0.7961288623595503 \n",
      "Epoch 5 | Step 1969 | loss: 0.43852306789710743 | accuracy: 0.7964373249299717 \n",
      "Epoch 5 | Step 1970 | loss: 0.4383675273736762 | accuracy: 0.7966567737430165 \n",
      "Epoch 5 | Step 1971 | loss: 0.4382766947606812 | accuracy: 0.796744428969359 \n",
      "Epoch 5 | Step 1972 | loss: 0.4384065833356645 | accuracy: 0.796614583333333 \n",
      "Epoch 5 | Step 1973 | loss: 0.4381601476933487 | accuracy: 0.7965720221606645 \n",
      "Epoch 5 | Step 1974 | loss: 0.438177152891844 | accuracy: 0.7966591850828726 \n",
      "Epoch 5 | Step 1975 | loss: 0.43845610037322874 | accuracy: 0.7964876033057848 \n",
      "Epoch 5 | Step 1976 | loss: 0.4381504945538856 | accuracy: 0.7966603708791206 \n",
      "Epoch 5 | Step 1977 | loss: 0.43819642254751023 | accuracy: 0.7966609589041093 \n",
      "Epoch 5 | Step 1978 | loss: 0.43804860595471223 | accuracy: 0.7969176912568303 \n",
      "Epoch 5 | Step 1979 | loss: 0.438287709568112 | accuracy: 0.7967047002724793 \n",
      "Epoch 5 | Step 1980 | loss: 0.4383114640317533 | accuracy: 0.7968325407608693 \n",
      "Epoch 5 | Step 1981 | loss: 0.43835335186503444 | accuracy: 0.7967479674796745 \n",
      "Epoch 5 | Step 1982 | loss: 0.43875391217502385 | accuracy: 0.7964949324324321 \n",
      "Epoch 5 | Step 1983 | loss: 0.4392012220347988 | accuracy: 0.7963274932614552 \n",
      "Epoch 5 | Step 1984 | loss: 0.43927515362219144 | accuracy: 0.7961189516129029 \n",
      "Epoch 5 | Step 1985 | loss: 0.43934553118557457 | accuracy: 0.7961628686327075 \n",
      "Epoch 5 | Step 1986 | loss: 0.43915242673879 | accuracy: 0.796248328877005 \n",
      "Epoch 5 | Step 1987 | loss: 0.4388127062320709 | accuracy: 0.7964166666666663 \n",
      "Epoch 5 | Step 1988 | loss: 0.43853820257998527 | accuracy: 0.7966256648936167 \n",
      "Epoch 5 | Step 1989 | loss: 0.43826680458509004 | accuracy: 0.7968335543766575 \n",
      "Epoch 5 | Step 1990 | loss: 0.43846035823620183 | accuracy: 0.7967096560846558 \n",
      "Epoch 5 | Step 1991 | loss: 0.4383957517335786 | accuracy: 0.7967925461741422 \n",
      "Epoch 5 | Step 1992 | loss: 0.43819083932198977 | accuracy: 0.7967927631578945 \n",
      "Epoch 5 | Step 1993 | loss: 0.4380882868929485 | accuracy: 0.7969160104986873 \n",
      "Epoch 5 | Step 1994 | loss: 0.43776403172478 | accuracy: 0.7971613219895285 \n",
      "Epoch 5 | Step 1995 | loss: 0.43781375659352495 | accuracy: 0.7970789817232373 \n",
      "Epoch 5 | Step 1996 | loss: 0.43806299714682 | accuracy: 0.7968749999999997 \n",
      "Epoch 5 | Step 1997 | loss: 0.43798919126584934 | accuracy: 0.7970373376623374 \n",
      "Epoch 5 | Step 1998 | loss: 0.4382095608686536 | accuracy: 0.7969559585492225 \n",
      "Epoch 5 | Step 1999 | loss: 0.4382969361251023 | accuracy: 0.7968749999999997 \n",
      "Epoch 5 | Step 2000 | loss: 0.438382097587143 | accuracy: 0.7969152706185564 \n",
      "Epoch 5 | Step 2001 | loss: 0.4385817869156982 | accuracy: 0.7967946658097683 \n",
      "Epoch 5 | Step 2002 | loss: 0.438602848083545 | accuracy: 0.7966746794871792 \n",
      "Epoch 5 | Step 2003 | loss: 0.438579745609742 | accuracy: 0.7967151534526852 \n",
      "Epoch 5 | Step 2004 | loss: 0.43860977135446605 | accuracy: 0.7966358418367344 \n",
      "Epoch 5 | Step 2005 | loss: 0.4385492382310426 | accuracy: 0.7967159669211193 \n",
      "Epoch 5 | Step 2006 | loss: 0.4385766759136607 | accuracy: 0.7967560279187814 \n",
      "Epoch 5 | Step 2007 | loss: 0.43859775239908244 | accuracy: 0.7967958860759491 \n",
      "Epoch 5 | Step 2008 | loss: 0.4383958191281617 | accuracy: 0.7969144570707067 \n",
      "Epoch 5 | Step 2009 | loss: 0.4382487312522283 | accuracy: 0.7969143576826193 \n",
      "Epoch 5 | Step 2010 | loss: 0.4383801681612005 | accuracy: 0.7968357412060298 \n",
      "Epoch 5 | Step 2011 | loss: 0.43840862418475907 | accuracy: 0.7968749999999997 \n",
      "Epoch 5 | Step 2012 | loss: 0.4385665730386972 | accuracy: 0.7967578124999997 \n",
      "Epoch 5 | Step 2013 | loss: 0.4385730314284489 | accuracy: 0.7968360349127179 \n",
      "Epoch 5 | Step 2014 | loss: 0.4391098294536866 | accuracy: 0.7964863184079599 \n",
      "Epoch 5 | Step 2015 | loss: 0.43897694016508665 | accuracy: 0.7966490544693047 \n",
      "Validation | Epoch 5 | Step 2015 | accuracy: 0.8047183792699467 \n",
      "Epoch 6 | Step 2016 | loss: 0.4431918263435364 | accuracy: 0.765625 \n",
      "Epoch 6 | Step 2017 | loss: 0.45024482905864716 | accuracy: 0.78125 \n",
      "Epoch 6 | Step 2018 | loss: 0.42376405994097394 | accuracy: 0.796875 \n",
      "Epoch 6 | Step 2019 | loss: 0.4382983446121216 | accuracy: 0.796875 \n",
      "Epoch 6 | Step 2020 | loss: 0.4304733514785767 | accuracy: 0.8 \n",
      "Epoch 6 | Step 2021 | loss: 0.43232108155886334 | accuracy: 0.7994791666666666 \n",
      "Epoch 6 | Step 2022 | loss: 0.4342143493039267 | accuracy: 0.796875 \n",
      "Epoch 6 | Step 2023 | loss: 0.4360910728573799 | accuracy: 0.796875 \n",
      "Epoch 6 | Step 2024 | loss: 0.4260779619216919 | accuracy: 0.8055555555555556 \n",
      "Epoch 6 | Step 2025 | loss: 0.4301301002502441 | accuracy: 0.803125 \n",
      "Epoch 6 | Step 2026 | loss: 0.4248502660881389 | accuracy: 0.8039772727272727 \n",
      "Epoch 6 | Step 2027 | loss: 0.4254344552755356 | accuracy: 0.8046875 \n",
      "Epoch 6 | Step 2028 | loss: 0.4206567223255451 | accuracy: 0.8028846153846154 \n",
      "Epoch 6 | Step 2029 | loss: 0.417991225208555 | accuracy: 0.8046875 \n",
      "Epoch 6 | Step 2030 | loss: 0.41114546259244283 | accuracy: 0.809375 \n",
      "Epoch 6 | Step 2031 | loss: 0.4036907199770212 | accuracy: 0.8173828125 \n",
      "Epoch 6 | Step 2032 | loss: 0.4004540671320522 | accuracy: 0.8216911764705882 \n",
      "Epoch 6 | Step 2033 | loss: 0.40037716759575737 | accuracy: 0.8185763888888888 \n",
      "Epoch 6 | Step 2034 | loss: 0.40329223243813767 | accuracy: 0.8166118421052632 \n",
      "Epoch 6 | Step 2035 | loss: 0.4007126122713089 | accuracy: 0.8171875 \n",
      "Epoch 6 | Step 2036 | loss: 0.39754647868020193 | accuracy: 0.8184523809523809 \n",
      "Epoch 6 | Step 2037 | loss: 0.3961632671681317 | accuracy: 0.8196022727272727 \n",
      "Epoch 6 | Step 2038 | loss: 0.39503148327703064 | accuracy: 0.8199728260869565 \n",
      "Epoch 6 | Step 2039 | loss: 0.3924135168393453 | accuracy: 0.8216145833333334 \n",
      "Epoch 6 | Step 2040 | loss: 0.39143845438957214 | accuracy: 0.82125 \n",
      "Epoch 6 | Step 2041 | loss: 0.39202044560359073 | accuracy: 0.8209134615384616 \n",
      "Epoch 6 | Step 2042 | loss: 0.3948364931124228 | accuracy: 0.8182870370370371 \n",
      "Epoch 6 | Step 2043 | loss: 0.3913118913769722 | accuracy: 0.8214285714285714 \n",
      "Epoch 6 | Step 2044 | loss: 0.39097702605970974 | accuracy: 0.8216594827586207 \n",
      "Epoch 6 | Step 2045 | loss: 0.3929931829373042 | accuracy: 0.8192708333333333 \n",
      "Epoch 6 | Step 2046 | loss: 0.39360540528451243 | accuracy: 0.8190524193548387 \n",
      "Epoch 6 | Step 2047 | loss: 0.3955712551251054 | accuracy: 0.81982421875 \n",
      "Epoch 6 | Step 2048 | loss: 0.399042063590252 | accuracy: 0.8172348484848485 \n",
      "Epoch 6 | Step 2049 | loss: 0.3981570093070759 | accuracy: 0.8189338235294118 \n",
      "Epoch 6 | Step 2050 | loss: 0.3967991616044726 | accuracy: 0.8196428571428571 \n",
      "Epoch 6 | Step 2051 | loss: 0.39654919256766635 | accuracy: 0.8190104166666666 \n",
      "Epoch 6 | Step 2052 | loss: 0.39699301767993617 | accuracy: 0.8184121621621622 \n",
      "Epoch 6 | Step 2053 | loss: 0.39605252915307093 | accuracy: 0.819078947368421 \n",
      "Epoch 6 | Step 2054 | loss: 0.3980141152174045 | accuracy: 0.8173076923076923 \n",
      "Epoch 6 | Step 2055 | loss: 0.398078553378582 | accuracy: 0.817578125 \n",
      "Epoch 6 | Step 2056 | loss: 0.3971099751751597 | accuracy: 0.819359756097561 \n",
      "Epoch 6 | Step 2057 | loss: 0.3988039990266164 | accuracy: 0.8188244047619048 \n",
      "Epoch 6 | Step 2058 | loss: 0.39814813746962435 | accuracy: 0.8197674418604651 \n",
      "Epoch 6 | Step 2059 | loss: 0.3985347497192296 | accuracy: 0.8199573863636364 \n",
      "Epoch 6 | Step 2060 | loss: 0.4016827086607615 | accuracy: 0.8180555555555555 \n",
      "Epoch 6 | Step 2061 | loss: 0.4036462773447451 | accuracy: 0.8165760869565217 \n",
      "Epoch 6 | Step 2062 | loss: 0.40304361695938923 | accuracy: 0.816156914893617 \n",
      "Epoch 6 | Step 2063 | loss: 0.4049709631750981 | accuracy: 0.8154296875 \n",
      "Epoch 6 | Step 2064 | loss: 0.4039748943581873 | accuracy: 0.8166454081632653 \n",
      "Epoch 6 | Step 2065 | loss: 0.40543558418750764 | accuracy: 0.816875 \n",
      "Epoch 6 | Step 2066 | loss: 0.40739548732252684 | accuracy: 0.8152573529411765 \n",
      "Epoch 6 | Step 2067 | loss: 0.4087042137980461 | accuracy: 0.8140024038461539 \n",
      "Epoch 6 | Step 2068 | loss: 0.4085695501768364 | accuracy: 0.8136792452830188 \n",
      "Epoch 6 | Step 2069 | loss: 0.40838907493485344 | accuracy: 0.8133680555555556 \n",
      "Epoch 6 | Step 2070 | loss: 0.4072464569048448 | accuracy: 0.8136363636363636 \n",
      "Epoch 6 | Step 2071 | loss: 0.4081661770386355 | accuracy: 0.814453125 \n",
      "Epoch 6 | Step 2072 | loss: 0.4083240058338433 | accuracy: 0.8152412280701754 \n",
      "Epoch 6 | Step 2073 | loss: 0.40863740135883464 | accuracy: 0.8149245689655172 \n",
      "Epoch 6 | Step 2074 | loss: 0.4095397202645318 | accuracy: 0.8146186440677966 \n",
      "Epoch 6 | Step 2075 | loss: 0.4098233391841253 | accuracy: 0.8153645833333333 \n",
      "Epoch 6 | Step 2076 | loss: 0.40976041897398524 | accuracy: 0.8148053278688525 \n",
      "Epoch 6 | Step 2077 | loss: 0.4100717657035397 | accuracy: 0.8150201612903226 \n",
      "Epoch 6 | Step 2078 | loss: 0.4106652774508037 | accuracy: 0.8152281746031746 \n",
      "Epoch 6 | Step 2079 | loss: 0.4089870541356504 | accuracy: 0.815673828125 \n",
      "Epoch 6 | Step 2080 | loss: 0.40851516952881445 | accuracy: 0.8153846153846154 \n",
      "Epoch 6 | Step 2081 | loss: 0.4067657445416306 | accuracy: 0.8167613636363636 \n",
      "Epoch 6 | Step 2082 | loss: 0.4063455916162747 | accuracy: 0.8169309701492538 \n",
      "Epoch 6 | Step 2083 | loss: 0.4060210923061651 | accuracy: 0.8175551470588235 \n",
      "Epoch 6 | Step 2084 | loss: 0.4072079874467159 | accuracy: 0.8170289855072463 \n",
      "Epoch 6 | Step 2085 | loss: 0.4095710277557373 | accuracy: 0.8149553571428572 \n",
      "Epoch 6 | Step 2086 | loss: 0.40835153552847847 | accuracy: 0.8158010563380281 \n",
      "Epoch 6 | Step 2087 | loss: 0.40828417034612763 | accuracy: 0.8161892361111112 \n",
      "Epoch 6 | Step 2088 | loss: 0.40856780907879137 | accuracy: 0.8157106164383562 \n",
      "Epoch 6 | Step 2089 | loss: 0.40854704581402446 | accuracy: 0.8156672297297297 \n",
      "Epoch 6 | Step 2090 | loss: 0.4091847137610118 | accuracy: 0.815625 \n",
      "Epoch 6 | Step 2091 | loss: 0.40855626291350317 | accuracy: 0.8159950657894737 \n",
      "Epoch 6 | Step 2092 | loss: 0.40832681431398765 | accuracy: 0.8159496753246753 \n",
      "Epoch 6 | Step 2093 | loss: 0.4096694752956048 | accuracy: 0.8151041666666666 \n",
      "Epoch 6 | Step 2094 | loss: 0.40924702528156814 | accuracy: 0.8152689873417721 \n",
      "Epoch 6 | Step 2095 | loss: 0.4093421518802643 | accuracy: 0.8150390625 \n",
      "Epoch 6 | Step 2096 | loss: 0.4088471057238402 | accuracy: 0.8157793209876543 \n",
      "Epoch 6 | Step 2097 | loss: 0.4077195565148098 | accuracy: 0.8165015243902439 \n",
      "Epoch 6 | Step 2098 | loss: 0.4068464920463332 | accuracy: 0.8172063253012049 \n",
      "Epoch 6 | Step 2099 | loss: 0.4072210749699956 | accuracy: 0.8165922619047619 \n",
      "Epoch 6 | Step 2100 | loss: 0.40802378338925976 | accuracy: 0.8163602941176471 \n",
      "Epoch 6 | Step 2101 | loss: 0.4071279944375504 | accuracy: 0.8170421511627907 \n",
      "Epoch 6 | Step 2102 | loss: 0.40699897107036637 | accuracy: 0.8169899425287356 \n",
      "Epoch 6 | Step 2103 | loss: 0.40761408887126227 | accuracy: 0.8171164772727273 \n",
      "Epoch 6 | Step 2104 | loss: 0.4070974015787746 | accuracy: 0.8172401685393258 \n",
      "Epoch 6 | Step 2105 | loss: 0.4079369091325336 | accuracy: 0.8164930555555555 \n",
      "Epoch 6 | Step 2106 | loss: 0.4069048231774634 | accuracy: 0.8167925824175825 \n",
      "Epoch 6 | Step 2107 | loss: 0.40959865956202796 | accuracy: 0.8152173913043478 \n",
      "Epoch 6 | Step 2108 | loss: 0.4092014697931146 | accuracy: 0.8158602150537635 \n",
      "Epoch 6 | Step 2109 | loss: 0.408489816366358 | accuracy: 0.8164893617021277 \n",
      "Epoch 6 | Step 2110 | loss: 0.4076486973386062 | accuracy: 0.8171052631578948 \n",
      "Epoch 6 | Step 2111 | loss: 0.4071641971046726 | accuracy: 0.8172200520833334 \n",
      "Epoch 6 | Step 2112 | loss: 0.406679233017656 | accuracy: 0.8173324742268041 \n",
      "Epoch 6 | Step 2113 | loss: 0.40819103590079714 | accuracy: 0.8164859693877551 \n",
      "Epoch 6 | Step 2114 | loss: 0.40740661187605426 | accuracy: 0.8161300505050505 \n",
      "Epoch 6 | Step 2115 | loss: 0.4072021421790123 | accuracy: 0.81640625 \n",
      "Epoch 6 | Step 2116 | loss: 0.4067262319645079 | accuracy: 0.8163675742574258 \n",
      "Epoch 6 | Step 2117 | loss: 0.40739203960287806 | accuracy: 0.8154105392156863 \n",
      "Epoch 6 | Step 2118 | loss: 0.40744747062331266 | accuracy: 0.8156856796116505 \n",
      "Epoch 6 | Step 2119 | loss: 0.40737241649856937 | accuracy: 0.8162560096153846 \n",
      "Epoch 6 | Step 2120 | loss: 0.4080136741910662 | accuracy: 0.8159226190476191 \n",
      "Epoch 6 | Step 2121 | loss: 0.4068086414404635 | accuracy: 0.8164799528301887 \n",
      "Epoch 6 | Step 2122 | loss: 0.40753986846620793 | accuracy: 0.8161507009345794 \n",
      "Epoch 6 | Step 2123 | loss: 0.40835513174533844 | accuracy: 0.8162615740740741 \n",
      "Epoch 6 | Step 2124 | loss: 0.4078757366456023 | accuracy: 0.8163704128440367 \n",
      "Epoch 6 | Step 2125 | loss: 0.40731671127406033 | accuracy: 0.8167613636363636 \n",
      "Epoch 6 | Step 2126 | loss: 0.4089486088838663 | accuracy: 0.8161599099099099 \n",
      "Epoch 6 | Step 2127 | loss: 0.40980000314967974 | accuracy: 0.8157087053571429 \n",
      "Epoch 6 | Step 2128 | loss: 0.41012863775270175 | accuracy: 0.8155420353982301 \n",
      "Epoch 6 | Step 2129 | loss: 0.4103816436570987 | accuracy: 0.8153782894736842 \n",
      "Epoch 6 | Step 2130 | loss: 0.4095462174519249 | accuracy: 0.8158967391304348 \n",
      "Epoch 6 | Step 2131 | loss: 0.40946131276673287 | accuracy: 0.8160021551724138 \n",
      "Epoch 6 | Step 2132 | loss: 0.408869358464184 | accuracy: 0.8161057692307693 \n",
      "Epoch 6 | Step 2133 | loss: 0.4090443614680888 | accuracy: 0.816207627118644 \n",
      "Epoch 6 | Step 2134 | loss: 0.4098896516972229 | accuracy: 0.8160451680672269 \n",
      "Epoch 6 | Step 2135 | loss: 0.4095655585328738 | accuracy: 0.8162760416666667 \n",
      "Epoch 6 | Step 2136 | loss: 0.4089628211722886 | accuracy: 0.8162448347107438 \n",
      "Epoch 6 | Step 2137 | loss: 0.40877845956653847 | accuracy: 0.8158299180327869 \n",
      "Epoch 6 | Step 2138 | loss: 0.40860794181746196 | accuracy: 0.8159298780487805 \n",
      "Epoch 6 | Step 2139 | loss: 0.40897073837057235 | accuracy: 0.8161542338709677 \n",
      "Epoch 6 | Step 2140 | loss: 0.4086450674533844 | accuracy: 0.816125 \n",
      "Epoch 6 | Step 2141 | loss: 0.40860543506486074 | accuracy: 0.8160962301587301 \n",
      "Epoch 6 | Step 2142 | loss: 0.4097335197794156 | accuracy: 0.8154527559055118 \n",
      "Epoch 6 | Step 2143 | loss: 0.4099034823011607 | accuracy: 0.815673828125 \n",
      "Epoch 6 | Step 2144 | loss: 0.4095151454441307 | accuracy: 0.8160125968992248 \n",
      "Epoch 6 | Step 2145 | loss: 0.4099084870173381 | accuracy: 0.815625 \n",
      "Epoch 6 | Step 2146 | loss: 0.41025347063559614 | accuracy: 0.815243320610687 \n",
      "Epoch 6 | Step 2147 | loss: 0.41060222324096796 | accuracy: 0.8146306818181818 \n",
      "Epoch 6 | Step 2148 | loss: 0.4101356415820301 | accuracy: 0.8150845864661654 \n",
      "Epoch 6 | Step 2149 | loss: 0.4104314722231965 | accuracy: 0.8147154850746269 \n",
      "Epoch 6 | Step 2150 | loss: 0.4106005410353343 | accuracy: 0.8149305555555556 \n",
      "Epoch 6 | Step 2151 | loss: 0.41033322648967013 | accuracy: 0.8150275735294118 \n",
      "Epoch 6 | Step 2152 | loss: 0.41036953673745596 | accuracy: 0.8153512773722628 \n",
      "Epoch 6 | Step 2153 | loss: 0.41043876932151074 | accuracy: 0.8151041666666666 \n",
      "Epoch 6 | Step 2154 | loss: 0.4104073587939036 | accuracy: 0.8151978417266187 \n",
      "Epoch 6 | Step 2155 | loss: 0.40983260784830366 | accuracy: 0.8157366071428571 \n",
      "Epoch 6 | Step 2156 | loss: 0.4094675933638363 | accuracy: 0.8160460992907801 \n",
      "Epoch 6 | Step 2157 | loss: 0.40944462468926335 | accuracy: 0.8160211267605634 \n",
      "Epoch 6 | Step 2158 | loss: 0.40950571782105455 | accuracy: 0.816215034965035 \n",
      "Epoch 6 | Step 2159 | loss: 0.4087520245876577 | accuracy: 0.8167317708333334 \n",
      "Epoch 6 | Step 2160 | loss: 0.4087329173910207 | accuracy: 0.8169181034482759 \n",
      "Epoch 6 | Step 2161 | loss: 0.4097936116669276 | accuracy: 0.8160316780821918 \n",
      "Epoch 6 | Step 2162 | loss: 0.4093796807486995 | accuracy: 0.8166454081632653 \n",
      "Epoch 6 | Step 2163 | loss: 0.40901541891130244 | accuracy: 0.8168285472972971 \n",
      "Epoch 6 | Step 2164 | loss: 0.408635540496583 | accuracy: 0.8171140939597313 \n",
      "Epoch 6 | Step 2165 | loss: 0.4086111813783646 | accuracy: 0.8170833333333332 \n",
      "Epoch 6 | Step 2166 | loss: 0.40842421461414824 | accuracy: 0.8170529801324501 \n",
      "Epoch 6 | Step 2167 | loss: 0.4090020603647358 | accuracy: 0.8164062499999997 \n",
      "Epoch 6 | Step 2168 | loss: 0.40919638537113967 | accuracy: 0.8162785947712414 \n",
      "Epoch 6 | Step 2169 | loss: 0.4089941252748688 | accuracy: 0.8164569805194801 \n",
      "Epoch 6 | Step 2170 | loss: 0.40851301743138224 | accuracy: 0.8164314516129029 \n",
      "Epoch 6 | Step 2171 | loss: 0.40824897835652035 | accuracy: 0.8167067307692304 \n",
      "Epoch 6 | Step 2172 | loss: 0.40757879709741873 | accuracy: 0.8171775477707003 \n",
      "Epoch 6 | Step 2173 | loss: 0.40727237545991246 | accuracy: 0.8175435126582274 \n",
      "Epoch 6 | Step 2174 | loss: 0.4068282793902751 | accuracy: 0.8178066037735845 \n",
      "Epoch 6 | Step 2175 | loss: 0.40708271116018296 | accuracy: 0.8175781249999996 \n",
      "Epoch 6 | Step 2176 | loss: 0.40675502645303 | accuracy: 0.8175465838509314 \n",
      "Epoch 6 | Step 2177 | loss: 0.4071735331305751 | accuracy: 0.8174189814814812 \n",
      "Epoch 6 | Step 2178 | loss: 0.40693136775420485 | accuracy: 0.8173888036809812 \n",
      "Epoch 6 | Step 2179 | loss: 0.406462843643456 | accuracy: 0.8178353658536582 \n",
      "Epoch 6 | Step 2180 | loss: 0.40629220604896543 | accuracy: 0.817613636363636 \n",
      "Epoch 6 | Step 2181 | loss: 0.40712705595665666 | accuracy: 0.8171121987951804 \n",
      "Epoch 6 | Step 2182 | loss: 0.4066465127610875 | accuracy: 0.817645958083832 \n",
      "Epoch 6 | Step 2183 | loss: 0.4063893914932296 | accuracy: 0.8178943452380949 \n",
      "Epoch 6 | Step 2184 | loss: 0.40712872024118546 | accuracy: 0.8176775147928991 \n",
      "Epoch 6 | Step 2185 | loss: 0.4063506121144575 | accuracy: 0.8181985294117644 \n",
      "Epoch 6 | Step 2186 | loss: 0.4066704605755053 | accuracy: 0.817708333333333 \n",
      "Epoch 6 | Step 2187 | loss: 0.4071112881566203 | accuracy: 0.8174055232558136 \n",
      "Epoch 6 | Step 2188 | loss: 0.4061389760130403 | accuracy: 0.8180997109826587 \n",
      "Epoch 6 | Step 2189 | loss: 0.4066530889135668 | accuracy: 0.8179777298850571 \n",
      "Epoch 6 | Step 2190 | loss: 0.40607111641338894 | accuracy: 0.8183928571428568 \n",
      "Epoch 6 | Step 2191 | loss: 0.4061733697625724 | accuracy: 0.8184481534090906 \n",
      "Epoch 6 | Step 2192 | loss: 0.40644241423256655 | accuracy: 0.8183262711864403 \n",
      "Epoch 6 | Step 2193 | loss: 0.40648220814345926 | accuracy: 0.8184691011235952 \n",
      "Epoch 6 | Step 2194 | loss: 0.40700837470299706 | accuracy: 0.8180865921787707 \n",
      "Epoch 6 | Step 2195 | loss: 0.40726502736409503 | accuracy: 0.8178819444444442 \n",
      "Epoch 6 | Step 2196 | loss: 0.40738172886779955 | accuracy: 0.8177658839779003 \n",
      "Epoch 6 | Step 2197 | loss: 0.4068210164269248 | accuracy: 0.8181662087912085 \n",
      "Epoch 6 | Step 2198 | loss: 0.4068658462639063 | accuracy: 0.818135245901639 \n",
      "Epoch 6 | Step 2199 | loss: 0.4069135880664639 | accuracy: 0.8180197010869562 \n",
      "Epoch 6 | Step 2200 | loss: 0.4067773401737213 | accuracy: 0.818074324324324 \n",
      "Epoch 6 | Step 2201 | loss: 0.406738121823598 | accuracy: 0.8181283602150534 \n",
      "Epoch 6 | Step 2202 | loss: 0.4068146210940764 | accuracy: 0.8181818181818179 \n",
      "Epoch 6 | Step 2203 | loss: 0.4066318615953973 | accuracy: 0.8181515957446805 \n",
      "Epoch 6 | Step 2204 | loss: 0.4063577013356345 | accuracy: 0.8182043650793648 \n",
      "Epoch 6 | Step 2205 | loss: 0.4059046453551242 | accuracy: 0.8184210526315786 \n",
      "Epoch 6 | Step 2206 | loss: 0.40606955286720037 | accuracy: 0.8181446335078532 \n",
      "Epoch 6 | Step 2207 | loss: 0.40615340663741034 | accuracy: 0.8181152343749997 \n",
      "Epoch 6 | Step 2208 | loss: 0.40611700180898674 | accuracy: 0.8179242227979272 \n",
      "Epoch 6 | Step 2209 | loss: 0.4060884904615658 | accuracy: 0.8178157216494842 \n",
      "Epoch 6 | Step 2210 | loss: 0.40616582005451884 | accuracy: 0.8177884615384613 \n",
      "Epoch 6 | Step 2211 | loss: 0.405830018222332 | accuracy: 0.8179209183673466 \n",
      "Epoch 6 | Step 2212 | loss: 0.4056509724123224 | accuracy: 0.8178934010152281 \n",
      "Epoch 6 | Step 2213 | loss: 0.40526765765565814 | accuracy: 0.8181029040404038 \n",
      "Epoch 6 | Step 2214 | loss: 0.4053401100875145 | accuracy: 0.8177606783919595 \n",
      "Epoch 6 | Step 2215 | loss: 0.4053917393088341 | accuracy: 0.8176562499999998 \n",
      "Epoch 6 | Step 2216 | loss: 0.4051924066164007 | accuracy: 0.817708333333333 \n",
      "Epoch 6 | Step 2217 | loss: 0.405213659795204 | accuracy: 0.8175278465346532 \n",
      "Epoch 6 | Step 2218 | loss: 0.4051224483645021 | accuracy: 0.8175800492610835 \n",
      "Epoch 6 | Step 2219 | loss: 0.4054970041501756 | accuracy: 0.8172487745098036 \n",
      "Epoch 6 | Step 2220 | loss: 0.40531025063700793 | accuracy: 0.8174542682926826 \n",
      "Epoch 6 | Step 2221 | loss: 0.4055607732638572 | accuracy: 0.8172026699029123 \n",
      "Epoch 6 | Step 2222 | loss: 0.4057198053108897 | accuracy: 0.8168780193236712 \n",
      "Epoch 6 | Step 2223 | loss: 0.4054709059687761 | accuracy: 0.8170823317307689 \n",
      "Epoch 6 | Step 2224 | loss: 0.4053505636288218 | accuracy: 0.8172099282296648 \n",
      "Epoch 6 | Step 2225 | loss: 0.4049703788189661 | accuracy: 0.8173363095238092 \n",
      "Epoch 6 | Step 2226 | loss: 0.4048151616801583 | accuracy: 0.8173874407582936 \n",
      "Epoch 6 | Step 2227 | loss: 0.4049627387298728 | accuracy: 0.8175117924528299 \n",
      "Epoch 6 | Step 2228 | loss: 0.4048472030062071 | accuracy: 0.8173415492957744 \n",
      "Epoch 6 | Step 2229 | loss: 0.4048418128323332 | accuracy: 0.8175379672897194 \n",
      "Epoch 6 | Step 2230 | loss: 0.40502735071404034 | accuracy: 0.817223837209302 \n",
      "Epoch 6 | Step 2231 | loss: 0.40501173627045417 | accuracy: 0.8172743055555552 \n",
      "Epoch 6 | Step 2232 | loss: 0.4053509549885851 | accuracy: 0.8171082949308753 \n",
      "Epoch 6 | Step 2233 | loss: 0.4058181308551666 | accuracy: 0.8165854357798162 \n",
      "Epoch 6 | Step 2234 | loss: 0.4059234066913117 | accuracy: 0.816495433789954 \n",
      "Epoch 6 | Step 2235 | loss: 0.405937342887575 | accuracy: 0.8162642045454543 \n",
      "Epoch 6 | Step 2236 | loss: 0.40576320468570315 | accuracy: 0.8161764705882351 \n",
      "Epoch 6 | Step 2237 | loss: 0.4060165712962279 | accuracy: 0.8160191441441439 \n",
      "Epoch 6 | Step 2238 | loss: 0.40573415935306806 | accuracy: 0.8162836322869953 \n",
      "Epoch 6 | Step 2239 | loss: 0.4060217248541968 | accuracy: 0.8163364955357141 \n",
      "Epoch 6 | Step 2240 | loss: 0.4061340363820394 | accuracy: 0.8162499999999997 \n",
      "Epoch 6 | Step 2241 | loss: 0.4060812508110451 | accuracy: 0.8162334070796458 \n",
      "Epoch 6 | Step 2242 | loss: 0.4061590950394517 | accuracy: 0.8163546255506605 \n",
      "Epoch 6 | Step 2243 | loss: 0.4058991971245983 | accuracy: 0.8165433114035086 \n",
      "Epoch 6 | Step 2244 | loss: 0.4055334181244196 | accuracy: 0.816866812227074 \n",
      "Epoch 6 | Step 2245 | loss: 0.40531547924746636 | accuracy: 0.816915760869565 \n",
      "Epoch 6 | Step 2246 | loss: 0.4049249589443207 | accuracy: 0.8171672077922075 \n",
      "Epoch 6 | Step 2247 | loss: 0.40471733669782506 | accuracy: 0.8171470905172411 \n",
      "Epoch 6 | Step 2248 | loss: 0.40460900329213284 | accuracy: 0.8173283261802573 \n",
      "Epoch 6 | Step 2249 | loss: 0.40508134039039284 | accuracy: 0.817174145299145 \n",
      "Epoch 6 | Step 2250 | loss: 0.40485573791443036 | accuracy: 0.817287234042553 \n",
      "Epoch 6 | Step 2251 | loss: 0.40461098124920314 | accuracy: 0.8172669491525422 \n",
      "Epoch 6 | Step 2252 | loss: 0.4045328470222055 | accuracy: 0.8174446202531643 \n",
      "Epoch 6 | Step 2253 | loss: 0.40500599296153095 | accuracy: 0.8174894957983191 \n",
      "Epoch 6 | Step 2254 | loss: 0.4051278925590435 | accuracy: 0.8174686192468616 \n",
      "Epoch 6 | Step 2255 | loss: 0.4051570873707533 | accuracy: 0.8173828124999998 \n",
      "Epoch 6 | Step 2256 | loss: 0.405625061993777 | accuracy: 0.8172977178423234 \n",
      "Epoch 6 | Step 2257 | loss: 0.4059411159231643 | accuracy: 0.8174070247933882 \n",
      "Epoch 6 | Step 2258 | loss: 0.4055702580836575 | accuracy: 0.8176440329218104 \n",
      "Epoch 6 | Step 2259 | loss: 0.4052368519736118 | accuracy: 0.8178790983606555 \n",
      "Epoch 6 | Step 2260 | loss: 0.4049460612997717 | accuracy: 0.818112244897959 \n",
      "Epoch 6 | Step 2261 | loss: 0.40480354973455757 | accuracy: 0.8182799796747965 \n",
      "Epoch 6 | Step 2262 | loss: 0.4046695319264524 | accuracy: 0.8183830971659917 \n",
      "Epoch 6 | Step 2263 | loss: 0.4046836657629859 | accuracy: 0.8182963709677417 \n",
      "Epoch 6 | Step 2264 | loss: 0.40518475332892084 | accuracy: 0.8179593373493974 \n",
      "Epoch 6 | Step 2265 | loss: 0.40496755170822146 | accuracy: 0.8181249999999998 \n",
      "Epoch 6 | Step 2266 | loss: 0.40531268585250674 | accuracy: 0.8179158366533862 \n",
      "Epoch 6 | Step 2267 | loss: 0.4060912359328497 | accuracy: 0.8175223214285712 \n",
      "Epoch 6 | Step 2268 | loss: 0.4059387850667177 | accuracy: 0.8175642292490116 \n",
      "Epoch 6 | Step 2269 | loss: 0.40586433659388327 | accuracy: 0.817728838582677 \n",
      "Epoch 6 | Step 2270 | loss: 0.4057618711508957 | accuracy: 0.8177083333333331 \n",
      "Epoch 6 | Step 2271 | loss: 0.40552245907019824 | accuracy: 0.8178100585937498 \n",
      "Epoch 6 | Step 2272 | loss: 0.40580334899954296 | accuracy: 0.8177285992217896 \n",
      "Epoch 6 | Step 2273 | loss: 0.4056927437006041 | accuracy: 0.8178294573643409 \n",
      "Epoch 6 | Step 2274 | loss: 0.4059124151712219 | accuracy: 0.8175675675675673 \n",
      "Epoch 6 | Step 2275 | loss: 0.4061334295914723 | accuracy: 0.8174278846153844 \n",
      "Epoch 6 | Step 2276 | loss: 0.4064862343314964 | accuracy: 0.8173491379310343 \n",
      "Epoch 6 | Step 2277 | loss: 0.4069499299498915 | accuracy: 0.8170324427480914 \n",
      "Epoch 6 | Step 2278 | loss: 0.4070479784854918 | accuracy: 0.8170152091254751 \n",
      "Epoch 6 | Step 2279 | loss: 0.4070287328777891 | accuracy: 0.8168797348484846 \n",
      "Epoch 6 | Step 2280 | loss: 0.40704020104318295 | accuracy: 0.8168042452830186 \n",
      "Epoch 6 | Step 2281 | loss: 0.4071979768070063 | accuracy: 0.8166705827067667 \n",
      "Epoch 6 | Step 2282 | loss: 0.4069729809010966 | accuracy: 0.816830524344569 \n",
      "Epoch 6 | Step 2283 | loss: 0.40729291915003935 | accuracy: 0.8168143656716416 \n",
      "Epoch 6 | Step 2284 | loss: 0.40744496721317336 | accuracy: 0.8166821561338288 \n",
      "Epoch 6 | Step 2285 | loss: 0.40720127865120215 | accuracy: 0.8167824074074072 \n",
      "Epoch 6 | Step 2286 | loss: 0.40696740733301506 | accuracy: 0.8168242619926197 \n",
      "Epoch 6 | Step 2287 | loss: 0.4067663925097269 | accuracy: 0.816808363970588 \n",
      "Epoch 6 | Step 2288 | loss: 0.40677535424739014 | accuracy: 0.8167925824175822 \n",
      "Epoch 6 | Step 2289 | loss: 0.4068209241776571 | accuracy: 0.8166628649635035 \n",
      "Epoch 6 | Step 2290 | loss: 0.4072378375313499 | accuracy: 0.8164204545454543 \n",
      "Epoch 6 | Step 2291 | loss: 0.40740937858388043 | accuracy: 0.8162930253623186 \n",
      "Epoch 6 | Step 2292 | loss: 0.40758639584809864 | accuracy: 0.8162229241877255 \n",
      "Epoch 6 | Step 2293 | loss: 0.4072324681839497 | accuracy: 0.8164343525179855 \n",
      "Epoch 6 | Step 2294 | loss: 0.4079093406490955 | accuracy: 0.8161962365591396 \n",
      "Epoch 6 | Step 2295 | loss: 0.40760284098131316 | accuracy: 0.8164062499999999 \n",
      "Epoch 6 | Step 2296 | loss: 0.40785656609569154 | accuracy: 0.816225533807829 \n",
      "Epoch 6 | Step 2297 | loss: 0.4075196455133722 | accuracy: 0.816433953900709 \n",
      "Epoch 6 | Step 2298 | loss: 0.40759258788381786 | accuracy: 0.8165856890459362 \n",
      "Epoch 6 | Step 2299 | loss: 0.4072987295582261 | accuracy: 0.8167363556338026 \n",
      "Epoch 6 | Step 2300 | loss: 0.4072859137727503 | accuracy: 0.8166118421052629 \n",
      "Epoch 6 | Step 2301 | loss: 0.4068496276240249 | accuracy: 0.8168159965034963 \n",
      "Epoch 6 | Step 2302 | loss: 0.40666337576062006 | accuracy: 0.8169642857142855 \n",
      "Epoch 6 | Step 2303 | loss: 0.40632057272725636 | accuracy: 0.8171657986111109 \n",
      "Epoch 6 | Step 2304 | loss: 0.40653257128689113 | accuracy: 0.8170415224913493 \n",
      "Epoch 6 | Step 2305 | loss: 0.40647317777419906 | accuracy: 0.8172413793103447 \n",
      "Epoch 6 | Step 2306 | loss: 0.4065653393973189 | accuracy: 0.8171713917525772 \n",
      "Epoch 6 | Step 2307 | loss: 0.40642539442402037 | accuracy: 0.8171553938356163 \n",
      "Epoch 6 | Step 2308 | loss: 0.4067649587022566 | accuracy: 0.8170328498293514 \n",
      "Epoch 6 | Step 2309 | loss: 0.4067571465255451 | accuracy: 0.8171237244897959 \n",
      "Epoch 6 | Step 2310 | loss: 0.40661750749006104 | accuracy: 0.8172139830508474 \n",
      "Epoch 6 | Step 2311 | loss: 0.40679034359149024 | accuracy: 0.8172508445945945 \n",
      "Epoch 6 | Step 2312 | loss: 0.4066075855232649 | accuracy: 0.8173400673400673 \n",
      "Epoch 6 | Step 2313 | loss: 0.4068235473944836 | accuracy: 0.8173238255033556 \n",
      "Epoch 6 | Step 2314 | loss: 0.4067964379404699 | accuracy: 0.8170986622073577 \n",
      "Epoch 6 | Step 2315 | loss: 0.40675948351621616 | accuracy: 0.8170833333333333 \n",
      "Epoch 6 | Step 2316 | loss: 0.4066342268869329 | accuracy: 0.8171719269102989 \n",
      "Epoch 6 | Step 2317 | loss: 0.406672855185357 | accuracy: 0.8171047185430462 \n",
      "Epoch 6 | Step 2318 | loss: 0.4065290897002707 | accuracy: 0.8171410891089108 \n",
      "Epoch 6 | Step 2319 | loss: 0.406630014706599 | accuracy: 0.8169716282894736 \n",
      "Epoch 6 | Step 2320 | loss: 0.40647833845654463 | accuracy: 0.8170594262295081 \n",
      "Epoch 6 | Step 2321 | loss: 0.40648911591448805 | accuracy: 0.8171466503267973 \n",
      "Epoch 6 | Step 2322 | loss: 0.40666293874625653 | accuracy: 0.8170806188925082 \n",
      "Epoch 6 | Step 2323 | loss: 0.40632600917831635 | accuracy: 0.8172179383116883 \n",
      "Epoch 6 | Step 2324 | loss: 0.4060247295496918 | accuracy: 0.8173543689320388 \n",
      "Epoch 6 | Step 2325 | loss: 0.40619461305679805 | accuracy: 0.8171370967741935 \n",
      "Epoch 6 | Step 2326 | loss: 0.4062122945041901 | accuracy: 0.8172226688102894 \n",
      "Epoch 6 | Step 2327 | loss: 0.40621245776613546 | accuracy: 0.817207532051282 \n",
      "Epoch 6 | Step 2328 | loss: 0.406130602279791 | accuracy: 0.8171425718849841 \n",
      "Epoch 6 | Step 2329 | loss: 0.4063978257832253 | accuracy: 0.817078025477707 \n",
      "Epoch 6 | Step 2330 | loss: 0.4070982753284393 | accuracy: 0.8167162698412699 \n",
      "Epoch 6 | Step 2331 | loss: 0.4071611281059964 | accuracy: 0.8166534810126582 \n",
      "Epoch 6 | Step 2332 | loss: 0.4066241712130206 | accuracy: 0.8170839905362776 \n",
      "Epoch 6 | Step 2333 | loss: 0.4068715775256636 | accuracy: 0.816873034591195 \n",
      "Epoch 6 | Step 2334 | loss: 0.40683047239870107 | accuracy: 0.8168593260188087 \n",
      "Epoch 6 | Step 2335 | loss: 0.40665387813933185 | accuracy: 0.81689453125 \n",
      "Epoch 6 | Step 2336 | loss: 0.40657766469728157 | accuracy: 0.8170268691588785 \n",
      "Epoch 6 | Step 2337 | loss: 0.4069477535830521 | accuracy: 0.8168672360248447 \n",
      "Epoch 6 | Step 2338 | loss: 0.40677054069544133 | accuracy: 0.8169504643962848 \n",
      "Epoch 6 | Step 2339 | loss: 0.4064821113866787 | accuracy: 0.8171296296296297 \n",
      "Epoch 6 | Step 2340 | loss: 0.4066516022040293 | accuracy: 0.8170673076923077 \n",
      "Epoch 6 | Step 2341 | loss: 0.406565606274122 | accuracy: 0.817101226993865 \n",
      "Epoch 6 | Step 2342 | loss: 0.40670169097021075 | accuracy: 0.8169438073394495 \n",
      "Epoch 6 | Step 2343 | loss: 0.4069922708610935 | accuracy: 0.8167873475609756 \n",
      "Epoch 6 | Step 2344 | loss: 0.40715747577984635 | accuracy: 0.8166318389057751 \n",
      "Epoch 6 | Step 2345 | loss: 0.40711368290763905 | accuracy: 0.8168087121212121 \n",
      "Epoch 6 | Step 2346 | loss: 0.407194697109594 | accuracy: 0.8167012839879154 \n",
      "Epoch 6 | Step 2347 | loss: 0.40709301088768307 | accuracy: 0.8167356927710844 \n",
      "Epoch 6 | Step 2348 | loss: 0.4072344507630522 | accuracy: 0.816722972972973 \n",
      "Epoch 6 | Step 2349 | loss: 0.4070740868142264 | accuracy: 0.8168038922155688 \n",
      "Epoch 6 | Step 2350 | loss: 0.40698664495304443 | accuracy: 0.8169776119402985 \n",
      "Epoch 6 | Step 2351 | loss: 0.4068487211618394 | accuracy: 0.8170107886904762 \n",
      "Epoch 6 | Step 2352 | loss: 0.40673778243694525 | accuracy: 0.8170901335311572 \n",
      "Epoch 6 | Step 2353 | loss: 0.40691051870231787 | accuracy: 0.8171227810650887 \n",
      "Epoch 6 | Step 2354 | loss: 0.40665675603007134 | accuracy: 0.8172013274336283 \n",
      "Epoch 6 | Step 2355 | loss: 0.4065179853316615 | accuracy: 0.817233455882353 \n",
      "Epoch 6 | Step 2356 | loss: 0.406635164122078 | accuracy: 0.8170821114369502 \n",
      "Epoch 6 | Step 2357 | loss: 0.4065606270355787 | accuracy: 0.8170230263157895 \n",
      "Epoch 6 | Step 2358 | loss: 0.4064159232134721 | accuracy: 0.8172376093294461 \n",
      "Epoch 6 | Step 2359 | loss: 0.40612669536020857 | accuracy: 0.817360101744186 \n",
      "Epoch 6 | Step 2360 | loss: 0.40627117817816516 | accuracy: 0.8174365942028986 \n",
      "Epoch 6 | Step 2361 | loss: 0.4063176196176192 | accuracy: 0.8174223265895953 \n",
      "Epoch 6 | Step 2362 | loss: 0.40609801498373227 | accuracy: 0.8174981988472623 \n",
      "Epoch 6 | Step 2363 | loss: 0.40646497798205783 | accuracy: 0.8173042385057471 \n",
      "Epoch 6 | Step 2364 | loss: 0.40622295046433327 | accuracy: 0.8173352435530086 \n",
      "Epoch 6 | Step 2365 | loss: 0.40599357966865807 | accuracy: 0.8174553571428571 \n",
      "Epoch 6 | Step 2366 | loss: 0.40589955342970674 | accuracy: 0.8175747863247863 \n",
      "Epoch 6 | Step 2367 | loss: 0.405847786121409 | accuracy: 0.8176047585227273 \n",
      "Epoch 6 | Step 2368 | loss: 0.4057973370420358 | accuracy: 0.8175460339943342 \n",
      "Epoch 6 | Step 2369 | loss: 0.405663486801635 | accuracy: 0.817531779661017 \n",
      "Epoch 6 | Step 2370 | loss: 0.4057157282678174 | accuracy: 0.817649647887324 \n",
      "Epoch 6 | Step 2371 | loss: 0.4055749261228555 | accuracy: 0.8176790730337079 \n",
      "Epoch 6 | Step 2372 | loss: 0.4051601513176738 | accuracy: 0.8179709383753502 \n",
      "Epoch 6 | Step 2373 | loss: 0.4049817761978623 | accuracy: 0.8181302374301676 \n",
      "Epoch 6 | Step 2374 | loss: 0.4049533816018144 | accuracy: 0.817983983286908 \n",
      "Epoch 6 | Step 2375 | loss: 0.4050303855290015 | accuracy: 0.8178385416666667 \n",
      "Epoch 6 | Step 2376 | loss: 0.40478142712089815 | accuracy: 0.8179536011080333 \n",
      "Epoch 6 | Step 2377 | loss: 0.40484549990181096 | accuracy: 0.818024861878453 \n",
      "Epoch 6 | Step 2378 | loss: 0.4051640718846938 | accuracy: 0.8178805096418733 \n",
      "Epoch 6 | Step 2379 | loss: 0.4049102417142181 | accuracy: 0.8179515796703297 \n",
      "Epoch 6 | Step 2380 | loss: 0.4050236275343045 | accuracy: 0.8178938356164384 \n",
      "Epoch 6 | Step 2381 | loss: 0.4048967839834468 | accuracy: 0.8180925546448088 \n",
      "Epoch 6 | Step 2382 | loss: 0.4050182541400924 | accuracy: 0.8179495912806539 \n",
      "Epoch 6 | Step 2383 | loss: 0.40505226041473763 | accuracy: 0.8180621603260869 \n",
      "Epoch 6 | Step 2384 | loss: 0.4050787091659013 | accuracy: 0.818089430894309 \n",
      "Epoch 6 | Step 2385 | loss: 0.40546978393921973 | accuracy: 0.8178209459459459 \n",
      "Epoch 6 | Step 2386 | loss: 0.4059110642523778 | accuracy: 0.8175960242587601 \n",
      "Epoch 6 | Step 2387 | loss: 0.40595955718108395 | accuracy: 0.8176663306451613 \n",
      "Epoch 6 | Step 2388 | loss: 0.4059815105979627 | accuracy: 0.8176524798927614 \n",
      "Epoch 6 | Step 2389 | loss: 0.4058634869475415 | accuracy: 0.8176804812834224 \n",
      "Epoch 6 | Step 2390 | loss: 0.405499053676923 | accuracy: 0.8178333333333333 \n",
      "Epoch 6 | Step 2391 | loss: 0.4052572375995681 | accuracy: 0.8179022606382979 \n",
      "Epoch 6 | Step 2392 | loss: 0.4049354872668769 | accuracy: 0.8181366047745358 \n",
      "Epoch 6 | Step 2393 | loss: 0.4051961747821045 | accuracy: 0.8179976851851852 \n",
      "Epoch 6 | Step 2394 | loss: 0.40519490134275676 | accuracy: 0.8180244063324539 \n",
      "Epoch 6 | Step 2395 | loss: 0.4050081222857299 | accuracy: 0.8180509868421053 \n",
      "Epoch 6 | Step 2396 | loss: 0.4049029934985118 | accuracy: 0.8181594488188977 \n",
      "Epoch 6 | Step 2397 | loss: 0.40453640129709734 | accuracy: 0.8184309554973822 \n",
      "Epoch 6 | Step 2398 | loss: 0.40463371808317244 | accuracy: 0.8183746736292428 \n",
      "Epoch 6 | Step 2399 | loss: 0.4048335805612926 | accuracy: 0.8181559244791666 \n",
      "Epoch 6 | Step 2400 | loss: 0.40486141679348875 | accuracy: 0.8182224025974026 \n",
      "Epoch 6 | Step 2401 | loss: 0.4051038159993645 | accuracy: 0.818086139896373 \n",
      "Epoch 6 | Step 2402 | loss: 0.4051708296826951 | accuracy: 0.8181120801033591 \n",
      "Epoch 6 | Step 2403 | loss: 0.4052945345102511 | accuracy: 0.818017074742268 \n",
      "Epoch 6 | Step 2404 | loss: 0.4055854367489679 | accuracy: 0.8178020565552699 \n",
      "Epoch 6 | Step 2405 | loss: 0.40553923604580067 | accuracy: 0.8177884615384615 \n",
      "Epoch 6 | Step 2406 | loss: 0.40559193510990915 | accuracy: 0.8176950127877238 \n",
      "Epoch 6 | Step 2407 | loss: 0.40557588534239597 | accuracy: 0.8176020408163265 \n",
      "Epoch 6 | Step 2408 | loss: 0.40551864308406976 | accuracy: 0.8176685750636132 \n",
      "Epoch 6 | Step 2409 | loss: 0.4056160492718522 | accuracy: 0.8175761421319797 \n",
      "Epoch 6 | Step 2410 | loss: 0.4056562216598776 | accuracy: 0.8176819620253165 \n",
      "Epoch 6 | Step 2411 | loss: 0.4054809142318036 | accuracy: 0.8177083333333334 \n",
      "Epoch 6 | Step 2412 | loss: 0.4052850183296563 | accuracy: 0.8177345717884131 \n",
      "Epoch 6 | Step 2413 | loss: 0.40540977095689 | accuracy: 0.8176821608040201 \n",
      "Epoch 6 | Step 2414 | loss: 0.40553823714716386 | accuracy: 0.8175908521303258 \n",
      "Epoch 6 | Step 2415 | loss: 0.4057214638963341 | accuracy: 0.8174609375 \n",
      "Epoch 6 | Step 2416 | loss: 0.40566930252863576 | accuracy: 0.8176044264339152 \n",
      "Epoch 6 | Step 2417 | loss: 0.4061240394836041 | accuracy: 0.8173585199004975 \n",
      "Epoch 6 | Step 2418 | loss: 0.4059942317733693 | accuracy: 0.8174694638985854 \n",
      "Validation | Epoch 6 | Step 2418 | accuracy: 0.8135962201790377 \n",
      "Epoch 7 | Step 2419 | loss: 0.40689218044281006 | accuracy: 0.84375 \n",
      "Epoch 7 | Step 2420 | loss: 0.42329373955726624 | accuracy: 0.8046875 \n",
      "Epoch 7 | Step 2421 | loss: 0.3980380098025004 | accuracy: 0.828125 \n",
      "Epoch 7 | Step 2422 | loss: 0.41319096088409424 | accuracy: 0.82421875 \n",
      "Epoch 7 | Step 2423 | loss: 0.40737468004226685 | accuracy: 0.81875 \n",
      "Epoch 7 | Step 2424 | loss: 0.4127998799085617 | accuracy: 0.8151041666666666 \n",
      "Epoch 7 | Step 2425 | loss: 0.4151854302201952 | accuracy: 0.8080357142857143 \n",
      "Epoch 7 | Step 2426 | loss: 0.4177548885345459 | accuracy: 0.802734375 \n",
      "Epoch 7 | Step 2427 | loss: 0.41091644432809615 | accuracy: 0.8072916666666666 \n",
      "Epoch 7 | Step 2428 | loss: 0.4162086367607117 | accuracy: 0.8078125 \n",
      "Epoch 7 | Step 2429 | loss: 0.41219025579365814 | accuracy: 0.8096590909090909 \n",
      "Epoch 7 | Step 2430 | loss: 0.4146223266919454 | accuracy: 0.8059895833333334 \n",
      "Epoch 7 | Step 2431 | loss: 0.40803338243411136 | accuracy: 0.8076923076923077 \n",
      "Epoch 7 | Step 2432 | loss: 0.40450945283685413 | accuracy: 0.8113839285714286 \n",
      "Epoch 7 | Step 2433 | loss: 0.3960512121518453 | accuracy: 0.8177083333333334 \n",
      "Epoch 7 | Step 2434 | loss: 0.3878419101238251 | accuracy: 0.82421875 \n",
      "Epoch 7 | Step 2435 | loss: 0.3845846091999727 | accuracy: 0.8272058823529411 \n",
      "Epoch 7 | Step 2436 | loss: 0.38418323795000714 | accuracy: 0.8237847222222222 \n",
      "Epoch 7 | Step 2437 | loss: 0.38716835097262736 | accuracy: 0.8223684210526315 \n",
      "Epoch 7 | Step 2438 | loss: 0.3854080930352211 | accuracy: 0.8234375 \n",
      "Epoch 7 | Step 2439 | loss: 0.38164342585064115 | accuracy: 0.8258928571428571 \n",
      "Epoch 7 | Step 2440 | loss: 0.37824643606489355 | accuracy: 0.8274147727272727 \n",
      "Epoch 7 | Step 2441 | loss: 0.3759122128071992 | accuracy: 0.828125 \n",
      "Epoch 7 | Step 2442 | loss: 0.37235485514005023 | accuracy: 0.8307291666666666 \n",
      "Epoch 7 | Step 2443 | loss: 0.3724000608921051 | accuracy: 0.831875 \n",
      "Epoch 7 | Step 2444 | loss: 0.37239129955951983 | accuracy: 0.8323317307692307 \n",
      "Epoch 7 | Step 2445 | loss: 0.3748849155726256 | accuracy: 0.8310185185185185 \n",
      "Epoch 7 | Step 2446 | loss: 0.37171071767807007 | accuracy: 0.8348214285714286 \n",
      "Epoch 7 | Step 2447 | loss: 0.37046460550406884 | accuracy: 0.8356681034482759 \n",
      "Epoch 7 | Step 2448 | loss: 0.3702836235364278 | accuracy: 0.8359375 \n",
      "Epoch 7 | Step 2449 | loss: 0.3699111419339334 | accuracy: 0.8371975806451613 \n",
      "Epoch 7 | Step 2450 | loss: 0.3712390111759305 | accuracy: 0.8369140625 \n",
      "Epoch 7 | Step 2451 | loss: 0.3745404635414933 | accuracy: 0.8357007575757576 \n",
      "Epoch 7 | Step 2452 | loss: 0.37475792537717256 | accuracy: 0.8363970588235294 \n",
      "Epoch 7 | Step 2453 | loss: 0.3736977219581604 | accuracy: 0.8370535714285714 \n",
      "Epoch 7 | Step 2454 | loss: 0.37413479304975933 | accuracy: 0.8363715277777778 \n",
      "Epoch 7 | Step 2455 | loss: 0.37491367153219274 | accuracy: 0.8357263513513513 \n",
      "Epoch 7 | Step 2456 | loss: 0.3744855868188958 | accuracy: 0.8359375 \n",
      "Epoch 7 | Step 2457 | loss: 0.3756020886775775 | accuracy: 0.8353365384615384 \n",
      "Epoch 7 | Step 2458 | loss: 0.37532903999090195 | accuracy: 0.835546875 \n",
      "Epoch 7 | Step 2459 | loss: 0.37396975043343333 | accuracy: 0.8365091463414634 \n",
      "Epoch 7 | Step 2460 | loss: 0.3763287266095479 | accuracy: 0.8359375 \n",
      "Epoch 7 | Step 2461 | loss: 0.3758556738842365 | accuracy: 0.8364825581395349 \n",
      "Epoch 7 | Step 2462 | loss: 0.37598453733054077 | accuracy: 0.8359375 \n",
      "Epoch 7 | Step 2463 | loss: 0.3793080144458347 | accuracy: 0.8333333333333334 \n",
      "Epoch 7 | Step 2464 | loss: 0.38238909322282544 | accuracy: 0.8311820652173914 \n",
      "Epoch 7 | Step 2465 | loss: 0.3818605168068663 | accuracy: 0.8311170212765957 \n",
      "Epoch 7 | Step 2466 | loss: 0.3844225239008665 | accuracy: 0.8307291666666666 \n",
      "Epoch 7 | Step 2467 | loss: 0.3825971034108376 | accuracy: 0.8316326530612245 \n",
      "Epoch 7 | Step 2468 | loss: 0.3838413679599762 | accuracy: 0.8315625 \n",
      "Epoch 7 | Step 2469 | loss: 0.3862024136618072 | accuracy: 0.8296568627450981 \n",
      "Epoch 7 | Step 2470 | loss: 0.3868672211582844 | accuracy: 0.8287259615384616 \n",
      "Epoch 7 | Step 2471 | loss: 0.3862361452489529 | accuracy: 0.8287146226415094 \n",
      "Epoch 7 | Step 2472 | loss: 0.3851701584127214 | accuracy: 0.8292824074074074 \n",
      "Epoch 7 | Step 2473 | loss: 0.38412422754547815 | accuracy: 0.8298295454545455 \n",
      "Epoch 7 | Step 2474 | loss: 0.3844978112195219 | accuracy: 0.8303571428571429 \n",
      "Epoch 7 | Step 2475 | loss: 0.3843605324887393 | accuracy: 0.8308662280701754 \n",
      "Epoch 7 | Step 2476 | loss: 0.3848762558452014 | accuracy: 0.830010775862069 \n",
      "Epoch 7 | Step 2477 | loss: 0.3854689295009031 | accuracy: 0.8294491525423728 \n",
      "Epoch 7 | Step 2478 | loss: 0.3855999201536179 | accuracy: 0.8296875 \n",
      "Epoch 7 | Step 2479 | loss: 0.38551121559299406 | accuracy: 0.8296618852459017 \n",
      "Epoch 7 | Step 2480 | loss: 0.3851615233767417 | accuracy: 0.8293850806451613 \n",
      "Epoch 7 | Step 2481 | loss: 0.3858426298413958 | accuracy: 0.8291170634920635 \n",
      "Epoch 7 | Step 2482 | loss: 0.38425698690116405 | accuracy: 0.830078125 \n",
      "Epoch 7 | Step 2483 | loss: 0.3835680278447958 | accuracy: 0.8302884615384616 \n",
      "Epoch 7 | Step 2484 | loss: 0.38144436478614807 | accuracy: 0.8314393939393939 \n",
      "Epoch 7 | Step 2485 | loss: 0.38126376048842475 | accuracy: 0.8316231343283582 \n",
      "Epoch 7 | Step 2486 | loss: 0.380543069804416 | accuracy: 0.8322610294117647 \n",
      "Epoch 7 | Step 2487 | loss: 0.382218851559404 | accuracy: 0.8312952898550725 \n",
      "Epoch 7 | Step 2488 | loss: 0.3852541412625994 | accuracy: 0.8290178571428571 \n",
      "Epoch 7 | Step 2489 | loss: 0.38414860611230556 | accuracy: 0.8298855633802817 \n",
      "Epoch 7 | Step 2490 | loss: 0.38377976045012474 | accuracy: 0.8300781250000001 \n",
      "Epoch 7 | Step 2491 | loss: 0.3838721860761512 | accuracy: 0.8304794520547946 \n",
      "Epoch 7 | Step 2492 | loss: 0.3842623406970823 | accuracy: 0.8306587837837838 \n",
      "Epoch 7 | Step 2493 | loss: 0.3851804033915202 | accuracy: 0.8308333333333333 \n",
      "Epoch 7 | Step 2494 | loss: 0.3845321151771044 | accuracy: 0.8310032894736842 \n",
      "Epoch 7 | Step 2495 | loss: 0.384502405857111 | accuracy: 0.8309659090909091 \n",
      "Epoch 7 | Step 2496 | loss: 0.38602435856293416 | accuracy: 0.8301282051282052 \n",
      "Epoch 7 | Step 2497 | loss: 0.38545829095417944 | accuracy: 0.8310917721518988 \n",
      "Epoch 7 | Step 2498 | loss: 0.38539534173905854 | accuracy: 0.8310546875 \n",
      "Epoch 7 | Step 2499 | loss: 0.38507056273060086 | accuracy: 0.8312114197530864 \n",
      "Epoch 7 | Step 2500 | loss: 0.38359434066749204 | accuracy: 0.8319359756097561 \n",
      "Epoch 7 | Step 2501 | loss: 0.3828092763222844 | accuracy: 0.8324548192771084 \n",
      "Epoch 7 | Step 2502 | loss: 0.3829415841471581 | accuracy: 0.8322172619047619 \n",
      "Epoch 7 | Step 2503 | loss: 0.3837792694568634 | accuracy: 0.8319852941176471 \n",
      "Epoch 7 | Step 2504 | loss: 0.38262505760026533 | accuracy: 0.833030523255814 \n",
      "Epoch 7 | Step 2505 | loss: 0.3827506495618272 | accuracy: 0.8324353448275862 \n",
      "Epoch 7 | Step 2506 | loss: 0.38315590945157135 | accuracy: 0.8325639204545454 \n",
      "Epoch 7 | Step 2507 | loss: 0.3826537952664193 | accuracy: 0.832689606741573 \n",
      "Epoch 7 | Step 2508 | loss: 0.38324248790740967 | accuracy: 0.8321180555555555 \n",
      "Epoch 7 | Step 2509 | loss: 0.38246877507849053 | accuracy: 0.8322458791208791 \n",
      "Epoch 7 | Step 2510 | loss: 0.3852241304905518 | accuracy: 0.8310122282608695 \n",
      "Epoch 7 | Step 2511 | loss: 0.38485596320962395 | accuracy: 0.8311491935483871 \n",
      "Epoch 7 | Step 2512 | loss: 0.38422482920453904 | accuracy: 0.8314494680851063 \n",
      "Epoch 7 | Step 2513 | loss: 0.38315294133989436 | accuracy: 0.8320723684210526 \n",
      "Epoch 7 | Step 2514 | loss: 0.3827474129696687 | accuracy: 0.83203125 \n",
      "Epoch 7 | Step 2515 | loss: 0.381738002152787 | accuracy: 0.8329574742268041 \n",
      "Epoch 7 | Step 2516 | loss: 0.38346890344911694 | accuracy: 0.8314732142857143 \n",
      "Epoch 7 | Step 2517 | loss: 0.3827236926916874 | accuracy: 0.8312815656565656 \n",
      "Epoch 7 | Step 2518 | loss: 0.3824000382423401 | accuracy: 0.83140625 \n",
      "Epoch 7 | Step 2519 | loss: 0.38162646169709685 | accuracy: 0.8319925742574258 \n",
      "Epoch 7 | Step 2520 | loss: 0.3823189241629021 | accuracy: 0.8311887254901961 \n",
      "Epoch 7 | Step 2521 | loss: 0.38231044573691286 | accuracy: 0.8313106796116505 \n",
      "Epoch 7 | Step 2522 | loss: 0.3823828029517944 | accuracy: 0.8318810096153846 \n",
      "Epoch 7 | Step 2523 | loss: 0.38280009059678943 | accuracy: 0.8316964285714286 \n",
      "Epoch 7 | Step 2524 | loss: 0.38154714526432865 | accuracy: 0.8325471698113207 \n",
      "Epoch 7 | Step 2525 | loss: 0.38262507110555594 | accuracy: 0.8320677570093458 \n",
      "Epoch 7 | Step 2526 | loss: 0.38320492387369826 | accuracy: 0.8323206018518519 \n",
      "Epoch 7 | Step 2527 | loss: 0.3824941079824343 | accuracy: 0.8322821100917431 \n",
      "Epoch 7 | Step 2528 | loss: 0.3819893239573999 | accuracy: 0.8323863636363636 \n",
      "Epoch 7 | Step 2529 | loss: 0.38385573042942595 | accuracy: 0.8313626126126126 \n",
      "Epoch 7 | Step 2530 | loss: 0.38437267007040127 | accuracy: 0.8311941964285714 \n",
      "Epoch 7 | Step 2531 | loss: 0.38484539619061797 | accuracy: 0.8308904867256637 \n",
      "Epoch 7 | Step 2532 | loss: 0.3848691631043166 | accuracy: 0.8305921052631579 \n",
      "Epoch 7 | Step 2533 | loss: 0.3839857670276061 | accuracy: 0.83125 \n",
      "Epoch 7 | Step 2534 | loss: 0.3838782062561348 | accuracy: 0.8313577586206896 \n",
      "Epoch 7 | Step 2535 | loss: 0.3834334740526656 | accuracy: 0.8313301282051282 \n",
      "Epoch 7 | Step 2536 | loss: 0.3839281323855206 | accuracy: 0.830905720338983 \n",
      "Epoch 7 | Step 2537 | loss: 0.3846158286353119 | accuracy: 0.8304884453781513 \n",
      "Epoch 7 | Step 2538 | loss: 0.38431909245749313 | accuracy: 0.8307291666666666 \n",
      "Epoch 7 | Step 2539 | loss: 0.3836882019584829 | accuracy: 0.831095041322314 \n",
      "Epoch 7 | Step 2540 | loss: 0.3835045185978295 | accuracy: 0.8310706967213115 \n",
      "Epoch 7 | Step 2541 | loss: 0.38314293179570175 | accuracy: 0.8310467479674797 \n",
      "Epoch 7 | Step 2542 | loss: 0.38328739916605337 | accuracy: 0.8314012096774194 \n",
      "Epoch 7 | Step 2543 | loss: 0.382782900929451 | accuracy: 0.8315 \n",
      "Epoch 7 | Step 2544 | loss: 0.3827193030525768 | accuracy: 0.8314732142857143 \n",
      "Epoch 7 | Step 2545 | loss: 0.38388017746876546 | accuracy: 0.8307086614173228 \n",
      "Epoch 7 | Step 2546 | loss: 0.3840327371144667 | accuracy: 0.8306884765625 \n",
      "Epoch 7 | Step 2547 | loss: 0.38370732547238817 | accuracy: 0.8306686046511628 \n",
      "Epoch 7 | Step 2548 | loss: 0.3840942782851366 | accuracy: 0.8306490384615385 \n",
      "Epoch 7 | Step 2549 | loss: 0.38426138961133155 | accuracy: 0.8305104961832062 \n",
      "Epoch 7 | Step 2550 | loss: 0.38442905980980757 | accuracy: 0.830374053030303 \n",
      "Epoch 7 | Step 2551 | loss: 0.38384792130244405 | accuracy: 0.8307095864661654 \n",
      "Epoch 7 | Step 2552 | loss: 0.38399420111481825 | accuracy: 0.8303404850746269 \n",
      "Epoch 7 | Step 2553 | loss: 0.38420422971248624 | accuracy: 0.8305555555555556 \n",
      "Epoch 7 | Step 2554 | loss: 0.38392895230037327 | accuracy: 0.8308823529411765 \n",
      "Epoch 7 | Step 2555 | loss: 0.38378054240759274 | accuracy: 0.8310903284671532 \n",
      "Epoch 7 | Step 2556 | loss: 0.3839182031975276 | accuracy: 0.8310688405797102 \n",
      "Epoch 7 | Step 2557 | loss: 0.38390211568033095 | accuracy: 0.8309352517985612 \n",
      "Epoch 7 | Step 2558 | loss: 0.3831823980169637 | accuracy: 0.8314732142857144 \n",
      "Epoch 7 | Step 2559 | loss: 0.38284257656716286 | accuracy: 0.8315602836879433 \n",
      "Epoch 7 | Step 2560 | loss: 0.3826814811204521 | accuracy: 0.8315360915492959 \n",
      "Epoch 7 | Step 2561 | loss: 0.3826972522310444 | accuracy: 0.8316215034965035 \n",
      "Epoch 7 | Step 2562 | loss: 0.381855183487965 | accuracy: 0.8322482638888888 \n",
      "Epoch 7 | Step 2563 | loss: 0.3815599440500654 | accuracy: 0.8323275862068965 \n",
      "Epoch 7 | Step 2564 | loss: 0.38285722461057037 | accuracy: 0.8313356164383562 \n",
      "Epoch 7 | Step 2565 | loss: 0.38236439096278885 | accuracy: 0.8319515306122449 \n",
      "Epoch 7 | Step 2566 | loss: 0.38200585695134626 | accuracy: 0.8321368243243243 \n",
      "Epoch 7 | Step 2567 | loss: 0.381606357909689 | accuracy: 0.8326342281879194 \n",
      "Epoch 7 | Step 2568 | loss: 0.3814802858233452 | accuracy: 0.8325 \n",
      "Epoch 7 | Step 2569 | loss: 0.3813394449207167 | accuracy: 0.8326779801324503 \n",
      "Epoch 7 | Step 2570 | loss: 0.38194388082545055 | accuracy: 0.8324424342105263 \n",
      "Epoch 7 | Step 2571 | loss: 0.38192318360400357 | accuracy: 0.8327205882352942 \n",
      "Epoch 7 | Step 2572 | loss: 0.3818472599634877 | accuracy: 0.8327922077922078 \n",
      "Epoch 7 | Step 2573 | loss: 0.38139682133351605 | accuracy: 0.8328629032258065 \n",
      "Epoch 7 | Step 2574 | loss: 0.381089379485601 | accuracy: 0.8329326923076923 \n",
      "Epoch 7 | Step 2575 | loss: 0.380384825881879 | accuracy: 0.8333996815286624 \n",
      "Epoch 7 | Step 2576 | loss: 0.38005877720027026 | accuracy: 0.8337618670886076 \n",
      "Epoch 7 | Step 2577 | loss: 0.3796624120488856 | accuracy: 0.8341194968553459 \n",
      "Epoch 7 | Step 2578 | loss: 0.37969530364498494 | accuracy: 0.83427734375 \n",
      "Epoch 7 | Step 2579 | loss: 0.37933358651880894 | accuracy: 0.8342391304347826 \n",
      "Epoch 7 | Step 2580 | loss: 0.37984837692828827 | accuracy: 0.8342978395061729 \n",
      "Epoch 7 | Step 2581 | loss: 0.3795460766992686 | accuracy: 0.8344516871165644 \n",
      "Epoch 7 | Step 2582 | loss: 0.37913240483257826 | accuracy: 0.8345083841463414 \n",
      "Epoch 7 | Step 2583 | loss: 0.3789581191359144 | accuracy: 0.834280303030303 \n",
      "Epoch 7 | Step 2584 | loss: 0.37987012434077544 | accuracy: 0.8337725903614458 \n",
      "Epoch 7 | Step 2585 | loss: 0.3793629005462109 | accuracy: 0.8343937125748503 \n",
      "Epoch 7 | Step 2586 | loss: 0.37910929845557323 | accuracy: 0.8345424107142857 \n",
      "Epoch 7 | Step 2587 | loss: 0.3797853004473906 | accuracy: 0.834319526627219 \n",
      "Epoch 7 | Step 2588 | loss: 0.37899477736038323 | accuracy: 0.8346507352941176 \n",
      "Epoch 7 | Step 2589 | loss: 0.3791854912251757 | accuracy: 0.8342470760233918 \n",
      "Epoch 7 | Step 2590 | loss: 0.3795801377746948 | accuracy: 0.8341206395348837 \n",
      "Epoch 7 | Step 2591 | loss: 0.3785594436474618 | accuracy: 0.8346278901734104 \n",
      "Epoch 7 | Step 2592 | loss: 0.37905234406734334 | accuracy: 0.8343211206896551 \n",
      "Epoch 7 | Step 2593 | loss: 0.3784548796926226 | accuracy: 0.8348214285714286 \n",
      "Epoch 7 | Step 2594 | loss: 0.3784542976116592 | accuracy: 0.8348721590909091 \n",
      "Epoch 7 | Step 2595 | loss: 0.37850472095322474 | accuracy: 0.8346574858757062 \n",
      "Epoch 7 | Step 2596 | loss: 0.37837081176511356 | accuracy: 0.8347085674157303 \n",
      "Epoch 7 | Step 2597 | loss: 0.37888614425446066 | accuracy: 0.8344099162011173 \n",
      "Epoch 7 | Step 2598 | loss: 0.37923906528287465 | accuracy: 0.8341145833333333 \n",
      "Epoch 7 | Step 2599 | loss: 0.37921534058797424 | accuracy: 0.834167817679558 \n",
      "Epoch 7 | Step 2600 | loss: 0.3786411450786905 | accuracy: 0.8346497252747253 \n",
      "Epoch 7 | Step 2601 | loss: 0.37861966174808354 | accuracy: 0.8346140710382514 \n",
      "Epoch 7 | Step 2602 | loss: 0.3786739101228507 | accuracy: 0.8344938858695652 \n",
      "Epoch 7 | Step 2603 | loss: 0.3785033238900674 | accuracy: 0.8347128378378378 \n",
      "Epoch 7 | Step 2604 | loss: 0.37840340390641203 | accuracy: 0.8347614247311828 \n",
      "Epoch 7 | Step 2605 | loss: 0.37866998738783564 | accuracy: 0.834725935828877 \n",
      "Epoch 7 | Step 2606 | loss: 0.3784458038020641 | accuracy: 0.8348570478723404 \n",
      "Epoch 7 | Step 2607 | loss: 0.37803935578891207 | accuracy: 0.8349041005291006 \n",
      "Epoch 7 | Step 2608 | loss: 0.37767820060253143 | accuracy: 0.8352796052631579 \n",
      "Epoch 7 | Step 2609 | loss: 0.37778282165527344 | accuracy: 0.8350785340314136 \n",
      "Epoch 7 | Step 2610 | loss: 0.37780450641488034 | accuracy: 0.8350423177083334 \n",
      "Epoch 7 | Step 2611 | loss: 0.3775298961394809 | accuracy: 0.8350874352331606 \n",
      "Epoch 7 | Step 2612 | loss: 0.3774908618214204 | accuracy: 0.8350515463917526 \n",
      "Epoch 7 | Step 2613 | loss: 0.377544205616682 | accuracy: 0.835176282051282 \n",
      "Epoch 7 | Step 2614 | loss: 0.3772011650156002 | accuracy: 0.8352200255102041 \n",
      "Epoch 7 | Step 2615 | loss: 0.37704155771865455 | accuracy: 0.8351840101522843 \n",
      "Epoch 7 | Step 2616 | loss: 0.37669941873261426 | accuracy: 0.8352272727272727 \n",
      "Epoch 7 | Step 2617 | loss: 0.37673584016124206 | accuracy: 0.8350345477386935 \n",
      "Epoch 7 | Step 2618 | loss: 0.3766661748290062 | accuracy: 0.834921875 \n",
      "Epoch 7 | Step 2619 | loss: 0.3766353529187577 | accuracy: 0.8346548507462687 \n",
      "Epoch 7 | Step 2620 | loss: 0.37678388218478404 | accuracy: 0.8346225247524752 \n",
      "Epoch 7 | Step 2621 | loss: 0.376883101433956 | accuracy: 0.8347444581280788 \n",
      "Epoch 7 | Step 2622 | loss: 0.37723061661509905 | accuracy: 0.8341758578431373 \n",
      "Epoch 7 | Step 2623 | loss: 0.3772716530939428 | accuracy: 0.8342987804878049 \n",
      "Epoch 7 | Step 2624 | loss: 0.37742800055776987 | accuracy: 0.8342688106796117 \n",
      "Epoch 7 | Step 2625 | loss: 0.3774142275397904 | accuracy: 0.8342391304347826 \n",
      "Epoch 7 | Step 2626 | loss: 0.37710812515937364 | accuracy: 0.8343599759615384 \n",
      "Epoch 7 | Step 2627 | loss: 0.3769680630932584 | accuracy: 0.8344796650717703 \n",
      "Epoch 7 | Step 2628 | loss: 0.3764644666796639 | accuracy: 0.8347470238095238 \n",
      "Epoch 7 | Step 2629 | loss: 0.3764623556091887 | accuracy: 0.8347156398104265 \n",
      "Epoch 7 | Step 2630 | loss: 0.3764845277622061 | accuracy: 0.8348319575471698 \n",
      "Epoch 7 | Step 2631 | loss: 0.3764563696765004 | accuracy: 0.8349471830985915 \n",
      "Epoch 7 | Step 2632 | loss: 0.37657183603705646 | accuracy: 0.8351343457943925 \n",
      "Epoch 7 | Step 2633 | loss: 0.3768230072287626 | accuracy: 0.8348110465116279 \n",
      "Epoch 7 | Step 2634 | loss: 0.3769473379684819 | accuracy: 0.8349247685185185 \n",
      "Epoch 7 | Step 2635 | loss: 0.3772858555690484 | accuracy: 0.8346774193548387 \n",
      "Epoch 7 | Step 2636 | loss: 0.37770346094162094 | accuracy: 0.8341456422018348 \n",
      "Epoch 7 | Step 2637 | loss: 0.3778889353416826 | accuracy: 0.834046803652968 \n",
      "Epoch 7 | Step 2638 | loss: 0.37785638733343646 | accuracy: 0.8339488636363637 \n",
      "Epoch 7 | Step 2639 | loss: 0.3777068339591652 | accuracy: 0.8340639140271493 \n",
      "Epoch 7 | Step 2640 | loss: 0.37795015015043654 | accuracy: 0.8338963963963963 \n",
      "Epoch 7 | Step 2641 | loss: 0.37770078842415405 | accuracy: 0.8340106502242153 \n",
      "Epoch 7 | Step 2642 | loss: 0.3778138422806348 | accuracy: 0.8340541294642857 \n",
      "Epoch 7 | Step 2643 | loss: 0.37792427764998543 | accuracy: 0.8340277777777778 \n",
      "Epoch 7 | Step 2644 | loss: 0.3779079501344039 | accuracy: 0.8339325221238938 \n",
      "Epoch 7 | Step 2645 | loss: 0.37787971189368663 | accuracy: 0.8341822687224669 \n",
      "Epoch 7 | Step 2646 | loss: 0.37770345846289083 | accuracy: 0.8343612938596491 \n",
      "Epoch 7 | Step 2647 | loss: 0.37746981241817557 | accuracy: 0.8346069868995634 \n",
      "Epoch 7 | Step 2648 | loss: 0.3773142774467883 | accuracy: 0.834578804347826 \n",
      "Epoch 7 | Step 2649 | loss: 0.3768773650452172 | accuracy: 0.8347537878787878 \n",
      "Epoch 7 | Step 2650 | loss: 0.3766851634557905 | accuracy: 0.8348599137931034 \n",
      "Epoch 7 | Step 2651 | loss: 0.3766100624088566 | accuracy: 0.8350321888412017 \n",
      "Epoch 7 | Step 2652 | loss: 0.37710487345854443 | accuracy: 0.8348023504273504 \n",
      "Epoch 7 | Step 2653 | loss: 0.3766851105588548 | accuracy: 0.8348404255319148 \n",
      "Epoch 7 | Step 2654 | loss: 0.3763030269893549 | accuracy: 0.8350768008474576 \n",
      "Epoch 7 | Step 2655 | loss: 0.37615518932101094 | accuracy: 0.835245253164557 \n",
      "Epoch 7 | Step 2656 | loss: 0.3766812501835222 | accuracy: 0.8351496848739496 \n",
      "Epoch 7 | Step 2657 | loss: 0.37672721005383897 | accuracy: 0.8352510460251046 \n",
      "Epoch 7 | Step 2658 | loss: 0.3768164965013663 | accuracy: 0.8350911458333333 \n",
      "Epoch 7 | Step 2659 | loss: 0.3773187567089603 | accuracy: 0.8349325726141079 \n",
      "Epoch 7 | Step 2660 | loss: 0.3774519140316435 | accuracy: 0.8349044421487604 \n",
      "Epoch 7 | Step 2661 | loss: 0.37712838865601966 | accuracy: 0.835133744855967 \n",
      "Epoch 7 | Step 2662 | loss: 0.3768218916947724 | accuracy: 0.8354252049180327 \n",
      "Epoch 7 | Step 2663 | loss: 0.37645166479811376 | accuracy: 0.8356505102040817 \n",
      "Epoch 7 | Step 2664 | loss: 0.3762352444776675 | accuracy: 0.8359375 \n",
      "Epoch 7 | Step 2665 | loss: 0.3761568403678384 | accuracy: 0.8360323886639676 \n",
      "Epoch 7 | Step 2666 | loss: 0.376250131115798 | accuracy: 0.8358744959677419 \n",
      "Epoch 7 | Step 2667 | loss: 0.3765442098479673 | accuracy: 0.8357806224899599 \n",
      "Epoch 7 | Step 2668 | loss: 0.37632400846481323 | accuracy: 0.835875 \n",
      "Epoch 7 | Step 2669 | loss: 0.37670106906814876 | accuracy: 0.8358441235059761 \n",
      "Epoch 7 | Step 2670 | loss: 0.3772889616943541 | accuracy: 0.8357514880952381 \n",
      "Epoch 7 | Step 2671 | loss: 0.3770991422442108 | accuracy: 0.8358448616600791 \n",
      "Epoch 7 | Step 2672 | loss: 0.37714000797177866 | accuracy: 0.8358759842519685 \n",
      "Epoch 7 | Step 2673 | loss: 0.3769343297855527 | accuracy: 0.8359068627450981 \n",
      "Epoch 7 | Step 2674 | loss: 0.3767190194921568 | accuracy: 0.8360595703125 \n",
      "Epoch 7 | Step 2675 | loss: 0.37691348501216576 | accuracy: 0.8358463035019456 \n",
      "Epoch 7 | Step 2676 | loss: 0.3767263617857482 | accuracy: 0.8360586240310077 \n",
      "Epoch 7 | Step 2677 | loss: 0.376956698862282 | accuracy: 0.8358470077220077 \n",
      "Epoch 7 | Step 2678 | loss: 0.3771504819393158 | accuracy: 0.8357572115384615 \n",
      "Epoch 7 | Step 2679 | loss: 0.37740367422615434 | accuracy: 0.8357878352490421 \n",
      "Epoch 7 | Step 2680 | loss: 0.37779646383897036 | accuracy: 0.8354007633587787 \n",
      "Epoch 7 | Step 2681 | loss: 0.3780380400188069 | accuracy: 0.8353136882129277 \n",
      "Epoch 7 | Step 2682 | loss: 0.3780491864590934 | accuracy: 0.8351680871212122 \n",
      "Epoch 7 | Step 2683 | loss: 0.3780640943995062 | accuracy: 0.8350825471698113 \n",
      "Epoch 7 | Step 2684 | loss: 0.3781060101394367 | accuracy: 0.8347626879699248 \n",
      "Epoch 7 | Step 2685 | loss: 0.377816398380401 | accuracy: 0.8349133895131086 \n",
      "Epoch 7 | Step 2686 | loss: 0.3780605249218087 | accuracy: 0.8349463619402985 \n",
      "Epoch 7 | Step 2687 | loss: 0.37816303558509146 | accuracy: 0.8348629182156134 \n",
      "Epoch 7 | Step 2688 | loss: 0.37798674018294726 | accuracy: 0.8350694444444444 \n",
      "Epoch 7 | Step 2689 | loss: 0.37773843653967465 | accuracy: 0.8351591328413284 \n",
      "Epoch 7 | Step 2690 | loss: 0.3775651602841476 | accuracy: 0.8350183823529411 \n",
      "Epoch 7 | Step 2691 | loss: 0.37749600279462214 | accuracy: 0.8349931318681318 \n",
      "Epoch 7 | Step 2692 | loss: 0.37764143563100033 | accuracy: 0.8347399635036497 \n",
      "Epoch 7 | Step 2693 | loss: 0.37805597446181566 | accuracy: 0.8344886363636363 \n",
      "Epoch 7 | Step 2694 | loss: 0.37829820962919714 | accuracy: 0.8344655797101449 \n",
      "Epoch 7 | Step 2695 | loss: 0.37847162971427734 | accuracy: 0.8343862815884476 \n",
      "Epoch 7 | Step 2696 | loss: 0.3781308706501406 | accuracy: 0.8345323741007195 \n",
      "Epoch 7 | Step 2697 | loss: 0.37876332949139324 | accuracy: 0.834285394265233 \n",
      "Epoch 7 | Step 2698 | loss: 0.37845315464905344 | accuracy: 0.8344308035714286 \n",
      "Epoch 7 | Step 2699 | loss: 0.3787433736264919 | accuracy: 0.8341859430604983 \n",
      "Epoch 7 | Step 2700 | loss: 0.3784160849684521 | accuracy: 0.8342752659574469 \n",
      "Epoch 7 | Step 2701 | loss: 0.37839395903024586 | accuracy: 0.834308745583039 \n",
      "Epoch 7 | Step 2702 | loss: 0.3780604015353701 | accuracy: 0.8345070422535213 \n",
      "Epoch 7 | Step 2703 | loss: 0.37806535269084746 | accuracy: 0.8343750000000002 \n",
      "Epoch 7 | Step 2704 | loss: 0.3776178889341289 | accuracy: 0.8345716783216786 \n",
      "Epoch 7 | Step 2705 | loss: 0.3774375563506882 | accuracy: 0.8346036585365856 \n",
      "Epoch 7 | Step 2706 | loss: 0.37705156320912986 | accuracy: 0.8348524305555558 \n",
      "Epoch 7 | Step 2707 | loss: 0.3772350169176875 | accuracy: 0.8348291522491351 \n",
      "Epoch 7 | Step 2708 | loss: 0.37709824370926837 | accuracy: 0.8349676724137933 \n",
      "Epoch 7 | Step 2709 | loss: 0.37728700205632515 | accuracy: 0.8348367697594503 \n",
      "Epoch 7 | Step 2710 | loss: 0.3771196405773295 | accuracy: 0.8349208047945207 \n",
      "Epoch 7 | Step 2711 | loss: 0.37749644595201526 | accuracy: 0.8346309726962459 \n",
      "Epoch 7 | Step 2712 | loss: 0.3773389102853076 | accuracy: 0.8347151360544218 \n",
      "Epoch 7 | Step 2713 | loss: 0.3771524949599122 | accuracy: 0.8348516949152543 \n",
      "Epoch 7 | Step 2714 | loss: 0.3772999554671147 | accuracy: 0.8348289695945947 \n",
      "Epoch 7 | Step 2715 | loss: 0.3770895344440385 | accuracy: 0.8349642255892258 \n",
      "Epoch 7 | Step 2716 | loss: 0.3773034468993246 | accuracy: 0.8347839765100673 \n",
      "Epoch 7 | Step 2717 | loss: 0.3772845461615752 | accuracy: 0.8345526755852845 \n",
      "Epoch 7 | Step 2718 | loss: 0.37714852164189033 | accuracy: 0.8345312500000002 \n",
      "Epoch 7 | Step 2719 | loss: 0.3770975616089135 | accuracy: 0.8345618770764122 \n",
      "Epoch 7 | Step 2720 | loss: 0.3770390557532281 | accuracy: 0.8346440397350995 \n",
      "Epoch 7 | Step 2721 | loss: 0.3768988243817499 | accuracy: 0.8347256600660068 \n",
      "Epoch 7 | Step 2722 | loss: 0.37704647391250284 | accuracy: 0.8346011513157897 \n",
      "Epoch 7 | Step 2723 | loss: 0.3768190512891678 | accuracy: 0.8347336065573774 \n",
      "Epoch 7 | Step 2724 | loss: 0.37679457489181994 | accuracy: 0.8348141339869285 \n",
      "Epoch 7 | Step 2725 | loss: 0.37695542375893887 | accuracy: 0.8347414495114011 \n",
      "Epoch 7 | Step 2726 | loss: 0.3767076394968221 | accuracy: 0.83492288961039 \n",
      "Epoch 7 | Step 2727 | loss: 0.3763904281225794 | accuracy: 0.83495145631068 \n",
      "Epoch 7 | Step 2728 | loss: 0.37657748047382633 | accuracy: 0.8348286290322584 \n",
      "Epoch 7 | Step 2729 | loss: 0.3765528128269788 | accuracy: 0.8350080385852093 \n",
      "Epoch 7 | Step 2730 | loss: 0.3764780984284026 | accuracy: 0.8348858173076926 \n",
      "Epoch 7 | Step 2731 | loss: 0.3764514563182676 | accuracy: 0.834914137380192 \n",
      "Epoch 7 | Step 2732 | loss: 0.37677317088956325 | accuracy: 0.8347929936305736 \n",
      "Epoch 7 | Step 2733 | loss: 0.3774567226568862 | accuracy: 0.8344742063492067 \n",
      "Epoch 7 | Step 2734 | loss: 0.3775366771070267 | accuracy: 0.8343552215189877 \n",
      "Epoch 7 | Step 2735 | loss: 0.3769786690687912 | accuracy: 0.8347298895899057 \n",
      "Epoch 7 | Step 2736 | loss: 0.37718081296240047 | accuracy: 0.8345617138364784 \n",
      "Epoch 7 | Step 2737 | loss: 0.3772293501139439 | accuracy: 0.8344925548589345 \n",
      "Epoch 7 | Step 2738 | loss: 0.3771129699423913 | accuracy: 0.8345703125000004 \n",
      "Epoch 7 | Step 2739 | loss: 0.37709008960337687 | accuracy: 0.8345989096573212 \n",
      "Epoch 7 | Step 2740 | loss: 0.37739091343391046 | accuracy: 0.834530279503106 \n",
      "Epoch 7 | Step 2741 | loss: 0.37721571833725714 | accuracy: 0.8346071981424152 \n",
      "Epoch 7 | Step 2742 | loss: 0.37693456762734784 | accuracy: 0.8347800925925929 \n",
      "Epoch 7 | Step 2743 | loss: 0.37718104124069246 | accuracy: 0.8346634615384619 \n",
      "Epoch 7 | Step 2744 | loss: 0.3771225793595697 | accuracy: 0.8346434049079758 \n",
      "Epoch 7 | Step 2745 | loss: 0.3772791209388584 | accuracy: 0.8345279051987771 \n",
      "Epoch 7 | Step 2746 | loss: 0.37752404927117095 | accuracy: 0.8343654725609759 \n",
      "Epoch 7 | Step 2747 | loss: 0.37772994037819513 | accuracy: 0.834299012158055 \n",
      "Epoch 7 | Step 2748 | loss: 0.37769274702577904 | accuracy: 0.8343276515151519 \n",
      "Epoch 7 | Step 2749 | loss: 0.37784804597361954 | accuracy: 0.8342145015105744 \n",
      "Epoch 7 | Step 2750 | loss: 0.37783725290413384 | accuracy: 0.8341961596385545 \n",
      "Epoch 7 | Step 2751 | loss: 0.3779984247219099 | accuracy: 0.8341310060060063 \n",
      "Epoch 7 | Step 2752 | loss: 0.37788345223058506 | accuracy: 0.8343001497005992 \n",
      "Epoch 7 | Step 2753 | loss: 0.37777056080191906 | accuracy: 0.8343283582089556 \n",
      "Epoch 7 | Step 2754 | loss: 0.37769562121303335 | accuracy: 0.8343563988095242 \n",
      "Epoch 7 | Step 2755 | loss: 0.37765970799618753 | accuracy: 0.834384272997033 \n",
      "Epoch 7 | Step 2756 | loss: 0.3777423138625526 | accuracy: 0.8345044378698229 \n",
      "Epoch 7 | Step 2757 | loss: 0.37743616956876824 | accuracy: 0.8346699852507378 \n",
      "Epoch 7 | Step 2758 | loss: 0.3773018035818552 | accuracy: 0.8346966911764709 \n",
      "Epoch 7 | Step 2759 | loss: 0.3775138177654963 | accuracy: 0.834494134897361 \n",
      "Epoch 7 | Step 2760 | loss: 0.37745222824010266 | accuracy: 0.8344298245614038 \n",
      "Epoch 7 | Step 2761 | loss: 0.37732469766202575 | accuracy: 0.8345936588921287 \n",
      "Epoch 7 | Step 2762 | loss: 0.37702361078456426 | accuracy: 0.8347111191860468 \n",
      "Epoch 7 | Step 2763 | loss: 0.3770493846008746 | accuracy: 0.8346920289855075 \n",
      "Epoch 7 | Step 2764 | loss: 0.3771495648546718 | accuracy: 0.8346730491329483 \n",
      "Epoch 7 | Step 2765 | loss: 0.3768800301235763 | accuracy: 0.8347892651296833 \n",
      "Epoch 7 | Step 2766 | loss: 0.3773865567884229 | accuracy: 0.8345456178160923 \n",
      "Epoch 7 | Step 2767 | loss: 0.3771508683618642 | accuracy: 0.8344824498567338 \n",
      "Epoch 7 | Step 2768 | loss: 0.3769740586621424 | accuracy: 0.8345982142857146 \n",
      "Epoch 7 | Step 2769 | loss: 0.3769130723768493 | accuracy: 0.834757834757835 \n",
      "Epoch 7 | Step 2770 | loss: 0.3768693775107918 | accuracy: 0.834827769886364 \n",
      "Epoch 7 | Step 2771 | loss: 0.3768604236520387 | accuracy: 0.8348087818696887 \n",
      "Epoch 7 | Step 2772 | loss: 0.3767357115018169 | accuracy: 0.834878177966102 \n",
      "Epoch 7 | Step 2773 | loss: 0.3767757326784271 | accuracy: 0.8349471830985918 \n",
      "Epoch 7 | Step 2774 | loss: 0.3766359341111079 | accuracy: 0.835015800561798 \n",
      "Epoch 7 | Step 2775 | loss: 0.3762052564644349 | accuracy: 0.835259103641457 \n",
      "Epoch 7 | Step 2776 | loss: 0.3761207482585031 | accuracy: 0.8354137569832405 \n",
      "Epoch 7 | Step 2777 | loss: 0.37599871629293946 | accuracy: 0.8353934540389976 \n",
      "Epoch 7 | Step 2778 | loss: 0.3760509256273511 | accuracy: 0.8352864583333337 \n",
      "Epoch 7 | Step 2779 | loss: 0.37584147959369735 | accuracy: 0.8353099030470917 \n",
      "Epoch 7 | Step 2780 | loss: 0.3759867610276078 | accuracy: 0.8352900552486191 \n",
      "Epoch 7 | Step 2781 | loss: 0.376273945056046 | accuracy: 0.835141184573003 \n",
      "Epoch 7 | Step 2782 | loss: 0.3760770324740439 | accuracy: 0.8351648351648355 \n",
      "Epoch 7 | Step 2783 | loss: 0.37623793576678216 | accuracy: 0.8351027397260277 \n",
      "Epoch 7 | Step 2784 | loss: 0.3760941467079963 | accuracy: 0.8352117486338801 \n",
      "Epoch 7 | Step 2785 | loss: 0.37611705848404137 | accuracy: 0.8352350136239786 \n",
      "Epoch 7 | Step 2786 | loss: 0.37606606320680513 | accuracy: 0.8353855298913047 \n",
      "Epoch 7 | Step 2787 | loss: 0.3761032689312289 | accuracy: 0.8354928861788621 \n",
      "Epoch 7 | Step 2788 | loss: 0.376406246463995 | accuracy: 0.8353040540540544 \n",
      "Epoch 7 | Step 2789 | loss: 0.37674375368417784 | accuracy: 0.8351583557951485 \n",
      "Epoch 7 | Step 2790 | loss: 0.37692697278113807 | accuracy: 0.8350974462365595 \n",
      "Epoch 7 | Step 2791 | loss: 0.37695974443137836 | accuracy: 0.8351206434316357 \n",
      "Epoch 7 | Step 2792 | loss: 0.37684873156847193 | accuracy: 0.8351854946524068 \n",
      "Epoch 7 | Step 2793 | loss: 0.37644484337170947 | accuracy: 0.8354166666666669 \n",
      "Epoch 7 | Step 2794 | loss: 0.376178888168107 | accuracy: 0.8355634973404258 \n",
      "Epoch 7 | Step 2795 | loss: 0.37588455079405025 | accuracy: 0.8357509946949605 \n",
      "Epoch 7 | Step 2796 | loss: 0.37612075882929374 | accuracy: 0.8356068121693124 \n",
      "Epoch 7 | Step 2797 | loss: 0.3761274302697751 | accuracy: 0.8356695250659634 \n",
      "Epoch 7 | Step 2798 | loss: 0.37587541380995226 | accuracy: 0.8356907894736845 \n",
      "Epoch 7 | Step 2799 | loss: 0.3757502268462046 | accuracy: 0.8357939632545934 \n",
      "Epoch 7 | Step 2800 | loss: 0.3754101854344316 | accuracy: 0.8360193062827228 \n",
      "Epoch 7 | Step 2801 | loss: 0.3754804677502608 | accuracy: 0.8359171018276765 \n",
      "Epoch 7 | Step 2802 | loss: 0.3757059983909133 | accuracy: 0.835734049479167 \n",
      "Epoch 7 | Step 2803 | loss: 0.3757422493649771 | accuracy: 0.835714285714286 \n",
      "Epoch 7 | Step 2804 | loss: 0.3759460632974005 | accuracy: 0.8356541450777205 \n",
      "Epoch 7 | Step 2805 | loss: 0.37600642504310144 | accuracy: 0.8356346899224809 \n",
      "Epoch 7 | Step 2806 | loss: 0.3761409727722102 | accuracy: 0.8356153350515467 \n",
      "Epoch 7 | Step 2807 | loss: 0.37633455274650585 | accuracy: 0.8354354113110543 \n",
      "Epoch 7 | Step 2808 | loss: 0.3763484500921693 | accuracy: 0.8352964743589747 \n",
      "Epoch 7 | Step 2809 | loss: 0.3763439947991728 | accuracy: 0.8353180946291563 \n",
      "Epoch 7 | Step 2810 | loss: 0.3762880575900178 | accuracy: 0.8352598852040819 \n",
      "Epoch 7 | Step 2811 | loss: 0.3762805366334117 | accuracy: 0.835440521628499 \n",
      "Epoch 7 | Step 2812 | loss: 0.37635108140216894 | accuracy: 0.8354219543147211 \n",
      "Epoch 7 | Step 2813 | loss: 0.3763717883749856 | accuracy: 0.8355617088607598 \n",
      "Epoch 7 | Step 2814 | loss: 0.3761629873905522 | accuracy: 0.8355823863636367 \n",
      "Epoch 7 | Step 2815 | loss: 0.3759593765441359 | accuracy: 0.8356029596977332 \n",
      "Epoch 7 | Step 2816 | loss: 0.37612628906815526 | accuracy: 0.835466394472362 \n",
      "Epoch 7 | Step 2817 | loss: 0.3761605339540279 | accuracy: 0.8354479949874689 \n",
      "Epoch 7 | Step 2818 | loss: 0.37634340226650265 | accuracy: 0.8353515625000003 \n",
      "Epoch 7 | Step 2819 | loss: 0.37626210531391735 | accuracy: 0.8354894014962596 \n",
      "Epoch 7 | Step 2820 | loss: 0.3767169116444852 | accuracy: 0.8352378731343286 \n",
      "Epoch 7 | Step 2821 | loss: 0.3765469714814324 | accuracy: 0.8353044514916378 \n",
      "Validation | Epoch 7 | Step 2821 | accuracy: 0.8219027912074869 \n",
      "Epoch 8 | Step 2822 | loss: 0.3344220519065857 | accuracy: 0.875 \n",
      "Epoch 8 | Step 2823 | loss: 0.35685840249061584 | accuracy: 0.828125 \n",
      "Epoch 8 | Step 2824 | loss: 0.34088770548502606 | accuracy: 0.84375 \n",
      "Epoch 8 | Step 2825 | loss: 0.3647090271115303 | accuracy: 0.84375 \n",
      "Epoch 8 | Step 2826 | loss: 0.36546987295150757 | accuracy: 0.8375 \n",
      "Epoch 8 | Step 2827 | loss: 0.37159107625484467 | accuracy: 0.8359375 \n",
      "Epoch 8 | Step 2828 | loss: 0.3783606972013201 | accuracy: 0.8325892857142857 \n",
      "Epoch 8 | Step 2829 | loss: 0.3842807188630104 | accuracy: 0.8359375 \n",
      "Epoch 8 | Step 2830 | loss: 0.377186119556427 | accuracy: 0.8368055555555556 \n",
      "Epoch 8 | Step 2831 | loss: 0.3824063718318939 | accuracy: 0.8359375 \n",
      "Epoch 8 | Step 2832 | loss: 0.37817314538088714 | accuracy: 0.8352272727272727 \n",
      "Epoch 8 | Step 2833 | loss: 0.3803725888331731 | accuracy: 0.8333333333333334 \n",
      "Epoch 8 | Step 2834 | loss: 0.373268010524603 | accuracy: 0.8353365384615384 \n",
      "Epoch 8 | Step 2835 | loss: 0.37042346596717834 | accuracy: 0.8359375 \n",
      "Epoch 8 | Step 2836 | loss: 0.36095624963442485 | accuracy: 0.8416666666666667 \n",
      "Epoch 8 | Step 2837 | loss: 0.3542592488229275 | accuracy: 0.84765625 \n",
      "Epoch 8 | Step 2838 | loss: 0.3516999132492963 | accuracy: 0.8511029411764706 \n",
      "Epoch 8 | Step 2839 | loss: 0.35090772807598114 | accuracy: 0.8480902777777778 \n",
      "Epoch 8 | Step 2840 | loss: 0.35231805788843257 | accuracy: 0.8486842105263158 \n",
      "Epoch 8 | Step 2841 | loss: 0.3505312785506248 | accuracy: 0.8484375 \n",
      "Epoch 8 | Step 2842 | loss: 0.3475032505534944 | accuracy: 0.8489583333333334 \n",
      "Epoch 8 | Step 2843 | loss: 0.3462116623466665 | accuracy: 0.8494318181818182 \n",
      "Epoch 8 | Step 2844 | loss: 0.3450056586576545 | accuracy: 0.8491847826086957 \n",
      "Epoch 8 | Step 2845 | loss: 0.34105776995420456 | accuracy: 0.8515625 \n",
      "Epoch 8 | Step 2846 | loss: 0.33986436724662783 | accuracy: 0.851875 \n",
      "Epoch 8 | Step 2847 | loss: 0.340712220622943 | accuracy: 0.8515625 \n",
      "Epoch 8 | Step 2848 | loss: 0.3432570155020113 | accuracy: 0.8495370370370371 \n",
      "Epoch 8 | Step 2849 | loss: 0.3408691169960158 | accuracy: 0.8521205357142857 \n",
      "Epoch 8 | Step 2850 | loss: 0.33935974178643064 | accuracy: 0.853448275862069 \n",
      "Epoch 8 | Step 2851 | loss: 0.3405153900384903 | accuracy: 0.8526041666666667 \n",
      "Epoch 8 | Step 2852 | loss: 0.33947396951337017 | accuracy: 0.8543346774193549 \n",
      "Epoch 8 | Step 2853 | loss: 0.3408414479345083 | accuracy: 0.8544921875 \n",
      "Epoch 8 | Step 2854 | loss: 0.3447130114743204 | accuracy: 0.8527462121212122 \n",
      "Epoch 8 | Step 2855 | loss: 0.3451806745108436 | accuracy: 0.8524816176470589 \n",
      "Epoch 8 | Step 2856 | loss: 0.3437458566256932 | accuracy: 0.8526785714285714 \n",
      "Epoch 8 | Step 2857 | loss: 0.34440328925848007 | accuracy: 0.8515625 \n",
      "Epoch 8 | Step 2858 | loss: 0.3443564764551214 | accuracy: 0.8509290540540541 \n",
      "Epoch 8 | Step 2859 | loss: 0.3436307993374373 | accuracy: 0.8523848684210527 \n",
      "Epoch 8 | Step 2860 | loss: 0.34449976682662964 | accuracy: 0.8521634615384616 \n",
      "Epoch 8 | Step 2861 | loss: 0.3441320464015007 | accuracy: 0.85234375 \n",
      "Epoch 8 | Step 2862 | loss: 0.34292514222424203 | accuracy: 0.8536585365853658 \n",
      "Epoch 8 | Step 2863 | loss: 0.3463824327502932 | accuracy: 0.8530505952380952 \n",
      "Epoch 8 | Step 2864 | loss: 0.34600211783897045 | accuracy: 0.8531976744186046 \n",
      "Epoch 8 | Step 2865 | loss: 0.34650332209738816 | accuracy: 0.8526278409090909 \n",
      "Epoch 8 | Step 2866 | loss: 0.35074355668491786 | accuracy: 0.8496527777777778 \n",
      "Epoch 8 | Step 2867 | loss: 0.3529373355533766 | accuracy: 0.8488451086956522 \n",
      "Epoch 8 | Step 2868 | loss: 0.35212325542531114 | accuracy: 0.8494015957446809 \n",
      "Epoch 8 | Step 2869 | loss: 0.3545555497209231 | accuracy: 0.8489583333333334 \n",
      "Epoch 8 | Step 2870 | loss: 0.35306478945576414 | accuracy: 0.8494897959183674 \n",
      "Epoch 8 | Step 2871 | loss: 0.35505921483039854 | accuracy: 0.84875 \n",
      "Epoch 8 | Step 2872 | loss: 0.35728692307191734 | accuracy: 0.8465073529411765 \n",
      "Epoch 8 | Step 2873 | loss: 0.35821447005638707 | accuracy: 0.8458533653846154 \n",
      "Epoch 8 | Step 2874 | loss: 0.35690430087863273 | accuracy: 0.8461084905660378 \n",
      "Epoch 8 | Step 2875 | loss: 0.35628106472668825 | accuracy: 0.8460648148148148 \n",
      "Epoch 8 | Step 2876 | loss: 0.35524339134042915 | accuracy: 0.8465909090909091 \n",
      "Epoch 8 | Step 2877 | loss: 0.3555930581476007 | accuracy: 0.8468191964285714 \n",
      "Epoch 8 | Step 2878 | loss: 0.3558682213749802 | accuracy: 0.8473135964912281 \n",
      "Epoch 8 | Step 2879 | loss: 0.3560544802197095 | accuracy: 0.8464439655172413 \n",
      "Epoch 8 | Step 2880 | loss: 0.3560548763153917 | accuracy: 0.8463983050847458 \n",
      "Epoch 8 | Step 2881 | loss: 0.3570459380745888 | accuracy: 0.8463541666666666 \n",
      "Epoch 8 | Step 2882 | loss: 0.3570270909637701 | accuracy: 0.8460553278688525 \n",
      "Epoch 8 | Step 2883 | loss: 0.35671233602108493 | accuracy: 0.8460181451612904 \n",
      "Epoch 8 | Step 2884 | loss: 0.3569714942621806 | accuracy: 0.8462301587301587 \n",
      "Epoch 8 | Step 2885 | loss: 0.35478450055234134 | accuracy: 0.84765625 \n",
      "Epoch 8 | Step 2886 | loss: 0.35411833639328294 | accuracy: 0.8475961538461538 \n",
      "Epoch 8 | Step 2887 | loss: 0.3521683026443828 | accuracy: 0.8482481060606061 \n",
      "Epoch 8 | Step 2888 | loss: 0.3519224662389328 | accuracy: 0.8479477611940298 \n",
      "Epoch 8 | Step 2889 | loss: 0.35152708870523114 | accuracy: 0.8481158088235294 \n",
      "Epoch 8 | Step 2890 | loss: 0.3529910389064015 | accuracy: 0.8471467391304348 \n",
      "Epoch 8 | Step 2891 | loss: 0.35511750025408606 | accuracy: 0.8455357142857143 \n",
      "Epoch 8 | Step 2892 | loss: 0.35426844341654173 | accuracy: 0.8459507042253521 \n",
      "Epoch 8 | Step 2893 | loss: 0.35407325211498475 | accuracy: 0.8461371527777778 \n",
      "Epoch 8 | Step 2894 | loss: 0.3542372706818254 | accuracy: 0.8458904109589042 \n",
      "Epoch 8 | Step 2895 | loss: 0.3550193261455845 | accuracy: 0.8458614864864866 \n",
      "Epoch 8 | Step 2896 | loss: 0.35578706820805867 | accuracy: 0.8460416666666668 \n",
      "Epoch 8 | Step 2897 | loss: 0.3551804854681617 | accuracy: 0.846422697368421 \n",
      "Epoch 8 | Step 2898 | loss: 0.35513013794824677 | accuracy: 0.8465909090909091 \n",
      "Epoch 8 | Step 2899 | loss: 0.3564170870261315 | accuracy: 0.8461538461538461 \n",
      "Epoch 8 | Step 2900 | loss: 0.35558724139310144 | accuracy: 0.8475079113924051 \n",
      "Epoch 8 | Step 2901 | loss: 0.355604362115264 | accuracy: 0.847265625 \n",
      "Epoch 8 | Step 2902 | loss: 0.35538551284943104 | accuracy: 0.8474151234567902 \n",
      "Epoch 8 | Step 2903 | loss: 0.35392033890253166 | accuracy: 0.8479420731707317 \n",
      "Epoch 8 | Step 2904 | loss: 0.3532483723149243 | accuracy: 0.8482680722891566 \n",
      "Epoch 8 | Step 2905 | loss: 0.3537026528446448 | accuracy: 0.8485863095238095 \n",
      "Epoch 8 | Step 2906 | loss: 0.3545876837828581 | accuracy: 0.8481617647058823 \n",
      "Epoch 8 | Step 2907 | loss: 0.35366197606158817 | accuracy: 0.8490188953488372 \n",
      "Epoch 8 | Step 2908 | loss: 0.35385434740576255 | accuracy: 0.8487787356321839 \n",
      "Epoch 8 | Step 2909 | loss: 0.35445788248696114 | accuracy: 0.8494318181818182 \n",
      "Epoch 8 | Step 2910 | loss: 0.3538158289837034 | accuracy: 0.8497191011235955 \n",
      "Epoch 8 | Step 2911 | loss: 0.35464129497607555 | accuracy: 0.8489583333333334 \n",
      "Epoch 8 | Step 2912 | loss: 0.3538820643673887 | accuracy: 0.8490728021978022 \n",
      "Epoch 8 | Step 2913 | loss: 0.3566893240355928 | accuracy: 0.84765625 \n",
      "Epoch 8 | Step 2914 | loss: 0.3562413349907886 | accuracy: 0.8479502688172043 \n",
      "Epoch 8 | Step 2915 | loss: 0.35576859164111163 | accuracy: 0.847905585106383 \n",
      "Epoch 8 | Step 2916 | loss: 0.35457243307640685 | accuracy: 0.8486842105263158 \n",
      "Epoch 8 | Step 2917 | loss: 0.3539642972561221 | accuracy: 0.8486328125 \n",
      "Epoch 8 | Step 2918 | loss: 0.35302890345607846 | accuracy: 0.8495489690721649 \n",
      "Epoch 8 | Step 2919 | loss: 0.3548953577267881 | accuracy: 0.8486926020408163 \n",
      "Epoch 8 | Step 2920 | loss: 0.35441757828900317 | accuracy: 0.8484848484848485 \n",
      "Epoch 8 | Step 2921 | loss: 0.3541050438582898 | accuracy: 0.8484375 \n",
      "Epoch 8 | Step 2922 | loss: 0.35338704435542084 | accuracy: 0.848855198019802 \n",
      "Epoch 8 | Step 2923 | loss: 0.35399613295700044 | accuracy: 0.8480392156862745 \n",
      "Epoch 8 | Step 2924 | loss: 0.35398967072223003 | accuracy: 0.847997572815534 \n",
      "Epoch 8 | Step 2925 | loss: 0.3540306264677874 | accuracy: 0.8484074519230769 \n",
      "Epoch 8 | Step 2926 | loss: 0.3545972746042979 | accuracy: 0.8476190476190476 \n",
      "Epoch 8 | Step 2927 | loss: 0.35364657401476274 | accuracy: 0.8483195754716981 \n",
      "Epoch 8 | Step 2928 | loss: 0.35476022527039613 | accuracy: 0.8475467289719626 \n",
      "Epoch 8 | Step 2929 | loss: 0.3554872739370223 | accuracy: 0.84765625 \n",
      "Epoch 8 | Step 2930 | loss: 0.3550781844132538 | accuracy: 0.8480504587155964 \n",
      "Epoch 8 | Step 2931 | loss: 0.35479817918755796 | accuracy: 0.8478693181818182 \n",
      "Epoch 8 | Step 2932 | loss: 0.3564821990492108 | accuracy: 0.8469876126126126 \n",
      "Epoch 8 | Step 2933 | loss: 0.3572684525113021 | accuracy: 0.8468191964285714 \n",
      "Epoch 8 | Step 2934 | loss: 0.3579315805593424 | accuracy: 0.8463772123893806 \n",
      "Epoch 8 | Step 2935 | loss: 0.3579319635765595 | accuracy: 0.8463541666666666 \n",
      "Epoch 8 | Step 2936 | loss: 0.3569846288017605 | accuracy: 0.846875 \n",
      "Epoch 8 | Step 2937 | loss: 0.35682180215572495 | accuracy: 0.8469827586206896 \n",
      "Epoch 8 | Step 2938 | loss: 0.3563909110350487 | accuracy: 0.8469551282051282 \n",
      "Epoch 8 | Step 2939 | loss: 0.3565515085297116 | accuracy: 0.8470603813559322 \n",
      "Epoch 8 | Step 2940 | loss: 0.35742355044148555 | accuracy: 0.8463760504201681 \n",
      "Epoch 8 | Step 2941 | loss: 0.35701324219505 | accuracy: 0.8467447916666667 \n",
      "Epoch 8 | Step 2942 | loss: 0.35611522062258294 | accuracy: 0.8471074380165289 \n",
      "Epoch 8 | Step 2943 | loss: 0.35579879911708057 | accuracy: 0.8473360655737705 \n",
      "Epoch 8 | Step 2944 | loss: 0.35574646172969326 | accuracy: 0.8471798780487805 \n",
      "Epoch 8 | Step 2945 | loss: 0.3559864919272162 | accuracy: 0.8472782258064516 \n",
      "Epoch 8 | Step 2946 | loss: 0.35564283597469337 | accuracy: 0.847125 \n",
      "Epoch 8 | Step 2947 | loss: 0.3556744374689602 | accuracy: 0.8468501984126984 \n",
      "Epoch 8 | Step 2948 | loss: 0.3569620560238681 | accuracy: 0.8465797244094488 \n",
      "Epoch 8 | Step 2949 | loss: 0.35706627939362084 | accuracy: 0.8465576171875 \n",
      "Epoch 8 | Step 2950 | loss: 0.35662255118521613 | accuracy: 0.8467781007751938 \n",
      "Epoch 8 | Step 2951 | loss: 0.3568896501110151 | accuracy: 0.8467548076923077 \n",
      "Epoch 8 | Step 2952 | loss: 0.35698667452990557 | accuracy: 0.8467318702290076 \n",
      "Epoch 8 | Step 2953 | loss: 0.35697573299209284 | accuracy: 0.8464725378787878 \n",
      "Epoch 8 | Step 2954 | loss: 0.3564481689293582 | accuracy: 0.846687030075188 \n",
      "Epoch 8 | Step 2955 | loss: 0.3565271093106982 | accuracy: 0.8465485074626866 \n",
      "Epoch 8 | Step 2956 | loss: 0.3568487696073674 | accuracy: 0.8466435185185185 \n",
      "Epoch 8 | Step 2957 | loss: 0.35672012070084325 | accuracy: 0.8468520220588235 \n",
      "Epoch 8 | Step 2958 | loss: 0.3565907198799788 | accuracy: 0.8473996350364964 \n",
      "Epoch 8 | Step 2959 | loss: 0.3565524184833403 | accuracy: 0.847259963768116 \n",
      "Epoch 8 | Step 2960 | loss: 0.35669129583046594 | accuracy: 0.8470098920863309 \n",
      "Epoch 8 | Step 2961 | loss: 0.35597279039876806 | accuracy: 0.8474330357142857 \n",
      "Epoch 8 | Step 2962 | loss: 0.3557550599600407 | accuracy: 0.8476285460992907 \n",
      "Epoch 8 | Step 2963 | loss: 0.3555625417912511 | accuracy: 0.8479313380281689 \n",
      "Epoch 8 | Step 2964 | loss: 0.3555246448808617 | accuracy: 0.8480113636363635 \n",
      "Epoch 8 | Step 2965 | loss: 0.35482255793693995 | accuracy: 0.848415798611111 \n",
      "Epoch 8 | Step 2966 | loss: 0.35465437101906744 | accuracy: 0.8484913793103447 \n",
      "Epoch 8 | Step 2967 | loss: 0.3559470667618595 | accuracy: 0.8474957191780821 \n",
      "Epoch 8 | Step 2968 | loss: 0.35548385136386973 | accuracy: 0.848001700680272 \n",
      "Epoch 8 | Step 2969 | loss: 0.35522618597826444 | accuracy: 0.8480785472972971 \n",
      "Epoch 8 | Step 2970 | loss: 0.3549750970314013 | accuracy: 0.8481543624161072 \n",
      "Epoch 8 | Step 2971 | loss: 0.35473309208949405 | accuracy: 0.8480208333333331 \n",
      "Epoch 8 | Step 2972 | loss: 0.35459694216977683 | accuracy: 0.848199503311258 \n",
      "Epoch 8 | Step 2973 | loss: 0.35517799628800467 | accuracy: 0.8480674342105261 \n",
      "Epoch 8 | Step 2974 | loss: 0.3552016246747347 | accuracy: 0.8479370915032678 \n",
      "Epoch 8 | Step 2975 | loss: 0.3551835472901146 | accuracy: 0.8479099025974024 \n",
      "Epoch 8 | Step 2976 | loss: 0.354744329664015 | accuracy: 0.8478830645161288 \n",
      "Epoch 8 | Step 2977 | loss: 0.354281690544807 | accuracy: 0.8479567307692306 \n",
      "Epoch 8 | Step 2978 | loss: 0.3536711182374104 | accuracy: 0.8483280254777068 \n",
      "Epoch 8 | Step 2979 | loss: 0.353367336471624 | accuracy: 0.8484968354430378 \n",
      "Epoch 8 | Step 2980 | loss: 0.3530903879389073 | accuracy: 0.8485652515723269 \n",
      "Epoch 8 | Step 2981 | loss: 0.3532239655964077 | accuracy: 0.8487304687499998 \n",
      "Epoch 8 | Step 2982 | loss: 0.35298182884728685 | accuracy: 0.8486995341614905 \n",
      "Epoch 8 | Step 2983 | loss: 0.3533273239010646 | accuracy: 0.8484760802469135 \n",
      "Epoch 8 | Step 2984 | loss: 0.35308207918895534 | accuracy: 0.8484470858895704 \n",
      "Epoch 8 | Step 2985 | loss: 0.35265422875924807 | accuracy: 0.8485137195121949 \n",
      "Epoch 8 | Step 2986 | loss: 0.35257813180937914 | accuracy: 0.8484848484848483 \n",
      "Epoch 8 | Step 2987 | loss: 0.3536439603531217 | accuracy: 0.84789156626506 \n",
      "Epoch 8 | Step 2988 | loss: 0.3530106893378103 | accuracy: 0.8484281437125747 \n",
      "Epoch 8 | Step 2989 | loss: 0.35272862363074503 | accuracy: 0.8484933035714284 \n",
      "Epoch 8 | Step 2990 | loss: 0.3535504306738193 | accuracy: 0.8481878698224851 \n",
      "Epoch 8 | Step 2991 | loss: 0.3529053327791831 | accuracy: 0.8484374999999998 \n",
      "Epoch 8 | Step 2992 | loss: 0.35315238636488105 | accuracy: 0.8481359649122805 \n",
      "Epoch 8 | Step 2993 | loss: 0.35359575018979783 | accuracy: 0.8479287790697673 \n",
      "Epoch 8 | Step 2994 | loss: 0.35249588401675913 | accuracy: 0.8485368497109825 \n",
      "Epoch 8 | Step 2995 | loss: 0.3529260537918957 | accuracy: 0.8484195402298849 \n",
      "Epoch 8 | Step 2996 | loss: 0.35228853719575065 | accuracy: 0.8486607142857141 \n",
      "Epoch 8 | Step 2997 | loss: 0.35229491916569794 | accuracy: 0.8488103693181817 \n",
      "Epoch 8 | Step 2998 | loss: 0.3525404150539872 | accuracy: 0.8485169491525422 \n",
      "Epoch 8 | Step 2999 | loss: 0.3525324180889665 | accuracy: 0.8485779494382021 \n",
      "Epoch 8 | Step 3000 | loss: 0.3528274820503575 | accuracy: 0.8484636871508379 \n",
      "Epoch 8 | Step 3001 | loss: 0.3532433531350559 | accuracy: 0.8480902777777776 \n",
      "Epoch 8 | Step 3002 | loss: 0.35309316571904803 | accuracy: 0.8481526243093921 \n",
      "Epoch 8 | Step 3003 | loss: 0.352590310540828 | accuracy: 0.8485576923076922 \n",
      "Epoch 8 | Step 3004 | loss: 0.352655535838643 | accuracy: 0.8485314207650272 \n",
      "Epoch 8 | Step 3005 | loss: 0.3527148725545924 | accuracy: 0.8485054347826085 \n",
      "Epoch 8 | Step 3006 | loss: 0.35260905188483155 | accuracy: 0.8486486486486485 \n",
      "Epoch 8 | Step 3007 | loss: 0.3523525143823315 | accuracy: 0.8487063172043009 \n",
      "Epoch 8 | Step 3008 | loss: 0.3525178880296288 | accuracy: 0.8488469251336896 \n",
      "Epoch 8 | Step 3009 | loss: 0.3524197988370631 | accuracy: 0.8488198138297871 \n",
      "Epoch 8 | Step 3010 | loss: 0.35199825788931866 | accuracy: 0.8490410052910051 \n",
      "Epoch 8 | Step 3011 | loss: 0.3515398632538945 | accuracy: 0.849424342105263 \n",
      "Epoch 8 | Step 3012 | loss: 0.35166436589825206 | accuracy: 0.8491492146596857 \n",
      "Epoch 8 | Step 3013 | loss: 0.3516892924283941 | accuracy: 0.8490397135416665 \n",
      "Epoch 8 | Step 3014 | loss: 0.3515084140350163 | accuracy: 0.848931347150259 \n",
      "Epoch 8 | Step 3015 | loss: 0.3513810692988719 | accuracy: 0.848985180412371 \n",
      "Epoch 8 | Step 3016 | loss: 0.3514835275136507 | accuracy: 0.8490384615384614 \n",
      "Epoch 8 | Step 3017 | loss: 0.35119424197746774 | accuracy: 0.8491709183673468 \n",
      "Epoch 8 | Step 3018 | loss: 0.35109670271123117 | accuracy: 0.8490640862944161 \n",
      "Epoch 8 | Step 3019 | loss: 0.3508178150714045 | accuracy: 0.8491161616161614 \n",
      "Epoch 8 | Step 3020 | loss: 0.35077919927074674 | accuracy: 0.8490891959798994 \n",
      "Epoch 8 | Step 3021 | loss: 0.35072616294026365 | accuracy: 0.8489062499999999 \n",
      "Epoch 8 | Step 3022 | loss: 0.350588538456912 | accuracy: 0.8488028606965172 \n",
      "Epoch 8 | Step 3023 | loss: 0.35077613960988446 | accuracy: 0.8487778465346534 \n",
      "Epoch 8 | Step 3024 | loss: 0.3508283194943601 | accuracy: 0.8489070197044334 \n",
      "Epoch 8 | Step 3025 | loss: 0.35114681706124656 | accuracy: 0.8485753676470587 \n",
      "Epoch 8 | Step 3026 | loss: 0.3510833849267261 | accuracy: 0.8487804878048779 \n",
      "Epoch 8 | Step 3027 | loss: 0.35133646197110696 | accuracy: 0.8486043689320387 \n",
      "Epoch 8 | Step 3028 | loss: 0.351284434829933 | accuracy: 0.848580917874396 \n",
      "Epoch 8 | Step 3029 | loss: 0.35106835886836046 | accuracy: 0.8485576923076922 \n",
      "Epoch 8 | Step 3030 | loss: 0.3510250156861172 | accuracy: 0.8486094497607655 \n",
      "Epoch 8 | Step 3031 | loss: 0.3505614957639149 | accuracy: 0.8487351190476189 \n",
      "Epoch 8 | Step 3032 | loss: 0.3504905978932764 | accuracy: 0.8487855450236965 \n",
      "Epoch 8 | Step 3033 | loss: 0.3505942896008491 | accuracy: 0.84876179245283 \n",
      "Epoch 8 | Step 3034 | loss: 0.3504217986209851 | accuracy: 0.848738262910798 \n",
      "Epoch 8 | Step 3035 | loss: 0.35058565646688505 | accuracy: 0.8487149532710279 \n",
      "Epoch 8 | Step 3036 | loss: 0.35083220573358753 | accuracy: 0.8483284883720928 \n",
      "Epoch 8 | Step 3037 | loss: 0.3510505856463202 | accuracy: 0.8484519675925924 \n",
      "Epoch 8 | Step 3038 | loss: 0.35135395392294844 | accuracy: 0.8483582949308754 \n",
      "Epoch 8 | Step 3039 | loss: 0.35166963265029655 | accuracy: 0.8481938073394494 \n",
      "Epoch 8 | Step 3040 | loss: 0.35173605185121154 | accuracy: 0.8481021689497715 \n",
      "Epoch 8 | Step 3041 | loss: 0.35176048888401545 | accuracy: 0.8480113636363635 \n",
      "Epoch 8 | Step 3042 | loss: 0.35167468147040487 | accuracy: 0.8481334841628958 \n",
      "Epoch 8 | Step 3043 | loss: 0.3517391974324578 | accuracy: 0.8481841216216215 \n",
      "Epoch 8 | Step 3044 | loss: 0.35148757549144755 | accuracy: 0.8482343049327353 \n",
      "Epoch 8 | Step 3045 | loss: 0.35160164628177876 | accuracy: 0.8482142857142856 \n",
      "Epoch 8 | Step 3046 | loss: 0.3516719510820176 | accuracy: 0.8481944444444444 \n",
      "Epoch 8 | Step 3047 | loss: 0.35166333022370794 | accuracy: 0.8481056415929202 \n",
      "Epoch 8 | Step 3048 | loss: 0.351810775270546 | accuracy: 0.8482929515418501 \n",
      "Epoch 8 | Step 3049 | loss: 0.35159193554468315 | accuracy: 0.8483415570175438 \n",
      "Epoch 8 | Step 3050 | loss: 0.3512800760144229 | accuracy: 0.8484579694323143 \n",
      "Epoch 8 | Step 3051 | loss: 0.35112361959789107 | accuracy: 0.8485054347826085 \n",
      "Epoch 8 | Step 3052 | loss: 0.3506896601610885 | accuracy: 0.8486877705627704 \n",
      "Epoch 8 | Step 3053 | loss: 0.3503882954346722 | accuracy: 0.8488011853448275 \n",
      "Epoch 8 | Step 3054 | loss: 0.350231304956608 | accuracy: 0.8489136266094419 \n",
      "Epoch 8 | Step 3055 | loss: 0.35074951136723537 | accuracy: 0.8487580128205127 \n",
      "Epoch 8 | Step 3056 | loss: 0.35032676737359225 | accuracy: 0.8489361702127658 \n",
      "Epoch 8 | Step 3057 | loss: 0.3500093283542131 | accuracy: 0.8491128177966101 \n",
      "Epoch 8 | Step 3058 | loss: 0.3499724998252804 | accuracy: 0.849222046413502 \n",
      "Epoch 8 | Step 3059 | loss: 0.35057125960578434 | accuracy: 0.8490677521008402 \n",
      "Epoch 8 | Step 3060 | loss: 0.3506758021011512 | accuracy: 0.8490455020920501 \n",
      "Epoch 8 | Step 3061 | loss: 0.35069485952456786 | accuracy: 0.8489583333333333 \n",
      "Epoch 8 | Step 3062 | loss: 0.35113606388638124 | accuracy: 0.8487422199170124 \n",
      "Epoch 8 | Step 3063 | loss: 0.351408419899704 | accuracy: 0.8486570247933883 \n",
      "Epoch 8 | Step 3064 | loss: 0.3510637418232827 | accuracy: 0.8488297325102879 \n",
      "Epoch 8 | Step 3065 | loss: 0.35067765353644476 | accuracy: 0.8490650614754097 \n",
      "Epoch 8 | Step 3066 | loss: 0.35039002445279327 | accuracy: 0.8492346938775509 \n",
      "Epoch 8 | Step 3067 | loss: 0.35023601825644324 | accuracy: 0.849466463414634 \n",
      "Epoch 8 | Step 3068 | loss: 0.35008579540831836 | accuracy: 0.8496330971659918 \n",
      "Epoch 8 | Step 3069 | loss: 0.3500646208563158 | accuracy: 0.8495463709677418 \n",
      "Epoch 8 | Step 3070 | loss: 0.35036618570726075 | accuracy: 0.8494603413654618 \n",
      "Epoch 8 | Step 3071 | loss: 0.3501892765760421 | accuracy: 0.8494374999999998 \n",
      "Epoch 8 | Step 3072 | loss: 0.35043692173235913 | accuracy: 0.8492903386454183 \n",
      "Epoch 8 | Step 3073 | loss: 0.35109697790845984 | accuracy: 0.8489583333333333 \n",
      "Epoch 8 | Step 3074 | loss: 0.3509674268984511 | accuracy: 0.8489995059288536 \n",
      "Epoch 8 | Step 3075 | loss: 0.35096815263661807 | accuracy: 0.8490403543307086 \n",
      "Epoch 8 | Step 3076 | loss: 0.3508940487515692 | accuracy: 0.8490196078431371 \n",
      "Epoch 8 | Step 3077 | loss: 0.3507659840397536 | accuracy: 0.8491210937499999 \n",
      "Epoch 8 | Step 3078 | loss: 0.3509558899625266 | accuracy: 0.8489178015564202 \n",
      "Epoch 8 | Step 3079 | loss: 0.35080719848935915 | accuracy: 0.849079457364341 \n",
      "Epoch 8 | Step 3080 | loss: 0.3510340667369282 | accuracy: 0.848998552123552 \n",
      "Epoch 8 | Step 3081 | loss: 0.3512100664468911 | accuracy: 0.8487379807692307 \n",
      "Epoch 8 | Step 3082 | loss: 0.3515436376420017 | accuracy: 0.8485991379310344 \n",
      "Epoch 8 | Step 3083 | loss: 0.35194563183165684 | accuracy: 0.8482228053435114 \n",
      "Epoch 8 | Step 3084 | loss: 0.35224713141473973 | accuracy: 0.8482652091254752 \n",
      "Epoch 8 | Step 3085 | loss: 0.3522214263000271 | accuracy: 0.8481297348484848 \n",
      "Epoch 8 | Step 3086 | loss: 0.35228397328898586 | accuracy: 0.8479363207547169 \n",
      "Epoch 8 | Step 3087 | loss: 0.3523295237157577 | accuracy: 0.8477443609022556 \n",
      "Epoch 8 | Step 3088 | loss: 0.35204447275690365 | accuracy: 0.8478464419475654 \n",
      "Epoch 8 | Step 3089 | loss: 0.3523609355759264 | accuracy: 0.8477145522388059 \n",
      "Epoch 8 | Step 3090 | loss: 0.3524327364552863 | accuracy: 0.8476417286245352 \n",
      "Epoch 8 | Step 3091 | loss: 0.3522962561360112 | accuracy: 0.8476851851851851 \n",
      "Epoch 8 | Step 3092 | loss: 0.35210820724603437 | accuracy: 0.8477283210332103 \n",
      "Epoch 8 | Step 3093 | loss: 0.3519151082591099 | accuracy: 0.8477711397058822 \n",
      "Epoch 8 | Step 3094 | loss: 0.35194784708512133 | accuracy: 0.8476991758241758 \n",
      "Epoch 8 | Step 3095 | loss: 0.35203349699069114 | accuracy: 0.8474566605839415 \n",
      "Epoch 8 | Step 3096 | loss: 0.3525391960144043 | accuracy: 0.8471590909090908 \n",
      "Epoch 8 | Step 3097 | loss: 0.3528369467543519 | accuracy: 0.8469202898550724 \n",
      "Epoch 8 | Step 3098 | loss: 0.35308529226788543 | accuracy: 0.8468524368231046 \n",
      "Epoch 8 | Step 3099 | loss: 0.35285371842144203 | accuracy: 0.8468974820143884 \n",
      "Epoch 8 | Step 3100 | loss: 0.3534255089725645 | accuracy: 0.846774193548387 \n",
      "Epoch 8 | Step 3101 | loss: 0.35309010467359 | accuracy: 0.8470424107142857 \n",
      "Epoch 8 | Step 3102 | loss: 0.35343198483524796 | accuracy: 0.8468638790035586 \n",
      "Epoch 8 | Step 3103 | loss: 0.35310727674910364 | accuracy: 0.8469636524822695 \n",
      "Epoch 8 | Step 3104 | loss: 0.3531619971716783 | accuracy: 0.846952296819788 \n",
      "Epoch 8 | Step 3105 | loss: 0.3528561772594989 | accuracy: 0.8472711267605634 \n",
      "Epoch 8 | Step 3106 | loss: 0.35286818261732134 | accuracy: 0.847094298245614 \n",
      "Epoch 8 | Step 3107 | loss: 0.35248219487550375 | accuracy: 0.8472465034965035 \n",
      "Epoch 8 | Step 3108 | loss: 0.35231959736721025 | accuracy: 0.8472343205574913 \n",
      "Epoch 8 | Step 3109 | loss: 0.35189710728203255 | accuracy: 0.8473849826388888 \n",
      "Epoch 8 | Step 3110 | loss: 0.3521566753465824 | accuracy: 0.847318339100346 \n",
      "Epoch 8 | Step 3111 | loss: 0.35213039543094304 | accuracy: 0.8474137931034482 \n",
      "Epoch 8 | Step 3112 | loss: 0.35224238811284814 | accuracy: 0.8472938144329896 \n",
      "Epoch 8 | Step 3113 | loss: 0.3520779281548441 | accuracy: 0.8473886986301369 \n",
      "Epoch 8 | Step 3114 | loss: 0.35241814313691633 | accuracy: 0.8471629692832764 \n",
      "Epoch 8 | Step 3115 | loss: 0.35228893834920155 | accuracy: 0.8470982142857142 \n",
      "Epoch 8 | Step 3116 | loss: 0.3521198788436793 | accuracy: 0.8471927966101694 \n",
      "Epoch 8 | Step 3117 | loss: 0.3524028530495392 | accuracy: 0.847022804054054 \n",
      "Epoch 8 | Step 3118 | loss: 0.35211389449108327 | accuracy: 0.8471170033670032 \n",
      "Epoch 8 | Step 3119 | loss: 0.3523074417006249 | accuracy: 0.8470532718120805 \n",
      "Epoch 8 | Step 3120 | loss: 0.3521817130687643 | accuracy: 0.8470422240802674 \n",
      "Epoch 8 | Step 3121 | loss: 0.3521109230816364 | accuracy: 0.8470312499999998 \n",
      "Epoch 8 | Step 3122 | loss: 0.3520496112860714 | accuracy: 0.8470722591362124 \n",
      "Epoch 8 | Step 3123 | loss: 0.3519198474603772 | accuracy: 0.8472682119205296 \n",
      "Epoch 8 | Step 3124 | loss: 0.35184748697005475 | accuracy: 0.8473597359735972 \n",
      "Epoch 8 | Step 3125 | loss: 0.35195076088175953 | accuracy: 0.8471936677631577 \n",
      "Epoch 8 | Step 3126 | loss: 0.3516530717494057 | accuracy: 0.847387295081967 \n",
      "Epoch 8 | Step 3127 | loss: 0.3516317315253556 | accuracy: 0.8474264705882351 \n",
      "Epoch 8 | Step 3128 | loss: 0.35186686641036097 | accuracy: 0.8473127035830617 \n",
      "Epoch 8 | Step 3129 | loss: 0.351649478029508 | accuracy: 0.8474533279220777 \n",
      "Epoch 8 | Step 3130 | loss: 0.35136907815354534 | accuracy: 0.8475930420711972 \n",
      "Epoch 8 | Step 3131 | loss: 0.35155526529396725 | accuracy: 0.8475302419354837 \n",
      "Epoch 8 | Step 3132 | loss: 0.35152210189790195 | accuracy: 0.8477692926045014 \n",
      "Epoch 8 | Step 3133 | loss: 0.3514422723211538 | accuracy: 0.847706330128205 \n",
      "Epoch 8 | Step 3134 | loss: 0.3513957530069655 | accuracy: 0.8476437699680509 \n",
      "Epoch 8 | Step 3135 | loss: 0.3517223543896796 | accuracy: 0.8474820859872609 \n",
      "Epoch 8 | Step 3136 | loss: 0.35232391494607157 | accuracy: 0.8471726190476189 \n",
      "Epoch 8 | Step 3137 | loss: 0.3524057836377921 | accuracy: 0.8471123417721517 \n",
      "Epoch 8 | Step 3138 | loss: 0.3518613622955718 | accuracy: 0.847446766561514 \n",
      "Epoch 8 | Step 3139 | loss: 0.3519794696344518 | accuracy: 0.8474351415094338 \n",
      "Epoch 8 | Step 3140 | loss: 0.35203716728754536 | accuracy: 0.84737460815047 \n",
      "Epoch 8 | Step 3141 | loss: 0.3518930540420113 | accuracy: 0.8474121093749998 \n",
      "Epoch 8 | Step 3142 | loss: 0.35182701018740437 | accuracy: 0.8474007009345793 \n",
      "Epoch 8 | Step 3143 | loss: 0.3521889446314816 | accuracy: 0.8473408385093166 \n",
      "Epoch 8 | Step 3144 | loss: 0.3519654818363601 | accuracy: 0.8474264705882352 \n",
      "Epoch 8 | Step 3145 | loss: 0.3517316997419167 | accuracy: 0.8476562499999998 \n",
      "Epoch 8 | Step 3146 | loss: 0.35197036468065684 | accuracy: 0.8475480769230768 \n",
      "Epoch 8 | Step 3147 | loss: 0.3519990306141916 | accuracy: 0.8475843558282207 \n",
      "Epoch 8 | Step 3148 | loss: 0.3520619090908527 | accuracy: 0.847524847094801 \n",
      "Epoch 8 | Step 3149 | loss: 0.35238347847650675 | accuracy: 0.84741806402439 \n",
      "Epoch 8 | Step 3150 | loss: 0.35259760540307095 | accuracy: 0.847359422492401 \n",
      "Epoch 8 | Step 3151 | loss: 0.3525737801284499 | accuracy: 0.8473958333333331 \n",
      "Epoch 8 | Step 3152 | loss: 0.3527389459559563 | accuracy: 0.8472432024169183 \n",
      "Epoch 8 | Step 3153 | loss: 0.352666994713875 | accuracy: 0.8473738704819276 \n",
      "Epoch 8 | Step 3154 | loss: 0.3527665378990114 | accuracy: 0.8473160660660659 \n",
      "Epoch 8 | Step 3155 | loss: 0.35267400955725553 | accuracy: 0.847445733532934 \n",
      "Epoch 8 | Step 3156 | loss: 0.3525373270262531 | accuracy: 0.8474813432835819 \n",
      "Epoch 8 | Step 3157 | loss: 0.3524995358394723 | accuracy: 0.8474237351190474 \n",
      "Epoch 8 | Step 3158 | loss: 0.3524662628548787 | accuracy: 0.8473664688427298 \n",
      "Epoch 8 | Step 3159 | loss: 0.3525723433177145 | accuracy: 0.8474944526627217 \n",
      "Epoch 8 | Step 3160 | loss: 0.35226908356918324 | accuracy: 0.8475755899705013 \n",
      "Epoch 8 | Step 3161 | loss: 0.35211405539337304 | accuracy: 0.8477022058823528 \n",
      "Epoch 8 | Step 3162 | loss: 0.3522658986517409 | accuracy: 0.8475073313782989 \n",
      "Epoch 8 | Step 3163 | loss: 0.3521480765520479 | accuracy: 0.8475877192982455 \n",
      "Epoch 8 | Step 3164 | loss: 0.3520261876871563 | accuracy: 0.8477587463556849 \n",
      "Epoch 8 | Step 3165 | loss: 0.3517020126848025 | accuracy: 0.8478833575581394 \n",
      "Epoch 8 | Step 3166 | loss: 0.3518994074368821 | accuracy: 0.8478260869565216 \n",
      "Epoch 8 | Step 3167 | loss: 0.35196016741798086 | accuracy: 0.8478594653179189 \n",
      "Epoch 8 | Step 3168 | loss: 0.3517216825777239 | accuracy: 0.8479827089337174 \n",
      "Epoch 8 | Step 3169 | loss: 0.35211916957264644 | accuracy: 0.8477909482758619 \n",
      "Epoch 8 | Step 3170 | loss: 0.35186894622265763 | accuracy: 0.8478689111747849 \n",
      "Epoch 8 | Step 3171 | loss: 0.3517468188915932 | accuracy: 0.8479017857142855 \n",
      "Epoch 8 | Step 3172 | loss: 0.35162244856017927 | accuracy: 0.8480235042735041 \n",
      "Epoch 8 | Step 3173 | loss: 0.35153845524076693 | accuracy: 0.8481001420454544 \n",
      "Epoch 8 | Step 3174 | loss: 0.35161647196363105 | accuracy: 0.8479992917847023 \n",
      "Epoch 8 | Step 3175 | loss: 0.35146829919458095 | accuracy: 0.8480755649717513 \n",
      "Epoch 8 | Step 3176 | loss: 0.35157796803494556 | accuracy: 0.848107394366197 \n",
      "Epoch 8 | Step 3177 | loss: 0.3514404522485276 | accuracy: 0.8480951544943819 \n",
      "Epoch 8 | Step 3178 | loss: 0.35113091954664005 | accuracy: 0.8482580532212883 \n",
      "Epoch 8 | Step 3179 | loss: 0.35109418189392394 | accuracy: 0.8483327513966479 \n",
      "Epoch 8 | Step 3180 | loss: 0.35100426597515505 | accuracy: 0.8483199860724232 \n",
      "Epoch 8 | Step 3181 | loss: 0.3511040860580072 | accuracy: 0.8482638888888887 \n",
      "Epoch 8 | Step 3182 | loss: 0.35084012728648817 | accuracy: 0.8484677977839333 \n",
      "Epoch 8 | Step 3183 | loss: 0.3510079248010781 | accuracy: 0.8484979281767954 \n",
      "Epoch 8 | Step 3184 | loss: 0.351220563587735 | accuracy: 0.8483557162534434 \n",
      "Epoch 8 | Step 3185 | loss: 0.35099242046311646 | accuracy: 0.8484718406593404 \n",
      "Epoch 8 | Step 3186 | loss: 0.35107890065402186 | accuracy: 0.8484160958904108 \n",
      "Epoch 8 | Step 3187 | loss: 0.3509491038778439 | accuracy: 0.8484887295081965 \n",
      "Epoch 8 | Step 3188 | loss: 0.35098264855649863 | accuracy: 0.8485609673024521 \n",
      "Epoch 8 | Step 3189 | loss: 0.3510556617832701 | accuracy: 0.8486752717391303 \n",
      "Epoch 8 | Step 3190 | loss: 0.35107647258091734 | accuracy: 0.8487466124661245 \n",
      "Epoch 8 | Step 3191 | loss: 0.35135213217219774 | accuracy: 0.8486064189189187 \n",
      "Epoch 8 | Step 3192 | loss: 0.3517539118820765 | accuracy: 0.8485090970350403 \n",
      "Epoch 8 | Step 3193 | loss: 0.3519101173326532 | accuracy: 0.8484543010752686 \n",
      "Epoch 8 | Step 3194 | loss: 0.35196611293199537 | accuracy: 0.8483997989276137 \n",
      "Epoch 8 | Step 3195 | loss: 0.3518550890811623 | accuracy: 0.8484291443850266 \n",
      "Epoch 8 | Step 3196 | loss: 0.3514660035371779 | accuracy: 0.8486666666666666 \n",
      "Epoch 8 | Step 3197 | loss: 0.35120170028444286 | accuracy: 0.8487782579787233 \n",
      "Epoch 8 | Step 3198 | loss: 0.350885436571245 | accuracy: 0.8489721485411139 \n",
      "Epoch 8 | Step 3199 | loss: 0.35113981480478595 | accuracy: 0.8488756613756612 \n",
      "Epoch 8 | Step 3200 | loss: 0.3511274939398022 | accuracy: 0.8489033641160948 \n",
      "Epoch 8 | Step 3201 | loss: 0.3509359237786969 | accuracy: 0.8489309210526315 \n",
      "Epoch 8 | Step 3202 | loss: 0.3508195660011035 | accuracy: 0.8490813648293962 \n",
      "Epoch 8 | Step 3203 | loss: 0.35048389442616096 | accuracy: 0.8493128272251308 \n",
      "Epoch 8 | Step 3204 | loss: 0.3505011439790301 | accuracy: 0.8492167101827675 \n",
      "Epoch 8 | Step 3205 | loss: 0.35070607919866825 | accuracy: 0.8491210937499999 \n",
      "Epoch 8 | Step 3206 | loss: 0.35072411716758417 | accuracy: 0.8490665584415583 \n",
      "Epoch 8 | Step 3207 | loss: 0.35094016126400435 | accuracy: 0.848931347150259 \n",
      "Epoch 8 | Step 3208 | loss: 0.35096711197564756 | accuracy: 0.848877583979328 \n",
      "Epoch 8 | Step 3209 | loss: 0.3511787331135001 | accuracy: 0.8487838273195875 \n",
      "Epoch 8 | Step 3210 | loss: 0.35143308008238083 | accuracy: 0.848529884318766 \n",
      "Epoch 8 | Step 3211 | loss: 0.3514913990711553 | accuracy: 0.8483974358974358 \n",
      "Epoch 8 | Step 3212 | loss: 0.3514964300805649 | accuracy: 0.8484255115089513 \n",
      "Epoch 8 | Step 3213 | loss: 0.35142355974839645 | accuracy: 0.8484135841836733 \n",
      "Epoch 8 | Step 3214 | loss: 0.35134317568543594 | accuracy: 0.8486005089058523 \n",
      "Epoch 8 | Step 3215 | loss: 0.35141447980694346 | accuracy: 0.8485485406091369 \n",
      "Epoch 8 | Step 3216 | loss: 0.3514245229431344 | accuracy: 0.8486155063291138 \n",
      "Epoch 8 | Step 3217 | loss: 0.3512649647515228 | accuracy: 0.8486426767676766 \n",
      "Epoch 8 | Step 3218 | loss: 0.35100979427396484 | accuracy: 0.848748425692695 \n",
      "Epoch 8 | Step 3219 | loss: 0.35116996346556345 | accuracy: 0.848657349246231 \n",
      "Epoch 8 | Step 3220 | loss: 0.35120683374410866 | accuracy: 0.8486842105263156 \n",
      "Epoch 8 | Step 3221 | loss: 0.35141155328601587 | accuracy: 0.8486328124999999 \n",
      "Epoch 8 | Step 3222 | loss: 0.3513229361124465 | accuracy: 0.8487375311720697 \n",
      "Epoch 8 | Step 3223 | loss: 0.35182001960663045 | accuracy: 0.8484919154228854 \n",
      "Epoch 8 | Step 3224 | loss: 0.3517250954439266 | accuracy: 0.8485256053377912 \n",
      "Validation | Epoch 8 | Step 3224 | accuracy: 0.8273684531450272 \n",
      "Epoch 9 | Step 3225 | loss: 0.284379780292511 | accuracy: 0.859375 \n",
      "Epoch 9 | Step 3226 | loss: 0.3334675431251526 | accuracy: 0.8359375 \n",
      "Epoch 9 | Step 3227 | loss: 0.3231537143389384 | accuracy: 0.8541666666666666 \n",
      "Epoch 9 | Step 3228 | loss: 0.3460616245865822 | accuracy: 0.8515625 \n",
      "Epoch 9 | Step 3229 | loss: 0.3504551827907562 | accuracy: 0.84375 \n",
      "Epoch 9 | Step 3230 | loss: 0.35639845828215283 | accuracy: 0.8385416666666666 \n",
      "Epoch 9 | Step 3231 | loss: 0.3628458295549665 | accuracy: 0.8370535714285714 \n",
      "Epoch 9 | Step 3232 | loss: 0.36965011060237885 | accuracy: 0.833984375 \n",
      "Epoch 9 | Step 3233 | loss: 0.3596680661042531 | accuracy: 0.8402777777777778 \n",
      "Epoch 9 | Step 3234 | loss: 0.36521284878253935 | accuracy: 0.840625 \n",
      "Epoch 9 | Step 3235 | loss: 0.3601871837269176 | accuracy: 0.84375 \n",
      "Epoch 9 | Step 3236 | loss: 0.36000701288382214 | accuracy: 0.84375 \n",
      "Epoch 9 | Step 3237 | loss: 0.3534738994561709 | accuracy: 0.8461538461538461 \n",
      "Epoch 9 | Step 3238 | loss: 0.35091056142534527 | accuracy: 0.8470982142857143 \n",
      "Epoch 9 | Step 3239 | loss: 0.34149343967437745 | accuracy: 0.8520833333333333 \n",
      "Epoch 9 | Step 3240 | loss: 0.33547307550907135 | accuracy: 0.8583984375 \n",
      "Epoch 9 | Step 3241 | loss: 0.33277008463354674 | accuracy: 0.8612132352941176 \n",
      "Epoch 9 | Step 3242 | loss: 0.3323519163661533 | accuracy: 0.8585069444444444 \n",
      "Epoch 9 | Step 3243 | loss: 0.3343919531295174 | accuracy: 0.8569078947368421 \n",
      "Epoch 9 | Step 3244 | loss: 0.3324263751506805 | accuracy: 0.8578125 \n",
      "Epoch 9 | Step 3245 | loss: 0.3276814733232771 | accuracy: 0.8601190476190477 \n",
      "Epoch 9 | Step 3246 | loss: 0.3257434896447442 | accuracy: 0.8600852272727273 \n",
      "Epoch 9 | Step 3247 | loss: 0.32485476784084155 | accuracy: 0.860733695652174 \n",
      "Epoch 9 | Step 3248 | loss: 0.32097632872561616 | accuracy: 0.8626302083333334 \n",
      "Epoch 9 | Step 3249 | loss: 0.31884232103824617 | accuracy: 0.86375 \n",
      "Epoch 9 | Step 3250 | loss: 0.3189546437217639 | accuracy: 0.8629807692307693 \n",
      "Epoch 9 | Step 3251 | loss: 0.32189005337379595 | accuracy: 0.8611111111111112 \n",
      "Epoch 9 | Step 3252 | loss: 0.3185282562460218 | accuracy: 0.8638392857142857 \n",
      "Epoch 9 | Step 3253 | loss: 0.31716072251056804 | accuracy: 0.8647629310344828 \n",
      "Epoch 9 | Step 3254 | loss: 0.31781229078769685 | accuracy: 0.8640625 \n",
      "Epoch 9 | Step 3255 | loss: 0.31683397004681246 | accuracy: 0.8654233870967742 \n",
      "Epoch 9 | Step 3256 | loss: 0.31793901696801186 | accuracy: 0.86572265625 \n",
      "Epoch 9 | Step 3257 | loss: 0.3217198370081006 | accuracy: 0.8631628787878788 \n",
      "Epoch 9 | Step 3258 | loss: 0.3216943293809891 | accuracy: 0.8625919117647058 \n",
      "Epoch 9 | Step 3259 | loss: 0.32006672620773313 | accuracy: 0.8625 \n",
      "Epoch 9 | Step 3260 | loss: 0.3197910562157631 | accuracy: 0.8628472222222222 \n",
      "Epoch 9 | Step 3261 | loss: 0.3200724487369125 | accuracy: 0.862331081081081 \n",
      "Epoch 9 | Step 3262 | loss: 0.3196686114135541 | accuracy: 0.8618421052631579 \n",
      "Epoch 9 | Step 3263 | loss: 0.3208278394662417 | accuracy: 0.8609775641025641 \n",
      "Epoch 9 | Step 3264 | loss: 0.32053257972002036 | accuracy: 0.8609375 \n",
      "Epoch 9 | Step 3265 | loss: 0.3193394040189139 | accuracy: 0.8612804878048781 \n",
      "Epoch 9 | Step 3266 | loss: 0.3224401899746487 | accuracy: 0.8604910714285714 \n",
      "Epoch 9 | Step 3267 | loss: 0.32178285024886916 | accuracy: 0.8604651162790697 \n",
      "Epoch 9 | Step 3268 | loss: 0.32229780405759817 | accuracy: 0.8604403409090909 \n",
      "Epoch 9 | Step 3269 | loss: 0.3257773333125645 | accuracy: 0.8583333333333333 \n",
      "Epoch 9 | Step 3270 | loss: 0.3277927980474804 | accuracy: 0.858016304347826 \n",
      "Epoch 9 | Step 3271 | loss: 0.3268562606040468 | accuracy: 0.8587101063829787 \n",
      "Epoch 9 | Step 3272 | loss: 0.3296465786794822 | accuracy: 0.8580729166666666 \n",
      "Epoch 9 | Step 3273 | loss: 0.3277921387735679 | accuracy: 0.8590561224489796 \n",
      "Epoch 9 | Step 3274 | loss: 0.32952755421400076 | accuracy: 0.8584375 \n",
      "Epoch 9 | Step 3275 | loss: 0.332067752293512 | accuracy: 0.8560049019607843 \n",
      "Epoch 9 | Step 3276 | loss: 0.3328205670874853 | accuracy: 0.8551682692307693 \n",
      "Epoch 9 | Step 3277 | loss: 0.33122417358857287 | accuracy: 0.8555424528301887 \n",
      "Epoch 9 | Step 3278 | loss: 0.3305082042460089 | accuracy: 0.8559027777777778 \n",
      "Epoch 9 | Step 3279 | loss: 0.3297239636833018 | accuracy: 0.85625 \n",
      "Epoch 9 | Step 3280 | loss: 0.33003880429480764 | accuracy: 0.8557477678571429 \n",
      "Epoch 9 | Step 3281 | loss: 0.32983776848567165 | accuracy: 0.856359649122807 \n",
      "Epoch 9 | Step 3282 | loss: 0.33035078464910905 | accuracy: 0.8553340517241379 \n",
      "Epoch 9 | Step 3283 | loss: 0.3308308531167144 | accuracy: 0.855667372881356 \n",
      "Epoch 9 | Step 3284 | loss: 0.3315687241653602 | accuracy: 0.85625 \n",
      "Epoch 9 | Step 3285 | loss: 0.33146369432816747 | accuracy: 0.8555327868852459 \n",
      "Epoch 9 | Step 3286 | loss: 0.3314152713264189 | accuracy: 0.8558467741935484 \n",
      "Epoch 9 | Step 3287 | loss: 0.3316671155274861 | accuracy: 0.855406746031746 \n",
      "Epoch 9 | Step 3288 | loss: 0.32958759507164365 | accuracy: 0.8564453125 \n",
      "Epoch 9 | Step 3289 | loss: 0.3289919486412636 | accuracy: 0.8567307692307692 \n",
      "Epoch 9 | Step 3290 | loss: 0.3271424104318475 | accuracy: 0.8574810606060606 \n",
      "Epoch 9 | Step 3291 | loss: 0.3265949107372939 | accuracy: 0.8575093283582089 \n",
      "Epoch 9 | Step 3292 | loss: 0.32623625524780336 | accuracy: 0.8582261029411765 \n",
      "Epoch 9 | Step 3293 | loss: 0.3276554408712664 | accuracy: 0.8575634057971014 \n",
      "Epoch 9 | Step 3294 | loss: 0.33002691801105233 | accuracy: 0.8560267857142857 \n",
      "Epoch 9 | Step 3295 | loss: 0.3291947847940553 | accuracy: 0.8569542253521126 \n",
      "Epoch 9 | Step 3296 | loss: 0.3288814771092601 | accuracy: 0.857421875 \n",
      "Epoch 9 | Step 3297 | loss: 0.3296541283800178 | accuracy: 0.8574486301369864 \n",
      "Epoch 9 | Step 3298 | loss: 0.33056076978509497 | accuracy: 0.8574746621621623 \n",
      "Epoch 9 | Step 3299 | loss: 0.3317117426792781 | accuracy: 0.8575 \n",
      "Epoch 9 | Step 3300 | loss: 0.3308239326273141 | accuracy: 0.858141447368421 \n",
      "Epoch 9 | Step 3301 | loss: 0.33088525878144553 | accuracy: 0.8579545454545454 \n",
      "Epoch 9 | Step 3302 | loss: 0.33240393931284934 | accuracy: 0.8571714743589743 \n",
      "Epoch 9 | Step 3303 | loss: 0.33145717484287074 | accuracy: 0.8581882911392406 \n",
      "Epoch 9 | Step 3304 | loss: 0.33150853309780365 | accuracy: 0.8580078125 \n",
      "Epoch 9 | Step 3305 | loss: 0.33099405320338265 | accuracy: 0.8587962962962963 \n",
      "Epoch 9 | Step 3306 | loss: 0.32924964642379345 | accuracy: 0.8595655487804879 \n",
      "Epoch 9 | Step 3307 | loss: 0.32890684579510293 | accuracy: 0.8599397590361446 \n",
      "Epoch 9 | Step 3308 | loss: 0.3288714951347738 | accuracy: 0.8603050595238095 \n",
      "Epoch 9 | Step 3309 | loss: 0.32960377843940974 | accuracy: 0.8601102941176471 \n",
      "Epoch 9 | Step 3310 | loss: 0.3288403938329499 | accuracy: 0.8610101744186046 \n",
      "Epoch 9 | Step 3311 | loss: 0.32909614515715646 | accuracy: 0.8608117816091954 \n",
      "Epoch 9 | Step 3312 | loss: 0.32970497130670345 | accuracy: 0.861328125 \n",
      "Epoch 9 | Step 3313 | loss: 0.32893332956212307 | accuracy: 0.8616573033707865 \n",
      "Epoch 9 | Step 3314 | loss: 0.32979495045211593 | accuracy: 0.8611111111111112 \n",
      "Epoch 9 | Step 3315 | loss: 0.32901268067595735 | accuracy: 0.861092032967033 \n",
      "Epoch 9 | Step 3316 | loss: 0.3315294221367526 | accuracy: 0.8600543478260869 \n",
      "Epoch 9 | Step 3317 | loss: 0.33108650692688535 | accuracy: 0.860383064516129 \n",
      "Epoch 9 | Step 3318 | loss: 0.3304872203697551 | accuracy: 0.8607047872340425 \n",
      "Epoch 9 | Step 3319 | loss: 0.32921598992849666 | accuracy: 0.8611842105263158 \n",
      "Epoch 9 | Step 3320 | loss: 0.32839684219410037 | accuracy: 0.8616536458333334 \n",
      "Epoch 9 | Step 3321 | loss: 0.3273502202685348 | accuracy: 0.8625966494845361 \n",
      "Epoch 9 | Step 3322 | loss: 0.3292095182197436 | accuracy: 0.8614477040816326 \n",
      "Epoch 9 | Step 3323 | loss: 0.32870398522025424 | accuracy: 0.8615845959595959 \n",
      "Epoch 9 | Step 3324 | loss: 0.32838444277644174 | accuracy: 0.8615625 \n",
      "Epoch 9 | Step 3325 | loss: 0.32775387153176994 | accuracy: 0.8618502475247525 \n",
      "Epoch 9 | Step 3326 | loss: 0.32826371943833793 | accuracy: 0.8609068627450981 \n",
      "Epoch 9 | Step 3327 | loss: 0.32857700039460835 | accuracy: 0.8605885922330098 \n",
      "Epoch 9 | Step 3328 | loss: 0.32895566222186284 | accuracy: 0.8608774038461539 \n",
      "Epoch 9 | Step 3329 | loss: 0.3293563421283451 | accuracy: 0.8602678571428571 \n",
      "Epoch 9 | Step 3330 | loss: 0.3283106939129111 | accuracy: 0.8611438679245284 \n",
      "Epoch 9 | Step 3331 | loss: 0.32946615227472015 | accuracy: 0.8605432242990654 \n",
      "Epoch 9 | Step 3332 | loss: 0.330437462500952 | accuracy: 0.8605324074074074 \n",
      "Epoch 9 | Step 3333 | loss: 0.3298681297706903 | accuracy: 0.8608084862385321 \n",
      "Epoch 9 | Step 3334 | loss: 0.32951480732722727 | accuracy: 0.8609375 \n",
      "Epoch 9 | Step 3335 | loss: 0.3309705570205913 | accuracy: 0.8602195945945946 \n",
      "Epoch 9 | Step 3336 | loss: 0.3318524848935861 | accuracy: 0.8602120535714286 \n",
      "Epoch 9 | Step 3337 | loss: 0.3323742819834601 | accuracy: 0.860066371681416 \n",
      "Epoch 9 | Step 3338 | loss: 0.33238962227315244 | accuracy: 0.8599232456140351 \n",
      "Epoch 9 | Step 3339 | loss: 0.33144250732401154 | accuracy: 0.8604619565217392 \n",
      "Epoch 9 | Step 3340 | loss: 0.3313182308499157 | accuracy: 0.8604525862068966 \n",
      "Epoch 9 | Step 3341 | loss: 0.3309869833736339 | accuracy: 0.860176282051282 \n",
      "Epoch 9 | Step 3342 | loss: 0.331629747935271 | accuracy: 0.8596398305084746 \n",
      "Epoch 9 | Step 3343 | loss: 0.33248474079520773 | accuracy: 0.859375 \n",
      "Epoch 9 | Step 3344 | loss: 0.3322505957136553 | accuracy: 0.859375 \n",
      "Epoch 9 | Step 3345 | loss: 0.3315471430455359 | accuracy: 0.8597623966942148 \n",
      "Epoch 9 | Step 3346 | loss: 0.33112501682805245 | accuracy: 0.860015368852459 \n",
      "Epoch 9 | Step 3347 | loss: 0.3308986985101934 | accuracy: 0.8598831300813008 \n",
      "Epoch 9 | Step 3348 | loss: 0.3311290810665778 | accuracy: 0.8598790322580645 \n",
      "Epoch 9 | Step 3349 | loss: 0.3307737801074983 | accuracy: 0.86 \n",
      "Epoch 9 | Step 3350 | loss: 0.33075704602968137 | accuracy: 0.8597470238095238 \n",
      "Epoch 9 | Step 3351 | loss: 0.3318057672714625 | accuracy: 0.859621062992126 \n",
      "Epoch 9 | Step 3352 | loss: 0.3318743344862015 | accuracy: 0.8594970703125 \n",
      "Epoch 9 | Step 3353 | loss: 0.3315306901931764 | accuracy: 0.859375 \n",
      "Epoch 9 | Step 3354 | loss: 0.3317791968584062 | accuracy: 0.859375 \n",
      "Epoch 9 | Step 3355 | loss: 0.3321010461290375 | accuracy: 0.8591364503816794 \n",
      "Epoch 9 | Step 3356 | loss: 0.3322068796013342 | accuracy: 0.8587831439393939 \n",
      "Epoch 9 | Step 3357 | loss: 0.33184205656661137 | accuracy: 0.8589050751879699 \n",
      "Epoch 9 | Step 3358 | loss: 0.3319428578686359 | accuracy: 0.8587919776119403 \n",
      "Epoch 9 | Step 3359 | loss: 0.33215858737627674 | accuracy: 0.858912037037037 \n",
      "Epoch 9 | Step 3360 | loss: 0.33204033247688247 | accuracy: 0.8591452205882353 \n",
      "Epoch 9 | Step 3361 | loss: 0.33189783435668396 | accuracy: 0.8592609489051095 \n",
      "Epoch 9 | Step 3362 | loss: 0.3318233153094417 | accuracy: 0.8592617753623188 \n",
      "Epoch 9 | Step 3363 | loss: 0.33209927776734616 | accuracy: 0.8585881294964028 \n",
      "Epoch 9 | Step 3364 | loss: 0.3315459594130517 | accuracy: 0.8589285714285714 \n",
      "Epoch 9 | Step 3365 | loss: 0.33159852429484654 | accuracy: 0.8590425531914893 \n",
      "Epoch 9 | Step 3366 | loss: 0.33136349391769365 | accuracy: 0.8590448943661971 \n",
      "Epoch 9 | Step 3367 | loss: 0.3311996793413497 | accuracy: 0.8592657342657342 \n",
      "Epoch 9 | Step 3368 | loss: 0.33044588834875177 | accuracy: 0.8597005208333333 \n",
      "Epoch 9 | Step 3369 | loss: 0.3303128988578404 | accuracy: 0.8598060344827585 \n",
      "Epoch 9 | Step 3370 | loss: 0.3314405961395945 | accuracy: 0.8593749999999999 \n",
      "Epoch 9 | Step 3371 | loss: 0.330966131014078 | accuracy: 0.8596938775510203 \n",
      "Epoch 9 | Step 3372 | loss: 0.3306488422928632 | accuracy: 0.8594805743243242 \n",
      "Epoch 9 | Step 3373 | loss: 0.33035063763592887 | accuracy: 0.8596895973154363 \n",
      "Epoch 9 | Step 3374 | loss: 0.330059987306595 | accuracy: 0.8596875 \n",
      "Epoch 9 | Step 3375 | loss: 0.3300801012294973 | accuracy: 0.8597889072847682 \n",
      "Epoch 9 | Step 3376 | loss: 0.33066050786721096 | accuracy: 0.8595805921052632 \n",
      "Epoch 9 | Step 3377 | loss: 0.33057749310350126 | accuracy: 0.8595792483660131 \n",
      "Epoch 9 | Step 3378 | loss: 0.3304252080716098 | accuracy: 0.8597808441558441 \n",
      "Epoch 9 | Step 3379 | loss: 0.32986672828274405 | accuracy: 0.8599798387096774 \n",
      "Epoch 9 | Step 3380 | loss: 0.32931893977981364 | accuracy: 0.8602764423076923 \n",
      "Epoch 9 | Step 3381 | loss: 0.32866942426960954 | accuracy: 0.8606687898089171 \n",
      "Epoch 9 | Step 3382 | loss: 0.32838369868224193 | accuracy: 0.8608583860759493 \n",
      "Epoch 9 | Step 3383 | loss: 0.3280426574952949 | accuracy: 0.8611438679245284 \n",
      "Epoch 9 | Step 3384 | loss: 0.3279954191297294 | accuracy: 0.86123046875 \n",
      "Epoch 9 | Step 3385 | loss: 0.32758960072298243 | accuracy: 0.8613159937888198 \n",
      "Epoch 9 | Step 3386 | loss: 0.328121962738626 | accuracy: 0.8611111111111112 \n",
      "Epoch 9 | Step 3387 | loss: 0.32770872938852386 | accuracy: 0.8612921779141104 \n",
      "Epoch 9 | Step 3388 | loss: 0.3272060691946892 | accuracy: 0.8618521341463414 \n",
      "Epoch 9 | Step 3389 | loss: 0.3270162947250137 | accuracy: 0.8619318181818182 \n",
      "Epoch 9 | Step 3390 | loss: 0.3279649518340469 | accuracy: 0.8612575301204819 \n",
      "Epoch 9 | Step 3391 | loss: 0.3274785763846188 | accuracy: 0.8616205089820359 \n",
      "Epoch 9 | Step 3392 | loss: 0.32725437659592876 | accuracy: 0.8617931547619048 \n",
      "Epoch 9 | Step 3393 | loss: 0.3281982844397869 | accuracy: 0.861409023668639 \n",
      "Epoch 9 | Step 3394 | loss: 0.3274659643278405 | accuracy: 0.8618566176470588 \n",
      "Epoch 9 | Step 3395 | loss: 0.32772113696524996 | accuracy: 0.8614766081871345 \n",
      "Epoch 9 | Step 3396 | loss: 0.32814923370646903 | accuracy: 0.8612827034883721 \n",
      "Epoch 9 | Step 3397 | loss: 0.32708260261943606 | accuracy: 0.861903901734104 \n",
      "Epoch 9 | Step 3398 | loss: 0.32747683305850006 | accuracy: 0.8617097701149425 \n",
      "Epoch 9 | Step 3399 | loss: 0.32682591046605824 | accuracy: 0.8620535714285714 \n",
      "Epoch 9 | Step 3400 | loss: 0.32687629793177986 | accuracy: 0.8623046875 \n",
      "Epoch 9 | Step 3401 | loss: 0.32722449487885547 | accuracy: 0.8622881355932204 \n",
      "Epoch 9 | Step 3402 | loss: 0.327029392625509 | accuracy: 0.8624473314606742 \n",
      "Epoch 9 | Step 3403 | loss: 0.32753522619188863 | accuracy: 0.8621682960893855 \n",
      "Epoch 9 | Step 3404 | loss: 0.32801824443870153 | accuracy: 0.86171875 \n",
      "Epoch 9 | Step 3405 | loss: 0.327943015493741 | accuracy: 0.861878453038674 \n",
      "Epoch 9 | Step 3406 | loss: 0.32744116753667296 | accuracy: 0.8622939560439561 \n",
      "Epoch 9 | Step 3407 | loss: 0.32743927445568055 | accuracy: 0.8622780054644809 \n",
      "Epoch 9 | Step 3408 | loss: 0.3273843264450201 | accuracy: 0.8622622282608695 \n",
      "Epoch 9 | Step 3409 | loss: 0.32740021686296233 | accuracy: 0.862331081081081 \n",
      "Epoch 9 | Step 3410 | loss: 0.32713859231882225 | accuracy: 0.862315188172043 \n",
      "Epoch 9 | Step 3411 | loss: 0.32727750514280374 | accuracy: 0.8623830213903744 \n",
      "Epoch 9 | Step 3412 | loss: 0.32712263883428394 | accuracy: 0.8624501329787234 \n",
      "Epoch 9 | Step 3413 | loss: 0.3266324258985976 | accuracy: 0.8625992063492064 \n",
      "Epoch 9 | Step 3414 | loss: 0.3263581886103281 | accuracy: 0.8628289473684211 \n",
      "Epoch 9 | Step 3415 | loss: 0.32649314434740584 | accuracy: 0.8626472513089005 \n",
      "Epoch 9 | Step 3416 | loss: 0.32662009634077577 | accuracy: 0.862548828125 \n",
      "Epoch 9 | Step 3417 | loss: 0.3264677456623535 | accuracy: 0.8626133419689119 \n",
      "Epoch 9 | Step 3418 | loss: 0.3263920258308197 | accuracy: 0.8626771907216495 \n",
      "Epoch 9 | Step 3419 | loss: 0.3265304025931239 | accuracy: 0.8626602564102565 \n",
      "Epoch 9 | Step 3420 | loss: 0.3261928430625374 | accuracy: 0.8628826530612245 \n",
      "Epoch 9 | Step 3421 | loss: 0.3262056631182659 | accuracy: 0.8627062182741116 \n",
      "Epoch 9 | Step 3422 | loss: 0.3258695713799412 | accuracy: 0.8630050505050505 \n",
      "Epoch 9 | Step 3423 | loss: 0.3259529800870314 | accuracy: 0.8629868090452262 \n",
      "Epoch 9 | Step 3424 | loss: 0.32585452541708976 | accuracy: 0.863046875 \n",
      "Epoch 9 | Step 3425 | loss: 0.325922185360496 | accuracy: 0.8629508706467661 \n",
      "Epoch 9 | Step 3426 | loss: 0.32616528883428886 | accuracy: 0.8627784653465347 \n",
      "Epoch 9 | Step 3427 | loss: 0.3262919704315113 | accuracy: 0.8627616995073891 \n",
      "Epoch 9 | Step 3428 | loss: 0.3266115771497 | accuracy: 0.862515318627451 \n",
      "Epoch 9 | Step 3429 | loss: 0.32654620743379387 | accuracy: 0.8626524390243903 \n",
      "Epoch 9 | Step 3430 | loss: 0.32695356734748054 | accuracy: 0.8624848300970874 \n",
      "Epoch 9 | Step 3431 | loss: 0.3268419920246385 | accuracy: 0.8625452898550725 \n",
      "Epoch 9 | Step 3432 | loss: 0.32665364530224095 | accuracy: 0.8625300480769231 \n",
      "Epoch 9 | Step 3433 | loss: 0.32657687972036875 | accuracy: 0.86251495215311 \n",
      "Epoch 9 | Step 3434 | loss: 0.3260768021856038 | accuracy: 0.8627976190476191 \n",
      "Epoch 9 | Step 3435 | loss: 0.32600098240997016 | accuracy: 0.8627813981042654 \n",
      "Epoch 9 | Step 3436 | loss: 0.3259870412777058 | accuracy: 0.8628390330188679 \n",
      "Epoch 9 | Step 3437 | loss: 0.325869098095827 | accuracy: 0.8628227699530516 \n",
      "Epoch 9 | Step 3438 | loss: 0.3259427385909538 | accuracy: 0.8628796728971962 \n",
      "Epoch 9 | Step 3439 | loss: 0.3262086079564208 | accuracy: 0.8626453488372093 \n",
      "Epoch 9 | Step 3440 | loss: 0.3262390112159431 | accuracy: 0.8627748842592593 \n",
      "Epoch 9 | Step 3441 | loss: 0.32666103328977336 | accuracy: 0.862543202764977 \n",
      "Epoch 9 | Step 3442 | loss: 0.3270104300538337 | accuracy: 0.8623136467889908 \n",
      "Epoch 9 | Step 3443 | loss: 0.32702367572479624 | accuracy: 0.8622288812785388 \n",
      "Epoch 9 | Step 3444 | loss: 0.3269327788190411 | accuracy: 0.8622869318181818 \n",
      "Epoch 9 | Step 3445 | loss: 0.32681773353486065 | accuracy: 0.8624151583710408 \n",
      "Epoch 9 | Step 3446 | loss: 0.3268120895634903 | accuracy: 0.862401463963964 \n",
      "Epoch 9 | Step 3447 | loss: 0.3267346930610762 | accuracy: 0.8623178251121076 \n",
      "Epoch 9 | Step 3448 | loss: 0.3268960420308371 | accuracy: 0.8622349330357143 \n",
      "Epoch 9 | Step 3449 | loss: 0.3270303156640797 | accuracy: 0.8622222222222222 \n",
      "Epoch 9 | Step 3450 | loss: 0.3269436816989851 | accuracy: 0.8622787610619469 \n",
      "Epoch 9 | Step 3451 | loss: 0.32702773284281955 | accuracy: 0.8625412995594713 \n",
      "Epoch 9 | Step 3452 | loss: 0.32690376304743607 | accuracy: 0.8626644736842105 \n",
      "Epoch 9 | Step 3453 | loss: 0.32667208511756524 | accuracy: 0.8627183406113537 \n",
      "Epoch 9 | Step 3454 | loss: 0.32653036804302904 | accuracy: 0.8627038043478261 \n",
      "Epoch 9 | Step 3455 | loss: 0.3261381142583247 | accuracy: 0.8628246753246753 \n",
      "Epoch 9 | Step 3456 | loss: 0.3257991438410408 | accuracy: 0.8629445043103449 \n",
      "Epoch 9 | Step 3457 | loss: 0.3256467709341788 | accuracy: 0.86306330472103 \n",
      "Epoch 9 | Step 3458 | loss: 0.3260152289627966 | accuracy: 0.8629139957264957 \n",
      "Epoch 9 | Step 3459 | loss: 0.32558168261609205 | accuracy: 0.8632313829787234 \n",
      "Epoch 9 | Step 3460 | loss: 0.3253681749358018 | accuracy: 0.86328125 \n",
      "Epoch 9 | Step 3461 | loss: 0.32536979755268847 | accuracy: 0.8633306962025317 \n",
      "Epoch 9 | Step 3462 | loss: 0.325883405423966 | accuracy: 0.8631171218487395 \n",
      "Epoch 9 | Step 3463 | loss: 0.32597694299709873 | accuracy: 0.8631014644351465 \n",
      "Epoch 9 | Step 3464 | loss: 0.3259857673197987 | accuracy: 0.8630859375 \n",
      "Epoch 9 | Step 3465 | loss: 0.3264075517654421 | accuracy: 0.8629408713692946 \n",
      "Epoch 9 | Step 3466 | loss: 0.326534641798863 | accuracy: 0.8629907024793388 \n",
      "Epoch 9 | Step 3467 | loss: 0.32620874918046827 | accuracy: 0.8631687242798354 \n",
      "Epoch 9 | Step 3468 | loss: 0.32581914881946633 | accuracy: 0.8633452868852459 \n",
      "Epoch 9 | Step 3469 | loss: 0.325594718541418 | accuracy: 0.8634566326530613 \n",
      "Epoch 9 | Step 3470 | loss: 0.3253418452492577 | accuracy: 0.8636305894308943 \n",
      "Epoch 9 | Step 3471 | loss: 0.3252123406662152 | accuracy: 0.8636766194331984 \n",
      "Epoch 9 | Step 3472 | loss: 0.3252872415487807 | accuracy: 0.8637222782258065 \n",
      "Epoch 9 | Step 3473 | loss: 0.32555613597952243 | accuracy: 0.8637048192771084 \n",
      "Epoch 9 | Step 3474 | loss: 0.3253186237215998 | accuracy: 0.863875 \n",
      "Epoch 9 | Step 3475 | loss: 0.3256104139099085 | accuracy: 0.8637325697211156 \n",
      "Epoch 9 | Step 3476 | loss: 0.3261829067672058 | accuracy: 0.8635292658730159 \n",
      "Epoch 9 | Step 3477 | loss: 0.3261231627506703 | accuracy: 0.8635128458498024 \n",
      "Epoch 9 | Step 3478 | loss: 0.3260873392458978 | accuracy: 0.8634965551181102 \n",
      "Epoch 9 | Step 3479 | loss: 0.32593125543173646 | accuracy: 0.8636029411764706 \n",
      "Epoch 9 | Step 3480 | loss: 0.3258457017946059 | accuracy: 0.86370849609375 \n",
      "Epoch 9 | Step 3481 | loss: 0.3260582076088466 | accuracy: 0.8634484435797666 \n",
      "Epoch 9 | Step 3482 | loss: 0.32598688788423263 | accuracy: 0.8634932170542635 \n",
      "Epoch 9 | Step 3483 | loss: 0.3261958312919243 | accuracy: 0.8634773166023166 \n",
      "Epoch 9 | Step 3484 | loss: 0.3263366078528076 | accuracy: 0.8633413461538462 \n",
      "Epoch 9 | Step 3485 | loss: 0.32666048641634193 | accuracy: 0.8631465517241379 \n",
      "Epoch 9 | Step 3486 | loss: 0.32705356083980974 | accuracy: 0.862893606870229 \n",
      "Epoch 9 | Step 3487 | loss: 0.3273554547997937 | accuracy: 0.8627019961977186 \n",
      "Epoch 9 | Step 3488 | loss: 0.3274225040028495 | accuracy: 0.8626302083333334 \n",
      "Epoch 9 | Step 3489 | loss: 0.3274816812771673 | accuracy: 0.8625 \n",
      "Epoch 9 | Step 3490 | loss: 0.3275585401439131 | accuracy: 0.8622532894736842 \n",
      "Epoch 9 | Step 3491 | loss: 0.32721562638934654 | accuracy: 0.8624765917602997 \n",
      "Epoch 9 | Step 3492 | loss: 0.32757611389258035 | accuracy: 0.8622901119402985 \n",
      "Epoch 9 | Step 3493 | loss: 0.327593574016511 | accuracy: 0.8623373605947955 \n",
      "Epoch 9 | Step 3494 | loss: 0.3274893846224858 | accuracy: 0.8623842592592592 \n",
      "Epoch 9 | Step 3495 | loss: 0.32730988399349037 | accuracy: 0.8624308118081181 \n",
      "Epoch 9 | Step 3496 | loss: 0.32716116665259903 | accuracy: 0.8624195772058824 \n",
      "Epoch 9 | Step 3497 | loss: 0.32708718439379914 | accuracy: 0.862408424908425 \n",
      "Epoch 9 | Step 3498 | loss: 0.3270955651889754 | accuracy: 0.8623403284671532 \n",
      "Epoch 9 | Step 3499 | loss: 0.3275594592636284 | accuracy: 0.8620454545454546 \n",
      "Epoch 9 | Step 3500 | loss: 0.3278161874175938 | accuracy: 0.861922554347826 \n",
      "Epoch 9 | Step 3501 | loss: 0.3279191366924708 | accuracy: 0.8618569494584838 \n",
      "Epoch 9 | Step 3502 | loss: 0.32752516217154587 | accuracy: 0.8620166366906474 \n",
      "Epoch 9 | Step 3503 | loss: 0.3281085394509806 | accuracy: 0.8617271505376344 \n",
      "Epoch 9 | Step 3504 | loss: 0.3278072048510826 | accuracy: 0.8617745535714286 \n",
      "Epoch 9 | Step 3505 | loss: 0.3280206721448391 | accuracy: 0.8615435943060499 \n",
      "Epoch 9 | Step 3506 | loss: 0.3277455172006122 | accuracy: 0.8617021276595745 \n",
      "Epoch 9 | Step 3507 | loss: 0.3277879224649168 | accuracy: 0.8615834805653712 \n",
      "Epoch 9 | Step 3508 | loss: 0.32755816969233514 | accuracy: 0.8617407570422536 \n",
      "Epoch 9 | Step 3509 | loss: 0.327597160715806 | accuracy: 0.8616776315789475 \n",
      "Epoch 9 | Step 3510 | loss: 0.3271703603905399 | accuracy: 0.861888111888112 \n",
      "Epoch 9 | Step 3511 | loss: 0.3271389695513956 | accuracy: 0.8619337979094077 \n",
      "Epoch 9 | Step 3512 | loss: 0.3267033365555109 | accuracy: 0.8620876736111112 \n",
      "Epoch 9 | Step 3513 | loss: 0.3269120631642822 | accuracy: 0.8620782871972318 \n",
      "Epoch 9 | Step 3514 | loss: 0.3268482649634626 | accuracy: 0.862176724137931 \n",
      "Epoch 9 | Step 3515 | loss: 0.32703132190040723 | accuracy: 0.8621134020618557 \n",
      "Epoch 9 | Step 3516 | loss: 0.32686543265638307 | accuracy: 0.862211044520548 \n",
      "Epoch 9 | Step 3517 | loss: 0.327224492874162 | accuracy: 0.8619880546075085 \n",
      "Epoch 9 | Step 3518 | loss: 0.3270415376339642 | accuracy: 0.8621386054421769 \n",
      "Epoch 9 | Step 3519 | loss: 0.3268215784076919 | accuracy: 0.8623940677966102 \n",
      "Epoch 9 | Step 3520 | loss: 0.3269887846970077 | accuracy: 0.862278293918919 \n",
      "Epoch 9 | Step 3521 | loss: 0.32678254851789207 | accuracy: 0.8623737373737373 \n",
      "Epoch 9 | Step 3522 | loss: 0.3270091950993412 | accuracy: 0.8622588087248322 \n",
      "Epoch 9 | Step 3523 | loss: 0.32689643688624537 | accuracy: 0.8620923913043478 \n",
      "Epoch 9 | Step 3524 | loss: 0.3267721337576709 | accuracy: 0.86203125 \n",
      "Epoch 9 | Step 3525 | loss: 0.3267167215034417 | accuracy: 0.8619705149501661 \n",
      "Epoch 9 | Step 3526 | loss: 0.32662269537219957 | accuracy: 0.8620136589403974 \n",
      "Epoch 9 | Step 3527 | loss: 0.3264268502445506 | accuracy: 0.8621596534653465 \n",
      "Epoch 9 | Step 3528 | loss: 0.32651575757680773 | accuracy: 0.862047697368421 \n",
      "Epoch 9 | Step 3529 | loss: 0.32632237120729995 | accuracy: 0.8620901639344263 \n",
      "Epoch 9 | Step 3530 | loss: 0.3263158048777021 | accuracy: 0.8621323529411765 \n",
      "Epoch 9 | Step 3531 | loss: 0.3265040864870682 | accuracy: 0.8620215798045603 \n",
      "Epoch 9 | Step 3532 | loss: 0.3262853176853101 | accuracy: 0.862114448051948 \n",
      "Epoch 9 | Step 3533 | loss: 0.32594714292044796 | accuracy: 0.862156148867314 \n",
      "Epoch 9 | Step 3534 | loss: 0.3260621102586871 | accuracy: 0.8620967741935484 \n",
      "Epoch 9 | Step 3535 | loss: 0.32603956303795834 | accuracy: 0.8622387459807074 \n",
      "Epoch 9 | Step 3536 | loss: 0.32592192483253984 | accuracy: 0.8620793269230769 \n",
      "Epoch 9 | Step 3537 | loss: 0.3258748880971356 | accuracy: 0.8620706869009584 \n",
      "Epoch 9 | Step 3538 | loss: 0.32634881347607675 | accuracy: 0.8619128184713376 \n",
      "Epoch 9 | Step 3539 | loss: 0.3270097274628898 | accuracy: 0.861656746031746 \n",
      "Epoch 9 | Step 3540 | loss: 0.32705057997115067 | accuracy: 0.8616989715189873 \n",
      "Epoch 9 | Step 3541 | loss: 0.32653758743019906 | accuracy: 0.86198738170347 \n",
      "Epoch 9 | Step 3542 | loss: 0.32667335319631524 | accuracy: 0.8619300314465409 \n",
      "Epoch 9 | Step 3543 | loss: 0.3267861374399881 | accuracy: 0.861873040752351 \n",
      "Epoch 9 | Step 3544 | loss: 0.3266595648135992 | accuracy: 0.86181640625 \n",
      "Epoch 9 | Step 3545 | loss: 0.326569452696129 | accuracy: 0.861857476635514 \n",
      "Epoch 9 | Step 3546 | loss: 0.3270095159640966 | accuracy: 0.8618012422360248 \n",
      "Epoch 9 | Step 3547 | loss: 0.32684505765467625 | accuracy: 0.8619388544891641 \n",
      "Epoch 9 | Step 3548 | loss: 0.32660517836978425 | accuracy: 0.8620273919753086 \n",
      "Epoch 9 | Step 3549 | loss: 0.3269486508461147 | accuracy: 0.8619230769230769 \n",
      "Epoch 9 | Step 3550 | loss: 0.32703167478913925 | accuracy: 0.8619152607361963 \n",
      "Epoch 9 | Step 3551 | loss: 0.327107312254585 | accuracy: 0.8619074923547401 \n",
      "Epoch 9 | Step 3552 | loss: 0.32741684225819473 | accuracy: 0.8618044969512195 \n",
      "Epoch 9 | Step 3553 | loss: 0.3276120129417867 | accuracy: 0.8616546352583586 \n",
      "Epoch 9 | Step 3554 | loss: 0.32750946477507115 | accuracy: 0.8616950757575758 \n",
      "Epoch 9 | Step 3555 | loss: 0.327521608990485 | accuracy: 0.8616408610271903 \n",
      "Epoch 9 | Step 3556 | loss: 0.3275031183947283 | accuracy: 0.8616810993975904 \n",
      "Epoch 9 | Step 3557 | loss: 0.32760262001563134 | accuracy: 0.8616741741741741 \n",
      "Epoch 9 | Step 3558 | loss: 0.3275526957865248 | accuracy: 0.8617608532934131 \n",
      "Epoch 9 | Step 3559 | loss: 0.32739428063826786 | accuracy: 0.8618936567164179 \n",
      "Epoch 9 | Step 3560 | loss: 0.32736483921429954 | accuracy: 0.8618396577380952 \n",
      "Epoch 9 | Step 3561 | loss: 0.32725551198250474 | accuracy: 0.861878709198813 \n",
      "Epoch 9 | Step 3562 | loss: 0.3273975688236706 | accuracy: 0.8620099852071006 \n",
      "Epoch 9 | Step 3563 | loss: 0.32710184688765054 | accuracy: 0.862094395280236 \n",
      "Epoch 9 | Step 3564 | loss: 0.32696450615630446 | accuracy: 0.8621783088235294 \n",
      "Epoch 9 | Step 3565 | loss: 0.3271214069683882 | accuracy: 0.8619868035190615 \n",
      "Epoch 9 | Step 3566 | loss: 0.3269908973696638 | accuracy: 0.8620705409356725 \n",
      "Epoch 9 | Step 3567 | loss: 0.3268821742548541 | accuracy: 0.8621993440233237 \n",
      "Epoch 9 | Step 3568 | loss: 0.32664810359304747 | accuracy: 0.862327398255814 \n",
      "Epoch 9 | Step 3569 | loss: 0.32679270795290044 | accuracy: 0.8623641304347827 \n",
      "Epoch 9 | Step 3570 | loss: 0.3268145796966693 | accuracy: 0.8624006502890174 \n",
      "Epoch 9 | Step 3571 | loss: 0.32654923569915645 | accuracy: 0.8624819884726225 \n",
      "Epoch 9 | Step 3572 | loss: 0.32702911439640797 | accuracy: 0.8622934626436781 \n",
      "Epoch 9 | Step 3573 | loss: 0.3268358976417424 | accuracy: 0.8622851002865329 \n",
      "Epoch 9 | Step 3574 | loss: 0.3266731244325641 | accuracy: 0.8623214285714286 \n",
      "Epoch 9 | Step 3575 | loss: 0.32654970111670345 | accuracy: 0.8624020655270656 \n",
      "Epoch 9 | Step 3576 | loss: 0.32651808553121336 | accuracy: 0.8624822443181818 \n",
      "Epoch 9 | Step 3577 | loss: 0.32653247778206335 | accuracy: 0.8624734419263456 \n",
      "Epoch 9 | Step 3578 | loss: 0.32637387631976705 | accuracy: 0.8624205508474576 \n",
      "Epoch 9 | Step 3579 | loss: 0.3264212529424214 | accuracy: 0.8623679577464789 \n",
      "Epoch 9 | Step 3580 | loss: 0.32627070351932863 | accuracy: 0.8624912219101124 \n",
      "Epoch 9 | Step 3581 | loss: 0.32599526147047714 | accuracy: 0.8626137955182073 \n",
      "Epoch 9 | Step 3582 | loss: 0.32597071336134886 | accuracy: 0.8626920391061452 \n",
      "Epoch 9 | Step 3583 | loss: 0.325897473271179 | accuracy: 0.8626827994428969 \n",
      "Epoch 9 | Step 3584 | loss: 0.3259667663524552 | accuracy: 0.8627170138888889 \n",
      "Epoch 9 | Step 3585 | loss: 0.32574543344512247 | accuracy: 0.8627943213296398 \n",
      "Epoch 9 | Step 3586 | loss: 0.32592472396996836 | accuracy: 0.8627417127071824 \n",
      "Epoch 9 | Step 3587 | loss: 0.3261030669793613 | accuracy: 0.862646349862259 \n",
      "Epoch 9 | Step 3588 | loss: 0.3259605491472473 | accuracy: 0.8627232142857143 \n",
      "Epoch 9 | Step 3589 | loss: 0.3260156239957029 | accuracy: 0.8625856164383562 \n",
      "Epoch 9 | Step 3590 | loss: 0.32587004542513653 | accuracy: 0.8626195355191257 \n",
      "Epoch 9 | Step 3591 | loss: 0.32577067910000834 | accuracy: 0.8626532697547684 \n",
      "Epoch 9 | Step 3592 | loss: 0.32584384573704556 | accuracy: 0.8627292798913043 \n",
      "Epoch 9 | Step 3593 | loss: 0.3258517762105966 | accuracy: 0.862720189701897 \n",
      "Epoch 9 | Step 3594 | loss: 0.3261756464838985 | accuracy: 0.8626266891891892 \n",
      "Epoch 9 | Step 3595 | loss: 0.3265176184495508 | accuracy: 0.862533692722372 \n",
      "Epoch 9 | Step 3596 | loss: 0.3266471759366095 | accuracy: 0.8624411962365591 \n",
      "Epoch 9 | Step 3597 | loss: 0.3267076336266851 | accuracy: 0.8623910857908847 \n",
      "Epoch 9 | Step 3598 | loss: 0.3266851025867593 | accuracy: 0.8623830213903744 \n",
      "Epoch 9 | Step 3599 | loss: 0.3263310617208484 | accuracy: 0.8625833333333334 \n",
      "Epoch 9 | Step 3600 | loss: 0.32615906004100437 | accuracy: 0.8626994680851063 \n",
      "Epoch 9 | Step 3601 | loss: 0.32587493956089053 | accuracy: 0.8628564323607427 \n",
      "Epoch 9 | Step 3602 | loss: 0.32617351495557395 | accuracy: 0.8626818783068783 \n",
      "Epoch 9 | Step 3603 | loss: 0.3262336531305065 | accuracy: 0.8626731530343008 \n",
      "Epoch 9 | Step 3604 | loss: 0.32605021286167635 | accuracy: 0.8627055921052632 \n",
      "Epoch 9 | Step 3605 | loss: 0.32594874286119746 | accuracy: 0.8627788713910761 \n",
      "Epoch 9 | Step 3606 | loss: 0.32569097727537194 | accuracy: 0.862892670157068 \n",
      "Epoch 9 | Step 3607 | loss: 0.325745601683622 | accuracy: 0.8627610966057441 \n",
      "Epoch 9 | Step 3608 | loss: 0.3259277035249401 | accuracy: 0.8625895182291666 \n",
      "Epoch 9 | Step 3609 | loss: 0.32599405046407315 | accuracy: 0.8625405844155845 \n",
      "Epoch 9 | Step 3610 | loss: 0.32614518597799297 | accuracy: 0.862410945595855 \n",
      "Epoch 9 | Step 3611 | loss: 0.3262339097661877 | accuracy: 0.8623627260981912 \n",
      "Epoch 9 | Step 3612 | loss: 0.3263379128400202 | accuracy: 0.8623147551546392 \n",
      "Epoch 9 | Step 3613 | loss: 0.3265691566206806 | accuracy: 0.8621866966580977 \n",
      "Epoch 9 | Step 3614 | loss: 0.32662138193845786 | accuracy: 0.862139423076923 \n",
      "Epoch 9 | Step 3615 | loss: 0.32666173421056105 | accuracy: 0.8622122762148338 \n",
      "Epoch 9 | Step 3616 | loss: 0.32657164263025873 | accuracy: 0.8622448979591837 \n",
      "Epoch 9 | Step 3617 | loss: 0.3265514101160092 | accuracy: 0.8623568702290076 \n",
      "Epoch 9 | Step 3618 | loss: 0.3266281629652545 | accuracy: 0.8623889593908629 \n",
      "Epoch 9 | Step 3619 | loss: 0.32660516323168104 | accuracy: 0.8624604430379746 \n",
      "Epoch 9 | Step 3620 | loss: 0.32648883251981337 | accuracy: 0.8624921085858586 \n",
      "Epoch 9 | Step 3621 | loss: 0.3262156064924729 | accuracy: 0.8626416876574308 \n",
      "Epoch 9 | Step 3622 | loss: 0.3263809860651221 | accuracy: 0.8623979271356784 \n",
      "Epoch 9 | Step 3623 | loss: 0.3264684361174594 | accuracy: 0.8623511904761905 \n",
      "Epoch 9 | Step 3624 | loss: 0.32671399690210856 | accuracy: 0.8623046875 \n",
      "Epoch 9 | Step 3625 | loss: 0.32656758979074413 | accuracy: 0.86241427680798 \n",
      "Epoch 9 | Step 3626 | loss: 0.32708222222565453 | accuracy: 0.8621735074626866 \n",
      "Epoch 9 | Step 3627 | loss: 0.3268898755829628 | accuracy: 0.8622588132214606 \n",
      "Validation | Epoch 9 | Step 3627 | accuracy: 0.8334825838154013 \n",
      "Epoch 10 | Step 3628 | loss: 0.24879246950149536 | accuracy: 0.90625 \n",
      "Epoch 10 | Step 3629 | loss: 0.3144107908010483 | accuracy: 0.84375 \n",
      "Epoch 10 | Step 3630 | loss: 0.2952535053094228 | accuracy: 0.8645833333333334 \n",
      "Epoch 10 | Step 3631 | loss: 0.32622750848531723 | accuracy: 0.8515625 \n",
      "Epoch 10 | Step 3632 | loss: 0.32846409678459165 | accuracy: 0.85 \n",
      "Epoch 10 | Step 3633 | loss: 0.3351414253314336 | accuracy: 0.8489583333333334 \n",
      "Epoch 10 | Step 3634 | loss: 0.340194080557142 | accuracy: 0.8459821428571429 \n",
      "Epoch 10 | Step 3635 | loss: 0.34877797216176987 | accuracy: 0.845703125 \n",
      "Epoch 10 | Step 3636 | loss: 0.34101564685503644 | accuracy: 0.8472222222222222 \n",
      "Epoch 10 | Step 3637 | loss: 0.34250297844409944 | accuracy: 0.846875 \n",
      "Epoch 10 | Step 3638 | loss: 0.33863018588586286 | accuracy: 0.8480113636363636 \n",
      "Epoch 10 | Step 3639 | loss: 0.3405690814057986 | accuracy: 0.84765625 \n",
      "Epoch 10 | Step 3640 | loss: 0.33434917147342974 | accuracy: 0.8497596153846154 \n",
      "Epoch 10 | Step 3641 | loss: 0.33224064111709595 | accuracy: 0.8515625 \n",
      "Epoch 10 | Step 3642 | loss: 0.32271906932195027 | accuracy: 0.8572916666666667 \n",
      "Epoch 10 | Step 3643 | loss: 0.31659195479005575 | accuracy: 0.86328125 \n",
      "Epoch 10 | Step 3644 | loss: 0.313630429260871 | accuracy: 0.8676470588235294 \n",
      "Epoch 10 | Step 3645 | loss: 0.31317728343937135 | accuracy: 0.8654513888888888 \n",
      "Epoch 10 | Step 3646 | loss: 0.3154263629725105 | accuracy: 0.865953947368421 \n",
      "Epoch 10 | Step 3647 | loss: 0.31276201382279395 | accuracy: 0.865625 \n",
      "Epoch 10 | Step 3648 | loss: 0.30843032541729154 | accuracy: 0.8675595238095238 \n",
      "Epoch 10 | Step 3649 | loss: 0.3073408075354316 | accuracy: 0.8671875 \n",
      "Epoch 10 | Step 3650 | loss: 0.3061174866945847 | accuracy: 0.8675271739130435 \n",
      "Epoch 10 | Step 3651 | loss: 0.30185837112367153 | accuracy: 0.8697916666666666 \n",
      "Epoch 10 | Step 3652 | loss: 0.300984770655632 | accuracy: 0.870625 \n",
      "Epoch 10 | Step 3653 | loss: 0.3009251831815793 | accuracy: 0.8707932692307693 \n",
      "Epoch 10 | Step 3654 | loss: 0.30275651646984947 | accuracy: 0.8692129629629629 \n",
      "Epoch 10 | Step 3655 | loss: 0.2994868223156248 | accuracy: 0.8722098214285714 \n",
      "Epoch 10 | Step 3656 | loss: 0.2978629418488207 | accuracy: 0.8733836206896551 \n",
      "Epoch 10 | Step 3657 | loss: 0.29829601049423216 | accuracy: 0.8723958333333334 \n",
      "Epoch 10 | Step 3658 | loss: 0.29705004442122673 | accuracy: 0.873991935483871 \n",
      "Epoch 10 | Step 3659 | loss: 0.297924411483109 | accuracy: 0.875 \n",
      "Epoch 10 | Step 3660 | loss: 0.30183636690631055 | accuracy: 0.8721590909090909 \n",
      "Epoch 10 | Step 3661 | loss: 0.30195872222675996 | accuracy: 0.8727022058823529 \n",
      "Epoch 10 | Step 3662 | loss: 0.29998852440289087 | accuracy: 0.8727678571428571 \n",
      "Epoch 10 | Step 3663 | loss: 0.30034054236279595 | accuracy: 0.8728298611111112 \n",
      "Epoch 10 | Step 3664 | loss: 0.30000330950762777 | accuracy: 0.8728885135135135 \n",
      "Epoch 10 | Step 3665 | loss: 0.2991174561412711 | accuracy: 0.8741776315789473 \n",
      "Epoch 10 | Step 3666 | loss: 0.2995239671988365 | accuracy: 0.874198717948718 \n",
      "Epoch 10 | Step 3667 | loss: 0.2996932491660118 | accuracy: 0.873828125 \n",
      "Epoch 10 | Step 3668 | loss: 0.2980330521013679 | accuracy: 0.8742378048780488 \n",
      "Epoch 10 | Step 3669 | loss: 0.3006179070188886 | accuracy: 0.8735119047619048 \n",
      "Epoch 10 | Step 3670 | loss: 0.29961733069530755 | accuracy: 0.8739098837209303 \n",
      "Epoch 10 | Step 3671 | loss: 0.29970810968767514 | accuracy: 0.8732244318181818 \n",
      "Epoch 10 | Step 3672 | loss: 0.30259537630610994 | accuracy: 0.8708333333333333 \n",
      "Epoch 10 | Step 3673 | loss: 0.3041269831035448 | accuracy: 0.8705842391304348 \n",
      "Epoch 10 | Step 3674 | loss: 0.3033522253340863 | accuracy: 0.870345744680851 \n",
      "Epoch 10 | Step 3675 | loss: 0.305896071717143 | accuracy: 0.869140625 \n",
      "Epoch 10 | Step 3676 | loss: 0.30413256616008516 | accuracy: 0.8695790816326531 \n",
      "Epoch 10 | Step 3677 | loss: 0.30628619790077205 | accuracy: 0.8696875 \n",
      "Epoch 10 | Step 3678 | loss: 0.3088648979570351 | accuracy: 0.867953431372549 \n",
      "Epoch 10 | Step 3679 | loss: 0.31003504131848997 | accuracy: 0.8668870192307693 \n",
      "Epoch 10 | Step 3680 | loss: 0.3084196760407034 | accuracy: 0.8673349056603774 \n",
      "Epoch 10 | Step 3681 | loss: 0.3076556725082574 | accuracy: 0.8677662037037037 \n",
      "Epoch 10 | Step 3682 | loss: 0.3068739411505786 | accuracy: 0.8681818181818182 \n",
      "Epoch 10 | Step 3683 | loss: 0.3073139459426914 | accuracy: 0.8685825892857143 \n",
      "Epoch 10 | Step 3684 | loss: 0.30722129632506456 | accuracy: 0.8695175438596491 \n",
      "Epoch 10 | Step 3685 | loss: 0.3078751859479937 | accuracy: 0.8685344827586207 \n",
      "Epoch 10 | Step 3686 | loss: 0.3081364467487497 | accuracy: 0.8686440677966102 \n",
      "Epoch 10 | Step 3687 | loss: 0.3091394824286302 | accuracy: 0.8684895833333334 \n",
      "Epoch 10 | Step 3688 | loss: 0.30883269011974335 | accuracy: 0.8683401639344263 \n",
      "Epoch 10 | Step 3689 | loss: 0.30858870307284014 | accuracy: 0.868195564516129 \n",
      "Epoch 10 | Step 3690 | loss: 0.3089979529853851 | accuracy: 0.8680555555555556 \n",
      "Epoch 10 | Step 3691 | loss: 0.3068359885364771 | accuracy: 0.86962890625 \n",
      "Epoch 10 | Step 3692 | loss: 0.3066048654226156 | accuracy: 0.8694711538461538 \n",
      "Epoch 10 | Step 3693 | loss: 0.30459273583961255 | accuracy: 0.8702651515151515 \n",
      "Epoch 10 | Step 3694 | loss: 0.3040621547556635 | accuracy: 0.8708022388059702 \n",
      "Epoch 10 | Step 3695 | loss: 0.30362461814109015 | accuracy: 0.8715533088235294 \n",
      "Epoch 10 | Step 3696 | loss: 0.3049060266087021 | accuracy: 0.8713768115942029 \n",
      "Epoch 10 | Step 3697 | loss: 0.3070019032273974 | accuracy: 0.8696428571428572 \n",
      "Epoch 10 | Step 3698 | loss: 0.3060650179083918 | accuracy: 0.8699383802816901 \n",
      "Epoch 10 | Step 3699 | loss: 0.3055582054787212 | accuracy: 0.8702256944444444 \n",
      "Epoch 10 | Step 3700 | loss: 0.3058893880615496 | accuracy: 0.870291095890411 \n",
      "Epoch 10 | Step 3701 | loss: 0.3066778722647074 | accuracy: 0.8697212837837838 \n",
      "Epoch 10 | Step 3702 | loss: 0.3078150010108947 | accuracy: 0.8697916666666666 \n",
      "Epoch 10 | Step 3703 | loss: 0.3071445991334162 | accuracy: 0.8700657894736842 \n",
      "Epoch 10 | Step 3704 | loss: 0.3070802409927566 | accuracy: 0.869724025974026 \n",
      "Epoch 10 | Step 3705 | loss: 0.308629837555763 | accuracy: 0.8689903846153846 \n",
      "Epoch 10 | Step 3706 | loss: 0.3073684533562841 | accuracy: 0.8700553797468354 \n",
      "Epoch 10 | Step 3707 | loss: 0.30770968254655595 | accuracy: 0.8693359375 \n",
      "Epoch 10 | Step 3708 | loss: 0.3069860637187957 | accuracy: 0.8699845679012346 \n",
      "Epoch 10 | Step 3709 | loss: 0.3055058821308903 | accuracy: 0.8709984756097561 \n",
      "Epoch 10 | Step 3710 | loss: 0.3053254472563065 | accuracy: 0.8714231927710844 \n",
      "Epoch 10 | Step 3711 | loss: 0.30552803955617397 | accuracy: 0.8716517857142857 \n",
      "Epoch 10 | Step 3712 | loss: 0.30647666717276845 | accuracy: 0.8713235294117647 \n",
      "Epoch 10 | Step 3713 | loss: 0.30587490925262134 | accuracy: 0.8719113372093024 \n",
      "Epoch 10 | Step 3714 | loss: 0.30630839607496363 | accuracy: 0.8717672413793104 \n",
      "Epoch 10 | Step 3715 | loss: 0.30685726400803426 | accuracy: 0.8721590909090909 \n",
      "Epoch 10 | Step 3716 | loss: 0.3061309666111227 | accuracy: 0.8727176966292135 \n",
      "Epoch 10 | Step 3717 | loss: 0.3070625535315936 | accuracy: 0.8720486111111111 \n",
      "Epoch 10 | Step 3718 | loss: 0.3062233562980378 | accuracy: 0.8720810439560439 \n",
      "Epoch 10 | Step 3719 | loss: 0.30872162447675405 | accuracy: 0.87109375 \n",
      "Epoch 10 | Step 3720 | loss: 0.30853397279016426 | accuracy: 0.8713037634408602 \n",
      "Epoch 10 | Step 3721 | loss: 0.30790580983491644 | accuracy: 0.871343085106383 \n",
      "Epoch 10 | Step 3722 | loss: 0.30670710896190834 | accuracy: 0.8720394736842105 \n",
      "Epoch 10 | Step 3723 | loss: 0.3060086898816127 | accuracy: 0.8720703125 \n",
      "Epoch 10 | Step 3724 | loss: 0.30516617261257356 | accuracy: 0.8730670103092784 \n",
      "Epoch 10 | Step 3725 | loss: 0.3072109423121626 | accuracy: 0.8718112244897959 \n",
      "Epoch 10 | Step 3726 | loss: 0.30681635484550923 | accuracy: 0.8720012626262627 \n",
      "Epoch 10 | Step 3727 | loss: 0.30655739903449997 | accuracy: 0.871875 \n",
      "Epoch 10 | Step 3728 | loss: 0.30610481937332895 | accuracy: 0.8720606435643564 \n",
      "Epoch 10 | Step 3729 | loss: 0.30642376168101426 | accuracy: 0.8717830882352942 \n",
      "Epoch 10 | Step 3730 | loss: 0.3065396035180507 | accuracy: 0.8716626213592233 \n",
      "Epoch 10 | Step 3731 | loss: 0.3066323201816814 | accuracy: 0.8718449519230769 \n",
      "Epoch 10 | Step 3732 | loss: 0.3073334358987353 | accuracy: 0.8711309523809524 \n",
      "Epoch 10 | Step 3733 | loss: 0.3063135461987188 | accuracy: 0.8717570754716981 \n",
      "Epoch 10 | Step 3734 | loss: 0.30761374324281626 | accuracy: 0.8713492990654206 \n",
      "Epoch 10 | Step 3735 | loss: 0.3086294782934364 | accuracy: 0.8709490740740741 \n",
      "Epoch 10 | Step 3736 | loss: 0.3079232913911888 | accuracy: 0.8714162844036697 \n",
      "Epoch 10 | Step 3737 | loss: 0.3077572089704599 | accuracy: 0.8713068181818182 \n",
      "Epoch 10 | Step 3738 | loss: 0.3089140689856296 | accuracy: 0.8706362612612613 \n",
      "Epoch 10 | Step 3739 | loss: 0.31013608737183457 | accuracy: 0.8703962053571429 \n",
      "Epoch 10 | Step 3740 | loss: 0.31104564679934904 | accuracy: 0.8698838495575221 \n",
      "Epoch 10 | Step 3741 | loss: 0.3109951180062795 | accuracy: 0.8700657894736842 \n",
      "Epoch 10 | Step 3742 | loss: 0.3099420022705326 | accuracy: 0.8705163043478261 \n",
      "Epoch 10 | Step 3743 | loss: 0.3097770068922946 | accuracy: 0.8705549568965517 \n",
      "Epoch 10 | Step 3744 | loss: 0.30949292516606475 | accuracy: 0.8705929487179487 \n",
      "Epoch 10 | Step 3745 | loss: 0.3098354401477311 | accuracy: 0.8704978813559322 \n",
      "Epoch 10 | Step 3746 | loss: 0.3106308710925718 | accuracy: 0.8700105042016807 \n",
      "Epoch 10 | Step 3747 | loss: 0.3104557510465382 | accuracy: 0.869921875 \n",
      "Epoch 10 | Step 3748 | loss: 0.30972484887138857 | accuracy: 0.8700929752066116 \n",
      "Epoch 10 | Step 3749 | loss: 0.3093348641376025 | accuracy: 0.8703893442622951 \n",
      "Epoch 10 | Step 3750 | loss: 0.30937511964542097 | accuracy: 0.8704268292682927 \n",
      "Epoch 10 | Step 3751 | loss: 0.3096911979298437 | accuracy: 0.8704637096774194 \n",
      "Epoch 10 | Step 3752 | loss: 0.3091823518276213 | accuracy: 0.870875 \n",
      "Epoch 10 | Step 3753 | loss: 0.3092177214603574 | accuracy: 0.8705357142857143 \n",
      "Epoch 10 | Step 3754 | loss: 0.3105101629974334 | accuracy: 0.8699557086614174 \n",
      "Epoch 10 | Step 3755 | loss: 0.3106032242067157 | accuracy: 0.8699951171875 \n",
      "Epoch 10 | Step 3756 | loss: 0.3101242415664731 | accuracy: 0.8701550387596899 \n",
      "Epoch 10 | Step 3757 | loss: 0.3103870554612232 | accuracy: 0.8700721153846154 \n",
      "Epoch 10 | Step 3758 | loss: 0.3105249420832131 | accuracy: 0.8699904580152672 \n",
      "Epoch 10 | Step 3759 | loss: 0.3103560030911907 | accuracy: 0.8697916666666666 \n",
      "Epoch 10 | Step 3760 | loss: 0.3100272782314988 | accuracy: 0.8697133458646616 \n",
      "Epoch 10 | Step 3761 | loss: 0.3101618857081256 | accuracy: 0.8696361940298507 \n",
      "Epoch 10 | Step 3762 | loss: 0.310598243607415 | accuracy: 0.8694444444444445 \n",
      "Epoch 10 | Step 3763 | loss: 0.3106086582821957 | accuracy: 0.8698299632352942 \n",
      "Epoch 10 | Step 3764 | loss: 0.3104833973585253 | accuracy: 0.870095802919708 \n",
      "Epoch 10 | Step 3765 | loss: 0.31033703835978016 | accuracy: 0.8701313405797102 \n",
      "Epoch 10 | Step 3766 | loss: 0.3105051243047919 | accuracy: 0.8696043165467627 \n",
      "Epoch 10 | Step 3767 | loss: 0.3097924840237412 | accuracy: 0.8699776785714287 \n",
      "Epoch 10 | Step 3768 | loss: 0.30980268490652657 | accuracy: 0.8700132978723405 \n",
      "Epoch 10 | Step 3769 | loss: 0.30962879420586026 | accuracy: 0.8700484154929579 \n",
      "Epoch 10 | Step 3770 | loss: 0.30962732673941784 | accuracy: 0.8703015734265735 \n",
      "Epoch 10 | Step 3771 | loss: 0.3088647668353384 | accuracy: 0.8707682291666667 \n",
      "Epoch 10 | Step 3772 | loss: 0.3086445949200925 | accuracy: 0.8709051724137932 \n",
      "Epoch 10 | Step 3773 | loss: 0.3097342174143006 | accuracy: 0.8702910958904111 \n",
      "Epoch 10 | Step 3774 | loss: 0.30929865591785527 | accuracy: 0.8708545918367347 \n",
      "Epoch 10 | Step 3775 | loss: 0.30894809186055844 | accuracy: 0.870777027027027 \n",
      "Epoch 10 | Step 3776 | loss: 0.30856130957203415 | accuracy: 0.871119966442953 \n",
      "Epoch 10 | Step 3777 | loss: 0.30827298790216434 | accuracy: 0.8709375 \n",
      "Epoch 10 | Step 3778 | loss: 0.30828046177001966 | accuracy: 0.8708609271523179 \n",
      "Epoch 10 | Step 3779 | loss: 0.30885062102032323 | accuracy: 0.8704769736842105 \n",
      "Epoch 10 | Step 3780 | loss: 0.3086733135327793 | accuracy: 0.870812908496732 \n",
      "Epoch 10 | Step 3781 | loss: 0.3085183465442099 | accuracy: 0.8708400974025974 \n",
      "Epoch 10 | Step 3782 | loss: 0.30793783587794143 | accuracy: 0.8710685483870968 \n",
      "Epoch 10 | Step 3783 | loss: 0.3074481078447439 | accuracy: 0.8714943910256411 \n",
      "Epoch 10 | Step 3784 | loss: 0.3067541342632026 | accuracy: 0.8719148089171974 \n",
      "Epoch 10 | Step 3785 | loss: 0.3066096058751963 | accuracy: 0.871934335443038 \n",
      "Epoch 10 | Step 3786 | loss: 0.3062743089109096 | accuracy: 0.8721501572327044 \n",
      "Epoch 10 | Step 3787 | loss: 0.30628493651747696 | accuracy: 0.87216796875 \n",
      "Epoch 10 | Step 3788 | loss: 0.3059730714892748 | accuracy: 0.8722826086956522 \n",
      "Epoch 10 | Step 3789 | loss: 0.3064417518951274 | accuracy: 0.8722029320987654 \n",
      "Epoch 10 | Step 3790 | loss: 0.30596378811297964 | accuracy: 0.8724118098159509 \n",
      "Epoch 10 | Step 3791 | loss: 0.3055493363701715 | accuracy: 0.8727134146341463 \n",
      "Epoch 10 | Step 3792 | loss: 0.30543511193810086 | accuracy: 0.8728219696969697 \n",
      "Epoch 10 | Step 3793 | loss: 0.3065812260092023 | accuracy: 0.8718938253012049 \n",
      "Epoch 10 | Step 3794 | loss: 0.3059393681451946 | accuracy: 0.8721931137724551 \n",
      "Epoch 10 | Step 3795 | loss: 0.30571804373037254 | accuracy: 0.8723028273809523 \n",
      "Epoch 10 | Step 3796 | loss: 0.30652456646840254 | accuracy: 0.8720414201183432 \n",
      "Epoch 10 | Step 3797 | loss: 0.30595338774078035 | accuracy: 0.8724264705882353 \n",
      "Epoch 10 | Step 3798 | loss: 0.3063175916148906 | accuracy: 0.8720760233918129 \n",
      "Epoch 10 | Step 3799 | loss: 0.30688941729969765 | accuracy: 0.8719113372093024 \n",
      "Epoch 10 | Step 3800 | loss: 0.3059410862839981 | accuracy: 0.872471098265896 \n",
      "Epoch 10 | Step 3801 | loss: 0.306153402246278 | accuracy: 0.8723060344827587 \n",
      "Epoch 10 | Step 3802 | loss: 0.3054624968767167 | accuracy: 0.8725892857142857 \n",
      "Epoch 10 | Step 3803 | loss: 0.30555532407015573 | accuracy: 0.8726029829545454 \n",
      "Epoch 10 | Step 3804 | loss: 0.30580829639556056 | accuracy: 0.8725282485875706 \n",
      "Epoch 10 | Step 3805 | loss: 0.3056496379248213 | accuracy: 0.8725421348314607 \n",
      "Epoch 10 | Step 3806 | loss: 0.3060212161121423 | accuracy: 0.8722939944134078 \n",
      "Epoch 10 | Step 3807 | loss: 0.3065704887939825 | accuracy: 0.8717013888888889 \n",
      "Epoch 10 | Step 3808 | loss: 0.30651510362796375 | accuracy: 0.8716332872928176 \n",
      "Epoch 10 | Step 3809 | loss: 0.30604758351058764 | accuracy: 0.8719093406593407 \n",
      "Epoch 10 | Step 3810 | loss: 0.3059304359832098 | accuracy: 0.8718408469945356 \n",
      "Epoch 10 | Step 3811 | loss: 0.3058651760220529 | accuracy: 0.8719429347826086 \n",
      "Epoch 10 | Step 3812 | loss: 0.3057981421818605 | accuracy: 0.872043918918919 \n",
      "Epoch 10 | Step 3813 | loss: 0.30550873920481697 | accuracy: 0.872059811827957 \n",
      "Epoch 10 | Step 3814 | loss: 0.30575563133081657 | accuracy: 0.8720755347593583 \n",
      "Epoch 10 | Step 3815 | loss: 0.3055129238265627 | accuracy: 0.8720910904255319 \n",
      "Epoch 10 | Step 3816 | loss: 0.30501986842937584 | accuracy: 0.8723544973544973 \n",
      "Epoch 10 | Step 3817 | loss: 0.30470503921571546 | accuracy: 0.8726151315789473 \n",
      "Epoch 10 | Step 3818 | loss: 0.3048008598426251 | accuracy: 0.8723821989528796 \n",
      "Epoch 10 | Step 3819 | loss: 0.3048778676893564 | accuracy: 0.8722330729166666 \n",
      "Epoch 10 | Step 3820 | loss: 0.3047871094756795 | accuracy: 0.8723283678756477 \n",
      "Epoch 10 | Step 3821 | loss: 0.30473156204235935 | accuracy: 0.8723421391752577 \n",
      "Epoch 10 | Step 3822 | loss: 0.30488298741670766 | accuracy: 0.872275641025641 \n",
      "Epoch 10 | Step 3823 | loss: 0.3045084737241269 | accuracy: 0.8725286989795918 \n",
      "Epoch 10 | Step 3824 | loss: 0.3045057783725904 | accuracy: 0.8724619289340102 \n",
      "Epoch 10 | Step 3825 | loss: 0.30429118939421407 | accuracy: 0.8726325757575758 \n",
      "Epoch 10 | Step 3826 | loss: 0.3043728549426526 | accuracy: 0.8726444723618091 \n",
      "Epoch 10 | Step 3827 | loss: 0.30427385978400723 | accuracy: 0.872421875 \n",
      "Epoch 10 | Step 3828 | loss: 0.3042919655789192 | accuracy: 0.8722792288557214 \n",
      "Epoch 10 | Step 3829 | loss: 0.30453241985328144 | accuracy: 0.8720606435643564 \n",
      "Epoch 10 | Step 3830 | loss: 0.3047187431839301 | accuracy: 0.8721520935960592 \n",
      "Epoch 10 | Step 3831 | loss: 0.3049720267893054 | accuracy: 0.8719362745098039 \n",
      "Epoch 10 | Step 3832 | loss: 0.30507677844384834 | accuracy: 0.8720274390243903 \n",
      "Epoch 10 | Step 3833 | loss: 0.3053139851075933 | accuracy: 0.8719660194174758 \n",
      "Epoch 10 | Step 3834 | loss: 0.3051640111323141 | accuracy: 0.8719806763285024 \n",
      "Epoch 10 | Step 3835 | loss: 0.3049318017438055 | accuracy: 0.8719951923076923 \n",
      "Epoch 10 | Step 3836 | loss: 0.30491744423882255 | accuracy: 0.8719348086124402 \n",
      "Epoch 10 | Step 3837 | loss: 0.30441701092890344 | accuracy: 0.872172619047619 \n",
      "Epoch 10 | Step 3838 | loss: 0.3042806958276515 | accuracy: 0.8721119668246445 \n",
      "Epoch 10 | Step 3839 | loss: 0.3044063744820515 | accuracy: 0.8720518867924528 \n",
      "Epoch 10 | Step 3840 | loss: 0.30424017154834654 | accuracy: 0.8720657276995305 \n",
      "Epoch 10 | Step 3841 | loss: 0.3043137385605653 | accuracy: 0.8722254672897196 \n",
      "Epoch 10 | Step 3842 | loss: 0.30453844105088446 | accuracy: 0.871875 \n",
      "Epoch 10 | Step 3843 | loss: 0.30485035858496484 | accuracy: 0.8719618055555556 \n",
      "Epoch 10 | Step 3844 | loss: 0.3052218316749495 | accuracy: 0.871903801843318 \n",
      "Epoch 10 | Step 3845 | loss: 0.3054704515075466 | accuracy: 0.8718463302752294 \n",
      "Epoch 10 | Step 3846 | loss: 0.30548057116602123 | accuracy: 0.8717180365296804 \n",
      "Epoch 10 | Step 3847 | loss: 0.30541586923328323 | accuracy: 0.8717329545454545 \n",
      "Epoch 10 | Step 3848 | loss: 0.3053451253952485 | accuracy: 0.8718891402714932 \n",
      "Epoch 10 | Step 3849 | loss: 0.3052241214895035 | accuracy: 0.8718327702702703 \n",
      "Epoch 10 | Step 3850 | loss: 0.30516283107178105 | accuracy: 0.8717769058295964 \n",
      "Epoch 10 | Step 3851 | loss: 0.30536362349188767 | accuracy: 0.8716517857142857 \n",
      "Epoch 10 | Step 3852 | loss: 0.3054574866427317 | accuracy: 0.8714583333333333 \n",
      "Epoch 10 | Step 3853 | loss: 0.30532458365227283 | accuracy: 0.8714740044247787 \n",
      "Epoch 10 | Step 3854 | loss: 0.3053365073408851 | accuracy: 0.8716272026431718 \n",
      "Epoch 10 | Step 3855 | loss: 0.30517227366043825 | accuracy: 0.8717105263157895 \n",
      "Epoch 10 | Step 3856 | loss: 0.30492440315052943 | accuracy: 0.8717931222707423 \n",
      "Epoch 10 | Step 3857 | loss: 0.3048910126090051 | accuracy: 0.8716711956521739 \n",
      "Epoch 10 | Step 3858 | loss: 0.3046372236111465 | accuracy: 0.8718208874458875 \n",
      "Epoch 10 | Step 3859 | loss: 0.3042688289464549 | accuracy: 0.8719692887931034 \n",
      "Epoch 10 | Step 3860 | loss: 0.304065156584134 | accuracy: 0.8721164163090128 \n",
      "Epoch 10 | Step 3861 | loss: 0.304350996310385 | accuracy: 0.8719951923076923 \n",
      "Epoch 10 | Step 3862 | loss: 0.3038456731020137 | accuracy: 0.8722739361702128 \n",
      "Epoch 10 | Step 3863 | loss: 0.30358782511646476 | accuracy: 0.872219279661017 \n",
      "Epoch 10 | Step 3864 | loss: 0.30363888881377543 | accuracy: 0.8722310126582279 \n",
      "Epoch 10 | Step 3865 | loss: 0.30416330006443165 | accuracy: 0.8719800420168067 \n",
      "Epoch 10 | Step 3866 | loss: 0.3041771809925097 | accuracy: 0.8719273012552301 \n",
      "Epoch 10 | Step 3867 | loss: 0.30418159092466046 | accuracy: 0.8718098958333333 \n",
      "Epoch 10 | Step 3868 | loss: 0.30463616667446763 | accuracy: 0.8714989626556017 \n",
      "Epoch 10 | Step 3869 | loss: 0.304941456672574 | accuracy: 0.8714488636363636 \n",
      "Epoch 10 | Step 3870 | loss: 0.3045942940339141 | accuracy: 0.8715920781893004 \n",
      "Epoch 10 | Step 3871 | loss: 0.30415346943697 | accuracy: 0.8718621926229508 \n",
      "Epoch 10 | Step 3872 | loss: 0.3038638271847551 | accuracy: 0.871938775510204 \n",
      "Epoch 10 | Step 3873 | loss: 0.30366048846787563 | accuracy: 0.8720782520325203 \n",
      "Epoch 10 | Step 3874 | loss: 0.3033811953748287 | accuracy: 0.8722798582995951 \n",
      "Epoch 10 | Step 3875 | loss: 0.3034610307865567 | accuracy: 0.8722278225806451 \n",
      "Epoch 10 | Step 3876 | loss: 0.3038692743064889 | accuracy: 0.8721134538152611 \n",
      "Epoch 10 | Step 3877 | loss: 0.3036565033793451 | accuracy: 0.8721875 \n",
      "Epoch 10 | Step 3878 | loss: 0.30386578674572884 | accuracy: 0.872074203187251 \n",
      "Epoch 10 | Step 3879 | loss: 0.30452831213672965 | accuracy: 0.8717137896825397 \n",
      "Epoch 10 | Step 3880 | loss: 0.30445270475898345 | accuracy: 0.8716650197628458 \n",
      "Epoch 10 | Step 3881 | loss: 0.30449428644001963 | accuracy: 0.8715551181102362 \n",
      "Epoch 10 | Step 3882 | loss: 0.3043452382672068 | accuracy: 0.8716299019607843 \n",
      "Epoch 10 | Step 3883 | loss: 0.30431151849916216 | accuracy: 0.8717041015625 \n",
      "Epoch 10 | Step 3884 | loss: 0.3044843603548838 | accuracy: 0.8715345330739299 \n",
      "Epoch 10 | Step 3885 | loss: 0.30435684698727716 | accuracy: 0.8716085271317829 \n",
      "Epoch 10 | Step 3886 | loss: 0.30444703006606316 | accuracy: 0.8716819498069498 \n",
      "Epoch 10 | Step 3887 | loss: 0.3045933779042502 | accuracy: 0.8716346153846154 \n",
      "Epoch 10 | Step 3888 | loss: 0.30489783696973016 | accuracy: 0.8715876436781609 \n",
      "Epoch 10 | Step 3889 | loss: 0.3053506811270278 | accuracy: 0.8713621183206107 \n",
      "Epoch 10 | Step 3890 | loss: 0.30561319021897637 | accuracy: 0.8711977186311787 \n",
      "Epoch 10 | Step 3891 | loss: 0.3057380589007429 | accuracy: 0.8709753787878788 \n",
      "Epoch 10 | Step 3892 | loss: 0.30579753062635107 | accuracy: 0.870813679245283 \n",
      "Epoch 10 | Step 3893 | loss: 0.3058271722349907 | accuracy: 0.8708881578947368 \n",
      "Epoch 10 | Step 3894 | loss: 0.3055307367879354 | accuracy: 0.8710791198501873 \n",
      "Epoch 10 | Step 3895 | loss: 0.30593518540263187 | accuracy: 0.871035447761194 \n",
      "Epoch 10 | Step 3896 | loss: 0.30590436377711466 | accuracy: 0.8708759293680297 \n",
      "Epoch 10 | Step 3897 | loss: 0.30588076219514576 | accuracy: 0.8709490740740741 \n",
      "Epoch 10 | Step 3898 | loss: 0.3056901927033915 | accuracy: 0.8710216789667896 \n",
      "Epoch 10 | Step 3899 | loss: 0.30555832435322167 | accuracy: 0.8709214154411764 \n",
      "Epoch 10 | Step 3900 | loss: 0.30547621240327655 | accuracy: 0.8709363553113552 \n",
      "Epoch 10 | Step 3901 | loss: 0.30553121087107354 | accuracy: 0.8708371350364963 \n",
      "Epoch 10 | Step 3902 | loss: 0.30597148228775384 | accuracy: 0.8705681818181817 \n",
      "Epoch 10 | Step 3903 | loss: 0.3061609128355117 | accuracy: 0.8705842391304347 \n",
      "Epoch 10 | Step 3904 | loss: 0.3062649730202955 | accuracy: 0.8706001805054151 \n",
      "Epoch 10 | Step 3905 | loss: 0.3059161769614804 | accuracy: 0.870728417266187 \n",
      "Epoch 10 | Step 3906 | loss: 0.3063391293248824 | accuracy: 0.8705757168458781 \n",
      "Epoch 10 | Step 3907 | loss: 0.3060053541724172 | accuracy: 0.8706473214285714 \n",
      "Epoch 10 | Step 3908 | loss: 0.30614703262615894 | accuracy: 0.8704403914590746 \n",
      "Epoch 10 | Step 3909 | loss: 0.3059575893249073 | accuracy: 0.8705119680851063 \n",
      "Epoch 10 | Step 3910 | loss: 0.3059410626075294 | accuracy: 0.8705830388692579 \n",
      "Epoch 10 | Step 3911 | loss: 0.305720947945202 | accuracy: 0.8707086267605634 \n",
      "Epoch 10 | Step 3912 | loss: 0.30572972825744704 | accuracy: 0.8707236842105263 \n",
      "Epoch 10 | Step 3913 | loss: 0.30533190123684767 | accuracy: 0.8709571678321677 \n",
      "Epoch 10 | Step 3914 | loss: 0.3052235809560438 | accuracy: 0.8709168118466898 \n",
      "Epoch 10 | Step 3915 | loss: 0.3047562535955675 | accuracy: 0.8711480034722221 \n",
      "Epoch 10 | Step 3916 | loss: 0.3049091460073696 | accuracy: 0.871107266435986 \n",
      "Epoch 10 | Step 3917 | loss: 0.304971017457288 | accuracy: 0.8711745689655171 \n",
      "Epoch 10 | Step 3918 | loss: 0.3052350643676582 | accuracy: 0.8710266323024054 \n",
      "Epoch 10 | Step 3919 | loss: 0.3050010746268378 | accuracy: 0.8710402397260273 \n",
      "Epoch 10 | Step 3920 | loss: 0.30534219823192826 | accuracy: 0.8708404436860068 \n",
      "Epoch 10 | Step 3921 | loss: 0.30517276928943854 | accuracy: 0.8708545918367347 \n",
      "Epoch 10 | Step 3922 | loss: 0.30500689967203964 | accuracy: 0.8710275423728814 \n",
      "Epoch 10 | Step 3923 | loss: 0.3051700258778561 | accuracy: 0.8709353885135135 \n",
      "Epoch 10 | Step 3924 | loss: 0.3049000216152533 | accuracy: 0.8711595117845118 \n",
      "Epoch 10 | Step 3925 | loss: 0.3051929820403958 | accuracy: 0.871067533557047 \n",
      "Epoch 10 | Step 3926 | loss: 0.3049985266549134 | accuracy: 0.8711329431438127 \n",
      "Epoch 10 | Step 3927 | loss: 0.30477792118986463 | accuracy: 0.8711979166666667 \n",
      "Epoch 10 | Step 3928 | loss: 0.30482293566398067 | accuracy: 0.8711586378737541 \n",
      "Epoch 10 | Step 3929 | loss: 0.3045993228720515 | accuracy: 0.8713783112582781 \n",
      "Epoch 10 | Step 3930 | loss: 0.3044739091652063 | accuracy: 0.871493399339934 \n",
      "Epoch 10 | Step 3931 | loss: 0.30461766860006684 | accuracy: 0.871350740131579 \n",
      "Epoch 10 | Step 3932 | loss: 0.30434623560944557 | accuracy: 0.871516393442623 \n",
      "Epoch 10 | Step 3933 | loss: 0.304365647628027 | accuracy: 0.8715277777777778 \n",
      "Epoch 10 | Step 3934 | loss: 0.30455174348059244 | accuracy: 0.8714372964169381 \n",
      "Epoch 10 | Step 3935 | loss: 0.30426965576487713 | accuracy: 0.8715503246753247 \n",
      "Epoch 10 | Step 3936 | loss: 0.30394278143601905 | accuracy: 0.8716120550161812 \n",
      "Epoch 10 | Step 3937 | loss: 0.3040782852518944 | accuracy: 0.8715221774193549 \n",
      "Epoch 10 | Step 3938 | loss: 0.3041187330265905 | accuracy: 0.8715836012861736 \n",
      "Epoch 10 | Step 3939 | loss: 0.3040388256120377 | accuracy: 0.8716446314102564 \n",
      "Epoch 10 | Step 3940 | loss: 0.3039958648407422 | accuracy: 0.8716054313099042 \n",
      "Epoch 10 | Step 3941 | loss: 0.3044106438281431 | accuracy: 0.8714171974522293 \n",
      "Epoch 10 | Step 3942 | loss: 0.30499499241511036 | accuracy: 0.8711805555555555 \n",
      "Epoch 10 | Step 3943 | loss: 0.3050264853842652 | accuracy: 0.8712420886075949 \n",
      "Epoch 10 | Step 3944 | loss: 0.30453815957537217 | accuracy: 0.871598974763407 \n",
      "Epoch 10 | Step 3945 | loss: 0.30469226598177324 | accuracy: 0.8716096698113207 \n",
      "Epoch 10 | Step 3946 | loss: 0.3048422856484088 | accuracy: 0.8715713166144201 \n",
      "Epoch 10 | Step 3947 | loss: 0.3046487686689944 | accuracy: 0.87158203125 \n",
      "Epoch 10 | Step 3948 | loss: 0.304554802281463 | accuracy: 0.8715926791277259 \n",
      "Epoch 10 | Step 3949 | loss: 0.3050409468897382 | accuracy: 0.8715062111801242 \n",
      "Epoch 10 | Step 3950 | loss: 0.3047695185746941 | accuracy: 0.8716621517027864 \n",
      "Epoch 10 | Step 3951 | loss: 0.30461582283914834 | accuracy: 0.8718171296296297 \n",
      "Epoch 10 | Step 3952 | loss: 0.30487988004317657 | accuracy: 0.8718269230769231 \n",
      "Epoch 10 | Step 3953 | loss: 0.30487548729027714 | accuracy: 0.8718845858895705 \n",
      "Epoch 10 | Step 3954 | loss: 0.3050230305858344 | accuracy: 0.8717029816513762 \n",
      "Epoch 10 | Step 3955 | loss: 0.3052406383723748 | accuracy: 0.8716177591463414 \n",
      "Epoch 10 | Step 3956 | loss: 0.3054522284077294 | accuracy: 0.8714380699088146 \n",
      "Epoch 10 | Step 3957 | loss: 0.3053343613039364 | accuracy: 0.8714962121212121 \n",
      "Epoch 10 | Step 3958 | loss: 0.30543212543081305 | accuracy: 0.8714123867069486 \n",
      "Epoch 10 | Step 3959 | loss: 0.3053891625569528 | accuracy: 0.8715173192771084 \n",
      "Epoch 10 | Step 3960 | loss: 0.30552075843553295 | accuracy: 0.8715277777777778 \n",
      "Epoch 10 | Step 3961 | loss: 0.3055366994199639 | accuracy: 0.8716317365269461 \n",
      "Epoch 10 | Step 3962 | loss: 0.30534882919112255 | accuracy: 0.8717350746268657 \n",
      "Epoch 10 | Step 3963 | loss: 0.305294036066958 | accuracy: 0.8717912946428571 \n",
      "Epoch 10 | Step 3964 | loss: 0.3052363406303022 | accuracy: 0.8718935459940653 \n",
      "Epoch 10 | Step 3965 | loss: 0.3054232732255079 | accuracy: 0.8719489644970414 \n",
      "Epoch 10 | Step 3966 | loss: 0.3051231954917093 | accuracy: 0.8720962389380531 \n",
      "Epoch 10 | Step 3967 | loss: 0.3049309514462949 | accuracy: 0.8722426470588235 \n",
      "Epoch 10 | Step 3968 | loss: 0.3051945073775883 | accuracy: 0.8721132697947214 \n",
      "Epoch 10 | Step 3969 | loss: 0.30503753267707895 | accuracy: 0.8720760233918129 \n",
      "Epoch 10 | Step 3970 | loss: 0.30491161428978436 | accuracy: 0.8722212099125365 \n",
      "Epoch 10 | Step 3971 | loss: 0.3047203098878612 | accuracy: 0.8722747093023255 \n",
      "Epoch 10 | Step 3972 | loss: 0.30491832360841237 | accuracy: 0.8722373188405798 \n",
      "Epoch 10 | Step 3973 | loss: 0.3050091202462341 | accuracy: 0.872245303468208 \n",
      "Epoch 10 | Step 3974 | loss: 0.3047879844130976 | accuracy: 0.8723883285302594 \n",
      "Epoch 10 | Step 3975 | loss: 0.30528267318832475 | accuracy: 0.8721264367816092 \n",
      "Epoch 10 | Step 3976 | loss: 0.30511863764514224 | accuracy: 0.8722242120343839 \n",
      "Epoch 10 | Step 3977 | loss: 0.3049256981270655 | accuracy: 0.8723214285714286 \n",
      "Epoch 10 | Step 3978 | loss: 0.3047649027445379 | accuracy: 0.8724626068376068 \n",
      "Epoch 10 | Step 3979 | loss: 0.304768594574522 | accuracy: 0.8725142045454546 \n",
      "Epoch 10 | Step 3980 | loss: 0.30481387847881486 | accuracy: 0.8725212464589235 \n",
      "Epoch 10 | Step 3981 | loss: 0.30471976850665905 | accuracy: 0.8724841101694916 \n",
      "Epoch 10 | Step 3982 | loss: 0.30479055886537265 | accuracy: 0.8725352112676056 \n",
      "Epoch 10 | Step 3983 | loss: 0.30458217432324813 | accuracy: 0.8726299157303371 \n",
      "Epoch 10 | Step 3984 | loss: 0.3042985404155502 | accuracy: 0.8727240896358543 \n",
      "Epoch 10 | Step 3985 | loss: 0.30435028518211915 | accuracy: 0.872643156424581 \n",
      "Epoch 10 | Step 3986 | loss: 0.30422082173957143 | accuracy: 0.8726932451253482 \n",
      "Epoch 10 | Step 3987 | loss: 0.3043323275529677 | accuracy: 0.8726996527777777 \n",
      "Epoch 10 | Step 3988 | loss: 0.3041019128465257 | accuracy: 0.8728791551246537 \n",
      "Epoch 10 | Step 3989 | loss: 0.30432903363230485 | accuracy: 0.8727986878453039 \n",
      "Epoch 10 | Step 3990 | loss: 0.30449409384701215 | accuracy: 0.8727186639118457 \n",
      "Epoch 10 | Step 3991 | loss: 0.3042687387256833 | accuracy: 0.8728537087912088 \n",
      "Epoch 10 | Step 3992 | loss: 0.30428114655899685 | accuracy: 0.8727739726027397 \n",
      "Epoch 10 | Step 3993 | loss: 0.3041967037108428 | accuracy: 0.8728227459016393 \n",
      "Epoch 10 | Step 3994 | loss: 0.30399472183200266 | accuracy: 0.8728286784741145 \n",
      "Epoch 10 | Step 3995 | loss: 0.3041358605108185 | accuracy: 0.8728770380434783 \n",
      "Epoch 10 | Step 3996 | loss: 0.30414727148486365 | accuracy: 0.8729674796747967 \n",
      "Epoch 10 | Step 3997 | loss: 0.30445085268568367 | accuracy: 0.8728462837837838 \n",
      "Epoch 10 | Step 3998 | loss: 0.3048240805491606 | accuracy: 0.8727678571428571 \n",
      "Epoch 10 | Step 3999 | loss: 0.3049326048342773 | accuracy: 0.8726898521505376 \n",
      "Epoch 10 | Step 4000 | loss: 0.30505109300722083 | accuracy: 0.8726541554959786 \n",
      "Epoch 10 | Step 4001 | loss: 0.3050148325728224 | accuracy: 0.8727022058823529 \n",
      "Epoch 10 | Step 4002 | loss: 0.3046751320759457 | accuracy: 0.8729166666666667 \n",
      "Epoch 10 | Step 4003 | loss: 0.30446046658177345 | accuracy: 0.8729637632978723 \n",
      "Epoch 10 | Step 4004 | loss: 0.3041719486764004 | accuracy: 0.8731349469496021 \n",
      "Epoch 10 | Step 4005 | loss: 0.3044724905932393 | accuracy: 0.873057208994709 \n",
      "Epoch 10 | Step 4006 | loss: 0.30454057368565374 | accuracy: 0.8730211081794196 \n",
      "Epoch 10 | Step 4007 | loss: 0.3043247816201889 | accuracy: 0.8730674342105263 \n",
      "Epoch 10 | Step 4008 | loss: 0.30418327963101904 | accuracy: 0.8731545275590551 \n",
      "Epoch 10 | Step 4009 | loss: 0.30392650659171705 | accuracy: 0.8733229712041884 \n",
      "Epoch 10 | Step 4010 | loss: 0.30390454116751575 | accuracy: 0.8732049608355091 \n",
      "Epoch 10 | Step 4011 | loss: 0.3041237607443085 | accuracy: 0.8730061848958334 \n",
      "Epoch 10 | Step 4012 | loss: 0.30414369563003646 | accuracy: 0.8728896103896104 \n",
      "Epoch 10 | Step 4013 | loss: 0.3042926745093549 | accuracy: 0.8728141191709845 \n",
      "Epoch 10 | Step 4014 | loss: 0.30432945828721203 | accuracy: 0.8727793927648578 \n",
      "Epoch 10 | Step 4015 | loss: 0.30443622602015435 | accuracy: 0.872704574742268 \n",
      "Epoch 10 | Step 4016 | loss: 0.30456632781764237 | accuracy: 0.8726301413881749 \n",
      "Epoch 10 | Step 4017 | loss: 0.30465703530189325 | accuracy: 0.8725560897435898 \n",
      "Epoch 10 | Step 4018 | loss: 0.30467831913162685 | accuracy: 0.8726822250639387 \n",
      "Epoch 10 | Step 4019 | loss: 0.30459649214635093 | accuracy: 0.8726482780612245 \n",
      "Epoch 10 | Step 4020 | loss: 0.3045721983788275 | accuracy: 0.8727337786259542 \n",
      "Epoch 10 | Step 4021 | loss: 0.3046941770817423 | accuracy: 0.8726998730964467 \n",
      "Epoch 10 | Step 4022 | loss: 0.3046434728405144 | accuracy: 0.8728243670886076 \n",
      "Epoch 10 | Step 4023 | loss: 0.3045033245450921 | accuracy: 0.8728298611111112 \n",
      "Epoch 10 | Step 4024 | loss: 0.3042391448912753 | accuracy: 0.8729534005037783 \n",
      "Epoch 10 | Step 4025 | loss: 0.3043958429790023 | accuracy: 0.8728015075376885 \n",
      "Epoch 10 | Step 4026 | loss: 0.30443606023352254 | accuracy: 0.8728070175438597 \n",
      "Epoch 10 | Step 4027 | loss: 0.30465061385184533 | accuracy: 0.872734375 \n",
      "Epoch 10 | Step 4028 | loss: 0.3045282897880845 | accuracy: 0.8728569201995012 \n",
      "Epoch 10 | Step 4029 | loss: 0.30497608882426036 | accuracy: 0.8725901741293532 \n",
      "Epoch 10 | Step 4030 | loss: 0.304695438066724 | accuracy: 0.8727351972837898 \n",
      "Validation | Epoch 10 | Step 4030 | accuracy: 0.8377439474517648 \n",
      "Epoch 11 | Step 4031 | loss: 0.2374727874994278 | accuracy: 0.90625 \n",
      "Epoch 11 | Step 4032 | loss: 0.30104706436395645 | accuracy: 0.8671875 \n",
      "Epoch 11 | Step 4033 | loss: 0.2846161375443141 | accuracy: 0.875 \n",
      "Epoch 11 | Step 4034 | loss: 0.3164634443819523 | accuracy: 0.859375 \n",
      "Epoch 11 | Step 4035 | loss: 0.3129530996084213 | accuracy: 0.8625 \n",
      "Epoch 11 | Step 4036 | loss: 0.32238200555245083 | accuracy: 0.8567708333333334 \n",
      "Epoch 11 | Step 4037 | loss: 0.32750059238501955 | accuracy: 0.8549107142857143 \n",
      "Epoch 11 | Step 4038 | loss: 0.3358145672827959 | accuracy: 0.85546875 \n",
      "Epoch 11 | Step 4039 | loss: 0.32563845813274384 | accuracy: 0.8576388888888888 \n",
      "Epoch 11 | Step 4040 | loss: 0.32971677333116534 | accuracy: 0.859375 \n",
      "Epoch 11 | Step 4041 | loss: 0.3251554085449739 | accuracy: 0.8607954545454546 \n",
      "Epoch 11 | Step 4042 | loss: 0.3269070126116276 | accuracy: 0.8580729166666666 \n",
      "Epoch 11 | Step 4043 | loss: 0.32072731050161213 | accuracy: 0.8605769230769231 \n",
      "Epoch 11 | Step 4044 | loss: 0.31838266445057734 | accuracy: 0.8616071428571429 \n",
      "Epoch 11 | Step 4045 | loss: 0.30812852482000985 | accuracy: 0.8666666666666667 \n",
      "Epoch 11 | Step 4046 | loss: 0.3022520476952195 | accuracy: 0.8720703125 \n",
      "Epoch 11 | Step 4047 | loss: 0.29878497912603263 | accuracy: 0.875 \n",
      "Epoch 11 | Step 4048 | loss: 0.29781638003057903 | accuracy: 0.8741319444444444 \n",
      "Epoch 11 | Step 4049 | loss: 0.2985004257214697 | accuracy: 0.8766447368421053 \n",
      "Epoch 11 | Step 4050 | loss: 0.295780311524868 | accuracy: 0.8765625 \n",
      "Epoch 11 | Step 4051 | loss: 0.2919202446937561 | accuracy: 0.8787202380952381 \n",
      "Epoch 11 | Step 4052 | loss: 0.2900176468220624 | accuracy: 0.8778409090909091 \n",
      "Epoch 11 | Step 4053 | loss: 0.28960315559221345 | accuracy: 0.8770380434782609 \n",
      "Epoch 11 | Step 4054 | loss: 0.28529149231811357 | accuracy: 0.8795572916666666 \n",
      "Epoch 11 | Step 4055 | loss: 0.2849436074495315 | accuracy: 0.88 \n",
      "Epoch 11 | Step 4056 | loss: 0.28446377871128226 | accuracy: 0.8798076923076923 \n",
      "Epoch 11 | Step 4057 | loss: 0.2866013132863574 | accuracy: 0.8778935185185185 \n",
      "Epoch 11 | Step 4058 | loss: 0.2838078934167112 | accuracy: 0.8800223214285714 \n",
      "Epoch 11 | Step 4059 | loss: 0.28202313081971525 | accuracy: 0.8803879310344828 \n",
      "Epoch 11 | Step 4060 | loss: 0.2827402641375859 | accuracy: 0.8791666666666667 \n",
      "Epoch 11 | Step 4061 | loss: 0.2812354660803271 | accuracy: 0.8800403225806451 \n",
      "Epoch 11 | Step 4062 | loss: 0.2827594559639692 | accuracy: 0.8798828125 \n",
      "Epoch 11 | Step 4063 | loss: 0.28574005040255457 | accuracy: 0.8778409090909091 \n",
      "Epoch 11 | Step 4064 | loss: 0.28518948835485114 | accuracy: 0.8782169117647058 \n",
      "Epoch 11 | Step 4065 | loss: 0.28259422310761034 | accuracy: 0.8799107142857143 \n",
      "Epoch 11 | Step 4066 | loss: 0.2828213601476615 | accuracy: 0.8797743055555556 \n",
      "Epoch 11 | Step 4067 | loss: 0.2820288373811824 | accuracy: 0.8800675675675675 \n",
      "Epoch 11 | Step 4068 | loss: 0.281993318153055 | accuracy: 0.8811677631578947 \n",
      "Epoch 11 | Step 4069 | loss: 0.28278458538727874 | accuracy: 0.8806089743589743 \n",
      "Epoch 11 | Step 4070 | loss: 0.28239812664687625 | accuracy: 0.880859375 \n",
      "Epoch 11 | Step 4071 | loss: 0.28103495552772423 | accuracy: 0.881859756097561 \n",
      "Epoch 11 | Step 4072 | loss: 0.2839651778340339 | accuracy: 0.8816964285714286 \n",
      "Epoch 11 | Step 4073 | loss: 0.28289164706718084 | accuracy: 0.8822674418604651 \n",
      "Epoch 11 | Step 4074 | loss: 0.2827424867586656 | accuracy: 0.8817471590909091 \n",
      "Epoch 11 | Step 4075 | loss: 0.2863690323299832 | accuracy: 0.8805555555555555 \n",
      "Epoch 11 | Step 4076 | loss: 0.28788057358368585 | accuracy: 0.8804347826086957 \n",
      "Epoch 11 | Step 4077 | loss: 0.2870350365943097 | accuracy: 0.8806515957446809 \n",
      "Epoch 11 | Step 4078 | loss: 0.289583987245957 | accuracy: 0.8798828125 \n",
      "Epoch 11 | Step 4079 | loss: 0.28797235659190584 | accuracy: 0.8807397959183674 \n",
      "Epoch 11 | Step 4080 | loss: 0.2895912271738052 | accuracy: 0.880625 \n",
      "Epoch 11 | Step 4081 | loss: 0.2919798738816205 | accuracy: 0.8783700980392157 \n",
      "Epoch 11 | Step 4082 | loss: 0.2927117261749047 | accuracy: 0.8780048076923077 \n",
      "Epoch 11 | Step 4083 | loss: 0.29145495171816843 | accuracy: 0.8782429245283019 \n",
      "Epoch 11 | Step 4084 | loss: 0.29027390590420477 | accuracy: 0.8790509259259259 \n",
      "Epoch 11 | Step 4085 | loss: 0.28962473273277284 | accuracy: 0.8792613636363636 \n",
      "Epoch 11 | Step 4086 | loss: 0.29002960505230085 | accuracy: 0.8794642857142857 \n",
      "Epoch 11 | Step 4087 | loss: 0.28963475844316316 | accuracy: 0.8804824561403509 \n",
      "Epoch 11 | Step 4088 | loss: 0.2898468693782543 | accuracy: 0.8793103448275862 \n",
      "Epoch 11 | Step 4089 | loss: 0.29048518962779285 | accuracy: 0.8797669491525424 \n",
      "Epoch 11 | Step 4090 | loss: 0.2914405956864357 | accuracy: 0.8799479166666667 \n",
      "Epoch 11 | Step 4091 | loss: 0.29140401277385775 | accuracy: 0.8793545081967213 \n",
      "Epoch 11 | Step 4092 | loss: 0.2908853580874781 | accuracy: 0.8790322580645161 \n",
      "Epoch 11 | Step 4093 | loss: 0.2905684879847935 | accuracy: 0.8797123015873016 \n",
      "Epoch 11 | Step 4094 | loss: 0.2882722453214228 | accuracy: 0.88134765625 \n",
      "Epoch 11 | Step 4095 | loss: 0.28813086656423714 | accuracy: 0.8807692307692307 \n",
      "Epoch 11 | Step 4096 | loss: 0.2862618147875323 | accuracy: 0.8813920454545454 \n",
      "Epoch 11 | Step 4097 | loss: 0.28581823230679354 | accuracy: 0.8815298507462687 \n",
      "Epoch 11 | Step 4098 | loss: 0.2855921788688968 | accuracy: 0.8823529411764706 \n",
      "Epoch 11 | Step 4099 | loss: 0.28733561889848847 | accuracy: 0.8822463768115942 \n",
      "Epoch 11 | Step 4100 | loss: 0.289538548886776 | accuracy: 0.8805803571428571 \n",
      "Epoch 11 | Step 4101 | loss: 0.289067687073224 | accuracy: 0.8809419014084507 \n",
      "Epoch 11 | Step 4102 | loss: 0.28850864101615215 | accuracy: 0.8815104166666666 \n",
      "Epoch 11 | Step 4103 | loss: 0.2885646826192124 | accuracy: 0.8814212328767124 \n",
      "Epoch 11 | Step 4104 | loss: 0.28939415212418584 | accuracy: 0.8811233108108109 \n",
      "Epoch 11 | Step 4105 | loss: 0.2904009069999059 | accuracy: 0.8810416666666666 \n",
      "Epoch 11 | Step 4106 | loss: 0.28977801199806363 | accuracy: 0.8811677631578947 \n",
      "Epoch 11 | Step 4107 | loss: 0.28998871921718894 | accuracy: 0.8808847402597403 \n",
      "Epoch 11 | Step 4108 | loss: 0.29117594487391985 | accuracy: 0.8802083333333334 \n",
      "Epoch 11 | Step 4109 | loss: 0.28995352266710017 | accuracy: 0.881131329113924 \n",
      "Epoch 11 | Step 4110 | loss: 0.29014251828193666 | accuracy: 0.8810546875 \n",
      "Epoch 11 | Step 4111 | loss: 0.2897652310353738 | accuracy: 0.8813657407407407 \n",
      "Epoch 11 | Step 4112 | loss: 0.2882544776288474 | accuracy: 0.8820503048780488 \n",
      "Epoch 11 | Step 4113 | loss: 0.28814121721738795 | accuracy: 0.8823418674698795 \n",
      "Epoch 11 | Step 4114 | loss: 0.28833133053211946 | accuracy: 0.8826264880952381 \n",
      "Epoch 11 | Step 4115 | loss: 0.2895705051281874 | accuracy: 0.8823529411764706 \n",
      "Epoch 11 | Step 4116 | loss: 0.2889336967884109 | accuracy: 0.8829941860465116 \n",
      "Epoch 11 | Step 4117 | loss: 0.28926463031220717 | accuracy: 0.8829022988505747 \n",
      "Epoch 11 | Step 4118 | loss: 0.28990079394795687 | accuracy: 0.8833451704545454 \n",
      "Epoch 11 | Step 4119 | loss: 0.28929435453388136 | accuracy: 0.8836025280898876 \n",
      "Epoch 11 | Step 4120 | loss: 0.29012128031916096 | accuracy: 0.8829861111111111 \n",
      "Epoch 11 | Step 4121 | loss: 0.2892318608669135 | accuracy: 0.883070054945055 \n",
      "Epoch 11 | Step 4122 | loss: 0.29184725281337043 | accuracy: 0.8819633152173914 \n",
      "Epoch 11 | Step 4123 | loss: 0.29157179385744125 | accuracy: 0.8820564516129032 \n",
      "Epoch 11 | Step 4124 | loss: 0.29105488147507336 | accuracy: 0.8821476063829787 \n",
      "Epoch 11 | Step 4125 | loss: 0.28967887131791376 | accuracy: 0.8828947368421053 \n",
      "Epoch 11 | Step 4126 | loss: 0.2892610440030695 | accuracy: 0.8831380208333334 \n",
      "Epoch 11 | Step 4127 | loss: 0.28834506224111195 | accuracy: 0.884020618556701 \n",
      "Epoch 11 | Step 4128 | loss: 0.2904260648148402 | accuracy: 0.8826530612244898 \n",
      "Epoch 11 | Step 4129 | loss: 0.2897648499770599 | accuracy: 0.8825757575757576 \n",
      "Epoch 11 | Step 4130 | loss: 0.2897183413803579 | accuracy: 0.8821875 \n",
      "Epoch 11 | Step 4131 | loss: 0.28926638506426683 | accuracy: 0.8822710396039604 \n",
      "Epoch 11 | Step 4132 | loss: 0.2895613438358495 | accuracy: 0.8817401960784313 \n",
      "Epoch 11 | Step 4133 | loss: 0.2895717227343218 | accuracy: 0.8816747572815534 \n",
      "Epoch 11 | Step 4134 | loss: 0.2900081147941261 | accuracy: 0.8817608173076923 \n",
      "Epoch 11 | Step 4135 | loss: 0.2902259349823 | accuracy: 0.88125 \n",
      "Epoch 11 | Step 4136 | loss: 0.28930357084521724 | accuracy: 0.8817806603773585 \n",
      "Epoch 11 | Step 4137 | loss: 0.29076355542535 | accuracy: 0.8812792056074766 \n",
      "Epoch 11 | Step 4138 | loss: 0.29166923228789277 | accuracy: 0.8810763888888888 \n",
      "Epoch 11 | Step 4139 | loss: 0.29074902846178896 | accuracy: 0.8815940366972477 \n",
      "Epoch 11 | Step 4140 | loss: 0.2905280592766677 | accuracy: 0.8816761363636364 \n",
      "Epoch 11 | Step 4141 | loss: 0.2916317847934931 | accuracy: 0.8811936936936937 \n",
      "Epoch 11 | Step 4142 | loss: 0.29271111743790784 | accuracy: 0.880859375 \n",
      "Epoch 11 | Step 4143 | loss: 0.29351630754175456 | accuracy: 0.8808075221238938 \n",
      "Epoch 11 | Step 4144 | loss: 0.2933727500208639 | accuracy: 0.8807565789473685 \n",
      "Epoch 11 | Step 4145 | loss: 0.2925210019816525 | accuracy: 0.8809782608695652 \n",
      "Epoch 11 | Step 4146 | loss: 0.2924399524927141 | accuracy: 0.8810614224137931 \n",
      "Epoch 11 | Step 4147 | loss: 0.29236344954906385 | accuracy: 0.8811431623931624 \n",
      "Epoch 11 | Step 4148 | loss: 0.2928161997411212 | accuracy: 0.880958686440678 \n",
      "Epoch 11 | Step 4149 | loss: 0.2934811320625435 | accuracy: 0.8807773109243697 \n",
      "Epoch 11 | Step 4150 | loss: 0.29343994557857533 | accuracy: 0.880859375 \n",
      "Epoch 11 | Step 4151 | loss: 0.2927255495028064 | accuracy: 0.881198347107438 \n",
      "Epoch 11 | Step 4152 | loss: 0.2923171931847199 | accuracy: 0.8814036885245902 \n",
      "Epoch 11 | Step 4153 | loss: 0.29225447301457586 | accuracy: 0.8814786585365854 \n",
      "Epoch 11 | Step 4154 | loss: 0.2924948085940655 | accuracy: 0.8813004032258065 \n",
      "Epoch 11 | Step 4155 | loss: 0.292218732237816 | accuracy: 0.88125 \n",
      "Epoch 11 | Step 4156 | loss: 0.2922194705359521 | accuracy: 0.8810763888888888 \n",
      "Epoch 11 | Step 4157 | loss: 0.29361533473326484 | accuracy: 0.8807824803149606 \n",
      "Epoch 11 | Step 4158 | loss: 0.2938158573815601 | accuracy: 0.880615234375 \n",
      "Epoch 11 | Step 4159 | loss: 0.293311755440032 | accuracy: 0.8806928294573644 \n",
      "Epoch 11 | Step 4160 | loss: 0.29367827211435044 | accuracy: 0.8806490384615384 \n",
      "Epoch 11 | Step 4161 | loss: 0.2938435581576735 | accuracy: 0.8806059160305344 \n",
      "Epoch 11 | Step 4162 | loss: 0.29358392355568497 | accuracy: 0.8804450757575758 \n",
      "Epoch 11 | Step 4163 | loss: 0.29317800633441254 | accuracy: 0.8804041353383458 \n",
      "Epoch 11 | Step 4164 | loss: 0.2934410835602392 | accuracy: 0.8801305970149254 \n",
      "Epoch 11 | Step 4165 | loss: 0.293862921551422 | accuracy: 0.8798611111111111 \n",
      "Epoch 11 | Step 4166 | loss: 0.2939426591072014 | accuracy: 0.8802849264705882 \n",
      "Epoch 11 | Step 4167 | loss: 0.29384147326876664 | accuracy: 0.8803604014598541 \n",
      "Epoch 11 | Step 4168 | loss: 0.2937047296892043 | accuracy: 0.8802083333333334 \n",
      "Epoch 11 | Step 4169 | loss: 0.29392432555449105 | accuracy: 0.8798336330935251 \n",
      "Epoch 11 | Step 4170 | loss: 0.2931123364184585 | accuracy: 0.8803571428571428 \n",
      "Epoch 11 | Step 4171 | loss: 0.29305478053312783 | accuracy: 0.880540780141844 \n",
      "Epoch 11 | Step 4172 | loss: 0.2929035002287006 | accuracy: 0.8806117957746479 \n",
      "Epoch 11 | Step 4173 | loss: 0.29285475038565134 | accuracy: 0.8806818181818182 \n",
      "Epoch 11 | Step 4174 | loss: 0.2920347633254198 | accuracy: 0.8809678819444445 \n",
      "Epoch 11 | Step 4175 | loss: 0.29205449706521536 | accuracy: 0.8808189655172415 \n",
      "Epoch 11 | Step 4176 | loss: 0.2932879407316039 | accuracy: 0.880244006849315 \n",
      "Epoch 11 | Step 4177 | loss: 0.29284058653173 | accuracy: 0.8807397959183674 \n",
      "Epoch 11 | Step 4178 | loss: 0.29260570122986235 | accuracy: 0.8805954391891891 \n",
      "Epoch 11 | Step 4179 | loss: 0.2922608211336521 | accuracy: 0.8808724832214765 \n",
      "Epoch 11 | Step 4180 | loss: 0.2919874992966653 | accuracy: 0.8807291666666667 \n",
      "Epoch 11 | Step 4181 | loss: 0.29197888451301507 | accuracy: 0.8807947019867549 \n",
      "Epoch 11 | Step 4182 | loss: 0.2925517352199869 | accuracy: 0.8806537828947368 \n",
      "Epoch 11 | Step 4183 | loss: 0.292464064129817 | accuracy: 0.880718954248366 \n",
      "Epoch 11 | Step 4184 | loss: 0.29248893909253093 | accuracy: 0.8807832792207793 \n",
      "Epoch 11 | Step 4185 | loss: 0.2919587710211355 | accuracy: 0.8808467741935484 \n",
      "Epoch 11 | Step 4186 | loss: 0.2914000004529954 | accuracy: 0.8813100961538461 \n",
      "Epoch 11 | Step 4187 | loss: 0.29066793098571203 | accuracy: 0.8818670382165605 \n",
      "Epoch 11 | Step 4188 | loss: 0.2905271143852911 | accuracy: 0.8819224683544303 \n",
      "Epoch 11 | Step 4189 | loss: 0.2903159766826991 | accuracy: 0.8820754716981132 \n",
      "Epoch 11 | Step 4190 | loss: 0.2902730366215111 | accuracy: 0.88203125 \n",
      "Epoch 11 | Step 4191 | loss: 0.2900732159614564 | accuracy: 0.8819875776397516 \n",
      "Epoch 11 | Step 4192 | loss: 0.29056918768235207 | accuracy: 0.8817515432098766 \n",
      "Epoch 11 | Step 4193 | loss: 0.2899719249068595 | accuracy: 0.8819976993865031 \n",
      "Epoch 11 | Step 4194 | loss: 0.28950975117523514 | accuracy: 0.8823361280487805 \n",
      "Epoch 11 | Step 4195 | loss: 0.289397289265286 | accuracy: 0.8824810606060606 \n",
      "Epoch 11 | Step 4196 | loss: 0.2905150011899961 | accuracy: 0.8816829819277109 \n",
      "Epoch 11 | Step 4197 | loss: 0.2899619691564653 | accuracy: 0.8819236526946108 \n",
      "Epoch 11 | Step 4198 | loss: 0.28959653402368246 | accuracy: 0.8819754464285714 \n",
      "Epoch 11 | Step 4199 | loss: 0.29064808142255766 | accuracy: 0.8817492603550295 \n",
      "Epoch 11 | Step 4200 | loss: 0.290064426730661 | accuracy: 0.8820772058823529 \n",
      "Epoch 11 | Step 4201 | loss: 0.29043175550232175 | accuracy: 0.8818530701754386 \n",
      "Epoch 11 | Step 4202 | loss: 0.290934103692687 | accuracy: 0.8816315406976745 \n",
      "Epoch 11 | Step 4203 | loss: 0.2898964897831742 | accuracy: 0.8821351156069365 \n",
      "Epoch 11 | Step 4204 | loss: 0.2901542113515839 | accuracy: 0.8820043103448276 \n",
      "Epoch 11 | Step 4205 | loss: 0.2894339660661563 | accuracy: 0.8822321428571429 \n",
      "Epoch 11 | Step 4206 | loss: 0.2895301005125725 | accuracy: 0.8822798295454546 \n",
      "Epoch 11 | Step 4207 | loss: 0.28989501731038786 | accuracy: 0.8821504237288136 \n",
      "Epoch 11 | Step 4208 | loss: 0.28964699582939757 | accuracy: 0.8821102528089888 \n",
      "Epoch 11 | Step 4209 | loss: 0.28980609820375247 | accuracy: 0.8819832402234636 \n",
      "Epoch 11 | Step 4210 | loss: 0.2903749189029139 | accuracy: 0.8817708333333333 \n",
      "Epoch 11 | Step 4211 | loss: 0.2903038437442228 | accuracy: 0.8817334254143646 \n",
      "Epoch 11 | Step 4212 | loss: 0.28975596405811377 | accuracy: 0.8820398351648352 \n",
      "Epoch 11 | Step 4213 | loss: 0.28969259148901294 | accuracy: 0.8820867486338798 \n",
      "Epoch 11 | Step 4214 | loss: 0.28979894911627424 | accuracy: 0.8819633152173914 \n",
      "Epoch 11 | Step 4215 | loss: 0.2898623845464476 | accuracy: 0.8821790540540541 \n",
      "Epoch 11 | Step 4216 | loss: 0.28956757209474054 | accuracy: 0.8820564516129032 \n",
      "Epoch 11 | Step 4217 | loss: 0.28986919958164364 | accuracy: 0.8821858288770054 \n",
      "Epoch 11 | Step 4218 | loss: 0.28971508791313544 | accuracy: 0.8822307180851063 \n",
      "Epoch 11 | Step 4219 | loss: 0.2891761083845741 | accuracy: 0.8824404761904762 \n",
      "Epoch 11 | Step 4220 | loss: 0.28899153992533705 | accuracy: 0.8826480263157894 \n",
      "Epoch 11 | Step 4221 | loss: 0.2893218708990134 | accuracy: 0.8822807591623036 \n",
      "Epoch 11 | Step 4222 | loss: 0.28942045557778345 | accuracy: 0.8821614583333334 \n",
      "Epoch 11 | Step 4223 | loss: 0.2892947461398156 | accuracy: 0.882205310880829 \n",
      "Epoch 11 | Step 4224 | loss: 0.2891866552845106 | accuracy: 0.8823292525773195 \n",
      "Epoch 11 | Step 4225 | loss: 0.28927488239147736 | accuracy: 0.8822115384615384 \n",
      "Epoch 11 | Step 4226 | loss: 0.28897692745893594 | accuracy: 0.8823341836734694 \n",
      "Epoch 11 | Step 4227 | loss: 0.2890621747084076 | accuracy: 0.8821383248730964 \n",
      "Epoch 11 | Step 4228 | loss: 0.28885785230632993 | accuracy: 0.8820233585858586 \n",
      "Epoch 11 | Step 4229 | loss: 0.2889915037170128 | accuracy: 0.8819880653266332 \n",
      "Epoch 11 | Step 4230 | loss: 0.28888549778610473 | accuracy: 0.881953125 \n",
      "Epoch 11 | Step 4231 | loss: 0.2888499688523919 | accuracy: 0.8819185323383084 \n",
      "Epoch 11 | Step 4232 | loss: 0.2890159318426458 | accuracy: 0.8817295792079208 \n",
      "Epoch 11 | Step 4233 | loss: 0.28898596047914676 | accuracy: 0.8818503694581281 \n",
      "Epoch 11 | Step 4234 | loss: 0.2892757246964703 | accuracy: 0.8816636029411765 \n",
      "Epoch 11 | Step 4235 | loss: 0.28932057259286326 | accuracy: 0.8817835365853659 \n",
      "Epoch 11 | Step 4236 | loss: 0.2895231578607583 | accuracy: 0.8816747572815534 \n",
      "Epoch 11 | Step 4237 | loss: 0.2893261638456497 | accuracy: 0.8816425120772947 \n",
      "Epoch 11 | Step 4238 | loss: 0.2889563759717231 | accuracy: 0.8817608173076923 \n",
      "Epoch 11 | Step 4239 | loss: 0.28895219722005167 | accuracy: 0.8817284688995215 \n",
      "Epoch 11 | Step 4240 | loss: 0.28844804008092195 | accuracy: 0.8819196428571429 \n",
      "Epoch 11 | Step 4241 | loss: 0.2884353208245259 | accuracy: 0.8820349526066351 \n",
      "Epoch 11 | Step 4242 | loss: 0.28840992596211296 | accuracy: 0.8820754716981132 \n",
      "Epoch 11 | Step 4243 | loss: 0.2881811545558378 | accuracy: 0.8821889671361502 \n",
      "Epoch 11 | Step 4244 | loss: 0.28822489685126546 | accuracy: 0.8822283878504673 \n",
      "Epoch 11 | Step 4245 | loss: 0.2883783924371696 | accuracy: 0.8820494186046511 \n",
      "Epoch 11 | Step 4246 | loss: 0.28866825766723453 | accuracy: 0.8819444444444444 \n",
      "Epoch 11 | Step 4247 | loss: 0.2892161922589424 | accuracy: 0.8816244239631337 \n",
      "Epoch 11 | Step 4248 | loss: 0.2894280747331063 | accuracy: 0.8814506880733946 \n",
      "Epoch 11 | Step 4249 | loss: 0.2893944404781136 | accuracy: 0.8813498858447488 \n",
      "Epoch 11 | Step 4250 | loss: 0.2893048657951029 | accuracy: 0.8814630681818182 \n",
      "Epoch 11 | Step 4251 | loss: 0.28919839552220167 | accuracy: 0.8816459276018099 \n",
      "Epoch 11 | Step 4252 | loss: 0.28900126122810804 | accuracy: 0.8816863738738738 \n",
      "Epoch 11 | Step 4253 | loss: 0.28880255121420306 | accuracy: 0.8817264573991032 \n",
      "Epoch 11 | Step 4254 | loss: 0.2889223519513116 | accuracy: 0.8816964285714286 \n",
      "Epoch 11 | Step 4255 | loss: 0.2890066226654581 | accuracy: 0.8817361111111112 \n",
      "Epoch 11 | Step 4256 | loss: 0.28891409831368803 | accuracy: 0.8816371681415929 \n",
      "Epoch 11 | Step 4257 | loss: 0.2888430978298711 | accuracy: 0.8818144273127754 \n",
      "Epoch 11 | Step 4258 | loss: 0.2886726104311252 | accuracy: 0.881921600877193 \n",
      "Epoch 11 | Step 4259 | loss: 0.2883745953440665 | accuracy: 0.8820278384279476 \n",
      "Epoch 11 | Step 4260 | loss: 0.28833683738889887 | accuracy: 0.8818614130434783 \n",
      "Epoch 11 | Step 4261 | loss: 0.2880504890244243 | accuracy: 0.8819669913419913 \n",
      "Epoch 11 | Step 4262 | loss: 0.2876761203374841 | accuracy: 0.8821390086206896 \n",
      "Epoch 11 | Step 4263 | loss: 0.2874966077986192 | accuracy: 0.8823095493562232 \n",
      "Epoch 11 | Step 4264 | loss: 0.28780576507123096 | accuracy: 0.8821447649572649 \n",
      "Epoch 11 | Step 4265 | loss: 0.28729122449108885 | accuracy: 0.8824468085106383 \n",
      "Epoch 11 | Step 4266 | loss: 0.2870107753107607 | accuracy: 0.882613877118644 \n",
      "Epoch 11 | Step 4267 | loss: 0.28700301079433166 | accuracy: 0.8826476793248945 \n",
      "Epoch 11 | Step 4268 | loss: 0.28745257143839054 | accuracy: 0.882484243697479 \n",
      "Epoch 11 | Step 4269 | loss: 0.2874962156599534 | accuracy: 0.8823875523012552 \n",
      "Epoch 11 | Step 4270 | loss: 0.28757783488060024 | accuracy: 0.8822916666666667 \n",
      "Epoch 11 | Step 4271 | loss: 0.28802261501550663 | accuracy: 0.8821965767634855 \n",
      "Epoch 11 | Step 4272 | loss: 0.2882497440253899 | accuracy: 0.8822314049586777 \n",
      "Epoch 11 | Step 4273 | loss: 0.2878664324496998 | accuracy: 0.8823945473251029 \n",
      "Epoch 11 | Step 4274 | loss: 0.2874700288731054 | accuracy: 0.8826203893442623 \n",
      "Epoch 11 | Step 4275 | loss: 0.2873025295989853 | accuracy: 0.8827168367346939 \n",
      "Epoch 11 | Step 4276 | loss: 0.2869442080155135 | accuracy: 0.8828760162601627 \n",
      "Epoch 11 | Step 4277 | loss: 0.2867481193622113 | accuracy: 0.8830339068825911 \n",
      "Epoch 11 | Step 4278 | loss: 0.28681301028137235 | accuracy: 0.8830645161290323 \n",
      "Epoch 11 | Step 4279 | loss: 0.2870869095844915 | accuracy: 0.8829693775100401 \n",
      "Epoch 11 | Step 4280 | loss: 0.2868459697067736 | accuracy: 0.8830625 \n",
      "Epoch 11 | Step 4281 | loss: 0.2870153314860692 | accuracy: 0.8830926294820717 \n",
      "Epoch 11 | Step 4282 | loss: 0.28764715462568247 | accuracy: 0.882750496031746 \n",
      "Epoch 11 | Step 4283 | loss: 0.2875682799064594 | accuracy: 0.8827198616600791 \n",
      "Epoch 11 | Step 4284 | loss: 0.287512124552736 | accuracy: 0.8826279527559056 \n",
      "Epoch 11 | Step 4285 | loss: 0.28736581174181947 | accuracy: 0.8826593137254902 \n",
      "Epoch 11 | Step 4286 | loss: 0.2873587280337232 | accuracy: 0.8826904296875 \n",
      "Epoch 11 | Step 4287 | loss: 0.28752535932374823 | accuracy: 0.8824173151750972 \n",
      "Epoch 11 | Step 4288 | loss: 0.2874052926840245 | accuracy: 0.8825702519379846 \n",
      "Epoch 11 | Step 4289 | loss: 0.28749711716612325 | accuracy: 0.8825410231660231 \n",
      "Epoch 11 | Step 4290 | loss: 0.28758129572065966 | accuracy: 0.8825120192307693 \n",
      "Epoch 11 | Step 4291 | loss: 0.28776803124567546 | accuracy: 0.8824832375478927 \n",
      "Epoch 11 | Step 4292 | loss: 0.2882085400740153 | accuracy: 0.8822757633587787 \n",
      "Epoch 11 | Step 4293 | loss: 0.2885330782020499 | accuracy: 0.8821292775665399 \n",
      "Epoch 11 | Step 4294 | loss: 0.2886013070572957 | accuracy: 0.8819247159090909 \n",
      "Epoch 11 | Step 4295 | loss: 0.28873184258645423 | accuracy: 0.8817806603773585 \n",
      "Epoch 11 | Step 4296 | loss: 0.288798838097574 | accuracy: 0.881578947368421 \n",
      "Epoch 11 | Step 4297 | loss: 0.2884778874587922 | accuracy: 0.8817883895131086 \n",
      "Epoch 11 | Step 4298 | loss: 0.28898464707629884 | accuracy: 0.8816464552238806 \n",
      "Epoch 11 | Step 4299 | loss: 0.2889985262405916 | accuracy: 0.881389405204461 \n",
      "Epoch 11 | Step 4300 | loss: 0.2890262701721102 | accuracy: 0.8813657407407407 \n",
      "Epoch 11 | Step 4301 | loss: 0.2888820990370207 | accuracy: 0.8813999077490775 \n",
      "Epoch 11 | Step 4302 | loss: 0.28875625547131184 | accuracy: 0.8814912683823529 \n",
      "Epoch 11 | Step 4303 | loss: 0.28859020188287055 | accuracy: 0.8815819597069597 \n",
      "Epoch 11 | Step 4304 | loss: 0.2886978004154932 | accuracy: 0.8813868613138686 \n",
      "Epoch 11 | Step 4305 | loss: 0.2890536892685023 | accuracy: 0.8810795454545455 \n",
      "Epoch 11 | Step 4306 | loss: 0.2892889460629743 | accuracy: 0.8809442934782609 \n",
      "Epoch 11 | Step 4307 | loss: 0.28937502955809397 | accuracy: 0.8808664259927798 \n",
      "Epoch 11 | Step 4308 | loss: 0.28904291277201916 | accuracy: 0.8810139388489209 \n",
      "Epoch 11 | Step 4309 | loss: 0.289493552432479 | accuracy: 0.8808243727598566 \n",
      "Epoch 11 | Step 4310 | loss: 0.2891731169340866 | accuracy: 0.8809709821428572 \n",
      "Epoch 11 | Step 4311 | loss: 0.2893162750211475 | accuracy: 0.8807829181494662 \n",
      "Epoch 11 | Step 4312 | loss: 0.2891605089266672 | accuracy: 0.8808178191489362 \n",
      "Epoch 11 | Step 4313 | loss: 0.2891618414344299 | accuracy: 0.8809628975265018 \n",
      "Epoch 11 | Step 4314 | loss: 0.28898799112460144 | accuracy: 0.8811069542253521 \n",
      "Epoch 11 | Step 4315 | loss: 0.2889634836922612 | accuracy: 0.8810855263157895 \n",
      "Epoch 11 | Step 4316 | loss: 0.28855652062521947 | accuracy: 0.8812827797202797 \n",
      "Epoch 11 | Step 4317 | loss: 0.2884848078109246 | accuracy: 0.8812608885017421 \n",
      "Epoch 11 | Step 4318 | loss: 0.28800022796106833 | accuracy: 0.8815104166666666 \n",
      "Epoch 11 | Step 4319 | loss: 0.2881353335345493 | accuracy: 0.8814878892733564 \n",
      "Epoch 11 | Step 4320 | loss: 0.2882223802136964 | accuracy: 0.8815193965517242 \n",
      "Epoch 11 | Step 4321 | loss: 0.28848516477649566 | accuracy: 0.8813359106529209 \n",
      "Epoch 11 | Step 4322 | loss: 0.2883685235036154 | accuracy: 0.8813677226027398 \n",
      "Epoch 11 | Step 4323 | loss: 0.2887282364146701 | accuracy: 0.881026023890785 \n",
      "Epoch 11 | Step 4324 | loss: 0.2884717413610747 | accuracy: 0.8811649659863946 \n",
      "Epoch 11 | Step 4325 | loss: 0.288303112049224 | accuracy: 0.88125 \n",
      "Epoch 11 | Step 4326 | loss: 0.28849169236884725 | accuracy: 0.8811233108108109 \n",
      "Epoch 11 | Step 4327 | loss: 0.2882538447626913 | accuracy: 0.8813131313131313 \n",
      "Epoch 11 | Step 4328 | loss: 0.2885143911628515 | accuracy: 0.8812919463087249 \n",
      "Epoch 11 | Step 4329 | loss: 0.2883078815994853 | accuracy: 0.8813754180602007 \n",
      "Epoch 11 | Step 4330 | loss: 0.2880380332718293 | accuracy: 0.8815625 \n",
      "Epoch 11 | Step 4331 | loss: 0.2880505546432397 | accuracy: 0.8814887873754153 \n",
      "Epoch 11 | Step 4332 | loss: 0.28780827688559 | accuracy: 0.8816742549668874 \n",
      "Epoch 11 | Step 4333 | loss: 0.2876932006513718 | accuracy: 0.8817037953795379 \n",
      "Epoch 11 | Step 4334 | loss: 0.28771678301946896 | accuracy: 0.881578947368421 \n",
      "Epoch 11 | Step 4335 | loss: 0.28744071597447163 | accuracy: 0.8817110655737705 \n",
      "Epoch 11 | Step 4336 | loss: 0.28748484006991576 | accuracy: 0.881689133986928 \n",
      "Epoch 11 | Step 4337 | loss: 0.28774448969562205 | accuracy: 0.8815655537459284 \n",
      "Epoch 11 | Step 4338 | loss: 0.2875010227276521 | accuracy: 0.8816964285714286 \n",
      "Epoch 11 | Step 4339 | loss: 0.28718423561274437 | accuracy: 0.8817758899676376 \n",
      "Epoch 11 | Step 4340 | loss: 0.28733266022416865 | accuracy: 0.8816532258064517 \n",
      "Epoch 11 | Step 4341 | loss: 0.2873509008545202 | accuracy: 0.8817323151125402 \n",
      "Epoch 11 | Step 4342 | loss: 0.28728180930305 | accuracy: 0.8818108974358975 \n",
      "Epoch 11 | Step 4343 | loss: 0.2872681085246441 | accuracy: 0.8817891373801917 \n",
      "Epoch 11 | Step 4344 | loss: 0.2877104112249652 | accuracy: 0.8815684713375797 \n",
      "Epoch 11 | Step 4345 | loss: 0.28831715174610667 | accuracy: 0.88125 \n",
      "Epoch 11 | Step 4346 | loss: 0.28823354573849647 | accuracy: 0.8813291139240507 \n",
      "Epoch 11 | Step 4347 | loss: 0.2877488819535599 | accuracy: 0.8816541798107256 \n",
      "Epoch 11 | Step 4348 | loss: 0.2879176170524187 | accuracy: 0.8817315251572327 \n",
      "Epoch 11 | Step 4349 | loss: 0.2880044023398322 | accuracy: 0.8817104231974922 \n",
      "Epoch 11 | Step 4350 | loss: 0.2878283214056865 | accuracy: 0.881689453125 \n",
      "Epoch 11 | Step 4351 | loss: 0.2877918380860971 | accuracy: 0.8816686137071651 \n",
      "Epoch 11 | Step 4352 | loss: 0.28823923206199775 | accuracy: 0.8815993788819876 \n",
      "Epoch 11 | Step 4353 | loss: 0.28795989635097724 | accuracy: 0.8816756965944272 \n",
      "Epoch 11 | Step 4354 | loss: 0.287756683718827 | accuracy: 0.8817515432098766 \n",
      "Epoch 11 | Step 4355 | loss: 0.28799772241940863 | accuracy: 0.8817307692307692 \n",
      "Epoch 11 | Step 4356 | loss: 0.28804265975129384 | accuracy: 0.8817580521472392 \n",
      "Epoch 11 | Step 4357 | loss: 0.288138087622434 | accuracy: 0.8816418195718655 \n",
      "Epoch 11 | Step 4358 | loss: 0.28835507679912376 | accuracy: 0.8815739329268293 \n",
      "Epoch 11 | Step 4359 | loss: 0.2886389702966148 | accuracy: 0.8814114741641338 \n",
      "Epoch 11 | Step 4360 | loss: 0.2885702601662188 | accuracy: 0.8813920454545454 \n",
      "Epoch 11 | Step 4361 | loss: 0.28857376286900654 | accuracy: 0.8814671450151057 \n",
      "Epoch 11 | Step 4362 | loss: 0.2885504380900817 | accuracy: 0.8815888554216867 \n",
      "Epoch 11 | Step 4363 | loss: 0.2886539962332886 | accuracy: 0.8815221471471472 \n",
      "Epoch 11 | Step 4364 | loss: 0.28866852416160577 | accuracy: 0.8815494011976048 \n",
      "Epoch 11 | Step 4365 | loss: 0.28852765282143406 | accuracy: 0.8816231343283583 \n",
      "Epoch 11 | Step 4366 | loss: 0.28854666461813305 | accuracy: 0.8816964285714286 \n",
      "Epoch 11 | Step 4367 | loss: 0.28844183221326736 | accuracy: 0.8817692878338279 \n",
      "Epoch 11 | Step 4368 | loss: 0.28866554556425505 | accuracy: 0.8818417159763313 \n",
      "Epoch 11 | Step 4369 | loss: 0.2883686394070805 | accuracy: 0.881959808259587 \n",
      "Epoch 11 | Step 4370 | loss: 0.288153283363756 | accuracy: 0.8821231617647058 \n",
      "Epoch 11 | Step 4371 | loss: 0.28834320108824113 | accuracy: 0.8819189882697948 \n",
      "Epoch 11 | Step 4372 | loss: 0.2882031881364814 | accuracy: 0.8819444444444444 \n",
      "Epoch 11 | Step 4373 | loss: 0.2880979045009126 | accuracy: 0.8820608600583091 \n",
      "Epoch 11 | Step 4374 | loss: 0.28791938780612025 | accuracy: 0.8820857558139535 \n",
      "Epoch 11 | Step 4375 | loss: 0.28811042928609293 | accuracy: 0.8820652173913044 \n",
      "Epoch 11 | Step 4376 | loss: 0.28811248566287784 | accuracy: 0.8821351156069365 \n",
      "Epoch 11 | Step 4377 | loss: 0.2878263659496128 | accuracy: 0.8822496397694525 \n",
      "Epoch 11 | Step 4378 | loss: 0.28822678282600017 | accuracy: 0.8820492097701149 \n",
      "Epoch 11 | Step 4379 | loss: 0.28805026183582644 | accuracy: 0.882118553008596 \n",
      "Epoch 11 | Step 4380 | loss: 0.28791724645665706 | accuracy: 0.8821428571428571 \n",
      "Epoch 11 | Step 4381 | loss: 0.28773233941902115 | accuracy: 0.8822560541310541 \n",
      "Epoch 11 | Step 4382 | loss: 0.28780321651985014 | accuracy: 0.8822354403409091 \n",
      "Epoch 11 | Step 4383 | loss: 0.2878731515564594 | accuracy: 0.8821706798866855 \n",
      "Epoch 11 | Step 4384 | loss: 0.28771630293652833 | accuracy: 0.8820621468926554 \n",
      "Epoch 11 | Step 4385 | loss: 0.28779623157961265 | accuracy: 0.8820862676056338 \n",
      "Epoch 11 | Step 4386 | loss: 0.2875421796663758 | accuracy: 0.8821980337078652 \n",
      "Epoch 11 | Step 4387 | loss: 0.28734265979515067 | accuracy: 0.882265406162465 \n",
      "Epoch 11 | Step 4388 | loss: 0.28733646667786145 | accuracy: 0.8822451117318436 \n",
      "Epoch 11 | Step 4389 | loss: 0.2871715146062433 | accuracy: 0.8823119777158774 \n",
      "Epoch 11 | Step 4390 | loss: 0.28718353006988756 | accuracy: 0.882421875 \n",
      "Epoch 11 | Step 4391 | loss: 0.2870090428605634 | accuracy: 0.882531163434903 \n",
      "Epoch 11 | Step 4392 | loss: 0.2871209448666533 | accuracy: 0.8824671961325967 \n",
      "Epoch 11 | Step 4393 | loss: 0.28724394543686516 | accuracy: 0.8824896694214877 \n",
      "Epoch 11 | Step 4394 | loss: 0.2870845099767813 | accuracy: 0.882554945054945 \n",
      "Epoch 11 | Step 4395 | loss: 0.2870417804138301 | accuracy: 0.8825770547945205 \n",
      "Epoch 11 | Step 4396 | loss: 0.2869436338828887 | accuracy: 0.8826417349726776 \n",
      "Epoch 11 | Step 4397 | loss: 0.28678716830807743 | accuracy: 0.8827060626702997 \n",
      "Epoch 11 | Step 4398 | loss: 0.28697150372697605 | accuracy: 0.8827700407608695 \n",
      "Epoch 11 | Step 4399 | loss: 0.28700236400695345 | accuracy: 0.8828760162601627 \n",
      "Epoch 11 | Step 4400 | loss: 0.28732801363677585 | accuracy: 0.8827702702702702 \n",
      "Epoch 11 | Step 4401 | loss: 0.2876758526639154 | accuracy: 0.8827072102425876 \n",
      "Epoch 11 | Step 4402 | loss: 0.2878536983563374 | accuracy: 0.8826864919354839 \n",
      "Epoch 11 | Step 4403 | loss: 0.28792762215032014 | accuracy: 0.8826239946380697 \n",
      "Epoch 11 | Step 4404 | loss: 0.28793941129417344 | accuracy: 0.8826453877005348 \n",
      "Epoch 11 | Step 4405 | loss: 0.287618411719799 | accuracy: 0.88275 \n",
      "Epoch 11 | Step 4406 | loss: 0.28740509637096456 | accuracy: 0.8828540558510638 \n",
      "Epoch 11 | Step 4407 | loss: 0.28710534186435943 | accuracy: 0.883040450928382 \n",
      "Epoch 11 | Step 4408 | loss: 0.2874439448394157 | accuracy: 0.8828538359788359 \n",
      "Epoch 11 | Step 4409 | loss: 0.28757653408991 | accuracy: 0.8827918865435356 \n",
      "Epoch 11 | Step 4410 | loss: 0.28733636225132564 | accuracy: 0.8828947368421053 \n",
      "Epoch 11 | Step 4411 | loss: 0.28723174014820513 | accuracy: 0.8829970472440944 \n",
      "Epoch 11 | Step 4412 | loss: 0.2869840305474104 | accuracy: 0.88313972513089 \n",
      "Epoch 11 | Step 4413 | loss: 0.2869567693485915 | accuracy: 0.8831592689295039 \n",
      "Epoch 11 | Step 4414 | loss: 0.28711901222898933 | accuracy: 0.8830159505208334 \n",
      "Epoch 11 | Step 4415 | loss: 0.287118688941776 | accuracy: 0.882913961038961 \n",
      "Epoch 11 | Step 4416 | loss: 0.28730344500180355 | accuracy: 0.8828529792746114 \n",
      "Epoch 11 | Step 4417 | loss: 0.28740964539214314 | accuracy: 0.8827923126614987 \n",
      "Epoch 11 | Step 4418 | loss: 0.28750197879355593 | accuracy: 0.8827319587628866 \n",
      "Epoch 11 | Step 4419 | loss: 0.28757701256817597 | accuracy: 0.8826719151670951 \n",
      "Epoch 11 | Step 4420 | loss: 0.2877315174119595 | accuracy: 0.8825721153846153 \n",
      "Epoch 11 | Step 4421 | loss: 0.28779459279745134 | accuracy: 0.8825527493606138 \n",
      "Epoch 11 | Step 4422 | loss: 0.2876671840227685 | accuracy: 0.8826530612244898 \n",
      "Epoch 11 | Step 4423 | loss: 0.28765606328503784 | accuracy: 0.8827131043256997 \n",
      "Epoch 11 | Step 4424 | loss: 0.2877059402086106 | accuracy: 0.8826538705583756 \n",
      "Epoch 11 | Step 4425 | loss: 0.2876780551634258 | accuracy: 0.8826740506329114 \n",
      "Epoch 11 | Step 4426 | loss: 0.28751516539716365 | accuracy: 0.8826941287878788 \n",
      "Epoch 11 | Step 4427 | loss: 0.28721679726460725 | accuracy: 0.8827928211586902 \n",
      "Epoch 11 | Step 4428 | loss: 0.28734534490273234 | accuracy: 0.8826162060301508 \n",
      "Epoch 11 | Step 4429 | loss: 0.28739406962069064 | accuracy: 0.8825971177944862 \n",
      "Epoch 11 | Step 4430 | loss: 0.28766486695036303 | accuracy: 0.8825390625 \n",
      "Epoch 11 | Step 4431 | loss: 0.28750052076399785 | accuracy: 0.8826761221945137 \n",
      "Epoch 11 | Step 4432 | loss: 0.28796438704156774 | accuracy: 0.8823460820895522 \n",
      "Epoch 11 | Step 4433 | loss: 0.28777098021569397 | accuracy: 0.8824668970356508 \n",
      "Validation | Epoch 11 | Step 4433 | accuracy: 0.8427155383608558 \n",
      "Epoch 12 | Step 4434 | loss: 0.20590780675411224 | accuracy: 0.9375 \n",
      "Epoch 12 | Step 4435 | loss: 0.2715843394398689 | accuracy: 0.890625 \n",
      "Epoch 12 | Step 4436 | loss: 0.2531508356332779 | accuracy: 0.9010416666666666 \n",
      "Epoch 12 | Step 4437 | loss: 0.2821291424334049 | accuracy: 0.88671875 \n",
      "Epoch 12 | Step 4438 | loss: 0.2836491197347641 | accuracy: 0.8875 \n",
      "Epoch 12 | Step 4439 | loss: 0.2912219390273094 | accuracy: 0.8802083333333334 \n",
      "Epoch 12 | Step 4440 | loss: 0.2971423885651997 | accuracy: 0.8772321428571429 \n",
      "Epoch 12 | Step 4441 | loss: 0.31013661436736584 | accuracy: 0.875 \n",
      "Epoch 12 | Step 4442 | loss: 0.3012651917007234 | accuracy: 0.8784722222222222 \n",
      "Epoch 12 | Step 4443 | loss: 0.30773802250623705 | accuracy: 0.875 \n",
      "Epoch 12 | Step 4444 | loss: 0.3039148436351256 | accuracy: 0.875 \n",
      "Epoch 12 | Step 4445 | loss: 0.30330802872776985 | accuracy: 0.8776041666666666 \n",
      "Epoch 12 | Step 4446 | loss: 0.2964494755634895 | accuracy: 0.8798076923076923 \n",
      "Epoch 12 | Step 4447 | loss: 0.2935703865119389 | accuracy: 0.8794642857142857 \n",
      "Epoch 12 | Step 4448 | loss: 0.28411189317703245 | accuracy: 0.8833333333333333 \n",
      "Epoch 12 | Step 4449 | loss: 0.28030379209667444 | accuracy: 0.8876953125 \n",
      "Epoch 12 | Step 4450 | loss: 0.2779362745144788 | accuracy: 0.890625 \n",
      "Epoch 12 | Step 4451 | loss: 0.2774166911840439 | accuracy: 0.8888888888888888 \n",
      "Epoch 12 | Step 4452 | loss: 0.2790757417678833 | accuracy: 0.8898026315789473 \n",
      "Epoch 12 | Step 4453 | loss: 0.27736357897520064 | accuracy: 0.88984375 \n",
      "Epoch 12 | Step 4454 | loss: 0.2737346660523188 | accuracy: 0.8913690476190477 \n",
      "Epoch 12 | Step 4455 | loss: 0.2718090557239272 | accuracy: 0.8913352272727273 \n",
      "Epoch 12 | Step 4456 | loss: 0.27197500998559204 | accuracy: 0.890625 \n",
      "Epoch 12 | Step 4457 | loss: 0.2674657745907704 | accuracy: 0.892578125 \n",
      "Epoch 12 | Step 4458 | loss: 0.26635953068733215 | accuracy: 0.8925 \n",
      "Epoch 12 | Step 4459 | loss: 0.26686048393066114 | accuracy: 0.8912259615384616 \n",
      "Epoch 12 | Step 4460 | loss: 0.2682596367818338 | accuracy: 0.8900462962962963 \n",
      "Epoch 12 | Step 4461 | loss: 0.265473768647228 | accuracy: 0.8917410714285714 \n",
      "Epoch 12 | Step 4462 | loss: 0.2633243418973068 | accuracy: 0.8922413793103449 \n",
      "Epoch 12 | Step 4463 | loss: 0.264215749502182 | accuracy: 0.8911458333333333 \n",
      "Epoch 12 | Step 4464 | loss: 0.26307559397912794 | accuracy: 0.8926411290322581 \n",
      "Epoch 12 | Step 4465 | loss: 0.2648729057982564 | accuracy: 0.89208984375 \n",
      "Epoch 12 | Step 4466 | loss: 0.2672412196795146 | accuracy: 0.890625 \n",
      "Epoch 12 | Step 4467 | loss: 0.26639189439661365 | accuracy: 0.8910845588235294 \n",
      "Epoch 12 | Step 4468 | loss: 0.26394196024962835 | accuracy: 0.8919642857142858 \n",
      "Epoch 12 | Step 4469 | loss: 0.2644729825357596 | accuracy: 0.8919270833333334 \n",
      "Epoch 12 | Step 4470 | loss: 0.2640322249483418 | accuracy: 0.8918918918918919 \n",
      "Epoch 12 | Step 4471 | loss: 0.26394290555464595 | accuracy: 0.891858552631579 \n",
      "Epoch 12 | Step 4472 | loss: 0.2641793974699118 | accuracy: 0.891426282051282 \n",
      "Epoch 12 | Step 4473 | loss: 0.26402461268007754 | accuracy: 0.89140625 \n",
      "Epoch 12 | Step 4474 | loss: 0.2629017869873745 | accuracy: 0.8917682926829268 \n",
      "Epoch 12 | Step 4475 | loss: 0.26648598519109545 | accuracy: 0.8913690476190477 \n",
      "Epoch 12 | Step 4476 | loss: 0.2652733059123505 | accuracy: 0.8913517441860465 \n",
      "Epoch 12 | Step 4477 | loss: 0.2654079561206428 | accuracy: 0.8913352272727273 \n",
      "Epoch 12 | Step 4478 | loss: 0.2689385894272063 | accuracy: 0.8895833333333333 \n",
      "Epoch 12 | Step 4479 | loss: 0.27047388482352963 | accuracy: 0.889266304347826 \n",
      "Epoch 12 | Step 4480 | loss: 0.2697229283921262 | accuracy: 0.8892952127659575 \n",
      "Epoch 12 | Step 4481 | loss: 0.2722309697419405 | accuracy: 0.8880208333333334 \n",
      "Epoch 12 | Step 4482 | loss: 0.2707790011654095 | accuracy: 0.8883928571428571 \n",
      "Epoch 12 | Step 4483 | loss: 0.2723657992482185 | accuracy: 0.888125 \n",
      "Epoch 12 | Step 4484 | loss: 0.27555328052417905 | accuracy: 0.8863357843137255 \n",
      "Epoch 12 | Step 4485 | loss: 0.27632611674758106 | accuracy: 0.8855168269230769 \n",
      "Epoch 12 | Step 4486 | loss: 0.2746774703264237 | accuracy: 0.8862028301886793 \n",
      "Epoch 12 | Step 4487 | loss: 0.2735192353526752 | accuracy: 0.8868634259259259 \n",
      "Epoch 12 | Step 4488 | loss: 0.27283089838244706 | accuracy: 0.8872159090909091 \n",
      "Epoch 12 | Step 4489 | loss: 0.27333098942680023 | accuracy: 0.8875558035714286 \n",
      "Epoch 12 | Step 4490 | loss: 0.2730776978689328 | accuracy: 0.8884320175438597 \n",
      "Epoch 12 | Step 4491 | loss: 0.2735869434886966 | accuracy: 0.8876616379310345 \n",
      "Epoch 12 | Step 4492 | loss: 0.2740968074333871 | accuracy: 0.887447033898305 \n",
      "Epoch 12 | Step 4493 | loss: 0.27543313627441735 | accuracy: 0.8875 \n",
      "Epoch 12 | Step 4494 | loss: 0.2754725562255892 | accuracy: 0.8867827868852459 \n",
      "Epoch 12 | Step 4495 | loss: 0.2747239886272339 | accuracy: 0.8865927419354839 \n",
      "Epoch 12 | Step 4496 | loss: 0.2748839304087655 | accuracy: 0.8869047619047619 \n",
      "Epoch 12 | Step 4497 | loss: 0.2730323730502279 | accuracy: 0.888427734375 \n",
      "Epoch 12 | Step 4498 | loss: 0.2729534192727163 | accuracy: 0.8882211538461539 \n",
      "Epoch 12 | Step 4499 | loss: 0.27113476553649624 | accuracy: 0.8892045454545454 \n",
      "Epoch 12 | Step 4500 | loss: 0.2704727794252226 | accuracy: 0.8899253731343284 \n",
      "Epoch 12 | Step 4501 | loss: 0.27019238230936676 | accuracy: 0.8899356617647058 \n",
      "Epoch 12 | Step 4502 | loss: 0.2715832001489143 | accuracy: 0.8890398550724637 \n",
      "Epoch 12 | Step 4503 | loss: 0.2732283202665194 | accuracy: 0.8877232142857143 \n",
      "Epoch 12 | Step 4504 | loss: 0.27267816159087177 | accuracy: 0.8879841549295775 \n",
      "Epoch 12 | Step 4505 | loss: 0.27203574176463824 | accuracy: 0.888671875 \n",
      "Epoch 12 | Step 4506 | loss: 0.27202722858892736 | accuracy: 0.8886986301369864 \n",
      "Epoch 12 | Step 4507 | loss: 0.27302184036454646 | accuracy: 0.8880912162162162 \n",
      "Epoch 12 | Step 4508 | loss: 0.274309849937757 | accuracy: 0.8879166666666667 \n",
      "Epoch 12 | Step 4509 | loss: 0.27344500645995157 | accuracy: 0.8881578947368421 \n",
      "Epoch 12 | Step 4510 | loss: 0.27335766906088066 | accuracy: 0.888189935064935 \n",
      "Epoch 12 | Step 4511 | loss: 0.274864608469682 | accuracy: 0.8878205128205128 \n",
      "Epoch 12 | Step 4512 | loss: 0.27386597723146044 | accuracy: 0.8886471518987342 \n",
      "Epoch 12 | Step 4513 | loss: 0.2742256795987489 | accuracy: 0.88828125 \n",
      "Epoch 12 | Step 4514 | loss: 0.27377526609250075 | accuracy: 0.8888888888888888 \n",
      "Epoch 12 | Step 4515 | loss: 0.27240566927485366 | accuracy: 0.8894817073170732 \n",
      "Epoch 12 | Step 4516 | loss: 0.27230778785355136 | accuracy: 0.8898719879518072 \n",
      "Epoch 12 | Step 4517 | loss: 0.27265696067895223 | accuracy: 0.8902529761904762 \n",
      "Epoch 12 | Step 4518 | loss: 0.27364726013997037 | accuracy: 0.8900735294117647 \n",
      "Epoch 12 | Step 4519 | loss: 0.27277647478635936 | accuracy: 0.8909883720930233 \n",
      "Epoch 12 | Step 4520 | loss: 0.27276546482382164 | accuracy: 0.8909841954022989 \n",
      "Epoch 12 | Step 4521 | loss: 0.27335012230006145 | accuracy: 0.8915127840909091 \n",
      "Epoch 12 | Step 4522 | loss: 0.2728422744555421 | accuracy: 0.8918539325842697 \n",
      "Epoch 12 | Step 4523 | loss: 0.27403742720683427 | accuracy: 0.8913194444444444 \n",
      "Epoch 12 | Step 4524 | loss: 0.2733909229000847 | accuracy: 0.8909684065934066 \n",
      "Epoch 12 | Step 4525 | loss: 0.2757083556574325 | accuracy: 0.8901154891304348 \n",
      "Epoch 12 | Step 4526 | loss: 0.2756883357801746 | accuracy: 0.8901209677419355 \n",
      "Epoch 12 | Step 4527 | loss: 0.27501995338404445 | accuracy: 0.890126329787234 \n",
      "Epoch 12 | Step 4528 | loss: 0.2735815791707291 | accuracy: 0.8911184210526316 \n",
      "Epoch 12 | Step 4529 | loss: 0.27297001844272034 | accuracy: 0.8912760416666666 \n",
      "Epoch 12 | Step 4530 | loss: 0.27196691699863723 | accuracy: 0.8919136597938144 \n",
      "Epoch 12 | Step 4531 | loss: 0.27416962537230294 | accuracy: 0.8909438775510204 \n",
      "Epoch 12 | Step 4532 | loss: 0.2735628731021979 | accuracy: 0.8909406565656566 \n",
      "Epoch 12 | Step 4533 | loss: 0.2732892552018167 | accuracy: 0.890625 \n",
      "Epoch 12 | Step 4534 | loss: 0.2726744751233867 | accuracy: 0.8907797029702971 \n",
      "Epoch 12 | Step 4535 | loss: 0.2728829364858423 | accuracy: 0.890625 \n",
      "Epoch 12 | Step 4536 | loss: 0.27315526144597146 | accuracy: 0.8904733009708737 \n",
      "Epoch 12 | Step 4537 | loss: 0.2734209205955268 | accuracy: 0.890625 \n",
      "Epoch 12 | Step 4538 | loss: 0.2736577069475538 | accuracy: 0.8900297619047619 \n",
      "Epoch 12 | Step 4539 | loss: 0.2726078217603127 | accuracy: 0.890625 \n",
      "Epoch 12 | Step 4540 | loss: 0.27425777369013465 | accuracy: 0.8898948598130841 \n",
      "Epoch 12 | Step 4541 | loss: 0.27514349958962875 | accuracy: 0.8893229166666666 \n",
      "Epoch 12 | Step 4542 | loss: 0.27444823646764155 | accuracy: 0.8896215596330275 \n",
      "Epoch 12 | Step 4543 | loss: 0.2743511031974447 | accuracy: 0.889346590909091 \n",
      "Epoch 12 | Step 4544 | loss: 0.275331948523049 | accuracy: 0.8889358108108109 \n",
      "Epoch 12 | Step 4545 | loss: 0.2763044248734203 | accuracy: 0.888671875 \n",
      "Epoch 12 | Step 4546 | loss: 0.2769988508878557 | accuracy: 0.8886891592920354 \n",
      "Epoch 12 | Step 4547 | loss: 0.2768836489372087 | accuracy: 0.8888432017543859 \n",
      "Epoch 12 | Step 4548 | loss: 0.27601496849371043 | accuracy: 0.8889945652173913 \n",
      "Epoch 12 | Step 4549 | loss: 0.27599754813930083 | accuracy: 0.8890086206896551 \n",
      "Epoch 12 | Step 4550 | loss: 0.27614374891815024 | accuracy: 0.8891559829059829 \n",
      "Epoch 12 | Step 4551 | loss: 0.27644879522465043 | accuracy: 0.8886387711864406 \n",
      "Epoch 12 | Step 4552 | loss: 0.2771283341806476 | accuracy: 0.8882615546218487 \n",
      "Epoch 12 | Step 4553 | loss: 0.2769529942423105 | accuracy: 0.8884114583333333 \n",
      "Epoch 12 | Step 4554 | loss: 0.2761416624892842 | accuracy: 0.8886880165289256 \n",
      "Epoch 12 | Step 4555 | loss: 0.2757464168501682 | accuracy: 0.8885758196721312 \n",
      "Epoch 12 | Step 4556 | loss: 0.27582350397497657 | accuracy: 0.8884654471544715 \n",
      "Epoch 12 | Step 4557 | loss: 0.27614748165492087 | accuracy: 0.8886088709677419 \n",
      "Epoch 12 | Step 4558 | loss: 0.27578697609901426 | accuracy: 0.888875 \n",
      "Epoch 12 | Step 4559 | loss: 0.2758593897497843 | accuracy: 0.8887648809523809 \n",
      "Epoch 12 | Step 4560 | loss: 0.2771480414341754 | accuracy: 0.8882874015748031 \n",
      "Epoch 12 | Step 4561 | loss: 0.27715545799583197 | accuracy: 0.8883056640625 \n",
      "Epoch 12 | Step 4562 | loss: 0.27659767265467683 | accuracy: 0.8884447674418605 \n",
      "Epoch 12 | Step 4563 | loss: 0.2770730169919821 | accuracy: 0.8882211538461539 \n",
      "Epoch 12 | Step 4564 | loss: 0.2771605758266595 | accuracy: 0.8884780534351145 \n",
      "Epoch 12 | Step 4565 | loss: 0.2767868036347808 | accuracy: 0.888375946969697 \n",
      "Epoch 12 | Step 4566 | loss: 0.27626525549064007 | accuracy: 0.8886278195488722 \n",
      "Epoch 12 | Step 4567 | loss: 0.27617020593650304 | accuracy: 0.8885261194029851 \n",
      "Epoch 12 | Step 4568 | loss: 0.2766426976080294 | accuracy: 0.8883101851851852 \n",
      "Epoch 12 | Step 4569 | loss: 0.27674320712685585 | accuracy: 0.8885569852941176 \n",
      "Epoch 12 | Step 4570 | loss: 0.2765737611011867 | accuracy: 0.8886861313868614 \n",
      "Epoch 12 | Step 4571 | loss: 0.2764055448165838 | accuracy: 0.8887001811594204 \n",
      "Epoch 12 | Step 4572 | loss: 0.2769023147847155 | accuracy: 0.8882643884892087 \n",
      "Epoch 12 | Step 4573 | loss: 0.27643046134284566 | accuracy: 0.8885044642857144 \n",
      "Epoch 12 | Step 4574 | loss: 0.2764045316065457 | accuracy: 0.8885195035460994 \n",
      "Epoch 12 | Step 4575 | loss: 0.27609212098407077 | accuracy: 0.8885343309859156 \n",
      "Epoch 12 | Step 4576 | loss: 0.27610298293037017 | accuracy: 0.8885489510489512 \n",
      "Epoch 12 | Step 4577 | loss: 0.2753550193996893 | accuracy: 0.8888888888888888 \n",
      "Epoch 12 | Step 4578 | loss: 0.27522299443853315 | accuracy: 0.8889008620689656 \n",
      "Epoch 12 | Step 4579 | loss: 0.2761023958047776 | accuracy: 0.8884845890410958 \n",
      "Epoch 12 | Step 4580 | loss: 0.2756056138852827 | accuracy: 0.8888180272108843 \n",
      "Epoch 12 | Step 4581 | loss: 0.27533919263530426 | accuracy: 0.8888302364864865 \n",
      "Epoch 12 | Step 4582 | loss: 0.274965444367204 | accuracy: 0.8889471476510067 \n",
      "Epoch 12 | Step 4583 | loss: 0.2746436775724094 | accuracy: 0.8892708333333333 \n",
      "Epoch 12 | Step 4584 | loss: 0.27462964865150835 | accuracy: 0.8891763245033113 \n",
      "Epoch 12 | Step 4585 | loss: 0.27519860010790204 | accuracy: 0.8890830592105263 \n",
      "Epoch 12 | Step 4586 | loss: 0.2751223060235479 | accuracy: 0.8893995098039216 \n",
      "Epoch 12 | Step 4587 | loss: 0.2748523433874181 | accuracy: 0.8895089285714286 \n",
      "Epoch 12 | Step 4588 | loss: 0.2745140007426663 | accuracy: 0.889616935483871 \n",
      "Epoch 12 | Step 4589 | loss: 0.2739965931918377 | accuracy: 0.8900240384615384 \n",
      "Epoch 12 | Step 4590 | loss: 0.27340384235807297 | accuracy: 0.8904259554140127 \n",
      "Epoch 12 | Step 4591 | loss: 0.27329711106759097 | accuracy: 0.8903283227848101 \n",
      "Epoch 12 | Step 4592 | loss: 0.27299080414217236 | accuracy: 0.8904284591194969 \n",
      "Epoch 12 | Step 4593 | loss: 0.272919720504433 | accuracy: 0.8904296875 \n",
      "Epoch 12 | Step 4594 | loss: 0.2726552346663446 | accuracy: 0.890527950310559 \n",
      "Epoch 12 | Step 4595 | loss: 0.2731145470414634 | accuracy: 0.8903356481481481 \n",
      "Epoch 12 | Step 4596 | loss: 0.27244475136505325 | accuracy: 0.8905291411042945 \n",
      "Epoch 12 | Step 4597 | loss: 0.2720290438794509 | accuracy: 0.8909108231707317 \n",
      "Epoch 12 | Step 4598 | loss: 0.2719069126880531 | accuracy: 0.8910984848484849 \n",
      "Epoch 12 | Step 4599 | loss: 0.2728168375520822 | accuracy: 0.8904367469879518 \n",
      "Epoch 12 | Step 4600 | loss: 0.27218509907137145 | accuracy: 0.8907185628742516 \n",
      "Epoch 12 | Step 4601 | loss: 0.27183972494233233 | accuracy: 0.8907180059523809 \n",
      "Epoch 12 | Step 4602 | loss: 0.27283289199750105 | accuracy: 0.8903476331360947 \n",
      "Epoch 12 | Step 4603 | loss: 0.2724037580630359 | accuracy: 0.8902573529411765 \n",
      "Epoch 12 | Step 4604 | loss: 0.27276079870804015 | accuracy: 0.8900767543859649 \n",
      "Epoch 12 | Step 4605 | loss: 0.2732932096303896 | accuracy: 0.8898982558139535 \n",
      "Epoch 12 | Step 4606 | loss: 0.27237817653686336 | accuracy: 0.8903540462427746 \n",
      "Epoch 12 | Step 4607 | loss: 0.2726622498754799 | accuracy: 0.8903556034482759 \n",
      "Epoch 12 | Step 4608 | loss: 0.27191753438540883 | accuracy: 0.890625 \n",
      "Epoch 12 | Step 4609 | loss: 0.27198859608986176 | accuracy: 0.8907137784090909 \n",
      "Epoch 12 | Step 4610 | loss: 0.2722393171598684 | accuracy: 0.8905367231638418 \n",
      "Epoch 12 | Step 4611 | loss: 0.2720769943481083 | accuracy: 0.8905372191011236 \n",
      "Epoch 12 | Step 4612 | loss: 0.27241493969656255 | accuracy: 0.8901885474860335 \n",
      "Epoch 12 | Step 4613 | loss: 0.27297236091560806 | accuracy: 0.88984375 \n",
      "Epoch 12 | Step 4614 | loss: 0.2729348457979236 | accuracy: 0.8899343922651933 \n",
      "Epoch 12 | Step 4615 | loss: 0.272503004051172 | accuracy: 0.8901098901098901 \n",
      "Epoch 12 | Step 4616 | loss: 0.2723989686190758 | accuracy: 0.890198087431694 \n",
      "Epoch 12 | Step 4617 | loss: 0.2723481587903657 | accuracy: 0.8902853260869565 \n",
      "Epoch 12 | Step 4618 | loss: 0.27238598828380195 | accuracy: 0.8903716216216216 \n",
      "Epoch 12 | Step 4619 | loss: 0.27216756664296654 | accuracy: 0.8902889784946236 \n",
      "Epoch 12 | Step 4620 | loss: 0.272410691103196 | accuracy: 0.8904578877005348 \n",
      "Epoch 12 | Step 4621 | loss: 0.2722717602836327 | accuracy: 0.8904587765957447 \n",
      "Epoch 12 | Step 4622 | loss: 0.2717158073786077 | accuracy: 0.890707671957672 \n",
      "Epoch 12 | Step 4623 | loss: 0.2715628021641784 | accuracy: 0.8908717105263158 \n",
      "Epoch 12 | Step 4624 | loss: 0.2718035539719449 | accuracy: 0.890625 \n",
      "Epoch 12 | Step 4625 | loss: 0.27192382033293466 | accuracy: 0.8902994791666666 \n",
      "Epoch 12 | Step 4626 | loss: 0.2718301511181453 | accuracy: 0.8903011658031088 \n",
      "Epoch 12 | Step 4627 | loss: 0.2717276190974051 | accuracy: 0.8903833762886598 \n",
      "Epoch 12 | Step 4628 | loss: 0.27191928334725235 | accuracy: 0.8903044871794872 \n",
      "Epoch 12 | Step 4629 | loss: 0.2716182359323212 | accuracy: 0.8905452806122449 \n",
      "Epoch 12 | Step 4630 | loss: 0.2717044996428613 | accuracy: 0.8903870558375635 \n",
      "Epoch 12 | Step 4631 | loss: 0.27150080149823996 | accuracy: 0.8903882575757576 \n",
      "Epoch 12 | Step 4632 | loss: 0.2716212070467487 | accuracy: 0.8903894472361809 \n",
      "Epoch 12 | Step 4633 | loss: 0.2714828871190551 | accuracy: 0.89046875 \n",
      "Epoch 12 | Step 4634 | loss: 0.27161113154235794 | accuracy: 0.8903140547263682 \n",
      "Epoch 12 | Step 4635 | loss: 0.27180496920453473 | accuracy: 0.890315594059406 \n",
      "Epoch 12 | Step 4636 | loss: 0.27192390170590663 | accuracy: 0.8903940886699507 \n",
      "Epoch 12 | Step 4637 | loss: 0.27203868139608267 | accuracy: 0.8902420343137255 \n",
      "Epoch 12 | Step 4638 | loss: 0.27211853934497404 | accuracy: 0.8903201219512196 \n",
      "Epoch 12 | Step 4639 | loss: 0.2723099023682403 | accuracy: 0.8900940533980582 \n",
      "Epoch 12 | Step 4640 | loss: 0.2720156654643555 | accuracy: 0.8901721014492754 \n",
      "Epoch 12 | Step 4641 | loss: 0.2716880425667537 | accuracy: 0.8903245192307693 \n",
      "Epoch 12 | Step 4642 | loss: 0.2717121050260858 | accuracy: 0.8902511961722488 \n",
      "Epoch 12 | Step 4643 | loss: 0.2711790253718698 | accuracy: 0.8904761904761904 \n",
      "Epoch 12 | Step 4644 | loss: 0.27117081078307925 | accuracy: 0.8904028436018957 \n",
      "Epoch 12 | Step 4645 | loss: 0.27116480427530615 | accuracy: 0.890403891509434 \n",
      "Epoch 12 | Step 4646 | loss: 0.2707938690420611 | accuracy: 0.8906983568075117 \n",
      "Epoch 12 | Step 4647 | loss: 0.2707786487641739 | accuracy: 0.8907710280373832 \n",
      "Epoch 12 | Step 4648 | loss: 0.2709372749162278 | accuracy: 0.8904796511627907 \n",
      "Epoch 12 | Step 4649 | loss: 0.2712894963721438 | accuracy: 0.8903356481481481 \n",
      "Epoch 12 | Step 4650 | loss: 0.2716692318015388 | accuracy: 0.8901209677419355 \n",
      "Epoch 12 | Step 4651 | loss: 0.2717626288943338 | accuracy: 0.8899799311926605 \n",
      "Epoch 12 | Step 4652 | loss: 0.2716396084250928 | accuracy: 0.8899115296803652 \n",
      "Epoch 12 | Step 4653 | loss: 0.2715455264530402 | accuracy: 0.8899147727272727 \n",
      "Epoch 12 | Step 4654 | loss: 0.27145069345359923 | accuracy: 0.8899886877828054 \n",
      "Epoch 12 | Step 4655 | loss: 0.27134420044787333 | accuracy: 0.8899915540540541 \n",
      "Epoch 12 | Step 4656 | loss: 0.27114786147536757 | accuracy: 0.8899943946188341 \n",
      "Epoch 12 | Step 4657 | loss: 0.27116354102534945 | accuracy: 0.8899972098214286 \n",
      "Epoch 12 | Step 4658 | loss: 0.2713510203361515 | accuracy: 0.8898611111111111 \n",
      "Epoch 12 | Step 4659 | loss: 0.271225707984604 | accuracy: 0.8898644911504425 \n",
      "Epoch 12 | Step 4660 | loss: 0.2712114306273443 | accuracy: 0.8899366740088106 \n",
      "Epoch 12 | Step 4661 | loss: 0.2709791854416073 | accuracy: 0.8900082236842105 \n",
      "Epoch 12 | Step 4662 | loss: 0.2707182536609312 | accuracy: 0.8901473799126638 \n",
      "Epoch 12 | Step 4663 | loss: 0.2707748075542247 | accuracy: 0.8900135869565218 \n",
      "Epoch 12 | Step 4664 | loss: 0.2706111040595294 | accuracy: 0.8900162337662337 \n",
      "Epoch 12 | Step 4665 | loss: 0.2702318489037715 | accuracy: 0.8901535560344828 \n",
      "Epoch 12 | Step 4666 | loss: 0.2700260841795307 | accuracy: 0.8903567596566524 \n",
      "Epoch 12 | Step 4667 | loss: 0.27042229524535033 | accuracy: 0.8902243589743589 \n",
      "Epoch 12 | Step 4668 | loss: 0.2698960871772567 | accuracy: 0.8904920212765958 \n",
      "Epoch 12 | Step 4669 | loss: 0.26961778142189613 | accuracy: 0.890625 \n",
      "Epoch 12 | Step 4670 | loss: 0.26957978000117794 | accuracy: 0.8906909282700421 \n",
      "Epoch 12 | Step 4671 | loss: 0.2700894860660332 | accuracy: 0.8904936974789915 \n",
      "Epoch 12 | Step 4672 | loss: 0.2701232036786103 | accuracy: 0.8903634937238494 \n",
      "Epoch 12 | Step 4673 | loss: 0.2702346285184228 | accuracy: 0.890234375 \n",
      "Epoch 12 | Step 4674 | loss: 0.2706216974377141 | accuracy: 0.8899766597510373 \n",
      "Epoch 12 | Step 4675 | loss: 0.2709234478798783 | accuracy: 0.8899793388429752 \n",
      "Epoch 12 | Step 4676 | loss: 0.2706245008564784 | accuracy: 0.8901105967078189 \n",
      "Epoch 12 | Step 4677 | loss: 0.2702464849733919 | accuracy: 0.8903688524590164 \n",
      "Epoch 12 | Step 4678 | loss: 0.26997640351859925 | accuracy: 0.8904336734693877 \n",
      "Epoch 12 | Step 4679 | loss: 0.26965052295264225 | accuracy: 0.8905614837398373 \n",
      "Epoch 12 | Step 4680 | loss: 0.269410279839628 | accuracy: 0.8906882591093117 \n",
      "Epoch 12 | Step 4681 | loss: 0.26948333423464566 | accuracy: 0.8906880040322581 \n",
      "Epoch 12 | Step 4682 | loss: 0.26978627768865104 | accuracy: 0.8904994979919679 \n",
      "Epoch 12 | Step 4683 | loss: 0.2695596418976787 | accuracy: 0.8905 \n",
      "Epoch 12 | Step 4684 | loss: 0.26963767878325373 | accuracy: 0.8905004980079682 \n",
      "Epoch 12 | Step 4685 | loss: 0.2702239336120707 | accuracy: 0.8902529761904762 \n",
      "Epoch 12 | Step 4686 | loss: 0.27022010812410757 | accuracy: 0.8901926877470355 \n",
      "Epoch 12 | Step 4687 | loss: 0.27015681582407725 | accuracy: 0.890132874015748 \n",
      "Epoch 12 | Step 4688 | loss: 0.27006349809029556 | accuracy: 0.8901348039215686 \n",
      "Epoch 12 | Step 4689 | loss: 0.27003602869808707 | accuracy: 0.89013671875 \n",
      "Epoch 12 | Step 4690 | loss: 0.2701593515705973 | accuracy: 0.8901386186770428 \n",
      "Epoch 12 | Step 4691 | loss: 0.27007369142632187 | accuracy: 0.8902616279069767 \n",
      "Epoch 12 | Step 4692 | loss: 0.2702239032647788 | accuracy: 0.8902027027027027 \n",
      "Epoch 12 | Step 4693 | loss: 0.2702006210501381 | accuracy: 0.8902043269230769 \n",
      "Epoch 12 | Step 4694 | loss: 0.27042055529652914 | accuracy: 0.8901460727969349 \n",
      "Epoch 12 | Step 4695 | loss: 0.2708325731845306 | accuracy: 0.8899689885496184 \n",
      "Epoch 12 | Step 4696 | loss: 0.27111613183873723 | accuracy: 0.889912072243346 \n",
      "Epoch 12 | Step 4697 | loss: 0.27130252303499197 | accuracy: 0.8897372159090909 \n",
      "Epoch 12 | Step 4698 | loss: 0.27139680329358834 | accuracy: 0.8896226415094339 \n",
      "Epoch 12 | Step 4699 | loss: 0.2713751101628285 | accuracy: 0.8895676691729323 \n",
      "Epoch 12 | Step 4700 | loss: 0.2710934136802341 | accuracy: 0.8896886704119851 \n",
      "Epoch 12 | Step 4701 | loss: 0.2715818424389437 | accuracy: 0.8895172574626866 \n",
      "Epoch 12 | Step 4702 | loss: 0.2715553976456918 | accuracy: 0.889521375464684 \n",
      "Epoch 12 | Step 4703 | loss: 0.2716364155764936 | accuracy: 0.889525462962963 \n",
      "Epoch 12 | Step 4704 | loss: 0.27138755412779203 | accuracy: 0.8895295202952029 \n",
      "Epoch 12 | Step 4705 | loss: 0.27124467557844023 | accuracy: 0.8895909926470589 \n",
      "Epoch 12 | Step 4706 | loss: 0.2711696179358517 | accuracy: 0.8896520146520146 \n",
      "Epoch 12 | Step 4707 | loss: 0.2712671316235608 | accuracy: 0.8895985401459854 \n",
      "Epoch 12 | Step 4708 | loss: 0.2715341149676933 | accuracy: 0.8894318181818182 \n",
      "Epoch 12 | Step 4709 | loss: 0.2717415193716688 | accuracy: 0.8892096920289855 \n",
      "Epoch 12 | Step 4710 | loss: 0.27193965668712744 | accuracy: 0.8891019855595668 \n",
      "Epoch 12 | Step 4711 | loss: 0.27158860143997715 | accuracy: 0.8892760791366906 \n",
      "Epoch 12 | Step 4712 | loss: 0.2720338910497648 | accuracy: 0.8891129032258065 \n",
      "Epoch 12 | Step 4713 | loss: 0.27171220369637045 | accuracy: 0.8892299107142857 \n",
      "Epoch 12 | Step 4714 | loss: 0.2717513085154031 | accuracy: 0.8891236654804271 \n",
      "Epoch 12 | Step 4715 | loss: 0.27155617465998294 | accuracy: 0.8891843971631206 \n",
      "Epoch 12 | Step 4716 | loss: 0.27153065468944876 | accuracy: 0.8892999116607774 \n",
      "Epoch 12 | Step 4717 | loss: 0.2713508792746238 | accuracy: 0.8894696302816901 \n",
      "Epoch 12 | Step 4718 | loss: 0.27130013317392615 | accuracy: 0.8895285087719298 \n",
      "Epoch 12 | Step 4719 | loss: 0.270922567148309 | accuracy: 0.8896962412587412 \n",
      "Epoch 12 | Step 4720 | loss: 0.27091648364731696 | accuracy: 0.8895905923344948 \n",
      "Epoch 12 | Step 4721 | loss: 0.2704348729716411 | accuracy: 0.8898111979166666 \n",
      "Epoch 12 | Step 4722 | loss: 0.27055592448241195 | accuracy: 0.8897599480968859 \n",
      "Epoch 12 | Step 4723 | loss: 0.27069258689880404 | accuracy: 0.889709051724138 \n",
      "Epoch 12 | Step 4724 | loss: 0.27100424217604313 | accuracy: 0.889551116838488 \n",
      "Epoch 12 | Step 4725 | loss: 0.27081209584458266 | accuracy: 0.8896083047945206 \n",
      "Epoch 12 | Step 4726 | loss: 0.27103856063540105 | accuracy: 0.8894517918088737 \n",
      "Epoch 12 | Step 4727 | loss: 0.27079912138228546 | accuracy: 0.889562074829932 \n",
      "Epoch 12 | Step 4728 | loss: 0.2705854340124942 | accuracy: 0.8896716101694915 \n",
      "Epoch 12 | Step 4729 | loss: 0.2707510505979129 | accuracy: 0.8895692567567568 \n",
      "Epoch 12 | Step 4730 | loss: 0.27044649647943936 | accuracy: 0.8897306397306397 \n",
      "Epoch 12 | Step 4731 | loss: 0.27085683359795804 | accuracy: 0.8895763422818792 \n",
      "Epoch 12 | Step 4732 | loss: 0.27068494115784847 | accuracy: 0.889684364548495 \n",
      "Epoch 12 | Step 4733 | loss: 0.270433168113232 | accuracy: 0.88984375 \n",
      "Epoch 12 | Step 4734 | loss: 0.27049348203842855 | accuracy: 0.8896906146179402 \n",
      "Epoch 12 | Step 4735 | loss: 0.27032506574463405 | accuracy: 0.8898489238410596 \n",
      "Epoch 12 | Step 4736 | loss: 0.2702592940810493 | accuracy: 0.8898514851485149 \n",
      "Epoch 12 | Step 4737 | loss: 0.27026692591607604 | accuracy: 0.8898026315789473 \n",
      "Epoch 12 | Step 4738 | loss: 0.2699618705960574 | accuracy: 0.8900102459016394 \n",
      "Epoch 12 | Step 4739 | loss: 0.2699644401961685 | accuracy: 0.8900122549019608 \n",
      "Epoch 12 | Step 4740 | loss: 0.2702259339804761 | accuracy: 0.8899124592833876 \n",
      "Epoch 12 | Step 4741 | loss: 0.2699615169171392 | accuracy: 0.8899655032467533 \n",
      "Epoch 12 | Step 4742 | loss: 0.2696707933466029 | accuracy: 0.8901193365695793 \n",
      "Epoch 12 | Step 4743 | loss: 0.269817714537344 | accuracy: 0.890070564516129 \n",
      "Epoch 12 | Step 4744 | loss: 0.2698132297042102 | accuracy: 0.8902230707395499 \n",
      "Epoch 12 | Step 4745 | loss: 0.26971323406085024 | accuracy: 0.8902243589743589 \n",
      "Epoch 12 | Step 4746 | loss: 0.2697219392552547 | accuracy: 0.8901757188498403 \n",
      "Epoch 12 | Step 4747 | loss: 0.2701790977245686 | accuracy: 0.8901273885350318 \n",
      "Epoch 12 | Step 4748 | loss: 0.2707146126126489 | accuracy: 0.8899305555555556 \n",
      "Epoch 12 | Step 4749 | loss: 0.2707021183605438 | accuracy: 0.8899821993670886 \n",
      "Epoch 12 | Step 4750 | loss: 0.2702307384519926 | accuracy: 0.8902799684542587 \n",
      "Epoch 12 | Step 4751 | loss: 0.27033308966073627 | accuracy: 0.8902810534591195 \n",
      "Epoch 12 | Step 4752 | loss: 0.270497045196523 | accuracy: 0.890282131661442 \n",
      "Epoch 12 | Step 4753 | loss: 0.2703532047802585 | accuracy: 0.890380859375 \n",
      "Epoch 12 | Step 4754 | loss: 0.2702941956967582 | accuracy: 0.8903329439252337 \n",
      "Epoch 12 | Step 4755 | loss: 0.2708262536697879 | accuracy: 0.890236801242236 \n",
      "Epoch 12 | Step 4756 | loss: 0.27054386701284944 | accuracy: 0.8903831269349846 \n",
      "Epoch 12 | Step 4757 | loss: 0.27032880050440655 | accuracy: 0.8904803240740741 \n",
      "Epoch 12 | Step 4758 | loss: 0.27050253957510023 | accuracy: 0.8904326923076923 \n",
      "Epoch 12 | Step 4759 | loss: 0.27058266978596646 | accuracy: 0.890433282208589 \n",
      "Epoch 12 | Step 4760 | loss: 0.27063805491461335 | accuracy: 0.8903383027522935 \n",
      "Epoch 12 | Step 4761 | loss: 0.27082438782856993 | accuracy: 0.8902915396341463 \n",
      "Epoch 12 | Step 4762 | loss: 0.2711118245695503 | accuracy: 0.8900550911854104 \n",
      "Epoch 12 | Step 4763 | loss: 0.2710196451481548 | accuracy: 0.8900568181818181 \n",
      "Epoch 12 | Step 4764 | loss: 0.27107199943227744 | accuracy: 0.8900113293051359 \n",
      "Epoch 12 | Step 4765 | loss: 0.2710469802953755 | accuracy: 0.8901543674698795 \n",
      "Epoch 12 | Step 4766 | loss: 0.27112634589632745 | accuracy: 0.8902027027027027 \n",
      "Epoch 12 | Step 4767 | loss: 0.27120371624648965 | accuracy: 0.8902039670658682 \n",
      "Epoch 12 | Step 4768 | loss: 0.27110636263196186 | accuracy: 0.8902518656716418 \n",
      "Epoch 12 | Step 4769 | loss: 0.2711242853575168 | accuracy: 0.8902064732142857 \n",
      "Epoch 12 | Step 4770 | loss: 0.27099814831945274 | accuracy: 0.8902540801186943 \n",
      "Epoch 12 | Step 4771 | loss: 0.2711848129667125 | accuracy: 0.8903014053254438 \n",
      "Epoch 12 | Step 4772 | loss: 0.27092524006918856 | accuracy: 0.8904406342182891 \n",
      "Epoch 12 | Step 4773 | loss: 0.2707387297249896 | accuracy: 0.890625 \n",
      "Epoch 12 | Step 4774 | loss: 0.2709171111064576 | accuracy: 0.8904875366568915 \n",
      "Epoch 12 | Step 4775 | loss: 0.27075055792753494 | accuracy: 0.8905793128654971 \n",
      "Epoch 12 | Step 4776 | loss: 0.2706174726866776 | accuracy: 0.8907161078717201 \n",
      "Epoch 12 | Step 4777 | loss: 0.2704424119749392 | accuracy: 0.8906704215116279 \n",
      "Epoch 12 | Step 4778 | loss: 0.27065255855736564 | accuracy: 0.890625 \n",
      "Epoch 12 | Step 4779 | loss: 0.2707013130144925 | accuracy: 0.8907153179190751 \n",
      "Epoch 12 | Step 4780 | loss: 0.27040510079273267 | accuracy: 0.890850144092219 \n",
      "Epoch 12 | Step 4781 | loss: 0.2709070705947866 | accuracy: 0.8905801005747126 \n",
      "Epoch 12 | Step 4782 | loss: 0.2707603062505712 | accuracy: 0.890625 \n",
      "Epoch 12 | Step 4783 | loss: 0.27055501301373786 | accuracy: 0.8907142857142857 \n",
      "Epoch 12 | Step 4784 | loss: 0.2703635582429734 | accuracy: 0.8908030626780626 \n",
      "Epoch 12 | Step 4785 | loss: 0.2703862847463993 | accuracy: 0.8908913352272727 \n",
      "Epoch 12 | Step 4786 | loss: 0.2704567182545287 | accuracy: 0.8908463172804533 \n",
      "Epoch 12 | Step 4787 | loss: 0.27031668526052116 | accuracy: 0.8907574152542372 \n",
      "Epoch 12 | Step 4788 | loss: 0.27039727965291155 | accuracy: 0.8907570422535211 \n",
      "Epoch 12 | Step 4789 | loss: 0.2701524090691567 | accuracy: 0.890844452247191 \n",
      "Epoch 12 | Step 4790 | loss: 0.26996756537037436 | accuracy: 0.8909313725490197 \n",
      "Epoch 12 | Step 4791 | loss: 0.27003533882219066 | accuracy: 0.8908868715083799 \n",
      "Epoch 12 | Step 4792 | loss: 0.269909828423956 | accuracy: 0.8909296657381616 \n",
      "Epoch 12 | Step 4793 | loss: 0.26998496314303777 | accuracy: 0.891015625 \n",
      "Epoch 12 | Step 4794 | loss: 0.26982619922989987 | accuracy: 0.891101108033241 \n",
      "Epoch 12 | Step 4795 | loss: 0.27006296724986667 | accuracy: 0.8909703038674033 \n",
      "Epoch 12 | Step 4796 | loss: 0.27009051654374994 | accuracy: 0.8909693526170799 \n",
      "Epoch 12 | Step 4797 | loss: 0.26991518208204424 | accuracy: 0.8910113324175825 \n",
      "Epoch 12 | Step 4798 | loss: 0.2698929134909424 | accuracy: 0.8909246575342465 \n",
      "Epoch 12 | Step 4799 | loss: 0.2697657213388574 | accuracy: 0.8909238387978142 \n",
      "Epoch 12 | Step 4800 | loss: 0.26950550844705107 | accuracy: 0.8910507493188011 \n",
      "Epoch 12 | Step 4801 | loss: 0.2696681987372757 | accuracy: 0.8910920516304348 \n",
      "Epoch 12 | Step 4802 | loss: 0.269679937925604 | accuracy: 0.8912178184281843 \n",
      "Epoch 12 | Step 4803 | loss: 0.2700425929515752 | accuracy: 0.891089527027027 \n",
      "Epoch 12 | Step 4804 | loss: 0.2703106480668179 | accuracy: 0.8909619272237197 \n",
      "Epoch 12 | Step 4805 | loss: 0.2705271648823898 | accuracy: 0.8908350134408602 \n",
      "Epoch 12 | Step 4806 | loss: 0.2706236211488142 | accuracy: 0.8907925603217158 \n",
      "Epoch 12 | Step 4807 | loss: 0.27067366483456984 | accuracy: 0.8907503342245989 \n",
      "Epoch 12 | Step 4808 | loss: 0.27032215835650797 | accuracy: 0.890875 \n",
      "Epoch 12 | Step 4809 | loss: 0.2701522510776181 | accuracy: 0.8909574468085106 \n",
      "Epoch 12 | Step 4810 | loss: 0.26984955447501185 | accuracy: 0.8911223474801061 \n",
      "Epoch 12 | Step 4811 | loss: 0.2701762518278824 | accuracy: 0.8909970238095238 \n",
      "Epoch 12 | Step 4812 | loss: 0.27024071026681945 | accuracy: 0.8909960422163589 \n",
      "Epoch 12 | Step 4813 | loss: 0.2700015920753545 | accuracy: 0.8911184210526316 \n",
      "Epoch 12 | Step 4814 | loss: 0.26988814632332575 | accuracy: 0.8911991469816273 \n",
      "Epoch 12 | Step 4815 | loss: 0.26962663504387724 | accuracy: 0.8913612565445026 \n",
      "Epoch 12 | Step 4816 | loss: 0.2695802893518782 | accuracy: 0.8914001305483029 \n",
      "Epoch 12 | Step 4817 | loss: 0.2697080027428459 | accuracy: 0.8913167317708334 \n",
      "Epoch 12 | Step 4818 | loss: 0.2697510719879884 | accuracy: 0.8911931818181819 \n",
      "Epoch 12 | Step 4819 | loss: 0.26982506049961036 | accuracy: 0.891232189119171 \n",
      "Epoch 12 | Step 4820 | loss: 0.2698606731471168 | accuracy: 0.8912306201550387 \n",
      "Epoch 12 | Step 4821 | loss: 0.2699540339448713 | accuracy: 0.8911082474226805 \n",
      "Epoch 12 | Step 4822 | loss: 0.27001134922924286 | accuracy: 0.8910266709511568 \n",
      "Epoch 12 | Step 4823 | loss: 0.27012959136030634 | accuracy: 0.8909455128205128 \n",
      "Epoch 12 | Step 4824 | loss: 0.27015575650326756 | accuracy: 0.8909846547314578 \n",
      "Epoch 12 | Step 4825 | loss: 0.27001448300648123 | accuracy: 0.8911431760204082 \n",
      "Epoch 12 | Step 4826 | loss: 0.2700064669697341 | accuracy: 0.8912611323155216 \n",
      "Epoch 12 | Step 4827 | loss: 0.2700103025713247 | accuracy: 0.8912595177664975 \n",
      "Epoch 12 | Step 4828 | loss: 0.269970321938207 | accuracy: 0.8912579113924051 \n",
      "Epoch 12 | Step 4829 | loss: 0.2698091893748504 | accuracy: 0.8914141414141414 \n",
      "Epoch 12 | Step 4830 | loss: 0.26952598390336013 | accuracy: 0.8915302267002518 \n",
      "Epoch 12 | Step 4831 | loss: 0.26963026842205384 | accuracy: 0.8913709170854272 \n",
      "Epoch 12 | Step 4832 | loss: 0.26966159966281794 | accuracy: 0.8913298872180451 \n",
      "Epoch 12 | Step 4833 | loss: 0.2698577069304885 | accuracy: 0.8912890625 \n",
      "Epoch 12 | Step 4834 | loss: 0.269686632490069 | accuracy: 0.8914432668329177 \n",
      "Epoch 12 | Step 4835 | loss: 0.2701597809235553 | accuracy: 0.8912080223880597 \n",
      "Epoch 12 | Step 4836 | loss: 0.2699379420864672 | accuracy: 0.8913068474078593 \n",
      "Validation | Epoch 12 | Step 4836 | accuracy: 0.8441359929063104 \n",
      "Epoch 13 | Step 4837 | loss: 0.19228073954582214 | accuracy: 0.953125 \n",
      "Epoch 13 | Step 4838 | loss: 0.2550784945487976 | accuracy: 0.8984375 \n",
      "Epoch 13 | Step 4839 | loss: 0.23037993411223093 | accuracy: 0.9166666666666666 \n",
      "Epoch 13 | Step 4840 | loss: 0.2504773996770382 | accuracy: 0.90625 \n",
      "Epoch 13 | Step 4841 | loss: 0.25588221848011017 | accuracy: 0.90625 \n",
      "Epoch 13 | Step 4842 | loss: 0.2705525979399681 | accuracy: 0.8932291666666666 \n",
      "Epoch 13 | Step 4843 | loss: 0.2785933975662504 | accuracy: 0.8883928571428571 \n",
      "Epoch 13 | Step 4844 | loss: 0.28874036110937595 | accuracy: 0.88671875 \n",
      "Epoch 13 | Step 4845 | loss: 0.28353013429376817 | accuracy: 0.8854166666666666 \n",
      "Epoch 13 | Step 4846 | loss: 0.2894579961895943 | accuracy: 0.8828125 \n",
      "Epoch 13 | Step 4847 | loss: 0.28766577216711914 | accuracy: 0.8835227272727273 \n",
      "Epoch 13 | Step 4848 | loss: 0.2902707867324353 | accuracy: 0.8815104166666666 \n",
      "Epoch 13 | Step 4849 | loss: 0.2840119944168972 | accuracy: 0.8846153846153846 \n",
      "Epoch 13 | Step 4850 | loss: 0.2806867989046234 | accuracy: 0.8839285714285714 \n",
      "Epoch 13 | Step 4851 | loss: 0.2705541153748831 | accuracy: 0.8885416666666667 \n",
      "Epoch 13 | Step 4852 | loss: 0.2661621514707805 | accuracy: 0.8916015625 \n",
      "Epoch 13 | Step 4853 | loss: 0.26612796678262607 | accuracy: 0.8933823529411765 \n",
      "Epoch 13 | Step 4854 | loss: 0.26359536002079653 | accuracy: 0.8932291666666666 \n",
      "Epoch 13 | Step 4855 | loss: 0.26536192156766597 | accuracy: 0.8947368421052632 \n",
      "Epoch 13 | Step 4856 | loss: 0.2624292001128197 | accuracy: 0.8953125 \n",
      "Epoch 13 | Step 4857 | loss: 0.25910097218695144 | accuracy: 0.8973214285714286 \n",
      "Epoch 13 | Step 4858 | loss: 0.25811895321715966 | accuracy: 0.8955965909090909 \n",
      "Epoch 13 | Step 4859 | loss: 0.2576967166817707 | accuracy: 0.8953804347826086 \n",
      "Epoch 13 | Step 4860 | loss: 0.25315868730346364 | accuracy: 0.8971354166666666 \n",
      "Epoch 13 | Step 4861 | loss: 0.25180696487426757 | accuracy: 0.8975 \n",
      "Epoch 13 | Step 4862 | loss: 0.252106344470611 | accuracy: 0.8978365384615384 \n",
      "Epoch 13 | Step 4863 | loss: 0.2535473770565457 | accuracy: 0.8975694444444444 \n",
      "Epoch 13 | Step 4864 | loss: 0.25077135807701517 | accuracy: 0.8995535714285714 \n",
      "Epoch 13 | Step 4865 | loss: 0.24844114996235944 | accuracy: 0.900323275862069 \n",
      "Epoch 13 | Step 4866 | loss: 0.24932345102230705 | accuracy: 0.9 \n",
      "Epoch 13 | Step 4867 | loss: 0.24837369976505153 | accuracy: 0.9017137096774194 \n",
      "Epoch 13 | Step 4868 | loss: 0.24971789214760062 | accuracy: 0.900390625 \n",
      "Epoch 13 | Step 4869 | loss: 0.25260777726317896 | accuracy: 0.8977272727272727 \n",
      "Epoch 13 | Step 4870 | loss: 0.2512380879591493 | accuracy: 0.8988970588235294 \n",
      "Epoch 13 | Step 4871 | loss: 0.2490562962634223 | accuracy: 0.9 \n",
      "Epoch 13 | Step 4872 | loss: 0.24978959105081028 | accuracy: 0.9001736111111112 \n",
      "Epoch 13 | Step 4873 | loss: 0.24896405194256757 | accuracy: 0.8999155405405406 \n",
      "Epoch 13 | Step 4874 | loss: 0.249311993780889 | accuracy: 0.899671052631579 \n",
      "Epoch 13 | Step 4875 | loss: 0.2503655759187845 | accuracy: 0.8986378205128205 \n",
      "Epoch 13 | Step 4876 | loss: 0.2500338554382324 | accuracy: 0.8984375 \n",
      "Epoch 13 | Step 4877 | loss: 0.2486786417117933 | accuracy: 0.8990091463414634 \n",
      "Epoch 13 | Step 4878 | loss: 0.2522558623126575 | accuracy: 0.8984375 \n",
      "Epoch 13 | Step 4879 | loss: 0.2510216870280199 | accuracy: 0.8982558139534884 \n",
      "Epoch 13 | Step 4880 | loss: 0.2507780800488862 | accuracy: 0.8980823863636364 \n",
      "Epoch 13 | Step 4881 | loss: 0.25393893288241487 | accuracy: 0.8958333333333334 \n",
      "Epoch 13 | Step 4882 | loss: 0.2549364518212235 | accuracy: 0.8960597826086957 \n",
      "Epoch 13 | Step 4883 | loss: 0.25397560412579384 | accuracy: 0.8966090425531915 \n",
      "Epoch 13 | Step 4884 | loss: 0.25664684269577254 | accuracy: 0.8958333333333334 \n",
      "Epoch 13 | Step 4885 | loss: 0.25535505645129136 | accuracy: 0.8960459183673469 \n",
      "Epoch 13 | Step 4886 | loss: 0.2568183022737502 | accuracy: 0.8953125 \n",
      "Epoch 13 | Step 4887 | loss: 0.25980319988493816 | accuracy: 0.8933823529411765 \n",
      "Epoch 13 | Step 4888 | loss: 0.26056531014350737 | accuracy: 0.8930288461538461 \n",
      "Epoch 13 | Step 4889 | loss: 0.25889387192591173 | accuracy: 0.8935731132075472 \n",
      "Epoch 13 | Step 4890 | loss: 0.25794672414108555 | accuracy: 0.8943865740740741 \n",
      "Epoch 13 | Step 4891 | loss: 0.25789410471916197 | accuracy: 0.8943181818181818 \n",
      "Epoch 13 | Step 4892 | loss: 0.25868606194853777 | accuracy: 0.8942522321428571 \n",
      "Epoch 13 | Step 4893 | loss: 0.2585676573870474 | accuracy: 0.8947368421052632 \n",
      "Epoch 13 | Step 4894 | loss: 0.2588042657950828 | accuracy: 0.8938577586206896 \n",
      "Epoch 13 | Step 4895 | loss: 0.25945969759407683 | accuracy: 0.8940677966101694 \n",
      "Epoch 13 | Step 4896 | loss: 0.2608301232258478 | accuracy: 0.8942708333333333 \n",
      "Epoch 13 | Step 4897 | loss: 0.26084163296418106 | accuracy: 0.8936987704918032 \n",
      "Epoch 13 | Step 4898 | loss: 0.260308374320307 | accuracy: 0.8936491935483871 \n",
      "Epoch 13 | Step 4899 | loss: 0.26003290026906933 | accuracy: 0.8940972222222222 \n",
      "Epoch 13 | Step 4900 | loss: 0.2581059988588094 | accuracy: 0.895263671875 \n",
      "Epoch 13 | Step 4901 | loss: 0.25837789040345405 | accuracy: 0.8947115384615385 \n",
      "Epoch 13 | Step 4902 | loss: 0.2565222818291548 | accuracy: 0.8953598484848485 \n",
      "Epoch 13 | Step 4903 | loss: 0.2558008018714278 | accuracy: 0.8959888059701493 \n",
      "Epoch 13 | Step 4904 | loss: 0.2556495199746945 | accuracy: 0.8965992647058824 \n",
      "Epoch 13 | Step 4905 | loss: 0.2570706828348878 | accuracy: 0.896286231884058 \n",
      "Epoch 13 | Step 4906 | loss: 0.25863310290234426 | accuracy: 0.8953125 \n",
      "Epoch 13 | Step 4907 | loss: 0.25795937025211224 | accuracy: 0.8959066901408451 \n",
      "Epoch 13 | Step 4908 | loss: 0.2572103086858987 | accuracy: 0.8962673611111112 \n",
      "Epoch 13 | Step 4909 | loss: 0.2572727560588758 | accuracy: 0.896404109589041 \n",
      "Epoch 13 | Step 4910 | loss: 0.2579147918401537 | accuracy: 0.8961148648648649 \n",
      "Epoch 13 | Step 4911 | loss: 0.25900112807750697 | accuracy: 0.8960416666666666 \n",
      "Epoch 13 | Step 4912 | loss: 0.2582657194059146 | accuracy: 0.8961759868421053 \n",
      "Epoch 13 | Step 4913 | loss: 0.25827035675575205 | accuracy: 0.8963068181818182 \n",
      "Epoch 13 | Step 4914 | loss: 0.25978064861817235 | accuracy: 0.8958333333333334 \n",
      "Epoch 13 | Step 4915 | loss: 0.2585409115764159 | accuracy: 0.896756329113924 \n",
      "Epoch 13 | Step 4916 | loss: 0.2587375586852431 | accuracy: 0.896484375 \n",
      "Epoch 13 | Step 4917 | loss: 0.25831913469750206 | accuracy: 0.8969907407407407 \n",
      "Epoch 13 | Step 4918 | loss: 0.2570627351723066 | accuracy: 0.8976753048780488 \n",
      "Epoch 13 | Step 4919 | loss: 0.25707728765815135 | accuracy: 0.8979668674698795 \n",
      "Epoch 13 | Step 4920 | loss: 0.2574256642588547 | accuracy: 0.8982514880952381 \n",
      "Epoch 13 | Step 4921 | loss: 0.25817132749978233 | accuracy: 0.8983455882352941 \n",
      "Epoch 13 | Step 4922 | loss: 0.25746203681757285 | accuracy: 0.8991642441860465 \n",
      "Epoch 13 | Step 4923 | loss: 0.2576796741321169 | accuracy: 0.8988864942528736 \n",
      "Epoch 13 | Step 4924 | loss: 0.25844827192750847 | accuracy: 0.8991477272727273 \n",
      "Epoch 13 | Step 4925 | loss: 0.25796092996436565 | accuracy: 0.8994030898876404 \n",
      "Epoch 13 | Step 4926 | loss: 0.2589247461822299 | accuracy: 0.8991319444444444 \n",
      "Epoch 13 | Step 4927 | loss: 0.25793811613386813 | accuracy: 0.8993818681318682 \n",
      "Epoch 13 | Step 4928 | loss: 0.2603916574431503 | accuracy: 0.8980978260869565 \n",
      "Epoch 13 | Step 4929 | loss: 0.2604705896428837 | accuracy: 0.8980174731182796 \n",
      "Epoch 13 | Step 4930 | loss: 0.26003797494984693 | accuracy: 0.8977726063829787 \n",
      "Epoch 13 | Step 4931 | loss: 0.25858368552044825 | accuracy: 0.8985197368421053 \n",
      "Epoch 13 | Step 4932 | loss: 0.25792081801531225 | accuracy: 0.8986002604166666 \n",
      "Epoch 13 | Step 4933 | loss: 0.25727554810108605 | accuracy: 0.8991623711340206 \n",
      "Epoch 13 | Step 4934 | loss: 0.2594279360254201 | accuracy: 0.8981186224489796 \n",
      "Epoch 13 | Step 4935 | loss: 0.25891083290781647 | accuracy: 0.8982007575757576 \n",
      "Epoch 13 | Step 4936 | loss: 0.25869022838771355 | accuracy: 0.8978125 \n",
      "Epoch 13 | Step 4937 | loss: 0.25821367562702396 | accuracy: 0.8978960396039604 \n",
      "Epoch 13 | Step 4938 | loss: 0.2581794642496344 | accuracy: 0.8978247549019608 \n",
      "Epoch 13 | Step 4939 | loss: 0.25841574074284557 | accuracy: 0.8976031553398058 \n",
      "Epoch 13 | Step 4940 | loss: 0.2587616303935648 | accuracy: 0.8976862980769231 \n",
      "Epoch 13 | Step 4941 | loss: 0.2591169094045958 | accuracy: 0.8970238095238096 \n",
      "Epoch 13 | Step 4942 | loss: 0.25831998245052584 | accuracy: 0.8974056603773585 \n",
      "Epoch 13 | Step 4943 | loss: 0.2600215122660745 | accuracy: 0.8969042056074766 \n",
      "Epoch 13 | Step 4944 | loss: 0.26084728601078205 | accuracy: 0.8964120370370371 \n",
      "Epoch 13 | Step 4945 | loss: 0.2600104851870363 | accuracy: 0.8966456422018348 \n",
      "Epoch 13 | Step 4946 | loss: 0.25992030630057517 | accuracy: 0.8964488636363637 \n",
      "Epoch 13 | Step 4947 | loss: 0.2608602865187972 | accuracy: 0.8959740990990991 \n",
      "Epoch 13 | Step 4948 | loss: 0.26221755965213694 | accuracy: 0.8955078125 \n",
      "Epoch 13 | Step 4949 | loss: 0.26315882294315157 | accuracy: 0.8953263274336283 \n",
      "Epoch 13 | Step 4950 | loss: 0.2631599973037578 | accuracy: 0.8951480263157895 \n",
      "Epoch 13 | Step 4951 | loss: 0.2621305897831917 | accuracy: 0.8953804347826086 \n",
      "Epoch 13 | Step 4952 | loss: 0.26193487252397785 | accuracy: 0.8954741379310345 \n",
      "Epoch 13 | Step 4953 | loss: 0.2622414847087656 | accuracy: 0.8954326923076923 \n",
      "Epoch 13 | Step 4954 | loss: 0.2626143935752117 | accuracy: 0.8951271186440678 \n",
      "Epoch 13 | Step 4955 | loss: 0.26316289459707354 | accuracy: 0.8949579831932774 \n",
      "Epoch 13 | Step 4956 | loss: 0.26303607542067764 | accuracy: 0.8950520833333333 \n",
      "Epoch 13 | Step 4957 | loss: 0.2624082541293349 | accuracy: 0.8952737603305785 \n",
      "Epoch 13 | Step 4958 | loss: 0.2619442493334168 | accuracy: 0.8953637295081968 \n",
      "Epoch 13 | Step 4959 | loss: 0.26184741758961017 | accuracy: 0.8953252032520326 \n",
      "Epoch 13 | Step 4960 | loss: 0.26192658160242344 | accuracy: 0.895539314516129 \n",
      "Epoch 13 | Step 4961 | loss: 0.2618579953312874 | accuracy: 0.8955 \n",
      "Epoch 13 | Step 4962 | loss: 0.2617396127491716 | accuracy: 0.8953373015873016 \n",
      "Epoch 13 | Step 4963 | loss: 0.26305444755657453 | accuracy: 0.8950541338582677 \n",
      "Epoch 13 | Step 4964 | loss: 0.2629528086981736 | accuracy: 0.895263671875 \n",
      "Epoch 13 | Step 4965 | loss: 0.26227134656767515 | accuracy: 0.8952277131782945 \n",
      "Epoch 13 | Step 4966 | loss: 0.2626152940094471 | accuracy: 0.8949519230769231 \n",
      "Epoch 13 | Step 4967 | loss: 0.2626413043787461 | accuracy: 0.8951574427480916 \n",
      "Epoch 13 | Step 4968 | loss: 0.2621640677592068 | accuracy: 0.8951231060606061 \n",
      "Epoch 13 | Step 4969 | loss: 0.26178561324687827 | accuracy: 0.8952067669172933 \n",
      "Epoch 13 | Step 4970 | loss: 0.2616925931799768 | accuracy: 0.8950559701492538 \n",
      "Epoch 13 | Step 4971 | loss: 0.2621517442442753 | accuracy: 0.8946759259259259 \n",
      "Epoch 13 | Step 4972 | loss: 0.26240937987013774 | accuracy: 0.8949908088235294 \n",
      "Epoch 13 | Step 4973 | loss: 0.26232612225478585 | accuracy: 0.8950729927007299 \n",
      "Epoch 13 | Step 4974 | loss: 0.26204274027891783 | accuracy: 0.8951539855072463 \n",
      "Epoch 13 | Step 4975 | loss: 0.26234213648725757 | accuracy: 0.8947841726618705 \n",
      "Epoch 13 | Step 4976 | loss: 0.2617349791207484 | accuracy: 0.8950892857142857 \n",
      "Epoch 13 | Step 4977 | loss: 0.2617501891779561 | accuracy: 0.8950576241134752 \n",
      "Epoch 13 | Step 4978 | loss: 0.2615446168666994 | accuracy: 0.8951364436619719 \n",
      "Epoch 13 | Step 4979 | loss: 0.26158714247541826 | accuracy: 0.8952141608391608 \n",
      "Epoch 13 | Step 4980 | loss: 0.26080619445484543 | accuracy: 0.8953993055555556 \n",
      "Epoch 13 | Step 4981 | loss: 0.260753462489309 | accuracy: 0.8953663793103448 \n",
      "Epoch 13 | Step 4982 | loss: 0.26181689910080336 | accuracy: 0.8945847602739726 \n",
      "Epoch 13 | Step 4983 | loss: 0.2612811108531595 | accuracy: 0.8949829931972789 \n",
      "Epoch 13 | Step 4984 | loss: 0.2609417087625007 | accuracy: 0.8951646959459459 \n",
      "Epoch 13 | Step 4985 | loss: 0.2608226966237862 | accuracy: 0.8952390939597316 \n",
      "Epoch 13 | Step 4986 | loss: 0.2605866178373496 | accuracy: 0.8953125 \n",
      "Epoch 13 | Step 4987 | loss: 0.26054438460149515 | accuracy: 0.8951779801324503 \n",
      "Epoch 13 | Step 4988 | loss: 0.2609874937977446 | accuracy: 0.8951480263157895 \n",
      "Epoch 13 | Step 4989 | loss: 0.26083770983554183 | accuracy: 0.8954248366013072 \n",
      "Epoch 13 | Step 4990 | loss: 0.26072644727764194 | accuracy: 0.8955965909090909 \n",
      "Epoch 13 | Step 4991 | loss: 0.26019703952535506 | accuracy: 0.895866935483871 \n",
      "Epoch 13 | Step 4992 | loss: 0.25970816511947376 | accuracy: 0.8962339743589743 \n",
      "Epoch 13 | Step 4993 | loss: 0.25919438779923565 | accuracy: 0.8965963375796179 \n",
      "Epoch 13 | Step 4994 | loss: 0.2590857920107208 | accuracy: 0.8964596518987342 \n",
      "Epoch 13 | Step 4995 | loss: 0.258765957031235 | accuracy: 0.8967177672955975 \n",
      "Epoch 13 | Step 4996 | loss: 0.25867662192322316 | accuracy: 0.89677734375 \n",
      "Epoch 13 | Step 4997 | loss: 0.25843040214747376 | accuracy: 0.8966420807453416 \n",
      "Epoch 13 | Step 4998 | loss: 0.2589499895679362 | accuracy: 0.896508487654321 \n",
      "Epoch 13 | Step 4999 | loss: 0.2584170235172371 | accuracy: 0.8966641104294478 \n",
      "Epoch 13 | Step 5000 | loss: 0.2580630299067352 | accuracy: 0.8969131097560976 \n",
      "Epoch 13 | Step 5001 | loss: 0.2580916328412114 | accuracy: 0.897064393939394 \n",
      "Epoch 13 | Step 5002 | loss: 0.2591441996754652 | accuracy: 0.896460843373494 \n",
      "Epoch 13 | Step 5003 | loss: 0.2585741405090886 | accuracy: 0.8967065868263473 \n",
      "Epoch 13 | Step 5004 | loss: 0.25835792086131515 | accuracy: 0.8965773809523809 \n",
      "Epoch 13 | Step 5005 | loss: 0.2593853251909363 | accuracy: 0.8962647928994083 \n",
      "Epoch 13 | Step 5006 | loss: 0.2589551456272602 | accuracy: 0.8963235294117647 \n",
      "Epoch 13 | Step 5007 | loss: 0.2593231754083382 | accuracy: 0.8961074561403509 \n",
      "Epoch 13 | Step 5008 | loss: 0.2598726476087819 | accuracy: 0.8958938953488372 \n",
      "Epoch 13 | Step 5009 | loss: 0.2589291197630022 | accuracy: 0.8963150289017341 \n",
      "Epoch 13 | Step 5010 | loss: 0.259120002174857 | accuracy: 0.8961925287356322 \n",
      "Epoch 13 | Step 5011 | loss: 0.25843368134328293 | accuracy: 0.8964285714285715 \n",
      "Epoch 13 | Step 5012 | loss: 0.25839001105420967 | accuracy: 0.896484375 \n",
      "Epoch 13 | Step 5013 | loss: 0.2587205346273837 | accuracy: 0.8963629943502824 \n",
      "Epoch 13 | Step 5014 | loss: 0.2585015389440435 | accuracy: 0.8965063202247191 \n",
      "Epoch 13 | Step 5015 | loss: 0.2586667316669192 | accuracy: 0.8963861731843575 \n",
      "Epoch 13 | Step 5016 | loss: 0.2592976138409641 | accuracy: 0.8961805555555555 \n",
      "Epoch 13 | Step 5017 | loss: 0.25918894541033066 | accuracy: 0.8962361878453039 \n",
      "Epoch 13 | Step 5018 | loss: 0.258715222211002 | accuracy: 0.8965487637362637 \n",
      "Epoch 13 | Step 5019 | loss: 0.2587037790424186 | accuracy: 0.8966871584699454 \n",
      "Epoch 13 | Step 5020 | loss: 0.2586179619816983 | accuracy: 0.8967391304347826 \n",
      "Epoch 13 | Step 5021 | loss: 0.2586898365133518 | accuracy: 0.896875 \n",
      "Epoch 13 | Step 5022 | loss: 0.2583306518693766 | accuracy: 0.8969254032258065 \n",
      "Epoch 13 | Step 5023 | loss: 0.2586090275071522 | accuracy: 0.8968081550802139 \n",
      "Epoch 13 | Step 5024 | loss: 0.25849858374196166 | accuracy: 0.8968583776595744 \n",
      "Epoch 13 | Step 5025 | loss: 0.2580204007250292 | accuracy: 0.8970734126984127 \n",
      "Epoch 13 | Step 5026 | loss: 0.2577166163999784 | accuracy: 0.897203947368421 \n",
      "Epoch 13 | Step 5027 | loss: 0.2578560945953375 | accuracy: 0.896842277486911 \n",
      "Epoch 13 | Step 5028 | loss: 0.2578836687607691 | accuracy: 0.896728515625 \n",
      "Epoch 13 | Step 5029 | loss: 0.2576619202531682 | accuracy: 0.8969397668393783 \n",
      "Epoch 13 | Step 5030 | loss: 0.2575919547108646 | accuracy: 0.8969072164948454 \n",
      "Epoch 13 | Step 5031 | loss: 0.25773196071386345 | accuracy: 0.8967147435897436 \n",
      "Epoch 13 | Step 5032 | loss: 0.25742971992158165 | accuracy: 0.8967633928571429 \n",
      "Epoch 13 | Step 5033 | loss: 0.25752524044459246 | accuracy: 0.8966529187817259 \n",
      "Epoch 13 | Step 5034 | loss: 0.25731522285125474 | accuracy: 0.8966224747474747 \n",
      "Epoch 13 | Step 5035 | loss: 0.25730801036759243 | accuracy: 0.8968278894472361 \n",
      "Epoch 13 | Step 5036 | loss: 0.2571580345556141 | accuracy: 0.896875 \n",
      "Epoch 13 | Step 5037 | loss: 0.2571945050684968 | accuracy: 0.8967661691542289 \n",
      "Epoch 13 | Step 5038 | loss: 0.25742437561402237 | accuracy: 0.8967357673267327 \n",
      "Epoch 13 | Step 5039 | loss: 0.25752255610497726 | accuracy: 0.8967826354679803 \n",
      "Epoch 13 | Step 5040 | loss: 0.2576370839321731 | accuracy: 0.8966758578431373 \n",
      "Epoch 13 | Step 5041 | loss: 0.2578342912764085 | accuracy: 0.8967225609756098 \n",
      "Epoch 13 | Step 5042 | loss: 0.25807103872733217 | accuracy: 0.8964654126213593 \n",
      "Epoch 13 | Step 5043 | loss: 0.25783591703084363 | accuracy: 0.8965126811594203 \n",
      "Epoch 13 | Step 5044 | loss: 0.257609537193695 | accuracy: 0.8966346153846154 \n",
      "Epoch 13 | Step 5045 | loss: 0.25761675952296514 | accuracy: 0.8966058612440191 \n",
      "Epoch 13 | Step 5046 | loss: 0.25716551049124636 | accuracy: 0.8967261904761905 \n",
      "Epoch 13 | Step 5047 | loss: 0.25708810515454605 | accuracy: 0.8966972748815166 \n",
      "Epoch 13 | Step 5048 | loss: 0.25704120552905335 | accuracy: 0.8966686320754716 \n",
      "Epoch 13 | Step 5049 | loss: 0.25664849603819745 | accuracy: 0.8969336854460094 \n",
      "Epoch 13 | Step 5050 | loss: 0.2565733969002685 | accuracy: 0.8969772196261683 \n",
      "Epoch 13 | Step 5051 | loss: 0.25673651809609227 | accuracy: 0.896875 \n",
      "Epoch 13 | Step 5052 | loss: 0.2570092980577439 | accuracy: 0.8968460648148148 \n",
      "Epoch 13 | Step 5053 | loss: 0.2574558870926981 | accuracy: 0.8966013824884793 \n",
      "Epoch 13 | Step 5054 | loss: 0.2575994157531394 | accuracy: 0.896430619266055 \n",
      "Epoch 13 | Step 5055 | loss: 0.2575476450939158 | accuracy: 0.896546803652968 \n",
      "Epoch 13 | Step 5056 | loss: 0.2574085202745417 | accuracy: 0.8965909090909091 \n",
      "Epoch 13 | Step 5057 | loss: 0.2573597298016376 | accuracy: 0.8966346153846154 \n",
      "Epoch 13 | Step 5058 | loss: 0.25711269424976535 | accuracy: 0.8968186936936937 \n",
      "Epoch 13 | Step 5059 | loss: 0.25695982759175284 | accuracy: 0.8968609865470852 \n",
      "Epoch 13 | Step 5060 | loss: 0.25704402140607796 | accuracy: 0.8967633928571429 \n",
      "Epoch 13 | Step 5061 | loss: 0.2571131121781138 | accuracy: 0.8967361111111111 \n",
      "Epoch 13 | Step 5062 | loss: 0.2570665926730211 | accuracy: 0.8967090707964602 \n",
      "Epoch 13 | Step 5063 | loss: 0.2571260989171818 | accuracy: 0.8968199339207048 \n",
      "Epoch 13 | Step 5064 | loss: 0.2568822647199819 | accuracy: 0.8968612938596491 \n",
      "Epoch 13 | Step 5065 | loss: 0.2566920418991792 | accuracy: 0.8969705240174672 \n",
      "Epoch 13 | Step 5066 | loss: 0.2567087583243846 | accuracy: 0.896875 \n",
      "Epoch 13 | Step 5067 | loss: 0.2564765600995583 | accuracy: 0.8968479437229437 \n",
      "Epoch 13 | Step 5068 | loss: 0.25602623688635123 | accuracy: 0.8969558189655172 \n",
      "Epoch 13 | Step 5069 | loss: 0.25579140264972594 | accuracy: 0.8971298283261803 \n",
      "Epoch 13 | Step 5070 | loss: 0.25616241771823317 | accuracy: 0.8969017094017094 \n",
      "Epoch 13 | Step 5071 | loss: 0.2557264540106692 | accuracy: 0.8972074468085106 \n",
      "Epoch 13 | Step 5072 | loss: 0.2555158598885192 | accuracy: 0.8972457627118644 \n",
      "Epoch 13 | Step 5073 | loss: 0.25541851430628365 | accuracy: 0.8973496835443038 \n",
      "Epoch 13 | Step 5074 | loss: 0.25576426505165933 | accuracy: 0.8972557773109243 \n",
      "Epoch 13 | Step 5075 | loss: 0.25570720138036046 | accuracy: 0.897293410041841 \n",
      "Epoch 13 | Step 5076 | loss: 0.2556514251666763 | accuracy: 0.8972005208333333 \n",
      "Epoch 13 | Step 5077 | loss: 0.25592261426058044 | accuracy: 0.8969139004149378 \n",
      "Epoch 13 | Step 5078 | loss: 0.2562004295447148 | accuracy: 0.896823347107438 \n",
      "Epoch 13 | Step 5079 | loss: 0.2558671313610096 | accuracy: 0.8970550411522634 \n",
      "Epoch 13 | Step 5080 | loss: 0.2554836039599336 | accuracy: 0.8972848360655737 \n",
      "Epoch 13 | Step 5081 | loss: 0.2553272872859117 | accuracy: 0.8973214285714286 \n",
      "Epoch 13 | Step 5082 | loss: 0.2550838097505937 | accuracy: 0.8973577235772358 \n",
      "Epoch 13 | Step 5083 | loss: 0.2548162542916984 | accuracy: 0.8975202429149798 \n",
      "Epoch 13 | Step 5084 | loss: 0.25481847880948927 | accuracy: 0.897492439516129 \n",
      "Epoch 13 | Step 5085 | loss: 0.255045261398616 | accuracy: 0.8972766064257028 \n",
      "Epoch 13 | Step 5086 | loss: 0.25479873523116103 | accuracy: 0.8973125 \n",
      "Epoch 13 | Step 5087 | loss: 0.2548657163858888 | accuracy: 0.8973481075697212 \n",
      "Epoch 13 | Step 5088 | loss: 0.25538637415165927 | accuracy: 0.8971354166666666 \n",
      "Epoch 13 | Step 5089 | loss: 0.25536133505021147 | accuracy: 0.8971714426877471 \n",
      "Epoch 13 | Step 5090 | loss: 0.2552422406811882 | accuracy: 0.8971456692913385 \n",
      "Epoch 13 | Step 5091 | loss: 0.25502085834741584 | accuracy: 0.8971813725490196 \n",
      "Epoch 13 | Step 5092 | loss: 0.25501006908598345 | accuracy: 0.89715576171875 \n",
      "Epoch 13 | Step 5093 | loss: 0.25505862912663213 | accuracy: 0.8972519455252919 \n",
      "Epoch 13 | Step 5094 | loss: 0.25502373286804475 | accuracy: 0.8972868217054264 \n",
      "Epoch 13 | Step 5095 | loss: 0.2551630914614006 | accuracy: 0.8972007722007722 \n",
      "Epoch 13 | Step 5096 | loss: 0.2551843266934155 | accuracy: 0.8972355769230769 \n",
      "Epoch 13 | Step 5097 | loss: 0.25533203509461366 | accuracy: 0.8972701149425287 \n",
      "Epoch 13 | Step 5098 | loss: 0.25581096826505106 | accuracy: 0.8970658396946565 \n",
      "Epoch 13 | Step 5099 | loss: 0.25623369225417697 | accuracy: 0.8968037072243346 \n",
      "Epoch 13 | Step 5100 | loss: 0.25651032395773754 | accuracy: 0.8966027462121212 \n",
      "Epoch 13 | Step 5101 | loss: 0.256578453391228 | accuracy: 0.8964622641509434 \n",
      "Epoch 13 | Step 5102 | loss: 0.256600266084411 | accuracy: 0.8963815789473685 \n",
      "Epoch 13 | Step 5103 | loss: 0.2563829593611566 | accuracy: 0.8964770599250936 \n",
      "Epoch 13 | Step 5104 | loss: 0.2569205984195221 | accuracy: 0.8962803171641791 \n",
      "Epoch 13 | Step 5105 | loss: 0.2568409961118573 | accuracy: 0.8961431226765799 \n",
      "Epoch 13 | Step 5106 | loss: 0.2569440334759376 | accuracy: 0.8961226851851852 \n",
      "Epoch 13 | Step 5107 | loss: 0.2567612614853795 | accuracy: 0.8962177121771218 \n",
      "Epoch 13 | Step 5108 | loss: 0.2566692590001312 | accuracy: 0.8962545955882353 \n",
      "Epoch 13 | Step 5109 | loss: 0.25659871589897304 | accuracy: 0.8962339743589743 \n",
      "Epoch 13 | Step 5110 | loss: 0.25662605222450546 | accuracy: 0.8961564781021898 \n",
      "Epoch 13 | Step 5111 | loss: 0.2569818012009966 | accuracy: 0.8960227272727272 \n",
      "Epoch 13 | Step 5112 | loss: 0.25721595962734317 | accuracy: 0.8958333333333334 \n",
      "Epoch 13 | Step 5113 | loss: 0.25724982029156557 | accuracy: 0.8958145306859205 \n",
      "Epoch 13 | Step 5114 | loss: 0.2569245065448524 | accuracy: 0.895908273381295 \n",
      "Epoch 13 | Step 5115 | loss: 0.257249149130023 | accuracy: 0.8958333333333334 \n",
      "Epoch 13 | Step 5116 | loss: 0.2569887971505522 | accuracy: 0.8958705357142858 \n",
      "Epoch 13 | Step 5117 | loss: 0.2569950001572798 | accuracy: 0.8958518683274022 \n",
      "Epoch 13 | Step 5118 | loss: 0.25683316659737127 | accuracy: 0.8958887411347518 \n",
      "Epoch 13 | Step 5119 | loss: 0.25683728205336265 | accuracy: 0.8959805653710248 \n",
      "Epoch 13 | Step 5120 | loss: 0.25669777768493524 | accuracy: 0.8961267605633803 \n",
      "Epoch 13 | Step 5121 | loss: 0.2566784045936767 | accuracy: 0.8961074561403509 \n",
      "Epoch 13 | Step 5122 | loss: 0.2563713932006091 | accuracy: 0.8961975524475524 \n",
      "Epoch 13 | Step 5123 | loss: 0.2563813849245213 | accuracy: 0.8960692508710801 \n",
      "Epoch 13 | Step 5124 | loss: 0.25591639036105723 | accuracy: 0.8963216145833334 \n",
      "Epoch 13 | Step 5125 | loss: 0.25600749367661113 | accuracy: 0.8963019031141869 \n",
      "Epoch 13 | Step 5126 | loss: 0.2561701013096446 | accuracy: 0.8963362068965517 \n",
      "Epoch 13 | Step 5127 | loss: 0.25647514751277006 | accuracy: 0.8962091924398625 \n",
      "Epoch 13 | Step 5128 | loss: 0.25636195707811055 | accuracy: 0.8962435787671232 \n",
      "Epoch 13 | Step 5129 | loss: 0.2566803088570616 | accuracy: 0.8960644197952219 \n",
      "Epoch 13 | Step 5130 | loss: 0.25639932217443867 | accuracy: 0.8962585034013606 \n",
      "Epoch 13 | Step 5131 | loss: 0.25623951367402464 | accuracy: 0.8963983050847457 \n",
      "Epoch 13 | Step 5132 | loss: 0.25641486919610873 | accuracy: 0.8963260135135135 \n",
      "Epoch 13 | Step 5133 | loss: 0.25616566465559215 | accuracy: 0.8964646464646465 \n",
      "Epoch 13 | Step 5134 | loss: 0.2564502130918853 | accuracy: 0.8963926174496645 \n",
      "Epoch 13 | Step 5135 | loss: 0.25624746517792174 | accuracy: 0.8965823578595318 \n",
      "Epoch 13 | Step 5136 | loss: 0.2559425957997638 | accuracy: 0.89671875 \n",
      "Epoch 13 | Step 5137 | loss: 0.25590021185502637 | accuracy: 0.8966465946843853 \n",
      "Epoch 13 | Step 5138 | loss: 0.25574487985561994 | accuracy: 0.8967818708609272 \n",
      "Epoch 13 | Step 5139 | loss: 0.2556472327744605 | accuracy: 0.8968131188118812 \n",
      "Epoch 13 | Step 5140 | loss: 0.25566369211791357 | accuracy: 0.8967927631578947 \n",
      "Epoch 13 | Step 5141 | loss: 0.25540946888141924 | accuracy: 0.896875 \n",
      "Epoch 13 | Step 5142 | loss: 0.25542371423026294 | accuracy: 0.8968035130718954 \n",
      "Epoch 13 | Step 5143 | loss: 0.25560981336168026 | accuracy: 0.8967324918566775 \n",
      "Epoch 13 | Step 5144 | loss: 0.2553288585857135 | accuracy: 0.8968648538961039 \n",
      "Epoch 13 | Step 5145 | loss: 0.2550639168247819 | accuracy: 0.896996359223301 \n",
      "Epoch 13 | Step 5146 | loss: 0.2551826351592615 | accuracy: 0.8969254032258065 \n",
      "Epoch 13 | Step 5147 | loss: 0.2551638325406805 | accuracy: 0.8970056270096463 \n",
      "Epoch 13 | Step 5148 | loss: 0.2549515492163405 | accuracy: 0.8970352564102564 \n",
      "Epoch 13 | Step 5149 | loss: 0.2549876900621875 | accuracy: 0.897064696485623 \n",
      "Epoch 13 | Step 5150 | loss: 0.2554226774413872 | accuracy: 0.8970441878980892 \n",
      "Epoch 13 | Step 5151 | loss: 0.25604331848167217 | accuracy: 0.8968253968253969 \n",
      "Epoch 13 | Step 5152 | loss: 0.2560709919073157 | accuracy: 0.8968057753164557 \n",
      "Epoch 13 | Step 5153 | loss: 0.25562847222345464 | accuracy: 0.8970327287066246 \n",
      "Epoch 13 | Step 5154 | loss: 0.2557423801495217 | accuracy: 0.897061713836478 \n",
      "Epoch 13 | Step 5155 | loss: 0.2558752836244979 | accuracy: 0.8970415360501567 \n",
      "Epoch 13 | Step 5156 | loss: 0.2557818858651443 | accuracy: 0.897021484375 \n",
      "Epoch 13 | Step 5157 | loss: 0.2556982171080564 | accuracy: 0.8970989096573209 \n",
      "Epoch 13 | Step 5158 | loss: 0.25622841408071295 | accuracy: 0.897078804347826 \n",
      "Epoch 13 | Step 5159 | loss: 0.25597507363594707 | accuracy: 0.8971555727554179 \n",
      "Epoch 13 | Step 5160 | loss: 0.25580088575773013 | accuracy: 0.8972318672839507 \n",
      "Epoch 13 | Step 5161 | loss: 0.2560897447741947 | accuracy: 0.8971634615384615 \n",
      "Epoch 13 | Step 5162 | loss: 0.25610489505657374 | accuracy: 0.8971913343558282 \n",
      "Epoch 13 | Step 5163 | loss: 0.25610023301766904 | accuracy: 0.8971234709480123 \n",
      "Epoch 13 | Step 5164 | loss: 0.25616782506155517 | accuracy: 0.8971036585365854 \n",
      "Epoch 13 | Step 5165 | loss: 0.25637584048292184 | accuracy: 0.8969414893617021 \n",
      "Epoch 13 | Step 5166 | loss: 0.25627656603852894 | accuracy: 0.897064393939394 \n",
      "Epoch 13 | Step 5167 | loss: 0.25627346186029215 | accuracy: 0.8969977341389728 \n",
      "Epoch 13 | Step 5168 | loss: 0.2562475124351589 | accuracy: 0.8971197289156626 \n",
      "Epoch 13 | Step 5169 | loss: 0.25623796372352764 | accuracy: 0.8971471471471472 \n",
      "Epoch 13 | Step 5170 | loss: 0.25633696326149424 | accuracy: 0.8971744011976048 \n",
      "Epoch 13 | Step 5171 | loss: 0.2561743937543967 | accuracy: 0.8972481343283583 \n",
      "Epoch 13 | Step 5172 | loss: 0.25615299854516255 | accuracy: 0.8972749255952381 \n",
      "Epoch 13 | Step 5173 | loss: 0.2560380350809421 | accuracy: 0.8973015578635015 \n",
      "Epoch 13 | Step 5174 | loss: 0.2562180279847784 | accuracy: 0.8973280325443787 \n",
      "Epoch 13 | Step 5175 | loss: 0.25591653209608195 | accuracy: 0.8974465339233039 \n",
      "Epoch 13 | Step 5176 | loss: 0.2557167394853688 | accuracy: 0.8975643382352941 \n",
      "Epoch 13 | Step 5177 | loss: 0.2558163738102156 | accuracy: 0.8974981671554252 \n",
      "Epoch 13 | Step 5178 | loss: 0.2556918454056942 | accuracy: 0.8975237573099415 \n",
      "Epoch 13 | Step 5179 | loss: 0.25552998415843375 | accuracy: 0.8976858600583091 \n",
      "Epoch 13 | Step 5180 | loss: 0.25539138386849036 | accuracy: 0.8977107558139535 \n",
      "Epoch 13 | Step 5181 | loss: 0.2556288224415501 | accuracy: 0.8976449275362319 \n",
      "Epoch 13 | Step 5182 | loss: 0.2555910824135892 | accuracy: 0.8976697976878613 \n",
      "Epoch 13 | Step 5183 | loss: 0.2552863135075018 | accuracy: 0.8978296109510087 \n",
      "Epoch 13 | Step 5184 | loss: 0.25575698002230834 | accuracy: 0.8976293103448276 \n",
      "Epoch 13 | Step 5185 | loss: 0.2555510272141171 | accuracy: 0.8976540114613181 \n",
      "Epoch 13 | Step 5186 | loss: 0.25534135390605234 | accuracy: 0.8977678571428571 \n",
      "Epoch 13 | Step 5187 | loss: 0.25516289321870195 | accuracy: 0.8978810541310541 \n",
      "Epoch 13 | Step 5188 | loss: 0.2551976823544298 | accuracy: 0.8979936079545454 \n",
      "Epoch 13 | Step 5189 | loss: 0.25532413949456484 | accuracy: 0.8979727337110481 \n",
      "Epoch 13 | Step 5190 | loss: 0.25515643913446157 | accuracy: 0.897996115819209 \n",
      "Epoch 13 | Step 5191 | loss: 0.25525276684005477 | accuracy: 0.8979753521126761 \n",
      "Epoch 13 | Step 5192 | loss: 0.25506040966661436 | accuracy: 0.8980424859550562 \n",
      "Epoch 13 | Step 5193 | loss: 0.2549141780042846 | accuracy: 0.8981530112044818 \n",
      "Epoch 13 | Step 5194 | loss: 0.25493675930290227 | accuracy: 0.8980883379888268 \n",
      "Epoch 13 | Step 5195 | loss: 0.25481418237961745 | accuracy: 0.8981545961002786 \n",
      "Epoch 13 | Step 5196 | loss: 0.2548288247444562 | accuracy: 0.8982638888888889 \n",
      "Epoch 13 | Step 5197 | loss: 0.25464118841694977 | accuracy: 0.8982860110803325 \n",
      "Epoch 13 | Step 5198 | loss: 0.2547421682811243 | accuracy: 0.8982216850828729 \n",
      "Epoch 13 | Step 5199 | loss: 0.2547909720254337 | accuracy: 0.8982868457300276 \n",
      "Epoch 13 | Step 5200 | loss: 0.25467413146007833 | accuracy: 0.8983516483516484 \n",
      "Epoch 13 | Step 5201 | loss: 0.2546570039162896 | accuracy: 0.8983304794520548 \n",
      "Epoch 13 | Step 5202 | loss: 0.2545185864908121 | accuracy: 0.8983521174863388 \n",
      "Epoch 13 | Step 5203 | loss: 0.2542595142036757 | accuracy: 0.8985013623978202 \n",
      "Epoch 13 | Step 5204 | loss: 0.25443116962180834 | accuracy: 0.8985224184782609 \n",
      "Epoch 13 | Step 5205 | loss: 0.2544580054921186 | accuracy: 0.8985857046070461 \n",
      "Epoch 13 | Step 5206 | loss: 0.25478939855018173 | accuracy: 0.8984797297297298 \n",
      "Epoch 13 | Step 5207 | loss: 0.25514187354524176 | accuracy: 0.8984164420485176 \n",
      "Epoch 13 | Step 5208 | loss: 0.25535135658117386 | accuracy: 0.8983114919354839 \n",
      "Epoch 13 | Step 5209 | loss: 0.25549612645728975 | accuracy: 0.8982908847184986 \n",
      "Epoch 13 | Step 5210 | loss: 0.255525773919043 | accuracy: 0.8982703877005348 \n",
      "Epoch 13 | Step 5211 | loss: 0.2552276415626208 | accuracy: 0.898375 \n",
      "Epoch 13 | Step 5212 | loss: 0.25507626165338654 | accuracy: 0.8984790558510638 \n",
      "Epoch 13 | Step 5213 | loss: 0.2548612055593523 | accuracy: 0.8984996684350133 \n",
      "Epoch 13 | Step 5214 | loss: 0.2552388713118576 | accuracy: 0.898354828042328 \n",
      "Epoch 13 | Step 5215 | loss: 0.2553199052142279 | accuracy: 0.8982932058047494 \n",
      "Epoch 13 | Step 5216 | loss: 0.25509855929566055 | accuracy: 0.8984786184210526 \n",
      "Epoch 13 | Step 5217 | loss: 0.25501835907459885 | accuracy: 0.8985810367454068 \n",
      "Epoch 13 | Step 5218 | loss: 0.2547713440321191 | accuracy: 0.8986829188481675 \n",
      "Epoch 13 | Step 5219 | loss: 0.254684580504583 | accuracy: 0.8987026762402088 \n",
      "Epoch 13 | Step 5220 | loss: 0.2547570684109814 | accuracy: 0.8986002604166666 \n",
      "Epoch 13 | Step 5221 | loss: 0.254790951040658 | accuracy: 0.8985795454545454 \n",
      "Epoch 13 | Step 5222 | loss: 0.2548861996767742 | accuracy: 0.898639896373057 \n",
      "Epoch 13 | Step 5223 | loss: 0.2549572231811145 | accuracy: 0.8986191860465116 \n",
      "Epoch 13 | Step 5224 | loss: 0.2550804730811991 | accuracy: 0.8985985824742269 \n",
      "Epoch 13 | Step 5225 | loss: 0.2550710633320489 | accuracy: 0.8985379177377892 \n",
      "Epoch 13 | Step 5226 | loss: 0.2550971794395874 | accuracy: 0.8984375 \n",
      "Epoch 13 | Step 5227 | loss: 0.25513186164752893 | accuracy: 0.898497442455243 \n",
      "Epoch 13 | Step 5228 | loss: 0.25498873050495663 | accuracy: 0.8985570790816326 \n",
      "Epoch 13 | Step 5229 | loss: 0.25497958991136244 | accuracy: 0.8986164122137404 \n",
      "Epoch 13 | Step 5230 | loss: 0.255055153298045 | accuracy: 0.8985564720812182 \n",
      "Epoch 13 | Step 5231 | loss: 0.25501504934664 | accuracy: 0.8986946202531646 \n",
      "Epoch 13 | Step 5232 | loss: 0.25485228801691756 | accuracy: 0.8988715277777778 \n",
      "Epoch 13 | Step 5233 | loss: 0.25455368828187946 | accuracy: 0.8989688287153652 \n",
      "Epoch 13 | Step 5234 | loss: 0.2546588309932892 | accuracy: 0.8987908291457286 \n",
      "Epoch 13 | Step 5235 | loss: 0.254717224989469 | accuracy: 0.8988486842105263 \n",
      "Epoch 13 | Step 5236 | loss: 0.25492935130372624 | accuracy: 0.8987890625 \n",
      "Epoch 13 | Step 5237 | loss: 0.2547772449634019 | accuracy: 0.8988855985037406 \n",
      "Epoch 13 | Step 5238 | loss: 0.25525201117592045 | accuracy: 0.898554104477612 \n",
      "Epoch 13 | Step 5239 | loss: 0.25500591689022806 | accuracy: 0.8986347010058742 \n",
      "Validation | Epoch 13 | Step 5239 | accuracy: 0.844707262786952 \n",
      "Epoch 14 | Step 5240 | loss: 0.2059684842824936 | accuracy: 0.953125 \n",
      "Epoch 14 | Step 5241 | loss: 0.26820390671491623 | accuracy: 0.890625 \n",
      "Epoch 14 | Step 5242 | loss: 0.24027135968208313 | accuracy: 0.90625 \n",
      "Epoch 14 | Step 5243 | loss: 0.25359511375427246 | accuracy: 0.91015625 \n",
      "Epoch 14 | Step 5244 | loss: 0.25627662539482116 | accuracy: 0.90625 \n",
      "Epoch 14 | Step 5245 | loss: 0.2631068229675293 | accuracy: 0.8984375 \n",
      "Epoch 14 | Step 5246 | loss: 0.27092456817626953 | accuracy: 0.890625 \n",
      "Epoch 14 | Step 5247 | loss: 0.2798478603363037 | accuracy: 0.890625 \n",
      "Epoch 14 | Step 5248 | loss: 0.2717873437537087 | accuracy: 0.8871527777777778 \n",
      "Epoch 14 | Step 5249 | loss: 0.2776425138115883 | accuracy: 0.884375 \n",
      "Epoch 14 | Step 5250 | loss: 0.2742235023867 | accuracy: 0.8835227272727273 \n",
      "Epoch 14 | Step 5251 | loss: 0.27569379284977913 | accuracy: 0.88671875 \n",
      "Epoch 14 | Step 5252 | loss: 0.26926618355971116 | accuracy: 0.8882211538461539 \n",
      "Epoch 14 | Step 5253 | loss: 0.2660894330058779 | accuracy: 0.8883928571428571 \n",
      "Epoch 14 | Step 5254 | loss: 0.25563568274180093 | accuracy: 0.8947916666666667 \n",
      "Epoch 14 | Step 5255 | loss: 0.25186026096343994 | accuracy: 0.8984375 \n",
      "Epoch 14 | Step 5256 | loss: 0.25097419759806466 | accuracy: 0.9007352941176471 \n",
      "Epoch 14 | Step 5257 | loss: 0.2501397894488441 | accuracy: 0.9001736111111112 \n",
      "Epoch 14 | Step 5258 | loss: 0.2510846414064106 | accuracy: 0.9021381578947368 \n",
      "Epoch 14 | Step 5259 | loss: 0.24871982932090758 | accuracy: 0.9015625 \n",
      "Epoch 14 | Step 5260 | loss: 0.24496732084524064 | accuracy: 0.9032738095238095 \n",
      "Epoch 14 | Step 5261 | loss: 0.24394615129991012 | accuracy: 0.9012784090909091 \n",
      "Epoch 14 | Step 5262 | loss: 0.24477383235226507 | accuracy: 0.8987771739130435 \n",
      "Epoch 14 | Step 5263 | loss: 0.24013400077819824 | accuracy: 0.8997395833333334 \n",
      "Epoch 14 | Step 5264 | loss: 0.2384459626674652 | accuracy: 0.900625 \n",
      "Epoch 14 | Step 5265 | loss: 0.23857538402080536 | accuracy: 0.9002403846153846 \n",
      "Epoch 14 | Step 5266 | loss: 0.2409947724254043 | accuracy: 0.9004629629629629 \n",
      "Epoch 14 | Step 5267 | loss: 0.23834605515003204 | accuracy: 0.90234375 \n",
      "Epoch 14 | Step 5268 | loss: 0.2360460429356016 | accuracy: 0.9030172413793104 \n",
      "Epoch 14 | Step 5269 | loss: 0.23790576457977294 | accuracy: 0.9015625 \n",
      "Epoch 14 | Step 5270 | loss: 0.2370609083483296 | accuracy: 0.9027217741935484 \n",
      "Epoch 14 | Step 5271 | loss: 0.2384779518470168 | accuracy: 0.90234375 \n",
      "Epoch 14 | Step 5272 | loss: 0.2409695495258678 | accuracy: 0.9015151515151515 \n",
      "Epoch 14 | Step 5273 | loss: 0.2393600318361731 | accuracy: 0.9030330882352942 \n",
      "Epoch 14 | Step 5274 | loss: 0.23659049442836216 | accuracy: 0.9044642857142857 \n",
      "Epoch 14 | Step 5275 | loss: 0.23721791555484137 | accuracy: 0.9040798611111112 \n",
      "Epoch 14 | Step 5276 | loss: 0.23693492766973134 | accuracy: 0.9037162162162162 \n",
      "Epoch 14 | Step 5277 | loss: 0.2372313518273203 | accuracy: 0.9033717105263158 \n",
      "Epoch 14 | Step 5278 | loss: 0.2375089533818074 | accuracy: 0.9026442307692307 \n",
      "Epoch 14 | Step 5279 | loss: 0.23706472516059876 | accuracy: 0.903125 \n",
      "Epoch 14 | Step 5280 | loss: 0.23612268668849293 | accuracy: 0.9035823170731707 \n",
      "Epoch 14 | Step 5281 | loss: 0.23965910857632047 | accuracy: 0.9029017857142857 \n",
      "Epoch 14 | Step 5282 | loss: 0.2387061046306477 | accuracy: 0.9029796511627907 \n",
      "Epoch 14 | Step 5283 | loss: 0.23796747895804318 | accuracy: 0.9026988636363636 \n",
      "Epoch 14 | Step 5284 | loss: 0.24153853985998366 | accuracy: 0.9010416666666666 \n",
      "Epoch 14 | Step 5285 | loss: 0.24254848516505698 | accuracy: 0.9011548913043478 \n",
      "Epoch 14 | Step 5286 | loss: 0.24175906593495228 | accuracy: 0.9012632978723404 \n",
      "Epoch 14 | Step 5287 | loss: 0.24368676698456207 | accuracy: 0.9007161458333334 \n",
      "Epoch 14 | Step 5288 | loss: 0.2423983350092051 | accuracy: 0.9011479591836735 \n",
      "Epoch 14 | Step 5289 | loss: 0.24390653431415557 | accuracy: 0.900625 \n",
      "Epoch 14 | Step 5290 | loss: 0.24663203604081096 | accuracy: 0.8995098039215687 \n",
      "Epoch 14 | Step 5291 | loss: 0.246875554896318 | accuracy: 0.8996394230769231 \n",
      "Epoch 14 | Step 5292 | loss: 0.24524061128778277 | accuracy: 0.9000589622641509 \n",
      "Epoch 14 | Step 5293 | loss: 0.24435287603625544 | accuracy: 0.9004629629629629 \n",
      "Epoch 14 | Step 5294 | loss: 0.2444114793430675 | accuracy: 0.9002840909090909 \n",
      "Epoch 14 | Step 5295 | loss: 0.24542248940893582 | accuracy: 0.9006696428571429 \n",
      "Epoch 14 | Step 5296 | loss: 0.24513563592182963 | accuracy: 0.9013157894736842 \n",
      "Epoch 14 | Step 5297 | loss: 0.2456938996911049 | accuracy: 0.9008620689655172 \n",
      "Epoch 14 | Step 5298 | loss: 0.2466950853497295 | accuracy: 0.9004237288135594 \n",
      "Epoch 14 | Step 5299 | loss: 0.24832574700315793 | accuracy: 0.9002604166666667 \n",
      "Epoch 14 | Step 5300 | loss: 0.24867539156655796 | accuracy: 0.9001024590163934 \n",
      "Epoch 14 | Step 5301 | loss: 0.24776991384644662 | accuracy: 0.8999495967741935 \n",
      "Epoch 14 | Step 5302 | loss: 0.24789009302381484 | accuracy: 0.8993055555555556 \n",
      "Epoch 14 | Step 5303 | loss: 0.24580888752825558 | accuracy: 0.900634765625 \n",
      "Epoch 14 | Step 5304 | loss: 0.24594019445089194 | accuracy: 0.9004807692307693 \n",
      "Epoch 14 | Step 5305 | loss: 0.2443146010239919 | accuracy: 0.9015151515151515 \n",
      "Epoch 14 | Step 5306 | loss: 0.24346716457338474 | accuracy: 0.9018190298507462 \n",
      "Epoch 14 | Step 5307 | loss: 0.24321952703244545 | accuracy: 0.9018841911764706 \n",
      "Epoch 14 | Step 5308 | loss: 0.24494854112466177 | accuracy: 0.9012681159420289 \n",
      "Epoch 14 | Step 5309 | loss: 0.24623327319111143 | accuracy: 0.9002232142857143 \n",
      "Epoch 14 | Step 5310 | loss: 0.2454299250958671 | accuracy: 0.9009683098591549 \n",
      "Epoch 14 | Step 5311 | loss: 0.2445115858895911 | accuracy: 0.9014756944444444 \n",
      "Epoch 14 | Step 5312 | loss: 0.24448295100911022 | accuracy: 0.9017551369863014 \n",
      "Epoch 14 | Step 5313 | loss: 0.24521327038874496 | accuracy: 0.901393581081081 \n",
      "Epoch 14 | Step 5314 | loss: 0.24629344324270885 | accuracy: 0.9010416666666666 \n",
      "Epoch 14 | Step 5315 | loss: 0.2454720627712576 | accuracy: 0.9015213815789473 \n",
      "Epoch 14 | Step 5316 | loss: 0.24553061808858598 | accuracy: 0.9015827922077922 \n",
      "Epoch 14 | Step 5317 | loss: 0.24693903747277382 | accuracy: 0.9012419871794872 \n",
      "Epoch 14 | Step 5318 | loss: 0.24584657463091839 | accuracy: 0.9020965189873418 \n",
      "Epoch 14 | Step 5319 | loss: 0.24600745383650063 | accuracy: 0.901953125 \n",
      "Epoch 14 | Step 5320 | loss: 0.24570144436977528 | accuracy: 0.902391975308642 \n",
      "Epoch 14 | Step 5321 | loss: 0.24458837182056614 | accuracy: 0.9030106707317073 \n",
      "Epoch 14 | Step 5322 | loss: 0.24483802735087384 | accuracy: 0.9032379518072289 \n",
      "Epoch 14 | Step 5323 | loss: 0.24507788391340346 | accuracy: 0.9034598214285714 \n",
      "Epoch 14 | Step 5324 | loss: 0.2460397678263047 | accuracy: 0.903125 \n",
      "Epoch 14 | Step 5325 | loss: 0.2451757863163948 | accuracy: 0.9040697674418605 \n",
      "Epoch 14 | Step 5326 | loss: 0.24515249674347625 | accuracy: 0.9040948275862069 \n",
      "Epoch 14 | Step 5327 | loss: 0.24571852961724455 | accuracy: 0.9044744318181818 \n",
      "Epoch 14 | Step 5328 | loss: 0.2451376012536917 | accuracy: 0.9050210674157303 \n",
      "Epoch 14 | Step 5329 | loss: 0.24605809963411754 | accuracy: 0.9046875 \n",
      "Epoch 14 | Step 5330 | loss: 0.2452569739831673 | accuracy: 0.9048763736263736 \n",
      "Epoch 14 | Step 5331 | loss: 0.24748581793645155 | accuracy: 0.9043817934782609 \n",
      "Epoch 14 | Step 5332 | loss: 0.24748461909832492 | accuracy: 0.9042338709677419 \n",
      "Epoch 14 | Step 5333 | loss: 0.24691305674136954 | accuracy: 0.9040890957446809 \n",
      "Epoch 14 | Step 5334 | loss: 0.24547179427586105 | accuracy: 0.9049342105263158 \n",
      "Epoch 14 | Step 5335 | loss: 0.2450111071423938 | accuracy: 0.9049479166666666 \n",
      "Epoch 14 | Step 5336 | loss: 0.244212878656756 | accuracy: 0.9056056701030928 \n",
      "Epoch 14 | Step 5337 | loss: 0.24636736261297246 | accuracy: 0.9051339285714286 \n",
      "Epoch 14 | Step 5338 | loss: 0.24579669858771142 | accuracy: 0.9053030303030303 \n",
      "Epoch 14 | Step 5339 | loss: 0.24548478372395038 | accuracy: 0.90484375 \n",
      "Epoch 14 | Step 5340 | loss: 0.24506674773327194 | accuracy: 0.9048576732673267 \n",
      "Epoch 14 | Step 5341 | loss: 0.24509001998048202 | accuracy: 0.9045649509803921 \n",
      "Epoch 14 | Step 5342 | loss: 0.2452293240184923 | accuracy: 0.9045813106796117 \n",
      "Epoch 14 | Step 5343 | loss: 0.24544879815612847 | accuracy: 0.9045973557692307 \n",
      "Epoch 14 | Step 5344 | loss: 0.24557600099416005 | accuracy: 0.9041666666666667 \n",
      "Epoch 14 | Step 5345 | loss: 0.24489159242443317 | accuracy: 0.9046285377358491 \n",
      "Epoch 14 | Step 5346 | loss: 0.2464864176706733 | accuracy: 0.9040595794392523 \n",
      "Epoch 14 | Step 5347 | loss: 0.24730754705766836 | accuracy: 0.9039351851851852 \n",
      "Epoch 14 | Step 5348 | loss: 0.24651928321210617 | accuracy: 0.9040997706422018 \n",
      "Epoch 14 | Step 5349 | loss: 0.24639319025657394 | accuracy: 0.9038352272727272 \n",
      "Epoch 14 | Step 5350 | loss: 0.2471438222774514 | accuracy: 0.903293918918919 \n",
      "Epoch 14 | Step 5351 | loss: 0.24826609855517745 | accuracy: 0.9030412946428571 \n",
      "Epoch 14 | Step 5352 | loss: 0.24922693547158115 | accuracy: 0.9027931415929203 \n",
      "Epoch 14 | Step 5353 | loss: 0.24912602382532337 | accuracy: 0.9028234649122807 \n",
      "Epoch 14 | Step 5354 | loss: 0.2482598889781081 | accuracy: 0.903125 \n",
      "Epoch 14 | Step 5355 | loss: 0.2480761681779705 | accuracy: 0.9031519396551724 \n",
      "Epoch 14 | Step 5356 | loss: 0.2481089986414991 | accuracy: 0.9033119658119658 \n",
      "Epoch 14 | Step 5357 | loss: 0.24819799076955198 | accuracy: 0.903072033898305 \n",
      "Epoch 14 | Step 5358 | loss: 0.24878426666269784 | accuracy: 0.9028361344537815 \n",
      "Epoch 14 | Step 5359 | loss: 0.24866925807048876 | accuracy: 0.9028645833333333 \n",
      "Epoch 14 | Step 5360 | loss: 0.24791398305784573 | accuracy: 0.903021694214876 \n",
      "Epoch 14 | Step 5361 | loss: 0.2476438279645365 | accuracy: 0.9029200819672131 \n",
      "Epoch 14 | Step 5362 | loss: 0.24766176642198873 | accuracy: 0.9030741869918699 \n",
      "Epoch 14 | Step 5363 | loss: 0.24785369628619763 | accuracy: 0.9032258064516129 \n",
      "Epoch 14 | Step 5364 | loss: 0.24765067034959792 | accuracy: 0.90325 \n",
      "Epoch 14 | Step 5365 | loss: 0.24778922026356062 | accuracy: 0.9029017857142857 \n",
      "Epoch 14 | Step 5366 | loss: 0.2489315471428586 | accuracy: 0.9025590551181102 \n",
      "Epoch 14 | Step 5367 | loss: 0.24890069948742166 | accuracy: 0.902587890625 \n",
      "Epoch 14 | Step 5368 | loss: 0.2483065377256667 | accuracy: 0.9027374031007752 \n",
      "Epoch 14 | Step 5369 | loss: 0.24874520937983807 | accuracy: 0.9025240384615385 \n",
      "Epoch 14 | Step 5370 | loss: 0.24865026311337493 | accuracy: 0.9027910305343512 \n",
      "Epoch 14 | Step 5371 | loss: 0.2481893150305206 | accuracy: 0.9028172348484849 \n",
      "Epoch 14 | Step 5372 | loss: 0.24765038260615857 | accuracy: 0.9031954887218046 \n",
      "Epoch 14 | Step 5373 | loss: 0.24751433591122057 | accuracy: 0.9031016791044776 \n",
      "Epoch 14 | Step 5374 | loss: 0.24793673593688895 | accuracy: 0.903125 \n",
      "Epoch 14 | Step 5375 | loss: 0.2481964847949498 | accuracy: 0.9033777573529411 \n",
      "Epoch 14 | Step 5376 | loss: 0.24808885934796646 | accuracy: 0.9033987226277372 \n",
      "Epoch 14 | Step 5377 | loss: 0.24765239434613698 | accuracy: 0.9035326086956522 \n",
      "Epoch 14 | Step 5378 | loss: 0.24796955442900281 | accuracy: 0.9031025179856115 \n",
      "Epoch 14 | Step 5379 | loss: 0.24746332301625185 | accuracy: 0.9034598214285714 \n",
      "Epoch 14 | Step 5380 | loss: 0.24752950419982275 | accuracy: 0.903479609929078 \n",
      "Epoch 14 | Step 5381 | loss: 0.24722442896643154 | accuracy: 0.9037191901408451 \n",
      "Epoch 14 | Step 5382 | loss: 0.24711593626054018 | accuracy: 0.9038461538461539 \n",
      "Epoch 14 | Step 5383 | loss: 0.24635663230179083 | accuracy: 0.904296875 \n",
      "Epoch 14 | Step 5384 | loss: 0.24637098893009382 | accuracy: 0.9040948275862069 \n",
      "Epoch 14 | Step 5385 | loss: 0.24761495244217246 | accuracy: 0.9035744863013698 \n",
      "Epoch 14 | Step 5386 | loss: 0.24720993866117633 | accuracy: 0.9038052721088435 \n",
      "Epoch 14 | Step 5387 | loss: 0.24682948874259317 | accuracy: 0.9039273648648649 \n",
      "Epoch 14 | Step 5388 | loss: 0.2465431489700439 | accuracy: 0.9042575503355704 \n",
      "Epoch 14 | Step 5389 | loss: 0.2463231053451697 | accuracy: 0.904375 \n",
      "Epoch 14 | Step 5390 | loss: 0.24643496394354775 | accuracy: 0.9041804635761589 \n",
      "Epoch 14 | Step 5391 | loss: 0.2467846908165436 | accuracy: 0.9041940789473685 \n",
      "Epoch 14 | Step 5392 | loss: 0.24646814298980377 | accuracy: 0.9044117647058824 \n",
      "Epoch 14 | Step 5393 | loss: 0.24650861908282554 | accuracy: 0.9044237012987013 \n",
      "Epoch 14 | Step 5394 | loss: 0.24605399884523885 | accuracy: 0.9045362903225806 \n",
      "Epoch 14 | Step 5395 | loss: 0.24550547742117673 | accuracy: 0.9047475961538461 \n",
      "Epoch 14 | Step 5396 | loss: 0.24494703859090805 | accuracy: 0.9050557324840764 \n",
      "Epoch 14 | Step 5397 | loss: 0.24493011921832833 | accuracy: 0.9047666139240507 \n",
      "Epoch 14 | Step 5398 | loss: 0.24468864505208512 | accuracy: 0.9046776729559748 \n",
      "Epoch 14 | Step 5399 | loss: 0.24466961487196387 | accuracy: 0.9046875 \n",
      "Epoch 14 | Step 5400 | loss: 0.2444725789546226 | accuracy: 0.9047942546583851 \n",
      "Epoch 14 | Step 5401 | loss: 0.2450157204803861 | accuracy: 0.9048032407407407 \n",
      "Epoch 14 | Step 5402 | loss: 0.24443013998079885 | accuracy: 0.9050038343558282 \n",
      "Epoch 14 | Step 5403 | loss: 0.2440367561378857 | accuracy: 0.9053925304878049 \n",
      "Epoch 14 | Step 5404 | loss: 0.24405704262581737 | accuracy: 0.9054924242424243 \n",
      "Epoch 14 | Step 5405 | loss: 0.2452391037291073 | accuracy: 0.9049322289156626 \n",
      "Epoch 14 | Step 5406 | loss: 0.24471623245292082 | accuracy: 0.905127245508982 \n",
      "Epoch 14 | Step 5407 | loss: 0.24432258551851624 | accuracy: 0.9050409226190477 \n",
      "Epoch 14 | Step 5408 | loss: 0.24531525615933378 | accuracy: 0.9046782544378699 \n",
      "Epoch 14 | Step 5409 | loss: 0.24490259898936048 | accuracy: 0.9047794117647059 \n",
      "Epoch 14 | Step 5410 | loss: 0.24525275700099286 | accuracy: 0.9045138888888888 \n",
      "Epoch 14 | Step 5411 | loss: 0.24580744493666085 | accuracy: 0.9043422965116279 \n",
      "Epoch 14 | Step 5412 | loss: 0.24489787190808038 | accuracy: 0.9047145953757225 \n",
      "Epoch 14 | Step 5413 | loss: 0.245059656557338 | accuracy: 0.9046336206896551 \n",
      "Epoch 14 | Step 5414 | loss: 0.24443639776536397 | accuracy: 0.9049107142857142 \n",
      "Epoch 14 | Step 5415 | loss: 0.24449987070296297 | accuracy: 0.9050071022727273 \n",
      "Epoch 14 | Step 5416 | loss: 0.24464270762972912 | accuracy: 0.9050141242937854 \n",
      "Epoch 14 | Step 5417 | loss: 0.24435009543647926 | accuracy: 0.9051088483146067 \n",
      "Epoch 14 | Step 5418 | loss: 0.24450689550052143 | accuracy: 0.9048533519553073 \n",
      "Epoch 14 | Step 5419 | loss: 0.2449736397713423 | accuracy: 0.9046875 \n",
      "Epoch 14 | Step 5420 | loss: 0.2448237553568176 | accuracy: 0.9047824585635359 \n",
      "Epoch 14 | Step 5421 | loss: 0.2444813204417517 | accuracy: 0.9050480769230769 \n",
      "Epoch 14 | Step 5422 | loss: 0.24440348494411165 | accuracy: 0.9052254098360656 \n",
      "Epoch 14 | Step 5423 | loss: 0.24453962031427934 | accuracy: 0.9051460597826086 \n",
      "Epoch 14 | Step 5424 | loss: 0.24462112852850476 | accuracy: 0.905152027027027 \n",
      "Epoch 14 | Step 5425 | loss: 0.24417826401129847 | accuracy: 0.905241935483871 \n",
      "Epoch 14 | Step 5426 | loss: 0.24425270751038974 | accuracy: 0.9053308823529411 \n",
      "Epoch 14 | Step 5427 | loss: 0.24408913043109662 | accuracy: 0.9054188829787234 \n",
      "Epoch 14 | Step 5428 | loss: 0.24359688655566916 | accuracy: 0.9055059523809523 \n",
      "Epoch 14 | Step 5429 | loss: 0.24347831069638853 | accuracy: 0.9056743421052632 \n",
      "Epoch 14 | Step 5430 | loss: 0.24359411481007232 | accuracy: 0.9053501308900523 \n",
      "Epoch 14 | Step 5431 | loss: 0.24369636717407653 | accuracy: 0.9054361979166666 \n",
      "Epoch 14 | Step 5432 | loss: 0.24343251521877673 | accuracy: 0.9056023316062176 \n",
      "Epoch 14 | Step 5433 | loss: 0.24333760983397051 | accuracy: 0.9055251288659794 \n",
      "Epoch 14 | Step 5434 | loss: 0.24343142322240732 | accuracy: 0.905448717948718 \n",
      "Epoch 14 | Step 5435 | loss: 0.24303141871125114 | accuracy: 0.9056122448979592 \n",
      "Epoch 14 | Step 5436 | loss: 0.24311397534790377 | accuracy: 0.9055361675126904 \n",
      "Epoch 14 | Step 5437 | loss: 0.24300114204636727 | accuracy: 0.9055397727272727 \n",
      "Epoch 14 | Step 5438 | loss: 0.24309297104426963 | accuracy: 0.9056218592964824 \n",
      "Epoch 14 | Step 5439 | loss: 0.24294633958488704 | accuracy: 0.905703125 \n",
      "Epoch 14 | Step 5440 | loss: 0.24307021561694975 | accuracy: 0.9055503731343284 \n",
      "Epoch 14 | Step 5441 | loss: 0.24320524211714764 | accuracy: 0.9054764851485149 \n",
      "Epoch 14 | Step 5442 | loss: 0.2432700313737827 | accuracy: 0.9054802955665024 \n",
      "Epoch 14 | Step 5443 | loss: 0.2433488549043735 | accuracy: 0.9053308823529411 \n",
      "Epoch 14 | Step 5444 | loss: 0.243504932922561 | accuracy: 0.9052591463414634 \n",
      "Epoch 14 | Step 5445 | loss: 0.24367982673558217 | accuracy: 0.9050364077669902 \n",
      "Epoch 14 | Step 5446 | loss: 0.24340808834286703 | accuracy: 0.905042270531401 \n",
      "Epoch 14 | Step 5447 | loss: 0.2431626752950251 | accuracy: 0.9050480769230769 \n",
      "Epoch 14 | Step 5448 | loss: 0.24319170825361636 | accuracy: 0.9049790669856459 \n",
      "Epoch 14 | Step 5449 | loss: 0.24267615452408792 | accuracy: 0.9052083333333333 \n",
      "Epoch 14 | Step 5450 | loss: 0.24265051859108758 | accuracy: 0.9052132701421801 \n",
      "Epoch 14 | Step 5451 | loss: 0.2425387303854497 | accuracy: 0.9052918632075472 \n",
      "Epoch 14 | Step 5452 | loss: 0.2421479114974049 | accuracy: 0.9055164319248826 \n",
      "Epoch 14 | Step 5453 | loss: 0.2421672131483243 | accuracy: 0.9055198598130841 \n",
      "Epoch 14 | Step 5454 | loss: 0.24239327328842739 | accuracy: 0.9053052325581395 \n",
      "Epoch 14 | Step 5455 | loss: 0.2427305223558236 | accuracy: 0.9050925925925926 \n",
      "Epoch 14 | Step 5456 | loss: 0.24299247477049102 | accuracy: 0.9050259216589862 \n",
      "Epoch 14 | Step 5457 | loss: 0.2429863655717548 | accuracy: 0.9050315366972477 \n",
      "Epoch 14 | Step 5458 | loss: 0.24286539951279829 | accuracy: 0.905037100456621 \n",
      "Epoch 14 | Step 5459 | loss: 0.2427441058172421 | accuracy: 0.904971590909091 \n",
      "Epoch 14 | Step 5460 | loss: 0.24260212443937543 | accuracy: 0.905118778280543 \n",
      "Epoch 14 | Step 5461 | loss: 0.24234419540913255 | accuracy: 0.9052646396396397 \n",
      "Epoch 14 | Step 5462 | loss: 0.24226252597677334 | accuracy: 0.9051989910313901 \n",
      "Epoch 14 | Step 5463 | loss: 0.24236869283153542 | accuracy: 0.9051339285714286 \n",
      "Epoch 14 | Step 5464 | loss: 0.2424728677339024 | accuracy: 0.9049305555555556 \n",
      "Epoch 14 | Step 5465 | loss: 0.2423413379727739 | accuracy: 0.9048672566371682 \n",
      "Epoch 14 | Step 5466 | loss: 0.24255309280188597 | accuracy: 0.9048733480176211 \n",
      "Epoch 14 | Step 5467 | loss: 0.24233827155018062 | accuracy: 0.9048793859649122 \n",
      "Epoch 14 | Step 5468 | loss: 0.242200599324495 | accuracy: 0.9050218340611353 \n",
      "Epoch 14 | Step 5469 | loss: 0.24229308765219607 | accuracy: 0.9049592391304347 \n",
      "Epoch 14 | Step 5470 | loss: 0.24212525014108394 | accuracy: 0.9049648268398268 \n",
      "Epoch 14 | Step 5471 | loss: 0.241787345148623 | accuracy: 0.9049703663793104 \n",
      "Epoch 14 | Step 5472 | loss: 0.241511766139274 | accuracy: 0.9052440987124464 \n",
      "Epoch 14 | Step 5473 | loss: 0.2418794439962277 | accuracy: 0.9050480769230769 \n",
      "Epoch 14 | Step 5474 | loss: 0.24150134397948042 | accuracy: 0.9053191489361702 \n",
      "Epoch 14 | Step 5475 | loss: 0.24125990426262556 | accuracy: 0.9053893008474576 \n",
      "Epoch 14 | Step 5476 | loss: 0.2411022606592641 | accuracy: 0.9054588607594937 \n",
      "Epoch 14 | Step 5477 | loss: 0.2415129895783773 | accuracy: 0.905265231092437 \n",
      "Epoch 14 | Step 5478 | loss: 0.24146377694282573 | accuracy: 0.9052693514644351 \n",
      "Epoch 14 | Step 5479 | loss: 0.24138291742031773 | accuracy: 0.9052083333333333 \n",
      "Epoch 14 | Step 5480 | loss: 0.2417244873168063 | accuracy: 0.9050181535269709 \n",
      "Epoch 14 | Step 5481 | loss: 0.2419304575863456 | accuracy: 0.9048941115702479 \n",
      "Epoch 14 | Step 5482 | loss: 0.24162283365005327 | accuracy: 0.9050925925925926 \n",
      "Epoch 14 | Step 5483 | loss: 0.2412458342790115 | accuracy: 0.9052894467213115 \n",
      "Epoch 14 | Step 5484 | loss: 0.2410819835504707 | accuracy: 0.9052933673469388 \n",
      "Epoch 14 | Step 5485 | loss: 0.24072797575253782 | accuracy: 0.9053607723577236 \n",
      "Epoch 14 | Step 5486 | loss: 0.2404694401240542 | accuracy: 0.9054908906882592 \n",
      "Epoch 14 | Step 5487 | loss: 0.24053618200724164 | accuracy: 0.9054939516129032 \n",
      "Epoch 14 | Step 5488 | loss: 0.2407945801156113 | accuracy: 0.905245983935743 \n",
      "Epoch 14 | Step 5489 | loss: 0.24057265588641166 | accuracy: 0.9053125 \n",
      "Epoch 14 | Step 5490 | loss: 0.24076715999271764 | accuracy: 0.905316235059761 \n",
      "Epoch 14 | Step 5491 | loss: 0.24133756753825952 | accuracy: 0.9050719246031746 \n",
      "Epoch 14 | Step 5492 | loss: 0.24128489976697287 | accuracy: 0.905076581027668 \n",
      "Epoch 14 | Step 5493 | loss: 0.24112468362441214 | accuracy: 0.9050812007874016 \n",
      "Epoch 14 | Step 5494 | loss: 0.2409386366313579 | accuracy: 0.9050857843137254 \n",
      "Epoch 14 | Step 5495 | loss: 0.24098942024284042 | accuracy: 0.90509033203125 \n",
      "Epoch 14 | Step 5496 | loss: 0.24108795702805316 | accuracy: 0.9050948443579766 \n",
      "Epoch 14 | Step 5497 | loss: 0.24105766083496485 | accuracy: 0.9052204457364341 \n",
      "Epoch 14 | Step 5498 | loss: 0.241028549789692 | accuracy: 0.9052244208494209 \n",
      "Epoch 14 | Step 5499 | loss: 0.2410199498041318 | accuracy: 0.9052283653846154 \n",
      "Epoch 14 | Step 5500 | loss: 0.2411919132560149 | accuracy: 0.9051724137931034 \n",
      "Epoch 14 | Step 5501 | loss: 0.2417035316977337 | accuracy: 0.9049379770992366 \n",
      "Epoch 14 | Step 5502 | loss: 0.24197122729436527 | accuracy: 0.9048835551330798 \n",
      "Epoch 14 | Step 5503 | loss: 0.24224042680791832 | accuracy: 0.9047111742424242 \n",
      "Epoch 14 | Step 5504 | loss: 0.24234583166972645 | accuracy: 0.9046580188679245 \n",
      "Epoch 14 | Step 5505 | loss: 0.2423156352251544 | accuracy: 0.904546522556391 \n",
      "Epoch 14 | Step 5506 | loss: 0.24209157801634362 | accuracy: 0.9046699438202247 \n",
      "Epoch 14 | Step 5507 | loss: 0.24265532960086617 | accuracy: 0.9045009328358209 \n",
      "Epoch 14 | Step 5508 | loss: 0.24255079283036263 | accuracy: 0.9045074349442379 \n",
      "Epoch 14 | Step 5509 | loss: 0.2426090198258559 | accuracy: 0.9043981481481481 \n",
      "Epoch 14 | Step 5510 | loss: 0.2424217370988258 | accuracy: 0.9044049815498155 \n",
      "Epoch 14 | Step 5511 | loss: 0.2423152711845058 | accuracy: 0.9044117647058824 \n",
      "Epoch 14 | Step 5512 | loss: 0.24222633087045545 | accuracy: 0.9044757326007326 \n",
      "Epoch 14 | Step 5513 | loss: 0.24221668552852024 | accuracy: 0.9044251824817519 \n",
      "Epoch 14 | Step 5514 | loss: 0.24247266609560358 | accuracy: 0.9042613636363637 \n",
      "Epoch 14 | Step 5515 | loss: 0.2426410299334405 | accuracy: 0.9041553442028986 \n",
      "Epoch 14 | Step 5516 | loss: 0.24275884056457114 | accuracy: 0.9041629061371841 \n",
      "Epoch 14 | Step 5517 | loss: 0.24242434095886115 | accuracy: 0.904226618705036 \n",
      "Epoch 14 | Step 5518 | loss: 0.24283998208554414 | accuracy: 0.9041778673835126 \n",
      "Epoch 14 | Step 5519 | loss: 0.24253964139414685 | accuracy: 0.904296875 \n",
      "Epoch 14 | Step 5520 | loss: 0.24243937106637345 | accuracy: 0.9044150355871886 \n",
      "Epoch 14 | Step 5521 | loss: 0.24233720596906141 | accuracy: 0.9044215425531915 \n",
      "Epoch 14 | Step 5522 | loss: 0.24228556767474635 | accuracy: 0.9044832155477032 \n",
      "Epoch 14 | Step 5523 | loss: 0.24210069834871192 | accuracy: 0.9045994718309859 \n",
      "Epoch 14 | Step 5524 | loss: 0.2420474446917835 | accuracy: 0.9046052631578947 \n",
      "Epoch 14 | Step 5525 | loss: 0.2417087433273559 | accuracy: 0.9047202797202797 \n",
      "Epoch 14 | Step 5526 | loss: 0.2416505026744633 | accuracy: 0.9047256097560976 \n",
      "Epoch 14 | Step 5527 | loss: 0.2411556468707406 | accuracy: 0.9049479166666666 \n",
      "Epoch 14 | Step 5528 | loss: 0.24114301705339788 | accuracy: 0.9050064878892734 \n",
      "Epoch 14 | Step 5529 | loss: 0.24129640457445178 | accuracy: 0.9049568965517242 \n",
      "Epoch 14 | Step 5530 | loss: 0.24155500098499647 | accuracy: 0.9049076460481099 \n",
      "Epoch 14 | Step 5531 | loss: 0.241439420857454 | accuracy: 0.904912243150685 \n",
      "Epoch 14 | Step 5532 | loss: 0.24173331848081875 | accuracy: 0.9046501706484642 \n",
      "Epoch 14 | Step 5533 | loss: 0.24146262112827527 | accuracy: 0.9048150510204082 \n",
      "Epoch 14 | Step 5534 | loss: 0.24124212191771652 | accuracy: 0.9049258474576272 \n",
      "Epoch 14 | Step 5535 | loss: 0.24150443960585305 | accuracy: 0.9048775337837838 \n",
      "Epoch 14 | Step 5536 | loss: 0.24129320849172195 | accuracy: 0.9049873737373737 \n",
      "Epoch 14 | Step 5537 | loss: 0.2415356399278913 | accuracy: 0.9048343120805369 \n",
      "Epoch 14 | Step 5538 | loss: 0.24127187076519963 | accuracy: 0.9050480769230769 \n",
      "Epoch 14 | Step 5539 | loss: 0.24100448595980803 | accuracy: 0.9051041666666667 \n",
      "Epoch 14 | Step 5540 | loss: 0.240925720091476 | accuracy: 0.9050041528239202 \n",
      "Epoch 14 | Step 5541 | loss: 0.24069952888303245 | accuracy: 0.9051117549668874 \n",
      "Epoch 14 | Step 5542 | loss: 0.24061038015600872 | accuracy: 0.9050639438943895 \n",
      "Epoch 14 | Step 5543 | loss: 0.24065558639305987 | accuracy: 0.905016447368421 \n",
      "Epoch 14 | Step 5544 | loss: 0.24035792529094416 | accuracy: 0.9051741803278689 \n",
      "Epoch 14 | Step 5545 | loss: 0.24040993037664032 | accuracy: 0.9051776960784313 \n",
      "Epoch 14 | Step 5546 | loss: 0.2405922275267129 | accuracy: 0.9051302931596091 \n",
      "Epoch 14 | Step 5547 | loss: 0.24039711365355299 | accuracy: 0.9052353896103896 \n",
      "Epoch 14 | Step 5548 | loss: 0.2402184506016256 | accuracy: 0.9052386731391586 \n",
      "Epoch 14 | Step 5549 | loss: 0.24035850741690204 | accuracy: 0.9050907258064517 \n",
      "Epoch 14 | Step 5550 | loss: 0.24036986083750556 | accuracy: 0.905144694533762 \n",
      "Epoch 14 | Step 5551 | loss: 0.24022571668506432 | accuracy: 0.9052984775641025 \n",
      "Epoch 14 | Step 5552 | loss: 0.2402375825344564 | accuracy: 0.9053514376996805 \n",
      "Epoch 14 | Step 5553 | loss: 0.2406584018022771 | accuracy: 0.9052547770700637 \n",
      "Epoch 14 | Step 5554 | loss: 0.2412526681546181 | accuracy: 0.9050595238095238 \n",
      "Epoch 14 | Step 5555 | loss: 0.24132634805444675 | accuracy: 0.9049643987341772 \n",
      "Epoch 14 | Step 5556 | loss: 0.24091517673775978 | accuracy: 0.9051656151419558 \n",
      "Epoch 14 | Step 5557 | loss: 0.24094794899131516 | accuracy: 0.9051690251572327 \n",
      "Epoch 14 | Step 5558 | loss: 0.24110135756035958 | accuracy: 0.9051724137931034 \n",
      "Epoch 14 | Step 5559 | loss: 0.24099264761898667 | accuracy: 0.9052734375 \n",
      "Epoch 14 | Step 5560 | loss: 0.2409084199512859 | accuracy: 0.9053251557632399 \n",
      "Epoch 14 | Step 5561 | loss: 0.24151013391265957 | accuracy: 0.9052309782608695 \n",
      "Epoch 14 | Step 5562 | loss: 0.24130007479305238 | accuracy: 0.9053792569659442 \n",
      "Epoch 14 | Step 5563 | loss: 0.24116762421657273 | accuracy: 0.9054783950617284 \n",
      "Epoch 14 | Step 5564 | loss: 0.2413494171316807 | accuracy: 0.9054326923076923 \n",
      "Epoch 14 | Step 5565 | loss: 0.24136291099198026 | accuracy: 0.9054351993865031 \n",
      "Epoch 14 | Step 5566 | loss: 0.24140679574249715 | accuracy: 0.905342125382263 \n",
      "Epoch 14 | Step 5567 | loss: 0.24146265238977788 | accuracy: 0.905344893292683 \n",
      "Epoch 14 | Step 5568 | loss: 0.2416690219544712 | accuracy: 0.9051576747720365 \n",
      "Epoch 14 | Step 5569 | loss: 0.241613181815906 | accuracy: 0.9052083333333333 \n",
      "Epoch 14 | Step 5570 | loss: 0.24165569657735594 | accuracy: 0.9050226586102719 \n",
      "Epoch 14 | Step 5571 | loss: 0.2416644202971674 | accuracy: 0.9050734186746988 \n",
      "Epoch 14 | Step 5572 | loss: 0.2416306487746067 | accuracy: 0.9051238738738738 \n",
      "Epoch 14 | Step 5573 | loss: 0.2417006106032226 | accuracy: 0.9050804640718563 \n",
      "Epoch 14 | Step 5574 | loss: 0.24156574844869216 | accuracy: 0.9051772388059701 \n",
      "Epoch 14 | Step 5575 | loss: 0.24145252663376077 | accuracy: 0.9052734375 \n",
      "Epoch 14 | Step 5576 | loss: 0.24133749980512642 | accuracy: 0.9053227002967359 \n",
      "Epoch 14 | Step 5577 | loss: 0.24150677102469129 | accuracy: 0.9053254437869822 \n",
      "Epoch 14 | Step 5578 | loss: 0.241235381404383 | accuracy: 0.9054664454277286 \n",
      "Epoch 14 | Step 5579 | loss: 0.2410845967119231 | accuracy: 0.9056066176470589 \n",
      "Epoch 14 | Step 5580 | loss: 0.24122905698427358 | accuracy: 0.9055626832844574 \n",
      "Epoch 14 | Step 5581 | loss: 0.24104275957447047 | accuracy: 0.905656067251462 \n",
      "Epoch 14 | Step 5582 | loss: 0.24094965248083583 | accuracy: 0.9057489067055393 \n",
      "Epoch 14 | Step 5583 | loss: 0.24081792489647172 | accuracy: 0.905750363372093 \n",
      "Epoch 14 | Step 5584 | loss: 0.24108196529357329 | accuracy: 0.9057065217391305 \n",
      "Epoch 14 | Step 5585 | loss: 0.24103339453566971 | accuracy: 0.9057532514450867 \n",
      "Epoch 14 | Step 5586 | loss: 0.24071483535192886 | accuracy: 0.9059347982708934 \n",
      "Epoch 14 | Step 5587 | loss: 0.24116778487189747 | accuracy: 0.9057112068965517 \n",
      "Epoch 14 | Step 5588 | loss: 0.24099926977154176 | accuracy: 0.9058022922636103 \n",
      "Epoch 14 | Step 5589 | loss: 0.24087149588125092 | accuracy: 0.9058928571428572 \n",
      "Epoch 14 | Step 5590 | loss: 0.24066486574730642 | accuracy: 0.9060274216524217 \n",
      "Epoch 14 | Step 5591 | loss: 0.24071251035837288 | accuracy: 0.9060724431818182 \n",
      "Epoch 14 | Step 5592 | loss: 0.24084374732825978 | accuracy: 0.9060729461756374 \n",
      "Epoch 14 | Step 5593 | loss: 0.24066243019733724 | accuracy: 0.9060734463276836 \n",
      "Epoch 14 | Step 5594 | loss: 0.2407349288253717 | accuracy: 0.9060299295774648 \n",
      "Epoch 14 | Step 5595 | loss: 0.2405196392511049 | accuracy: 0.9060744382022472 \n",
      "Epoch 14 | Step 5596 | loss: 0.24042761578362862 | accuracy: 0.9060749299719888 \n",
      "Epoch 14 | Step 5597 | loss: 0.24050776462731416 | accuracy: 0.9059444832402235 \n",
      "Epoch 14 | Step 5598 | loss: 0.24034555818792172 | accuracy: 0.9060323816155988 \n",
      "Epoch 14 | Step 5599 | loss: 0.24042458503196637 | accuracy: 0.9061197916666667 \n",
      "Epoch 14 | Step 5600 | loss: 0.24028717730596785 | accuracy: 0.9061201523545707 \n",
      "Epoch 14 | Step 5601 | loss: 0.24049901849080846 | accuracy: 0.9059910220994475 \n",
      "Epoch 14 | Step 5602 | loss: 0.24054188088362538 | accuracy: 0.90599173553719 \n",
      "Epoch 14 | Step 5603 | loss: 0.2404713873638884 | accuracy: 0.9060782967032966 \n",
      "Epoch 14 | Step 5604 | loss: 0.24048312557478474 | accuracy: 0.9059931506849315 \n",
      "Epoch 14 | Step 5605 | loss: 0.24042191912160546 | accuracy: 0.9059511612021858 \n",
      "Epoch 14 | Step 5606 | loss: 0.24015052310046447 | accuracy: 0.9060797002724795 \n",
      "Epoch 14 | Step 5607 | loss: 0.24042537174714002 | accuracy: 0.9060801630434783 \n",
      "Epoch 14 | Step 5608 | loss: 0.2404277183539499 | accuracy: 0.9061229674796748 \n",
      "Epoch 14 | Step 5609 | loss: 0.2408143433566029 | accuracy: 0.9059966216216216 \n",
      "Epoch 14 | Step 5610 | loss: 0.24107232836459203 | accuracy: 0.9059130727762803 \n",
      "Epoch 14 | Step 5611 | loss: 0.24127794091179167 | accuracy: 0.9057459677419355 \n",
      "Epoch 14 | Step 5612 | loss: 0.24141762525482408 | accuracy: 0.9056635388739946 \n",
      "Epoch 14 | Step 5613 | loss: 0.2415318481305385 | accuracy: 0.9055815508021391 \n",
      "Epoch 14 | Step 5614 | loss: 0.24125396106640498 | accuracy: 0.9056666666666666 \n",
      "Epoch 14 | Step 5615 | loss: 0.2410593657615654 | accuracy: 0.905751329787234 \n",
      "Epoch 14 | Step 5616 | loss: 0.2407981710068743 | accuracy: 0.9058355437665783 \n",
      "Epoch 14 | Step 5617 | loss: 0.24117534629330434 | accuracy: 0.9056712962962963 \n",
      "Epoch 14 | Step 5618 | loss: 0.2412503906832836 | accuracy: 0.9055903693931399 \n",
      "Epoch 14 | Step 5619 | loss: 0.24101416058838368 | accuracy: 0.9056743421052632 \n",
      "Epoch 14 | Step 5620 | loss: 0.24099941494974877 | accuracy: 0.9057168635170604 \n",
      "Epoch 14 | Step 5621 | loss: 0.24077102953460827 | accuracy: 0.9058409685863874 \n",
      "Epoch 14 | Step 5622 | loss: 0.240677584380923 | accuracy: 0.9058420365535248 \n",
      "Epoch 14 | Step 5623 | loss: 0.24081498724020398 | accuracy: 0.9057210286458334 \n",
      "Epoch 14 | Step 5624 | loss: 0.24089593629945408 | accuracy: 0.9057224025974026 \n",
      "Epoch 14 | Step 5625 | loss: 0.24094491886274186 | accuracy: 0.9057642487046632 \n",
      "Epoch 14 | Step 5626 | loss: 0.24100549936833615 | accuracy: 0.905765503875969 \n",
      "Epoch 14 | Step 5627 | loss: 0.24113748581676753 | accuracy: 0.9056862113402062 \n",
      "Epoch 14 | Step 5628 | loss: 0.2411326907172914 | accuracy: 0.9056474935732648 \n",
      "Epoch 14 | Step 5629 | loss: 0.24119410898823004 | accuracy: 0.9055689102564103 \n",
      "Epoch 14 | Step 5630 | loss: 0.2412741310189447 | accuracy: 0.9056106138107417 \n",
      "Epoch 14 | Step 5631 | loss: 0.24114207495764203 | accuracy: 0.9057318239795918 \n",
      "Epoch 14 | Step 5632 | loss: 0.241172231392551 | accuracy: 0.9058126590330788 \n",
      "Epoch 14 | Step 5633 | loss: 0.2412446839971288 | accuracy: 0.9057741116751269 \n",
      "Epoch 14 | Step 5634 | loss: 0.2412002490479735 | accuracy: 0.9058939873417722 \n",
      "Epoch 14 | Step 5635 | loss: 0.24109523463053534 | accuracy: 0.9059343434343434 \n",
      "Epoch 14 | Step 5636 | loss: 0.2408017738339883 | accuracy: 0.9060138539042821 \n",
      "Epoch 14 | Step 5637 | loss: 0.24087702569051003 | accuracy: 0.9059359296482412 \n",
      "Epoch 14 | Step 5638 | loss: 0.24088660696694128 | accuracy: 0.9058975563909775 \n",
      "Epoch 14 | Step 5639 | loss: 0.2410274211317301 | accuracy: 0.9058203125 \n",
      "Epoch 14 | Step 5640 | loss: 0.24090319634078447 | accuracy: 0.9058993142144638 \n",
      "Epoch 14 | Step 5641 | loss: 0.24137598150108583 | accuracy: 0.9056669776119403 \n",
      "Epoch 14 | Step 5642 | loss: 0.2411307860027176 | accuracy: 0.9058154893868022 \n",
      "Validation | Epoch 14 | Step 5642 | accuracy: 0.8496788536960428 \n",
      "Epoch 15 | Step 5643 | loss: 0.18134063482284546 | accuracy: 0.953125 \n",
      "Epoch 15 | Step 5644 | loss: 0.24624237418174744 | accuracy: 0.90625 \n",
      "Epoch 15 | Step 5645 | loss: 0.21789846320947012 | accuracy: 0.9166666666666666 \n",
      "Epoch 15 | Step 5646 | loss: 0.23482845351099968 | accuracy: 0.9140625 \n",
      "Epoch 15 | Step 5647 | loss: 0.23424502909183503 | accuracy: 0.9125 \n",
      "Epoch 15 | Step 5648 | loss: 0.24158375213543573 | accuracy: 0.9088541666666666 \n",
      "Epoch 15 | Step 5649 | loss: 0.25217909259455545 | accuracy: 0.9017857142857143 \n",
      "Epoch 15 | Step 5650 | loss: 0.2604194451123476 | accuracy: 0.8984375 \n",
      "Epoch 15 | Step 5651 | loss: 0.25309572617212933 | accuracy: 0.8958333333333334 \n",
      "Epoch 15 | Step 5652 | loss: 0.2587584227323532 | accuracy: 0.8953125 \n",
      "Epoch 15 | Step 5653 | loss: 0.2565246034752239 | accuracy: 0.8934659090909091 \n",
      "Epoch 15 | Step 5654 | loss: 0.2569297179579735 | accuracy: 0.8932291666666666 \n",
      "Epoch 15 | Step 5655 | loss: 0.2519865230872081 | accuracy: 0.8954326923076923 \n",
      "Epoch 15 | Step 5656 | loss: 0.25022667965718676 | accuracy: 0.8950892857142857 \n",
      "Epoch 15 | Step 5657 | loss: 0.24150213897228237 | accuracy: 0.9 \n",
      "Epoch 15 | Step 5658 | loss: 0.23798657953739163 | accuracy: 0.9033203125 \n",
      "Epoch 15 | Step 5659 | loss: 0.23907986458610087 | accuracy: 0.9053308823529411 \n",
      "Epoch 15 | Step 5660 | loss: 0.23732928021086586 | accuracy: 0.9045138888888888 \n",
      "Epoch 15 | Step 5661 | loss: 0.23822044149825447 | accuracy: 0.9046052631578947 \n",
      "Epoch 15 | Step 5662 | loss: 0.23714009672403336 | accuracy: 0.90390625 \n",
      "Epoch 15 | Step 5663 | loss: 0.2333608241308303 | accuracy: 0.9055059523809523 \n",
      "Epoch 15 | Step 5664 | loss: 0.23219316520474173 | accuracy: 0.9041193181818182 \n",
      "Epoch 15 | Step 5665 | loss: 0.2324370081010072 | accuracy: 0.9014945652173914 \n",
      "Epoch 15 | Step 5666 | loss: 0.22773562899480262 | accuracy: 0.9036458333333334 \n",
      "Epoch 15 | Step 5667 | loss: 0.2265973088145256 | accuracy: 0.904375 \n",
      "Epoch 15 | Step 5668 | loss: 0.22623435035347939 | accuracy: 0.9032451923076923 \n",
      "Epoch 15 | Step 5669 | loss: 0.2275553403629197 | accuracy: 0.9033564814814815 \n",
      "Epoch 15 | Step 5670 | loss: 0.2250121201255492 | accuracy: 0.9051339285714286 \n",
      "Epoch 15 | Step 5671 | loss: 0.2220905939566678 | accuracy: 0.90625 \n",
      "Epoch 15 | Step 5672 | loss: 0.22379160250226657 | accuracy: 0.9046875 \n",
      "Epoch 15 | Step 5673 | loss: 0.22297848016023636 | accuracy: 0.9057459677419355 \n",
      "Epoch 15 | Step 5674 | loss: 0.22392151481471956 | accuracy: 0.90576171875 \n",
      "Epoch 15 | Step 5675 | loss: 0.2258860900095015 | accuracy: 0.9053030303030303 \n",
      "Epoch 15 | Step 5676 | loss: 0.22408661355867104 | accuracy: 0.9057904411764706 \n",
      "Epoch 15 | Step 5677 | loss: 0.2218282910329955 | accuracy: 0.9066964285714286 \n",
      "Epoch 15 | Step 5678 | loss: 0.2227586182869143 | accuracy: 0.90625 \n",
      "Epoch 15 | Step 5679 | loss: 0.22198633185109576 | accuracy: 0.9058277027027027 \n",
      "Epoch 15 | Step 5680 | loss: 0.2226176067794624 | accuracy: 0.9054276315789473 \n",
      "Epoch 15 | Step 5681 | loss: 0.22309789271690908 | accuracy: 0.9046474358974359 \n",
      "Epoch 15 | Step 5682 | loss: 0.22275402192026378 | accuracy: 0.905078125 \n",
      "Epoch 15 | Step 5683 | loss: 0.22162122424782776 | accuracy: 0.9051067073170732 \n",
      "Epoch 15 | Step 5684 | loss: 0.22507740433017412 | accuracy: 0.9047619047619048 \n",
      "Epoch 15 | Step 5685 | loss: 0.22416806342296822 | accuracy: 0.904796511627907 \n",
      "Epoch 15 | Step 5686 | loss: 0.22345523282208227 | accuracy: 0.9041193181818182 \n",
      "Epoch 15 | Step 5687 | loss: 0.22692151218652726 | accuracy: 0.9024305555555555 \n",
      "Epoch 15 | Step 5688 | loss: 0.22786024099458818 | accuracy: 0.9028532608695652 \n",
      "Epoch 15 | Step 5689 | loss: 0.22711913810765488 | accuracy: 0.9029255319148937 \n",
      "Epoch 15 | Step 5690 | loss: 0.22927881265059114 | accuracy: 0.9026692708333334 \n",
      "Epoch 15 | Step 5691 | loss: 0.22792612183458952 | accuracy: 0.9033801020408163 \n",
      "Epoch 15 | Step 5692 | loss: 0.22972807720303534 | accuracy: 0.903125 \n",
      "Epoch 15 | Step 5693 | loss: 0.2332120907365107 | accuracy: 0.9022671568627451 \n",
      "Epoch 15 | Step 5694 | loss: 0.23365273856772825 | accuracy: 0.9017427884615384 \n",
      "Epoch 15 | Step 5695 | loss: 0.23224052604076997 | accuracy: 0.902122641509434 \n",
      "Epoch 15 | Step 5696 | loss: 0.2312036514006279 | accuracy: 0.9024884259259259 \n",
      "Epoch 15 | Step 5697 | loss: 0.23151174092834645 | accuracy: 0.9022727272727272 \n",
      "Epoch 15 | Step 5698 | loss: 0.23242176018123115 | accuracy: 0.90234375 \n",
      "Epoch 15 | Step 5699 | loss: 0.23223114654160382 | accuracy: 0.9029605263157895 \n",
      "Epoch 15 | Step 5700 | loss: 0.23261941005957537 | accuracy: 0.9030172413793104 \n",
      "Epoch 15 | Step 5701 | loss: 0.23359635686975413 | accuracy: 0.903072033898305 \n",
      "Epoch 15 | Step 5702 | loss: 0.23497875245908897 | accuracy: 0.903125 \n",
      "Epoch 15 | Step 5703 | loss: 0.2355050123373016 | accuracy: 0.9024077868852459 \n",
      "Epoch 15 | Step 5704 | loss: 0.23474865034222603 | accuracy: 0.9024697580645161 \n",
      "Epoch 15 | Step 5705 | loss: 0.2348620765029438 | accuracy: 0.9025297619047619 \n",
      "Epoch 15 | Step 5706 | loss: 0.2329325684113428 | accuracy: 0.90380859375 \n",
      "Epoch 15 | Step 5707 | loss: 0.2330963005240147 | accuracy: 0.9036057692307692 \n",
      "Epoch 15 | Step 5708 | loss: 0.23146641581799043 | accuracy: 0.9043560606060606 \n",
      "Epoch 15 | Step 5709 | loss: 0.23101716599802471 | accuracy: 0.9046175373134329 \n",
      "Epoch 15 | Step 5710 | loss: 0.23076463172979214 | accuracy: 0.9051011029411765 \n",
      "Epoch 15 | Step 5711 | loss: 0.23246322064727976 | accuracy: 0.9044384057971014 \n",
      "Epoch 15 | Step 5712 | loss: 0.23332226648926735 | accuracy: 0.9037946428571428 \n",
      "Epoch 15 | Step 5713 | loss: 0.2327265946168295 | accuracy: 0.9044894366197183 \n",
      "Epoch 15 | Step 5714 | loss: 0.23191889033963284 | accuracy: 0.9051649305555556 \n",
      "Epoch 15 | Step 5715 | loss: 0.2317148082672733 | accuracy: 0.9056078767123288 \n",
      "Epoch 15 | Step 5716 | loss: 0.23249668557498906 | accuracy: 0.9047719594594594 \n",
      "Epoch 15 | Step 5717 | loss: 0.23338013559579848 | accuracy: 0.904375 \n",
      "Epoch 15 | Step 5718 | loss: 0.23255622357522188 | accuracy: 0.9046052631578947 \n",
      "Epoch 15 | Step 5719 | loss: 0.23232457496516115 | accuracy: 0.9050324675324676 \n",
      "Epoch 15 | Step 5720 | loss: 0.2336618780898742 | accuracy: 0.9044471153846154 \n",
      "Epoch 15 | Step 5721 | loss: 0.2326513293989097 | accuracy: 0.9052610759493671 \n",
      "Epoch 15 | Step 5722 | loss: 0.23274737102910875 | accuracy: 0.9052734375 \n",
      "Epoch 15 | Step 5723 | loss: 0.23267219436389427 | accuracy: 0.9054783950617284 \n",
      "Epoch 15 | Step 5724 | loss: 0.2317023528966962 | accuracy: 0.9058689024390244 \n",
      "Epoch 15 | Step 5725 | loss: 0.23199813094842864 | accuracy: 0.9060617469879518 \n",
      "Epoch 15 | Step 5726 | loss: 0.2323155322422584 | accuracy: 0.90625 \n",
      "Epoch 15 | Step 5727 | loss: 0.23307009979205973 | accuracy: 0.9060661764705882 \n",
      "Epoch 15 | Step 5728 | loss: 0.23230255195914312 | accuracy: 0.9069767441860465 \n",
      "Epoch 15 | Step 5729 | loss: 0.23230241744340152 | accuracy: 0.9067887931034483 \n",
      "Epoch 15 | Step 5730 | loss: 0.23293607046997006 | accuracy: 0.9071377840909091 \n",
      "Epoch 15 | Step 5731 | loss: 0.23247972540975956 | accuracy: 0.9074789325842697 \n",
      "Epoch 15 | Step 5732 | loss: 0.23366325340337224 | accuracy: 0.9071180555555556 \n",
      "Epoch 15 | Step 5733 | loss: 0.23276048792260035 | accuracy: 0.9074519230769231 \n",
      "Epoch 15 | Step 5734 | loss: 0.23473449853127418 | accuracy: 0.9069293478260869 \n",
      "Epoch 15 | Step 5735 | loss: 0.2348490335768269 | accuracy: 0.9067540322580645 \n",
      "Epoch 15 | Step 5736 | loss: 0.2342069259190813 | accuracy: 0.906748670212766 \n",
      "Epoch 15 | Step 5737 | loss: 0.23286400766749132 | accuracy: 0.9075657894736842 \n",
      "Epoch 15 | Step 5738 | loss: 0.23243188159540296 | accuracy: 0.9075520833333334 \n",
      "Epoch 15 | Step 5739 | loss: 0.23194394391222098 | accuracy: 0.907860824742268 \n",
      "Epoch 15 | Step 5740 | loss: 0.23409090343178535 | accuracy: 0.9070471938775511 \n",
      "Epoch 15 | Step 5741 | loss: 0.23328554871106388 | accuracy: 0.907354797979798 \n",
      "Epoch 15 | Step 5742 | loss: 0.23305766955018042 | accuracy: 0.906875 \n",
      "Epoch 15 | Step 5743 | loss: 0.23275020630052773 | accuracy: 0.9068688118811881 \n",
      "Epoch 15 | Step 5744 | loss: 0.23254887642813662 | accuracy: 0.9068627450980392 \n",
      "Epoch 15 | Step 5745 | loss: 0.23266665738763162 | accuracy: 0.9068567961165048 \n",
      "Epoch 15 | Step 5746 | loss: 0.2328007550766835 | accuracy: 0.9068509615384616 \n",
      "Epoch 15 | Step 5747 | loss: 0.2329433642682575 | accuracy: 0.9066964285714286 \n",
      "Epoch 15 | Step 5748 | loss: 0.23205602492363947 | accuracy: 0.9071344339622641 \n",
      "Epoch 15 | Step 5749 | loss: 0.2335450099171879 | accuracy: 0.9065420560747663 \n",
      "Epoch 15 | Step 5750 | loss: 0.2343958559687491 | accuracy: 0.9063946759259259 \n",
      "Epoch 15 | Step 5751 | loss: 0.23355720554469922 | accuracy: 0.9068233944954128 \n",
      "Epoch 15 | Step 5752 | loss: 0.2335354284806685 | accuracy: 0.9066761363636363 \n",
      "Epoch 15 | Step 5753 | loss: 0.23411916666202717 | accuracy: 0.9065315315315315 \n",
      "Epoch 15 | Step 5754 | loss: 0.2352742398423808 | accuracy: 0.90625 \n",
      "Epoch 15 | Step 5755 | loss: 0.2363324252377569 | accuracy: 0.9059734513274337 \n",
      "Epoch 15 | Step 5756 | loss: 0.23616287791938112 | accuracy: 0.9061129385964912 \n",
      "Epoch 15 | Step 5757 | loss: 0.23532566376354383 | accuracy: 0.9063858695652174 \n",
      "Epoch 15 | Step 5758 | loss: 0.23565282980943547 | accuracy: 0.90625 \n",
      "Epoch 15 | Step 5759 | loss: 0.2358175694433033 | accuracy: 0.90625 \n",
      "Epoch 15 | Step 5760 | loss: 0.23592344141107494 | accuracy: 0.9061175847457628 \n",
      "Epoch 15 | Step 5761 | loss: 0.236363262814634 | accuracy: 0.9057247899159664 \n",
      "Epoch 15 | Step 5762 | loss: 0.23648434989154338 | accuracy: 0.905859375 \n",
      "Epoch 15 | Step 5763 | loss: 0.23582082432656248 | accuracy: 0.906120867768595 \n",
      "Epoch 15 | Step 5764 | loss: 0.23546200233404754 | accuracy: 0.90625 \n",
      "Epoch 15 | Step 5765 | loss: 0.2353986500482249 | accuracy: 0.90625 \n",
      "Epoch 15 | Step 5766 | loss: 0.23548357044496843 | accuracy: 0.9065020161290323 \n",
      "Epoch 15 | Step 5767 | loss: 0.23529976391792298 | accuracy: 0.906625 \n",
      "Epoch 15 | Step 5768 | loss: 0.23527676470222927 | accuracy: 0.9067460317460317 \n",
      "Epoch 15 | Step 5769 | loss: 0.23655243382209867 | accuracy: 0.906373031496063 \n",
      "Epoch 15 | Step 5770 | loss: 0.23626930080354214 | accuracy: 0.9066162109375 \n",
      "Epoch 15 | Step 5771 | loss: 0.2355616589387258 | accuracy: 0.9068556201550387 \n",
      "Epoch 15 | Step 5772 | loss: 0.23599195732520176 | accuracy: 0.9067307692307692 \n",
      "Epoch 15 | Step 5773 | loss: 0.23599594808716812 | accuracy: 0.9069656488549618 \n",
      "Epoch 15 | Step 5774 | loss: 0.23553623688040357 | accuracy: 0.9070785984848485 \n",
      "Epoch 15 | Step 5775 | loss: 0.23507510573792278 | accuracy: 0.9074248120300752 \n",
      "Epoch 15 | Step 5776 | loss: 0.23482540227583984 | accuracy: 0.9074160447761194 \n",
      "Epoch 15 | Step 5777 | loss: 0.2353234781159295 | accuracy: 0.9072916666666667 \n",
      "Epoch 15 | Step 5778 | loss: 0.23552007732145927 | accuracy: 0.9075137867647058 \n",
      "Epoch 15 | Step 5779 | loss: 0.23535582303565783 | accuracy: 0.9076186131386861 \n",
      "Epoch 15 | Step 5780 | loss: 0.23501676105070804 | accuracy: 0.9074954710144928 \n",
      "Epoch 15 | Step 5781 | loss: 0.23537942960107927 | accuracy: 0.9070368705035972 \n",
      "Epoch 15 | Step 5782 | loss: 0.23497123367020062 | accuracy: 0.9073660714285714 \n",
      "Epoch 15 | Step 5783 | loss: 0.23497278481087785 | accuracy: 0.9072473404255319 \n",
      "Epoch 15 | Step 5784 | loss: 0.2346947967586383 | accuracy: 0.9074603873239436 \n",
      "Epoch 15 | Step 5785 | loss: 0.23455498508223288 | accuracy: 0.9076704545454546 \n",
      "Epoch 15 | Step 5786 | loss: 0.23385989769465393 | accuracy: 0.9079861111111112 \n",
      "Epoch 15 | Step 5787 | loss: 0.23379565004644723 | accuracy: 0.9080818965517241 \n",
      "Epoch 15 | Step 5788 | loss: 0.23482732985117663 | accuracy: 0.9077482876712328 \n",
      "Epoch 15 | Step 5789 | loss: 0.2344371368284939 | accuracy: 0.9080569727891157 \n",
      "Epoch 15 | Step 5790 | loss: 0.2340688014755378 | accuracy: 0.9082559121621622 \n",
      "Epoch 15 | Step 5791 | loss: 0.23382165437976785 | accuracy: 0.9084521812080537 \n",
      "Epoch 15 | Step 5792 | loss: 0.23351223816474279 | accuracy: 0.9086458333333334 \n",
      "Epoch 15 | Step 5793 | loss: 0.2334356243839327 | accuracy: 0.9086299668874173 \n",
      "Epoch 15 | Step 5794 | loss: 0.23365305844498307 | accuracy: 0.9087171052631579 \n",
      "Epoch 15 | Step 5795 | loss: 0.23348890157306895 | accuracy: 0.9088031045751634 \n",
      "Epoch 15 | Step 5796 | loss: 0.23355101503722078 | accuracy: 0.908786525974026 \n",
      "Epoch 15 | Step 5797 | loss: 0.2331258257550578 | accuracy: 0.9088709677419354 \n",
      "Epoch 15 | Step 5798 | loss: 0.23255892097949982 | accuracy: 0.9092548076923077 \n",
      "Epoch 15 | Step 5799 | loss: 0.2319347565151324 | accuracy: 0.9095342356687898 \n",
      "Epoch 15 | Step 5800 | loss: 0.23183137489647804 | accuracy: 0.909315664556962 \n",
      "Epoch 15 | Step 5801 | loss: 0.2316303258796908 | accuracy: 0.9093946540880503 \n",
      "Epoch 15 | Step 5802 | loss: 0.2316579269245267 | accuracy: 0.909375 \n",
      "Epoch 15 | Step 5803 | loss: 0.23136671313217708 | accuracy: 0.9094526397515528 \n",
      "Epoch 15 | Step 5804 | loss: 0.23211013121001514 | accuracy: 0.9093364197530864 \n",
      "Epoch 15 | Step 5805 | loss: 0.23150038070108261 | accuracy: 0.9096050613496932 \n",
      "Epoch 15 | Step 5806 | loss: 0.23113579593780564 | accuracy: 0.9099657012195121 \n",
      "Epoch 15 | Step 5807 | loss: 0.23111750456419858 | accuracy: 0.9100378787878788 \n",
      "Epoch 15 | Step 5808 | loss: 0.23209181885762387 | accuracy: 0.9096385542168675 \n",
      "Epoch 15 | Step 5809 | loss: 0.23158271744579612 | accuracy: 0.9098053892215568 \n",
      "Epoch 15 | Step 5810 | loss: 0.23123875535314992 | accuracy: 0.9097842261904762 \n",
      "Epoch 15 | Step 5811 | loss: 0.2321803230329378 | accuracy: 0.9093934911242604 \n",
      "Epoch 15 | Step 5812 | loss: 0.23176286071538926 | accuracy: 0.9095588235294118 \n",
      "Epoch 15 | Step 5813 | loss: 0.23217331291290752 | accuracy: 0.9093567251461988 \n",
      "Epoch 15 | Step 5814 | loss: 0.23255697681113732 | accuracy: 0.9093386627906976 \n",
      "Epoch 15 | Step 5815 | loss: 0.23169186866352323 | accuracy: 0.9096820809248555 \n",
      "Epoch 15 | Step 5816 | loss: 0.23186578712929254 | accuracy: 0.9095725574712644 \n",
      "Epoch 15 | Step 5817 | loss: 0.2312176878963198 | accuracy: 0.9099107142857142 \n",
      "Epoch 15 | Step 5818 | loss: 0.23114182469858366 | accuracy: 0.9099786931818182 \n",
      "Epoch 15 | Step 5819 | loss: 0.23145367356680208 | accuracy: 0.909957627118644 \n",
      "Epoch 15 | Step 5820 | loss: 0.231272974292214 | accuracy: 0.9100245786516854 \n",
      "Epoch 15 | Step 5821 | loss: 0.23141131179625762 | accuracy: 0.9098289106145251 \n",
      "Epoch 15 | Step 5822 | loss: 0.23192833885550498 | accuracy: 0.909375 \n",
      "Epoch 15 | Step 5823 | loss: 0.2317448487268627 | accuracy: 0.9094440607734806 \n",
      "Epoch 15 | Step 5824 | loss: 0.2313778810612448 | accuracy: 0.9096840659340659 \n",
      "Epoch 15 | Step 5825 | loss: 0.2313844110470652 | accuracy: 0.9097506830601093 \n",
      "Epoch 15 | Step 5826 | loss: 0.2313292359366365 | accuracy: 0.9097316576086957 \n",
      "Epoch 15 | Step 5827 | loss: 0.23135798734587593 | accuracy: 0.9097972972972973 \n",
      "Epoch 15 | Step 5828 | loss: 0.2309962224255326 | accuracy: 0.9098622311827957 \n",
      "Epoch 15 | Step 5829 | loss: 0.23128365848791152 | accuracy: 0.9097593582887701 \n",
      "Epoch 15 | Step 5830 | loss: 0.23129248365442803 | accuracy: 0.9097406914893617 \n",
      "Epoch 15 | Step 5831 | loss: 0.23085049165304375 | accuracy: 0.9099702380952381 \n",
      "Epoch 15 | Step 5832 | loss: 0.23066557614426864 | accuracy: 0.9101151315789474 \n",
      "Epoch 15 | Step 5833 | loss: 0.2307673054527862 | accuracy: 0.9100948952879581 \n",
      "Epoch 15 | Step 5834 | loss: 0.2306677392528703 | accuracy: 0.91015625 \n",
      "Epoch 15 | Step 5835 | loss: 0.23042380639926138 | accuracy: 0.9103788860103627 \n",
      "Epoch 15 | Step 5836 | loss: 0.23033120967063708 | accuracy: 0.9104381443298969 \n",
      "Epoch 15 | Step 5837 | loss: 0.23052143897765723 | accuracy: 0.9104967948717949 \n",
      "Epoch 15 | Step 5838 | loss: 0.23035507307064776 | accuracy: 0.9104751275510204 \n",
      "Epoch 15 | Step 5839 | loss: 0.2304048302209922 | accuracy: 0.9103743654822335 \n",
      "Epoch 15 | Step 5840 | loss: 0.23026687508881694 | accuracy: 0.9104324494949495 \n",
      "Epoch 15 | Step 5841 | loss: 0.23050760563893533 | accuracy: 0.910411432160804 \n",
      "Epoch 15 | Step 5842 | loss: 0.23040836736559867 | accuracy: 0.91046875 \n",
      "Epoch 15 | Step 5843 | loss: 0.23053426988682343 | accuracy: 0.9103700248756219 \n",
      "Epoch 15 | Step 5844 | loss: 0.23070824397082376 | accuracy: 0.9102722772277227 \n",
      "Epoch 15 | Step 5845 | loss: 0.2307976413096113 | accuracy: 0.9102524630541872 \n",
      "Epoch 15 | Step 5846 | loss: 0.2308770003272038 | accuracy: 0.9102328431372549 \n",
      "Epoch 15 | Step 5847 | loss: 0.23094597422495122 | accuracy: 0.9102896341463415 \n",
      "Epoch 15 | Step 5848 | loss: 0.23101308471658855 | accuracy: 0.9101183252427184 \n",
      "Epoch 15 | Step 5849 | loss: 0.23071215809255408 | accuracy: 0.9100996376811594 \n",
      "Epoch 15 | Step 5850 | loss: 0.23039078404410526 | accuracy: 0.9103064903846154 \n",
      "Epoch 15 | Step 5851 | loss: 0.23044934711958232 | accuracy: 0.9102123205741627 \n",
      "Epoch 15 | Step 5852 | loss: 0.22995891514278594 | accuracy: 0.9104166666666667 \n",
      "Epoch 15 | Step 5853 | loss: 0.22992469243246233 | accuracy: 0.9106190758293838 \n",
      "Epoch 15 | Step 5854 | loss: 0.22989796095018117 | accuracy: 0.9105984669811321 \n",
      "Epoch 15 | Step 5855 | loss: 0.2294532255807393 | accuracy: 0.9107981220657277 \n",
      "Epoch 15 | Step 5856 | loss: 0.22939667446869555 | accuracy: 0.9109959112149533 \n",
      "Epoch 15 | Step 5857 | loss: 0.2294935913279999 | accuracy: 0.9109011627906977 \n",
      "Epoch 15 | Step 5858 | loss: 0.22980023803258384 | accuracy: 0.9107349537037037 \n",
      "Epoch 15 | Step 5859 | loss: 0.23018656780917524 | accuracy: 0.9106422811059908 \n",
      "Epoch 15 | Step 5860 | loss: 0.23019874779456254 | accuracy: 0.9106221330275229 \n",
      "Epoch 15 | Step 5861 | loss: 0.2300643442564359 | accuracy: 0.9106735159817352 \n",
      "Epoch 15 | Step 5862 | loss: 0.22992176562547684 | accuracy: 0.9107244318181819 \n",
      "Epoch 15 | Step 5863 | loss: 0.2298326145739577 | accuracy: 0.910774886877828 \n",
      "Epoch 15 | Step 5864 | loss: 0.22959185176872993 | accuracy: 0.9108952702702703 \n",
      "Epoch 15 | Step 5865 | loss: 0.22939215500258545 | accuracy: 0.9109445067264574 \n",
      "Epoch 15 | Step 5866 | loss: 0.22934643970802426 | accuracy: 0.9109933035714286 \n",
      "Epoch 15 | Step 5867 | loss: 0.2294917744398117 | accuracy: 0.9108333333333334 \n",
      "Epoch 15 | Step 5868 | loss: 0.22932996079985019 | accuracy: 0.9108130530973452 \n",
      "Epoch 15 | Step 5869 | loss: 0.22937562155828603 | accuracy: 0.9107929515418502 \n",
      "Epoch 15 | Step 5870 | loss: 0.229194440274385 | accuracy: 0.9107730263157895 \n",
      "Epoch 15 | Step 5871 | loss: 0.2291359934614215 | accuracy: 0.9107532751091703 \n",
      "Epoch 15 | Step 5872 | loss: 0.22919289132823115 | accuracy: 0.9106657608695652 \n",
      "Epoch 15 | Step 5873 | loss: 0.22915281781128474 | accuracy: 0.9105790043290043 \n",
      "Epoch 15 | Step 5874 | loss: 0.228834166737466 | accuracy: 0.9106950431034483 \n",
      "Epoch 15 | Step 5875 | loss: 0.22852197992955153 | accuracy: 0.9109442060085837 \n",
      "Epoch 15 | Step 5876 | loss: 0.22888232321820706 | accuracy: 0.9108573717948718 \n",
      "Epoch 15 | Step 5877 | loss: 0.2284887343645096 | accuracy: 0.9111037234042553 \n",
      "Epoch 15 | Step 5878 | loss: 0.22830832692778716 | accuracy: 0.911083156779661 \n",
      "Epoch 15 | Step 5879 | loss: 0.22821986291730453 | accuracy: 0.9110627637130801 \n",
      "Epoch 15 | Step 5880 | loss: 0.2286861196410756 | accuracy: 0.9109768907563025 \n",
      "Epoch 15 | Step 5881 | loss: 0.22855700515054758 | accuracy: 0.9109571129707112 \n",
      "Epoch 15 | Step 5882 | loss: 0.22853226934870083 | accuracy: 0.9108072916666666 \n",
      "Epoch 15 | Step 5883 | loss: 0.22888621292173617 | accuracy: 0.9105290456431535 \n",
      "Epoch 15 | Step 5884 | loss: 0.2290526850164429 | accuracy: 0.9103822314049587 \n",
      "Epoch 15 | Step 5885 | loss: 0.2287509145192158 | accuracy: 0.9106867283950617 \n",
      "Epoch 15 | Step 5886 | loss: 0.22832314346413143 | accuracy: 0.9108606557377049 \n",
      "Epoch 15 | Step 5887 | loss: 0.22822317444548315 | accuracy: 0.910905612244898 \n",
      "Epoch 15 | Step 5888 | loss: 0.22794693235943958 | accuracy: 0.9108866869918699 \n",
      "Epoch 15 | Step 5889 | loss: 0.22767136647151068 | accuracy: 0.9110576923076923 \n",
      "Epoch 15 | Step 5890 | loss: 0.22771406215765783 | accuracy: 0.9109122983870968 \n",
      "Epoch 15 | Step 5891 | loss: 0.22785882077303277 | accuracy: 0.9107053212851406 \n",
      "Epoch 15 | Step 5892 | loss: 0.2275838459134102 | accuracy: 0.9108125 \n",
      "Epoch 15 | Step 5893 | loss: 0.22768314052150543 | accuracy: 0.9107943227091634 \n",
      "Epoch 15 | Step 5894 | loss: 0.228149849330149 | accuracy: 0.9105902777777778 \n",
      "Epoch 15 | Step 5895 | loss: 0.22810981643529749 | accuracy: 0.9105731225296443 \n",
      "Epoch 15 | Step 5896 | loss: 0.22789760086480088 | accuracy: 0.9105561023622047 \n",
      "Epoch 15 | Step 5897 | loss: 0.2276685321447896 | accuracy: 0.9106617647058823 \n",
      "Epoch 15 | Step 5898 | loss: 0.22773176722694188 | accuracy: 0.91070556640625 \n",
      "Epoch 15 | Step 5899 | loss: 0.22780332473697365 | accuracy: 0.9106882295719845 \n",
      "Epoch 15 | Step 5900 | loss: 0.22766986350680507 | accuracy: 0.9107921511627907 \n",
      "Epoch 15 | Step 5901 | loss: 0.22778622765798826 | accuracy: 0.9107746138996139 \n",
      "Epoch 15 | Step 5902 | loss: 0.22781319291545796 | accuracy: 0.9108173076923077 \n",
      "Epoch 15 | Step 5903 | loss: 0.22796202214056505 | accuracy: 0.9106800766283525 \n",
      "Epoch 15 | Step 5904 | loss: 0.22847678535084687 | accuracy: 0.9104842557251909 \n",
      "Epoch 15 | Step 5905 | loss: 0.2287378897571745 | accuracy: 0.9104087452471483 \n",
      "Epoch 15 | Step 5906 | loss: 0.22895299818253878 | accuracy: 0.9103338068181818 \n",
      "Epoch 15 | Step 5907 | loss: 0.2290874683069733 | accuracy: 0.9103183962264151 \n",
      "Epoch 15 | Step 5908 | loss: 0.22924902805484326 | accuracy: 0.9101268796992481 \n",
      "Epoch 15 | Step 5909 | loss: 0.22906960848342167 | accuracy: 0.9102294007490637 \n",
      "Epoch 15 | Step 5910 | loss: 0.22982629038282296 | accuracy: 0.909981343283582 \n",
      "Epoch 15 | Step 5911 | loss: 0.22963180262803146 | accuracy: 0.9100836431226765 \n",
      "Epoch 15 | Step 5912 | loss: 0.22973385133125163 | accuracy: 0.9100694444444445 \n",
      "Epoch 15 | Step 5913 | loss: 0.22958607020413305 | accuracy: 0.9100553505535055 \n",
      "Epoch 15 | Step 5914 | loss: 0.22948912196957014 | accuracy: 0.9100988051470589 \n",
      "Epoch 15 | Step 5915 | loss: 0.22943023895169354 | accuracy: 0.9101419413919414 \n",
      "Epoch 15 | Step 5916 | loss: 0.2294392045179423 | accuracy: 0.9100707116788321 \n",
      "Epoch 15 | Step 5917 | loss: 0.22966952562332155 | accuracy: 0.91 \n",
      "Epoch 15 | Step 5918 | loss: 0.2297669960104901 | accuracy: 0.9099864130434783 \n",
      "Epoch 15 | Step 5919 | loss: 0.2299624311364515 | accuracy: 0.9099729241877257 \n",
      "Epoch 15 | Step 5920 | loss: 0.22959816675606393 | accuracy: 0.9101281474820145 \n",
      "Epoch 15 | Step 5921 | loss: 0.22997238329448152 | accuracy: 0.9100582437275987 \n",
      "Epoch 15 | Step 5922 | loss: 0.229701217263937 | accuracy: 0.9101562500000001 \n",
      "Epoch 15 | Step 5923 | loss: 0.2295478844875967 | accuracy: 0.9104203736654806 \n",
      "Epoch 15 | Step 5924 | loss: 0.22944203267494837 | accuracy: 0.910405585106383 \n",
      "Epoch 15 | Step 5925 | loss: 0.2294289833033464 | accuracy: 0.910446113074205 \n",
      "Epoch 15 | Step 5926 | loss: 0.22924259189568774 | accuracy: 0.9105413732394366 \n",
      "Epoch 15 | Step 5927 | loss: 0.22915425467909428 | accuracy: 0.9105811403508772 \n",
      "Epoch 15 | Step 5928 | loss: 0.22887469182064482 | accuracy: 0.9107298951048951 \n",
      "Epoch 15 | Step 5929 | loss: 0.2288185739143385 | accuracy: 0.9107687282229965 \n",
      "Epoch 15 | Step 5930 | loss: 0.22834352887649503 | accuracy: 0.9110243055555556 \n",
      "Epoch 15 | Step 5931 | loss: 0.22844499140771615 | accuracy: 0.9111159169550173 \n",
      "Epoch 15 | Step 5932 | loss: 0.22862769516891446 | accuracy: 0.9110452586206896 \n",
      "Epoch 15 | Step 5933 | loss: 0.22895111197356097 | accuracy: 0.9108676975945017 \n",
      "Epoch 15 | Step 5934 | loss: 0.22881149416406676 | accuracy: 0.9108518835616438 \n",
      "Epoch 15 | Step 5935 | loss: 0.2289888979581029 | accuracy: 0.9106761945392492 \n",
      "Epoch 15 | Step 5936 | loss: 0.22873698253514005 | accuracy: 0.9108205782312925 \n",
      "Epoch 15 | Step 5937 | loss: 0.22859769329681234 | accuracy: 0.9109110169491526 \n",
      "Epoch 15 | Step 5938 | loss: 0.2287473928032292 | accuracy: 0.9108424831081081 \n",
      "Epoch 15 | Step 5939 | loss: 0.22847479162894516 | accuracy: 0.9109848484848485 \n",
      "Epoch 15 | Step 5940 | loss: 0.22879953174883086 | accuracy: 0.9109165268456376 \n",
      "Epoch 15 | Step 5941 | loss: 0.22852968100620352 | accuracy: 0.9111099498327759 \n",
      "Epoch 15 | Step 5942 | loss: 0.2281883861372868 | accuracy: 0.9111979166666667 \n",
      "Epoch 15 | Step 5943 | loss: 0.22813506704133216 | accuracy: 0.9111295681063123 \n",
      "Epoch 15 | Step 5944 | loss: 0.2278459542091714 | accuracy: 0.9112686258278145 \n",
      "Epoch 15 | Step 5945 | loss: 0.22780040459762704 | accuracy: 0.9112520627062707 \n",
      "Epoch 15 | Step 5946 | loss: 0.22776040422583096 | accuracy: 0.9112356085526315 \n",
      "Epoch 15 | Step 5947 | loss: 0.2275177374482155 | accuracy: 0.9113729508196722 \n",
      "Epoch 15 | Step 5948 | loss: 0.22760886881573528 | accuracy: 0.9113051470588235 \n",
      "Epoch 15 | Step 5949 | loss: 0.2278487850526645 | accuracy: 0.9113395765472313 \n",
      "Epoch 15 | Step 5950 | loss: 0.22764682307742634 | accuracy: 0.911424512987013 \n",
      "Epoch 15 | Step 5951 | loss: 0.22742690514881633 | accuracy: 0.9114583333333334 \n",
      "Epoch 15 | Step 5952 | loss: 0.22760927569000952 | accuracy: 0.911391129032258 \n",
      "Epoch 15 | Step 5953 | loss: 0.22767539899736355 | accuracy: 0.9114248392282959 \n",
      "Epoch 15 | Step 5954 | loss: 0.2275883483533294 | accuracy: 0.9115584935897436 \n",
      "Epoch 15 | Step 5955 | loss: 0.22761275990607258 | accuracy: 0.9115914536741214 \n",
      "Epoch 15 | Step 5956 | loss: 0.22810197054485606 | accuracy: 0.9115246815286624 \n",
      "Epoch 15 | Step 5957 | loss: 0.2286950055332411 | accuracy: 0.9113095238095238 \n",
      "Epoch 15 | Step 5958 | loss: 0.22872454953627497 | accuracy: 0.9112935126582279 \n",
      "Epoch 15 | Step 5959 | loss: 0.22833823335095535 | accuracy: 0.9115240536277602 \n",
      "Epoch 15 | Step 5960 | loss: 0.22837307261970807 | accuracy: 0.9115566037735849 \n",
      "Epoch 15 | Step 5961 | loss: 0.22854438928601137 | accuracy: 0.911490987460815 \n",
      "Epoch 15 | Step 5962 | loss: 0.2284418278373778 | accuracy: 0.9115234375 \n",
      "Epoch 15 | Step 5963 | loss: 0.22835821683904464 | accuracy: 0.9116043613707165 \n",
      "Epoch 15 | Step 5964 | loss: 0.22894471328451027 | accuracy: 0.9115392080745341 \n",
      "Epoch 15 | Step 5965 | loss: 0.22867089062467816 | accuracy: 0.9116679566563467 \n",
      "Epoch 15 | Step 5966 | loss: 0.2285192887540217 | accuracy: 0.9117959104938271 \n",
      "Epoch 15 | Step 5967 | loss: 0.22879959638302144 | accuracy: 0.9117307692307692 \n",
      "Epoch 15 | Step 5968 | loss: 0.22886856028273062 | accuracy: 0.9117139570552147 \n",
      "Epoch 15 | Step 5969 | loss: 0.2289299326023195 | accuracy: 0.9116016819571865 \n",
      "Epoch 15 | Step 5970 | loss: 0.2289290186926359 | accuracy: 0.9115853658536586 \n",
      "Epoch 15 | Step 5971 | loss: 0.22910728819645648 | accuracy: 0.9114266717325228 \n",
      "Epoch 15 | Step 5972 | loss: 0.22903349887241017 | accuracy: 0.9113636363636364 \n",
      "Epoch 15 | Step 5973 | loss: 0.2290779876204776 | accuracy: 0.9112537764350453 \n",
      "Epoch 15 | Step 5974 | loss: 0.22907748279801335 | accuracy: 0.9114269578313253 \n",
      "Epoch 15 | Step 5975 | loss: 0.22910345186879327 | accuracy: 0.9114583333333334 \n",
      "Epoch 15 | Step 5976 | loss: 0.22929818968394558 | accuracy: 0.9113959580838323 \n",
      "Epoch 15 | Step 5977 | loss: 0.22911862428508586 | accuracy: 0.911473880597015 \n",
      "Epoch 15 | Step 5978 | loss: 0.2290528378937216 | accuracy: 0.9115048363095238 \n",
      "Epoch 15 | Step 5979 | loss: 0.22888968982222527 | accuracy: 0.9115356083086054 \n",
      "Epoch 15 | Step 5980 | loss: 0.22913988741368232 | accuracy: 0.9115661982248521 \n",
      "Epoch 15 | Step 5981 | loss: 0.2288832688226109 | accuracy: 0.9116426991150443 \n",
      "Epoch 15 | Step 5982 | loss: 0.2287147873903022 | accuracy: 0.9117647058823529 \n",
      "Epoch 15 | Step 5983 | loss: 0.22887417424983642 | accuracy: 0.9117027126099707 \n",
      "Epoch 15 | Step 5984 | loss: 0.22865431363645353 | accuracy: 0.9117781432748538 \n",
      "Epoch 15 | Step 5985 | loss: 0.22858641407406366 | accuracy: 0.9118531341107872 \n",
      "Epoch 15 | Step 5986 | loss: 0.22848070451859817 | accuracy: 0.9117460029069767 \n",
      "Epoch 15 | Step 5987 | loss: 0.22873535324697908 | accuracy: 0.9117300724637681 \n",
      "Epoch 15 | Step 5988 | loss: 0.22866513373362535 | accuracy: 0.9118045520231214 \n",
      "Epoch 15 | Step 5989 | loss: 0.22836788252038984 | accuracy: 0.9119686599423631 \n",
      "Epoch 15 | Step 5990 | loss: 0.22877482050794296 | accuracy: 0.9117277298850575 \n",
      "Epoch 15 | Step 5991 | loss: 0.22861265956843138 | accuracy: 0.9118015759312321 \n",
      "Epoch 15 | Step 5992 | loss: 0.22843412650482994 | accuracy: 0.911875 \n",
      "Epoch 15 | Step 5993 | loss: 0.22820224568375155 | accuracy: 0.9119925213675214 \n",
      "Epoch 15 | Step 5994 | loss: 0.2282782941209999 | accuracy: 0.9120205965909091 \n",
      "Epoch 15 | Step 5995 | loss: 0.2283944445358795 | accuracy: 0.9120042492917847 \n",
      "Epoch 15 | Step 5996 | loss: 0.22819813589255014 | accuracy: 0.9120321327683616 \n",
      "Epoch 15 | Step 5997 | loss: 0.2282733696447292 | accuracy: 0.9119718309859155 \n",
      "Epoch 15 | Step 5998 | loss: 0.22806434936068032 | accuracy: 0.9119996488764045 \n",
      "Epoch 15 | Step 5999 | loss: 0.2279958109311363 | accuracy: 0.9120273109243697 \n",
      "Epoch 15 | Step 6000 | loss: 0.22804280924064488 | accuracy: 0.9118802374301676 \n",
      "Epoch 15 | Step 6001 | loss: 0.22792590399140436 | accuracy: 0.911908077994429 \n",
      "Epoch 15 | Step 6002 | loss: 0.22792139889465438 | accuracy: 0.9119791666666667 \n",
      "Epoch 15 | Step 6003 | loss: 0.2278055561051144 | accuracy: 0.911963296398892 \n",
      "Epoch 15 | Step 6004 | loss: 0.22798926650819198 | accuracy: 0.9120338397790055 \n",
      "Epoch 15 | Step 6005 | loss: 0.22802090382116227 | accuracy: 0.9120609504132231 \n",
      "Epoch 15 | Step 6006 | loss: 0.22790784351937063 | accuracy: 0.9121308379120879 \n",
      "Epoch 15 | Step 6007 | loss: 0.2278450609886483 | accuracy: 0.9120719178082192 \n",
      "Epoch 15 | Step 6008 | loss: 0.2277599920014866 | accuracy: 0.9120560109289617 \n",
      "Epoch 15 | Step 6009 | loss: 0.22743529440677784 | accuracy: 0.9122104904632152 \n",
      "Epoch 15 | Step 6010 | loss: 0.22769168207583868 | accuracy: 0.9121942934782609 \n",
      "Epoch 15 | Step 6011 | loss: 0.22768551363612255 | accuracy: 0.9122628726287263 \n",
      "Epoch 15 | Step 6012 | loss: 0.22803731095549223 | accuracy: 0.9121621621621622 \n",
      "Epoch 15 | Step 6013 | loss: 0.22834540323186114 | accuracy: 0.9120619946091644 \n",
      "Epoch 15 | Step 6014 | loss: 0.22852568891179817 | accuracy: 0.9119623655913979 \n",
      "Epoch 15 | Step 6015 | loss: 0.22869206931012565 | accuracy: 0.9118632707774799 \n",
      "Epoch 15 | Step 6016 | loss: 0.22883786430413072 | accuracy: 0.9118064839572193 \n",
      "Epoch 15 | Step 6017 | loss: 0.22855915486812592 | accuracy: 0.911875 \n",
      "Epoch 15 | Step 6018 | loss: 0.22844886997754268 | accuracy: 0.9118184840425532 \n",
      "Epoch 15 | Step 6019 | loss: 0.22818638708452332 | accuracy: 0.9119280503978779 \n",
      "Epoch 15 | Step 6020 | loss: 0.22857777352528597 | accuracy: 0.9117476851851852 \n",
      "Epoch 15 | Step 6021 | loss: 0.2286724641250746 | accuracy: 0.9116919525065963 \n",
      "Epoch 15 | Step 6022 | loss: 0.22842853735936317 | accuracy: 0.9118009868421053 \n",
      "Epoch 15 | Step 6023 | loss: 0.22837266517592852 | accuracy: 0.91186843832021 \n",
      "Epoch 15 | Step 6024 | loss: 0.2281836250611625 | accuracy: 0.911976439790576 \n",
      "Epoch 15 | Step 6025 | loss: 0.2280585400507282 | accuracy: 0.9120022845953003 \n",
      "Epoch 15 | Step 6026 | loss: 0.22816563269589096 | accuracy: 0.9119466145833334 \n",
      "Epoch 15 | Step 6027 | loss: 0.22821806545381423 | accuracy: 0.9119318181818182 \n",
      "Epoch 15 | Step 6028 | loss: 0.22824481569732408 | accuracy: 0.9119980569948186 \n",
      "Epoch 15 | Step 6029 | loss: 0.2283300403938737 | accuracy: 0.911983204134367 \n",
      "Epoch 15 | Step 6030 | loss: 0.22836316691845962 | accuracy: 0.9119684278350515 \n",
      "Epoch 15 | Step 6031 | loss: 0.22838993405008684 | accuracy: 0.9119938946015425 \n",
      "Epoch 15 | Step 6032 | loss: 0.22844145099322002 | accuracy: 0.9119391025641026 \n",
      "Epoch 15 | Step 6033 | loss: 0.22850382472852918 | accuracy: 0.9119245524296675 \n",
      "Epoch 15 | Step 6034 | loss: 0.22837299633086944 | accuracy: 0.9119499362244898 \n",
      "Epoch 15 | Step 6035 | loss: 0.2283516969465421 | accuracy: 0.9120149491094147 \n",
      "Epoch 15 | Step 6036 | loss: 0.22840255453501862 | accuracy: 0.9120399746192893 \n",
      "Epoch 15 | Step 6037 | loss: 0.22836104733279988 | accuracy: 0.9121044303797469 \n",
      "Epoch 15 | Step 6038 | loss: 0.22817127858147476 | accuracy: 0.9122474747474747 \n",
      "Epoch 15 | Step 6039 | loss: 0.22791319218480616 | accuracy: 0.9123110831234257 \n",
      "Epoch 15 | Step 6040 | loss: 0.22801156532974098 | accuracy: 0.9121388190954773 \n",
      "Epoch 15 | Step 6041 | loss: 0.22806961513252785 | accuracy: 0.9120848997493735 \n",
      "Epoch 15 | Step 6042 | loss: 0.22828843351453543 | accuracy: 0.91203125 \n",
      "Epoch 15 | Step 6043 | loss: 0.22813026402656575 | accuracy: 0.9121337281795511 \n",
      "Epoch 15 | Step 6044 | loss: 0.22856200808909402 | accuracy: 0.9119247512437811 \n",
      "Epoch 15 | Step 6045 | loss: 0.22833397522309873 | accuracy: 0.9120577350443705 \n",
      "Validation | Epoch 15 | Step 6045 | accuracy: 0.8526587201790377 \n",
      "Epoch 16 | Step 6046 | loss: 0.1708499938249588 | accuracy: 0.953125 \n",
      "Epoch 16 | Step 6047 | loss: 0.2540782764554024 | accuracy: 0.8984375 \n",
      "Epoch 16 | Step 6048 | loss: 0.2185200254122416 | accuracy: 0.9270833333333334 \n",
      "Epoch 16 | Step 6049 | loss: 0.23807089030742645 | accuracy: 0.92578125 \n",
      "Epoch 16 | Step 6050 | loss: 0.2337618201971054 | accuracy: 0.925 \n",
      "Epoch 16 | Step 6051 | loss: 0.2412961944937706 | accuracy: 0.9140625 \n",
      "Epoch 16 | Step 6052 | loss: 0.24865400152547018 | accuracy: 0.9107142857142857 \n",
      "Epoch 16 | Step 6053 | loss: 0.2532963287085295 | accuracy: 0.90625 \n",
      "Epoch 16 | Step 6054 | loss: 0.2432127296924591 | accuracy: 0.90625 \n",
      "Epoch 16 | Step 6055 | loss: 0.24629770815372468 | accuracy: 0.9015625 \n",
      "Epoch 16 | Step 6056 | loss: 0.24257401580160315 | accuracy: 0.9019886363636364 \n",
      "Epoch 16 | Step 6057 | loss: 0.246519656231006 | accuracy: 0.9010416666666666 \n",
      "Epoch 16 | Step 6058 | loss: 0.243526517198636 | accuracy: 0.9038461538461539 \n",
      "Epoch 16 | Step 6059 | loss: 0.24213629961013794 | accuracy: 0.9040178571428571 \n",
      "Epoch 16 | Step 6060 | loss: 0.23274902999401093 | accuracy: 0.9072916666666667 \n",
      "Epoch 16 | Step 6061 | loss: 0.22923529613763094 | accuracy: 0.91015625 \n",
      "Epoch 16 | Step 6062 | loss: 0.2310931112836389 | accuracy: 0.9108455882352942 \n",
      "Epoch 16 | Step 6063 | loss: 0.22942019502321878 | accuracy: 0.9097222222222222 \n",
      "Epoch 16 | Step 6064 | loss: 0.23112660332729942 | accuracy: 0.9103618421052632 \n",
      "Epoch 16 | Step 6065 | loss: 0.22887220680713655 | accuracy: 0.91015625 \n",
      "Epoch 16 | Step 6066 | loss: 0.2254169491075334 | accuracy: 0.9114583333333334 \n",
      "Epoch 16 | Step 6067 | loss: 0.22325395995920355 | accuracy: 0.9112215909090909 \n",
      "Epoch 16 | Step 6068 | loss: 0.22302286974761798 | accuracy: 0.9103260869565217 \n",
      "Epoch 16 | Step 6069 | loss: 0.21854326408356428 | accuracy: 0.912109375 \n",
      "Epoch 16 | Step 6070 | loss: 0.21710450500249862 | accuracy: 0.9125 \n",
      "Epoch 16 | Step 6071 | loss: 0.21622314562018102 | accuracy: 0.9128605769230769 \n",
      "Epoch 16 | Step 6072 | loss: 0.2175663839335795 | accuracy: 0.9126157407407407 \n",
      "Epoch 16 | Step 6073 | loss: 0.21502541351531232 | accuracy: 0.9140625 \n",
      "Epoch 16 | Step 6074 | loss: 0.2129992649986826 | accuracy: 0.9148706896551724 \n",
      "Epoch 16 | Step 6075 | loss: 0.21464356010158855 | accuracy: 0.9135416666666667 \n",
      "Epoch 16 | Step 6076 | loss: 0.21367067074583423 | accuracy: 0.9143145161290323 \n",
      "Epoch 16 | Step 6077 | loss: 0.2146454679314047 | accuracy: 0.9140625 \n",
      "Epoch 16 | Step 6078 | loss: 0.21643288591594406 | accuracy: 0.9138257575757576 \n",
      "Epoch 16 | Step 6079 | loss: 0.21460234746336937 | accuracy: 0.9149816176470589 \n",
      "Epoch 16 | Step 6080 | loss: 0.21164654514619283 | accuracy: 0.9165178571428572 \n",
      "Epoch 16 | Step 6081 | loss: 0.21200995167924297 | accuracy: 0.9162326388888888 \n",
      "Epoch 16 | Step 6082 | loss: 0.21074579797081044 | accuracy: 0.9155405405405406 \n",
      "Epoch 16 | Step 6083 | loss: 0.2111767677492217 | accuracy: 0.915296052631579 \n",
      "Epoch 16 | Step 6084 | loss: 0.2112089340121318 | accuracy: 0.9150641025641025 \n",
      "Epoch 16 | Step 6085 | loss: 0.21096866969019173 | accuracy: 0.915625 \n",
      "Epoch 16 | Step 6086 | loss: 0.20982701440409915 | accuracy: 0.9157774390243902 \n",
      "Epoch 16 | Step 6087 | loss: 0.212567122032245 | accuracy: 0.9151785714285714 \n",
      "Epoch 16 | Step 6088 | loss: 0.21245324039875074 | accuracy: 0.9142441860465116 \n",
      "Epoch 16 | Step 6089 | loss: 0.21164697594940662 | accuracy: 0.9137073863636364 \n",
      "Epoch 16 | Step 6090 | loss: 0.21475413160191642 | accuracy: 0.9118055555555555 \n",
      "Epoch 16 | Step 6091 | loss: 0.21515359486574712 | accuracy: 0.9116847826086957 \n",
      "Epoch 16 | Step 6092 | loss: 0.21435966596324393 | accuracy: 0.9122340425531915 \n",
      "Epoch 16 | Step 6093 | loss: 0.2161303226215144 | accuracy: 0.912109375 \n",
      "Epoch 16 | Step 6094 | loss: 0.21495195691074645 | accuracy: 0.9132653061224489 \n",
      "Epoch 16 | Step 6095 | loss: 0.21630017176270486 | accuracy: 0.913125 \n",
      "Epoch 16 | Step 6096 | loss: 0.21981070161450142 | accuracy: 0.9123774509803921 \n",
      "Epoch 16 | Step 6097 | loss: 0.22009380462651068 | accuracy: 0.9125600961538461 \n",
      "Epoch 16 | Step 6098 | loss: 0.21851782908417144 | accuracy: 0.9130306603773585 \n",
      "Epoch 16 | Step 6099 | loss: 0.21807092193652083 | accuracy: 0.9126157407407407 \n",
      "Epoch 16 | Step 6100 | loss: 0.21895489516583355 | accuracy: 0.9119318181818182 \n",
      "Epoch 16 | Step 6101 | loss: 0.2198161497446043 | accuracy: 0.912109375 \n",
      "Epoch 16 | Step 6102 | loss: 0.2196174142392058 | accuracy: 0.912828947368421 \n",
      "Epoch 16 | Step 6103 | loss: 0.2201221750984932 | accuracy: 0.9129849137931034 \n",
      "Epoch 16 | Step 6104 | loss: 0.22110154176667585 | accuracy: 0.9126059322033898 \n",
      "Epoch 16 | Step 6105 | loss: 0.22276111555596192 | accuracy: 0.9127604166666666 \n",
      "Epoch 16 | Step 6106 | loss: 0.22285564329291954 | accuracy: 0.9126536885245902 \n",
      "Epoch 16 | Step 6107 | loss: 0.22210010754004603 | accuracy: 0.9125504032258065 \n",
      "Epoch 16 | Step 6108 | loss: 0.222079179234921 | accuracy: 0.9124503968253969 \n",
      "Epoch 16 | Step 6109 | loss: 0.22007577889598906 | accuracy: 0.91357421875 \n",
      "Epoch 16 | Step 6110 | loss: 0.22048741258107699 | accuracy: 0.9132211538461539 \n",
      "Epoch 16 | Step 6111 | loss: 0.21863558786836537 | accuracy: 0.9142992424242424 \n",
      "Epoch 16 | Step 6112 | loss: 0.21780532609615752 | accuracy: 0.9146455223880597 \n",
      "Epoch 16 | Step 6113 | loss: 0.21770445991526632 | accuracy: 0.9152113970588235 \n",
      "Epoch 16 | Step 6114 | loss: 0.21952882139147192 | accuracy: 0.9148550724637681 \n",
      "Epoch 16 | Step 6115 | loss: 0.22027986337031638 | accuracy: 0.9145089285714286 \n",
      "Epoch 16 | Step 6116 | loss: 0.21998190155751268 | accuracy: 0.9148327464788732 \n",
      "Epoch 16 | Step 6117 | loss: 0.2191419523830215 | accuracy: 0.9153645833333334 \n",
      "Epoch 16 | Step 6118 | loss: 0.2192604787749787 | accuracy: 0.915667808219178 \n",
      "Epoch 16 | Step 6119 | loss: 0.21997569350374713 | accuracy: 0.9146959459459459 \n",
      "Epoch 16 | Step 6120 | loss: 0.22127418686946232 | accuracy: 0.9139583333333333 \n",
      "Epoch 16 | Step 6121 | loss: 0.2202609607851819 | accuracy: 0.9142680921052632 \n",
      "Epoch 16 | Step 6122 | loss: 0.21995320751682504 | accuracy: 0.9143668831168831 \n",
      "Epoch 16 | Step 6123 | loss: 0.2215850405777112 | accuracy: 0.9136618589743589 \n",
      "Epoch 16 | Step 6124 | loss: 0.22063578467203093 | accuracy: 0.9143591772151899 \n",
      "Epoch 16 | Step 6125 | loss: 0.2208335523493588 | accuracy: 0.914453125 \n",
      "Epoch 16 | Step 6126 | loss: 0.22059579993839618 | accuracy: 0.9147376543209876 \n",
      "Epoch 16 | Step 6127 | loss: 0.21952055203841953 | accuracy: 0.915015243902439 \n",
      "Epoch 16 | Step 6128 | loss: 0.21976811761956616 | accuracy: 0.9150978915662651 \n",
      "Epoch 16 | Step 6129 | loss: 0.22024325378948734 | accuracy: 0.9151785714285714 \n",
      "Epoch 16 | Step 6130 | loss: 0.2212830959874041 | accuracy: 0.9150735294117647 \n",
      "Epoch 16 | Step 6131 | loss: 0.22062420507156572 | accuracy: 0.9158793604651163 \n",
      "Epoch 16 | Step 6132 | loss: 0.22062409446499814 | accuracy: 0.9157686781609196 \n",
      "Epoch 16 | Step 6133 | loss: 0.22152990077368237 | accuracy: 0.916015625 \n",
      "Epoch 16 | Step 6134 | loss: 0.22123969580685154 | accuracy: 0.9164325842696629 \n",
      "Epoch 16 | Step 6135 | loss: 0.2223687424427933 | accuracy: 0.9161458333333333 \n",
      "Epoch 16 | Step 6136 | loss: 0.22164284585268942 | accuracy: 0.9163804945054945 \n",
      "Epoch 16 | Step 6137 | loss: 0.22360410079683946 | accuracy: 0.9159307065217391 \n",
      "Epoch 16 | Step 6138 | loss: 0.22375930324997953 | accuracy: 0.9158266129032258 \n",
      "Epoch 16 | Step 6139 | loss: 0.2231235829915138 | accuracy: 0.9158909574468085 \n",
      "Epoch 16 | Step 6140 | loss: 0.2217906183318088 | accuracy: 0.9166118421052631 \n",
      "Epoch 16 | Step 6141 | loss: 0.22130997541050115 | accuracy: 0.91650390625 \n",
      "Epoch 16 | Step 6142 | loss: 0.22071935881658927 | accuracy: 0.916881443298969 \n",
      "Epoch 16 | Step 6143 | loss: 0.22268507964148812 | accuracy: 0.9161352040816326 \n",
      "Epoch 16 | Step 6144 | loss: 0.221911879801991 | accuracy: 0.91635101010101 \n",
      "Epoch 16 | Step 6145 | loss: 0.2217044249176979 | accuracy: 0.91609375 \n",
      "Epoch 16 | Step 6146 | loss: 0.22133791033584294 | accuracy: 0.9159962871287128 \n",
      "Epoch 16 | Step 6147 | loss: 0.22127541651328406 | accuracy: 0.9162071078431373 \n",
      "Epoch 16 | Step 6148 | loss: 0.22138887383405445 | accuracy: 0.9161104368932039 \n",
      "Epoch 16 | Step 6149 | loss: 0.22151653225032183 | accuracy: 0.916015625 \n",
      "Epoch 16 | Step 6150 | loss: 0.22181133925914764 | accuracy: 0.9157738095238095 \n",
      "Epoch 16 | Step 6151 | loss: 0.22090431218439677 | accuracy: 0.9162735849056604 \n",
      "Epoch 16 | Step 6152 | loss: 0.22227915271977397 | accuracy: 0.9155957943925234 \n",
      "Epoch 16 | Step 6153 | loss: 0.2230493761599064 | accuracy: 0.9155092592592593 \n",
      "Epoch 16 | Step 6154 | loss: 0.2222652853628911 | accuracy: 0.9157110091743119 \n",
      "Epoch 16 | Step 6155 | loss: 0.22213106602430344 | accuracy: 0.9154829545454546 \n",
      "Epoch 16 | Step 6156 | loss: 0.222724606996184 | accuracy: 0.915259009009009 \n",
      "Epoch 16 | Step 6157 | loss: 0.22388208963509118 | accuracy: 0.9147600446428571 \n",
      "Epoch 16 | Step 6158 | loss: 0.22470622318508351 | accuracy: 0.9145464601769911 \n",
      "Epoch 16 | Step 6159 | loss: 0.22460006281994938 | accuracy: 0.9143366228070176 \n",
      "Epoch 16 | Step 6160 | loss: 0.22372380592252897 | accuracy: 0.9145380434782608 \n",
      "Epoch 16 | Step 6161 | loss: 0.2237400291166429 | accuracy: 0.9143318965517241 \n",
      "Epoch 16 | Step 6162 | loss: 0.22376089568576243 | accuracy: 0.9143963675213675 \n",
      "Epoch 16 | Step 6163 | loss: 0.22398486600841505 | accuracy: 0.9141949152542372 \n",
      "Epoch 16 | Step 6164 | loss: 0.2245071855287592 | accuracy: 0.913734243697479 \n",
      "Epoch 16 | Step 6165 | loss: 0.22453712268422046 | accuracy: 0.9138020833333333 \n",
      "Epoch 16 | Step 6166 | loss: 0.22380004447600074 | accuracy: 0.9141270661157025 \n",
      "Epoch 16 | Step 6167 | loss: 0.2234633254101042 | accuracy: 0.9139344262295082 \n",
      "Epoch 16 | Step 6168 | loss: 0.22341906654883206 | accuracy: 0.9138719512195121 \n",
      "Epoch 16 | Step 6169 | loss: 0.22372592715246062 | accuracy: 0.9139364919354839 \n",
      "Epoch 16 | Step 6170 | loss: 0.2233866487145424 | accuracy: 0.914125 \n",
      "Epoch 16 | Step 6171 | loss: 0.22342795553425002 | accuracy: 0.9140625 \n",
      "Epoch 16 | Step 6172 | loss: 0.22471291689187523 | accuracy: 0.9136318897637795 \n",
      "Epoch 16 | Step 6173 | loss: 0.2244382009957917 | accuracy: 0.9139404296875 \n",
      "Epoch 16 | Step 6174 | loss: 0.2236537392749343 | accuracy: 0.9142441860465116 \n",
      "Epoch 16 | Step 6175 | loss: 0.2240859730885579 | accuracy: 0.9139423076923077 \n",
      "Epoch 16 | Step 6176 | loss: 0.2239960743725755 | accuracy: 0.9141221374045801 \n",
      "Epoch 16 | Step 6177 | loss: 0.22361230872797244 | accuracy: 0.9140625 \n",
      "Epoch 16 | Step 6178 | loss: 0.22313024249291957 | accuracy: 0.9143562030075187 \n",
      "Epoch 16 | Step 6179 | loss: 0.22281741528813517 | accuracy: 0.9144123134328357 \n",
      "Epoch 16 | Step 6180 | loss: 0.22335586691344222 | accuracy: 0.914236111111111 \n",
      "Epoch 16 | Step 6181 | loss: 0.2237318770631271 | accuracy: 0.9142922794117646 \n",
      "Epoch 16 | Step 6182 | loss: 0.22360623220022574 | accuracy: 0.9143476277372262 \n",
      "Epoch 16 | Step 6183 | loss: 0.22332778497450592 | accuracy: 0.9144021739130433 \n",
      "Epoch 16 | Step 6184 | loss: 0.22376692820367194 | accuracy: 0.9137814748201438 \n",
      "Epoch 16 | Step 6185 | loss: 0.22321986151593073 | accuracy: 0.9140624999999999 \n",
      "Epoch 16 | Step 6186 | loss: 0.22328778932280577 | accuracy: 0.9138962765957447 \n",
      "Epoch 16 | Step 6187 | loss: 0.2229355957726358 | accuracy: 0.9140625 \n",
      "Epoch 16 | Step 6188 | loss: 0.22274294422639837 | accuracy: 0.9142263986013986 \n",
      "Epoch 16 | Step 6189 | loss: 0.22197381174191835 | accuracy: 0.9144965277777778 \n",
      "Epoch 16 | Step 6190 | loss: 0.22192074466368247 | accuracy: 0.9144396551724138 \n",
      "Epoch 16 | Step 6191 | loss: 0.22297549405938957 | accuracy: 0.9140625 \n",
      "Epoch 16 | Step 6192 | loss: 0.22256677405161113 | accuracy: 0.9143282312925171 \n",
      "Epoch 16 | Step 6193 | loss: 0.22225309963765982 | accuracy: 0.914379222972973 \n",
      "Epoch 16 | Step 6194 | loss: 0.22205519801218238 | accuracy: 0.9144295302013423 \n",
      "Epoch 16 | Step 6195 | loss: 0.22183334544301034 | accuracy: 0.9145833333333333 \n",
      "Epoch 16 | Step 6196 | loss: 0.2218556683880604 | accuracy: 0.9146316225165563 \n",
      "Epoch 16 | Step 6197 | loss: 0.22211846096539184 | accuracy: 0.914782072368421 \n",
      "Epoch 16 | Step 6198 | loss: 0.22206543235023038 | accuracy: 0.9149305555555556 \n",
      "Epoch 16 | Step 6199 | loss: 0.22207531124933974 | accuracy: 0.9149756493506493 \n",
      "Epoch 16 | Step 6200 | loss: 0.22163830548524857 | accuracy: 0.9152217741935483 \n",
      "Epoch 16 | Step 6201 | loss: 0.22105464487312695 | accuracy: 0.9155649038461539 \n",
      "Epoch 16 | Step 6202 | loss: 0.2205241646641379 | accuracy: 0.9158041401273885 \n",
      "Epoch 16 | Step 6203 | loss: 0.2204914683876913 | accuracy: 0.9156447784810127 \n",
      "Epoch 16 | Step 6204 | loss: 0.22029362426801297 | accuracy: 0.9156839622641509 \n",
      "Epoch 16 | Step 6205 | loss: 0.22030450575985014 | accuracy: 0.915625 \n",
      "Epoch 16 | Step 6206 | loss: 0.2200900425914652 | accuracy: 0.9157608695652174 \n",
      "Epoch 16 | Step 6207 | loss: 0.22066163910943784 | accuracy: 0.9155092592592593 \n",
      "Epoch 16 | Step 6208 | loss: 0.21992324822885126 | accuracy: 0.9158358895705522 \n",
      "Epoch 16 | Step 6209 | loss: 0.21964185812124393 | accuracy: 0.9160632621951219 \n",
      "Epoch 16 | Step 6210 | loss: 0.2197410950154969 | accuracy: 0.9160984848484849 \n",
      "Epoch 16 | Step 6211 | loss: 0.22084373971783972 | accuracy: 0.9157567771084337 \n",
      "Epoch 16 | Step 6212 | loss: 0.2202963396282253 | accuracy: 0.9159805389221557 \n",
      "Epoch 16 | Step 6213 | loss: 0.21998223192280247 | accuracy: 0.9159226190476191 \n",
      "Epoch 16 | Step 6214 | loss: 0.2211364242275791 | accuracy: 0.9155880177514792 \n",
      "Epoch 16 | Step 6215 | loss: 0.22069498405737034 | accuracy: 0.9159007352941176 \n",
      "Epoch 16 | Step 6216 | loss: 0.22114494634650603 | accuracy: 0.9155701754385965 \n",
      "Epoch 16 | Step 6217 | loss: 0.2216133165151574 | accuracy: 0.9154251453488372 \n",
      "Epoch 16 | Step 6218 | loss: 0.22075105583392127 | accuracy: 0.9158236994219653 \n",
      "Epoch 16 | Step 6219 | loss: 0.2209959539702569 | accuracy: 0.9158584770114943 \n",
      "Epoch 16 | Step 6220 | loss: 0.22027568927833013 | accuracy: 0.9161607142857143 \n",
      "Epoch 16 | Step 6221 | loss: 0.22019761995497075 | accuracy: 0.9161931818181818 \n",
      "Epoch 16 | Step 6222 | loss: 0.22044237345288703 | accuracy: 0.9161370056497176 \n",
      "Epoch 16 | Step 6223 | loss: 0.22023553351003133 | accuracy: 0.9161692415730337 \n",
      "Epoch 16 | Step 6224 | loss: 0.22038688481520008 | accuracy: 0.9158519553072626 \n",
      "Epoch 16 | Step 6225 | loss: 0.22100922092795372 | accuracy: 0.915625 \n",
      "Epoch 16 | Step 6226 | loss: 0.2208728428868299 | accuracy: 0.9156595303867403 \n",
      "Epoch 16 | Step 6227 | loss: 0.22054129953567797 | accuracy: 0.9159512362637363 \n",
      "Epoch 16 | Step 6228 | loss: 0.22035893048745037 | accuracy: 0.9161543715846995 \n",
      "Epoch 16 | Step 6229 | loss: 0.2202575325803912 | accuracy: 0.9161854619565217 \n",
      "Epoch 16 | Step 6230 | loss: 0.22030648734118488 | accuracy: 0.9162162162162162 \n",
      "Epoch 16 | Step 6231 | loss: 0.21990253992619052 | accuracy: 0.9163306451612904 \n",
      "Epoch 16 | Step 6232 | loss: 0.22000052297816558 | accuracy: 0.9164438502673797 \n",
      "Epoch 16 | Step 6233 | loss: 0.2199645529877632 | accuracy: 0.9163896276595744 \n",
      "Epoch 16 | Step 6234 | loss: 0.21947724683574898 | accuracy: 0.9165013227513228 \n",
      "Epoch 16 | Step 6235 | loss: 0.21935308442304008 | accuracy: 0.9166118421052631 \n",
      "Epoch 16 | Step 6236 | loss: 0.21941679201200995 | accuracy: 0.9165575916230366 \n",
      "Epoch 16 | Step 6237 | loss: 0.21937584054345885 | accuracy: 0.9165852864583334 \n",
      "Epoch 16 | Step 6238 | loss: 0.2190589355063562 | accuracy: 0.9167746113989638 \n",
      "Epoch 16 | Step 6239 | loss: 0.21887703001806416 | accuracy: 0.9169619845360825 \n",
      "Epoch 16 | Step 6240 | loss: 0.2191362737845152 | accuracy: 0.9167467948717949 \n",
      "Epoch 16 | Step 6241 | loss: 0.21887192973981098 | accuracy: 0.9167729591836735 \n",
      "Epoch 16 | Step 6242 | loss: 0.21894395374102035 | accuracy: 0.9166402284263959 \n",
      "Epoch 16 | Step 6243 | loss: 0.2188489565795118 | accuracy: 0.9166666666666666 \n",
      "Epoch 16 | Step 6244 | loss: 0.218991703274262 | accuracy: 0.9166143216080402 \n",
      "Epoch 16 | Step 6245 | loss: 0.2189204140752554 | accuracy: 0.9165625 \n",
      "Epoch 16 | Step 6246 | loss: 0.21897395518585225 | accuracy: 0.9164334577114428 \n",
      "Epoch 16 | Step 6247 | loss: 0.21907690115789374 | accuracy: 0.9164603960396039 \n",
      "Epoch 16 | Step 6248 | loss: 0.21929759411095398 | accuracy: 0.9164100985221675 \n",
      "Epoch 16 | Step 6249 | loss: 0.21935808307984295 | accuracy: 0.9162837009803921 \n",
      "Epoch 16 | Step 6250 | loss: 0.21945272923969641 | accuracy: 0.9163871951219512 \n",
      "Epoch 16 | Step 6251 | loss: 0.2196083784248065 | accuracy: 0.9162621359223301 \n",
      "Epoch 16 | Step 6252 | loss: 0.21930686589600384 | accuracy: 0.9163647342995169 \n",
      "Epoch 16 | Step 6253 | loss: 0.21892867094049087 | accuracy: 0.9166165865384616 \n",
      "Epoch 16 | Step 6254 | loss: 0.219007851832221 | accuracy: 0.9164922248803827 \n",
      "Epoch 16 | Step 6255 | loss: 0.21853988848271824 | accuracy: 0.9166666666666666 \n",
      "Epoch 16 | Step 6256 | loss: 0.21838693536147122 | accuracy: 0.9167654028436019 \n",
      "Epoch 16 | Step 6257 | loss: 0.2182686601255862 | accuracy: 0.9168632075471698 \n",
      "Epoch 16 | Step 6258 | loss: 0.21785402168550402 | accuracy: 0.9171068075117371 \n",
      "Epoch 16 | Step 6259 | loss: 0.2177437081167074 | accuracy: 0.9172021028037384 \n",
      "Epoch 16 | Step 6260 | loss: 0.2178949868609739 | accuracy: 0.917078488372093 \n",
      "Epoch 16 | Step 6261 | loss: 0.21818665577167715 | accuracy: 0.9169560185185185 \n",
      "Epoch 16 | Step 6262 | loss: 0.21856351680881966 | accuracy: 0.9167626728110599 \n",
      "Epoch 16 | Step 6263 | loss: 0.21854414493529076 | accuracy: 0.916786123853211 \n",
      "Epoch 16 | Step 6264 | loss: 0.21837246285317696 | accuracy: 0.9168093607305936 \n",
      "Epoch 16 | Step 6265 | loss: 0.21828426674685694 | accuracy: 0.9168323863636364 \n",
      "Epoch 16 | Step 6266 | loss: 0.2181419907179893 | accuracy: 0.9169259049773756 \n",
      "Epoch 16 | Step 6267 | loss: 0.21789098507514945 | accuracy: 0.917088963963964 \n",
      "Epoch 16 | Step 6268 | loss: 0.21763036633954455 | accuracy: 0.9171804932735426 \n",
      "Epoch 16 | Step 6269 | loss: 0.21763267111964524 | accuracy: 0.9171316964285714 \n",
      "Epoch 16 | Step 6270 | loss: 0.21787939995527267 | accuracy: 0.9169444444444445 \n",
      "Epoch 16 | Step 6271 | loss: 0.21780917948458048 | accuracy: 0.9169662610619469 \n",
      "Epoch 16 | Step 6272 | loss: 0.21786091004042898 | accuracy: 0.9169190528634361 \n",
      "Epoch 16 | Step 6273 | loss: 0.217651557667475 | accuracy: 0.9168722587719298 \n",
      "Epoch 16 | Step 6274 | loss: 0.217534766154258 | accuracy: 0.9169623362445415 \n",
      "Epoch 16 | Step 6275 | loss: 0.21759852912762892 | accuracy: 0.9168478260869565 \n",
      "Epoch 16 | Step 6276 | loss: 0.21749951213082194 | accuracy: 0.9168695887445888 \n",
      "Epoch 16 | Step 6277 | loss: 0.2171525144307264 | accuracy: 0.9169585129310345 \n",
      "Epoch 16 | Step 6278 | loss: 0.2169855602501288 | accuracy: 0.9171137339055794 \n",
      "Epoch 16 | Step 6279 | loss: 0.21722358474746728 | accuracy: 0.9170673076923077 \n",
      "Epoch 16 | Step 6280 | loss: 0.21680527475286038 | accuracy: 0.9172872340425532 \n",
      "Epoch 16 | Step 6281 | loss: 0.2166172715566926 | accuracy: 0.9173066737288136 \n",
      "Epoch 16 | Step 6282 | loss: 0.21647351766437417 | accuracy: 0.9173259493670886 \n",
      "Epoch 16 | Step 6283 | loss: 0.21695597682680404 | accuracy: 0.9171481092436975 \n",
      "Epoch 16 | Step 6284 | loss: 0.21681297872854577 | accuracy: 0.9171678870292888 \n",
      "Epoch 16 | Step 6285 | loss: 0.21673903558403254 | accuracy: 0.9170572916666667 \n",
      "Epoch 16 | Step 6286 | loss: 0.21704079136561555 | accuracy: 0.9169476141078838 \n",
      "Epoch 16 | Step 6287 | loss: 0.2172386108720598 | accuracy: 0.9168388429752066 \n",
      "Epoch 16 | Step 6288 | loss: 0.216905434558421 | accuracy: 0.9169881687242798 \n",
      "Epoch 16 | Step 6289 | loss: 0.21642541024284284 | accuracy: 0.9172003073770492 \n",
      "Epoch 16 | Step 6290 | loss: 0.21618469436557924 | accuracy: 0.9172831632653061 \n",
      "Epoch 16 | Step 6291 | loss: 0.21582922424242748 | accuracy: 0.9173018292682927 \n",
      "Epoch 16 | Step 6292 | loss: 0.21552810084964583 | accuracy: 0.9174468623481782 \n",
      "Epoch 16 | Step 6293 | loss: 0.21555773240904655 | accuracy: 0.9174647177419355 \n",
      "Epoch 16 | Step 6294 | loss: 0.2156893187258617 | accuracy: 0.9172314257028112 \n",
      "Epoch 16 | Step 6295 | loss: 0.21541086488962174 | accuracy: 0.9173125 \n",
      "Epoch 16 | Step 6296 | loss: 0.21554039204975523 | accuracy: 0.9172684262948207 \n",
      "Epoch 16 | Step 6297 | loss: 0.2160315942314882 | accuracy: 0.9170386904761905 \n",
      "Epoch 16 | Step 6298 | loss: 0.21596621995858054 | accuracy: 0.9169960474308301 \n",
      "Epoch 16 | Step 6299 | loss: 0.21573234073759065 | accuracy: 0.9170767716535433 \n",
      "Epoch 16 | Step 6300 | loss: 0.2154640430913252 | accuracy: 0.917156862745098 \n",
      "Epoch 16 | Step 6301 | loss: 0.2154994569136761 | accuracy: 0.91717529296875 \n",
      "Epoch 16 | Step 6302 | loss: 0.21552227031627982 | accuracy: 0.9171935797665369 \n",
      "Epoch 16 | Step 6303 | loss: 0.21545813134474348 | accuracy: 0.9172722868217055 \n",
      "Epoch 16 | Step 6304 | loss: 0.21553483461551223 | accuracy: 0.9172297297297297 \n",
      "Epoch 16 | Step 6305 | loss: 0.2154650145998368 | accuracy: 0.9172475961538461 \n",
      "Epoch 16 | Step 6306 | loss: 0.21554779138601604 | accuracy: 0.9172054597701149 \n",
      "Epoch 16 | Step 6307 | loss: 0.21621679599958524 | accuracy: 0.9169847328244275 \n",
      "Epoch 16 | Step 6308 | loss: 0.21645605790751066 | accuracy: 0.9169439163498099 \n",
      "Epoch 16 | Step 6309 | loss: 0.21668524949839624 | accuracy: 0.9167850378787878 \n",
      "Epoch 16 | Step 6310 | loss: 0.21672697112245382 | accuracy: 0.9167452830188679 \n",
      "Epoch 16 | Step 6311 | loss: 0.21681100426984015 | accuracy: 0.9166470864661654 \n",
      "Epoch 16 | Step 6312 | loss: 0.21669928846734296 | accuracy: 0.9166666666666666 \n",
      "Epoch 16 | Step 6313 | loss: 0.2173440533120241 | accuracy: 0.9164528917910447 \n",
      "Epoch 16 | Step 6314 | loss: 0.21713607639185117 | accuracy: 0.9165892193308549 \n",
      "Epoch 16 | Step 6315 | loss: 0.21728271157653245 | accuracy: 0.9164930555555555 \n",
      "Epoch 16 | Step 6316 | loss: 0.21704323848235213 | accuracy: 0.9165705719557194 \n",
      "Epoch 16 | Step 6317 | loss: 0.21694952556315594 | accuracy: 0.9165900735294117 \n",
      "Epoch 16 | Step 6318 | loss: 0.21684054402641328 | accuracy: 0.9166666666666665 \n",
      "Epoch 16 | Step 6319 | loss: 0.216944729596594 | accuracy: 0.9165716240875912 \n",
      "Epoch 16 | Step 6320 | loss: 0.21708828487179502 | accuracy: 0.9164772727272726 \n",
      "Epoch 16 | Step 6321 | loss: 0.2172538153827191 | accuracy: 0.9164402173913042 \n",
      "Epoch 16 | Step 6322 | loss: 0.21745758705405988 | accuracy: 0.9163470216606497 \n",
      "Epoch 16 | Step 6323 | loss: 0.21710974047724296 | accuracy: 0.9164231115107913 \n",
      "Epoch 16 | Step 6324 | loss: 0.21749298114289525 | accuracy: 0.9163866487455196 \n",
      "Epoch 16 | Step 6325 | loss: 0.21719047805028308 | accuracy: 0.9165178571428572 \n",
      "Epoch 16 | Step 6326 | loss: 0.21701362633620297 | accuracy: 0.9167037366548043 \n",
      "Epoch 16 | Step 6327 | loss: 0.21697141330504252 | accuracy: 0.9166112588652482 \n",
      "Epoch 16 | Step 6328 | loss: 0.21699165924067212 | accuracy: 0.9166298586572438 \n",
      "Epoch 16 | Step 6329 | loss: 0.2168368641549433 | accuracy: 0.9167033450704225 \n",
      "Epoch 16 | Step 6330 | loss: 0.2167250150651263 | accuracy: 0.9167214912280702 \n",
      "Epoch 16 | Step 6331 | loss: 0.21646615081316944 | accuracy: 0.9167395104895105 \n",
      "Epoch 16 | Step 6332 | loss: 0.21637176216064016 | accuracy: 0.9167029616724739 \n",
      "Epoch 16 | Step 6333 | loss: 0.2159010620736 | accuracy: 0.9169379340277778 \n",
      "Epoch 16 | Step 6334 | loss: 0.21599035405885805 | accuracy: 0.9170090830449827 \n",
      "Epoch 16 | Step 6335 | loss: 0.21622335163169895 | accuracy: 0.9170258620689655 \n",
      "Epoch 16 | Step 6336 | loss: 0.2165371260743371 | accuracy: 0.916881443298969 \n",
      "Epoch 16 | Step 6337 | loss: 0.216357872630023 | accuracy: 0.9168450342465754 \n",
      "Epoch 16 | Step 6338 | loss: 0.21660001044489013 | accuracy: 0.9167022184300341 \n",
      "Epoch 16 | Step 6339 | loss: 0.21633238190797724 | accuracy: 0.9167729591836735 \n",
      "Epoch 16 | Step 6340 | loss: 0.21622301822496676 | accuracy: 0.916843220338983 \n",
      "Epoch 16 | Step 6341 | loss: 0.21639357857104088 | accuracy: 0.9167546452702703 \n",
      "Epoch 16 | Step 6342 | loss: 0.21609966228606323 | accuracy: 0.9168244949494949 \n",
      "Epoch 16 | Step 6343 | loss: 0.21633379488883403 | accuracy: 0.9168414429530202 \n",
      "Epoch 16 | Step 6344 | loss: 0.21607688729679306 | accuracy: 0.9170673076923077 \n",
      "Epoch 16 | Step 6345 | loss: 0.21584393960734208 | accuracy: 0.9171354166666666 \n",
      "Epoch 16 | Step 6346 | loss: 0.21583562418570945 | accuracy: 0.917047342192691 \n",
      "Epoch 16 | Step 6347 | loss: 0.21569539194568893 | accuracy: 0.9171150662251656 \n",
      "Epoch 16 | Step 6348 | loss: 0.2156590263393059 | accuracy: 0.9171307755775577 \n",
      "Epoch 16 | Step 6349 | loss: 0.21569168016216472 | accuracy: 0.9170949835526315 \n",
      "Epoch 16 | Step 6350 | loss: 0.2155421518155786 | accuracy: 0.9171618852459016 \n",
      "Epoch 16 | Step 6351 | loss: 0.215601987868937 | accuracy: 0.9171772875816994 \n",
      "Epoch 16 | Step 6352 | loss: 0.2159187541091481 | accuracy: 0.9171416938110749 \n",
      "Epoch 16 | Step 6353 | loss: 0.21577303999333414 | accuracy: 0.9171570616883117 \n",
      "Epoch 16 | Step 6354 | loss: 0.2155660122488309 | accuracy: 0.9172734627831716 \n",
      "Epoch 16 | Step 6355 | loss: 0.21573908874584782 | accuracy: 0.9171875 \n",
      "Epoch 16 | Step 6356 | loss: 0.21584523943555317 | accuracy: 0.9171523311897106 \n",
      "Epoch 16 | Step 6357 | loss: 0.2156877434358765 | accuracy: 0.9172676282051282 \n",
      "Epoch 16 | Step 6358 | loss: 0.21574431693496796 | accuracy: 0.9172324281150159 \n",
      "Epoch 16 | Step 6359 | loss: 0.21628154973220673 | accuracy: 0.9171476910828026 \n",
      "Epoch 16 | Step 6360 | loss: 0.2168771966818779 | accuracy: 0.9169642857142857 \n",
      "Epoch 16 | Step 6361 | loss: 0.21691980352035806 | accuracy: 0.9169303797468354 \n",
      "Epoch 16 | Step 6362 | loss: 0.216509033382315 | accuracy: 0.9171431388012619 \n",
      "Epoch 16 | Step 6363 | loss: 0.21645266747793313 | accuracy: 0.9171580188679245 \n",
      "Epoch 16 | Step 6364 | loss: 0.21661536010174914 | accuracy: 0.9171238244514106 \n",
      "Epoch 16 | Step 6365 | loss: 0.2164706593612209 | accuracy: 0.917138671875 \n",
      "Epoch 16 | Step 6366 | loss: 0.21636250060388232 | accuracy: 0.9172507788161994 \n",
      "Epoch 16 | Step 6367 | loss: 0.21699689886307125 | accuracy: 0.9171195652173914 \n",
      "Epoch 16 | Step 6368 | loss: 0.21672327237509353 | accuracy: 0.9171826625386997 \n",
      "Epoch 16 | Step 6369 | loss: 0.2165799115864951 | accuracy: 0.9172935956790124 \n",
      "Epoch 16 | Step 6370 | loss: 0.2168257528772721 | accuracy: 0.9173076923076923 \n",
      "Epoch 16 | Step 6371 | loss: 0.21683820311917118 | accuracy: 0.9173696319018405 \n",
      "Epoch 16 | Step 6372 | loss: 0.21683591360437032 | accuracy: 0.9173834097859327 \n",
      "Epoch 16 | Step 6373 | loss: 0.2168992135628331 | accuracy: 0.9173494664634146 \n",
      "Epoch 16 | Step 6374 | loss: 0.2170533717448588 | accuracy: 0.917220744680851 \n",
      "Epoch 16 | Step 6375 | loss: 0.21696694021423657 | accuracy: 0.9172821969696969 \n",
      "Epoch 16 | Step 6376 | loss: 0.21697692399748864 | accuracy: 0.9172016616314199 \n",
      "Epoch 16 | Step 6377 | loss: 0.2169938058962664 | accuracy: 0.9173098644578314 \n",
      "Epoch 16 | Step 6378 | loss: 0.21700212536183922 | accuracy: 0.9172766516516516 \n",
      "Epoch 16 | Step 6379 | loss: 0.21715928023000677 | accuracy: 0.9171968562874252 \n",
      "Epoch 16 | Step 6380 | loss: 0.21699714747382634 | accuracy: 0.9172108208955224 \n",
      "Epoch 16 | Step 6381 | loss: 0.2169200235844723 | accuracy: 0.9172247023809523 \n",
      "Epoch 16 | Step 6382 | loss: 0.2167931713981869 | accuracy: 0.9171921364985163 \n",
      "Epoch 16 | Step 6383 | loss: 0.21698650102731745 | accuracy: 0.9172059911242604 \n",
      "Epoch 16 | Step 6384 | loss: 0.21675276332109022 | accuracy: 0.9173119469026548 \n",
      "Epoch 16 | Step 6385 | loss: 0.21661822245839765 | accuracy: 0.9174172794117647 \n",
      "Epoch 16 | Step 6386 | loss: 0.2168094756360278 | accuracy: 0.9173387096774194 \n",
      "Epoch 16 | Step 6387 | loss: 0.2166280330142431 | accuracy: 0.9174433479532164 \n",
      "Epoch 16 | Step 6388 | loss: 0.21645120818048455 | accuracy: 0.9175473760932945 \n",
      "Epoch 16 | Step 6389 | loss: 0.21633214726610933 | accuracy: 0.917469113372093 \n",
      "Epoch 16 | Step 6390 | loss: 0.216603924377241 | accuracy: 0.9174365942028986 \n",
      "Epoch 16 | Step 6391 | loss: 0.21652458670597546 | accuracy: 0.9174494219653179 \n",
      "Epoch 16 | Step 6392 | loss: 0.21623255333914193 | accuracy: 0.9176422910662824 \n",
      "Epoch 16 | Step 6393 | loss: 0.21661682546823874 | accuracy: 0.9174299568965517 \n",
      "Epoch 16 | Step 6394 | loss: 0.21643638230838885 | accuracy: 0.9175322349570201 \n",
      "Epoch 16 | Step 6395 | loss: 0.21625247687101365 | accuracy: 0.9176339285714286 \n",
      "Epoch 16 | Step 6396 | loss: 0.21598535432265356 | accuracy: 0.9177350427350427 \n",
      "Epoch 16 | Step 6397 | loss: 0.216047012289478 | accuracy: 0.9177911931818182 \n",
      "Epoch 16 | Step 6398 | loss: 0.21617788671602947 | accuracy: 0.9177584985835694 \n",
      "Epoch 16 | Step 6399 | loss: 0.21594341776970416 | accuracy: 0.917770127118644 \n",
      "Epoch 16 | Step 6400 | loss: 0.2160250185660913 | accuracy: 0.917693661971831 \n",
      "Epoch 16 | Step 6401 | loss: 0.21582660062259504 | accuracy: 0.9177054073033708 \n",
      "Epoch 16 | Step 6402 | loss: 0.21572622894739904 | accuracy: 0.9177608543417367 \n",
      "Epoch 16 | Step 6403 | loss: 0.2157526073675582 | accuracy: 0.9177287011173184 \n",
      "Epoch 16 | Step 6404 | loss: 0.21563018426755676 | accuracy: 0.9177837743732591 \n",
      "Epoch 16 | Step 6405 | loss: 0.21571858608060412 | accuracy: 0.9178385416666667 \n",
      "Epoch 16 | Step 6406 | loss: 0.21554786420925173 | accuracy: 0.9179362880886427 \n",
      "Epoch 16 | Step 6407 | loss: 0.21572642670481246 | accuracy: 0.9179471685082873 \n",
      "Epoch 16 | Step 6408 | loss: 0.21576205671818788 | accuracy: 0.9180010330578512 \n",
      "Epoch 16 | Step 6409 | loss: 0.21559853806764215 | accuracy: 0.9181404532967034 \n",
      "Epoch 16 | Step 6410 | loss: 0.21546645903424042 | accuracy: 0.9181506849315069 \n",
      "Epoch 16 | Step 6411 | loss: 0.21538740567496564 | accuracy: 0.9181181693989071 \n",
      "Epoch 16 | Step 6412 | loss: 0.21509938246547688 | accuracy: 0.9182561307901907 \n",
      "Epoch 16 | Step 6413 | loss: 0.21539434563854468 | accuracy: 0.9182235054347826 \n",
      "Epoch 16 | Step 6414 | loss: 0.21538378451736315 | accuracy: 0.9182757452574526 \n",
      "Epoch 16 | Step 6415 | loss: 0.21575843413939347 | accuracy: 0.918116554054054 \n",
      "Epoch 16 | Step 6416 | loss: 0.21603702129218777 | accuracy: 0.9179582210242587 \n",
      "Epoch 16 | Step 6417 | loss: 0.21621496074141994 | accuracy: 0.9178427419354839 \n",
      "Epoch 16 | Step 6418 | loss: 0.21638416001528263 | accuracy: 0.9177278820375335 \n",
      "Epoch 16 | Step 6419 | loss: 0.21659696703766756 | accuracy: 0.9176136363636364 \n",
      "Epoch 16 | Step 6420 | loss: 0.21635401825110118 | accuracy: 0.917625 \n",
      "Epoch 16 | Step 6421 | loss: 0.2161568360442811 | accuracy: 0.9176778590425532 \n",
      "Epoch 16 | Step 6422 | loss: 0.21588420636695008 | accuracy: 0.9177718832891246 \n",
      "Epoch 16 | Step 6423 | loss: 0.2162370650028741 | accuracy: 0.9176173941798942 \n",
      "Epoch 16 | Step 6424 | loss: 0.21629647782814534 | accuracy: 0.9175874010554089 \n",
      "Epoch 16 | Step 6425 | loss: 0.21606711174704527 | accuracy: 0.9176809210526315 \n",
      "Epoch 16 | Step 6426 | loss: 0.2160243677694028 | accuracy: 0.917732939632546 \n",
      "Epoch 16 | Step 6427 | loss: 0.21580063218143597 | accuracy: 0.9178255890052356 \n",
      "Epoch 16 | Step 6428 | loss: 0.21568546272989353 | accuracy: 0.9178769582245431 \n",
      "Epoch 16 | Step 6429 | loss: 0.21574615755040819 | accuracy: 0.9177652994791666 \n",
      "Epoch 16 | Step 6430 | loss: 0.21578872209632552 | accuracy: 0.9177353896103896 \n",
      "Epoch 16 | Step 6431 | loss: 0.21573784408868904 | accuracy: 0.9177461139896373 \n",
      "Epoch 16 | Step 6432 | loss: 0.2158051590009253 | accuracy: 0.9177164082687338 \n",
      "Epoch 16 | Step 6433 | loss: 0.21584354001145387 | accuracy: 0.9176868556701031 \n",
      "Epoch 16 | Step 6434 | loss: 0.21584029076261815 | accuracy: 0.9176976221079691 \n",
      "Epoch 16 | Step 6435 | loss: 0.21587253673336446 | accuracy: 0.9176282051282051 \n",
      "Epoch 16 | Step 6436 | loss: 0.21587001219811036 | accuracy: 0.917599104859335 \n",
      "Epoch 16 | Step 6437 | loss: 0.2157089332194657 | accuracy: 0.9176897321428571 \n",
      "Epoch 16 | Step 6438 | loss: 0.21562851004245628 | accuracy: 0.9177401399491094 \n",
      "Epoch 16 | Step 6439 | loss: 0.21571207558972583 | accuracy: 0.9175920050761421 \n",
      "Epoch 16 | Step 6440 | loss: 0.21563677819846552 | accuracy: 0.9177215189873418 \n",
      "Epoch 16 | Step 6441 | loss: 0.21547926313272028 | accuracy: 0.9178503787878788 \n",
      "Epoch 16 | Step 6442 | loss: 0.21519974326381755 | accuracy: 0.9179392317380353 \n",
      "Epoch 16 | Step 6443 | loss: 0.2152674132817654 | accuracy: 0.9178706030150754 \n",
      "Epoch 16 | Step 6444 | loss: 0.21533622611360742 | accuracy: 0.9178414786967418 \n",
      "Epoch 16 | Step 6445 | loss: 0.2155906823836267 | accuracy: 0.917734375 \n",
      "Epoch 16 | Step 6446 | loss: 0.21542408224427492 | accuracy: 0.9177836658354115 \n",
      "Epoch 16 | Step 6447 | loss: 0.21589454276422362 | accuracy: 0.9175217661691543 \n",
      "Epoch 16 | Step 6448 | loss: 0.21562112144959475 | accuracy: 0.917640861595239 \n",
      "Validation | Epoch 16 | Step 6448 | accuracy: 0.8537240610881285 \n",
      "Epoch 17 | Step 6449 | loss: 0.1639072299003601 | accuracy: 0.953125 \n",
      "Epoch 17 | Step 6450 | loss: 0.2388969361782074 | accuracy: 0.8984375 \n",
      "Epoch 17 | Step 6451 | loss: 0.2044843782981237 | accuracy: 0.9166666666666666 \n",
      "Epoch 17 | Step 6452 | loss: 0.22050436958670616 | accuracy: 0.91796875 \n",
      "Epoch 17 | Step 6453 | loss: 0.21697579324245453 | accuracy: 0.925 \n",
      "Epoch 17 | Step 6454 | loss: 0.22839204221963882 | accuracy: 0.9166666666666666 \n",
      "Epoch 17 | Step 6455 | loss: 0.23243493480341776 | accuracy: 0.9151785714285714 \n",
      "Epoch 17 | Step 6456 | loss: 0.2411533873528242 | accuracy: 0.9140625 \n",
      "Epoch 17 | Step 6457 | loss: 0.23372744189368355 | accuracy: 0.9131944444444444 \n",
      "Epoch 17 | Step 6458 | loss: 0.2366078317165375 | accuracy: 0.9109375 \n",
      "Epoch 17 | Step 6459 | loss: 0.23167404396967453 | accuracy: 0.9133522727272727 \n",
      "Epoch 17 | Step 6460 | loss: 0.23326403026779494 | accuracy: 0.9140625 \n",
      "Epoch 17 | Step 6461 | loss: 0.2313804844251046 | accuracy: 0.9158653846153846 \n",
      "Epoch 17 | Step 6462 | loss: 0.23032601816313608 | accuracy: 0.9162946428571429 \n",
      "Epoch 17 | Step 6463 | loss: 0.2207489088177681 | accuracy: 0.9197916666666667 \n",
      "Epoch 17 | Step 6464 | loss: 0.21703773131594062 | accuracy: 0.921875 \n",
      "Epoch 17 | Step 6465 | loss: 0.21847418082111023 | accuracy: 0.9227941176470589 \n",
      "Epoch 17 | Step 6466 | loss: 0.21595585718750954 | accuracy: 0.921875 \n",
      "Epoch 17 | Step 6467 | loss: 0.21839315836366854 | accuracy: 0.9226973684210527 \n",
      "Epoch 17 | Step 6468 | loss: 0.21581326611340046 | accuracy: 0.92265625 \n",
      "Epoch 17 | Step 6469 | loss: 0.21237495080346153 | accuracy: 0.9241071428571429 \n",
      "Epoch 17 | Step 6470 | loss: 0.21168228001757103 | accuracy: 0.9225852272727273 \n",
      "Epoch 17 | Step 6471 | loss: 0.21203331163396005 | accuracy: 0.9211956521739131 \n",
      "Epoch 17 | Step 6472 | loss: 0.20810720697045326 | accuracy: 0.9225260416666666 \n",
      "Epoch 17 | Step 6473 | loss: 0.20641135692596435 | accuracy: 0.9225 \n",
      "Epoch 17 | Step 6474 | loss: 0.2063394859433174 | accuracy: 0.9224759615384616 \n",
      "Epoch 17 | Step 6475 | loss: 0.20741334281585835 | accuracy: 0.921875 \n",
      "Epoch 17 | Step 6476 | loss: 0.20472372908677375 | accuracy: 0.9229910714285714 \n",
      "Epoch 17 | Step 6477 | loss: 0.20215982815314984 | accuracy: 0.9240301724137931 \n",
      "Epoch 17 | Step 6478 | loss: 0.2036696930726369 | accuracy: 0.9234375 \n",
      "Epoch 17 | Step 6479 | loss: 0.2031942351210502 | accuracy: 0.9243951612903226 \n",
      "Epoch 17 | Step 6480 | loss: 0.2050618384964764 | accuracy: 0.923828125 \n",
      "Epoch 17 | Step 6481 | loss: 0.20633857358585705 | accuracy: 0.9232954545454546 \n",
      "Epoch 17 | Step 6482 | loss: 0.20463987921967225 | accuracy: 0.9241727941176471 \n",
      "Epoch 17 | Step 6483 | loss: 0.20164034281458174 | accuracy: 0.9258928571428572 \n",
      "Epoch 17 | Step 6484 | loss: 0.20202144152588314 | accuracy: 0.9253472222222222 \n",
      "Epoch 17 | Step 6485 | loss: 0.2005327545307778 | accuracy: 0.924831081081081 \n",
      "Epoch 17 | Step 6486 | loss: 0.2016392946243286 | accuracy: 0.9243421052631579 \n",
      "Epoch 17 | Step 6487 | loss: 0.2018405646085739 | accuracy: 0.9234775641025641 \n",
      "Epoch 17 | Step 6488 | loss: 0.2017368745058775 | accuracy: 0.923828125 \n",
      "Epoch 17 | Step 6489 | loss: 0.20051906566794325 | accuracy: 0.9241615853658537 \n",
      "Epoch 17 | Step 6490 | loss: 0.20281990333682015 | accuracy: 0.9233630952380952 \n",
      "Epoch 17 | Step 6491 | loss: 0.20223638796529106 | accuracy: 0.9229651162790697 \n",
      "Epoch 17 | Step 6492 | loss: 0.20071454786441542 | accuracy: 0.9232954545454546 \n",
      "Epoch 17 | Step 6493 | loss: 0.20331016812059616 | accuracy: 0.9215277777777777 \n",
      "Epoch 17 | Step 6494 | loss: 0.203810116843037 | accuracy: 0.9215353260869565 \n",
      "Epoch 17 | Step 6495 | loss: 0.20297835894087526 | accuracy: 0.921875 \n",
      "Epoch 17 | Step 6496 | loss: 0.20468654204159975 | accuracy: 0.9215494791666666 \n",
      "Epoch 17 | Step 6497 | loss: 0.20359409676522625 | accuracy: 0.9221938775510204 \n",
      "Epoch 17 | Step 6498 | loss: 0.2049553993344307 | accuracy: 0.921875 \n",
      "Epoch 17 | Step 6499 | loss: 0.20809230062307096 | accuracy: 0.9203431372549019 \n",
      "Epoch 17 | Step 6500 | loss: 0.20780307656297317 | accuracy: 0.9209735576923077 \n",
      "Epoch 17 | Step 6501 | loss: 0.20622181583125637 | accuracy: 0.9212853773584906 \n",
      "Epoch 17 | Step 6502 | loss: 0.2053205613736753 | accuracy: 0.9212962962962963 \n",
      "Epoch 17 | Step 6503 | loss: 0.20594621409069408 | accuracy: 0.9207386363636364 \n",
      "Epoch 17 | Step 6504 | loss: 0.20682355814746448 | accuracy: 0.9204799107142857 \n",
      "Epoch 17 | Step 6505 | loss: 0.2070112034939883 | accuracy: 0.9207785087719298 \n",
      "Epoch 17 | Step 6506 | loss: 0.20728138320404907 | accuracy: 0.9210668103448276 \n",
      "Epoch 17 | Step 6507 | loss: 0.20849433263479653 | accuracy: 0.9208156779661016 \n",
      "Epoch 17 | Step 6508 | loss: 0.2099128045141697 | accuracy: 0.92109375 \n",
      "Epoch 17 | Step 6509 | loss: 0.21032262410296768 | accuracy: 0.9208504098360656 \n",
      "Epoch 17 | Step 6510 | loss: 0.20953275960299275 | accuracy: 0.920866935483871 \n",
      "Epoch 17 | Step 6511 | loss: 0.20972727499310934 | accuracy: 0.9203869047619048 \n",
      "Epoch 17 | Step 6512 | loss: 0.20798961748369038 | accuracy: 0.921142578125 \n",
      "Epoch 17 | Step 6513 | loss: 0.20864495245309977 | accuracy: 0.9206730769230769 \n",
      "Epoch 17 | Step 6514 | loss: 0.20689911790417903 | accuracy: 0.9214015151515151 \n",
      "Epoch 17 | Step 6515 | loss: 0.2058639436293004 | accuracy: 0.9221082089552238 \n",
      "Epoch 17 | Step 6516 | loss: 0.20543556101620197 | accuracy: 0.9225643382352942 \n",
      "Epoch 17 | Step 6517 | loss: 0.20665560867907345 | accuracy: 0.9225543478260869 \n",
      "Epoch 17 | Step 6518 | loss: 0.2070075874882085 | accuracy: 0.9225446428571429 \n",
      "Epoch 17 | Step 6519 | loss: 0.20684680227242724 | accuracy: 0.9227552816901409 \n",
      "Epoch 17 | Step 6520 | loss: 0.2060880409553647 | accuracy: 0.9231770833333334 \n",
      "Epoch 17 | Step 6521 | loss: 0.2060615292763057 | accuracy: 0.9235873287671232 \n",
      "Epoch 17 | Step 6522 | loss: 0.20716196973178838 | accuracy: 0.9227195945945946 \n",
      "Epoch 17 | Step 6523 | loss: 0.20832790046930313 | accuracy: 0.9225 \n",
      "Epoch 17 | Step 6524 | loss: 0.2074275588322627 | accuracy: 0.9226973684210527 \n",
      "Epoch 17 | Step 6525 | loss: 0.20734965307759 | accuracy: 0.9228896103896104 \n",
      "Epoch 17 | Step 6526 | loss: 0.20881948495904604 | accuracy: 0.9220753205128205 \n",
      "Epoch 17 | Step 6527 | loss: 0.20795402807902685 | accuracy: 0.9226661392405063 \n",
      "Epoch 17 | Step 6528 | loss: 0.20806805184111 | accuracy: 0.92265625 \n",
      "Epoch 17 | Step 6529 | loss: 0.20789839134172158 | accuracy: 0.9228395061728395 \n",
      "Epoch 17 | Step 6530 | loss: 0.2069554300751628 | accuracy: 0.9232088414634146 \n",
      "Epoch 17 | Step 6531 | loss: 0.20734697732939777 | accuracy: 0.9231927710843374 \n",
      "Epoch 17 | Step 6532 | loss: 0.2079935883659692 | accuracy: 0.9231770833333334 \n",
      "Epoch 17 | Step 6533 | loss: 0.20888571642777498 | accuracy: 0.9229779411764706 \n",
      "Epoch 17 | Step 6534 | loss: 0.20848409978802815 | accuracy: 0.9235101744186046 \n",
      "Epoch 17 | Step 6535 | loss: 0.20859096370551777 | accuracy: 0.9233117816091954 \n",
      "Epoch 17 | Step 6536 | loss: 0.20910697591237046 | accuracy: 0.9234730113636364 \n",
      "Epoch 17 | Step 6537 | loss: 0.20866997816254584 | accuracy: 0.9236306179775281 \n",
      "Epoch 17 | Step 6538 | loss: 0.20992052546805806 | accuracy: 0.9232638888888889 \n",
      "Epoch 17 | Step 6539 | loss: 0.20903628385001485 | accuracy: 0.923592032967033 \n",
      "Epoch 17 | Step 6540 | loss: 0.21084952718861724 | accuracy: 0.923233695652174 \n",
      "Epoch 17 | Step 6541 | loss: 0.21106550890591838 | accuracy: 0.922883064516129 \n",
      "Epoch 17 | Step 6542 | loss: 0.21053714550873068 | accuracy: 0.9230385638297872 \n",
      "Epoch 17 | Step 6543 | loss: 0.2092449531743401 | accuracy: 0.9236842105263158 \n",
      "Epoch 17 | Step 6544 | loss: 0.20857458810011545 | accuracy: 0.9239908854166666 \n",
      "Epoch 17 | Step 6545 | loss: 0.20806105480980627 | accuracy: 0.9244523195876289 \n",
      "Epoch 17 | Step 6546 | loss: 0.2102156336210212 | accuracy: 0.9237882653061225 \n",
      "Epoch 17 | Step 6547 | loss: 0.20933824867913217 | accuracy: 0.9240845959595959 \n",
      "Epoch 17 | Step 6548 | loss: 0.20916631877422331 | accuracy: 0.92375 \n",
      "Epoch 17 | Step 6549 | loss: 0.20889653413012477 | accuracy: 0.9237314356435643 \n",
      "Epoch 17 | Step 6550 | loss: 0.2086869945713118 | accuracy: 0.9237132352941176 \n",
      "Epoch 17 | Step 6551 | loss: 0.20887866847723432 | accuracy: 0.9236953883495146 \n",
      "Epoch 17 | Step 6552 | loss: 0.20886528993455264 | accuracy: 0.9239783653846154 \n",
      "Epoch 17 | Step 6553 | loss: 0.20911514390082586 | accuracy: 0.9236607142857143 \n",
      "Epoch 17 | Step 6554 | loss: 0.2083257775542871 | accuracy: 0.9239386792452831 \n",
      "Epoch 17 | Step 6555 | loss: 0.21007747224001128 | accuracy: 0.9231892523364486 \n",
      "Epoch 17 | Step 6556 | loss: 0.21082653284624772 | accuracy: 0.9230324074074074 \n",
      "Epoch 17 | Step 6557 | loss: 0.21021119183903442 | accuracy: 0.9231651376146789 \n",
      "Epoch 17 | Step 6558 | loss: 0.21016627062450755 | accuracy: 0.9230113636363636 \n",
      "Epoch 17 | Step 6559 | loss: 0.21055260783917196 | accuracy: 0.9230011261261262 \n",
      "Epoch 17 | Step 6560 | loss: 0.2118315930877413 | accuracy: 0.9225725446428571 \n",
      "Epoch 17 | Step 6561 | loss: 0.2128632187315848 | accuracy: 0.9224280973451328 \n",
      "Epoch 17 | Step 6562 | loss: 0.21285347875795865 | accuracy: 0.9222861842105263 \n",
      "Epoch 17 | Step 6563 | loss: 0.21208927495324092 | accuracy: 0.9225543478260869 \n",
      "Epoch 17 | Step 6564 | loss: 0.21231014352163363 | accuracy: 0.9225484913793104 \n",
      "Epoch 17 | Step 6565 | loss: 0.21225128004438856 | accuracy: 0.922409188034188 \n",
      "Epoch 17 | Step 6566 | loss: 0.21252874303924835 | accuracy: 0.9221398305084746 \n",
      "Epoch 17 | Step 6567 | loss: 0.2128012958569687 | accuracy: 0.9217436974789915 \n",
      "Epoch 17 | Step 6568 | loss: 0.21274424027651548 | accuracy: 0.9217447916666667 \n",
      "Epoch 17 | Step 6569 | loss: 0.2120659427086184 | accuracy: 0.921875 \n",
      "Epoch 17 | Step 6570 | loss: 0.21181216695513883 | accuracy: 0.921875 \n",
      "Epoch 17 | Step 6571 | loss: 0.21170297246880648 | accuracy: 0.9221290650406504 \n",
      "Epoch 17 | Step 6572 | loss: 0.21190271784941997 | accuracy: 0.9222530241935484 \n",
      "Epoch 17 | Step 6573 | loss: 0.21164025515317916 | accuracy: 0.92225 \n",
      "Epoch 17 | Step 6574 | loss: 0.211699176697977 | accuracy: 0.9222470238095238 \n",
      "Epoch 17 | Step 6575 | loss: 0.21300820507637158 | accuracy: 0.921751968503937 \n",
      "Epoch 17 | Step 6576 | loss: 0.2129091151873581 | accuracy: 0.921875 \n",
      "Epoch 17 | Step 6577 | loss: 0.2121148168925167 | accuracy: 0.9222383720930233 \n",
      "Epoch 17 | Step 6578 | loss: 0.21269361623204672 | accuracy: 0.9217548076923077 \n",
      "Epoch 17 | Step 6579 | loss: 0.21276907867375222 | accuracy: 0.921875 \n",
      "Epoch 17 | Step 6580 | loss: 0.2123173445350293 | accuracy: 0.9221117424242424 \n",
      "Epoch 17 | Step 6581 | loss: 0.2117701482615973 | accuracy: 0.9223449248120301 \n",
      "Epoch 17 | Step 6582 | loss: 0.21152516137530555 | accuracy: 0.9223414179104478 \n",
      "Epoch 17 | Step 6583 | loss: 0.21212191587245022 | accuracy: 0.922337962962963 \n",
      "Epoch 17 | Step 6584 | loss: 0.21231818062198513 | accuracy: 0.9224494485294118 \n",
      "Epoch 17 | Step 6585 | loss: 0.2121521698406143 | accuracy: 0.9226733576642335 \n",
      "Epoch 17 | Step 6586 | loss: 0.21179411382130955 | accuracy: 0.9228940217391305 \n",
      "Epoch 17 | Step 6587 | loss: 0.21205726453511836 | accuracy: 0.9223246402877698 \n",
      "Epoch 17 | Step 6588 | loss: 0.21164528275174754 | accuracy: 0.9224330357142857 \n",
      "Epoch 17 | Step 6589 | loss: 0.21169972911160043 | accuracy: 0.9223182624113475 \n",
      "Epoch 17 | Step 6590 | loss: 0.2113908403880999 | accuracy: 0.9223151408450704 \n",
      "Epoch 17 | Step 6591 | loss: 0.21129409411362002 | accuracy: 0.9225305944055944 \n",
      "Epoch 17 | Step 6592 | loss: 0.21048187262689075 | accuracy: 0.9230685763888888 \n",
      "Epoch 17 | Step 6593 | loss: 0.21034840299137708 | accuracy: 0.9230603448275863 \n",
      "Epoch 17 | Step 6594 | loss: 0.21123749216737814 | accuracy: 0.9227311643835616 \n",
      "Epoch 17 | Step 6595 | loss: 0.21080670029330417 | accuracy: 0.9230442176870748 \n",
      "Epoch 17 | Step 6596 | loss: 0.21044969724843635 | accuracy: 0.9231418918918919 \n",
      "Epoch 17 | Step 6597 | loss: 0.21005805431796404 | accuracy: 0.923238255033557 \n",
      "Epoch 17 | Step 6598 | loss: 0.20984840447704 | accuracy: 0.9233333333333333 \n",
      "Epoch 17 | Step 6599 | loss: 0.2097520274140977 | accuracy: 0.9232201986754967 \n",
      "Epoch 17 | Step 6600 | loss: 0.2100484789300122 | accuracy: 0.9233141447368421 \n",
      "Epoch 17 | Step 6601 | loss: 0.20993017843540976 | accuracy: 0.9234068627450981 \n",
      "Epoch 17 | Step 6602 | loss: 0.2099355458729453 | accuracy: 0.9233969155844156 \n",
      "Epoch 17 | Step 6603 | loss: 0.2095251875058297 | accuracy: 0.9234879032258064 \n",
      "Epoch 17 | Step 6604 | loss: 0.20903378748931947 | accuracy: 0.9237780448717948 \n",
      "Epoch 17 | Step 6605 | loss: 0.20845230478959478 | accuracy: 0.9239649681528662 \n",
      "Epoch 17 | Step 6606 | loss: 0.20850400074939185 | accuracy: 0.9237539556962026 \n",
      "Epoch 17 | Step 6607 | loss: 0.2083186796345051 | accuracy: 0.9236438679245284 \n",
      "Epoch 17 | Step 6608 | loss: 0.20819898978807033 | accuracy: 0.9236328125 \n",
      "Epoch 17 | Step 6609 | loss: 0.20791329207442563 | accuracy: 0.9237189440993789 \n",
      "Epoch 17 | Step 6610 | loss: 0.20850886363122198 | accuracy: 0.9235146604938271 \n",
      "Epoch 17 | Step 6611 | loss: 0.20782012940367306 | accuracy: 0.9237921779141104 \n",
      "Epoch 17 | Step 6612 | loss: 0.20757343333850548 | accuracy: 0.9239710365853658 \n",
      "Epoch 17 | Step 6613 | loss: 0.20770153371673641 | accuracy: 0.9238636363636363 \n",
      "Epoch 17 | Step 6614 | loss: 0.20879953996424216 | accuracy: 0.9235692771084337 \n",
      "Epoch 17 | Step 6615 | loss: 0.2082012240401285 | accuracy: 0.9238398203592815 \n",
      "Epoch 17 | Step 6616 | loss: 0.20786320772908984 | accuracy: 0.9237351190476191 \n",
      "Epoch 17 | Step 6617 | loss: 0.20886413479697774 | accuracy: 0.9235392011834319 \n",
      "Epoch 17 | Step 6618 | loss: 0.20850839834002888 | accuracy: 0.9237132352941176 \n",
      "Epoch 17 | Step 6619 | loss: 0.20880921951860015 | accuracy: 0.9236111111111112 \n",
      "Epoch 17 | Step 6620 | loss: 0.20940640802646793 | accuracy: 0.9234193313953488 \n",
      "Epoch 17 | Step 6621 | loss: 0.2086403569303496 | accuracy: 0.9236813583815029 \n",
      "Epoch 17 | Step 6622 | loss: 0.2088415832098188 | accuracy: 0.9236709770114943 \n",
      "Epoch 17 | Step 6623 | loss: 0.20812108201639992 | accuracy: 0.9239285714285714 \n",
      "Epoch 17 | Step 6624 | loss: 0.20798775071108883 | accuracy: 0.9239169034090909 \n",
      "Epoch 17 | Step 6625 | loss: 0.20825418215350242 | accuracy: 0.9238170903954802 \n",
      "Epoch 17 | Step 6626 | loss: 0.20806410004583636 | accuracy: 0.9238061797752809 \n",
      "Epoch 17 | Step 6627 | loss: 0.20815949982770995 | accuracy: 0.9237081005586593 \n",
      "Epoch 17 | Step 6628 | loss: 0.20872347686025833 | accuracy: 0.9234375 \n",
      "Epoch 17 | Step 6629 | loss: 0.20851569602173337 | accuracy: 0.9234288674033149 \n",
      "Epoch 17 | Step 6630 | loss: 0.20825319180449287 | accuracy: 0.923592032967033 \n",
      "Epoch 17 | Step 6631 | loss: 0.20816200499326154 | accuracy: 0.9237534153005464 \n",
      "Epoch 17 | Step 6632 | loss: 0.2082406544814939 | accuracy: 0.9237432065217391 \n",
      "Epoch 17 | Step 6633 | loss: 0.20826089768796355 | accuracy: 0.9236486486486486 \n",
      "Epoch 17 | Step 6634 | loss: 0.20780791286178815 | accuracy: 0.9236391129032258 \n",
      "Epoch 17 | Step 6635 | loss: 0.20787758575403753 | accuracy: 0.923629679144385 \n",
      "Epoch 17 | Step 6636 | loss: 0.20782860186188779 | accuracy: 0.9236203457446809 \n",
      "Epoch 17 | Step 6637 | loss: 0.20729211106817558 | accuracy: 0.923859126984127 \n",
      "Epoch 17 | Step 6638 | loss: 0.20706070810556412 | accuracy: 0.9240131578947368 \n",
      "Epoch 17 | Step 6639 | loss: 0.20708605748508613 | accuracy: 0.9240019633507853 \n",
      "Epoch 17 | Step 6640 | loss: 0.20704092147449651 | accuracy: 0.924072265625 \n",
      "Epoch 17 | Step 6641 | loss: 0.2067262524150196 | accuracy: 0.9242227979274611 \n",
      "Epoch 17 | Step 6642 | loss: 0.20657444361251653 | accuracy: 0.9242106958762887 \n",
      "Epoch 17 | Step 6643 | loss: 0.20665975419374613 | accuracy: 0.924198717948718 \n",
      "Epoch 17 | Step 6644 | loss: 0.2063663179929159 | accuracy: 0.9242665816326531 \n",
      "Epoch 17 | Step 6645 | loss: 0.20639057707060413 | accuracy: 0.9240958121827412 \n",
      "Epoch 17 | Step 6646 | loss: 0.20623292503031818 | accuracy: 0.9240845959595959 \n",
      "Epoch 17 | Step 6647 | loss: 0.2064131050553154 | accuracy: 0.9241520100502513 \n",
      "Epoch 17 | Step 6648 | loss: 0.2063042198866606 | accuracy: 0.923984375 \n",
      "Epoch 17 | Step 6649 | loss: 0.20639118070329598 | accuracy: 0.923818407960199 \n",
      "Epoch 17 | Step 6650 | loss: 0.2064537523996712 | accuracy: 0.9238087871287128 \n",
      "Epoch 17 | Step 6651 | loss: 0.2065071447435858 | accuracy: 0.9237222906403941 \n",
      "Epoch 17 | Step 6652 | loss: 0.20661967145461663 | accuracy: 0.9237132352941176 \n",
      "Epoch 17 | Step 6653 | loss: 0.20684866890674683 | accuracy: 0.9237042682926829 \n",
      "Epoch 17 | Step 6654 | loss: 0.20694706039231958 | accuracy: 0.9234678398058253 \n",
      "Epoch 17 | Step 6655 | loss: 0.20662765665618693 | accuracy: 0.9236111111111112 \n",
      "Epoch 17 | Step 6656 | loss: 0.20624012829592595 | accuracy: 0.9237530048076923 \n",
      "Epoch 17 | Step 6657 | loss: 0.20634688593839345 | accuracy: 0.9235944976076556 \n",
      "Epoch 17 | Step 6658 | loss: 0.20585380966464678 | accuracy: 0.9237351190476191 \n",
      "Epoch 17 | Step 6659 | loss: 0.20574576916146617 | accuracy: 0.9238744075829384 \n",
      "Epoch 17 | Step 6660 | loss: 0.20566570249227983 | accuracy: 0.9240123820754716 \n",
      "Epoch 17 | Step 6661 | loss: 0.20516545874691905 | accuracy: 0.9242224178403756 \n",
      "Epoch 17 | Step 6662 | loss: 0.20510325546019545 | accuracy: 0.9242844626168224 \n",
      "Epoch 17 | Step 6663 | loss: 0.20517844322115875 | accuracy: 0.9242005813953489 \n",
      "Epoch 17 | Step 6664 | loss: 0.20561247953662165 | accuracy: 0.9239004629629629 \n",
      "Epoch 17 | Step 6665 | loss: 0.2059842470329478 | accuracy: 0.9238191244239631 \n",
      "Epoch 17 | Step 6666 | loss: 0.20588991791009903 | accuracy: 0.923881880733945 \n",
      "Epoch 17 | Step 6667 | loss: 0.2057524200307724 | accuracy: 0.9239440639269406 \n",
      "Epoch 17 | Step 6668 | loss: 0.20563436638225208 | accuracy: 0.9239346590909091 \n",
      "Epoch 17 | Step 6669 | loss: 0.20554933410424453 | accuracy: 0.9239960407239819 \n",
      "Epoch 17 | Step 6670 | loss: 0.2052670026550422 | accuracy: 0.9239864864864865 \n",
      "Epoch 17 | Step 6671 | loss: 0.20504713212160786 | accuracy: 0.9240470852017937 \n",
      "Epoch 17 | Step 6672 | loss: 0.20504708421815718 | accuracy: 0.9240373883928571 \n",
      "Epoch 17 | Step 6673 | loss: 0.20518855485651227 | accuracy: 0.9239583333333333 \n",
      "Epoch 17 | Step 6674 | loss: 0.20513894936416002 | accuracy: 0.9238799778761062 \n",
      "Epoch 17 | Step 6675 | loss: 0.20526357933813255 | accuracy: 0.9238023127753304 \n",
      "Epoch 17 | Step 6676 | loss: 0.20499852482686964 | accuracy: 0.9237938596491229 \n",
      "Epoch 17 | Step 6677 | loss: 0.20489783897410313 | accuracy: 0.923853711790393 \n",
      "Epoch 17 | Step 6678 | loss: 0.20495379819818166 | accuracy: 0.9237092391304348 \n",
      "Epoch 17 | Step 6679 | loss: 0.2048001242922498 | accuracy: 0.9237689393939394 \n",
      "Epoch 17 | Step 6680 | loss: 0.20447458660808102 | accuracy: 0.923895474137931 \n",
      "Epoch 17 | Step 6681 | loss: 0.20420262012870527 | accuracy: 0.9240879828326181 \n",
      "Epoch 17 | Step 6682 | loss: 0.20441156383763012 | accuracy: 0.9239449786324786 \n",
      "Epoch 17 | Step 6683 | loss: 0.20409732543407602 | accuracy: 0.9241356382978724 \n",
      "Epoch 17 | Step 6684 | loss: 0.20398778878783774 | accuracy: 0.9241260593220338 \n",
      "Epoch 17 | Step 6685 | loss: 0.20396923421555935 | accuracy: 0.9240506329113924 \n",
      "Epoch 17 | Step 6686 | loss: 0.20442608017630937 | accuracy: 0.9239758403361344 \n",
      "Epoch 17 | Step 6687 | loss: 0.20434858378755497 | accuracy: 0.923967050209205 \n",
      "Epoch 17 | Step 6688 | loss: 0.20428114707271258 | accuracy: 0.923828125 \n",
      "Epoch 17 | Step 6689 | loss: 0.2045532027220825 | accuracy: 0.9236255186721992 \n",
      "Epoch 17 | Step 6690 | loss: 0.20468864232794312 | accuracy: 0.9235537190082644 \n",
      "Epoch 17 | Step 6691 | loss: 0.20436229320710578 | accuracy: 0.923804012345679 \n",
      "Epoch 17 | Step 6692 | loss: 0.20391326135054963 | accuracy: 0.9240522540983607 \n",
      "Epoch 17 | Step 6693 | loss: 0.20354972703724492 | accuracy: 0.924170918367347 \n",
      "Epoch 17 | Step 6694 | loss: 0.20316293508541294 | accuracy: 0.9243521341463414 \n",
      "Epoch 17 | Step 6695 | loss: 0.20283965449704816 | accuracy: 0.9244686234817814 \n",
      "Epoch 17 | Step 6696 | loss: 0.20291705294362 | accuracy: 0.9243951612903226 \n",
      "Epoch 17 | Step 6697 | loss: 0.20302831423450188 | accuracy: 0.9243850401606426 \n",
      "Epoch 17 | Step 6698 | loss: 0.2027895808517933 | accuracy: 0.9244375 \n",
      "Epoch 17 | Step 6699 | loss: 0.202913372194862 | accuracy: 0.9244272908366534 \n",
      "Epoch 17 | Step 6700 | loss: 0.2033630825046982 | accuracy: 0.9242311507936508 \n",
      "Epoch 17 | Step 6701 | loss: 0.20335905722125244 | accuracy: 0.9242835968379447 \n",
      "Epoch 17 | Step 6702 | loss: 0.203125461847998 | accuracy: 0.9243356299212598 \n",
      "Epoch 17 | Step 6703 | loss: 0.20275279327350504 | accuracy: 0.9244485294117647 \n",
      "Epoch 17 | Step 6704 | loss: 0.20280203592847101 | accuracy: 0.92449951171875 \n",
      "Epoch 17 | Step 6705 | loss: 0.20278944315729439 | accuracy: 0.9245500972762646 \n",
      "Epoch 17 | Step 6706 | loss: 0.2027497082197851 | accuracy: 0.9245397286821705 \n",
      "Epoch 17 | Step 6707 | loss: 0.20282695873938933 | accuracy: 0.9245294401544402 \n",
      "Epoch 17 | Step 6708 | loss: 0.2027936645711844 | accuracy: 0.924639423076923 \n",
      "Epoch 17 | Step 6709 | loss: 0.2029204051442073 | accuracy: 0.9245090996168582 \n",
      "Epoch 17 | Step 6710 | loss: 0.20350002039593595 | accuracy: 0.9243201335877863 \n",
      "Epoch 17 | Step 6711 | loss: 0.20369845472927783 | accuracy: 0.9242514258555133 \n",
      "Epoch 17 | Step 6712 | loss: 0.2039602237725348 | accuracy: 0.9240056818181818 \n",
      "Epoch 17 | Step 6713 | loss: 0.20406305826497528 | accuracy: 0.923997641509434 \n",
      "Epoch 17 | Step 6714 | loss: 0.20411515025828117 | accuracy: 0.9239309210526315 \n",
      "Epoch 17 | Step 6715 | loss: 0.2040487238474553 | accuracy: 0.9239232209737828 \n",
      "Epoch 17 | Step 6716 | loss: 0.20482128099607888 | accuracy: 0.9236823694029851 \n",
      "Epoch 17 | Step 6717 | loss: 0.20461800769248417 | accuracy: 0.9237337360594795 \n",
      "Epoch 17 | Step 6718 | loss: 0.20475512607781976 | accuracy: 0.9236689814814815 \n",
      "Epoch 17 | Step 6719 | loss: 0.2045855538376583 | accuracy: 0.9237200184501845 \n",
      "Epoch 17 | Step 6720 | loss: 0.20456641882329302 | accuracy: 0.9236557904411765 \n",
      "Epoch 17 | Step 6721 | loss: 0.2043942359613848 | accuracy: 0.9237065018315018 \n",
      "Epoch 17 | Step 6722 | loss: 0.20433286868416478 | accuracy: 0.9235857664233577 \n",
      "Epoch 17 | Step 6723 | loss: 0.2044645646214485 | accuracy: 0.9234659090909091 \n",
      "Epoch 17 | Step 6724 | loss: 0.20452998467869515 | accuracy: 0.9234601449275363 \n",
      "Epoch 17 | Step 6725 | loss: 0.2046514831564056 | accuracy: 0.9233980144404332 \n",
      "Epoch 17 | Step 6726 | loss: 0.20434433693508447 | accuracy: 0.9235049460431655 \n",
      "Epoch 17 | Step 6727 | loss: 0.20472194580194342 | accuracy: 0.9234431003584229 \n",
      "Epoch 17 | Step 6728 | loss: 0.2045135553394045 | accuracy: 0.9234933035714286 \n",
      "Epoch 17 | Step 6729 | loss: 0.20431152458080615 | accuracy: 0.9237099644128114 \n",
      "Epoch 17 | Step 6730 | loss: 0.2042955397925478 | accuracy: 0.9235926418439716 \n",
      "Epoch 17 | Step 6731 | loss: 0.20424087719445513 | accuracy: 0.9235865724381626 \n",
      "Epoch 17 | Step 6732 | loss: 0.20414754339087174 | accuracy: 0.9236355633802817 \n",
      "Epoch 17 | Step 6733 | loss: 0.20411390641279387 | accuracy: 0.9235745614035088 \n",
      "Epoch 17 | Step 6734 | loss: 0.203878010955307 | accuracy: 0.9236232517482518 \n",
      "Epoch 17 | Step 6735 | loss: 0.20383532791810582 | accuracy: 0.9236171602787456 \n",
      "Epoch 17 | Step 6736 | loss: 0.20336064833423328 | accuracy: 0.923828125 \n",
      "Epoch 17 | Step 6737 | loss: 0.2033975714476051 | accuracy: 0.9238213667820069 \n",
      "Epoch 17 | Step 6738 | loss: 0.2036195714155148 | accuracy: 0.9238146551724138 \n",
      "Epoch 17 | Step 6739 | loss: 0.20393259667141742 | accuracy: 0.9238079896907216 \n",
      "Epoch 17 | Step 6740 | loss: 0.20376455444485359 | accuracy: 0.9238013698630136 \n",
      "Epoch 17 | Step 6741 | loss: 0.2039747840054206 | accuracy: 0.9236348122866894 \n",
      "Epoch 17 | Step 6742 | loss: 0.2037173292415888 | accuracy: 0.9236819727891157 \n",
      "Epoch 17 | Step 6743 | loss: 0.20355813586610857 | accuracy: 0.9237817796610169 \n",
      "Epoch 17 | Step 6744 | loss: 0.20373486478284403 | accuracy: 0.9237225506756757 \n",
      "Epoch 17 | Step 6745 | loss: 0.2034456248486082 | accuracy: 0.9238741582491582 \n",
      "Epoch 17 | Step 6746 | loss: 0.20378206922803946 | accuracy: 0.9238674496644296 \n",
      "Epoch 17 | Step 6747 | loss: 0.20360817595768133 | accuracy: 0.9239130434782609 \n",
      "Epoch 17 | Step 6748 | loss: 0.20333477646112438 | accuracy: 0.9239583333333333 \n",
      "Epoch 17 | Step 6749 | loss: 0.20323541136675097 | accuracy: 0.9240033222591362 \n",
      "Epoch 17 | Step 6750 | loss: 0.20305854175856564 | accuracy: 0.9240480132450332 \n",
      "Epoch 17 | Step 6751 | loss: 0.2030385371186945 | accuracy: 0.9240408415841584 \n",
      "Epoch 17 | Step 6752 | loss: 0.20300681987091107 | accuracy: 0.9239823190789473 \n",
      "Epoch 17 | Step 6753 | loss: 0.2028419898670227 | accuracy: 0.9240266393442623 \n",
      "Epoch 17 | Step 6754 | loss: 0.20285665175688805 | accuracy: 0.9240706699346405 \n",
      "Epoch 17 | Step 6755 | loss: 0.2030945001382392 | accuracy: 0.9240635179153095 \n",
      "Epoch 17 | Step 6756 | loss: 0.20289546604473863 | accuracy: 0.9241071428571429 \n",
      "Epoch 17 | Step 6757 | loss: 0.20273404209166276 | accuracy: 0.9242010517799353 \n",
      "Epoch 17 | Step 6758 | loss: 0.20291215705294757 | accuracy: 0.9241935483870968 \n",
      "Epoch 17 | Step 6759 | loss: 0.20299432328467962 | accuracy: 0.9242363344051447 \n",
      "Epoch 17 | Step 6760 | loss: 0.20283440963771093 | accuracy: 0.9243289262820513 \n",
      "Epoch 17 | Step 6761 | loss: 0.20288716699368653 | accuracy: 0.9243710063897763 \n",
      "Epoch 17 | Step 6762 | loss: 0.2034477958823465 | accuracy: 0.9241640127388535 \n",
      "Epoch 17 | Step 6763 | loss: 0.20399154084069385 | accuracy: 0.9239583333333333 \n",
      "Epoch 17 | Step 6764 | loss: 0.20404901775189588 | accuracy: 0.9239022943037974 \n",
      "Epoch 17 | Step 6765 | loss: 0.20369491613343682 | accuracy: 0.9240437697160884 \n",
      "Epoch 17 | Step 6766 | loss: 0.2037125764730966 | accuracy: 0.9240369496855346 \n",
      "Epoch 17 | Step 6767 | loss: 0.20379101358891277 | accuracy: 0.9240301724137931 \n",
      "Epoch 17 | Step 6768 | loss: 0.20367912466172125 | accuracy: 0.924072265625 \n",
      "Epoch 17 | Step 6769 | loss: 0.20366995549554762 | accuracy: 0.9241627725856698 \n",
      "Epoch 17 | Step 6770 | loss: 0.20421467885745234 | accuracy: 0.9240100931677019 \n",
      "Epoch 17 | Step 6771 | loss: 0.20395278407047404 | accuracy: 0.9241002321981424 \n",
      "Epoch 17 | Step 6772 | loss: 0.20382332877704387 | accuracy: 0.9241415895061729 \n",
      "Epoch 17 | Step 6773 | loss: 0.20408533199475357 | accuracy: 0.9240865384615384 \n",
      "Epoch 17 | Step 6774 | loss: 0.20411665287394462 | accuracy: 0.9241276840490797 \n",
      "Epoch 17 | Step 6775 | loss: 0.20415596634331823 | accuracy: 0.9240730122324159 \n",
      "Epoch 17 | Step 6776 | loss: 0.204148536252721 | accuracy: 0.9240663109756098 \n",
      "Epoch 17 | Step 6777 | loss: 0.20427842019267353 | accuracy: 0.9239171732522796 \n",
      "Epoch 17 | Step 6778 | loss: 0.2041744479853095 | accuracy: 0.9239583333333333 \n",
      "Epoch 17 | Step 6779 | loss: 0.20421944259246666 | accuracy: 0.9238104229607251 \n",
      "Epoch 17 | Step 6780 | loss: 0.204240908666727 | accuracy: 0.9239457831325302 \n",
      "Epoch 17 | Step 6781 | loss: 0.20426655829221274 | accuracy: 0.9239395645645646 \n",
      "Epoch 17 | Step 6782 | loss: 0.2044523536132838 | accuracy: 0.9238866017964071 \n",
      "Epoch 17 | Step 6783 | loss: 0.2043224459486221 | accuracy: 0.9239272388059702 \n",
      "Epoch 17 | Step 6784 | loss: 0.20430154501948325 | accuracy: 0.9238746279761905 \n",
      "Epoch 17 | Step 6785 | loss: 0.2041649562182341 | accuracy: 0.9238686943620178 \n",
      "Epoch 17 | Step 6786 | loss: 0.20436787078454646 | accuracy: 0.9238165680473372 \n",
      "Epoch 17 | Step 6787 | loss: 0.20418833550010806 | accuracy: 0.92390302359882 \n",
      "Epoch 17 | Step 6788 | loss: 0.2040807189967702 | accuracy: 0.9239889705882353 \n",
      "Epoch 17 | Step 6789 | loss: 0.20422229238531803 | accuracy: 0.9238453079178885 \n",
      "Epoch 17 | Step 6790 | loss: 0.2040543119853351 | accuracy: 0.9239309210526315 \n",
      "Epoch 17 | Step 6791 | loss: 0.2038773947093994 | accuracy: 0.9240615889212828 \n",
      "Epoch 17 | Step 6792 | loss: 0.20376972921279277 | accuracy: 0.9241006540697675 \n",
      "Epoch 17 | Step 6793 | loss: 0.20402793666158894 | accuracy: 0.9240942028985507 \n",
      "Epoch 17 | Step 6794 | loss: 0.20393841108576408 | accuracy: 0.924087789017341 \n",
      "Epoch 17 | Step 6795 | loss: 0.20363348140582568 | accuracy: 0.9242615273775217 \n",
      "Epoch 17 | Step 6796 | loss: 0.2040127245388154 | accuracy: 0.9241199712643678 \n",
      "Epoch 17 | Step 6797 | loss: 0.20384258080946335 | accuracy: 0.9241583094555874 \n",
      "Epoch 17 | Step 6798 | loss: 0.2036682726017066 | accuracy: 0.9242410714285715 \n",
      "Epoch 17 | Step 6799 | loss: 0.20347591532006898 | accuracy: 0.9243233618233618 \n",
      "Epoch 17 | Step 6800 | loss: 0.2035073185212571 | accuracy: 0.9243607954545454 \n",
      "Epoch 17 | Step 6801 | loss: 0.2035990532371545 | accuracy: 0.9243537535410765 \n",
      "Epoch 17 | Step 6802 | loss: 0.20337269476241307 | accuracy: 0.9244350282485876 \n",
      "Epoch 17 | Step 6803 | loss: 0.20334606367937272 | accuracy: 0.9243397887323944 \n",
      "Epoch 17 | Step 6804 | loss: 0.20313070526116345 | accuracy: 0.9243767556179775 \n",
      "Epoch 17 | Step 6805 | loss: 0.20304376721716055 | accuracy: 0.9244135154061625 \n",
      "Epoch 17 | Step 6806 | loss: 0.20311459611747515 | accuracy: 0.9243191340782123 \n",
      "Epoch 17 | Step 6807 | loss: 0.2029696190755679 | accuracy: 0.9243558495821727 \n",
      "Epoch 17 | Step 6808 | loss: 0.20305397618148058 | accuracy: 0.9243923611111111 \n",
      "Epoch 17 | Step 6809 | loss: 0.20286806249717593 | accuracy: 0.9244719529085873 \n",
      "Epoch 17 | Step 6810 | loss: 0.20308212874179382 | accuracy: 0.9244216160220995 \n",
      "Epoch 17 | Step 6811 | loss: 0.2031450758870311 | accuracy: 0.9244576446280992 \n",
      "Epoch 17 | Step 6812 | loss: 0.2030933999589511 | accuracy: 0.9245364010989011 \n",
      "Epoch 17 | Step 6813 | loss: 0.2030031757811977 | accuracy: 0.9245291095890411 \n",
      "Epoch 17 | Step 6814 | loss: 0.20290420143330679 | accuracy: 0.9245645491803278 \n",
      "Epoch 17 | Step 6815 | loss: 0.2026049642333867 | accuracy: 0.9246849455040872 \n",
      "Epoch 17 | Step 6816 | loss: 0.2028725068489818 | accuracy: 0.9246773097826086 \n",
      "Epoch 17 | Step 6817 | loss: 0.20288080685749282 | accuracy: 0.9247120596205962 \n",
      "Epoch 17 | Step 6818 | loss: 0.2032704954010409 | accuracy: 0.9245777027027027 \n",
      "Epoch 17 | Step 6819 | loss: 0.20354328722243678 | accuracy: 0.9244861859838275 \n",
      "Epoch 17 | Step 6820 | loss: 0.20373155230716347 | accuracy: 0.9243531586021505 \n",
      "Epoch 17 | Step 6821 | loss: 0.20387958383672036 | accuracy: 0.9243046246648794 \n",
      "Epoch 17 | Step 6822 | loss: 0.20411181710859666 | accuracy: 0.9242145721925134 \n",
      "Epoch 17 | Step 6823 | loss: 0.20387422740459438 | accuracy: 0.92425 \n",
      "Epoch 17 | Step 6824 | loss: 0.20370621678042916 | accuracy: 0.9242436835106383 \n",
      "Epoch 17 | Step 6825 | loss: 0.20343549071319536 | accuracy: 0.9243617374005305 \n",
      "Epoch 17 | Step 6826 | loss: 0.2038193297764611 | accuracy: 0.9241071428571429 \n",
      "Epoch 17 | Step 6827 | loss: 0.20385874336030047 | accuracy: 0.9241012532981531 \n",
      "Epoch 17 | Step 6828 | loss: 0.20358603608451387 | accuracy: 0.92421875 \n",
      "Epoch 17 | Step 6829 | loss: 0.2036161807969486 | accuracy: 0.9242536089238845 \n",
      "Epoch 17 | Step 6830 | loss: 0.20342681631055798 | accuracy: 0.9242882853403142 \n",
      "Epoch 17 | Step 6831 | loss: 0.2032847188160251 | accuracy: 0.9243227806788512 \n",
      "Epoch 17 | Step 6832 | loss: 0.20333399390801785 | accuracy: 0.9242350260416666 \n",
      "Epoch 17 | Step 6833 | loss: 0.2033923054283315 | accuracy: 0.9242288961038961 \n",
      "Epoch 17 | Step 6834 | loss: 0.20335980072385904 | accuracy: 0.9242227979274611 \n",
      "Epoch 17 | Step 6835 | loss: 0.20342536517045906 | accuracy: 0.9241763565891473 \n",
      "Epoch 17 | Step 6836 | loss: 0.20343413442066033 | accuracy: 0.9242106958762887 \n",
      "Epoch 17 | Step 6837 | loss: 0.20345101132031268 | accuracy: 0.9241243573264781 \n",
      "Epoch 17 | Step 6838 | loss: 0.20347148604117904 | accuracy: 0.9240785256410257 \n",
      "Epoch 17 | Step 6839 | loss: 0.20350701718226719 | accuracy: 0.9240728900255755 \n",
      "Epoch 17 | Step 6840 | loss: 0.20339094995692064 | accuracy: 0.9241071428571429 \n",
      "Epoch 17 | Step 6841 | loss: 0.20338446682949402 | accuracy: 0.9241412213740458 \n",
      "Epoch 17 | Step 6842 | loss: 0.20343658275108042 | accuracy: 0.9241354695431472 \n",
      "Epoch 17 | Step 6843 | loss: 0.20337938613529444 | accuracy: 0.9242088607594937 \n",
      "Epoch 17 | Step 6844 | loss: 0.20321799167478924 | accuracy: 0.9243213383838383 \n",
      "Epoch 17 | Step 6845 | loss: 0.2029398869845068 | accuracy: 0.924433249370277 \n",
      "Epoch 17 | Step 6846 | loss: 0.20302527437183124 | accuracy: 0.9243090452261307 \n",
      "Epoch 17 | Step 6847 | loss: 0.20310910216026135 | accuracy: 0.9243421052631579 \n",
      "Epoch 17 | Step 6848 | loss: 0.20333707036450502 | accuracy: 0.9242578125 \n",
      "Epoch 17 | Step 6849 | loss: 0.20321760441819922 | accuracy: 0.9243298004987531 \n",
      "Epoch 17 | Step 6850 | loss: 0.20362622403905756 | accuracy: 0.9241682213930348 \n",
      "Epoch 17 | Step 6851 | loss: 0.20335524627203974 | accuracy: 0.9242708243743953 \n",
      "Validation | Epoch 17 | Step 6851 | accuracy: 0.8543570895086635 \n",
      "Epoch 18 | Step 6852 | loss: 0.16438910365104675 | accuracy: 0.953125 \n",
      "Epoch 18 | Step 6853 | loss: 0.24614983797073364 | accuracy: 0.8984375 \n",
      "Epoch 18 | Step 6854 | loss: 0.21138707796732584 | accuracy: 0.9166666666666666 \n",
      "Epoch 18 | Step 6855 | loss: 0.22171539068222046 | accuracy: 0.91796875 \n",
      "Epoch 18 | Step 6856 | loss: 0.2161155343055725 | accuracy: 0.921875 \n",
      "Epoch 18 | Step 6857 | loss: 0.223409836490949 | accuracy: 0.9140625 \n",
      "Epoch 18 | Step 6858 | loss: 0.23105020182473318 | accuracy: 0.9129464285714286 \n",
      "Epoch 18 | Step 6859 | loss: 0.23856619000434875 | accuracy: 0.9140625 \n",
      "Epoch 18 | Step 6860 | loss: 0.23059583538108402 | accuracy: 0.9131944444444444 \n",
      "Epoch 18 | Step 6861 | loss: 0.23076486885547637 | accuracy: 0.9109375 \n",
      "Epoch 18 | Step 6862 | loss: 0.224761732599952 | accuracy: 0.9133522727272727 \n",
      "Epoch 18 | Step 6863 | loss: 0.22838823000590006 | accuracy: 0.9114583333333334 \n",
      "Epoch 18 | Step 6864 | loss: 0.22602335306314322 | accuracy: 0.9134615384615384 \n",
      "Epoch 18 | Step 6865 | loss: 0.22304212621280126 | accuracy: 0.9151785714285714 \n",
      "Epoch 18 | Step 6866 | loss: 0.2134081616997719 | accuracy: 0.9197916666666667 \n",
      "Epoch 18 | Step 6867 | loss: 0.2097383108921349 | accuracy: 0.921875 \n",
      "Epoch 18 | Step 6868 | loss: 0.21196698485051885 | accuracy: 0.9227941176470589 \n",
      "Epoch 18 | Step 6869 | loss: 0.20937676520811188 | accuracy: 0.9201388888888888 \n",
      "Epoch 18 | Step 6870 | loss: 0.2109433228248044 | accuracy: 0.9210526315789473 \n",
      "Epoch 18 | Step 6871 | loss: 0.2079714197665453 | accuracy: 0.921875 \n",
      "Epoch 18 | Step 6872 | loss: 0.20427976513192767 | accuracy: 0.9226190476190477 \n",
      "Epoch 18 | Step 6873 | loss: 0.20307347415523094 | accuracy: 0.921875 \n",
      "Epoch 18 | Step 6874 | loss: 0.20330982979225076 | accuracy: 0.920516304347826 \n",
      "Epoch 18 | Step 6875 | loss: 0.19887916930019855 | accuracy: 0.921875 \n",
      "Epoch 18 | Step 6876 | loss: 0.19686951339244843 | accuracy: 0.9225 \n",
      "Epoch 18 | Step 6877 | loss: 0.1962759099327601 | accuracy: 0.9230769230769231 \n",
      "Epoch 18 | Step 6878 | loss: 0.19657421443197462 | accuracy: 0.9224537037037037 \n",
      "Epoch 18 | Step 6879 | loss: 0.19365357447947776 | accuracy: 0.9241071428571429 \n",
      "Epoch 18 | Step 6880 | loss: 0.19109073461129747 | accuracy: 0.9251077586206896 \n",
      "Epoch 18 | Step 6881 | loss: 0.19337186291813852 | accuracy: 0.9239583333333333 \n",
      "Epoch 18 | Step 6882 | loss: 0.19299940404392057 | accuracy: 0.9248991935483871 \n",
      "Epoch 18 | Step 6883 | loss: 0.194101047469303 | accuracy: 0.9248046875 \n",
      "Epoch 18 | Step 6884 | loss: 0.19570453848802682 | accuracy: 0.9242424242424242 \n",
      "Epoch 18 | Step 6885 | loss: 0.1938685939154204 | accuracy: 0.9246323529411765 \n",
      "Epoch 18 | Step 6886 | loss: 0.19072756086077008 | accuracy: 0.9263392857142857 \n",
      "Epoch 18 | Step 6887 | loss: 0.19130494197209677 | accuracy: 0.9266493055555556 \n",
      "Epoch 18 | Step 6888 | loss: 0.18971621587469772 | accuracy: 0.9269425675675675 \n",
      "Epoch 18 | Step 6889 | loss: 0.1910575440055446 | accuracy: 0.9263980263157895 \n",
      "Epoch 18 | Step 6890 | loss: 0.19069359585260737 | accuracy: 0.9262820512820513 \n",
      "Epoch 18 | Step 6891 | loss: 0.19060659669339658 | accuracy: 0.926171875 \n",
      "Epoch 18 | Step 6892 | loss: 0.1893351790381641 | accuracy: 0.926829268292683 \n",
      "Epoch 18 | Step 6893 | loss: 0.19195873609610967 | accuracy: 0.9259672619047619 \n",
      "Epoch 18 | Step 6894 | loss: 0.1918134328930877 | accuracy: 0.9251453488372093 \n",
      "Epoch 18 | Step 6895 | loss: 0.19024139490317216 | accuracy: 0.9254261363636364 \n",
      "Epoch 18 | Step 6896 | loss: 0.19174796657429802 | accuracy: 0.9246527777777778 \n",
      "Epoch 18 | Step 6897 | loss: 0.19191928580403328 | accuracy: 0.9245923913043478 \n",
      "Epoch 18 | Step 6898 | loss: 0.19164125954217098 | accuracy: 0.9245345744680851 \n",
      "Epoch 18 | Step 6899 | loss: 0.1929066626665493 | accuracy: 0.9244791666666666 \n",
      "Epoch 18 | Step 6900 | loss: 0.1919393696042956 | accuracy: 0.9250637755102041 \n",
      "Epoch 18 | Step 6901 | loss: 0.19404198929667474 | accuracy: 0.925 \n",
      "Epoch 18 | Step 6902 | loss: 0.19775141614909267 | accuracy: 0.9237132352941176 \n",
      "Epoch 18 | Step 6903 | loss: 0.19812734897893208 | accuracy: 0.9236778846153846 \n",
      "Epoch 18 | Step 6904 | loss: 0.19629188444254533 | accuracy: 0.9245283018867925 \n",
      "Epoch 18 | Step 6905 | loss: 0.19527910263450057 | accuracy: 0.9244791666666666 \n",
      "Epoch 18 | Step 6906 | loss: 0.19611549431627448 | accuracy: 0.9235795454545455 \n",
      "Epoch 18 | Step 6907 | loss: 0.19713369650500162 | accuracy: 0.9235491071428571 \n",
      "Epoch 18 | Step 6908 | loss: 0.19729850166722349 | accuracy: 0.9240679824561403 \n",
      "Epoch 18 | Step 6909 | loss: 0.1978251800454896 | accuracy: 0.9240301724137931 \n",
      "Epoch 18 | Step 6910 | loss: 0.19892069293280779 | accuracy: 0.923728813559322 \n",
      "Epoch 18 | Step 6911 | loss: 0.19998350391785305 | accuracy: 0.92421875 \n",
      "Epoch 18 | Step 6912 | loss: 0.20007558166980743 | accuracy: 0.9244364754098361 \n",
      "Epoch 18 | Step 6913 | loss: 0.19923552798648034 | accuracy: 0.9241431451612904 \n",
      "Epoch 18 | Step 6914 | loss: 0.19921047465195732 | accuracy: 0.9241071428571429 \n",
      "Epoch 18 | Step 6915 | loss: 0.19743518787436187 | accuracy: 0.9248046875 \n",
      "Epoch 18 | Step 6916 | loss: 0.19797824644125425 | accuracy: 0.9245192307692308 \n",
      "Epoch 18 | Step 6917 | loss: 0.1964538787124735 | accuracy: 0.9251893939393939 \n",
      "Epoch 18 | Step 6918 | loss: 0.19553168284804073 | accuracy: 0.925839552238806 \n",
      "Epoch 18 | Step 6919 | loss: 0.19511267247007175 | accuracy: 0.9260110294117647 \n",
      "Epoch 18 | Step 6920 | loss: 0.19639764844939328 | accuracy: 0.9254981884057971 \n",
      "Epoch 18 | Step 6921 | loss: 0.1967064092201846 | accuracy: 0.9254464285714286 \n",
      "Epoch 18 | Step 6922 | loss: 0.19663333126776655 | accuracy: 0.9256161971830986 \n",
      "Epoch 18 | Step 6923 | loss: 0.19587875250726938 | accuracy: 0.9259982638888888 \n",
      "Epoch 18 | Step 6924 | loss: 0.1958587721806683 | accuracy: 0.9261558219178082 \n",
      "Epoch 18 | Step 6925 | loss: 0.1964525901586623 | accuracy: 0.925464527027027 \n",
      "Epoch 18 | Step 6926 | loss: 0.1977323666214943 | accuracy: 0.9247916666666667 \n",
      "Epoch 18 | Step 6927 | loss: 0.1966531950196153 | accuracy: 0.9247532894736842 \n",
      "Epoch 18 | Step 6928 | loss: 0.19616387658692025 | accuracy: 0.9251217532467533 \n",
      "Epoch 18 | Step 6929 | loss: 0.19749016916522613 | accuracy: 0.9244791666666666 \n",
      "Epoch 18 | Step 6930 | loss: 0.1967702184485484 | accuracy: 0.9250395569620253 \n",
      "Epoch 18 | Step 6931 | loss: 0.19719086950644854 | accuracy: 0.925 \n",
      "Epoch 18 | Step 6932 | loss: 0.19692448563413859 | accuracy: 0.9251543209876543 \n",
      "Epoch 18 | Step 6933 | loss: 0.19607348658326196 | accuracy: 0.9256859756097561 \n",
      "Epoch 18 | Step 6934 | loss: 0.1967345453709005 | accuracy: 0.9256400602409639 \n",
      "Epoch 18 | Step 6935 | loss: 0.1975618667368378 | accuracy: 0.9255952380952381 \n",
      "Epoch 18 | Step 6936 | loss: 0.19893840682857178 | accuracy: 0.925 \n",
      "Epoch 18 | Step 6937 | loss: 0.19844955353196278 | accuracy: 0.9256904069767442 \n",
      "Epoch 18 | Step 6938 | loss: 0.19839008914670725 | accuracy: 0.9256465517241379 \n",
      "Epoch 18 | Step 6939 | loss: 0.19934340524063868 | accuracy: 0.92578125 \n",
      "Epoch 18 | Step 6940 | loss: 0.19899623271789443 | accuracy: 0.9259129213483146 \n",
      "Epoch 18 | Step 6941 | loss: 0.20050835866067146 | accuracy: 0.9255208333333333 \n",
      "Epoch 18 | Step 6942 | loss: 0.19978875257484205 | accuracy: 0.9256524725274725 \n",
      "Epoch 18 | Step 6943 | loss: 0.20143447630107403 | accuracy: 0.9254415760869565 \n",
      "Epoch 18 | Step 6944 | loss: 0.20150267316769527 | accuracy: 0.9250672043010753 \n",
      "Epoch 18 | Step 6945 | loss: 0.20083695356833173 | accuracy: 0.9251994680851063 \n",
      "Epoch 18 | Step 6946 | loss: 0.19945409862618696 | accuracy: 0.9258223684210526 \n",
      "Epoch 18 | Step 6947 | loss: 0.1989580881781876 | accuracy: 0.9259440104166666 \n",
      "Epoch 18 | Step 6948 | loss: 0.19842654574163182 | accuracy: 0.9263853092783505 \n",
      "Epoch 18 | Step 6949 | loss: 0.20048585093143034 | accuracy: 0.9260204081632653 \n",
      "Epoch 18 | Step 6950 | loss: 0.19963678168226975 | accuracy: 0.9262941919191919 \n",
      "Epoch 18 | Step 6951 | loss: 0.1993545449525118 | accuracy: 0.92609375 \n",
      "Epoch 18 | Step 6952 | loss: 0.19899410400355216 | accuracy: 0.9260519801980198 \n",
      "Epoch 18 | Step 6953 | loss: 0.19880036754058858 | accuracy: 0.9260110294117647 \n",
      "Epoch 18 | Step 6954 | loss: 0.1990611982143041 | accuracy: 0.9259708737864077 \n",
      "Epoch 18 | Step 6955 | loss: 0.1990771760017826 | accuracy: 0.92578125 \n",
      "Epoch 18 | Step 6956 | loss: 0.19909300683509737 | accuracy: 0.9254464285714286 \n",
      "Epoch 18 | Step 6957 | loss: 0.19822244634324648 | accuracy: 0.9258549528301887 \n",
      "Epoch 18 | Step 6958 | loss: 0.19975299931296678 | accuracy: 0.9250876168224299 \n",
      "Epoch 18 | Step 6959 | loss: 0.20068357395077194 | accuracy: 0.9250578703703703 \n",
      "Epoch 18 | Step 6960 | loss: 0.19981872741508921 | accuracy: 0.9253153669724771 \n",
      "Epoch 18 | Step 6961 | loss: 0.19970421987501058 | accuracy: 0.9255681818181818 \n",
      "Epoch 18 | Step 6962 | loss: 0.20001357438059542 | accuracy: 0.9253941441441441 \n",
      "Epoch 18 | Step 6963 | loss: 0.20094422111287713 | accuracy: 0.9249441964285714 \n",
      "Epoch 18 | Step 6964 | loss: 0.20190424749017816 | accuracy: 0.9247787610619469 \n",
      "Epoch 18 | Step 6965 | loss: 0.20179832746323786 | accuracy: 0.924890350877193 \n",
      "Epoch 18 | Step 6966 | loss: 0.20096999419772107 | accuracy: 0.9252717391304348 \n",
      "Epoch 18 | Step 6967 | loss: 0.2008195636344367 | accuracy: 0.9252424568965517 \n",
      "Epoch 18 | Step 6968 | loss: 0.20074516305556664 | accuracy: 0.9249465811965812 \n",
      "Epoch 18 | Step 6969 | loss: 0.20083839673612078 | accuracy: 0.9247881355932204 \n",
      "Epoch 18 | Step 6970 | loss: 0.20100598087330826 | accuracy: 0.9247636554621849 \n",
      "Epoch 18 | Step 6971 | loss: 0.20102110430598258 | accuracy: 0.9248697916666667 \n",
      "Epoch 18 | Step 6972 | loss: 0.2002660516372397 | accuracy: 0.9252324380165289 \n",
      "Epoch 18 | Step 6973 | loss: 0.1998885131028832 | accuracy: 0.9252049180327869 \n",
      "Epoch 18 | Step 6974 | loss: 0.19982526227226102 | accuracy: 0.9253048780487805 \n",
      "Epoch 18 | Step 6975 | loss: 0.2000905646672172 | accuracy: 0.9255292338709677 \n",
      "Epoch 18 | Step 6976 | loss: 0.19967042696475984 | accuracy: 0.92575 \n",
      "Epoch 18 | Step 6977 | loss: 0.1996013546983401 | accuracy: 0.925719246031746 \n",
      "Epoch 18 | Step 6978 | loss: 0.20093775112328566 | accuracy: 0.9251968503937008 \n",
      "Epoch 18 | Step 6979 | loss: 0.20090223709121346 | accuracy: 0.9254150390625 \n",
      "Epoch 18 | Step 6980 | loss: 0.20013770022133523 | accuracy: 0.9257509689922481 \n",
      "Epoch 18 | Step 6981 | loss: 0.20078913959173056 | accuracy: 0.9252403846153846 \n",
      "Epoch 18 | Step 6982 | loss: 0.20084949690877027 | accuracy: 0.9254532442748091 \n",
      "Epoch 18 | Step 6983 | loss: 0.2002682824139342 | accuracy: 0.9256628787878788 \n",
      "Epoch 18 | Step 6984 | loss: 0.199697874710524 | accuracy: 0.9258693609022557 \n",
      "Epoch 18 | Step 6985 | loss: 0.19933393503080554 | accuracy: 0.9260727611940298 \n",
      "Epoch 18 | Step 6986 | loss: 0.1998473016752137 | accuracy: 0.9260416666666667 \n",
      "Epoch 18 | Step 6987 | loss: 0.20020457417430246 | accuracy: 0.9261259191176471 \n",
      "Epoch 18 | Step 6988 | loss: 0.1999795267725513 | accuracy: 0.9263229927007299 \n",
      "Epoch 18 | Step 6989 | loss: 0.19955821815824162 | accuracy: 0.9265172101449275 \n",
      "Epoch 18 | Step 6990 | loss: 0.19994599361428253 | accuracy: 0.9259217625899281 \n",
      "Epoch 18 | Step 6991 | loss: 0.1995309406625373 | accuracy: 0.9261160714285714 \n",
      "Epoch 18 | Step 6992 | loss: 0.19946863016126848 | accuracy: 0.9260859929078015 \n",
      "Epoch 18 | Step 6993 | loss: 0.19890099774364015 | accuracy: 0.9262764084507042 \n",
      "Epoch 18 | Step 6994 | loss: 0.19874085381731288 | accuracy: 0.9264641608391608 \n",
      "Epoch 18 | Step 6995 | loss: 0.19795443029660317 | accuracy: 0.9268663194444444 \n",
      "Epoch 18 | Step 6996 | loss: 0.19781787904172107 | accuracy: 0.9268318965517242 \n",
      "Epoch 18 | Step 6997 | loss: 0.19889673891745202 | accuracy: 0.926583904109589 \n",
      "Epoch 18 | Step 6998 | loss: 0.19847569908617305 | accuracy: 0.9268707482993197 \n",
      "Epoch 18 | Step 6999 | loss: 0.19805033771774253 | accuracy: 0.9270481418918919 \n",
      "Epoch 18 | Step 7000 | loss: 0.19770807252834308 | accuracy: 0.9272231543624161 \n",
      "Epoch 18 | Step 7001 | loss: 0.19755306258797645 | accuracy: 0.9273958333333333 \n",
      "Epoch 18 | Step 7002 | loss: 0.19751051546919424 | accuracy: 0.9272557947019867 \n",
      "Epoch 18 | Step 7003 | loss: 0.19767858092918209 | accuracy: 0.9274259868421053 \n",
      "Epoch 18 | Step 7004 | loss: 0.1975742093975248 | accuracy: 0.9274918300653595 \n",
      "Epoch 18 | Step 7005 | loss: 0.1974430965235481 | accuracy: 0.9275568181818182 \n",
      "Epoch 18 | Step 7006 | loss: 0.19698600966122842 | accuracy: 0.9276209677419355 \n",
      "Epoch 18 | Step 7007 | loss: 0.19647362914222938 | accuracy: 0.9278846153846154 \n",
      "Epoch 18 | Step 7008 | loss: 0.1959844214521396 | accuracy: 0.9281449044585988 \n",
      "Epoch 18 | Step 7009 | loss: 0.19601851494251926 | accuracy: 0.928006329113924 \n",
      "Epoch 18 | Step 7010 | loss: 0.1958873836124468 | accuracy: 0.9278694968553459 \n",
      "Epoch 18 | Step 7011 | loss: 0.19593598693609238 | accuracy: 0.927734375 \n",
      "Epoch 18 | Step 7012 | loss: 0.19588364781059833 | accuracy: 0.9276979813664596 \n",
      "Epoch 18 | Step 7013 | loss: 0.19660147417474677 | accuracy: 0.9276620370370371 \n",
      "Epoch 18 | Step 7014 | loss: 0.19594266192496188 | accuracy: 0.9279141104294478 \n",
      "Epoch 18 | Step 7015 | loss: 0.1957750115543604 | accuracy: 0.9280678353658537 \n",
      "Epoch 18 | Step 7016 | loss: 0.195796653221954 | accuracy: 0.928030303030303 \n",
      "Epoch 18 | Step 7017 | loss: 0.1968636895608471 | accuracy: 0.927710843373494 \n",
      "Epoch 18 | Step 7018 | loss: 0.19629384746808493 | accuracy: 0.9279565868263473 \n",
      "Epoch 18 | Step 7019 | loss: 0.19596370460376852 | accuracy: 0.9281063988095238 \n",
      "Epoch 18 | Step 7020 | loss: 0.19703427706597118 | accuracy: 0.9276997041420119 \n",
      "Epoch 18 | Step 7021 | loss: 0.19671286949340036 | accuracy: 0.9278492647058824 \n",
      "Epoch 18 | Step 7022 | loss: 0.19697570983777968 | accuracy: 0.9279057017543859 \n",
      "Epoch 18 | Step 7023 | loss: 0.19744990965308146 | accuracy: 0.9276889534883721 \n",
      "Epoch 18 | Step 7024 | loss: 0.1967223178530704 | accuracy: 0.9279263005780347 \n",
      "Epoch 18 | Step 7025 | loss: 0.19689177571870814 | accuracy: 0.9278915229885057 \n",
      "Epoch 18 | Step 7026 | loss: 0.19624510441507612 | accuracy: 0.928125 \n",
      "Epoch 18 | Step 7027 | loss: 0.19618242386389861 | accuracy: 0.9280894886363636 \n",
      "Epoch 18 | Step 7028 | loss: 0.19659711782541653 | accuracy: 0.927877824858757 \n",
      "Epoch 18 | Step 7029 | loss: 0.19631305203009186 | accuracy: 0.9278441011235955 \n",
      "Epoch 18 | Step 7030 | loss: 0.19641319291884674 | accuracy: 0.9277234636871509 \n",
      "Epoch 18 | Step 7031 | loss: 0.19696089517739085 | accuracy: 0.9276909722222222 \n",
      "Epoch 18 | Step 7032 | loss: 0.19672266332154775 | accuracy: 0.9275725138121547 \n",
      "Epoch 18 | Step 7033 | loss: 0.19638515386607622 | accuracy: 0.9277129120879121 \n",
      "Epoch 18 | Step 7034 | loss: 0.19625992600709363 | accuracy: 0.9277663934426229 \n",
      "Epoch 18 | Step 7035 | loss: 0.19624737496285335 | accuracy: 0.927734375 \n",
      "Epoch 18 | Step 7036 | loss: 0.19636415347859665 | accuracy: 0.9276182432432433 \n",
      "Epoch 18 | Step 7037 | loss: 0.1959046373364105 | accuracy: 0.9278393817204301 \n",
      "Epoch 18 | Step 7038 | loss: 0.1961062558911701 | accuracy: 0.9279745989304813 \n",
      "Epoch 18 | Step 7039 | loss: 0.1960695344320637 | accuracy: 0.9279421542553191 \n",
      "Epoch 18 | Step 7040 | loss: 0.19564799802801597 | accuracy: 0.9280753968253969 \n",
      "Epoch 18 | Step 7041 | loss: 0.19554196560853407 | accuracy: 0.9282072368421053 \n",
      "Epoch 18 | Step 7042 | loss: 0.19564690230248485 | accuracy: 0.9280104712041884 \n",
      "Epoch 18 | Step 7043 | loss: 0.1956652047811076 | accuracy: 0.9278971354166666 \n",
      "Epoch 18 | Step 7044 | loss: 0.1953367572760335 | accuracy: 0.9281088082901554 \n",
      "Epoch 18 | Step 7045 | loss: 0.19516677874111638 | accuracy: 0.9281572164948454 \n",
      "Epoch 18 | Step 7046 | loss: 0.19533638071555356 | accuracy: 0.928125 \n",
      "Epoch 18 | Step 7047 | loss: 0.1952264532826993 | accuracy: 0.928093112244898 \n",
      "Epoch 18 | Step 7048 | loss: 0.19522317771227832 | accuracy: 0.9278236040609137 \n",
      "Epoch 18 | Step 7049 | loss: 0.19510263998550598 | accuracy: 0.9277935606060606 \n",
      "Epoch 18 | Step 7050 | loss: 0.19517159428279005 | accuracy: 0.9279208542713567 \n",
      "Epoch 18 | Step 7051 | loss: 0.19512998055666686 | accuracy: 0.927890625 \n",
      "Epoch 18 | Step 7052 | loss: 0.19517171616429713 | accuracy: 0.927782960199005 \n",
      "Epoch 18 | Step 7053 | loss: 0.1951553910454311 | accuracy: 0.9277537128712872 \n",
      "Epoch 18 | Step 7054 | loss: 0.19535756158858097 | accuracy: 0.9276477832512315 \n",
      "Epoch 18 | Step 7055 | loss: 0.1955579499184501 | accuracy: 0.9274662990196079 \n",
      "Epoch 18 | Step 7056 | loss: 0.19562724977731705 | accuracy: 0.9276676829268292 \n",
      "Epoch 18 | Step 7057 | loss: 0.19578466025515667 | accuracy: 0.9274120145631068 \n",
      "Epoch 18 | Step 7058 | loss: 0.19553029072889383 | accuracy: 0.927536231884058 \n",
      "Epoch 18 | Step 7059 | loss: 0.19518463446113926 | accuracy: 0.9276592548076923 \n",
      "Epoch 18 | Step 7060 | loss: 0.1952435053778037 | accuracy: 0.9276315789473685 \n",
      "Epoch 18 | Step 7061 | loss: 0.19478148151011693 | accuracy: 0.9278273809523809 \n",
      "Epoch 18 | Step 7062 | loss: 0.19458192247915043 | accuracy: 0.928021327014218 \n",
      "Epoch 18 | Step 7063 | loss: 0.19448775720765005 | accuracy: 0.9281397405660378 \n",
      "Epoch 18 | Step 7064 | loss: 0.19405692682859482 | accuracy: 0.9284037558685446 \n",
      "Epoch 18 | Step 7065 | loss: 0.19403753116309086 | accuracy: 0.9285922897196262 \n",
      "Epoch 18 | Step 7066 | loss: 0.19412637179674105 | accuracy: 0.9285610465116279 \n",
      "Epoch 18 | Step 7067 | loss: 0.19450607005920675 | accuracy: 0.9283854166666666 \n",
      "Epoch 18 | Step 7068 | loss: 0.19483140598519058 | accuracy: 0.928211405529954 \n",
      "Epoch 18 | Step 7069 | loss: 0.19475787556772933 | accuracy: 0.9282540137614679 \n",
      "Epoch 18 | Step 7070 | loss: 0.1945594368187804 | accuracy: 0.9282962328767124 \n",
      "Epoch 18 | Step 7071 | loss: 0.19430774436755613 | accuracy: 0.928409090909091 \n",
      "Epoch 18 | Step 7072 | loss: 0.19415968299181752 | accuracy: 0.9285209276018099 \n",
      "Epoch 18 | Step 7073 | loss: 0.19388204557938618 | accuracy: 0.9285613738738738 \n",
      "Epoch 18 | Step 7074 | loss: 0.19363544954847328 | accuracy: 0.9286014573991032 \n",
      "Epoch 18 | Step 7075 | loss: 0.193578134290874 | accuracy: 0.9285714285714286 \n",
      "Epoch 18 | Step 7076 | loss: 0.19374960992071363 | accuracy: 0.9284722222222223 \n",
      "Epoch 18 | Step 7077 | loss: 0.19362661526002714 | accuracy: 0.9284430309734514 \n",
      "Epoch 18 | Step 7078 | loss: 0.19371859571744693 | accuracy: 0.9284140969162996 \n",
      "Epoch 18 | Step 7079 | loss: 0.1934346440983446 | accuracy: 0.928453947368421 \n",
      "Epoch 18 | Step 7080 | loss: 0.19345046833613033 | accuracy: 0.9285616812227074 \n",
      "Epoch 18 | Step 7081 | loss: 0.19343399580406107 | accuracy: 0.9286005434782608 \n",
      "Epoch 18 | Step 7082 | loss: 0.19342986749106156 | accuracy: 0.9286390692640693 \n",
      "Epoch 18 | Step 7083 | loss: 0.1931206164881587 | accuracy: 0.9287446120689655 \n",
      "Epoch 18 | Step 7084 | loss: 0.19287431754907314 | accuracy: 0.9289163090128756 \n",
      "Epoch 18 | Step 7085 | loss: 0.1931231586405864 | accuracy: 0.9288194444444444 \n",
      "Epoch 18 | Step 7086 | loss: 0.1927937958785828 | accuracy: 0.9289893617021276 \n",
      "Epoch 18 | Step 7087 | loss: 0.19264850673912945 | accuracy: 0.9290254237288136 \n",
      "Epoch 18 | Step 7088 | loss: 0.19258049938371916 | accuracy: 0.9290611814345991 \n",
      "Epoch 18 | Step 7089 | loss: 0.19301322268462984 | accuracy: 0.9290309873949579 \n",
      "Epoch 18 | Step 7090 | loss: 0.1929220410383396 | accuracy: 0.9290010460251046 \n",
      "Epoch 18 | Step 7091 | loss: 0.19287786145384114 | accuracy: 0.9288411458333333 \n",
      "Epoch 18 | Step 7092 | loss: 0.1931230832370485 | accuracy: 0.9285529045643154 \n",
      "Epoch 18 | Step 7093 | loss: 0.1933093089764276 | accuracy: 0.9283961776859504 \n",
      "Epoch 18 | Step 7094 | loss: 0.19301792832068454 | accuracy: 0.9286265432098766 \n",
      "Epoch 18 | Step 7095 | loss: 0.19255894382835412 | accuracy: 0.9287909836065574 \n",
      "Epoch 18 | Step 7096 | loss: 0.19220957503635056 | accuracy: 0.9288265306122448 \n",
      "Epoch 18 | Step 7097 | loss: 0.1918133755585527 | accuracy: 0.9289253048780488 \n",
      "Epoch 18 | Step 7098 | loss: 0.19149006474838565 | accuracy: 0.9290232793522267 \n",
      "Epoch 18 | Step 7099 | loss: 0.19153264321146474 | accuracy: 0.9289944556451613 \n",
      "Epoch 18 | Step 7100 | loss: 0.19170570541098414 | accuracy: 0.9289031124497992 \n",
      "Epoch 18 | Step 7101 | loss: 0.19136032781004905 | accuracy: 0.9290625 \n",
      "Epoch 18 | Step 7102 | loss: 0.1914420684435928 | accuracy: 0.9289716135458167 \n",
      "Epoch 18 | Step 7103 | loss: 0.19181320186527 | accuracy: 0.9288194444444444 \n",
      "Epoch 18 | Step 7104 | loss: 0.19184391344842233 | accuracy: 0.9287919960474308 \n",
      "Epoch 18 | Step 7105 | loss: 0.1916041952359864 | accuracy: 0.9288877952755905 \n",
      "Epoch 18 | Step 7106 | loss: 0.19126384264113858 | accuracy: 0.928921568627451 \n",
      "Epoch 18 | Step 7107 | loss: 0.191285828826949 | accuracy: 0.928955078125 \n",
      "Epoch 18 | Step 7108 | loss: 0.19124129878407786 | accuracy: 0.9289883268482491 \n",
      "Epoch 18 | Step 7109 | loss: 0.1912896164165911 | accuracy: 0.9289607558139535 \n",
      "Epoch 18 | Step 7110 | loss: 0.19131395197743153 | accuracy: 0.9289333976833977 \n",
      "Epoch 18 | Step 7111 | loss: 0.19133270743947764 | accuracy: 0.9289663461538461 \n",
      "Epoch 18 | Step 7112 | loss: 0.19144259872792782 | accuracy: 0.9288793103448276 \n",
      "Epoch 18 | Step 7113 | loss: 0.19197881386707757 | accuracy: 0.9286736641221374 \n",
      "Epoch 18 | Step 7114 | loss: 0.19228025086705675 | accuracy: 0.9285884030418251 \n",
      "Epoch 18 | Step 7115 | loss: 0.1924705673573595 | accuracy: 0.9284446022727273 \n",
      "Epoch 18 | Step 7116 | loss: 0.19256556011595816 | accuracy: 0.9284198113207547 \n",
      "Epoch 18 | Step 7117 | loss: 0.19266747296752787 | accuracy: 0.9282777255639098 \n",
      "Epoch 18 | Step 7118 | loss: 0.19263764523834773 | accuracy: 0.928253745318352 \n",
      "Epoch 18 | Step 7119 | loss: 0.1933395657966386 | accuracy: 0.9279967350746269 \n",
      "Epoch 18 | Step 7120 | loss: 0.1931322436350429 | accuracy: 0.928032063197026 \n",
      "Epoch 18 | Step 7121 | loss: 0.1933274843626552 | accuracy: 0.9279513888888888 \n",
      "Epoch 18 | Step 7122 | loss: 0.19314235003452018 | accuracy: 0.9279866236162362 \n",
      "Epoch 18 | Step 7123 | loss: 0.19315172846922102 | accuracy: 0.9280215992647058 \n",
      "Epoch 18 | Step 7124 | loss: 0.19298616215422915 | accuracy: 0.9281135531135531 \n",
      "Epoch 18 | Step 7125 | loss: 0.19294412934432068 | accuracy: 0.9280337591240876 \n",
      "Epoch 18 | Step 7126 | loss: 0.1930631452256983 | accuracy: 0.9278977272727272 \n",
      "Epoch 18 | Step 7127 | loss: 0.19316951417620634 | accuracy: 0.9278759057971014 \n",
      "Epoch 18 | Step 7128 | loss: 0.19323822393314075 | accuracy: 0.927797833935018 \n",
      "Epoch 18 | Step 7129 | loss: 0.19296031884795473 | accuracy: 0.9277765287769785 \n",
      "Epoch 18 | Step 7130 | loss: 0.19348390902455992 | accuracy: 0.9276433691756273 \n",
      "Epoch 18 | Step 7131 | loss: 0.19325528549296517 | accuracy: 0.9276785714285715 \n",
      "Epoch 18 | Step 7132 | loss: 0.19303993239097325 | accuracy: 0.9278803380782918 \n",
      "Epoch 18 | Step 7133 | loss: 0.19296776175710328 | accuracy: 0.9278590425531915 \n",
      "Epoch 18 | Step 7134 | loss: 0.19291291488564902 | accuracy: 0.9278931095406361 \n",
      "Epoch 18 | Step 7135 | loss: 0.19280208983051947 | accuracy: 0.9279269366197183 \n",
      "Epoch 18 | Step 7136 | loss: 0.19277367821910926 | accuracy: 0.9279057017543859 \n",
      "Epoch 18 | Step 7137 | loss: 0.1924794597902915 | accuracy: 0.928048513986014 \n",
      "Epoch 18 | Step 7138 | loss: 0.19238392367491738 | accuracy: 0.9280270034843205 \n",
      "Epoch 18 | Step 7139 | loss: 0.19194369794179997 | accuracy: 0.9282769097222222 \n",
      "Epoch 18 | Step 7140 | loss: 0.1919996508471281 | accuracy: 0.9282547577854672 \n",
      "Epoch 18 | Step 7141 | loss: 0.19223896388349862 | accuracy: 0.9281788793103448 \n",
      "Epoch 18 | Step 7142 | loss: 0.19256517219379596 | accuracy: 0.9281035223367697 \n",
      "Epoch 18 | Step 7143 | loss: 0.1924101224500839 | accuracy: 0.928082191780822 \n",
      "Epoch 18 | Step 7144 | loss: 0.192606298793298 | accuracy: 0.9280076791808873 \n",
      "Epoch 18 | Step 7145 | loss: 0.19231572014843526 | accuracy: 0.9281462585034014 \n",
      "Epoch 18 | Step 7146 | loss: 0.1921695248807891 | accuracy: 0.9282309322033898 \n",
      "Epoch 18 | Step 7147 | loss: 0.1922713163988413 | accuracy: 0.9282094594594594 \n",
      "Epoch 18 | Step 7148 | loss: 0.19195076278865536 | accuracy: 0.9283459595959596 \n",
      "Epoch 18 | Step 7149 | loss: 0.19225131982824945 | accuracy: 0.928324244966443 \n",
      "Epoch 18 | Step 7150 | loss: 0.1920090918257882 | accuracy: 0.9285117056856187 \n",
      "Epoch 18 | Step 7151 | loss: 0.19173309336105981 | accuracy: 0.92859375 \n",
      "Epoch 18 | Step 7152 | loss: 0.19161443397452269 | accuracy: 0.9287271594684385 \n",
      "Epoch 18 | Step 7153 | loss: 0.19143502665868659 | accuracy: 0.9287562086092715 \n",
      "Epoch 18 | Step 7154 | loss: 0.19146761189986378 | accuracy: 0.9286819306930693 \n",
      "Epoch 18 | Step 7155 | loss: 0.1913822342298533 | accuracy: 0.9286595394736842 \n",
      "Epoch 18 | Step 7156 | loss: 0.1911709698497272 | accuracy: 0.9287397540983606 \n",
      "Epoch 18 | Step 7157 | loss: 0.19129936324030744 | accuracy: 0.9287173202614379 \n",
      "Epoch 18 | Step 7158 | loss: 0.19151533421747846 | accuracy: 0.9286950325732899 \n",
      "Epoch 18 | Step 7159 | loss: 0.19133326503169998 | accuracy: 0.9286728896103896 \n",
      "Epoch 18 | Step 7160 | loss: 0.19117799160164148 | accuracy: 0.9287520226537217 \n",
      "Epoch 18 | Step 7161 | loss: 0.19137022985566043 | accuracy: 0.9287298387096774 \n",
      "Epoch 18 | Step 7162 | loss: 0.19153953025003717 | accuracy: 0.928758038585209 \n",
      "Epoch 18 | Step 7163 | loss: 0.19140649243043015 | accuracy: 0.928886217948718 \n",
      "Epoch 18 | Step 7164 | loss: 0.19139294740491017 | accuracy: 0.9289137380191693 \n",
      "Epoch 18 | Step 7165 | loss: 0.19196716416033968 | accuracy: 0.9287420382165605 \n",
      "Epoch 18 | Step 7166 | loss: 0.19248925967821998 | accuracy: 0.9285714285714286 \n",
      "Epoch 18 | Step 7167 | loss: 0.1924517602199995 | accuracy: 0.9285007911392406 \n",
      "Epoch 18 | Step 7168 | loss: 0.19210108938371342 | accuracy: 0.9286277602523659 \n",
      "Epoch 18 | Step 7169 | loss: 0.19208315668522186 | accuracy: 0.9285573899371069 \n",
      "Epoch 18 | Step 7170 | loss: 0.19221749128686222 | accuracy: 0.9285364420062696 \n",
      "Epoch 18 | Step 7171 | loss: 0.19208397835027424 | accuracy: 0.928564453125 \n",
      "Epoch 18 | Step 7172 | loss: 0.19198892409463536 | accuracy: 0.9286409657320872 \n",
      "Epoch 18 | Step 7173 | loss: 0.19262054319614946 | accuracy: 0.9284743788819876 \n",
      "Epoch 18 | Step 7174 | loss: 0.19235803911191388 | accuracy: 0.9285023219814241 \n",
      "Epoch 18 | Step 7175 | loss: 0.1922298082047038 | accuracy: 0.9286265432098766 \n",
      "Epoch 18 | Step 7176 | loss: 0.19250307844235343 | accuracy: 0.9286538461538462 \n",
      "Epoch 18 | Step 7177 | loss: 0.19254063472060334 | accuracy: 0.9287768404907976 \n",
      "Epoch 18 | Step 7178 | loss: 0.1925323428272836 | accuracy: 0.9287079510703364 \n",
      "Epoch 18 | Step 7179 | loss: 0.1924728159679145 | accuracy: 0.928687118902439 \n",
      "Epoch 18 | Step 7180 | loss: 0.19257996976375574 | accuracy: 0.928713905775076 \n",
      "Epoch 18 | Step 7181 | loss: 0.1925097409522894 | accuracy: 0.9287405303030303 \n",
      "Epoch 18 | Step 7182 | loss: 0.19250240282709857 | accuracy: 0.928672583081571 \n",
      "Epoch 18 | Step 7183 | loss: 0.19252068482070075 | accuracy: 0.9287932981927711 \n",
      "Epoch 18 | Step 7184 | loss: 0.1924524397642404 | accuracy: 0.9288194444444444 \n",
      "Epoch 18 | Step 7185 | loss: 0.19267887287511073 | accuracy: 0.9286583083832335 \n",
      "Epoch 18 | Step 7186 | loss: 0.1924397437430139 | accuracy: 0.9287313432835821 \n",
      "Epoch 18 | Step 7187 | loss: 0.192372032840337 | accuracy: 0.9287109375 \n",
      "Epoch 18 | Step 7188 | loss: 0.19223011517206348 | accuracy: 0.9287833827893175 \n",
      "Epoch 18 | Step 7189 | loss: 0.19245965739150012 | accuracy: 0.9287629437869822 \n",
      "Epoch 18 | Step 7190 | loss: 0.19226096873789753 | accuracy: 0.928834808259587 \n",
      "Epoch 18 | Step 7191 | loss: 0.19218965663629411 | accuracy: 0.92890625 \n",
      "Epoch 18 | Step 7192 | loss: 0.19233335934776008 | accuracy: 0.9288398093841642 \n",
      "Epoch 18 | Step 7193 | loss: 0.19218958221506646 | accuracy: 0.9289108187134503 \n",
      "Epoch 18 | Step 7194 | loss: 0.19203896794479017 | accuracy: 0.9290269679300291 \n",
      "Epoch 18 | Step 7195 | loss: 0.1919114587525295 | accuracy: 0.9290515988372093 \n",
      "Epoch 18 | Step 7196 | loss: 0.19230471171330707 | accuracy: 0.9290307971014493 \n",
      "Epoch 18 | Step 7197 | loss: 0.19220522481065258 | accuracy: 0.929055274566474 \n",
      "Epoch 18 | Step 7198 | loss: 0.1919007339549682 | accuracy: 0.9292146974063401 \n",
      "Epoch 18 | Step 7199 | loss: 0.1923446564924442 | accuracy: 0.9290140086206896 \n",
      "Epoch 18 | Step 7200 | loss: 0.1922790889326685 | accuracy: 0.928993553008596 \n",
      "Epoch 18 | Step 7201 | loss: 0.19210471817425312 | accuracy: 0.9290625 \n",
      "Epoch 18 | Step 7202 | loss: 0.19187594377077535 | accuracy: 0.9291310541310541 \n",
      "Epoch 18 | Step 7203 | loss: 0.19200680853629645 | accuracy: 0.9291548295454546 \n",
      "Epoch 18 | Step 7204 | loss: 0.19209855929987957 | accuracy: 0.9291342067988668 \n",
      "Epoch 18 | Step 7205 | loss: 0.1918735168874263 | accuracy: 0.929246115819209 \n",
      "Epoch 18 | Step 7206 | loss: 0.1919468024457004 | accuracy: 0.929137323943662 \n",
      "Epoch 18 | Step 7207 | loss: 0.19174768733844322 | accuracy: 0.9292047050561798 \n",
      "Epoch 18 | Step 7208 | loss: 0.19173180009303634 | accuracy: 0.9292279411764706 \n",
      "Epoch 18 | Step 7209 | loss: 0.1917519309667235 | accuracy: 0.9292510474860335 \n",
      "Epoch 18 | Step 7210 | loss: 0.19162421214879383 | accuracy: 0.9293175487465181 \n",
      "Epoch 18 | Step 7211 | loss: 0.19170366811255607 | accuracy: 0.9293402777777777 \n",
      "Epoch 18 | Step 7212 | loss: 0.19152812160283236 | accuracy: 0.929406163434903 \n",
      "Epoch 18 | Step 7213 | loss: 0.19166449885506648 | accuracy: 0.9294716850828729 \n",
      "Epoch 18 | Step 7214 | loss: 0.19168031071992608 | accuracy: 0.9294938016528925 \n",
      "Epoch 18 | Step 7215 | loss: 0.19156336628801213 | accuracy: 0.9296016483516484 \n",
      "Epoch 18 | Step 7216 | loss: 0.19144261748823393 | accuracy: 0.9296232876712329 \n",
      "Epoch 18 | Step 7217 | loss: 0.19133666658499193 | accuracy: 0.9296448087431693 \n",
      "Epoch 18 | Step 7218 | loss: 0.19101962303027137 | accuracy: 0.9297939373297003 \n",
      "Epoch 18 | Step 7219 | loss: 0.19136416079962376 | accuracy: 0.9297299592391305 \n",
      "Epoch 18 | Step 7220 | loss: 0.19135443888463294 | accuracy: 0.9297510162601627 \n",
      "Epoch 18 | Step 7221 | loss: 0.1916571122770373 | accuracy: 0.9296452702702702 \n",
      "Epoch 18 | Step 7222 | loss: 0.19187687849500423 | accuracy: 0.9295400943396226 \n",
      "Epoch 18 | Step 7223 | loss: 0.19207751079993216 | accuracy: 0.9294774865591398 \n",
      "Epoch 18 | Step 7224 | loss: 0.1922643667451497 | accuracy: 0.9294571045576407 \n",
      "Epoch 18 | Step 7225 | loss: 0.19246251277506024 | accuracy: 0.9293114973262032 \n",
      "Epoch 18 | Step 7226 | loss: 0.1922341104547182 | accuracy: 0.929375 \n",
      "Epoch 18 | Step 7227 | loss: 0.19203983928928978 | accuracy: 0.9293966090425532 \n",
      "Epoch 18 | Step 7228 | loss: 0.19181693386810203 | accuracy: 0.929459549071618 \n",
      "Epoch 18 | Step 7229 | loss: 0.19218416035017633 | accuracy: 0.9292328042328042 \n",
      "Epoch 18 | Step 7230 | loss: 0.19223888470031963 | accuracy: 0.9291309366754618 \n",
      "Epoch 18 | Step 7231 | loss: 0.19199164347036882 | accuracy: 0.9292351973684211 \n",
      "Epoch 18 | Step 7232 | loss: 0.19194511805228354 | accuracy: 0.9292568897637795 \n",
      "Epoch 18 | Step 7233 | loss: 0.19174280425250834 | accuracy: 0.9293193717277487 \n",
      "Epoch 18 | Step 7234 | loss: 0.19157301973035995 | accuracy: 0.9293815274151436 \n",
      "Epoch 18 | Step 7235 | loss: 0.19168503370989728 | accuracy: 0.9293212890625 \n",
      "Epoch 18 | Step 7236 | loss: 0.19171117011989858 | accuracy: 0.9292613636363637 \n",
      "Epoch 18 | Step 7237 | loss: 0.19168009514404077 | accuracy: 0.9292827072538861 \n",
      "Epoch 18 | Step 7238 | loss: 0.191787817084666 | accuracy: 0.9292231912144703 \n",
      "Epoch 18 | Step 7239 | loss: 0.1918452075039295 | accuracy: 0.9292042525773195 \n",
      "Epoch 18 | Step 7240 | loss: 0.19192372988382764 | accuracy: 0.9291050771208226 \n",
      "Epoch 18 | Step 7241 | loss: 0.1919655981927345 | accuracy: 0.9291266025641025 \n",
      "Epoch 18 | Step 7242 | loss: 0.1919936634733548 | accuracy: 0.9291480179028133 \n",
      "Epoch 18 | Step 7243 | loss: 0.19186808474894074 | accuracy: 0.9292091836734694 \n",
      "Epoch 18 | Step 7244 | loss: 0.19184396366657488 | accuracy: 0.929270038167939 \n",
      "Epoch 18 | Step 7245 | loss: 0.1918685164132396 | accuracy: 0.929251269035533 \n",
      "Epoch 18 | Step 7246 | loss: 0.19179517919126937 | accuracy: 0.9293117088607595 \n",
      "Epoch 18 | Step 7247 | loss: 0.1916824927120798 | accuracy: 0.9293718434343434 \n",
      "Epoch 18 | Step 7248 | loss: 0.19141861873324625 | accuracy: 0.929471032745592 \n",
      "Epoch 18 | Step 7249 | loss: 0.19144311522943283 | accuracy: 0.9294519472361809 \n",
      "Epoch 18 | Step 7250 | loss: 0.19151442725780907 | accuracy: 0.9293154761904762 \n",
      "Epoch 18 | Step 7251 | loss: 0.1917972236685454 | accuracy: 0.929296875 \n",
      "Epoch 18 | Step 7252 | loss: 0.19171105746988043 | accuracy: 0.9293562967581047 \n",
      "Epoch 18 | Step 7253 | loss: 0.1920741841901297 | accuracy: 0.9291822139303483 \n",
      "Epoch 18 | Step 7254 | loss: 0.1917942669751034 | accuracy: 0.9292723752428816 \n",
      "Validation | Epoch 18 | Step 7254 | accuracy: 0.8535079048438505 \n",
      "Epoch 19 | Step 7255 | loss: 0.15846887230873108 | accuracy: 0.953125 \n",
      "Epoch 19 | Step 7256 | loss: 0.24073751270771027 | accuracy: 0.890625 \n",
      "Epoch 19 | Step 7257 | loss: 0.205086017648379 | accuracy: 0.9114583333333334 \n",
      "Epoch 19 | Step 7258 | loss: 0.2181008644402027 | accuracy: 0.9140625 \n",
      "Epoch 19 | Step 7259 | loss: 0.2116314649581909 | accuracy: 0.921875 \n",
      "Epoch 19 | Step 7260 | loss: 0.21854624152183533 | accuracy: 0.9140625 \n",
      "Epoch 19 | Step 7261 | loss: 0.22302906853812082 | accuracy: 0.9129464285714286 \n",
      "Epoch 19 | Step 7262 | loss: 0.22600275836884975 | accuracy: 0.9140625 \n",
      "Epoch 19 | Step 7263 | loss: 0.21616986393928528 | accuracy: 0.9166666666666666 \n",
      "Epoch 19 | Step 7264 | loss: 0.21782137155532838 | accuracy: 0.915625 \n",
      "Epoch 19 | Step 7265 | loss: 0.2107494663108479 | accuracy: 0.9176136363636364 \n",
      "Epoch 19 | Step 7266 | loss: 0.21338050439953804 | accuracy: 0.91796875 \n",
      "Epoch 19 | Step 7267 | loss: 0.21143717146836793 | accuracy: 0.9194711538461539 \n",
      "Epoch 19 | Step 7268 | loss: 0.20923307750906264 | accuracy: 0.921875 \n",
      "Epoch 19 | Step 7269 | loss: 0.20012737015883128 | accuracy: 0.9260416666666667 \n",
      "Epoch 19 | Step 7270 | loss: 0.1979509787634015 | accuracy: 0.927734375 \n",
      "Epoch 19 | Step 7271 | loss: 0.20011962599614086 | accuracy: 0.9283088235294118 \n",
      "Epoch 19 | Step 7272 | loss: 0.19748189797004065 | accuracy: 0.9279513888888888 \n",
      "Epoch 19 | Step 7273 | loss: 0.19937904335950551 | accuracy: 0.928453947368421 \n",
      "Epoch 19 | Step 7274 | loss: 0.19636099711060523 | accuracy: 0.9296875 \n",
      "Epoch 19 | Step 7275 | loss: 0.19294444613513492 | accuracy: 0.9308035714285714 \n",
      "Epoch 19 | Step 7276 | loss: 0.19112581725824962 | accuracy: 0.9303977272727273 \n",
      "Epoch 19 | Step 7277 | loss: 0.19022465238104697 | accuracy: 0.9313858695652174 \n",
      "Epoch 19 | Step 7278 | loss: 0.1861187433823943 | accuracy: 0.9329427083333334 \n",
      "Epoch 19 | Step 7279 | loss: 0.18475974708795548 | accuracy: 0.933125 \n",
      "Epoch 19 | Step 7280 | loss: 0.18375783442304686 | accuracy: 0.9332932692307693 \n",
      "Epoch 19 | Step 7281 | loss: 0.18474116562693207 | accuracy: 0.9322916666666666 \n",
      "Epoch 19 | Step 7282 | loss: 0.18177688946681364 | accuracy: 0.93359375 \n",
      "Epoch 19 | Step 7283 | loss: 0.17947826585892973 | accuracy: 0.9342672413793104 \n",
      "Epoch 19 | Step 7284 | loss: 0.18103334878881772 | accuracy: 0.9333333333333333 \n",
      "Epoch 19 | Step 7285 | loss: 0.1805214860266255 | accuracy: 0.9344758064516129 \n",
      "Epoch 19 | Step 7286 | loss: 0.18185222218744457 | accuracy: 0.93359375 \n",
      "Epoch 19 | Step 7287 | loss: 0.18297705257480795 | accuracy: 0.9332386363636364 \n",
      "Epoch 19 | Step 7288 | loss: 0.18127897053080447 | accuracy: 0.9338235294117647 \n",
      "Epoch 19 | Step 7289 | loss: 0.1788417113678796 | accuracy: 0.9348214285714286 \n",
      "Epoch 19 | Step 7290 | loss: 0.17906678136852053 | accuracy: 0.9348958333333334 \n",
      "Epoch 19 | Step 7291 | loss: 0.17737955096605662 | accuracy: 0.9349662162162162 \n",
      "Epoch 19 | Step 7292 | loss: 0.17855845548604665 | accuracy: 0.9337993421052632 \n",
      "Epoch 19 | Step 7293 | loss: 0.17859880664409736 | accuracy: 0.9330929487179487 \n",
      "Epoch 19 | Step 7294 | loss: 0.17860528603196144 | accuracy: 0.9328125 \n",
      "Epoch 19 | Step 7295 | loss: 0.17717617677479255 | accuracy: 0.9333079268292683 \n",
      "Epoch 19 | Step 7296 | loss: 0.17984931667645773 | accuracy: 0.9326636904761905 \n",
      "Epoch 19 | Step 7297 | loss: 0.17931025388628938 | accuracy: 0.9324127906976745 \n",
      "Epoch 19 | Step 7298 | loss: 0.17802941003306347 | accuracy: 0.9325284090909091 \n",
      "Epoch 19 | Step 7299 | loss: 0.1793816382686297 | accuracy: 0.9315972222222222 \n",
      "Epoch 19 | Step 7300 | loss: 0.17924858905051066 | accuracy: 0.9313858695652174 \n",
      "Epoch 19 | Step 7301 | loss: 0.17873938429228803 | accuracy: 0.9311835106382979 \n",
      "Epoch 19 | Step 7302 | loss: 0.18019021659468612 | accuracy: 0.9309895833333334 \n",
      "Epoch 19 | Step 7303 | loss: 0.1791839245326665 | accuracy: 0.9314413265306123 \n",
      "Epoch 19 | Step 7304 | loss: 0.1808979867398739 | accuracy: 0.9315625 \n",
      "Epoch 19 | Step 7305 | loss: 0.1839964300686238 | accuracy: 0.9310661764705882 \n",
      "Epoch 19 | Step 7306 | loss: 0.18421732963850865 | accuracy: 0.9308894230769231 \n",
      "Epoch 19 | Step 7307 | loss: 0.18266057982197348 | accuracy: 0.9313089622641509 \n",
      "Epoch 19 | Step 7308 | loss: 0.18214317562955398 | accuracy: 0.9314236111111112 \n",
      "Epoch 19 | Step 7309 | loss: 0.18299604667858643 | accuracy: 0.9303977272727273 \n",
      "Epoch 19 | Step 7310 | loss: 0.18398239796182939 | accuracy: 0.9305245535714286 \n",
      "Epoch 19 | Step 7311 | loss: 0.18406587956767334 | accuracy: 0.930921052631579 \n",
      "Epoch 19 | Step 7312 | loss: 0.18456555992878718 | accuracy: 0.9307650862068966 \n",
      "Epoch 19 | Step 7313 | loss: 0.18578848129106781 | accuracy: 0.9300847457627118 \n",
      "Epoch 19 | Step 7314 | loss: 0.18679197890063126 | accuracy: 0.93046875 \n",
      "Epoch 19 | Step 7315 | loss: 0.1877802389322734 | accuracy: 0.930327868852459 \n",
      "Epoch 19 | Step 7316 | loss: 0.18686494075002208 | accuracy: 0.930695564516129 \n",
      "Epoch 19 | Step 7317 | loss: 0.18712538587195532 | accuracy: 0.9303075396825397 \n",
      "Epoch 19 | Step 7318 | loss: 0.1855850744759664 | accuracy: 0.930908203125 \n",
      "Epoch 19 | Step 7319 | loss: 0.18632623793987127 | accuracy: 0.9307692307692308 \n",
      "Epoch 19 | Step 7320 | loss: 0.1847112820003972 | accuracy: 0.9315814393939394 \n",
      "Epoch 19 | Step 7321 | loss: 0.18370475597790817 | accuracy: 0.9323694029850746 \n",
      "Epoch 19 | Step 7322 | loss: 0.1836671731708681 | accuracy: 0.9324448529411765 \n",
      "Epoch 19 | Step 7323 | loss: 0.18514428525299265 | accuracy: 0.9322916666666666 \n",
      "Epoch 19 | Step 7324 | loss: 0.1851574057979243 | accuracy: 0.9321428571428572 \n",
      "Epoch 19 | Step 7325 | loss: 0.18514925986528397 | accuracy: 0.9324383802816901 \n",
      "Epoch 19 | Step 7326 | loss: 0.18443292493207586 | accuracy: 0.9327256944444444 \n",
      "Epoch 19 | Step 7327 | loss: 0.1848089359190366 | accuracy: 0.9330051369863014 \n",
      "Epoch 19 | Step 7328 | loss: 0.1853530377753683 | accuracy: 0.9322212837837838 \n",
      "Epoch 19 | Step 7329 | loss: 0.1864025683204333 | accuracy: 0.9322916666666666 \n",
      "Epoch 19 | Step 7330 | loss: 0.18513975243427253 | accuracy: 0.9325657894736842 \n",
      "Epoch 19 | Step 7331 | loss: 0.18491583994843744 | accuracy: 0.9326298701298701 \n",
      "Epoch 19 | Step 7332 | loss: 0.18636452932006273 | accuracy: 0.9320913461538461 \n",
      "Epoch 19 | Step 7333 | loss: 0.185436104954798 | accuracy: 0.9325553797468354 \n",
      "Epoch 19 | Step 7334 | loss: 0.18599567161872982 | accuracy: 0.9322265625 \n",
      "Epoch 19 | Step 7335 | loss: 0.186050923978105 | accuracy: 0.9320987654320988 \n",
      "Epoch 19 | Step 7336 | loss: 0.1852395222863046 | accuracy: 0.9323551829268293 \n",
      "Epoch 19 | Step 7337 | loss: 0.1857265093060861 | accuracy: 0.932605421686747 \n",
      "Epoch 19 | Step 7338 | loss: 0.18630397310923963 | accuracy: 0.9324776785714286 \n",
      "Epoch 19 | Step 7339 | loss: 0.18751490422908 | accuracy: 0.9319852941176471 \n",
      "Epoch 19 | Step 7340 | loss: 0.18719504019895264 | accuracy: 0.9322311046511628 \n",
      "Epoch 19 | Step 7341 | loss: 0.1870637216615951 | accuracy: 0.9321120689655172 \n",
      "Epoch 19 | Step 7342 | loss: 0.18786695252426647 | accuracy: 0.9321732954545454 \n",
      "Epoch 19 | Step 7343 | loss: 0.1874582746557975 | accuracy: 0.9324087078651685 \n",
      "Epoch 19 | Step 7344 | loss: 0.18874252496494187 | accuracy: 0.9319444444444445 \n",
      "Epoch 19 | Step 7345 | loss: 0.18792092636391355 | accuracy: 0.9321771978021978 \n",
      "Epoch 19 | Step 7346 | loss: 0.18973566883284113 | accuracy: 0.9317255434782609 \n",
      "Epoch 19 | Step 7347 | loss: 0.19002532926938867 | accuracy: 0.931619623655914 \n",
      "Epoch 19 | Step 7348 | loss: 0.18938994312540014 | accuracy: 0.9318484042553191 \n",
      "Epoch 19 | Step 7349 | loss: 0.1880323442189317 | accuracy: 0.9325657894736842 \n",
      "Epoch 19 | Step 7350 | loss: 0.18764422826158503 | accuracy: 0.9326171875 \n",
      "Epoch 19 | Step 7351 | loss: 0.1871590092778206 | accuracy: 0.9328286082474226 \n",
      "Epoch 19 | Step 7352 | loss: 0.18941883993696193 | accuracy: 0.9322385204081632 \n",
      "Epoch 19 | Step 7353 | loss: 0.1885704170122291 | accuracy: 0.9326073232323232 \n",
      "Epoch 19 | Step 7354 | loss: 0.18844581790268422 | accuracy: 0.93234375 \n",
      "Epoch 19 | Step 7355 | loss: 0.18825680570732248 | accuracy: 0.9320853960396039 \n",
      "Epoch 19 | Step 7356 | loss: 0.18809007583003418 | accuracy: 0.9321384803921569 \n",
      "Epoch 19 | Step 7357 | loss: 0.18836307040985348 | accuracy: 0.9320388349514563 \n",
      "Epoch 19 | Step 7358 | loss: 0.1882328813035901 | accuracy: 0.9322415865384616 \n",
      "Epoch 19 | Step 7359 | loss: 0.1881988538872628 | accuracy: 0.9321428571428572 \n",
      "Epoch 19 | Step 7360 | loss: 0.1872848630794939 | accuracy: 0.9324882075471698 \n",
      "Epoch 19 | Step 7361 | loss: 0.1889831550488962 | accuracy: 0.9316588785046729 \n",
      "Epoch 19 | Step 7362 | loss: 0.1899866534879914 | accuracy: 0.9311342592592593 \n",
      "Epoch 19 | Step 7363 | loss: 0.18917823090739205 | accuracy: 0.9313360091743119 \n",
      "Epoch 19 | Step 7364 | loss: 0.18916102776473218 | accuracy: 0.9311079545454546 \n",
      "Epoch 19 | Step 7365 | loss: 0.18964552174548846 | accuracy: 0.930884009009009 \n",
      "Epoch 19 | Step 7366 | loss: 0.19072829499574645 | accuracy: 0.9303850446428571 \n",
      "Epoch 19 | Step 7367 | loss: 0.19164446253428416 | accuracy: 0.9303097345132744 \n",
      "Epoch 19 | Step 7368 | loss: 0.19166352841676326 | accuracy: 0.9305098684210527 \n",
      "Epoch 19 | Step 7369 | loss: 0.19080284898695737 | accuracy: 0.9308423913043479 \n",
      "Epoch 19 | Step 7370 | loss: 0.19086239499778584 | accuracy: 0.9307650862068966 \n",
      "Epoch 19 | Step 7371 | loss: 0.19079043607935947 | accuracy: 0.9306891025641025 \n",
      "Epoch 19 | Step 7372 | loss: 0.19087996687424386 | accuracy: 0.9304819915254238 \n",
      "Epoch 19 | Step 7373 | loss: 0.1909241865412528 | accuracy: 0.9304096638655462 \n",
      "Epoch 19 | Step 7374 | loss: 0.19097017608582972 | accuracy: 0.93046875 \n",
      "Epoch 19 | Step 7375 | loss: 0.1903474846900987 | accuracy: 0.9307851239669421 \n",
      "Epoch 19 | Step 7376 | loss: 0.19009856403362554 | accuracy: 0.9304559426229508 \n",
      "Epoch 19 | Step 7377 | loss: 0.189817479470881 | accuracy: 0.9307672764227642 \n",
      "Epoch 19 | Step 7378 | loss: 0.19006286080806487 | accuracy: 0.9309475806451613 \n",
      "Epoch 19 | Step 7379 | loss: 0.18981448876857757 | accuracy: 0.930625 \n",
      "Epoch 19 | Step 7380 | loss: 0.18991669255589683 | accuracy: 0.9304315476190477 \n",
      "Epoch 19 | Step 7381 | loss: 0.19113240279550628 | accuracy: 0.9298720472440944 \n",
      "Epoch 19 | Step 7382 | loss: 0.1909216184867546 | accuracy: 0.93017578125 \n",
      "Epoch 19 | Step 7383 | loss: 0.19012900124224583 | accuracy: 0.9305959302325582 \n",
      "Epoch 19 | Step 7384 | loss: 0.19041375116660045 | accuracy: 0.9302884615384616 \n",
      "Epoch 19 | Step 7385 | loss: 0.19050165271486036 | accuracy: 0.9304627862595419 \n",
      "Epoch 19 | Step 7386 | loss: 0.19011573538635718 | accuracy: 0.9306344696969696 \n",
      "Epoch 19 | Step 7387 | loss: 0.18961430721937267 | accuracy: 0.9309210526315789 \n",
      "Epoch 19 | Step 7388 | loss: 0.18924933577429004 | accuracy: 0.9312033582089552 \n",
      "Epoch 19 | Step 7389 | loss: 0.18971361291629296 | accuracy: 0.9310185185185185 \n",
      "Epoch 19 | Step 7390 | loss: 0.19015797156402292 | accuracy: 0.9308363970588235 \n",
      "Epoch 19 | Step 7391 | loss: 0.18990059039235985 | accuracy: 0.9309990875912408 \n",
      "Epoch 19 | Step 7392 | loss: 0.1895461014971353 | accuracy: 0.9311594202898551 \n",
      "Epoch 19 | Step 7393 | loss: 0.18983880709186732 | accuracy: 0.9307553956834532 \n",
      "Epoch 19 | Step 7394 | loss: 0.18955876364239624 | accuracy: 0.9310267857142858 \n",
      "Epoch 19 | Step 7395 | loss: 0.18944375095426613 | accuracy: 0.931072695035461 \n",
      "Epoch 19 | Step 7396 | loss: 0.1888528118356013 | accuracy: 0.9312279929577465 \n",
      "Epoch 19 | Step 7397 | loss: 0.18867053336405254 | accuracy: 0.9314903846153846 \n",
      "Epoch 19 | Step 7398 | loss: 0.18801716063171625 | accuracy: 0.9317491319444444 \n",
      "Epoch 19 | Step 7399 | loss: 0.18792344485891277 | accuracy: 0.9318965517241379 \n",
      "Epoch 19 | Step 7400 | loss: 0.1889696601931363 | accuracy: 0.931720890410959 \n",
      "Epoch 19 | Step 7401 | loss: 0.18858149049638892 | accuracy: 0.9319727891156463 \n",
      "Epoch 19 | Step 7402 | loss: 0.1882374882698059 | accuracy: 0.9321157094594594 \n",
      "Epoch 19 | Step 7403 | loss: 0.1879857027490667 | accuracy: 0.9321518456375839 \n",
      "Epoch 19 | Step 7404 | loss: 0.18774341861406962 | accuracy: 0.9322916666666666 \n",
      "Epoch 19 | Step 7405 | loss: 0.18768540508305 | accuracy: 0.9322226821192053 \n",
      "Epoch 19 | Step 7406 | loss: 0.18773636339526428 | accuracy: 0.932360197368421 \n",
      "Epoch 19 | Step 7407 | loss: 0.1876320354883967 | accuracy: 0.9323937908496732 \n",
      "Epoch 19 | Step 7408 | loss: 0.18765837495977228 | accuracy: 0.932426948051948 \n",
      "Epoch 19 | Step 7409 | loss: 0.1871771686019436 | accuracy: 0.9325604838709678 \n",
      "Epoch 19 | Step 7410 | loss: 0.18669161467980117 | accuracy: 0.932792467948718 \n",
      "Epoch 19 | Step 7411 | loss: 0.1862952634692192 | accuracy: 0.932921974522293 \n",
      "Epoch 19 | Step 7412 | loss: 0.186338225073075 | accuracy: 0.9328520569620253 \n",
      "Epoch 19 | Step 7413 | loss: 0.18613149549038904 | accuracy: 0.9328812893081762 \n",
      "Epoch 19 | Step 7414 | loss: 0.18618200537748636 | accuracy: 0.9326171875 \n",
      "Epoch 19 | Step 7415 | loss: 0.18594318179425245 | accuracy: 0.9326475155279503 \n",
      "Epoch 19 | Step 7416 | loss: 0.18643244857221475 | accuracy: 0.9326774691358025 \n",
      "Epoch 19 | Step 7417 | loss: 0.1857476320369112 | accuracy: 0.9329946319018405 \n",
      "Epoch 19 | Step 7418 | loss: 0.18556584781262933 | accuracy: 0.9332126524390244 \n",
      "Epoch 19 | Step 7419 | loss: 0.18573145830270016 | accuracy: 0.9332386363636364 \n",
      "Epoch 19 | Step 7420 | loss: 0.18689653241490745 | accuracy: 0.9328878012048193 \n",
      "Epoch 19 | Step 7421 | loss: 0.18646111638246185 | accuracy: 0.9331025449101796 \n",
      "Epoch 19 | Step 7422 | loss: 0.18609745330398994 | accuracy: 0.9332217261904762 \n",
      "Epoch 19 | Step 7423 | loss: 0.18708933695886265 | accuracy: 0.932969674556213 \n",
      "Epoch 19 | Step 7424 | loss: 0.18679557179703435 | accuracy: 0.9330882352941177 \n",
      "Epoch 19 | Step 7425 | loss: 0.1871931619114346 | accuracy: 0.9330226608187134 \n",
      "Epoch 19 | Step 7426 | loss: 0.1877091232427331 | accuracy: 0.9328670058139535 \n",
      "Epoch 19 | Step 7427 | loss: 0.18700963379330718 | accuracy: 0.9330744219653179 \n",
      "Epoch 19 | Step 7428 | loss: 0.18712435517160372 | accuracy: 0.9330998563218391 \n",
      "Epoch 19 | Step 7429 | loss: 0.1864206119094576 | accuracy: 0.9333928571428571 \n",
      "Epoch 19 | Step 7430 | loss: 0.1862301638519222 | accuracy: 0.9334161931818182 \n",
      "Epoch 19 | Step 7431 | loss: 0.18644414631660375 | accuracy: 0.933350988700565 \n",
      "Epoch 19 | Step 7432 | loss: 0.18618856512763526 | accuracy: 0.9334620786516854 \n",
      "Epoch 19 | Step 7433 | loss: 0.18642533158456814 | accuracy: 0.9333100558659218 \n",
      "Epoch 19 | Step 7434 | loss: 0.18692213313447104 | accuracy: 0.9333333333333333 \n",
      "Epoch 19 | Step 7435 | loss: 0.18668541946134515 | accuracy: 0.9332700276243094 \n",
      "Epoch 19 | Step 7436 | loss: 0.18632633214468483 | accuracy: 0.9333791208791209 \n",
      "Epoch 19 | Step 7437 | loss: 0.1862091550735828 | accuracy: 0.9334016393442623 \n",
      "Epoch 19 | Step 7438 | loss: 0.18616333822517292 | accuracy: 0.9333389945652174 \n",
      "Epoch 19 | Step 7439 | loss: 0.18620561675445454 | accuracy: 0.933277027027027 \n",
      "Epoch 19 | Step 7440 | loss: 0.18576488784083756 | accuracy: 0.9332997311827957 \n",
      "Epoch 19 | Step 7441 | loss: 0.18586487888811745 | accuracy: 0.9332386363636364 \n",
      "Epoch 19 | Step 7442 | loss: 0.18577256390547497 | accuracy: 0.933095079787234 \n",
      "Epoch 19 | Step 7443 | loss: 0.1853556591603491 | accuracy: 0.9332010582010583 \n",
      "Epoch 19 | Step 7444 | loss: 0.18525807704580458 | accuracy: 0.9333059210526315 \n",
      "Epoch 19 | Step 7445 | loss: 0.18517234472860217 | accuracy: 0.9331642670157068 \n",
      "Epoch 19 | Step 7446 | loss: 0.18503656707859287 | accuracy: 0.9332682291666666 \n",
      "Epoch 19 | Step 7447 | loss: 0.18472117104524158 | accuracy: 0.9333711139896373 \n",
      "Epoch 19 | Step 7448 | loss: 0.18459008084898143 | accuracy: 0.9334729381443299 \n",
      "Epoch 19 | Step 7449 | loss: 0.18467506770140085 | accuracy: 0.9334935897435898 \n",
      "Epoch 19 | Step 7450 | loss: 0.18442980713230006 | accuracy: 0.9334343112244898 \n",
      "Epoch 19 | Step 7451 | loss: 0.1845416759854646 | accuracy: 0.9332170050761421 \n",
      "Epoch 19 | Step 7452 | loss: 0.1844443902749606 | accuracy: 0.9332386363636364 \n",
      "Epoch 19 | Step 7453 | loss: 0.18466341873658962 | accuracy: 0.9331815326633166 \n",
      "Epoch 19 | Step 7454 | loss: 0.1845312750712037 | accuracy: 0.933203125 \n",
      "Epoch 19 | Step 7455 | loss: 0.18454115570925955 | accuracy: 0.9331467661691543 \n",
      "Epoch 19 | Step 7456 | loss: 0.1844475450418373 | accuracy: 0.9332456683168316 \n",
      "Epoch 19 | Step 7457 | loss: 0.1845677305985554 | accuracy: 0.9331126847290641 \n",
      "Epoch 19 | Step 7458 | loss: 0.18455850979422822 | accuracy: 0.9332107843137255 \n",
      "Epoch 19 | Step 7459 | loss: 0.18478950083982654 | accuracy: 0.9333079268292683 \n",
      "Epoch 19 | Step 7460 | loss: 0.18486946542720192 | accuracy: 0.9333282766990292 \n",
      "Epoch 19 | Step 7461 | loss: 0.1846365466138015 | accuracy: 0.9334239130434783 \n",
      "Epoch 19 | Step 7462 | loss: 0.1842817376511028 | accuracy: 0.9335186298076923 \n",
      "Epoch 19 | Step 7463 | loss: 0.184299994776979 | accuracy: 0.9334629186602871 \n",
      "Epoch 19 | Step 7464 | loss: 0.1838538117351986 | accuracy: 0.9336309523809524 \n",
      "Epoch 19 | Step 7465 | loss: 0.1836990942181004 | accuracy: 0.9338714454976303 \n",
      "Epoch 19 | Step 7466 | loss: 0.18353833349527054 | accuracy: 0.9340359669811321 \n",
      "Epoch 19 | Step 7467 | loss: 0.1830855504797658 | accuracy: 0.9342723004694836 \n",
      "Epoch 19 | Step 7468 | loss: 0.18306199081729504 | accuracy: 0.9344334112149533 \n",
      "Epoch 19 | Step 7469 | loss: 0.18319244554569555 | accuracy: 0.934375 \n",
      "Epoch 19 | Step 7470 | loss: 0.1837334562851875 | accuracy: 0.9342447916666666 \n",
      "Epoch 19 | Step 7471 | loss: 0.18413365948172758 | accuracy: 0.9341877880184332 \n",
      "Epoch 19 | Step 7472 | loss: 0.1841330029617209 | accuracy: 0.9342029816513762 \n",
      "Epoch 19 | Step 7473 | loss: 0.18392247277988147 | accuracy: 0.9342180365296804 \n",
      "Epoch 19 | Step 7474 | loss: 0.18361736153337088 | accuracy: 0.9343039772727273 \n",
      "Epoch 19 | Step 7475 | loss: 0.183406553892798 | accuracy: 0.9345305429864253 \n",
      "Epoch 19 | Step 7476 | loss: 0.18313579184112247 | accuracy: 0.9346143018018018 \n",
      "Epoch 19 | Step 7477 | loss: 0.182903843510044 | accuracy: 0.9346272421524664 \n",
      "Epoch 19 | Step 7478 | loss: 0.18279558356984385 | accuracy: 0.9347098214285714 \n",
      "Epoch 19 | Step 7479 | loss: 0.18296443386210334 | accuracy: 0.9346527777777778 \n",
      "Epoch 19 | Step 7480 | loss: 0.18286510454738034 | accuracy: 0.9346653761061947 \n",
      "Epoch 19 | Step 7481 | loss: 0.1829695061243053 | accuracy: 0.9346090308370044 \n",
      "Epoch 19 | Step 7482 | loss: 0.1827191474210275 | accuracy: 0.9346902412280702 \n",
      "Epoch 19 | Step 7483 | loss: 0.18276228963938343 | accuracy: 0.9347707423580786 \n",
      "Epoch 19 | Step 7484 | loss: 0.1827744265937287 | accuracy: 0.9347146739130435 \n",
      "Epoch 19 | Step 7485 | loss: 0.18265650718114076 | accuracy: 0.9347267316017316 \n",
      "Epoch 19 | Step 7486 | loss: 0.1822902513667941 | accuracy: 0.9348733836206896 \n",
      "Epoch 19 | Step 7487 | loss: 0.1820915160069138 | accuracy: 0.9350187768240343 \n",
      "Epoch 19 | Step 7488 | loss: 0.18222145605673137 | accuracy: 0.9349626068376068 \n",
      "Epoch 19 | Step 7489 | loss: 0.1819397453615006 | accuracy: 0.9351063829787234 \n",
      "Epoch 19 | Step 7490 | loss: 0.1817738187451989 | accuracy: 0.9351165254237288 \n",
      "Epoch 19 | Step 7491 | loss: 0.18173876829162428 | accuracy: 0.9350606540084389 \n",
      "Epoch 19 | Step 7492 | loss: 0.18211762566401177 | accuracy: 0.9349396008403361 \n",
      "Epoch 19 | Step 7493 | loss: 0.18203208140374227 | accuracy: 0.9348849372384938 \n",
      "Epoch 19 | Step 7494 | loss: 0.18190955491736532 | accuracy: 0.9348958333333334 \n",
      "Epoch 19 | Step 7495 | loss: 0.1822792630163466 | accuracy: 0.9347121369294605 \n",
      "Epoch 19 | Step 7496 | loss: 0.18237131492288644 | accuracy: 0.9345945247933884 \n",
      "Epoch 19 | Step 7497 | loss: 0.18202393075811518 | accuracy: 0.9347993827160493 \n",
      "Epoch 19 | Step 7498 | loss: 0.1816087678135907 | accuracy: 0.9349385245901639 \n",
      "Epoch 19 | Step 7499 | loss: 0.18124408679349083 | accuracy: 0.9350765306122449 \n",
      "Epoch 19 | Step 7500 | loss: 0.18086926472502027 | accuracy: 0.9353404471544715 \n",
      "Epoch 19 | Step 7501 | loss: 0.18053967001949728 | accuracy: 0.9354757085020243 \n",
      "Epoch 19 | Step 7502 | loss: 0.18063241045080847 | accuracy: 0.9353578629032258 \n",
      "Epoch 19 | Step 7503 | loss: 0.18074654856599479 | accuracy: 0.9352409638554217 \n",
      "Epoch 19 | Step 7504 | loss: 0.18046073013544084 | accuracy: 0.935375 \n",
      "Epoch 19 | Step 7505 | loss: 0.1805625706911087 | accuracy: 0.9353212151394422 \n",
      "Epoch 19 | Step 7506 | loss: 0.18092142098716327 | accuracy: 0.9351438492063492 \n",
      "Epoch 19 | Step 7507 | loss: 0.18099245717638565 | accuracy: 0.9350296442687747 \n",
      "Epoch 19 | Step 7508 | loss: 0.18073599917564806 | accuracy: 0.9351008858267716 \n",
      "Epoch 19 | Step 7509 | loss: 0.18040902150027893 | accuracy: 0.935171568627451 \n",
      "Epoch 19 | Step 7510 | loss: 0.1805355578835588 | accuracy: 0.9351806640625 \n",
      "Epoch 19 | Step 7511 | loss: 0.1804264334795076 | accuracy: 0.9351896887159533 \n",
      "Epoch 19 | Step 7512 | loss: 0.18044313641135082 | accuracy: 0.9351986434108527 \n",
      "Epoch 19 | Step 7513 | loss: 0.18035134837088898 | accuracy: 0.935207528957529 \n",
      "Epoch 19 | Step 7514 | loss: 0.1802816019894985 | accuracy: 0.9352764423076924 \n",
      "Epoch 19 | Step 7515 | loss: 0.1803415827881331 | accuracy: 0.9351652298850575 \n",
      "Epoch 19 | Step 7516 | loss: 0.18091765503960713 | accuracy: 0.9349355916030534 \n",
      "Epoch 19 | Step 7517 | loss: 0.18122707961743326 | accuracy: 0.9349453422053232 \n",
      "Epoch 19 | Step 7518 | loss: 0.18153660544053174 | accuracy: 0.9347182765151515 \n",
      "Epoch 19 | Step 7519 | loss: 0.18153286320420933 | accuracy: 0.9347287735849057 \n",
      "Epoch 19 | Step 7520 | loss: 0.181689299054836 | accuracy: 0.9346217105263158 \n",
      "Epoch 19 | Step 7521 | loss: 0.18165041760224085 | accuracy: 0.9346324906367042 \n",
      "Epoch 19 | Step 7522 | loss: 0.18234897707936482 | accuracy: 0.9343516791044776 \n",
      "Epoch 19 | Step 7523 | loss: 0.18206212331703606 | accuracy: 0.9344795539033457 \n",
      "Epoch 19 | Step 7524 | loss: 0.18216367361170274 | accuracy: 0.9344328703703704 \n",
      "Epoch 19 | Step 7525 | loss: 0.18189573631625333 | accuracy: 0.9345595018450185 \n",
      "Epoch 19 | Step 7526 | loss: 0.18180524538654616 | accuracy: 0.9345703125 \n",
      "Epoch 19 | Step 7527 | loss: 0.18169339899069223 | accuracy: 0.9346955128205128 \n",
      "Epoch 19 | Step 7528 | loss: 0.1817130913318944 | accuracy: 0.934591697080292 \n",
      "Epoch 19 | Step 7529 | loss: 0.18176418491385202 | accuracy: 0.9345454545454546 \n",
      "Epoch 19 | Step 7530 | loss: 0.18173747112893543 | accuracy: 0.9344995471014492 \n",
      "Epoch 19 | Step 7531 | loss: 0.18188150697774408 | accuracy: 0.9344539711191335 \n",
      "Epoch 19 | Step 7532 | loss: 0.18158004143469628 | accuracy: 0.9346897482014388 \n",
      "Epoch 19 | Step 7533 | loss: 0.18208078591413399 | accuracy: 0.9345878136200717 \n",
      "Epoch 19 | Step 7534 | loss: 0.18187963137669225 | accuracy: 0.9345982142857143 \n",
      "Epoch 19 | Step 7535 | loss: 0.18160216173561444 | accuracy: 0.9348309608540926 \n",
      "Epoch 19 | Step 7536 | loss: 0.18163581332522083 | accuracy: 0.9348404255319149 \n",
      "Epoch 19 | Step 7537 | loss: 0.18157774465349455 | accuracy: 0.934905035335689 \n",
      "Epoch 19 | Step 7538 | loss: 0.1814804650370924 | accuracy: 0.9349141725352113 \n",
      "Epoch 19 | Step 7539 | loss: 0.18137211781321913 | accuracy: 0.9348684210526316 \n",
      "Epoch 19 | Step 7540 | loss: 0.18108465079661018 | accuracy: 0.9349868881118881 \n",
      "Epoch 19 | Step 7541 | loss: 0.1809479546983068 | accuracy: 0.9349956445993032 \n",
      "Epoch 19 | Step 7542 | loss: 0.1804938085454827 | accuracy: 0.9352213541666666 \n",
      "Epoch 19 | Step 7543 | loss: 0.18049728910351712 | accuracy: 0.9352292387543253 \n",
      "Epoch 19 | Step 7544 | loss: 0.18073451337886273 | accuracy: 0.9351831896551724 \n",
      "Epoch 19 | Step 7545 | loss: 0.1810997300925329 | accuracy: 0.9350300687285223 \n",
      "Epoch 19 | Step 7546 | loss: 0.18099721065684138 | accuracy: 0.9350385273972602 \n",
      "Epoch 19 | Step 7547 | loss: 0.18124309826782137 | accuracy: 0.9349402730375427 \n",
      "Epoch 19 | Step 7548 | loss: 0.1809593700506047 | accuracy: 0.9351084183673469 \n",
      "Epoch 19 | Step 7549 | loss: 0.18083296780616556 | accuracy: 0.9351694915254237 \n",
      "Epoch 19 | Step 7550 | loss: 0.1809787001536304 | accuracy: 0.9350717905405406 \n",
      "Epoch 19 | Step 7551 | loss: 0.1807241199368781 | accuracy: 0.9351325757575758 \n",
      "Epoch 19 | Step 7552 | loss: 0.18099544336081758 | accuracy: 0.9350880872483222 \n",
      "Epoch 19 | Step 7553 | loss: 0.18075379660745536 | accuracy: 0.9352529264214047 \n",
      "Epoch 19 | Step 7554 | loss: 0.1804581963891785 | accuracy: 0.9353125 \n",
      "Epoch 19 | Step 7555 | loss: 0.18041162340100428 | accuracy: 0.9353716777408638 \n",
      "Epoch 19 | Step 7556 | loss: 0.18020825454385478 | accuracy: 0.9354304635761589 \n",
      "Epoch 19 | Step 7557 | loss: 0.18025255076611796 | accuracy: 0.9353857260726073 \n",
      "Epoch 19 | Step 7558 | loss: 0.18018659729951705 | accuracy: 0.9353412828947368 \n",
      "Epoch 19 | Step 7559 | loss: 0.17998293043404337 | accuracy: 0.9353483606557377 \n",
      "Epoch 19 | Step 7560 | loss: 0.18013352863003623 | accuracy: 0.9353043300653595 \n",
      "Epoch 19 | Step 7561 | loss: 0.1803582470487889 | accuracy: 0.9353114820846905 \n",
      "Epoch 19 | Step 7562 | loss: 0.18019260012532604 | accuracy: 0.9354200487012987 \n",
      "Epoch 19 | Step 7563 | loss: 0.18011313605703974 | accuracy: 0.9355279126213593 \n",
      "Epoch 19 | Step 7564 | loss: 0.18033226628697693 | accuracy: 0.9355846774193548 \n",
      "Epoch 19 | Step 7565 | loss: 0.18050142347668918 | accuracy: 0.9355405948553055 \n",
      "Epoch 19 | Step 7566 | loss: 0.18034139463009366 | accuracy: 0.9356470352564102 \n",
      "Epoch 19 | Step 7567 | loss: 0.18032657377683703 | accuracy: 0.9356529552715654 \n",
      "Epoch 19 | Step 7568 | loss: 0.1809245294944686 | accuracy: 0.9355095541401274 \n",
      "Epoch 19 | Step 7569 | loss: 0.1813579954916523 | accuracy: 0.9353174603174603 \n",
      "Epoch 19 | Step 7570 | loss: 0.18136680155662424 | accuracy: 0.9352254746835443 \n",
      "Epoch 19 | Step 7571 | loss: 0.18101476557106255 | accuracy: 0.9353312302839116 \n",
      "Epoch 19 | Step 7572 | loss: 0.18101308927080545 | accuracy: 0.9351906446540881 \n",
      "Epoch 19 | Step 7573 | loss: 0.1811379226607776 | accuracy: 0.935099921630094 \n",
      "Epoch 19 | Step 7574 | loss: 0.1810742660076358 | accuracy: 0.93515625 \n",
      "Epoch 19 | Step 7575 | loss: 0.18096845865110375 | accuracy: 0.9352122274143302 \n",
      "Epoch 19 | Step 7576 | loss: 0.18165014717751043 | accuracy: 0.9349767080745341 \n",
      "Epoch 19 | Step 7577 | loss: 0.1813633391754731 | accuracy: 0.9351296439628483 \n",
      "Epoch 19 | Step 7578 | loss: 0.18127674932511137 | accuracy: 0.9351851851851852 \n",
      "Epoch 19 | Step 7579 | loss: 0.181534432642735 | accuracy: 0.9351923076923077 \n",
      "Epoch 19 | Step 7580 | loss: 0.18159045769255952 | accuracy: 0.9352473159509203 \n",
      "Epoch 19 | Step 7581 | loss: 0.18155882397057085 | accuracy: 0.9351586391437309 \n",
      "Epoch 19 | Step 7582 | loss: 0.18148182224618592 | accuracy: 0.9351657774390244 \n",
      "Epoch 19 | Step 7583 | loss: 0.18162638357752728 | accuracy: 0.9349829027355623 \n",
      "Epoch 19 | Step 7584 | loss: 0.1815449416298758 | accuracy: 0.9349905303030303 \n",
      "Epoch 19 | Step 7585 | loss: 0.18153282740009877 | accuracy: 0.9349037009063444 \n",
      "Epoch 19 | Step 7586 | loss: 0.18159104485334046 | accuracy: 0.9350056475903614 \n",
      "Epoch 19 | Step 7587 | loss: 0.18153271232326113 | accuracy: 0.9349662162162162 \n",
      "Epoch 19 | Step 7588 | loss: 0.18179180318054683 | accuracy: 0.9347866766467066 \n",
      "Epoch 19 | Step 7589 | loss: 0.1815963202336831 | accuracy: 0.9348414179104477 \n",
      "Epoch 19 | Step 7590 | loss: 0.18156431113103672 | accuracy: 0.9348958333333334 \n",
      "Epoch 19 | Step 7591 | loss: 0.18138447212668837 | accuracy: 0.9349499258160238 \n",
      "Epoch 19 | Step 7592 | loss: 0.18154976458547736 | accuracy: 0.9349112426035503 \n",
      "Epoch 19 | Step 7593 | loss: 0.18139458101539485 | accuracy: 0.9349188790560472 \n",
      "Epoch 19 | Step 7594 | loss: 0.18134330588885966 | accuracy: 0.9350183823529412 \n",
      "Epoch 19 | Step 7595 | loss: 0.1814653637799874 | accuracy: 0.9349340175953079 \n",
      "Epoch 19 | Step 7596 | loss: 0.18134468165362438 | accuracy: 0.9349415204678363 \n",
      "Epoch 19 | Step 7597 | loss: 0.181183853439183 | accuracy: 0.9350400874635568 \n",
      "Epoch 19 | Step 7598 | loss: 0.1811127423871915 | accuracy: 0.935047238372093 \n",
      "Epoch 19 | Step 7599 | loss: 0.1814486712973187 | accuracy: 0.9350090579710145 \n",
      "Epoch 19 | Step 7600 | loss: 0.18131084080161042 | accuracy: 0.9350162572254336 \n",
      "Epoch 19 | Step 7601 | loss: 0.18104076736555663 | accuracy: 0.9351585014409222 \n",
      "Epoch 19 | Step 7602 | loss: 0.18140653108685523 | accuracy: 0.9349856321839081 \n",
      "Epoch 19 | Step 7603 | loss: 0.18128258586570323 | accuracy: 0.9349928366762178 \n",
      "Epoch 19 | Step 7604 | loss: 0.18121076859533788 | accuracy: 0.935 \n",
      "Epoch 19 | Step 7605 | loss: 0.1809493539658537 | accuracy: 0.9350961538461539 \n",
      "Epoch 19 | Step 7606 | loss: 0.1810200004732575 | accuracy: 0.9351473721590909 \n",
      "Epoch 19 | Step 7607 | loss: 0.18115200726025166 | accuracy: 0.9351097733711048 \n",
      "Epoch 19 | Step 7608 | loss: 0.18100159050170647 | accuracy: 0.9350723870056498 \n",
      "Epoch 19 | Step 7609 | loss: 0.18102145873954598 | accuracy: 0.9349911971830986 \n",
      "Epoch 19 | Step 7610 | loss: 0.1808579150022248 | accuracy: 0.9350421348314607 \n",
      "Epoch 19 | Step 7611 | loss: 0.18081431561449662 | accuracy: 0.9350927871148459 \n",
      "Epoch 19 | Step 7612 | loss: 0.18089836218794964 | accuracy: 0.935012220670391 \n",
      "Epoch 19 | Step 7613 | loss: 0.18082122296136402 | accuracy: 0.9350626740947076 \n",
      "Epoch 19 | Step 7614 | loss: 0.18085618051182892 | accuracy: 0.9351128472222222 \n",
      "Epoch 19 | Step 7615 | loss: 0.18075062729769137 | accuracy: 0.935119459833795 \n",
      "Epoch 19 | Step 7616 | loss: 0.18088527372652324 | accuracy: 0.9351260359116023 \n",
      "Epoch 19 | Step 7617 | loss: 0.1808947462167786 | accuracy: 0.9351325757575758 \n",
      "Epoch 19 | Step 7618 | loss: 0.18082877104221792 | accuracy: 0.9351390796703297 \n",
      "Epoch 19 | Step 7619 | loss: 0.1807150627550197 | accuracy: 0.9351455479452054 \n",
      "Epoch 19 | Step 7620 | loss: 0.18066502186403574 | accuracy: 0.935151980874317 \n",
      "Epoch 19 | Step 7621 | loss: 0.18034448676643644 | accuracy: 0.9352861035422343 \n",
      "Epoch 19 | Step 7622 | loss: 0.18068163470446091 | accuracy: 0.9352072010869565 \n",
      "Epoch 19 | Step 7623 | loss: 0.18070875646339524 | accuracy: 0.9352134146341463 \n",
      "Epoch 19 | Step 7624 | loss: 0.18103411504747094 | accuracy: 0.9351773648648649 \n",
      "Epoch 19 | Step 7625 | loss: 0.18122466893570444 | accuracy: 0.9351836253369272 \n",
      "Epoch 19 | Step 7626 | loss: 0.1813938208024508 | accuracy: 0.9350638440860215 \n",
      "Epoch 19 | Step 7627 | loss: 0.18148607703739772 | accuracy: 0.9350284852546917 \n",
      "Epoch 19 | Step 7628 | loss: 0.18171228254263733 | accuracy: 0.9349097593582888 \n",
      "Epoch 19 | Step 7629 | loss: 0.18144889719287555 | accuracy: 0.9349583333333333 \n",
      "Epoch 19 | Step 7630 | loss: 0.18129629656632848 | accuracy: 0.9350066489361702 \n",
      "Epoch 19 | Step 7631 | loss: 0.18103798258486414 | accuracy: 0.9351790450928382 \n",
      "Epoch 19 | Step 7632 | loss: 0.18145256831493012 | accuracy: 0.9350198412698413 \n",
      "Epoch 19 | Step 7633 | loss: 0.181478415431558 | accuracy: 0.9350676121372031 \n",
      "Epoch 19 | Step 7634 | loss: 0.18120975452230165 | accuracy: 0.9351973684210526 \n",
      "Epoch 19 | Step 7635 | loss: 0.18120375503431468 | accuracy: 0.9352034120734908 \n",
      "Epoch 19 | Step 7636 | loss: 0.1810562790551891 | accuracy: 0.9352094240837696 \n",
      "Epoch 19 | Step 7637 | loss: 0.18084876528179988 | accuracy: 0.9352969973890339 \n",
      "Epoch 19 | Step 7638 | loss: 0.1808810906271295 | accuracy: 0.935302734375 \n",
      "Epoch 19 | Step 7639 | loss: 0.1809137720663052 | accuracy: 0.9352272727272727 \n",
      "Epoch 19 | Step 7640 | loss: 0.18091020089395615 | accuracy: 0.9352331606217616 \n",
      "Epoch 19 | Step 7641 | loss: 0.18103242749276088 | accuracy: 0.9351582687338501 \n",
      "Epoch 19 | Step 7642 | loss: 0.18099478613969283 | accuracy: 0.9351643041237113 \n",
      "Epoch 19 | Step 7643 | loss: 0.1810413384594617 | accuracy: 0.9351301413881749 \n",
      "Epoch 19 | Step 7644 | loss: 0.18106097121460316 | accuracy: 0.935176282051282 \n",
      "Epoch 19 | Step 7645 | loss: 0.1810564624474329 | accuracy: 0.9351822250639387 \n",
      "Epoch 19 | Step 7646 | loss: 0.18097949629573493 | accuracy: 0.9351482780612245 \n",
      "Epoch 19 | Step 7647 | loss: 0.18098645660144683 | accuracy: 0.9351940203562341 \n",
      "Epoch 19 | Step 7648 | loss: 0.18098784144495042 | accuracy: 0.9351998730964467 \n",
      "Epoch 19 | Step 7649 | loss: 0.18091936734846875 | accuracy: 0.935245253164557 \n",
      "Epoch 19 | Step 7650 | loss: 0.1807713135982854 | accuracy: 0.9352904040404041 \n",
      "Epoch 19 | Step 7651 | loss: 0.1804924242536277 | accuracy: 0.9354140428211587 \n",
      "Epoch 19 | Step 7652 | loss: 0.18050194397830782 | accuracy: 0.9353800251256281 \n",
      "Epoch 19 | Step 7653 | loss: 0.1805595967797259 | accuracy: 0.9353070175438597 \n",
      "Epoch 19 | Step 7654 | loss: 0.18079514340497554 | accuracy: 0.9353125 \n",
      "Epoch 19 | Step 7655 | loss: 0.18064852502020518 | accuracy: 0.9353569201995012 \n",
      "Epoch 19 | Step 7656 | loss: 0.18100871925070808 | accuracy: 0.9351679104477612 \n",
      "Epoch 19 | Step 7657 | loss: 0.18074895063456767 | accuracy: 0.9352432189153382 \n",
      "Validation | Epoch 19 | Step 7657 | accuracy: 0.8524425639347597 \n",
      "Epoch 20 | Step 7658 | loss: 0.1421123594045639 | accuracy: 0.953125 \n",
      "Epoch 20 | Step 7659 | loss: 0.21021122485399246 | accuracy: 0.9140625 \n",
      "Epoch 20 | Step 7660 | loss: 0.18054970105489096 | accuracy: 0.9375 \n",
      "Epoch 20 | Step 7661 | loss: 0.1961836852133274 | accuracy: 0.93359375 \n",
      "Epoch 20 | Step 7662 | loss: 0.19091198742389678 | accuracy: 0.934375 \n",
      "Epoch 20 | Step 7663 | loss: 0.20041318982839584 | accuracy: 0.9296875 \n",
      "Epoch 20 | Step 7664 | loss: 0.20633964453424727 | accuracy: 0.9263392857142857 \n",
      "Epoch 20 | Step 7665 | loss: 0.21104157716035843 | accuracy: 0.92578125 \n",
      "Epoch 20 | Step 7666 | loss: 0.20597653422090742 | accuracy: 0.9253472222222222 \n",
      "Epoch 20 | Step 7667 | loss: 0.20746538043022156 | accuracy: 0.9234375 \n",
      "Epoch 20 | Step 7668 | loss: 0.2009147568182512 | accuracy: 0.9261363636363636 \n",
      "Epoch 20 | Step 7669 | loss: 0.20288023352622986 | accuracy: 0.92578125 \n",
      "Epoch 20 | Step 7670 | loss: 0.19974997410407433 | accuracy: 0.9254807692307693 \n",
      "Epoch 20 | Step 7671 | loss: 0.19709756757531846 | accuracy: 0.9274553571428571 \n",
      "Epoch 20 | Step 7672 | loss: 0.1885421022772789 | accuracy: 0.93125 \n",
      "Epoch 20 | Step 7673 | loss: 0.1859012828208506 | accuracy: 0.93359375 \n",
      "Epoch 20 | Step 7674 | loss: 0.1886985034627073 | accuracy: 0.9338235294117647 \n",
      "Epoch 20 | Step 7675 | loss: 0.18567554280161858 | accuracy: 0.9331597222222222 \n",
      "Epoch 20 | Step 7676 | loss: 0.1873102043020098 | accuracy: 0.9342105263157895 \n",
      "Epoch 20 | Step 7677 | loss: 0.18385978154838084 | accuracy: 0.93359375 \n",
      "Epoch 20 | Step 7678 | loss: 0.18028616160154343 | accuracy: 0.9345238095238095 \n",
      "Epoch 20 | Step 7679 | loss: 0.17788656089793553 | accuracy: 0.9346590909090909 \n",
      "Epoch 20 | Step 7680 | loss: 0.1771694561061652 | accuracy: 0.9347826086956522 \n",
      "Epoch 20 | Step 7681 | loss: 0.17304752332468828 | accuracy: 0.9361979166666666 \n",
      "Epoch 20 | Step 7682 | loss: 0.17099732011556626 | accuracy: 0.936875 \n",
      "Epoch 20 | Step 7683 | loss: 0.17015943991450164 | accuracy: 0.9368990384615384 \n",
      "Epoch 20 | Step 7684 | loss: 0.17004311277910514 | accuracy: 0.9357638888888888 \n",
      "Epoch 20 | Step 7685 | loss: 0.16724407273743833 | accuracy: 0.9369419642857143 \n",
      "Epoch 20 | Step 7686 | loss: 0.16540849157448473 | accuracy: 0.9375 \n",
      "Epoch 20 | Step 7687 | loss: 0.1674734557668368 | accuracy: 0.9369791666666667 \n",
      "Epoch 20 | Step 7688 | loss: 0.1672318068242842 | accuracy: 0.9380040322580645 \n",
      "Epoch 20 | Step 7689 | loss: 0.16918971668928862 | accuracy: 0.93603515625 \n",
      "Epoch 20 | Step 7690 | loss: 0.1701178794557398 | accuracy: 0.9351325757575758 \n",
      "Epoch 20 | Step 7691 | loss: 0.16830800670911283 | accuracy: 0.9356617647058824 \n",
      "Epoch 20 | Step 7692 | loss: 0.16573983814035143 | accuracy: 0.9370535714285714 \n",
      "Epoch 20 | Step 7693 | loss: 0.16639863575498262 | accuracy: 0.9366319444444444 \n",
      "Epoch 20 | Step 7694 | loss: 0.16461367784319697 | accuracy: 0.9366554054054054 \n",
      "Epoch 20 | Step 7695 | loss: 0.16619366681889483 | accuracy: 0.936266447368421 \n",
      "Epoch 20 | Step 7696 | loss: 0.166217904824477 | accuracy: 0.9354967948717948 \n",
      "Epoch 20 | Step 7697 | loss: 0.1659591890871525 | accuracy: 0.93515625 \n",
      "Epoch 20 | Step 7698 | loss: 0.16403218504132294 | accuracy: 0.9359756097560976 \n",
      "Epoch 20 | Step 7699 | loss: 0.16681191307448207 | accuracy: 0.9352678571428571 \n",
      "Epoch 20 | Step 7700 | loss: 0.1669166803706524 | accuracy: 0.9349563953488372 \n",
      "Epoch 20 | Step 7701 | loss: 0.1653359705074267 | accuracy: 0.9360795454545454 \n",
      "Epoch 20 | Step 7702 | loss: 0.16699271003405255 | accuracy: 0.9350694444444444 \n",
      "Epoch 20 | Step 7703 | loss: 0.16697056073209515 | accuracy: 0.9347826086956522 \n",
      "Epoch 20 | Step 7704 | loss: 0.16685990418525454 | accuracy: 0.9345079787234043 \n",
      "Epoch 20 | Step 7705 | loss: 0.16918968129903078 | accuracy: 0.9342447916666666 \n",
      "Epoch 20 | Step 7706 | loss: 0.16856141662111088 | accuracy: 0.9349489795918368 \n",
      "Epoch 20 | Step 7707 | loss: 0.1701680228114128 | accuracy: 0.9353125 \n",
      "Epoch 20 | Step 7708 | loss: 0.17393971512130663 | accuracy: 0.9338235294117647 \n",
      "Epoch 20 | Step 7709 | loss: 0.1739310034765647 | accuracy: 0.9341947115384616 \n",
      "Epoch 20 | Step 7710 | loss: 0.17243395548946452 | accuracy: 0.9345518867924528 \n",
      "Epoch 20 | Step 7711 | loss: 0.17147818387106614 | accuracy: 0.9343171296296297 \n",
      "Epoch 20 | Step 7712 | loss: 0.1721928372979164 | accuracy: 0.9338068181818182 \n",
      "Epoch 20 | Step 7713 | loss: 0.17337410617619753 | accuracy: 0.93359375 \n",
      "Epoch 20 | Step 7714 | loss: 0.1737425475005518 | accuracy: 0.9339364035087719 \n",
      "Epoch 20 | Step 7715 | loss: 0.17421094109785967 | accuracy: 0.9334590517241379 \n",
      "Epoch 20 | Step 7716 | loss: 0.1753806271037813 | accuracy: 0.9329978813559322 \n",
      "Epoch 20 | Step 7717 | loss: 0.1766262607028087 | accuracy: 0.9333333333333333 \n",
      "Epoch 20 | Step 7718 | loss: 0.17731749657236162 | accuracy: 0.9331454918032787 \n",
      "Epoch 20 | Step 7719 | loss: 0.1762240812663109 | accuracy: 0.9332157258064516 \n",
      "Epoch 20 | Step 7720 | loss: 0.17643180536845374 | accuracy: 0.9330357142857143 \n",
      "Epoch 20 | Step 7721 | loss: 0.17469047906342894 | accuracy: 0.93408203125 \n",
      "Epoch 20 | Step 7722 | loss: 0.17558272859224908 | accuracy: 0.9338942307692307 \n",
      "Epoch 20 | Step 7723 | loss: 0.17407784046548785 | accuracy: 0.9346590909090909 \n",
      "Epoch 20 | Step 7724 | loss: 0.1732684862035424 | accuracy: 0.9354011194029851 \n",
      "Epoch 20 | Step 7725 | loss: 0.17312087195322795 | accuracy: 0.9354319852941176 \n",
      "Epoch 20 | Step 7726 | loss: 0.17444156596194144 | accuracy: 0.9350090579710145 \n",
      "Epoch 20 | Step 7727 | loss: 0.17432503625750542 | accuracy: 0.9350446428571428 \n",
      "Epoch 20 | Step 7728 | loss: 0.17429218672111002 | accuracy: 0.9352992957746479 \n",
      "Epoch 20 | Step 7729 | loss: 0.1738615364043249 | accuracy: 0.935546875 \n",
      "Epoch 20 | Step 7730 | loss: 0.1740568448623566 | accuracy: 0.9357876712328768 \n",
      "Epoch 20 | Step 7731 | loss: 0.1747175278897221 | accuracy: 0.9347550675675675 \n",
      "Epoch 20 | Step 7732 | loss: 0.17593182573715846 | accuracy: 0.9341666666666667 \n",
      "Epoch 20 | Step 7733 | loss: 0.17465998075510325 | accuracy: 0.9346217105263158 \n",
      "Epoch 20 | Step 7734 | loss: 0.17419877435479844 | accuracy: 0.9346590909090909 \n",
      "Epoch 20 | Step 7735 | loss: 0.1755033920590694 | accuracy: 0.9340945512820513 \n",
      "Epoch 20 | Step 7736 | loss: 0.17458431649057168 | accuracy: 0.9345332278481012 \n",
      "Epoch 20 | Step 7737 | loss: 0.17482958249747751 | accuracy: 0.9341796875 \n",
      "Epoch 20 | Step 7738 | loss: 0.17471926374199948 | accuracy: 0.9344135802469136 \n",
      "Epoch 20 | Step 7739 | loss: 0.17425648613673883 | accuracy: 0.9344512195121951 \n",
      "Epoch 20 | Step 7740 | loss: 0.1748319149735462 | accuracy: 0.9344879518072289 \n",
      "Epoch 20 | Step 7741 | loss: 0.17576305532739273 | accuracy: 0.9343377976190477 \n",
      "Epoch 20 | Step 7742 | loss: 0.1769502906238331 | accuracy: 0.9336397058823529 \n",
      "Epoch 20 | Step 7743 | loss: 0.17655990532664362 | accuracy: 0.9342296511627907 \n",
      "Epoch 20 | Step 7744 | loss: 0.17659008074765914 | accuracy: 0.9339080459770115 \n",
      "Epoch 20 | Step 7745 | loss: 0.17765988595783708 | accuracy: 0.9339488636363636 \n",
      "Epoch 20 | Step 7746 | loss: 0.17740808628248364 | accuracy: 0.9339887640449438 \n",
      "Epoch 20 | Step 7747 | loss: 0.17861752460400263 | accuracy: 0.9335069444444445 \n",
      "Epoch 20 | Step 7748 | loss: 0.1779909788088484 | accuracy: 0.9337225274725275 \n",
      "Epoch 20 | Step 7749 | loss: 0.1797857575280511 | accuracy: 0.9334239130434783 \n",
      "Epoch 20 | Step 7750 | loss: 0.18024357296125862 | accuracy: 0.9331317204301075 \n",
      "Epoch 20 | Step 7751 | loss: 0.17968699978070057 | accuracy: 0.9331781914893617 \n",
      "Epoch 20 | Step 7752 | loss: 0.17846445002053912 | accuracy: 0.9337171052631579 \n",
      "Epoch 20 | Step 7753 | loss: 0.1780787454918027 | accuracy: 0.9337565104166666 \n"
     ]
    }
   ],
   "source": [
    "logger = SimpleLogger()\n",
    "train(20, model, train_iter, valid_iter, optimizer, criterion, task.train_step, task.eval_step, logger)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nano-seq-r7R1Yrai-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
