{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from nano_seq.task.classification import ClassificationTask, Config\n",
    "from nano_seq.data.utils import get_encoder_mask\n",
    "from nano_seq.logger import SimpleLogger\n",
    "from nano_seq.trainer import train\n",
    "from nano_seq.data import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = ClassificationTask(\n",
    "    Config(\n",
    "        embed_dims=8,\n",
    "        batch_size=64,\n",
    "        num_heads=2,\n",
    "        encoder_layers=1,\n",
    "        encoder_dropout=0.3,\n",
    "        spm_dict_path=\"../../model.vocab\",\n",
    "        left_pad_src=False,\n",
    "        train_path=\"../../data/train\",\n",
    "        valid_path=\"../../data/valid\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dictionary: 10000it [00:00, 1178241.47it/s]\n"
     ]
    }
   ],
   "source": [
    "dictionary = Dictionary.from_spm(\"../../model.vocab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dictionary: 10000it [00:00, 1245191.78it/s]\n",
      "Loading dataset: 25757it [00:00, 229677.93it/s]\n",
      "Loading dataset: 2862it [00:00, 224564.55it/s]\n"
     ]
    }
   ],
   "source": [
    "train_iter, valid_iter, model = task.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Step 1 | loss: 0.9300647377967834 | accuracy: 0.53125 \n",
      "Epoch 1 | Step 2 | loss: 0.8472145199775696 | accuracy: 0.59375 \n",
      "Epoch 1 | Step 3 | loss: 0.8254353205362955 | accuracy: 0.59375 \n",
      "Epoch 1 | Step 4 | loss: 0.8300240784883499 | accuracy: 0.5703125 \n",
      "Epoch 1 | Step 5 | loss: 0.8271782755851745 | accuracy: 0.55625 \n",
      "Epoch 1 | Step 6 | loss: 0.8231574694315592 | accuracy: 0.5546875 \n",
      "Epoch 1 | Step 7 | loss: 0.8250481316021511 | accuracy: 0.5401785714285714 \n",
      "Epoch 1 | Step 8 | loss: 0.8174914047122002 | accuracy: 0.52734375 \n",
      "Epoch 1 | Step 9 | loss: 0.8046575122409396 | accuracy: 0.5277777777777778 \n",
      "Epoch 1 | Step 10 | loss: 0.8020536482334137 | accuracy: 0.521875 \n",
      "Epoch 1 | Step 11 | loss: 0.7965392091057517 | accuracy: 0.5241477272727273 \n",
      "Epoch 1 | Step 12 | loss: 0.7925603340069453 | accuracy: 0.5182291666666666 \n",
      "Epoch 1 | Step 13 | loss: 0.7922681111555833 | accuracy: 0.5060096153846154 \n",
      "Epoch 1 | Step 14 | loss: 0.7871394625731877 | accuracy: 0.5044642857142857 \n",
      "Epoch 1 | Step 15 | loss: 0.7850782831509908 | accuracy: 0.5020833333333333 \n",
      "Epoch 1 | Step 16 | loss: 0.7807754352688789 | accuracy: 0.50390625 \n",
      "Epoch 1 | Step 17 | loss: 0.7819129368838142 | accuracy: 0.4963235294117647 \n",
      "Epoch 1 | Step 18 | loss: 0.7772708535194397 | accuracy: 0.4982638888888889 \n",
      "Epoch 1 | Step 19 | loss: 0.7738183234867296 | accuracy: 0.5008223684210527 \n",
      "Epoch 1 | Step 20 | loss: 0.7717087924480438 | accuracy: 0.5 \n",
      "Epoch 1 | Step 21 | loss: 0.7720259314491635 | accuracy: 0.49404761904761907 \n",
      "Epoch 1 | Step 22 | loss: 0.7703984163024209 | accuracy: 0.49360795454545453 \n",
      "Epoch 1 | Step 23 | loss: 0.7672076095705447 | accuracy: 0.49320652173913043 \n",
      "Epoch 1 | Step 24 | loss: 0.7653903439640999 | accuracy: 0.4921875 \n",
      "Epoch 1 | Step 25 | loss: 0.763889548778534 | accuracy: 0.49125 \n",
      "Epoch 1 | Step 26 | loss: 0.7632641081626599 | accuracy: 0.4879807692307692 \n",
      "Epoch 1 | Step 27 | loss: 0.7613083918889364 | accuracy: 0.4895833333333333 \n",
      "Epoch 1 | Step 28 | loss: 0.7600202453987939 | accuracy: 0.49107142857142855 \n",
      "Epoch 1 | Step 29 | loss: 0.7588107154287141 | accuracy: 0.49191810344827586 \n",
      "Epoch 1 | Step 30 | loss: 0.757018639643987 | accuracy: 0.490625 \n",
      "Epoch 1 | Step 31 | loss: 0.7553242214264408 | accuracy: 0.4899193548387097 \n",
      "Epoch 1 | Step 32 | loss: 0.7542481757700443 | accuracy: 0.48974609375 \n",
      "Epoch 1 | Step 33 | loss: 0.7520952333103527 | accuracy: 0.49195075757575757 \n",
      "Epoch 1 | Step 34 | loss: 0.7511581901241752 | accuracy: 0.49034926470588236 \n",
      "Epoch 1 | Step 35 | loss: 0.7504706740379333 | accuracy: 0.490625 \n",
      "Epoch 1 | Step 36 | loss: 0.7509698420763016 | accuracy: 0.4887152777777778 \n",
      "Epoch 1 | Step 37 | loss: 0.7503896065660425 | accuracy: 0.4877533783783784 \n",
      "Epoch 1 | Step 38 | loss: 0.7491586694591924 | accuracy: 0.4897203947368421 \n",
      "Epoch 1 | Step 39 | loss: 0.7482472062110901 | accuracy: 0.4895833333333333 \n",
      "Epoch 1 | Step 40 | loss: 0.7480987519025802 | accuracy: 0.48828125 \n",
      "Epoch 1 | Step 41 | loss: 0.74771836763475 | accuracy: 0.48628048780487804 \n",
      "Epoch 1 | Step 42 | loss: 0.7469117343425751 | accuracy: 0.48735119047619047 \n",
      "Epoch 1 | Step 43 | loss: 0.7461610547331876 | accuracy: 0.48655523255813954 \n",
      "Epoch 1 | Step 44 | loss: 0.7453301779248498 | accuracy: 0.4875710227272727 \n",
      "Epoch 1 | Step 45 | loss: 0.7438926047748989 | accuracy: 0.4895833333333333 \n",
      "Epoch 1 | Step 46 | loss: 0.7429420598175215 | accuracy: 0.4904891304347826 \n",
      "Epoch 1 | Step 47 | loss: 0.7427857404059552 | accuracy: 0.4903590425531915 \n",
      "Epoch 1 | Step 48 | loss: 0.742951696117719 | accuracy: 0.4889322916666667 \n",
      "Epoch 1 | Step 49 | loss: 0.7422944818224225 | accuracy: 0.48947704081632654 \n",
      "Epoch 1 | Step 50 | loss: 0.7413750422000885 | accuracy: 0.489375 \n",
      "Epoch 1 | Step 51 | loss: 0.7396038782362845 | accuracy: 0.49142156862745096 \n",
      "Epoch 1 | Step 52 | loss: 0.739565059542656 | accuracy: 0.4909855769230769 \n",
      "Epoch 1 | Step 53 | loss: 0.7392425300940028 | accuracy: 0.49056603773584906 \n",
      "Epoch 1 | Step 54 | loss: 0.7388670764587544 | accuracy: 0.4895833333333333 \n",
      "Epoch 1 | Step 55 | loss: 0.7381029139865528 | accuracy: 0.49204545454545456 \n",
      "Epoch 1 | Step 56 | loss: 0.7380767603005681 | accuracy: 0.4927455357142857 \n",
      "Epoch 1 | Step 57 | loss: 0.7379256779687446 | accuracy: 0.4920504385964912 \n",
      "Epoch 1 | Step 58 | loss: 0.7369225929523336 | accuracy: 0.49353448275862066 \n",
      "Epoch 1 | Step 59 | loss: 0.7361577648227497 | accuracy: 0.4947033898305085 \n",
      "Epoch 1 | Step 60 | loss: 0.7349752306938171 | accuracy: 0.49583333333333335 \n",
      "Epoch 1 | Step 61 | loss: 0.7351958526939643 | accuracy: 0.49436475409836067 \n",
      "Epoch 1 | Step 62 | loss: 0.734506651278465 | accuracy: 0.4959677419354839 \n",
      "Epoch 1 | Step 63 | loss: 0.7342484905606225 | accuracy: 0.49603174603174605 \n",
      "Epoch 1 | Step 64 | loss: 0.7332166070118546 | accuracy: 0.4970703125 \n",
      "Epoch 1 | Step 65 | loss: 0.733023279446822 | accuracy: 0.4971153846153846 \n",
      "Epoch 1 | Step 66 | loss: 0.7325782712661859 | accuracy: 0.4981060606060606 \n",
      "Epoch 1 | Step 67 | loss: 0.7325510302586342 | accuracy: 0.4979011194029851 \n",
      "Epoch 1 | Step 68 | loss: 0.7324610764489454 | accuracy: 0.49793198529411764 \n",
      "Epoch 1 | Step 69 | loss: 0.7324010513830876 | accuracy: 0.49818840579710144 \n",
      "Epoch 1 | Step 70 | loss: 0.7317033410072327 | accuracy: 0.4984375 \n",
      "Epoch 1 | Step 71 | loss: 0.7312267170825475 | accuracy: 0.4982394366197183 \n",
      "Epoch 1 | Step 72 | loss: 0.7304949851499664 | accuracy: 0.4991319444444444 \n",
      "Epoch 1 | Step 73 | loss: 0.7301092270302446 | accuracy: 0.4987157534246575 \n",
      "Epoch 1 | Step 74 | loss: 0.7299325595030913 | accuracy: 0.5 \n",
      "Epoch 1 | Step 75 | loss: 0.729563901424408 | accuracy: 0.4997916666666667 \n",
      "Epoch 1 | Step 76 | loss: 0.7289164427079653 | accuracy: 0.5010279605263158 \n",
      "Epoch 1 | Step 77 | loss: 0.7285388367516654 | accuracy: 0.5012175324675324 \n",
      "Epoch 1 | Step 78 | loss: 0.728399565586677 | accuracy: 0.5010016025641025 \n",
      "Epoch 1 | Step 79 | loss: 0.7282702432403082 | accuracy: 0.5013844936708861 \n",
      "Epoch 1 | Step 80 | loss: 0.7278301425278186 | accuracy: 0.5025390625 \n",
      "Epoch 1 | Step 81 | loss: 0.7281372951872555 | accuracy: 0.5007716049382716 \n",
      "Epoch 1 | Step 82 | loss: 0.7275437916197428 | accuracy: 0.5020960365853657 \n",
      "Epoch 1 | Step 83 | loss: 0.7274148255945688 | accuracy: 0.5013177710843372 \n",
      "Epoch 1 | Step 84 | loss: 0.7270870904127756 | accuracy: 0.5018601190476188 \n",
      "Epoch 1 | Step 85 | loss: 0.7265868909218732 | accuracy: 0.5022058823529411 \n",
      "Epoch 1 | Step 86 | loss: 0.7262609663397767 | accuracy: 0.5019985465116278 \n",
      "Epoch 1 | Step 87 | loss: 0.7262696623802185 | accuracy: 0.5008979885057471 \n",
      "Epoch 1 | Step 88 | loss: 0.7261167839169502 | accuracy: 0.5005326704545454 \n",
      "Epoch 1 | Step 89 | loss: 0.726075322440501 | accuracy: 0.4998244382022472 \n",
      "Epoch 1 | Step 90 | loss: 0.726082275973426 | accuracy: 0.49947916666666664 \n",
      "Epoch 1 | Step 91 | loss: 0.7255929066584661 | accuracy: 0.4994848901098901 \n",
      "Epoch 1 | Step 92 | loss: 0.724859642593757 | accuracy: 0.5001698369565217 \n",
      "Epoch 1 | Step 93 | loss: 0.7247570458278861 | accuracy: 0.5005040322580645 \n",
      "Epoch 1 | Step 94 | loss: 0.7246001851051411 | accuracy: 0.5 \n",
      "Epoch 1 | Step 95 | loss: 0.7241723976637188 | accuracy: 0.5004934210526316 \n",
      "Epoch 1 | Step 96 | loss: 0.7236259082953135 | accuracy: 0.5011393229166666 \n",
      "Epoch 1 | Step 97 | loss: 0.7233482888064433 | accuracy: 0.5022551546391752 \n",
      "Epoch 1 | Step 98 | loss: 0.7228590335164752 | accuracy: 0.5031887755102041 \n",
      "Epoch 1 | Step 99 | loss: 0.7226880620224307 | accuracy: 0.5026830808080809 \n",
      "Epoch 1 | Step 100 | loss: 0.7231163930892944 | accuracy: 0.5017187500000001 \n",
      "Epoch 1 | Step 101 | loss: 0.7227716428218501 | accuracy: 0.5023205445544555 \n",
      "Epoch 1 | Step 102 | loss: 0.7225881528620627 | accuracy: 0.5029105392156863 \n",
      "Epoch 1 | Step 103 | loss: 0.7224132314469051 | accuracy: 0.5024271844660194 \n",
      "Epoch 1 | Step 104 | loss: 0.722161556665714 | accuracy: 0.5030048076923077 \n",
      "Epoch 1 | Step 105 | loss: 0.7217021964845203 | accuracy: 0.503125 \n",
      "Epoch 1 | Step 106 | loss: 0.7219243730014225 | accuracy: 0.5026533018867925 \n",
      "Epoch 1 | Step 107 | loss: 0.7213844890906432 | accuracy: 0.5030665887850467 \n",
      "Epoch 1 | Step 108 | loss: 0.7212788335703038 | accuracy: 0.5027488425925926 \n",
      "Epoch 1 | Step 109 | loss: 0.7207797858693185 | accuracy: 0.5030103211009175 \n",
      "Epoch 1 | Step 110 | loss: 0.7202293959530917 | accuracy: 0.5039772727272728 \n",
      "Epoch 1 | Step 111 | loss: 0.7200307346679069 | accuracy: 0.5038006756756758 \n",
      "Epoch 1 | Step 112 | loss: 0.7203929179481098 | accuracy: 0.5029296875000001 \n",
      "Epoch 1 | Step 113 | loss: 0.7196556240056469 | accuracy: 0.5041482300884957 \n",
      "Epoch 1 | Step 114 | loss: 0.7193369227543212 | accuracy: 0.5041118421052634 \n",
      "Epoch 1 | Step 115 | loss: 0.7198048327280128 | accuracy: 0.5031250000000003 \n",
      "Epoch 1 | Step 116 | loss: 0.7195627509519972 | accuracy: 0.50323275862069 \n",
      "Epoch 1 | Step 117 | loss: 0.7194060805516366 | accuracy: 0.5032051282051285 \n",
      "Epoch 1 | Step 118 | loss: 0.7192523348129402 | accuracy: 0.5033103813559325 \n",
      "Epoch 1 | Step 119 | loss: 0.7188693500366532 | accuracy: 0.504464285714286 \n",
      "Epoch 1 | Step 120 | loss: 0.7190434133013089 | accuracy: 0.5039062500000003 \n",
      "Epoch 1 | Step 121 | loss: 0.7184093308842872 | accuracy: 0.5051652892561987 \n",
      "Epoch 1 | Step 122 | loss: 0.7179267240352318 | accuracy: 0.5060194672131152 \n",
      "Epoch 1 | Step 123 | loss: 0.7178228182521292 | accuracy: 0.5067327235772362 \n",
      "Epoch 1 | Step 124 | loss: 0.7178902928867648 | accuracy: 0.506426411290323 \n",
      "Epoch 1 | Step 125 | loss: 0.7177509365081787 | accuracy: 0.5063750000000004 \n",
      "Epoch 1 | Step 126 | loss: 0.7178061708571419 | accuracy: 0.5060763888888892 \n",
      "Epoch 1 | Step 127 | loss: 0.7173297386469804 | accuracy: 0.5071358267716538 \n",
      "Epoch 1 | Step 128 | loss: 0.7170931859873235 | accuracy: 0.5075683593750002 \n",
      "Epoch 1 | Step 129 | loss: 0.7170520923858466 | accuracy: 0.5076308139534886 \n",
      "Epoch 1 | Step 130 | loss: 0.7166417355720813 | accuracy: 0.5084134615384618 \n",
      "Epoch 1 | Step 131 | loss: 0.71630986228244 | accuracy: 0.5087070610687026 \n",
      "Epoch 1 | Step 132 | loss: 0.716362895839142 | accuracy: 0.5082859848484851 \n",
      "Epoch 1 | Step 133 | loss: 0.7162337764761502 | accuracy: 0.5088110902255641 \n",
      "Epoch 1 | Step 134 | loss: 0.7156291208160457 | accuracy: 0.5100279850746271 \n",
      "Epoch 1 | Step 135 | loss: 0.7153744180997212 | accuracy: 0.5106481481481484 \n",
      "Epoch 1 | Step 136 | loss: 0.7150517154265853 | accuracy: 0.5113740808823531 \n",
      "Epoch 1 | Step 137 | loss: 0.7150273879949194 | accuracy: 0.5112910583941608 \n",
      "Epoch 1 | Step 138 | loss: 0.7148058595864669 | accuracy: 0.5117753623188408 \n",
      "Epoch 1 | Step 139 | loss: 0.7147634175183962 | accuracy: 0.511803057553957 \n",
      "Epoch 1 | Step 140 | loss: 0.7148303768464498 | accuracy: 0.511607142857143 \n",
      "Epoch 1 | Step 141 | loss: 0.7146721029957982 | accuracy: 0.5123005319148938 \n",
      "Epoch 1 | Step 142 | loss: 0.7142208340302321 | accuracy: 0.5129841549295777 \n",
      "Epoch 1 | Step 143 | loss: 0.7140463140460995 | accuracy: 0.5134396853146856 \n",
      "Epoch 1 | Step 144 | loss: 0.7137915314071709 | accuracy: 0.5142144097222225 \n",
      "Epoch 1 | Step 145 | loss: 0.7137020419383873 | accuracy: 0.5141163793103452 \n",
      "Epoch 1 | Step 146 | loss: 0.7138345151731414 | accuracy: 0.513377568493151 \n",
      "Epoch 1 | Step 147 | loss: 0.713677265206162 | accuracy: 0.5134991496598642 \n",
      "Epoch 1 | Step 148 | loss: 0.7135711042462171 | accuracy: 0.5137246621621625 \n",
      "Epoch 1 | Step 149 | loss: 0.7134828095468101 | accuracy: 0.5140520134228191 \n",
      "Epoch 1 | Step 150 | loss: 0.713210793733597 | accuracy: 0.5145833333333337 \n",
      "Epoch 1 | Step 151 | loss: 0.7132679966111848 | accuracy: 0.5139693708609275 \n",
      "Epoch 1 | Step 152 | loss: 0.7130968762855783 | accuracy: 0.5145970394736846 \n",
      "Epoch 1 | Step 153 | loss: 0.713096714487263 | accuracy: 0.5143995098039219 \n",
      "Epoch 1 | Step 154 | loss: 0.7129153558960211 | accuracy: 0.514711850649351 \n",
      "Epoch 1 | Step 155 | loss: 0.7124701296129536 | accuracy: 0.5155241935483874 \n",
      "Epoch 1 | Step 156 | loss: 0.7122922283716693 | accuracy: 0.5156250000000002 \n",
      "Epoch 1 | Step 157 | loss: 0.7119601479001867 | accuracy: 0.5166202229299365 \n",
      "Epoch 1 | Step 158 | loss: 0.7117720329308813 | accuracy: 0.5170094936708862 \n",
      "Epoch 1 | Step 159 | loss: 0.7115858009776231 | accuracy: 0.5172955974842769 \n",
      "Epoch 1 | Step 160 | loss: 0.7113821461796762 | accuracy: 0.5176757812500001 \n",
      "Epoch 1 | Step 161 | loss: 0.7111160477496083 | accuracy: 0.517468944099379 \n",
      "Epoch 1 | Step 162 | loss: 0.710789176049056 | accuracy: 0.5182291666666669 \n",
      "Epoch 1 | Step 163 | loss: 0.7106610927845072 | accuracy: 0.5182131901840492 \n",
      "Epoch 1 | Step 164 | loss: 0.7105110153192427 | accuracy: 0.5180068597560977 \n",
      "Epoch 1 | Step 165 | loss: 0.7102941773154517 | accuracy: 0.5181818181818183 \n",
      "Epoch 1 | Step 166 | loss: 0.7103045029812547 | accuracy: 0.5179781626506025 \n",
      "Epoch 1 | Step 167 | loss: 0.7100886966653925 | accuracy: 0.518619011976048 \n",
      "Epoch 1 | Step 168 | loss: 0.7100198464024634 | accuracy: 0.5186941964285715 \n",
      "Epoch 1 | Step 169 | loss: 0.7098653157787209 | accuracy: 0.5185835798816569 \n",
      "Epoch 1 | Step 170 | loss: 0.7098880098146549 | accuracy: 0.518933823529412 \n",
      "Epoch 1 | Step 171 | loss: 0.7096307521675064 | accuracy: 0.5194627192982458 \n",
      "Epoch 1 | Step 172 | loss: 0.7094605745271193 | accuracy: 0.5198946220930235 \n",
      "Epoch 1 | Step 173 | loss: 0.7089027025107013 | accuracy: 0.5205924855491332 \n",
      "Epoch 1 | Step 174 | loss: 0.7085937994650039 | accuracy: 0.5213721264367819 \n",
      "Epoch 1 | Step 175 | loss: 0.708484342098236 | accuracy: 0.521339285714286 \n",
      "Epoch 1 | Step 176 | loss: 0.708338959311897 | accuracy: 0.5214843750000003 \n",
      "Epoch 1 | Step 177 | loss: 0.7086010800916596 | accuracy: 0.5208333333333337 \n",
      "Epoch 1 | Step 178 | loss: 0.7086091945680338 | accuracy: 0.5208918539325846 \n",
      "Epoch 1 | Step 179 | loss: 0.7083468620337586 | accuracy: 0.5214734636871512 \n",
      "Epoch 1 | Step 180 | loss: 0.7080110020107692 | accuracy: 0.5219618055555558 \n",
      "Epoch 1 | Step 181 | loss: 0.7077006246503544 | accuracy: 0.5223584254143648 \n",
      "Epoch 1 | Step 182 | loss: 0.7072722784110477 | accuracy: 0.5234375000000001 \n",
      "Epoch 1 | Step 183 | loss: 0.7071506560174492 | accuracy: 0.5232240437158471 \n",
      "Epoch 1 | Step 184 | loss: 0.7072174510230187 | accuracy: 0.5234375000000001 \n",
      "Epoch 1 | Step 185 | loss: 0.7069471223934275 | accuracy: 0.5239020270270272 \n",
      "Epoch 1 | Step 186 | loss: 0.7067923879110684 | accuracy: 0.5237735215053765 \n",
      "Epoch 1 | Step 187 | loss: 0.7066038945779441 | accuracy: 0.5242312834224601 \n",
      "Epoch 1 | Step 188 | loss: 0.7064089790937746 | accuracy: 0.524434840425532 \n",
      "Epoch 1 | Step 189 | loss: 0.7059830518626661 | accuracy: 0.5252976190476191 \n",
      "Epoch 1 | Step 190 | loss: 0.7058190129305185 | accuracy: 0.5254934210526315 \n",
      "Epoch 1 | Step 191 | loss: 0.7055015679429337 | accuracy: 0.5260143979057591 \n",
      "Epoch 1 | Step 192 | loss: 0.7053814915319282 | accuracy: 0.5260416666666666 \n",
      "Epoch 1 | Step 193 | loss: 0.7053167171428857 | accuracy: 0.526473445595855 \n",
      "Epoch 1 | Step 194 | loss: 0.7051593151289162 | accuracy: 0.5265786082474228 \n",
      "Epoch 1 | Step 195 | loss: 0.7051302277124843 | accuracy: 0.5267628205128206 \n",
      "Epoch 1 | Step 196 | loss: 0.704660409263202 | accuracy: 0.5275031887755104 \n",
      "Epoch 1 | Step 197 | loss: 0.7041640317984642 | accuracy: 0.5279980964467007 \n",
      "Epoch 1 | Step 198 | loss: 0.7041203662602586 | accuracy: 0.5280934343434346 \n",
      "Epoch 1 | Step 199 | loss: 0.7041102393188667 | accuracy: 0.5283448492462314 \n",
      "Epoch 1 | Step 200 | loss: 0.703848847746849 | accuracy: 0.5285156250000003 \n",
      "Epoch 1 | Step 201 | loss: 0.7035591006278991 | accuracy: 0.5289179104477615 \n",
      "Epoch 1 | Step 202 | loss: 0.703468088466342 | accuracy: 0.5286200495049508 \n",
      "Epoch 1 | Step 203 | loss: 0.7032873366266634 | accuracy: 0.5289408866995077 \n",
      "Epoch 1 | Step 204 | loss: 0.7031225833822697 | accuracy: 0.5288756127450983 \n",
      "Epoch 1 | Step 205 | loss: 0.7029656962650577 | accuracy: 0.529192073170732 \n",
      "Epoch 1 | Step 206 | loss: 0.7027681961800287 | accuracy: 0.5295054611650489 \n",
      "Epoch 1 | Step 207 | loss: 0.7024348291797913 | accuracy: 0.5298913043478265 \n",
      "Epoch 1 | Step 208 | loss: 0.7021853903738351 | accuracy: 0.5302734375000004 \n",
      "Epoch 1 | Step 209 | loss: 0.7021628524127758 | accuracy: 0.530502392344498 \n",
      "Epoch 1 | Step 210 | loss: 0.7018654465675352 | accuracy: 0.5309523809523814 \n",
      "Epoch 1 | Step 211 | loss: 0.7016763938546744 | accuracy: 0.5309537914691947 \n",
      "Epoch 1 | Step 212 | loss: 0.7015515335325924 | accuracy: 0.5314711084905664 \n",
      "Epoch 1 | Step 213 | loss: 0.7014370781714926 | accuracy: 0.5315434272300473 \n",
      "Epoch 1 | Step 214 | loss: 0.7012753932275504 | accuracy: 0.5320531542056078 \n",
      "Epoch 1 | Step 215 | loss: 0.7009304212969402 | accuracy: 0.5324854651162794 \n",
      "Epoch 1 | Step 216 | loss: 0.7006029663262543 | accuracy: 0.5332031250000002 \n",
      "Epoch 1 | Step 217 | loss: 0.7007811000819578 | accuracy: 0.5329781105990785 \n",
      "Epoch 1 | Step 218 | loss: 0.7005896765157715 | accuracy: 0.5331135321100919 \n",
      "Epoch 1 | Step 219 | loss: 0.700231628330875 | accuracy: 0.5338898401826486 \n",
      "Epoch 1 | Step 220 | loss: 0.6997955815358594 | accuracy: 0.5344460227272729 \n",
      "Epoch 1 | Step 221 | loss: 0.699545221630804 | accuracy: 0.5345729638009051 \n",
      "Epoch 1 | Step 222 | loss: 0.6993253475373928 | accuracy: 0.5351210585585587 \n",
      "Epoch 1 | Step 223 | loss: 0.6989869542186035 | accuracy: 0.5358043721973096 \n",
      "Epoch 1 | Step 224 | loss: 0.698691567139966 | accuracy: 0.5363420758928573 \n",
      "Epoch 1 | Step 225 | loss: 0.6987324968973795 | accuracy: 0.536388888888889 \n",
      "Epoch 1 | Step 226 | loss: 0.6986595044093848 | accuracy: 0.5365044247787611 \n",
      "Epoch 1 | Step 227 | loss: 0.6985063106478047 | accuracy: 0.5366189427312776 \n",
      "Epoch 1 | Step 228 | loss: 0.6982772883615994 | accuracy: 0.5370065789473686 \n",
      "Epoch 1 | Step 229 | loss: 0.6979384698201474 | accuracy: 0.5375955240174675 \n",
      "Epoch 1 | Step 230 | loss: 0.6973340581292691 | accuracy: 0.5384510869565219 \n",
      "Epoch 1 | Step 231 | loss: 0.6975829593546977 | accuracy: 0.5380817099567101 \n",
      "Epoch 1 | Step 232 | loss: 0.6971865923240266 | accuracy: 0.5386584051724139 \n",
      "Epoch 1 | Step 233 | loss: 0.6972041309135665 | accuracy: 0.538760729613734 \n",
      "Epoch 1 | Step 234 | loss: 0.697110230087215 | accuracy: 0.5389957264957266 \n",
      "Epoch 1 | Step 235 | loss: 0.6969686084605277 | accuracy: 0.5390957446808511 \n",
      "Epoch 1 | Step 236 | loss: 0.6965072781352672 | accuracy: 0.5396583686440678 \n",
      "Epoch 1 | Step 237 | loss: 0.6965845516462366 | accuracy: 0.5398206751054853 \n",
      "Epoch 1 | Step 238 | loss: 0.6966133598519973 | accuracy: 0.5397846638655462 \n",
      "Epoch 1 | Step 239 | loss: 0.6962864351571852 | accuracy: 0.5403373430962343 \n",
      "Epoch 1 | Step 240 | loss: 0.6961559809744357 | accuracy: 0.5403645833333334 \n",
      "Epoch 1 | Step 241 | loss: 0.696078549776829 | accuracy: 0.5405860995850622 \n",
      "Epoch 1 | Step 242 | loss: 0.696198245956878 | accuracy: 0.5403538223140496 \n",
      "Epoch 1 | Step 243 | loss: 0.6958632662953662 | accuracy: 0.5409593621399177 \n",
      "Epoch 1 | Step 244 | loss: 0.6955487039245541 | accuracy: 0.5413678278688525 \n",
      "Epoch 1 | Step 245 | loss: 0.6955532171288314 | accuracy: 0.5412627551020408 \n",
      "Epoch 1 | Step 246 | loss: 0.6954340716687644 | accuracy: 0.5413490853658537 \n",
      "Epoch 1 | Step 247 | loss: 0.6950976095701518 | accuracy: 0.5416244939271255 \n",
      "Epoch 1 | Step 248 | loss: 0.6950326105279306 | accuracy: 0.5418346774193549 \n",
      "Epoch 1 | Step 249 | loss: 0.6950731112296321 | accuracy: 0.5417294176706827 \n",
      "Epoch 1 | Step 250 | loss: 0.6948189129829405 | accuracy: 0.5421875 \n",
      "Epoch 1 | Step 251 | loss: 0.6947588806608282 | accuracy: 0.5425174302788844 \n",
      "Epoch 1 | Step 252 | loss: 0.6947416781433043 | accuracy: 0.543030753968254 \n",
      "Epoch 1 | Step 253 | loss: 0.6944661811877615 | accuracy: 0.5431694664031621 \n",
      "Epoch 1 | Step 254 | loss: 0.6941828647936422 | accuracy: 0.5433686023622047 \n",
      "Epoch 1 | Step 255 | loss: 0.6941409351778964 | accuracy: 0.5435661764705882 \n",
      "Epoch 1 | Step 256 | loss: 0.69385520927608 | accuracy: 0.5438232421875 \n",
      "Epoch 1 | Step 257 | loss: 0.6935987041154259 | accuracy: 0.5441999027237354 \n",
      "Epoch 1 | Step 258 | loss: 0.6933814081572746 | accuracy: 0.5446947674418605 \n",
      "Epoch 1 | Step 259 | loss: 0.6932981594188792 | accuracy: 0.5450048262548263 \n",
      "Epoch 1 | Step 260 | loss: 0.6932471967660463 | accuracy: 0.5450721153846154 \n",
      "Epoch 1 | Step 261 | loss: 0.6929046536770815 | accuracy: 0.5454382183908046 \n",
      "Epoch 1 | Step 262 | loss: 0.6928983212427328 | accuracy: 0.5456822519083969 \n",
      "Epoch 1 | Step 263 | loss: 0.6926132073420534 | accuracy: 0.5463997148288974 \n",
      "Epoch 1 | Step 264 | loss: 0.6921790700518723 | accuracy: 0.5471117424242424 \n",
      "Epoch 1 | Step 265 | loss: 0.6919649036425464 | accuracy: 0.5476415094339623 \n",
      "Epoch 1 | Step 266 | loss: 0.6917755081689446 | accuracy: 0.5479323308270677 \n",
      "Epoch 1 | Step 267 | loss: 0.6915806585483336 | accuracy: 0.5482794943820225 \n",
      "Epoch 1 | Step 268 | loss: 0.6914940912332107 | accuracy: 0.5485074626865671 \n",
      "Epoch 1 | Step 269 | loss: 0.6912164267111001 | accuracy: 0.5489660780669146 \n",
      "Epoch 1 | Step 270 | loss: 0.6910280905388019 | accuracy: 0.5491319444444446 \n",
      "Epoch 1 | Step 271 | loss: 0.6909563519418018 | accuracy: 0.5490083025830259 \n",
      "Epoch 1 | Step 272 | loss: 0.6908210093045934 | accuracy: 0.5491727941176472 \n",
      "Epoch 1 | Step 273 | loss: 0.6906775199013314 | accuracy: 0.5494505494505496 \n",
      "Epoch 1 | Step 274 | loss: 0.6905471671671762 | accuracy: 0.5496692518248177 \n",
      "Epoch 1 | Step 275 | loss: 0.6905259600552645 | accuracy: 0.5498863636363639 \n",
      "Epoch 1 | Step 276 | loss: 0.690631409054217 | accuracy: 0.5497622282608698 \n",
      "Epoch 1 | Step 277 | loss: 0.6905299005525636 | accuracy: 0.5498646209386284 \n",
      "Epoch 1 | Step 278 | loss: 0.6905722821787964 | accuracy: 0.55007868705036 \n",
      "Epoch 1 | Step 279 | loss: 0.6903283177310848 | accuracy: 0.5505152329749107 \n",
      "Epoch 1 | Step 280 | loss: 0.6901626950928144 | accuracy: 0.5507812500000003 \n",
      "Epoch 1 | Step 281 | loss: 0.6900155162471894 | accuracy: 0.5511009786476871 \n",
      "Epoch 1 | Step 282 | loss: 0.6896289542634436 | accuracy: 0.5516954787234045 \n",
      "Epoch 1 | Step 283 | loss: 0.6895830262676145 | accuracy: 0.5518440812720851 \n",
      "Epoch 1 | Step 284 | loss: 0.689367691395988 | accuracy: 0.5521016725352116 \n",
      "Epoch 1 | Step 285 | loss: 0.6892432992918449 | accuracy: 0.5523574561403511 \n",
      "Epoch 1 | Step 286 | loss: 0.6888037526107335 | accuracy: 0.5528846153846156 \n",
      "Epoch 1 | Step 287 | loss: 0.6886659023653755 | accuracy: 0.553244773519164 \n",
      "Epoch 1 | Step 288 | loss: 0.6884390198522143 | accuracy: 0.5537109375000003 \n",
      "Epoch 1 | Step 289 | loss: 0.6886091133302471 | accuracy: 0.5537954152249138 \n",
      "Epoch 1 | Step 290 | loss: 0.6885748154130475 | accuracy: 0.5540948275862072 \n",
      "Epoch 1 | Step 291 | loss: 0.6887343351783621 | accuracy: 0.5538552405498285 \n",
      "Epoch 1 | Step 292 | loss: 0.6885598081431977 | accuracy: 0.5541523972602742 \n",
      "Epoch 1 | Step 293 | loss: 0.6884435219976276 | accuracy: 0.5540742320819114 \n",
      "Epoch 1 | Step 294 | loss: 0.6883075494750017 | accuracy: 0.554262329931973 \n",
      "Epoch 1 | Step 295 | loss: 0.6882659002885981 | accuracy: 0.5546080508474578 \n",
      "Epoch 1 | Step 296 | loss: 0.6878232742483552 | accuracy: 0.555268158783784 \n",
      "Epoch 1 | Step 297 | loss: 0.687763319071696 | accuracy: 0.5555029461279464 \n",
      "Epoch 1 | Step 298 | loss: 0.6875421162819704 | accuracy: 0.5555788590604029 \n",
      "Epoch 1 | Step 299 | loss: 0.6873864675046609 | accuracy: 0.5557587792642144 \n",
      "Epoch 1 | Step 300 | loss: 0.6872310692071916 | accuracy: 0.5557812500000003 \n",
      "Epoch 1 | Step 301 | loss: 0.6871887835553319 | accuracy: 0.5557516611295685 \n",
      "Epoch 1 | Step 302 | loss: 0.6871196635511537 | accuracy: 0.555825745033113 \n",
      "Epoch 1 | Step 303 | loss: 0.6870514152467054 | accuracy: 0.5558993399339938 \n",
      "Epoch 1 | Step 304 | loss: 0.6870997675547474 | accuracy: 0.5558696546052635 \n",
      "Epoch 1 | Step 305 | loss: 0.686938093724798 | accuracy: 0.5560450819672135 \n",
      "Epoch 1 | Step 306 | loss: 0.6866416981796813 | accuracy: 0.556525735294118 \n",
      "Epoch 1 | Step 307 | loss: 0.6865244465076186 | accuracy: 0.5567996742671013 \n",
      "Epoch 1 | Step 308 | loss: 0.6863944702721262 | accuracy: 0.5569703733766237 \n",
      "Epoch 1 | Step 309 | loss: 0.6862276090387388 | accuracy: 0.5573927993527511 \n",
      "Epoch 1 | Step 310 | loss: 0.6860197705607262 | accuracy: 0.5576108870967744 \n",
      "Epoch 1 | Step 311 | loss: 0.6857244408782273 | accuracy: 0.5579782958199359 \n",
      "Epoch 1 | Step 312 | loss: 0.6855117604136468 | accuracy: 0.5581430288461541 \n",
      "Epoch 1 | Step 313 | loss: 0.6851602830825904 | accuracy: 0.5586561501597447 \n",
      "Epoch 1 | Step 314 | loss: 0.6851202982246496 | accuracy: 0.558817675159236 \n",
      "Epoch 1 | Step 315 | loss: 0.6848215309400407 | accuracy: 0.5593253968253971 \n",
      "Epoch 1 | Step 316 | loss: 0.6847496215678468 | accuracy: 0.5592859968354433 \n",
      "Epoch 1 | Step 317 | loss: 0.684477206096288 | accuracy: 0.5595918769716091 \n",
      "Epoch 1 | Step 318 | loss: 0.6843334826283484 | accuracy: 0.5596992924528305 \n",
      "Epoch 1 | Step 319 | loss: 0.6841427874415645 | accuracy: 0.5600019592476492 \n",
      "Epoch 1 | Step 320 | loss: 0.6841696564108133 | accuracy: 0.5600585937500002 \n",
      "Epoch 1 | Step 321 | loss: 0.6839220794933236 | accuracy: 0.5603095794392525 \n",
      "Epoch 1 | Step 322 | loss: 0.6839082324356767 | accuracy: 0.5603163819875778 \n",
      "Epoch 1 | Step 323 | loss: 0.683678573130085 | accuracy: 0.5607101393188856 \n",
      "Epoch 1 | Step 324 | loss: 0.6834448791212505 | accuracy: 0.5610532407407409 \n",
      "Epoch 1 | Step 325 | loss: 0.6833302404330326 | accuracy: 0.5612980769230771 \n",
      "Epoch 1 | Step 326 | loss: 0.6831089739053526 | accuracy: 0.5618289877300615 \n",
      "Epoch 1 | Step 327 | loss: 0.6830349227339484 | accuracy: 0.5619266055045873 \n",
      "Epoch 1 | Step 328 | loss: 0.6828668059372319 | accuracy: 0.5621665396341464 \n",
      "Epoch 1 | Step 329 | loss: 0.6829227803325942 | accuracy: 0.562025075987842 \n",
      "Epoch 1 | Step 330 | loss: 0.682818830013275 | accuracy: 0.5623579545454547 \n",
      "Epoch 1 | Step 331 | loss: 0.6825923159763532 | accuracy: 0.5625472054380667 \n",
      "Epoch 1 | Step 332 | loss: 0.6824322448796537 | accuracy: 0.5627823795180725 \n",
      "Epoch 1 | Step 333 | loss: 0.6822032794222103 | accuracy: 0.5631569069069071 \n",
      "Epoch 1 | Step 334 | loss: 0.6820040935884694 | accuracy: 0.5634824101796408 \n",
      "Epoch 1 | Step 335 | loss: 0.6817835110336988 | accuracy: 0.563992537313433 \n",
      "Epoch 1 | Step 336 | loss: 0.6814288658400378 | accuracy: 0.5644066220238096 \n",
      "Epoch 1 | Step 337 | loss: 0.6813066223254899 | accuracy: 0.5644473293768547 \n",
      "Epoch 1 | Step 338 | loss: 0.6812510351104851 | accuracy: 0.56458025147929 \n",
      "Epoch 1 | Step 339 | loss: 0.6812066590539827 | accuracy: 0.564712389380531 \n",
      "Epoch 1 | Step 340 | loss: 0.6810470235698365 | accuracy: 0.5649816176470589 \n",
      "Epoch 1 | Step 341 | loss: 0.6806938681434678 | accuracy: 0.5654325513196482 \n",
      "Epoch 1 | Step 342 | loss: 0.6805106878977771 | accuracy: 0.5656524122807018 \n",
      "Epoch 1 | Step 343 | loss: 0.6803259350815599 | accuracy: 0.5660532069970846 \n",
      "Epoch 1 | Step 344 | loss: 0.6800342488080958 | accuracy: 0.566451671511628 \n",
      "Epoch 1 | Step 345 | loss: 0.6801421355510106 | accuracy: 0.5666213768115943 \n",
      "Epoch 1 | Step 346 | loss: 0.6798802509128704 | accuracy: 0.5670610549132948 \n",
      "Epoch 1 | Step 347 | loss: 0.6795556816656241 | accuracy: 0.5675432276657061 \n",
      "Epoch 1 | Step 348 | loss: 0.679517878026798 | accuracy: 0.5677981321839081 \n",
      "Epoch 1 | Step 349 | loss: 0.6794944265510429 | accuracy: 0.5678277220630372 \n",
      "Epoch 1 | Step 350 | loss: 0.6792150735855104 | accuracy: 0.5682589285714286 \n",
      "Epoch 1 | Step 351 | loss: 0.6789870876871963 | accuracy: 0.568420584045584 \n",
      "Epoch 1 | Step 352 | loss: 0.6787962473251604 | accuracy: 0.5687144886363636 \n",
      "Epoch 1 | Step 353 | loss: 0.6787142665798199 | accuracy: 0.5687411473087819 \n",
      "Epoch 1 | Step 354 | loss: 0.6786370609102951 | accuracy: 0.5687676553672316 \n",
      "Epoch 1 | Step 355 | loss: 0.6784202260030828 | accuracy: 0.5690580985915493 \n",
      "Epoch 1 | Step 356 | loss: 0.6783828197905188 | accuracy: 0.5690396769662921 \n",
      "Epoch 1 | Step 357 | loss: 0.6782987513462037 | accuracy: 0.5692401960784313 \n",
      "Epoch 1 | Step 358 | loss: 0.6784503756288711 | accuracy: 0.5689594972067039 \n",
      "Epoch 1 | Step 359 | loss: 0.6781785225801815 | accuracy: 0.5692026462395543 \n",
      "Epoch 1 | Step 360 | loss: 0.6779620261655915 | accuracy: 0.5694878472222222 \n",
      "Epoch 1 | Step 361 | loss: 0.6777976551544634 | accuracy: 0.5695983379501385 \n",
      "Epoch 1 | Step 362 | loss: 0.6775367704544278 | accuracy: 0.5699240331491713 \n",
      "Epoch 1 | Step 363 | loss: 0.6774623822574773 | accuracy: 0.5699896694214877 \n",
      "Epoch 1 | Step 364 | loss: 0.6772663850378204 | accuracy: 0.5698832417582418 \n",
      "Epoch 1 | Step 365 | loss: 0.677159690203732 | accuracy: 0.5699914383561644 \n",
      "Epoch 1 | Step 366 | loss: 0.6769004314323592 | accuracy: 0.5702698087431693 \n",
      "Epoch 1 | Step 367 | loss: 0.6768267458401194 | accuracy: 0.5705466621253406 \n",
      "Epoch 1 | Step 368 | loss: 0.6766672403268192 | accuracy: 0.5706946331521738 \n",
      "Epoch 1 | Step 369 | loss: 0.6765524576996077 | accuracy: 0.5707994579945799 \n",
      "Epoch 1 | Step 370 | loss: 0.6765795805969754 | accuracy: 0.5707770270270269 \n",
      "Epoch 1 | Step 371 | loss: 0.6764711038764276 | accuracy: 0.5710495283018867 \n",
      "Epoch 1 | Step 372 | loss: 0.6763449455461196 | accuracy: 0.571362567204301 \n",
      "Epoch 1 | Step 373 | loss: 0.6761879508680698 | accuracy: 0.571590147453083 \n",
      "Epoch 1 | Step 374 | loss: 0.6761347715229913 | accuracy: 0.5718165106951871 \n",
      "Epoch 1 | Step 375 | loss: 0.67603262090683 | accuracy: 0.57175 \n",
      "Epoch 1 | Step 376 | loss: 0.6759151396282178 | accuracy: 0.571766954787234 \n",
      "Epoch 1 | Step 377 | loss: 0.6758830561561991 | accuracy: 0.5719081564986738 \n",
      "Epoch 1 | Step 378 | loss: 0.6759025076078993 | accuracy: 0.5718419312169312 \n",
      "Epoch 1 | Step 379 | loss: 0.6756039384487125 | accuracy: 0.5721058707124009 \n",
      "Epoch 1 | Step 380 | loss: 0.6755035122758467 | accuracy: 0.5721628289473683 \n",
      "Epoch 1 | Step 381 | loss: 0.6753610090946591 | accuracy: 0.5720964566929132 \n",
      "Epoch 1 | Step 382 | loss: 0.6752009831798017 | accuracy: 0.5721531413612564 \n",
      "Epoch 1 | Step 383 | loss: 0.6750476330752164 | accuracy: 0.5722911227154045 \n",
      "Epoch 1 | Step 384 | loss: 0.6749693743574126 | accuracy: 0.5722249348958331 \n",
      "Epoch 1 | Step 385 | loss: 0.6749181993595968 | accuracy: 0.5723214285714284 \n",
      "Epoch 1 | Step 386 | loss: 0.6748682067493086 | accuracy: 0.5725388601036268 \n",
      "Epoch 1 | Step 387 | loss: 0.6747694554563027 | accuracy: 0.5727551679586561 \n",
      "Epoch 1 | Step 388 | loss: 0.6746809161508209 | accuracy: 0.5728898195876286 \n",
      "Epoch 1 | Step 389 | loss: 0.6746954285087197 | accuracy: 0.5729434447300769 \n",
      "Epoch 1 | Step 390 | loss: 0.6743560586220182 | accuracy: 0.5733974358974356 \n",
      "Epoch 1 | Step 391 | loss: 0.6743677371298263 | accuracy: 0.5735693734015342 \n",
      "Epoch 1 | Step 392 | loss: 0.6743124974321348 | accuracy: 0.5737802933673466 \n",
      "Epoch 1 | Step 393 | loss: 0.674082014245235 | accuracy: 0.5740298982188291 \n",
      "Epoch 1 | Step 394 | loss: 0.6740676995158803 | accuracy: 0.5741989213197966 \n",
      "Epoch 1 | Step 395 | loss: 0.6740164313135271 | accuracy: 0.5742484177215186 \n",
      "Epoch 1 | Step 396 | loss: 0.6737010980194268 | accuracy: 0.5747316919191915 \n",
      "Epoch 1 | Step 397 | loss: 0.6737551570539213 | accuracy: 0.574504093198992 \n",
      "Epoch 1 | Step 398 | loss: 0.6736738575463321 | accuracy: 0.5746702261306529 \n",
      "Epoch 1 | Step 399 | loss: 0.6734962635171745 | accuracy: 0.5749138471177941 \n",
      "Epoch 1 | Step 400 | loss: 0.6735469891130927 | accuracy: 0.5748828124999996 \n",
      "Epoch 1 | Step 401 | loss: 0.6735346186488053 | accuracy: 0.5749298628428924 \n",
      "Epoch 1 | Step 402 | loss: 0.673493700092705 | accuracy: 0.5750155472636812 \n",
      "Epoch 1 | Step 403 | loss: 0.6733896951225795 | accuracy: 0.5750433174019708 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6419690251350403 | accuracy: 0.59375 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6543331742286682 | accuracy: 0.5703125 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6557575066884359 | accuracy: 0.578125 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6626750975847244 | accuracy: 0.5703125 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6624691367149353 | accuracy: 0.575 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6606266697247823 | accuracy: 0.5833333333333334 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.661624380520412 | accuracy: 0.5848214285714286 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6618573144078255 | accuracy: 0.580078125 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6621063550313314 | accuracy: 0.5746527777777778 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.662358683347702 | accuracy: 0.575 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6592053608460859 | accuracy: 0.578125 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6541577478249868 | accuracy: 0.5846354166666666 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6545149729802058 | accuracy: 0.5853365384615384 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6486352384090424 | accuracy: 0.5970982142857143 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6447629531224569 | accuracy: 0.60625 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6436177119612694 | accuracy: 0.6083984375 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6446691576172324 | accuracy: 0.6075367647058824 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6422600646813711 | accuracy: 0.6128472222222222 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6440335574902987 | accuracy: 0.615953947368421 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6443527102470398 | accuracy: 0.615625 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6449671671504066 | accuracy: 0.6145833333333334 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6431191888722506 | accuracy: 0.6207386363636364 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.644065084664718 | accuracy: 0.6175271739130435 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6439073656996092 | accuracy: 0.6184895833333334 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6435802602767944 | accuracy: 0.619375 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6404417340572064 | accuracy: 0.6237980769230769 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6386672964802494 | accuracy: 0.625 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6384626775979996 | accuracy: 0.625 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6394834127919428 | accuracy: 0.6233836206896551 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6408910652001699 | accuracy: 0.6213541666666667 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6395869293520527 | accuracy: 0.6255040322580645 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6367516461759806 | accuracy: 0.62890625 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.634863990725893 | accuracy: 0.631155303030303 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.635276222930235 | accuracy: 0.6305147058823529 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6342985544885907 | accuracy: 0.6316964285714286 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6325217833121618 | accuracy: 0.6328125 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6327018737792969 | accuracy: 0.6338682432432432 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6328793873912409 | accuracy: 0.6332236842105263 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6324784205510066 | accuracy: 0.6322115384615384 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.632263246178627 | accuracy: 0.63359375 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6326500715278996 | accuracy: 0.6322408536585366 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6307729908398219 | accuracy: 0.6343005952380952 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6311772493428961 | accuracy: 0.6333575581395349 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.631277783350511 | accuracy: 0.6324573863636364 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.631047080622779 | accuracy: 0.6338617152637905 \n",
      "Epoch 2 | Step 404 | loss: 0.5867972373962402 | accuracy: 0.65625 \n",
      "Epoch 2 | Step 405 | loss: 0.6122640073299408 | accuracy: 0.6328125 \n",
      "Epoch 2 | Step 406 | loss: 0.5923295219739279 | accuracy: 0.671875 \n",
      "Epoch 2 | Step 407 | loss: 0.585214376449585 | accuracy: 0.68359375 \n",
      "Epoch 2 | Step 408 | loss: 0.5967813014984131 | accuracy: 0.671875 \n",
      "Epoch 2 | Step 409 | loss: 0.6045694649219513 | accuracy: 0.6614583333333334 \n",
      "Epoch 2 | Step 410 | loss: 0.6156373705182757 | accuracy: 0.6428571428571429 \n",
      "Epoch 2 | Step 411 | loss: 0.6248643025755882 | accuracy: 0.630859375 \n",
      "Epoch 2 | Step 412 | loss: 0.6232220464282565 | accuracy: 0.6267361111111112 \n",
      "Epoch 2 | Step 413 | loss: 0.6248550593852997 | accuracy: 0.625 \n",
      "Epoch 2 | Step 414 | loss: 0.6241967894814231 | accuracy: 0.6264204545454546 \n",
      "Epoch 2 | Step 415 | loss: 0.6295474270979563 | accuracy: 0.6171875 \n",
      "Epoch 2 | Step 416 | loss: 0.6279060198710515 | accuracy: 0.6237980769230769 \n",
      "Epoch 2 | Step 417 | loss: 0.6272931141512734 | accuracy: 0.6238839285714286 \n",
      "Epoch 2 | Step 418 | loss: 0.6243165810902913 | accuracy: 0.6291666666666667 \n",
      "Epoch 2 | Step 419 | loss: 0.6213228665292263 | accuracy: 0.634765625 \n",
      "Epoch 2 | Step 420 | loss: 0.6174566465265611 | accuracy: 0.6387867647058824 \n",
      "Epoch 2 | Step 421 | loss: 0.6194528738657633 | accuracy: 0.6414930555555556 \n",
      "Epoch 2 | Step 422 | loss: 0.6196673983021787 | accuracy: 0.6422697368421053 \n",
      "Epoch 2 | Step 423 | loss: 0.6196881711483002 | accuracy: 0.64453125 \n",
      "Epoch 2 | Step 424 | loss: 0.6202373703320821 | accuracy: 0.6443452380952381 \n",
      "Epoch 2 | Step 425 | loss: 0.6185860525478016 | accuracy: 0.6484375 \n",
      "Epoch 2 | Step 426 | loss: 0.6173578656238058 | accuracy: 0.6514945652173914 \n",
      "Epoch 2 | Step 427 | loss: 0.6171405836939811 | accuracy: 0.6536458333333334 \n",
      "Epoch 2 | Step 428 | loss: 0.615452525615692 | accuracy: 0.653125 \n",
      "Epoch 2 | Step 429 | loss: 0.6151906458231118 | accuracy: 0.6532451923076923 \n",
      "Epoch 2 | Step 430 | loss: 0.6135641800032721 | accuracy: 0.6556712962962963 \n",
      "Epoch 2 | Step 431 | loss: 0.6112162321805953 | accuracy: 0.6584821428571429 \n",
      "Epoch 2 | Step 432 | loss: 0.6095610199303462 | accuracy: 0.6594827586206896 \n",
      "Epoch 2 | Step 433 | loss: 0.610908790429433 | accuracy: 0.659375 \n",
      "Epoch 2 | Step 434 | loss: 0.6093552997035364 | accuracy: 0.6612903225806451 \n",
      "Epoch 2 | Step 435 | loss: 0.610887924209237 | accuracy: 0.65966796875 \n",
      "Epoch 2 | Step 436 | loss: 0.6112787145556825 | accuracy: 0.6605113636363636 \n",
      "Epoch 2 | Step 437 | loss: 0.6123961911481969 | accuracy: 0.6585477941176471 \n",
      "Epoch 2 | Step 438 | loss: 0.6127657430512563 | accuracy: 0.6584821428571429 \n",
      "Epoch 2 | Step 439 | loss: 0.6136729054980807 | accuracy: 0.6592881944444444 \n",
      "Epoch 2 | Step 440 | loss: 0.6135124676936382 | accuracy: 0.660472972972973 \n",
      "Epoch 2 | Step 441 | loss: 0.6128898074752407 | accuracy: 0.6624177631578948 \n",
      "Epoch 2 | Step 442 | loss: 0.6130179946239179 | accuracy: 0.6610576923076924 \n",
      "Epoch 2 | Step 443 | loss: 0.6138403177261353 | accuracy: 0.6597656250000001 \n",
      "Epoch 2 | Step 444 | loss: 0.6139915440140702 | accuracy: 0.6600609756097563 \n",
      "Epoch 2 | Step 445 | loss: 0.6107447338955744 | accuracy: 0.6636904761904764 \n",
      "Epoch 2 | Step 446 | loss: 0.6099043620187183 | accuracy: 0.6642441860465118 \n",
      "Epoch 2 | Step 447 | loss: 0.6078998629342427 | accuracy: 0.6672585227272729 \n",
      "Epoch 2 | Step 448 | loss: 0.6090145117706723 | accuracy: 0.665277777777778 \n",
      "Epoch 2 | Step 449 | loss: 0.6108504371798558 | accuracy: 0.6633831521739132 \n",
      "Epoch 2 | Step 450 | loss: 0.6100900534619677 | accuracy: 0.6638962765957448 \n",
      "Epoch 2 | Step 451 | loss: 0.610164505119125 | accuracy: 0.6650390625000001 \n",
      "Epoch 2 | Step 452 | loss: 0.60908670023996 | accuracy: 0.6658163265306124 \n",
      "Epoch 2 | Step 453 | loss: 0.6082271426916123 | accuracy: 0.6659375000000002 \n",
      "Epoch 2 | Step 454 | loss: 0.6093563957541597 | accuracy: 0.6654411764705884 \n",
      "Epoch 2 | Step 455 | loss: 0.6107705963345674 | accuracy: 0.6649639423076924 \n",
      "Epoch 2 | Step 456 | loss: 0.6113894272525355 | accuracy: 0.6642099056603775 \n",
      "Epoch 2 | Step 457 | loss: 0.6105536879212768 | accuracy: 0.6657986111111113 \n",
      "Epoch 2 | Step 458 | loss: 0.609065501798283 | accuracy: 0.6670454545454547 \n",
      "Epoch 2 | Step 459 | loss: 0.6094777844846249 | accuracy: 0.6671316964285715 \n",
      "Epoch 2 | Step 460 | loss: 0.6101084900529761 | accuracy: 0.6661184210526317 \n",
      "Epoch 2 | Step 461 | loss: 0.6113605833259123 | accuracy: 0.6643318965517243 \n",
      "Epoch 2 | Step 462 | loss: 0.6115673522827989 | accuracy: 0.6641949152542375 \n",
      "Epoch 2 | Step 463 | loss: 0.6109209850430488 | accuracy: 0.6643229166666668 \n",
      "Epoch 2 | Step 464 | loss: 0.6111835255974629 | accuracy: 0.6639344262295083 \n",
      "Epoch 2 | Step 465 | loss: 0.6111357601419571 | accuracy: 0.6635584677419356 \n",
      "Epoch 2 | Step 466 | loss: 0.6112480707584865 | accuracy: 0.6629464285714287 \n",
      "Epoch 2 | Step 467 | loss: 0.6100967251695693 | accuracy: 0.6635742187500001 \n",
      "Epoch 2 | Step 468 | loss: 0.6107917726039886 | accuracy: 0.6627403846153848 \n",
      "Epoch 2 | Step 469 | loss: 0.6102608780969273 | accuracy: 0.6635890151515152 \n",
      "Epoch 2 | Step 470 | loss: 0.6105712016127003 | accuracy: 0.6630130597014926 \n",
      "Epoch 2 | Step 471 | loss: 0.6099672155345187 | accuracy: 0.6642922794117648 \n",
      "Epoch 2 | Step 472 | loss: 0.6110953442428423 | accuracy: 0.6630434782608696 \n",
      "Epoch 2 | Step 473 | loss: 0.6126753802810396 | accuracy: 0.6602678571428573 \n",
      "Epoch 2 | Step 474 | loss: 0.6134741570748073 | accuracy: 0.6599911971830988 \n",
      "Epoch 2 | Step 475 | loss: 0.6127424302200476 | accuracy: 0.6614583333333336 \n",
      "Epoch 2 | Step 476 | loss: 0.6129149814991102 | accuracy: 0.661815068493151 \n",
      "Epoch 2 | Step 477 | loss: 0.6131674691631988 | accuracy: 0.6623733108108111 \n",
      "Epoch 2 | Step 478 | loss: 0.6134737535317739 | accuracy: 0.6627083333333336 \n",
      "Epoch 2 | Step 479 | loss: 0.6127529359961811 | accuracy: 0.6632401315789476 \n",
      "Epoch 2 | Step 480 | loss: 0.6123747496635883 | accuracy: 0.6631493506493509 \n",
      "Epoch 2 | Step 481 | loss: 0.6127316397734177 | accuracy: 0.6628605769230771 \n",
      "Epoch 2 | Step 482 | loss: 0.6124314405495608 | accuracy: 0.6631724683544306 \n",
      "Epoch 2 | Step 483 | loss: 0.6123090092092752 | accuracy: 0.6628906250000002 \n",
      "Epoch 2 | Step 484 | loss: 0.6130925170433374 | accuracy: 0.6618441358024693 \n",
      "Epoch 2 | Step 485 | loss: 0.613350873676742 | accuracy: 0.661204268292683 \n",
      "Epoch 2 | Step 486 | loss: 0.613296315253499 | accuracy: 0.6611445783132531 \n",
      "Epoch 2 | Step 487 | loss: 0.6134793329096976 | accuracy: 0.6610863095238096 \n",
      "Epoch 2 | Step 488 | loss: 0.6133499443531036 | accuracy: 0.6604779411764706 \n",
      "Epoch 2 | Step 489 | loss: 0.6124937711066978 | accuracy: 0.6615188953488372 \n",
      "Epoch 2 | Step 490 | loss: 0.612336216644309 | accuracy: 0.662176724137931 \n",
      "Epoch 2 | Step 491 | loss: 0.6129614612595602 | accuracy: 0.6612215909090909 \n",
      "Epoch 2 | Step 492 | loss: 0.6132921820945954 | accuracy: 0.660814606741573 \n",
      "Epoch 2 | Step 493 | loss: 0.6133207026455136 | accuracy: 0.6609375 \n",
      "Epoch 2 | Step 494 | loss: 0.6125880509287446 | accuracy: 0.6622596153846153 \n",
      "Epoch 2 | Step 495 | loss: 0.6121167284638984 | accuracy: 0.6630434782608695 \n",
      "Epoch 2 | Step 496 | loss: 0.6119793791283842 | accuracy: 0.6633064516129031 \n",
      "Epoch 2 | Step 497 | loss: 0.6116455676073722 | accuracy: 0.6640624999999999 \n",
      "Epoch 2 | Step 498 | loss: 0.6112387760689383 | accuracy: 0.6648026315789473 \n",
      "Epoch 2 | Step 499 | loss: 0.6106885637467104 | accuracy: 0.6658528645833331 \n",
      "Epoch 2 | Step 500 | loss: 0.6102763927474463 | accuracy: 0.6659149484536081 \n",
      "Epoch 2 | Step 501 | loss: 0.6106121488371672 | accuracy: 0.6661352040816325 \n",
      "Epoch 2 | Step 502 | loss: 0.6098016009788318 | accuracy: 0.6668244949494948 \n",
      "Epoch 2 | Step 503 | loss: 0.6099875518679617 | accuracy: 0.6667187499999998 \n",
      "Epoch 2 | Step 504 | loss: 0.6099734504034022 | accuracy: 0.6664603960396038 \n",
      "Epoch 2 | Step 505 | loss: 0.6098291602204826 | accuracy: 0.666360294117647 \n",
      "Epoch 2 | Step 506 | loss: 0.6102024371762876 | accuracy: 0.6652002427184465 \n",
      "Epoch 2 | Step 507 | loss: 0.6095270866957994 | accuracy: 0.6655649038461537 \n",
      "Epoch 2 | Step 508 | loss: 0.6092449713320958 | accuracy: 0.6654761904761903 \n",
      "Epoch 2 | Step 509 | loss: 0.6090981906877373 | accuracy: 0.6652417452830187 \n",
      "Epoch 2 | Step 510 | loss: 0.6087764604626413 | accuracy: 0.6651577102803737 \n",
      "Epoch 2 | Step 511 | loss: 0.6086193110655854 | accuracy: 0.6655092592592591 \n",
      "Epoch 2 | Step 512 | loss: 0.6076749144890985 | accuracy: 0.6662844036697246 \n",
      "Epoch 2 | Step 513 | loss: 0.6075927086851812 | accuracy: 0.6660511363636362 \n",
      "Epoch 2 | Step 514 | loss: 0.6086521033231201 | accuracy: 0.6653997747747746 \n",
      "Epoch 2 | Step 515 | loss: 0.6089239341339894 | accuracy: 0.6648995535714285 \n",
      "Epoch 2 | Step 516 | loss: 0.6082203332829264 | accuracy: 0.6656526548672566 \n",
      "Epoch 2 | Step 517 | loss: 0.6082254154117482 | accuracy: 0.6651589912280701 \n",
      "Epoch 2 | Step 518 | loss: 0.608945284978203 | accuracy: 0.6641304347826086 \n",
      "Epoch 2 | Step 519 | loss: 0.6092396052233103 | accuracy: 0.6640624999999999 \n",
      "Epoch 2 | Step 520 | loss: 0.608428713857618 | accuracy: 0.6647970085470084 \n",
      "Epoch 2 | Step 521 | loss: 0.608772142206208 | accuracy: 0.6644597457627117 \n",
      "Epoch 2 | Step 522 | loss: 0.608741428421325 | accuracy: 0.6641281512605041 \n",
      "Epoch 2 | Step 523 | loss: 0.6084359290699163 | accuracy: 0.6645833333333332 \n",
      "Epoch 2 | Step 524 | loss: 0.6078303379953399 | accuracy: 0.665160123966942 \n",
      "Epoch 2 | Step 525 | loss: 0.6079225308093867 | accuracy: 0.6645747950819672 \n",
      "Epoch 2 | Step 526 | loss: 0.6082099838470054 | accuracy: 0.6643800813008129 \n",
      "Epoch 2 | Step 527 | loss: 0.6079652826151539 | accuracy: 0.6643145161290321 \n",
      "Epoch 2 | Step 528 | loss: 0.6080225279331206 | accuracy: 0.6641249999999999 \n",
      "Epoch 2 | Step 529 | loss: 0.6081948907129348 | accuracy: 0.663690476190476 \n",
      "Epoch 2 | Step 530 | loss: 0.6076093989563738 | accuracy: 0.6643700787401574 \n",
      "Epoch 2 | Step 531 | loss: 0.6073554989416151 | accuracy: 0.6646728515624999 \n",
      "Epoch 2 | Step 532 | loss: 0.6080739209356233 | accuracy: 0.664486434108527 \n",
      "Epoch 2 | Step 533 | loss: 0.6076660011823359 | accuracy: 0.665264423076923 \n",
      "Epoch 2 | Step 534 | loss: 0.6077105678219831 | accuracy: 0.6653148854961831 \n",
      "Epoch 2 | Step 535 | loss: 0.6087247695435176 | accuracy: 0.6644176136363635 \n",
      "Epoch 2 | Step 536 | loss: 0.6081067119774064 | accuracy: 0.6648261278195488 \n",
      "Epoch 2 | Step 537 | loss: 0.6076624640333118 | accuracy: 0.6651119402985074 \n",
      "Epoch 2 | Step 538 | loss: 0.6074528475602466 | accuracy: 0.6653935185185185 \n",
      "Epoch 2 | Step 539 | loss: 0.6068433770800337 | accuracy: 0.6656709558823529 \n",
      "Epoch 2 | Step 540 | loss: 0.6068476571218809 | accuracy: 0.6656021897810219 \n",
      "Epoch 2 | Step 541 | loss: 0.6066257981718449 | accuracy: 0.6653079710144928 \n",
      "Epoch 2 | Step 542 | loss: 0.6065645756052551 | accuracy: 0.6656924460431655 \n",
      "Epoch 2 | Step 543 | loss: 0.6064813577703067 | accuracy: 0.6659598214285715 \n",
      "Epoch 2 | Step 544 | loss: 0.6060663282025789 | accuracy: 0.6662234042553191 \n",
      "Epoch 2 | Step 545 | loss: 0.6056577229583765 | accuracy: 0.6663732394366197 \n",
      "Epoch 2 | Step 546 | loss: 0.6053339574303659 | accuracy: 0.6665209790209791 \n",
      "Epoch 2 | Step 547 | loss: 0.6050910368147823 | accuracy: 0.6663411458333334 \n",
      "Epoch 2 | Step 548 | loss: 0.6048636446739064 | accuracy: 0.6665948275862069 \n",
      "Epoch 2 | Step 549 | loss: 0.6054956200596403 | accuracy: 0.6659888698630136 \n",
      "Epoch 2 | Step 550 | loss: 0.6057407067341057 | accuracy: 0.665922619047619 \n",
      "Epoch 2 | Step 551 | loss: 0.6052708478795514 | accuracy: 0.6665962837837837 \n",
      "Epoch 2 | Step 552 | loss: 0.6049413743035105 | accuracy: 0.6668414429530201 \n",
      "Epoch 2 | Step 553 | loss: 0.604537320335706 | accuracy: 0.6671874999999999 \n",
      "Epoch 2 | Step 554 | loss: 0.6044860748660484 | accuracy: 0.6667011589403973 \n",
      "Epoch 2 | Step 555 | loss: 0.6047186320157426 | accuracy: 0.6667351973684209 \n",
      "Epoch 2 | Step 556 | loss: 0.6050828642704906 | accuracy: 0.6664624183006534 \n",
      "Epoch 2 | Step 557 | loss: 0.6052749863305649 | accuracy: 0.6660917207792206 \n",
      "Epoch 2 | Step 558 | loss: 0.6047463080575388 | accuracy: 0.6664314516129031 \n",
      "Epoch 2 | Step 559 | loss: 0.6043922402537785 | accuracy: 0.6663661858974357 \n",
      "Epoch 2 | Step 560 | loss: 0.6042375695553553 | accuracy: 0.6666003184713374 \n",
      "Epoch 2 | Step 561 | loss: 0.6041297503287277 | accuracy: 0.6670292721518986 \n",
      "Epoch 2 | Step 562 | loss: 0.6039510558611191 | accuracy: 0.6666666666666665 \n",
      "Epoch 2 | Step 563 | loss: 0.6041014099493622 | accuracy: 0.6666992187499998 \n",
      "Epoch 2 | Step 564 | loss: 0.6041225030185273 | accuracy: 0.6672166149068322 \n",
      "Epoch 2 | Step 565 | loss: 0.6040026716612004 | accuracy: 0.6671489197530862 \n",
      "Epoch 2 | Step 566 | loss: 0.6040108911464551 | accuracy: 0.6673696319018403 \n",
      "Epoch 2 | Step 567 | loss: 0.6040191848467037 | accuracy: 0.6671112804878047 \n",
      "Epoch 2 | Step 568 | loss: 0.6040234199075989 | accuracy: 0.6668560606060604 \n",
      "Epoch 2 | Step 569 | loss: 0.6042380920016622 | accuracy: 0.6668862951807227 \n",
      "Epoch 2 | Step 570 | loss: 0.6041460388791775 | accuracy: 0.667196856287425 \n",
      "Epoch 2 | Step 571 | loss: 0.6045209586265541 | accuracy: 0.6672247023809522 \n",
      "Epoch 2 | Step 572 | loss: 0.6047761025866107 | accuracy: 0.6668823964497039 \n",
      "Epoch 2 | Step 573 | loss: 0.6046774375088074 | accuracy: 0.6672794117647056 \n",
      "Epoch 2 | Step 574 | loss: 0.6048077928741076 | accuracy: 0.6672149122807015 \n",
      "Epoch 2 | Step 575 | loss: 0.604937948633072 | accuracy: 0.66687863372093 \n",
      "Epoch 2 | Step 576 | loss: 0.6045025392419342 | accuracy: 0.6671784682080923 \n",
      "Epoch 2 | Step 577 | loss: 0.6048136666930956 | accuracy: 0.6670258620689653 \n",
      "Epoch 2 | Step 578 | loss: 0.6045756423473359 | accuracy: 0.6673214285714283 \n",
      "Epoch 2 | Step 579 | loss: 0.6047006786208261 | accuracy: 0.6670809659090907 \n",
      "Epoch 2 | Step 580 | loss: 0.6050838004734557 | accuracy: 0.6665783898305083 \n",
      "Epoch 2 | Step 581 | loss: 0.6053681268116061 | accuracy: 0.6659058988764044 \n",
      "Epoch 2 | Step 582 | loss: 0.6053313225008256 | accuracy: 0.6663756983240222 \n",
      "Epoch 2 | Step 583 | loss: 0.6051275258262951 | accuracy: 0.666753472222222 \n",
      "Epoch 2 | Step 584 | loss: 0.604699398766565 | accuracy: 0.6670407458563534 \n",
      "Epoch 2 | Step 585 | loss: 0.6042292814005862 | accuracy: 0.6674965659340658 \n",
      "Epoch 2 | Step 586 | loss: 0.6042481431218444 | accuracy: 0.6674351092896174 \n",
      "Epoch 2 | Step 587 | loss: 0.604709456310324 | accuracy: 0.6667798913043477 \n",
      "Epoch 2 | Step 588 | loss: 0.6045012089046272 | accuracy: 0.6670608108108107 \n",
      "Epoch 2 | Step 589 | loss: 0.6042820364236832 | accuracy: 0.6670026881720429 \n",
      "Epoch 2 | Step 590 | loss: 0.6043651641052674 | accuracy: 0.6671122994652405 \n",
      "Epoch 2 | Step 591 | loss: 0.6041242228226459 | accuracy: 0.6671376329787233 \n",
      "Epoch 2 | Step 592 | loss: 0.6039072611029186 | accuracy: 0.6675760582010581 \n",
      "Epoch 2 | Step 593 | loss: 0.6034689484458221 | accuracy: 0.6680098684210526 \n",
      "Epoch 2 | Step 594 | loss: 0.6032630799640536 | accuracy: 0.6681119109947643 \n",
      "Epoch 2 | Step 595 | loss: 0.6034820028580725 | accuracy: 0.6675618489583334 \n",
      "Epoch 2 | Step 596 | loss: 0.603926466073397 | accuracy: 0.6671794041450777 \n",
      "Epoch 2 | Step 597 | loss: 0.6038407850818537 | accuracy: 0.6673646907216495 \n",
      "Epoch 2 | Step 598 | loss: 0.6041512710925862 | accuracy: 0.6670673076923077 \n",
      "Epoch 2 | Step 599 | loss: 0.6037275108451747 | accuracy: 0.6676498724489796 \n",
      "Epoch 2 | Step 600 | loss: 0.6031057568370994 | accuracy: 0.6680678934010152 \n",
      "Epoch 2 | Step 601 | loss: 0.6032762861613072 | accuracy: 0.6680082070707071 \n",
      "Epoch 2 | Step 602 | loss: 0.6036866642721935 | accuracy: 0.6677920854271356 \n",
      "Epoch 2 | Step 603 | loss: 0.6034332990646365 | accuracy: 0.6678125 \n",
      "Epoch 2 | Step 604 | loss: 0.6029858061330238 | accuracy: 0.668143656716418 \n",
      "Epoch 2 | Step 605 | loss: 0.6029547290636763 | accuracy: 0.6683941831683168 \n",
      "Epoch 2 | Step 606 | loss: 0.6026016840793817 | accuracy: 0.6690270935960592 \n",
      "Epoch 2 | Step 607 | loss: 0.6024213684540171 | accuracy: 0.6690410539215687 \n",
      "Epoch 2 | Step 608 | loss: 0.602464597399642 | accuracy: 0.6689024390243903 \n",
      "Epoch 2 | Step 609 | loss: 0.6021382039033095 | accuracy: 0.6691444174757282 \n",
      "Epoch 2 | Step 610 | loss: 0.6020831290074594 | accuracy: 0.668780193236715 \n",
      "Epoch 2 | Step 611 | loss: 0.601727847583019 | accuracy: 0.6688701923076923 \n",
      "Epoch 2 | Step 612 | loss: 0.601995436768783 | accuracy: 0.6688098086124402 \n",
      "Epoch 2 | Step 613 | loss: 0.6018911713645574 | accuracy: 0.669047619047619 \n",
      "Epoch 2 | Step 614 | loss: 0.6019531070338608 | accuracy: 0.6691350710900474 \n",
      "Epoch 2 | Step 615 | loss: 0.6019815549535573 | accuracy: 0.6692216981132075 \n",
      "Epoch 2 | Step 616 | loss: 0.6020591096698961 | accuracy: 0.669380868544601 \n",
      "Epoch 2 | Step 617 | loss: 0.6019618182538828 | accuracy: 0.6696845794392523 \n",
      "Epoch 2 | Step 618 | loss: 0.6016963362693789 | accuracy: 0.6697674418604651 \n",
      "Epoch 2 | Step 619 | loss: 0.6015561280979053 | accuracy: 0.6700665509259259 \n",
      "Epoch 2 | Step 620 | loss: 0.6022757736768594 | accuracy: 0.6693548387096774 \n",
      "Epoch 2 | Step 621 | loss: 0.6021880857441406 | accuracy: 0.6693663990825688 \n",
      "Epoch 2 | Step 622 | loss: 0.6020751679869005 | accuracy: 0.6693778538812786 \n",
      "Epoch 2 | Step 623 | loss: 0.6018854916095736 | accuracy: 0.6693892045454546 \n",
      "Epoch 2 | Step 624 | loss: 0.6015818369874051 | accuracy: 0.6697539592760181 \n",
      "Epoch 2 | Step 625 | loss: 0.6013560469623087 | accuracy: 0.6699746621621622 \n",
      "Epoch 2 | Step 626 | loss: 0.6011624127760065 | accuracy: 0.6703335201793722 \n",
      "Epoch 2 | Step 627 | loss: 0.6011916548013689 | accuracy: 0.6706194196428571 \n",
      "Epoch 2 | Step 628 | loss: 0.6015683613883127 | accuracy: 0.6701388888888888 \n",
      "Epoch 2 | Step 629 | loss: 0.6016189856866823 | accuracy: 0.6702157079646017 \n",
      "Epoch 2 | Step 630 | loss: 0.6017205415843344 | accuracy: 0.6700853524229075 \n",
      "Epoch 2 | Step 631 | loss: 0.601523409548559 | accuracy: 0.6705043859649122 \n",
      "Epoch 2 | Step 632 | loss: 0.6011997440496389 | accuracy: 0.6710562227074236 \n",
      "Epoch 2 | Step 633 | loss: 0.6007050847229752 | accuracy: 0.6716032608695652 \n",
      "Epoch 2 | Step 634 | loss: 0.6011927725174728 | accuracy: 0.6711985930735931 \n",
      "Epoch 2 | Step 635 | loss: 0.6008906126793091 | accuracy: 0.6714709051724138 \n",
      "Epoch 2 | Step 636 | loss: 0.6012116372585299 | accuracy: 0.6712714592274678 \n",
      "Epoch 2 | Step 637 | loss: 0.601365535050376 | accuracy: 0.6711404914529915 \n",
      "Epoch 2 | Step 638 | loss: 0.6012562053000676 | accuracy: 0.6710771276595745 \n",
      "Epoch 2 | Step 639 | loss: 0.600903014131522 | accuracy: 0.6714777542372882 \n",
      "Epoch 2 | Step 640 | loss: 0.6010921981012773 | accuracy: 0.6714794303797469 \n",
      "Epoch 2 | Step 641 | loss: 0.6016252881088179 | accuracy: 0.6712184873949579 \n",
      "Epoch 2 | Step 642 | loss: 0.6015848012399476 | accuracy: 0.6713519874476988 \n",
      "Epoch 2 | Step 643 | loss: 0.6015174529204769 | accuracy: 0.6715494791666666 \n",
      "Epoch 2 | Step 644 | loss: 0.601545473228352 | accuracy: 0.6712914937759336 \n",
      "Epoch 2 | Step 645 | loss: 0.6018389600121288 | accuracy: 0.6708419421487604 \n",
      "Epoch 2 | Step 646 | loss: 0.601630028505875 | accuracy: 0.6712962962962963 \n",
      "Epoch 2 | Step 647 | loss: 0.6013583410225933 | accuracy: 0.6718109631147541 \n",
      "Epoch 2 | Step 648 | loss: 0.6013928424338908 | accuracy: 0.6716836734693877 \n",
      "Epoch 2 | Step 649 | loss: 0.6013174159982343 | accuracy: 0.6717479674796748 \n",
      "Epoch 2 | Step 650 | loss: 0.6010634528721878 | accuracy: 0.6719382591093117 \n",
      "Epoch 2 | Step 651 | loss: 0.6011842608211504 | accuracy: 0.6716859879032258 \n",
      "Epoch 2 | Step 652 | loss: 0.6015611153290455 | accuracy: 0.6713102409638554 \n",
      "Epoch 2 | Step 653 | loss: 0.6013168669939043 | accuracy: 0.671375 \n",
      "Epoch 2 | Step 654 | loss: 0.6015378691523201 | accuracy: 0.6711902390438247 \n",
      "Epoch 2 | Step 655 | loss: 0.6015454470401721 | accuracy: 0.6710069444444444 \n",
      "Epoch 2 | Step 656 | loss: 0.601434147051672 | accuracy: 0.6711338932806324 \n",
      "Epoch 2 | Step 657 | loss: 0.6013165666597098 | accuracy: 0.6710752952755905 \n",
      "Epoch 2 | Step 658 | loss: 0.6012622523541546 | accuracy: 0.6709558823529411 \n",
      "Epoch 2 | Step 659 | loss: 0.6010717720491814 | accuracy: 0.67132568359375 \n",
      "Epoch 2 | Step 660 | loss: 0.601066065089712 | accuracy: 0.6714494163424124 \n",
      "Epoch 2 | Step 661 | loss: 0.6010222110406375 | accuracy: 0.6714510658914729 \n",
      "Epoch 2 | Step 662 | loss: 0.6010970729888638 | accuracy: 0.671573359073359 \n",
      "Epoch 2 | Step 663 | loss: 0.601072845894557 | accuracy: 0.6713942307692308 \n",
      "Epoch 2 | Step 664 | loss: 0.6008559845644854 | accuracy: 0.6716355363984674 \n",
      "Epoch 2 | Step 665 | loss: 0.6010988339895512 | accuracy: 0.671457538167939 \n",
      "Epoch 2 | Step 666 | loss: 0.6007927444271264 | accuracy: 0.6718155893536122 \n",
      "Epoch 2 | Step 667 | loss: 0.6004248312251137 | accuracy: 0.672170928030303 \n",
      "Epoch 2 | Step 668 | loss: 0.6002537127935663 | accuracy: 0.6722877358490567 \n",
      "Epoch 2 | Step 669 | loss: 0.6002680588709682 | accuracy: 0.6723449248120301 \n",
      "Epoch 2 | Step 670 | loss: 0.6001430409454677 | accuracy: 0.6724016853932584 \n",
      "Epoch 2 | Step 671 | loss: 0.6000747125762614 | accuracy: 0.6724580223880597 \n",
      "Epoch 2 | Step 672 | loss: 0.5998557414928779 | accuracy: 0.6726881970260223 \n",
      "Epoch 2 | Step 673 | loss: 0.5996040700762363 | accuracy: 0.6728587962962963 \n",
      "Epoch 2 | Step 674 | loss: 0.5993652195288249 | accuracy: 0.6729128228782287 \n",
      "Epoch 2 | Step 675 | loss: 0.5992348328890172 | accuracy: 0.6731962316176471 \n",
      "Epoch 2 | Step 676 | loss: 0.5992095281571262 | accuracy: 0.6734775641025641 \n",
      "Epoch 2 | Step 677 | loss: 0.5991737985045373 | accuracy: 0.6734146897810219 \n",
      "Epoch 2 | Step 678 | loss: 0.5991959048401229 | accuracy: 0.6734659090909091 \n",
      "Epoch 2 | Step 679 | loss: 0.5995373415990155 | accuracy: 0.6731770833333334 \n",
      "Epoch 2 | Step 680 | loss: 0.5996072644145913 | accuracy: 0.6735108303249098 \n",
      "Epoch 2 | Step 681 | loss: 0.5996762247179913 | accuracy: 0.6733925359712231 \n",
      "Epoch 2 | Step 682 | loss: 0.5994434782894712 | accuracy: 0.6735551075268817 \n",
      "Epoch 2 | Step 683 | loss: 0.5994438423642093 | accuracy: 0.6734933035714286 \n",
      "Epoch 2 | Step 684 | loss: 0.5993190703655056 | accuracy: 0.673654359430605 \n",
      "Epoch 2 | Step 685 | loss: 0.5990037665510857 | accuracy: 0.6738696808510638 \n",
      "Epoch 2 | Step 686 | loss: 0.5991721381778855 | accuracy: 0.6738074204946997 \n",
      "Epoch 2 | Step 687 | loss: 0.598978866468853 | accuracy: 0.6739656690140845 \n",
      "Epoch 2 | Step 688 | loss: 0.5987744428609549 | accuracy: 0.6742324561403509 \n",
      "Epoch 2 | Step 689 | loss: 0.5982188395895327 | accuracy: 0.6748251748251748 \n",
      "Epoch 2 | Step 690 | loss: 0.5982767213720065 | accuracy: 0.6747060104529616 \n",
      "Epoch 2 | Step 691 | loss: 0.598067290770511 | accuracy: 0.6748046875 \n",
      "Epoch 2 | Step 692 | loss: 0.5983986311099111 | accuracy: 0.674848615916955 \n",
      "Epoch 2 | Step 693 | loss: 0.5982995371366371 | accuracy: 0.675 \n",
      "Epoch 2 | Step 694 | loss: 0.5984892459054995 | accuracy: 0.6747207903780069 \n",
      "Epoch 2 | Step 695 | loss: 0.5982952482283934 | accuracy: 0.674978595890411 \n",
      "Epoch 2 | Step 696 | loss: 0.5982509236083504 | accuracy: 0.6750746587030717 \n",
      "Epoch 2 | Step 697 | loss: 0.5983451589637875 | accuracy: 0.6750637755102041 \n",
      "Epoch 2 | Step 698 | loss: 0.5983380549034831 | accuracy: 0.6752648305084746 \n",
      "Epoch 2 | Step 699 | loss: 0.5981321094205252 | accuracy: 0.6753061655405407 \n",
      "Epoch 2 | Step 700 | loss: 0.5981183430361829 | accuracy: 0.6753998316498318 \n",
      "Epoch 2 | Step 701 | loss: 0.597915516703721 | accuracy: 0.675650167785235 \n",
      "Epoch 2 | Step 702 | loss: 0.5979231724571625 | accuracy: 0.6755330267558529 \n",
      "Epoch 2 | Step 703 | loss: 0.5979306373000147 | accuracy: 0.6754166666666668 \n",
      "Epoch 2 | Step 704 | loss: 0.597803435551368 | accuracy: 0.675404900332226 \n",
      "Epoch 2 | Step 705 | loss: 0.5976988441304657 | accuracy: 0.6757036423841061 \n",
      "Epoch 2 | Step 706 | loss: 0.5975451291394315 | accuracy: 0.6757941419141915 \n",
      "Epoch 2 | Step 707 | loss: 0.5977103134715246 | accuracy: 0.6756784539473685 \n",
      "Epoch 2 | Step 708 | loss: 0.5975633758990494 | accuracy: 0.6757172131147542 \n",
      "Epoch 2 | Step 709 | loss: 0.597346494108244 | accuracy: 0.6758578431372549 \n",
      "Epoch 2 | Step 710 | loss: 0.5974149161324831 | accuracy: 0.6757430781758957 \n",
      "Epoch 2 | Step 711 | loss: 0.5972700371564212 | accuracy: 0.6759334415584416 \n",
      "Epoch 2 | Step 712 | loss: 0.5971163477519573 | accuracy: 0.6762742718446602 \n",
      "Epoch 2 | Step 713 | loss: 0.5968751068076783 | accuracy: 0.6765120967741935 \n",
      "Epoch 2 | Step 714 | loss: 0.5965909376213409 | accuracy: 0.6767483922829582 \n",
      "Epoch 2 | Step 715 | loss: 0.5964619669203578 | accuracy: 0.6766826923076923 \n",
      "Epoch 2 | Step 716 | loss: 0.5961029193462277 | accuracy: 0.6770167731629393 \n",
      "Epoch 2 | Step 717 | loss: 0.5961926253927744 | accuracy: 0.677000398089172 \n",
      "Epoch 2 | Step 718 | loss: 0.5961466947245222 | accuracy: 0.6770337301587301 \n",
      "Epoch 2 | Step 719 | loss: 0.5961964653828479 | accuracy: 0.6770174050632911 \n",
      "Epoch 2 | Step 720 | loss: 0.5958772893959794 | accuracy: 0.677592665615142 \n",
      "Epoch 2 | Step 721 | loss: 0.5958867421690026 | accuracy: 0.6774764150943396 \n",
      "Epoch 2 | Step 722 | loss: 0.595723084895215 | accuracy: 0.6777037617554859 \n",
      "Epoch 2 | Step 723 | loss: 0.5957022389397028 | accuracy: 0.677783203125 \n",
      "Epoch 2 | Step 724 | loss: 0.5955778124547825 | accuracy: 0.6779108255451713 \n",
      "Epoch 2 | Step 725 | loss: 0.5957015519556794 | accuracy: 0.6777950310559007 \n",
      "Epoch 2 | Step 726 | loss: 0.5955245269710437 | accuracy: 0.677921826625387 \n",
      "Epoch 2 | Step 727 | loss: 0.5953790160976813 | accuracy: 0.6778549382716049 \n",
      "Epoch 2 | Step 728 | loss: 0.5953476388637838 | accuracy: 0.6777884615384615 \n",
      "Epoch 2 | Step 729 | loss: 0.5951305452299998 | accuracy: 0.6780099693251533 \n",
      "Epoch 2 | Step 730 | loss: 0.5951055665628627 | accuracy: 0.6778478593272171 \n",
      "Epoch 2 | Step 731 | loss: 0.5950871896816464 | accuracy: 0.6781154725609756 \n",
      "Epoch 2 | Step 732 | loss: 0.5953098428647932 | accuracy: 0.6779065349544073 \n",
      "Epoch 2 | Step 733 | loss: 0.5953155645818421 | accuracy: 0.678125 \n",
      "Epoch 2 | Step 734 | loss: 0.5951939641168831 | accuracy: 0.6783421450151057 \n",
      "Epoch 2 | Step 735 | loss: 0.5950416139809482 | accuracy: 0.6785109186746988 \n",
      "Epoch 2 | Step 736 | loss: 0.5949364046792727 | accuracy: 0.678490990990991 \n",
      "Epoch 2 | Step 737 | loss: 0.5948466804926981 | accuracy: 0.6786583083832335 \n",
      "Epoch 2 | Step 738 | loss: 0.5945674510144475 | accuracy: 0.6791044776119403 \n",
      "Epoch 2 | Step 739 | loss: 0.5943196823909168 | accuracy: 0.6792689732142857 \n",
      "Epoch 2 | Step 740 | loss: 0.5943979546648811 | accuracy: 0.6790615727002968 \n",
      "Epoch 2 | Step 741 | loss: 0.5944269354174122 | accuracy: 0.6789478550295858 \n",
      "Epoch 2 | Step 742 | loss: 0.5943465895709034 | accuracy: 0.6791574483775811 \n",
      "Epoch 2 | Step 743 | loss: 0.5941325671532574 | accuracy: 0.6794577205882352 \n",
      "Epoch 2 | Step 744 | loss: 0.5937806685998641 | accuracy: 0.6797104105571846 \n",
      "Epoch 2 | Step 745 | loss: 0.5936332456549704 | accuracy: 0.6798702485380115 \n",
      "Epoch 2 | Step 746 | loss: 0.5936153600584312 | accuracy: 0.6799836005830902 \n",
      "Epoch 2 | Step 747 | loss: 0.5932204375086827 | accuracy: 0.6802325581395346 \n",
      "Epoch 2 | Step 748 | loss: 0.5934490877649057 | accuracy: 0.6801630434782606 \n",
      "Epoch 2 | Step 749 | loss: 0.5933961527195968 | accuracy: 0.6802745664739882 \n",
      "Epoch 2 | Step 750 | loss: 0.5930621968394396 | accuracy: 0.6805655619596539 \n",
      "Epoch 2 | Step 751 | loss: 0.5932418223598906 | accuracy: 0.6806303879310343 \n",
      "Epoch 2 | Step 752 | loss: 0.5931969950226451 | accuracy: 0.6807843839541545 \n",
      "Epoch 2 | Step 753 | loss: 0.5929396919693264 | accuracy: 0.6810714285714284 \n",
      "Epoch 2 | Step 754 | loss: 0.5927054370060943 | accuracy: 0.6811342592592591 \n",
      "Epoch 2 | Step 755 | loss: 0.5926250865344295 | accuracy: 0.6812855113636362 \n",
      "Epoch 2 | Step 756 | loss: 0.5926001266953626 | accuracy: 0.681258852691218 \n",
      "Epoch 2 | Step 757 | loss: 0.5926354737099953 | accuracy: 0.6812764830508473 \n",
      "Epoch 2 | Step 758 | loss: 0.5923930592100383 | accuracy: 0.6815580985915491 \n",
      "Epoch 2 | Step 759 | loss: 0.5923847314179611 | accuracy: 0.6814431179775279 \n",
      "Epoch 2 | Step 760 | loss: 0.5923122298650713 | accuracy: 0.6815476190476188 \n",
      "Epoch 2 | Step 761 | loss: 0.5925111911316822 | accuracy: 0.6814333100558657 \n",
      "Epoch 2 | Step 762 | loss: 0.5924385426602321 | accuracy: 0.6814502089136488 \n",
      "Epoch 2 | Step 763 | loss: 0.5922360856499934 | accuracy: 0.6815104166666665 \n",
      "Epoch 2 | Step 764 | loss: 0.5923127504762188 | accuracy: 0.6814404432132961 \n",
      "Epoch 2 | Step 765 | loss: 0.5921311571947117 | accuracy: 0.6815866712707179 \n",
      "Epoch 2 | Step 766 | loss: 0.5922143309076953 | accuracy: 0.6813877410468316 \n",
      "Epoch 2 | Step 767 | loss: 0.5920742526650425 | accuracy: 0.6814903846153842 \n",
      "Epoch 2 | Step 768 | loss: 0.5920575212942407 | accuracy: 0.6815068493150681 \n",
      "Epoch 2 | Step 769 | loss: 0.5918800781170523 | accuracy: 0.6815659153005461 \n",
      "Epoch 2 | Step 770 | loss: 0.5919628491681015 | accuracy: 0.6816246594005446 \n",
      "Epoch 2 | Step 771 | loss: 0.5919187821285877 | accuracy: 0.6815981657608693 \n",
      "Epoch 2 | Step 772 | loss: 0.5919831746477419 | accuracy: 0.6815294715447151 \n",
      "Epoch 2 | Step 773 | loss: 0.5920681652990545 | accuracy: 0.681503378378378 \n",
      "Epoch 2 | Step 774 | loss: 0.59200253729229 | accuracy: 0.6816880053908353 \n",
      "Epoch 2 | Step 775 | loss: 0.5921347186930715 | accuracy: 0.6816196236559137 \n",
      "Epoch 2 | Step 776 | loss: 0.5920839994426704 | accuracy: 0.681761058981233 \n",
      "Epoch 2 | Step 777 | loss: 0.5919707558531172 | accuracy: 0.6819017379679141 \n",
      "Epoch 2 | Step 778 | loss: 0.5918961342970528 | accuracy: 0.681958333333333 \n",
      "Epoch 2 | Step 779 | loss: 0.5918228726913318 | accuracy: 0.6820146276595742 \n",
      "Epoch 2 | Step 780 | loss: 0.5918725702901732 | accuracy: 0.6819877320954905 \n",
      "Epoch 2 | Step 781 | loss: 0.5919717902701996 | accuracy: 0.6818369708994706 \n",
      "Epoch 2 | Step 782 | loss: 0.591647714848254 | accuracy: 0.6820580474934034 \n",
      "Epoch 2 | Step 783 | loss: 0.591621518370352 | accuracy: 0.6819490131578945 \n",
      "Epoch 2 | Step 784 | loss: 0.5915691166568614 | accuracy: 0.6821686351706033 \n",
      "Epoch 2 | Step 785 | loss: 0.5913922244497617 | accuracy: 0.6822643979057589 \n",
      "Epoch 2 | Step 786 | loss: 0.591340127797413 | accuracy: 0.6823188642297647 \n",
      "Epoch 2 | Step 787 | loss: 0.5914653743772456 | accuracy: 0.6821695963541664 \n",
      "Epoch 2 | Step 788 | loss: 0.5915149985195753 | accuracy: 0.6823051948051945 \n",
      "Epoch 2 | Step 789 | loss: 0.5915652594572521 | accuracy: 0.6821972150259065 \n",
      "Epoch 2 | Step 790 | loss: 0.5914512423735871 | accuracy: 0.682332041343669 \n",
      "Epoch 2 | Step 791 | loss: 0.5913778511980144 | accuracy: 0.6824259020618554 \n",
      "Epoch 2 | Step 792 | loss: 0.5915526941533567 | accuracy: 0.6823184447300769 \n",
      "Epoch 2 | Step 793 | loss: 0.5913417366070625 | accuracy: 0.6826121794871792 \n",
      "Epoch 2 | Step 794 | loss: 0.5915299593792547 | accuracy: 0.6825047953964192 \n",
      "Epoch 2 | Step 795 | loss: 0.5915000694898926 | accuracy: 0.6825573979591834 \n",
      "Epoch 2 | Step 796 | loss: 0.591248498466482 | accuracy: 0.6828482824427478 \n",
      "Epoch 2 | Step 797 | loss: 0.5912671609578399 | accuracy: 0.6827807741116748 \n",
      "Epoch 2 | Step 798 | loss: 0.5913571911522105 | accuracy: 0.6827531645569618 \n",
      "Epoch 2 | Step 799 | loss: 0.5910882538918294 | accuracy: 0.6829229797979796 \n",
      "Epoch 2 | Step 800 | loss: 0.5911620843320411 | accuracy: 0.6828164357682617 \n",
      "Epoch 2 | Step 801 | loss: 0.5910909906703624 | accuracy: 0.6829067211055273 \n",
      "Epoch 2 | Step 802 | loss: 0.5908920146468888 | accuracy: 0.6830748746867165 \n",
      "Epoch 2 | Step 803 | loss: 0.5909981261193754 | accuracy: 0.6830078124999998 \n",
      "Epoch 2 | Step 804 | loss: 0.5911382518504328 | accuracy: 0.6827852244389024 \n",
      "Epoch 2 | Step 805 | loss: 0.5912921904627959 | accuracy: 0.6826026119402983 \n",
      "Epoch 2 | Step 806 | loss: 0.5912125783581891 | accuracy: 0.6827056771768231 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6123537421226501 | accuracy: 0.625 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6211115717887878 | accuracy: 0.6328125 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6105220119158427 | accuracy: 0.65625 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6201430857181549 | accuracy: 0.64453125 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6161007881164551 | accuracy: 0.6625 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6156788965066274 | accuracy: 0.6588541666666666 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6155808397701809 | accuracy: 0.6607142857142857 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6144749373197556 | accuracy: 0.662109375 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6126706401507059 | accuracy: 0.6597222222222222 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6106418192386627 | accuracy: 0.6609375 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6089418584650214 | accuracy: 0.6619318181818182 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6025206198294958 | accuracy: 0.66796875 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6032989529462961 | accuracy: 0.6670673076923077 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5982430747577122 | accuracy: 0.6752232142857143 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5930870453516642 | accuracy: 0.6802083333333333 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5912297815084457 | accuracy: 0.6845703125 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5942868520231808 | accuracy: 0.6829044117647058 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5904760228263007 | accuracy: 0.6857638888888888 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.593452092848326 | accuracy: 0.6866776315789473 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5932667762041092 | accuracy: 0.684375 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5935449344771249 | accuracy: 0.6845238095238095 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5894896225495772 | accuracy: 0.6896306818181818 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5917843632076097 | accuracy: 0.685461956521739 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5929817607005438 | accuracy: 0.6848958333333334 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5927727150917054 | accuracy: 0.685 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5888446007783597 | accuracy: 0.6875 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5858472155200111 | accuracy: 0.6886574074074074 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.584493097450052 | accuracy: 0.6902901785714286 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5855331102321888 | accuracy: 0.6885775862068966 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5867502301931381 | accuracy: 0.6890625 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5851066160586572 | accuracy: 0.6900201612903226 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5814724732190371 | accuracy: 0.6943359375 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5795911767266013 | accuracy: 0.6964962121212122 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5822263062000275 | accuracy: 0.6943933823529411 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5808757594653539 | accuracy: 0.6950892857142857 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5790823979510201 | accuracy: 0.6957465277777778 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5796256580868283 | accuracy: 0.6951013513513513 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5799651114564193 | accuracy: 0.6944901315789473 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5794489200298603 | accuracy: 0.6935096153846154 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5798169210553169 | accuracy: 0.69453125 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5806000058243914 | accuracy: 0.6928353658536586 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5787400134972164 | accuracy: 0.6930803571428571 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5790574592213298 | accuracy: 0.6925872093023255 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5789816122163426 | accuracy: 0.6921164772727272 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5797737611664666 | accuracy: 0.6912288652526007 \n",
      "Epoch 3 | Step 807 | loss: 0.5203176736831665 | accuracy: 0.796875 \n",
      "Epoch 3 | Step 808 | loss: 0.5748103559017181 | accuracy: 0.6953125 \n",
      "Epoch 3 | Step 809 | loss: 0.5392293830712637 | accuracy: 0.7291666666666666 \n",
      "Epoch 3 | Step 810 | loss: 0.5260245278477669 | accuracy: 0.7421875 \n",
      "Epoch 3 | Step 811 | loss: 0.543783551454544 | accuracy: 0.725 \n",
      "Epoch 3 | Step 812 | loss: 0.5480086753765742 | accuracy: 0.71875 \n",
      "Epoch 3 | Step 813 | loss: 0.557009539433888 | accuracy: 0.7075892857142857 \n",
      "Epoch 3 | Step 814 | loss: 0.5690254308283329 | accuracy: 0.701171875 \n",
      "Epoch 3 | Step 815 | loss: 0.5667920476860471 | accuracy: 0.703125 \n",
      "Epoch 3 | Step 816 | loss: 0.5722969025373459 | accuracy: 0.6953125 \n",
      "Epoch 3 | Step 817 | loss: 0.5695456022566016 | accuracy: 0.6974431818181818 \n",
      "Epoch 3 | Step 818 | loss: 0.5757318859299024 | accuracy: 0.6940104166666666 \n",
      "Epoch 3 | Step 819 | loss: 0.5771614794547741 | accuracy: 0.6923076923076923 \n",
      "Epoch 3 | Step 820 | loss: 0.5773247246231351 | accuracy: 0.6908482142857143 \n",
      "Epoch 3 | Step 821 | loss: 0.5751735031604767 | accuracy: 0.690625 \n",
      "Epoch 3 | Step 822 | loss: 0.5683041326701641 | accuracy: 0.6982421875 \n",
      "Epoch 3 | Step 823 | loss: 0.5618516364518333 | accuracy: 0.7068014705882353 \n",
      "Epoch 3 | Step 824 | loss: 0.5657125198178821 | accuracy: 0.7039930555555556 \n",
      "Epoch 3 | Step 825 | loss: 0.566830332341947 | accuracy: 0.7023026315789473 \n",
      "Epoch 3 | Step 826 | loss: 0.5654552474617958 | accuracy: 0.70546875 \n",
      "Epoch 3 | Step 827 | loss: 0.5647856550557273 | accuracy: 0.7053571428571429 \n",
      "Epoch 3 | Step 828 | loss: 0.5628293522379615 | accuracy: 0.7052556818181819 \n",
      "Epoch 3 | Step 829 | loss: 0.5609334616557412 | accuracy: 0.7078804347826086 \n",
      "Epoch 3 | Step 830 | loss: 0.5605641094346842 | accuracy: 0.7076822916666666 \n",
      "Epoch 3 | Step 831 | loss: 0.5577588641643524 | accuracy: 0.71 \n",
      "Epoch 3 | Step 832 | loss: 0.5585009352518961 | accuracy: 0.7073317307692307 \n",
      "Epoch 3 | Step 833 | loss: 0.556848723579336 | accuracy: 0.7100694444444444 \n",
      "Epoch 3 | Step 834 | loss: 0.5524385826928274 | accuracy: 0.71484375 \n",
      "Epoch 3 | Step 835 | loss: 0.5516674724118462 | accuracy: 0.7149784482758621 \n",
      "Epoch 3 | Step 836 | loss: 0.5522132198015849 | accuracy: 0.7151041666666667 \n",
      "Epoch 3 | Step 837 | loss: 0.5507911712892594 | accuracy: 0.7162298387096774 \n",
      "Epoch 3 | Step 838 | loss: 0.5522243231534958 | accuracy: 0.71630859375 \n",
      "Epoch 3 | Step 839 | loss: 0.5529886375774037 | accuracy: 0.7154356060606061 \n",
      "Epoch 3 | Step 840 | loss: 0.5535917948274052 | accuracy: 0.7146139705882353 \n",
      "Epoch 3 | Step 841 | loss: 0.5539317948477609 | accuracy: 0.7138392857142857 \n",
      "Epoch 3 | Step 842 | loss: 0.5547478199005127 | accuracy: 0.7157118055555556 \n",
      "Epoch 3 | Step 843 | loss: 0.5532402621733176 | accuracy: 0.7166385135135135 \n",
      "Epoch 3 | Step 844 | loss: 0.5530687507830168 | accuracy: 0.7154605263157895 \n",
      "Epoch 3 | Step 845 | loss: 0.5536607396908295 | accuracy: 0.7147435897435898 \n",
      "Epoch 3 | Step 846 | loss: 0.5535056427121162 | accuracy: 0.716796875 \n",
      "Epoch 3 | Step 847 | loss: 0.5544418052929204 | accuracy: 0.7172256097560976 \n",
      "Epoch 3 | Step 848 | loss: 0.5511219927242825 | accuracy: 0.719122023809524 \n",
      "Epoch 3 | Step 849 | loss: 0.5498878006325213 | accuracy: 0.7202034883720931 \n",
      "Epoch 3 | Step 850 | loss: 0.5479971962896262 | accuracy: 0.7212357954545455 \n",
      "Epoch 3 | Step 851 | loss: 0.5493577380975089 | accuracy: 0.7208333333333333 \n",
      "Epoch 3 | Step 852 | loss: 0.5508181031631388 | accuracy: 0.7197690217391305 \n",
      "Epoch 3 | Step 853 | loss: 0.5499739843480131 | accuracy: 0.7200797872340425 \n",
      "Epoch 3 | Step 854 | loss: 0.5497032906860114 | accuracy: 0.7210286458333334 \n",
      "Epoch 3 | Step 855 | loss: 0.548219033041779 | accuracy: 0.7219387755102041 \n",
      "Epoch 3 | Step 856 | loss: 0.547747501730919 | accuracy: 0.7221875 \n",
      "Epoch 3 | Step 857 | loss: 0.5490255829165965 | accuracy: 0.7221200980392157 \n",
      "Epoch 3 | Step 858 | loss: 0.550853752746032 | accuracy: 0.7205528846153846 \n",
      "Epoch 3 | Step 859 | loss: 0.5508777279898807 | accuracy: 0.7208136792452831 \n",
      "Epoch 3 | Step 860 | loss: 0.5496280833526895 | accuracy: 0.7216435185185185 \n",
      "Epoch 3 | Step 861 | loss: 0.5472783944823526 | accuracy: 0.7238636363636364 \n",
      "Epoch 3 | Step 862 | loss: 0.5480923003384046 | accuracy: 0.7232142857142857 \n",
      "Epoch 3 | Step 863 | loss: 0.5483723293270982 | accuracy: 0.7239583333333334 \n",
      "Epoch 3 | Step 864 | loss: 0.5500584183068112 | accuracy: 0.7227909482758621 \n",
      "Epoch 3 | Step 865 | loss: 0.5506467950546137 | accuracy: 0.722457627118644 \n",
      "Epoch 3 | Step 866 | loss: 0.5498229324817658 | accuracy: 0.7223958333333333 \n",
      "Epoch 3 | Step 867 | loss: 0.549811568416533 | accuracy: 0.7228483606557377 \n",
      "Epoch 3 | Step 868 | loss: 0.5495049991915304 | accuracy: 0.7222782258064516 \n",
      "Epoch 3 | Step 869 | loss: 0.5493827897404868 | accuracy: 0.7222222222222222 \n",
      "Epoch 3 | Step 870 | loss: 0.5480221682228149 | accuracy: 0.72265625 \n",
      "Epoch 3 | Step 871 | loss: 0.5493095961900859 | accuracy: 0.7213942307692308 \n",
      "Epoch 3 | Step 872 | loss: 0.5479866699738937 | accuracy: 0.7223011363636364 \n",
      "Epoch 3 | Step 873 | loss: 0.547513805218597 | accuracy: 0.722714552238806 \n",
      "Epoch 3 | Step 874 | loss: 0.5469426293583478 | accuracy: 0.7231158088235294 \n",
      "Epoch 3 | Step 875 | loss: 0.548305838868238 | accuracy: 0.7219202898550725 \n",
      "Epoch 3 | Step 876 | loss: 0.5504328574453082 | accuracy: 0.7189732142857143 \n",
      "Epoch 3 | Step 877 | loss: 0.5509325416994767 | accuracy: 0.7189700704225352 \n",
      "Epoch 3 | Step 878 | loss: 0.5499356281426219 | accuracy: 0.7202690972222222 \n",
      "Epoch 3 | Step 879 | loss: 0.5497585085973349 | accuracy: 0.7208904109589042 \n",
      "Epoch 3 | Step 880 | loss: 0.550000622465804 | accuracy: 0.7208614864864866 \n",
      "Epoch 3 | Step 881 | loss: 0.5509296250343324 | accuracy: 0.7208333333333334 \n",
      "Epoch 3 | Step 882 | loss: 0.550084495230725 | accuracy: 0.7220394736842106 \n",
      "Epoch 3 | Step 883 | loss: 0.5494696312136466 | accuracy: 0.7221996753246754 \n",
      "Epoch 3 | Step 884 | loss: 0.54977241005653 | accuracy: 0.7215544871794872 \n",
      "Epoch 3 | Step 885 | loss: 0.5492575108250486 | accuracy: 0.7223101265822784 \n",
      "Epoch 3 | Step 886 | loss: 0.5485775869339705 | accuracy: 0.7228515625 \n",
      "Epoch 3 | Step 887 | loss: 0.5498905649155748 | accuracy: 0.7216435185185185 \n",
      "Epoch 3 | Step 888 | loss: 0.5495573271338533 | accuracy: 0.7214176829268293 \n",
      "Epoch 3 | Step 889 | loss: 0.549496226641069 | accuracy: 0.7211972891566265 \n",
      "Epoch 3 | Step 890 | loss: 0.5496105995206606 | accuracy: 0.7215401785714286 \n",
      "Epoch 3 | Step 891 | loss: 0.5496032774448395 | accuracy: 0.7209558823529412 \n",
      "Epoch 3 | Step 892 | loss: 0.5486673068168552 | accuracy: 0.721656976744186 \n",
      "Epoch 3 | Step 893 | loss: 0.5485044484851004 | accuracy: 0.7221623563218391 \n",
      "Epoch 3 | Step 894 | loss: 0.5492776408791542 | accuracy: 0.7215909090909091 \n",
      "Epoch 3 | Step 895 | loss: 0.5500267750761482 | accuracy: 0.7213834269662921 \n",
      "Epoch 3 | Step 896 | loss: 0.5504449175463781 | accuracy: 0.7215277777777778 \n",
      "Epoch 3 | Step 897 | loss: 0.5499616743444086 | accuracy: 0.7218406593406593 \n",
      "Epoch 3 | Step 898 | loss: 0.549723855179289 | accuracy: 0.7218070652173914 \n",
      "Epoch 3 | Step 899 | loss: 0.5498755202498486 | accuracy: 0.7219422043010753 \n",
      "Epoch 3 | Step 900 | loss: 0.5493708164133924 | accuracy: 0.7222406914893617 \n",
      "Epoch 3 | Step 901 | loss: 0.548737945682124 | accuracy: 0.7230263157894737 \n",
      "Epoch 3 | Step 902 | loss: 0.5478097706412274 | accuracy: 0.7236328125 \n",
      "Epoch 3 | Step 903 | loss: 0.547104034841675 | accuracy: 0.7243878865979382 \n",
      "Epoch 3 | Step 904 | loss: 0.5475129059382846 | accuracy: 0.7244897959183674 \n",
      "Epoch 3 | Step 905 | loss: 0.5468655523627693 | accuracy: 0.724905303030303 \n",
      "Epoch 3 | Step 906 | loss: 0.5472511994838712 | accuracy: 0.72453125 \n",
      "Epoch 3 | Step 907 | loss: 0.5474420785903928 | accuracy: 0.724319306930693 \n",
      "Epoch 3 | Step 908 | loss: 0.5477004845937091 | accuracy: 0.7239583333333334 \n",
      "Epoch 3 | Step 909 | loss: 0.5482830370514136 | accuracy: 0.7236043689320388 \n",
      "Epoch 3 | Step 910 | loss: 0.5475277169965778 | accuracy: 0.7244591346153846 \n",
      "Epoch 3 | Step 911 | loss: 0.5474125637894582 | accuracy: 0.7245535714285715 \n",
      "Epoch 3 | Step 912 | loss: 0.5472273115279537 | accuracy: 0.7246462264150944 \n",
      "Epoch 3 | Step 913 | loss: 0.5470647302186376 | accuracy: 0.7254672897196262 \n",
      "Epoch 3 | Step 914 | loss: 0.5473741019765535 | accuracy: 0.7252604166666666 \n",
      "Epoch 3 | Step 915 | loss: 0.5463404685532279 | accuracy: 0.7259174311926605 \n",
      "Epoch 3 | Step 916 | loss: 0.5459222416986117 | accuracy: 0.7258522727272727 \n",
      "Epoch 3 | Step 917 | loss: 0.5472612319228883 | accuracy: 0.7252252252252253 \n",
      "Epoch 3 | Step 918 | loss: 0.54810022536133 | accuracy: 0.7244698660714286 \n",
      "Epoch 3 | Step 919 | loss: 0.547280123275993 | accuracy: 0.7252488938053098 \n",
      "Epoch 3 | Step 920 | loss: 0.5471626964577455 | accuracy: 0.7250548245614035 \n",
      "Epoch 3 | Step 921 | loss: 0.5478960332663161 | accuracy: 0.7241847826086957 \n",
      "Epoch 3 | Step 922 | loss: 0.547931255965397 | accuracy: 0.7240032327586207 \n",
      "Epoch 3 | Step 923 | loss: 0.5472392888150661 | accuracy: 0.7240918803418803 \n",
      "Epoch 3 | Step 924 | loss: 0.5474347002425434 | accuracy: 0.7241790254237288 \n",
      "Epoch 3 | Step 925 | loss: 0.5476594502184569 | accuracy: 0.7238707983193278 \n",
      "Epoch 3 | Step 926 | loss: 0.5472688749432562 | accuracy: 0.7243489583333333 \n",
      "Epoch 3 | Step 927 | loss: 0.546635267163111 | accuracy: 0.7241735537190083 \n",
      "Epoch 3 | Step 928 | loss: 0.5468114634029199 | accuracy: 0.7241290983606558 \n",
      "Epoch 3 | Step 929 | loss: 0.5469202975916666 | accuracy: 0.7245934959349594 \n",
      "Epoch 3 | Step 930 | loss: 0.547327786684036 | accuracy: 0.7239163306451613 \n",
      "Epoch 3 | Step 931 | loss: 0.5472889080047605 | accuracy: 0.72425 \n",
      "Epoch 3 | Step 932 | loss: 0.547355385526778 | accuracy: 0.7239583333333334 \n",
      "Epoch 3 | Step 933 | loss: 0.5468479866587269 | accuracy: 0.7244094488188977 \n",
      "Epoch 3 | Step 934 | loss: 0.5469449132215229 | accuracy: 0.7242431640625 \n",
      "Epoch 3 | Step 935 | loss: 0.5476299540479052 | accuracy: 0.7237160852713178 \n",
      "Epoch 3 | Step 936 | loss: 0.5470911537225428 | accuracy: 0.7245192307692307 \n",
      "Epoch 3 | Step 937 | loss: 0.5470025200425211 | accuracy: 0.7243559160305344 \n",
      "Epoch 3 | Step 938 | loss: 0.5478894970182214 | accuracy: 0.7238399621212122 \n",
      "Epoch 3 | Step 939 | loss: 0.5472615551679653 | accuracy: 0.7239191729323309 \n",
      "Epoch 3 | Step 940 | loss: 0.5463804006576537 | accuracy: 0.7243470149253731 \n",
      "Epoch 3 | Step 941 | loss: 0.5460286950623546 | accuracy: 0.7246527777777778 \n",
      "Epoch 3 | Step 942 | loss: 0.5455670946222894 | accuracy: 0.7248391544117647 \n",
      "Epoch 3 | Step 943 | loss: 0.5458396688429977 | accuracy: 0.724566605839416 \n",
      "Epoch 3 | Step 944 | loss: 0.5454631110896234 | accuracy: 0.7246376811594203 \n",
      "Epoch 3 | Step 945 | loss: 0.5454661284419271 | accuracy: 0.7248201438848921 \n",
      "Epoch 3 | Step 946 | loss: 0.545597635422434 | accuracy: 0.7248883928571429 \n",
      "Epoch 3 | Step 947 | loss: 0.5455144309828467 | accuracy: 0.7248448581560284 \n",
      "Epoch 3 | Step 948 | loss: 0.545153463600387 | accuracy: 0.7248019366197183 \n",
      "Epoch 3 | Step 949 | loss: 0.5448089746328499 | accuracy: 0.724868881118881 \n",
      "Epoch 3 | Step 950 | loss: 0.5444554305738872 | accuracy: 0.7246093749999999 \n",
      "Epoch 3 | Step 951 | loss: 0.5442072703920561 | accuracy: 0.7252155172413792 \n",
      "Epoch 3 | Step 952 | loss: 0.5448912235155496 | accuracy: 0.7247431506849314 \n",
      "Epoch 3 | Step 953 | loss: 0.5450542451573066 | accuracy: 0.7249149659863945 \n",
      "Epoch 3 | Step 954 | loss: 0.5445710062175183 | accuracy: 0.725612331081081 \n",
      "Epoch 3 | Step 955 | loss: 0.5442759310639144 | accuracy: 0.7258808724832214 \n",
      "Epoch 3 | Step 956 | loss: 0.5439641505479812 | accuracy: 0.7259374999999999 \n",
      "Epoch 3 | Step 957 | loss: 0.5439515530273613 | accuracy: 0.7255794701986754 \n",
      "Epoch 3 | Step 958 | loss: 0.5444534748400511 | accuracy: 0.7254317434210525 \n",
      "Epoch 3 | Step 959 | loss: 0.5448250382943869 | accuracy: 0.724877450980392 \n",
      "Epoch 3 | Step 960 | loss: 0.5446417318149046 | accuracy: 0.7247362012987012 \n",
      "Epoch 3 | Step 961 | loss: 0.5439413339860978 | accuracy: 0.7252016129032257 \n",
      "Epoch 3 | Step 962 | loss: 0.5436841654471862 | accuracy: 0.7254607371794871 \n",
      "Epoch 3 | Step 963 | loss: 0.5434889649129977 | accuracy: 0.7253184713375795 \n",
      "Epoch 3 | Step 964 | loss: 0.5433735722982431 | accuracy: 0.7254746835443037 \n",
      "Epoch 3 | Step 965 | loss: 0.5431992362880108 | accuracy: 0.7254323899371068 \n",
      "Epoch 3 | Step 966 | loss: 0.543335271626711 | accuracy: 0.7250976562499999 \n",
      "Epoch 3 | Step 967 | loss: 0.542969819736777 | accuracy: 0.7257375776397514 \n",
      "Epoch 3 | Step 968 | loss: 0.5429182598988217 | accuracy: 0.7255015432098765 \n",
      "Epoch 3 | Step 969 | loss: 0.5427001409369745 | accuracy: 0.7255559815950919 \n",
      "Epoch 3 | Step 970 | loss: 0.5427488730084606 | accuracy: 0.725514481707317 \n",
      "Epoch 3 | Step 971 | loss: 0.5427051647142931 | accuracy: 0.7254734848484847 \n",
      "Epoch 3 | Step 972 | loss: 0.5431847128882465 | accuracy: 0.7248682228915662 \n",
      "Epoch 3 | Step 973 | loss: 0.5430673872996233 | accuracy: 0.7251122754491017 \n",
      "Epoch 3 | Step 974 | loss: 0.5433695857368764 | accuracy: 0.7248883928571428 \n",
      "Epoch 3 | Step 975 | loss: 0.5436199266882338 | accuracy: 0.7246671597633135 \n",
      "Epoch 3 | Step 976 | loss: 0.5437228127437479 | accuracy: 0.7249080882352941 \n",
      "Epoch 3 | Step 977 | loss: 0.5439494184234686 | accuracy: 0.7247807017543859 \n",
      "Epoch 3 | Step 978 | loss: 0.5440707277766493 | accuracy: 0.7247456395348837 \n",
      "Epoch 3 | Step 979 | loss: 0.543361863132157 | accuracy: 0.7253432080924855 \n",
      "Epoch 3 | Step 980 | loss: 0.5436083891953544 | accuracy: 0.7253951149425287 \n",
      "Epoch 3 | Step 981 | loss: 0.5434724509716032 | accuracy: 0.7253571428571428 \n",
      "Epoch 3 | Step 982 | loss: 0.5437081390145149 | accuracy: 0.7254083806818181 \n",
      "Epoch 3 | Step 983 | loss: 0.5441488453560628 | accuracy: 0.7249293785310734 \n",
      "Epoch 3 | Step 984 | loss: 0.5446190387010573 | accuracy: 0.7245435393258427 \n",
      "Epoch 3 | Step 985 | loss: 0.5445301321298716 | accuracy: 0.7248603351955307 \n",
      "Epoch 3 | Step 986 | loss: 0.5446895571218596 | accuracy: 0.7251736111111111 \n",
      "Epoch 3 | Step 987 | loss: 0.5441457187931841 | accuracy: 0.7252244475138122 \n",
      "Epoch 3 | Step 988 | loss: 0.5435576889213625 | accuracy: 0.7257898351648352 \n",
      "Epoch 3 | Step 989 | loss: 0.5434187593681564 | accuracy: 0.7258367486338798 \n",
      "Epoch 3 | Step 990 | loss: 0.5436617063115472 | accuracy: 0.7258831521739131 \n",
      "Epoch 3 | Step 991 | loss: 0.5436256101002565 | accuracy: 0.7259290540540541 \n",
      "Epoch 3 | Step 992 | loss: 0.5433135989212221 | accuracy: 0.7264784946236559 \n",
      "Epoch 3 | Step 993 | loss: 0.5436133890547217 | accuracy: 0.7261864973262032 \n",
      "Epoch 3 | Step 994 | loss: 0.543476551612641 | accuracy: 0.7263962765957447 \n",
      "Epoch 3 | Step 995 | loss: 0.5430067646755743 | accuracy: 0.7269345238095238 \n",
      "Epoch 3 | Step 996 | loss: 0.5425709835792842 | accuracy: 0.7273026315789474 \n",
      "Epoch 3 | Step 997 | loss: 0.5425466715665388 | accuracy: 0.7275850785340314 \n",
      "Epoch 3 | Step 998 | loss: 0.5425729374401271 | accuracy: 0.7275390625 \n",
      "Epoch 3 | Step 999 | loss: 0.5431510909542518 | accuracy: 0.7273316062176166 \n",
      "Epoch 3 | Step 1000 | loss: 0.5429490216306805 | accuracy: 0.7272873711340206 \n",
      "Epoch 3 | Step 1001 | loss: 0.5435705975080148 | accuracy: 0.7267628205128205 \n",
      "Epoch 3 | Step 1002 | loss: 0.5432067486096402 | accuracy: 0.7271205357142857 \n",
      "Epoch 3 | Step 1003 | loss: 0.5427718991555539 | accuracy: 0.727395304568528 \n",
      "Epoch 3 | Step 1004 | loss: 0.5429977925136836 | accuracy: 0.7272727272727273 \n",
      "Epoch 3 | Step 1005 | loss: 0.5434264762317715 | accuracy: 0.7271513819095478 \n",
      "Epoch 3 | Step 1006 | loss: 0.5431365123391152 | accuracy: 0.72734375 \n",
      "Epoch 3 | Step 1007 | loss: 0.5426641100674721 | accuracy: 0.7275342039800995 \n",
      "Epoch 3 | Step 1008 | loss: 0.5427437156143756 | accuracy: 0.7275680693069307 \n",
      "Epoch 3 | Step 1009 | loss: 0.5423326167860644 | accuracy: 0.7279864532019704 \n",
      "Epoch 3 | Step 1010 | loss: 0.542374525438337 | accuracy: 0.7277113970588235 \n",
      "Epoch 3 | Step 1011 | loss: 0.5424716822984744 | accuracy: 0.7274390243902439 \n",
      "Epoch 3 | Step 1012 | loss: 0.5422039010281704 | accuracy: 0.7276243932038835 \n",
      "Epoch 3 | Step 1013 | loss: 0.542135555819037 | accuracy: 0.7274305555555556 \n",
      "Epoch 3 | Step 1014 | loss: 0.5416026871937973 | accuracy: 0.7276141826923077 \n",
      "Epoch 3 | Step 1015 | loss: 0.5418793798633741 | accuracy: 0.7275717703349283 \n",
      "Epoch 3 | Step 1016 | loss: 0.5416828984305974 | accuracy: 0.7277529761904762 \n",
      "Epoch 3 | Step 1017 | loss: 0.5417986868117094 | accuracy: 0.7276362559241706 \n",
      "Epoch 3 | Step 1018 | loss: 0.5416705968245021 | accuracy: 0.7278154481132075 \n",
      "Epoch 3 | Step 1019 | loss: 0.5418006243280402 | accuracy: 0.7275528169014085 \n",
      "Epoch 3 | Step 1020 | loss: 0.5416486321765686 | accuracy: 0.7276577102803738 \n",
      "Epoch 3 | Step 1021 | loss: 0.5412804444168889 | accuracy: 0.7275436046511627 \n",
      "Epoch 3 | Step 1022 | loss: 0.5411141687245281 | accuracy: 0.7276475694444444 \n",
      "Epoch 3 | Step 1023 | loss: 0.5419213561693096 | accuracy: 0.7268145161290323 \n",
      "Epoch 3 | Step 1024 | loss: 0.5418646427196101 | accuracy: 0.7268491972477065 \n",
      "Epoch 3 | Step 1025 | loss: 0.541634577730475 | accuracy: 0.727097602739726 \n",
      "Epoch 3 | Step 1026 | loss: 0.541475919295441 | accuracy: 0.7269176136363636 \n",
      "Epoch 3 | Step 1027 | loss: 0.5412216883708988 | accuracy: 0.7269513574660633 \n",
      "Epoch 3 | Step 1028 | loss: 0.5409320821096231 | accuracy: 0.7271255630630631 \n",
      "Epoch 3 | Step 1029 | loss: 0.5408588415304106 | accuracy: 0.7271580717488789 \n",
      "Epoch 3 | Step 1030 | loss: 0.5407530431236539 | accuracy: 0.7273995535714286 \n",
      "Epoch 3 | Step 1031 | loss: 0.5414058934317694 | accuracy: 0.7267361111111111 \n",
      "Epoch 3 | Step 1032 | loss: 0.541411991404221 | accuracy: 0.7266316371681416 \n",
      "Epoch 3 | Step 1033 | loss: 0.5415801059306979 | accuracy: 0.7265280837004405 \n",
      "Epoch 3 | Step 1034 | loss: 0.5413642320455165 | accuracy: 0.7266995614035088 \n",
      "Epoch 3 | Step 1035 | loss: 0.5409647271883018 | accuracy: 0.7271424672489083 \n",
      "Epoch 3 | Step 1036 | loss: 0.540361405973849 | accuracy: 0.7275815217391305 \n",
      "Epoch 3 | Step 1037 | loss: 0.5409717895251847 | accuracy: 0.7271374458874459 \n",
      "Epoch 3 | Step 1038 | loss: 0.5405260097106982 | accuracy: 0.7274380387931034 \n",
      "Epoch 3 | Step 1039 | loss: 0.5408448521927189 | accuracy: 0.7273336909871244 \n",
      "Epoch 3 | Step 1040 | loss: 0.5409892248546974 | accuracy: 0.7271634615384616 \n",
      "Epoch 3 | Step 1041 | loss: 0.540807387169371 | accuracy: 0.7272606382978724 \n",
      "Epoch 3 | Step 1042 | loss: 0.5405220561108345 | accuracy: 0.727489406779661 \n",
      "Epoch 3 | Step 1043 | loss: 0.5407938680568323 | accuracy: 0.7274525316455697 \n",
      "Epoch 3 | Step 1044 | loss: 0.5413113208878939 | accuracy: 0.7272190126050421 \n",
      "Epoch 3 | Step 1045 | loss: 0.5413341315221585 | accuracy: 0.727314330543933 \n",
      "Epoch 3 | Step 1046 | loss: 0.5412313898404437 | accuracy: 0.7272135416666666 \n",
      "Epoch 3 | Step 1047 | loss: 0.5413685000783672 | accuracy: 0.7269839211618258 \n",
      "Epoch 3 | Step 1048 | loss: 0.5416519595079183 | accuracy: 0.726691632231405 \n",
      "Epoch 3 | Step 1049 | loss: 0.541429773034382 | accuracy: 0.7270447530864198 \n",
      "Epoch 3 | Step 1050 | loss: 0.5409863532566631 | accuracy: 0.7273949795081968 \n",
      "Epoch 3 | Step 1051 | loss: 0.5410851381262952 | accuracy: 0.727295918367347 \n",
      "Epoch 3 | Step 1052 | loss: 0.5409914429594829 | accuracy: 0.7271341463414634 \n",
      "Epoch 3 | Step 1053 | loss: 0.5407992024653351 | accuracy: 0.7271634615384616 \n",
      "Epoch 3 | Step 1054 | loss: 0.5408313449832699 | accuracy: 0.7271295362903226 \n",
      "Epoch 3 | Step 1055 | loss: 0.5413668064707252 | accuracy: 0.7268448795180723 \n",
      "Epoch 3 | Step 1056 | loss: 0.5409404420852659 | accuracy: 0.72725 \n",
      "Epoch 3 | Step 1057 | loss: 0.5413413688956027 | accuracy: 0.7270916334661355 \n",
      "Epoch 3 | Step 1058 | loss: 0.5413938022795175 | accuracy: 0.7269965277777778 \n",
      "Epoch 3 | Step 1059 | loss: 0.5412488167464966 | accuracy: 0.7272727272727273 \n",
      "Epoch 3 | Step 1060 | loss: 0.5411598461819443 | accuracy: 0.7272391732283464 \n",
      "Epoch 3 | Step 1061 | loss: 0.5410976080333483 | accuracy: 0.727328431372549 \n",
      "Epoch 3 | Step 1062 | loss: 0.5408373095560817 | accuracy: 0.72747802734375 \n",
      "Epoch 3 | Step 1063 | loss: 0.5408902792151334 | accuracy: 0.7275656614785992 \n",
      "Epoch 3 | Step 1064 | loss: 0.540837974049324 | accuracy: 0.7276526162790697 \n",
      "Epoch 3 | Step 1065 | loss: 0.5408815306586187 | accuracy: 0.7276182432432432 \n",
      "Epoch 3 | Step 1066 | loss: 0.5409584884460154 | accuracy: 0.7274038461538461 \n",
      "Epoch 3 | Step 1067 | loss: 0.5407187137110477 | accuracy: 0.7277897509578544 \n",
      "Epoch 3 | Step 1068 | loss: 0.5410171540183873 | accuracy: 0.7274570610687023 \n",
      "Epoch 3 | Step 1069 | loss: 0.5407214870697643 | accuracy: 0.7278992395437263 \n",
      "Epoch 3 | Step 1070 | loss: 0.5402392299112043 | accuracy: 0.728219696969697 \n",
      "Epoch 3 | Step 1071 | loss: 0.5401144912782703 | accuracy: 0.7282429245283019 \n",
      "Epoch 3 | Step 1072 | loss: 0.5401493229140014 | accuracy: 0.7283834586466166 \n",
      "Epoch 3 | Step 1073 | loss: 0.540026339140724 | accuracy: 0.7282888576779026 \n",
      "Epoch 3 | Step 1074 | loss: 0.5399629127845833 | accuracy: 0.7283698694029851 \n",
      "Epoch 3 | Step 1075 | loss: 0.5398135694872489 | accuracy: 0.7286245353159851 \n",
      "Epoch 3 | Step 1076 | loss: 0.5396228236180762 | accuracy: 0.7287037037037037 \n",
      "Epoch 3 | Step 1077 | loss: 0.5394942980410866 | accuracy: 0.7286093173431735 \n",
      "Epoch 3 | Step 1078 | loss: 0.539256744634579 | accuracy: 0.7288602941176471 \n",
      "Epoch 3 | Step 1079 | loss: 0.5392683308858136 | accuracy: 0.7290521978021978 \n",
      "Epoch 3 | Step 1080 | loss: 0.5391902180701275 | accuracy: 0.7290145985401459 \n",
      "Epoch 3 | Step 1081 | loss: 0.5391557937318626 | accuracy: 0.7289772727272728 \n",
      "Epoch 3 | Step 1082 | loss: 0.5395423317517057 | accuracy: 0.7289402173913043 \n",
      "Epoch 3 | Step 1083 | loss: 0.5395036007307925 | accuracy: 0.729298285198556 \n",
      "Epoch 3 | Step 1084 | loss: 0.5394447228248169 | accuracy: 0.7292603417266187 \n",
      "Epoch 3 | Step 1085 | loss: 0.5391131746298948 | accuracy: 0.7294466845878136 \n",
      "Epoch 3 | Step 1086 | loss: 0.5390134515506878 | accuracy: 0.7295200892857143 \n",
      "Epoch 3 | Step 1087 | loss: 0.5389327640211028 | accuracy: 0.7293705516014235 \n",
      "Epoch 3 | Step 1088 | loss: 0.5385634653957174 | accuracy: 0.7296653368794326 \n",
      "Epoch 3 | Step 1089 | loss: 0.5387860081642336 | accuracy: 0.7293507067137809 \n",
      "Epoch 3 | Step 1090 | loss: 0.5384687331150951 | accuracy: 0.729643485915493 \n",
      "Epoch 3 | Step 1091 | loss: 0.5382802969531005 | accuracy: 0.7298245614035088 \n",
      "Epoch 3 | Step 1092 | loss: 0.5376993141599464 | accuracy: 0.7302229020979021 \n",
      "Epoch 3 | Step 1093 | loss: 0.5377389405454904 | accuracy: 0.7300740418118467 \n",
      "Epoch 3 | Step 1094 | loss: 0.5374344570769201 | accuracy: 0.7303059895833334 \n",
      "Epoch 3 | Step 1095 | loss: 0.5378415225698869 | accuracy: 0.7299956747404844 \n",
      "Epoch 3 | Step 1096 | loss: 0.5375197866867325 | accuracy: 0.7301724137931035 \n",
      "Epoch 3 | Step 1097 | loss: 0.5378271107821117 | accuracy: 0.7300257731958762 \n",
      "Epoch 3 | Step 1098 | loss: 0.5376774598270243 | accuracy: 0.7300406678082192 \n",
      "Epoch 3 | Step 1099 | loss: 0.537662408966253 | accuracy: 0.7299488054607508 \n",
      "Epoch 3 | Step 1100 | loss: 0.5378068544629477 | accuracy: 0.7299107142857143 \n",
      "Epoch 3 | Step 1101 | loss: 0.5377877361693623 | accuracy: 0.7298728813559322 \n",
      "Epoch 3 | Step 1102 | loss: 0.5376061685383318 | accuracy: 0.7297825168918919 \n",
      "Epoch 3 | Step 1103 | loss: 0.5374867160512942 | accuracy: 0.7298505892255892 \n",
      "Epoch 3 | Step 1104 | loss: 0.5372835324714645 | accuracy: 0.7300755033557047 \n",
      "Epoch 3 | Step 1105 | loss: 0.5372603893479373 | accuracy: 0.7298808528428093 \n",
      "Epoch 3 | Step 1106 | loss: 0.5372359535098074 | accuracy: 0.7296875 \n",
      "Epoch 3 | Step 1107 | loss: 0.5373602874849324 | accuracy: 0.7294954318936877 \n",
      "Epoch 3 | Step 1108 | loss: 0.5372491130568332 | accuracy: 0.7298220198675497 \n",
      "Epoch 3 | Step 1109 | loss: 0.5369979947707045 | accuracy: 0.7300433168316832 \n",
      "Epoch 3 | Step 1110 | loss: 0.5370690001076772 | accuracy: 0.7298005756578948 \n",
      "Epoch 3 | Step 1111 | loss: 0.5368780176170534 | accuracy: 0.7299692622950821 \n",
      "Epoch 3 | Step 1112 | loss: 0.5365842118177536 | accuracy: 0.7300857843137256 \n",
      "Epoch 3 | Step 1113 | loss: 0.5366893233033653 | accuracy: 0.7298452768729643 \n",
      "Epoch 3 | Step 1114 | loss: 0.5364571654951414 | accuracy: 0.7300121753246754 \n",
      "Epoch 3 | Step 1115 | loss: 0.5361859378884137 | accuracy: 0.7303296925566344 \n",
      "Epoch 3 | Step 1116 | loss: 0.5359274016272635 | accuracy: 0.7304939516129033 \n",
      "Epoch 3 | Step 1117 | loss: 0.5356766062150813 | accuracy: 0.7306069131832799 \n",
      "Epoch 3 | Step 1118 | loss: 0.5355847858083553 | accuracy: 0.7307191506410258 \n",
      "Epoch 3 | Step 1119 | loss: 0.5352835093443387 | accuracy: 0.7309804313099042 \n",
      "Epoch 3 | Step 1120 | loss: 0.5353404890959431 | accuracy: 0.730891719745223 \n",
      "Epoch 3 | Step 1121 | loss: 0.5354710107757933 | accuracy: 0.7310019841269842 \n",
      "Epoch 3 | Step 1122 | loss: 0.5355471034970466 | accuracy: 0.7308148734177216 \n",
      "Epoch 3 | Step 1123 | loss: 0.5352595099703372 | accuracy: 0.7312204258675079 \n",
      "Epoch 3 | Step 1124 | loss: 0.5353628973353586 | accuracy: 0.7311320754716981 \n",
      "Epoch 3 | Step 1125 | loss: 0.5352562366047625 | accuracy: 0.7312402037617555 \n",
      "Epoch 3 | Step 1126 | loss: 0.5350941793993117 | accuracy: 0.73134765625 \n",
      "Epoch 3 | Step 1127 | loss: 0.5349867007814094 | accuracy: 0.7313084112149533 \n",
      "Epoch 3 | Step 1128 | loss: 0.5351948538181946 | accuracy: 0.7311723602484472 \n",
      "Epoch 3 | Step 1129 | loss: 0.5349653897455235 | accuracy: 0.7313273993808049 \n",
      "Epoch 3 | Step 1130 | loss: 0.5347856873715368 | accuracy: 0.7311921296296297 \n",
      "Epoch 3 | Step 1131 | loss: 0.5347306042451127 | accuracy: 0.7312019230769231 \n",
      "Epoch 3 | Step 1132 | loss: 0.5344916540055189 | accuracy: 0.7314033742331288 \n",
      "Epoch 3 | Step 1133 | loss: 0.5343675719124099 | accuracy: 0.731460244648318 \n",
      "Epoch 3 | Step 1134 | loss: 0.5344956588090921 | accuracy: 0.7312785823170732 \n",
      "Epoch 3 | Step 1135 | loss: 0.5349266895044902 | accuracy: 0.7310505319148937 \n",
      "Epoch 3 | Step 1136 | loss: 0.5349528964721796 | accuracy: 0.7311553030303031 \n",
      "Epoch 3 | Step 1137 | loss: 0.5349560626683999 | accuracy: 0.7311650302114804 \n",
      "Epoch 3 | Step 1138 | loss: 0.5348125041787883 | accuracy: 0.7312688253012049 \n",
      "Epoch 3 | Step 1139 | loss: 0.5346811796809818 | accuracy: 0.7312781531531531 \n",
      "Epoch 3 | Step 1140 | loss: 0.5345907953684915 | accuracy: 0.7313342065868264 \n",
      "Epoch 3 | Step 1141 | loss: 0.5343770305612194 | accuracy: 0.7315298507462686 \n",
      "Epoch 3 | Step 1142 | loss: 0.5341440757647866 | accuracy: 0.7315383184523809 \n",
      "Epoch 3 | Step 1143 | loss: 0.5342073920749415 | accuracy: 0.7315003709198813 \n",
      "Epoch 3 | Step 1144 | loss: 0.5340711387127814 | accuracy: 0.7315551035502958 \n",
      "Epoch 3 | Step 1145 | loss: 0.533995730950769 | accuracy: 0.7317016961651918 \n",
      "Epoch 3 | Step 1146 | loss: 0.5337261495344778 | accuracy: 0.7318933823529412 \n",
      "Epoch 3 | Step 1147 | loss: 0.5333199493171881 | accuracy: 0.7320839442815249 \n",
      "Epoch 3 | Step 1148 | loss: 0.5332337390435368 | accuracy: 0.7321363304093568 \n",
      "Epoch 3 | Step 1149 | loss: 0.53328401102269 | accuracy: 0.7321884110787172 \n",
      "Epoch 3 | Step 1150 | loss: 0.5328926727348982 | accuracy: 0.7323764534883721 \n",
      "Epoch 3 | Step 1151 | loss: 0.5330927638903908 | accuracy: 0.7321557971014493 \n",
      "Epoch 3 | Step 1152 | loss: 0.5330502321093069 | accuracy: 0.732162210982659 \n",
      "Epoch 3 | Step 1153 | loss: 0.532654151706943 | accuracy: 0.7324837896253602 \n",
      "Epoch 3 | Step 1154 | loss: 0.53286000341177 | accuracy: 0.7325790229885057 \n",
      "Epoch 3 | Step 1155 | loss: 0.5327986828064851 | accuracy: 0.7326737106017192 \n",
      "Epoch 3 | Step 1156 | loss: 0.5325910838161196 | accuracy: 0.7329464285714286 \n",
      "Epoch 3 | Step 1157 | loss: 0.5324312298216372 | accuracy: 0.7330840455840456 \n",
      "Epoch 3 | Step 1158 | loss: 0.5323850680989298 | accuracy: 0.7331764914772727 \n",
      "Epoch 3 | Step 1159 | loss: 0.5323417076139207 | accuracy: 0.7331356232294618 \n",
      "Epoch 3 | Step 1160 | loss: 0.5323149561040146 | accuracy: 0.7331391242937854 \n",
      "Epoch 3 | Step 1161 | loss: 0.532091364558314 | accuracy: 0.7333186619718309 \n",
      "Epoch 3 | Step 1162 | loss: 0.5320316245046894 | accuracy: 0.7332338483146067 \n",
      "Epoch 3 | Step 1163 | loss: 0.5319504666061294 | accuracy: 0.7332808123249299 \n",
      "Epoch 3 | Step 1164 | loss: 0.532149909428378 | accuracy: 0.7332402234636871 \n",
      "Epoch 3 | Step 1165 | loss: 0.5320503049242131 | accuracy: 0.7333304317548747 \n",
      "Epoch 3 | Step 1166 | loss: 0.5319947396715482 | accuracy: 0.7335069444444444 \n",
      "Epoch 3 | Step 1167 | loss: 0.5321577282163245 | accuracy: 0.7333362188365651 \n",
      "Epoch 3 | Step 1168 | loss: 0.5320131898090984 | accuracy: 0.7333822513812155 \n",
      "Epoch 3 | Step 1169 | loss: 0.5320070793970229 | accuracy: 0.7331697658402204 \n",
      "Epoch 3 | Step 1170 | loss: 0.5318806950043846 | accuracy: 0.7331730769230769 \n",
      "Epoch 3 | Step 1171 | loss: 0.5318153597720682 | accuracy: 0.7331763698630137 \n",
      "Epoch 3 | Step 1172 | loss: 0.5315787369599108 | accuracy: 0.7333504098360656 \n",
      "Epoch 3 | Step 1173 | loss: 0.5316736411496145 | accuracy: 0.7333532016348774 \n",
      "Epoch 3 | Step 1174 | loss: 0.5315673797512833 | accuracy: 0.7333984375 \n",
      "Epoch 3 | Step 1175 | loss: 0.5315777776525598 | accuracy: 0.7334434281842819 \n",
      "Epoch 3 | Step 1176 | loss: 0.5316917673156071 | accuracy: 0.733277027027027 \n",
      "Epoch 3 | Step 1177 | loss: 0.5317362359752554 | accuracy: 0.733237870619946 \n",
      "Epoch 3 | Step 1178 | loss: 0.5319795755128709 | accuracy: 0.7331989247311828 \n",
      "Epoch 3 | Step 1179 | loss: 0.5319925553837029 | accuracy: 0.7332439678284183 \n",
      "Epoch 3 | Step 1180 | loss: 0.5317325926719505 | accuracy: 0.7334141042780749 \n",
      "Epoch 3 | Step 1181 | loss: 0.5315256872971855 | accuracy: 0.7335833333333334 \n",
      "Epoch 3 | Step 1182 | loss: 0.531436196350037 | accuracy: 0.7335438829787234 \n",
      "Epoch 3 | Step 1183 | loss: 0.5313742973444002 | accuracy: 0.7336289787798409 \n",
      "Epoch 3 | Step 1184 | loss: 0.5313390685767726 | accuracy: 0.7335896164021164 \n",
      "Epoch 3 | Step 1185 | loss: 0.5310382836726852 | accuracy: 0.7337978232189973 \n",
      "Epoch 3 | Step 1186 | loss: 0.5310159170313887 | accuracy: 0.7336348684210526 \n",
      "Epoch 3 | Step 1187 | loss: 0.5309115297055935 | accuracy: 0.7338008530183727 \n",
      "Epoch 3 | Step 1188 | loss: 0.530674907159431 | accuracy: 0.7338432591623036 \n",
      "Epoch 3 | Step 1189 | loss: 0.5305373429007071 | accuracy: 0.7338854438642297 \n",
      "Epoch 3 | Step 1190 | loss: 0.5306007605977358 | accuracy: 0.7337239583333334 \n",
      "Epoch 3 | Step 1191 | loss: 0.5307358830006094 | accuracy: 0.7337256493506493 \n",
      "Epoch 3 | Step 1192 | loss: 0.5308529969324104 | accuracy: 0.7337273316062176 \n",
      "Epoch 3 | Step 1193 | loss: 0.5307916436700552 | accuracy: 0.7338501291989664 \n",
      "Epoch 3 | Step 1194 | loss: 0.5306123401393597 | accuracy: 0.7338514819587629 \n",
      "Epoch 3 | Step 1195 | loss: 0.5308018161276007 | accuracy: 0.7337323264781491 \n",
      "Epoch 3 | Step 1196 | loss: 0.5305347018516982 | accuracy: 0.7338942307692308 \n",
      "Epoch 3 | Step 1197 | loss: 0.5306653332374895 | accuracy: 0.7338554987212276 \n",
      "Epoch 3 | Step 1198 | loss: 0.5305972683946698 | accuracy: 0.7340959821428571 \n",
      "Epoch 3 | Step 1199 | loss: 0.5303716287206451 | accuracy: 0.7341762086513995 \n",
      "Epoch 3 | Step 1200 | loss: 0.5304454538574074 | accuracy: 0.7341767131979695 \n",
      "Epoch 3 | Step 1201 | loss: 0.530543700124644 | accuracy: 0.7339794303797469 \n",
      "Epoch 3 | Step 1202 | loss: 0.5303343721110412 | accuracy: 0.7340988005050505 \n",
      "Epoch 3 | Step 1203 | loss: 0.5303826443194143 | accuracy: 0.7341388539042821 \n",
      "Epoch 3 | Step 1204 | loss: 0.5303583910417318 | accuracy: 0.734100188442211 \n",
      "Epoch 3 | Step 1205 | loss: 0.5301748579157923 | accuracy: 0.734296679197995 \n",
      "Epoch 3 | Step 1206 | loss: 0.5303678346425296 | accuracy: 0.7341796875 \n",
      "Epoch 3 | Step 1207 | loss: 0.5304722525086487 | accuracy: 0.7340243142144638 \n",
      "Epoch 3 | Step 1208 | loss: 0.5306888681590854 | accuracy: 0.7337919776119403 \n",
      "Epoch 3 | Step 1209 | loss: 0.5305181990190416 | accuracy: 0.7340247177012801 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5816408395767212 | accuracy: 0.65625 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5862952172756195 | accuracy: 0.6640625 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.563454786936442 | accuracy: 0.6875 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5704338252544403 | accuracy: 0.6796875 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5660409927368164 | accuracy: 0.6875 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.565356065829595 | accuracy: 0.6875 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5623556205204555 | accuracy: 0.6919642857142857 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5588929280638695 | accuracy: 0.6953125 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.555868493186103 | accuracy: 0.6944444444444444 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5530251681804657 | accuracy: 0.6984375 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5519761551510204 | accuracy: 0.6988636363636364 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5453849136829376 | accuracy: 0.7057291666666666 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5463859393046453 | accuracy: 0.7055288461538461 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5420483968087606 | accuracy: 0.7098214285714286 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.535678267478943 | accuracy: 0.7166666666666667 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5336363799870015 | accuracy: 0.7197265625 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5393562772694757 | accuracy: 0.7169117647058824 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5356855839490892 | accuracy: 0.7170138888888888 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5389893321614517 | accuracy: 0.71875 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5379059240221978 | accuracy: 0.71953125 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5384656488895417 | accuracy: 0.7209821428571429 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5335469110445543 | accuracy: 0.7258522727272728 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5370435818381931 | accuracy: 0.7214673913043478 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5396815687417984 | accuracy: 0.720703125 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5397395968437195 | accuracy: 0.720625 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5354939309450297 | accuracy: 0.7241586538461539 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.532504474675214 | accuracy: 0.7256944444444444 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5302180913942202 | accuracy: 0.7287946428571429 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5316684030253312 | accuracy: 0.7268318965517241 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5322648694117864 | accuracy: 0.7286458333333333 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5303346889634286 | accuracy: 0.7293346774193549 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5260023456066847 | accuracy: 0.734375 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5244142259612228 | accuracy: 0.7348484848484849 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5289238367010566 | accuracy: 0.7316176470588235 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5274346394198282 | accuracy: 0.7321428571428571 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5255313772294257 | accuracy: 0.734375 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5264730944826796 | accuracy: 0.7347972972972973 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.526846737453812 | accuracy: 0.734375 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5260340265738659 | accuracy: 0.7339743589743589 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5267626836895942 | accuracy: 0.7339843749999999 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.527596289064826 | accuracy: 0.7336128048780487 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5254858817373004 | accuracy: 0.7351190476190476 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5258192669513615 | accuracy: 0.7343749999999999 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5261146724224092 | accuracy: 0.7340198863636364 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5278089112705655 | accuracy: 0.732201087474823 \n",
      "Epoch 4 | Step 1210 | loss: 0.4583965241909027 | accuracy: 0.765625 \n",
      "Epoch 4 | Step 1211 | loss: 0.5082017034292221 | accuracy: 0.71875 \n",
      "Epoch 4 | Step 1212 | loss: 0.4700745145479838 | accuracy: 0.7604166666666666 \n",
      "Epoch 4 | Step 1213 | loss: 0.4625220522284508 | accuracy: 0.76953125 \n",
      "Epoch 4 | Step 1214 | loss: 0.4747086226940155 | accuracy: 0.7625 \n",
      "Epoch 4 | Step 1215 | loss: 0.47681527336438495 | accuracy: 0.7578125 \n",
      "Epoch 4 | Step 1216 | loss: 0.4865725721631731 | accuracy: 0.7566964285714286 \n",
      "Epoch 4 | Step 1217 | loss: 0.4947274774312973 | accuracy: 0.75 \n",
      "Epoch 4 | Step 1218 | loss: 0.4922051926453908 | accuracy: 0.7517361111111112 \n",
      "Epoch 4 | Step 1219 | loss: 0.49967717230319975 | accuracy: 0.746875 \n",
      "Epoch 4 | Step 1220 | loss: 0.4960138445550745 | accuracy: 0.7514204545454546 \n",
      "Epoch 4 | Step 1221 | loss: 0.504070503016313 | accuracy: 0.7473958333333334 \n",
      "Epoch 4 | Step 1222 | loss: 0.5035518109798431 | accuracy: 0.75 \n",
      "Epoch 4 | Step 1223 | loss: 0.5085689489330564 | accuracy: 0.7455357142857143 \n",
      "Epoch 4 | Step 1224 | loss: 0.5050053099791209 | accuracy: 0.746875 \n",
      "Epoch 4 | Step 1225 | loss: 0.49719469062983984 | accuracy: 0.7529296875 \n",
      "Epoch 4 | Step 1226 | loss: 0.4929177883793326 | accuracy: 0.7555147058823529 \n",
      "Epoch 4 | Step 1227 | loss: 0.49760424925221336 | accuracy: 0.7517361111111112 \n",
      "Epoch 4 | Step 1228 | loss: 0.4957859265176873 | accuracy: 0.7516447368421053 \n",
      "Epoch 4 | Step 1229 | loss: 0.4965303599834442 | accuracy: 0.753125 \n",
      "Epoch 4 | Step 1230 | loss: 0.49613174370356966 | accuracy: 0.7514880952380952 \n",
      "Epoch 4 | Step 1231 | loss: 0.4957834685390646 | accuracy: 0.7521306818181818 \n",
      "Epoch 4 | Step 1232 | loss: 0.49260185594144074 | accuracy: 0.7540760869565217 \n",
      "Epoch 4 | Step 1233 | loss: 0.49304110805193585 | accuracy: 0.75390625 \n",
      "Epoch 4 | Step 1234 | loss: 0.489298415184021 | accuracy: 0.756875 \n",
      "Epoch 4 | Step 1235 | loss: 0.49040716657271755 | accuracy: 0.7542067307692307 \n",
      "Epoch 4 | Step 1236 | loss: 0.4900987435270239 | accuracy: 0.7546296296296297 \n",
      "Epoch 4 | Step 1237 | loss: 0.4850354333009039 | accuracy: 0.7589285714285714 \n",
      "Epoch 4 | Step 1238 | loss: 0.48513138705286485 | accuracy: 0.7591594827586207 \n",
      "Epoch 4 | Step 1239 | loss: 0.48635920882225037 | accuracy: 0.7609375 \n",
      "Epoch 4 | Step 1240 | loss: 0.48490697818417705 | accuracy: 0.7610887096774194 \n",
      "Epoch 4 | Step 1241 | loss: 0.4860529424622655 | accuracy: 0.7607421875 \n",
      "Epoch 4 | Step 1242 | loss: 0.4878409550045476 | accuracy: 0.7604166666666666 \n",
      "Epoch 4 | Step 1243 | loss: 0.4888252466917038 | accuracy: 0.7596507352941176 \n",
      "Epoch 4 | Step 1244 | loss: 0.4895537997995104 | accuracy: 0.7584821428571429 \n",
      "Epoch 4 | Step 1245 | loss: 0.4900295279092259 | accuracy: 0.7586805555555556 \n",
      "Epoch 4 | Step 1246 | loss: 0.4884753597749246 | accuracy: 0.7605574324324325 \n",
      "Epoch 4 | Step 1247 | loss: 0.4872059516216579 | accuracy: 0.7615131578947368 \n",
      "Epoch 4 | Step 1248 | loss: 0.4876834849516551 | accuracy: 0.7616185897435898 \n",
      "Epoch 4 | Step 1249 | loss: 0.48713910952210426 | accuracy: 0.762890625 \n",
      "Epoch 4 | Step 1250 | loss: 0.4883221511433764 | accuracy: 0.7629573170731707 \n",
      "Epoch 4 | Step 1251 | loss: 0.48539469568502336 | accuracy: 0.7652529761904762 \n",
      "Epoch 4 | Step 1252 | loss: 0.48426602191703266 | accuracy: 0.7652616279069767 \n",
      "Epoch 4 | Step 1253 | loss: 0.4831196577711539 | accuracy: 0.765625 \n",
      "Epoch 4 | Step 1254 | loss: 0.4846147649817997 | accuracy: 0.7649305555555556 \n",
      "Epoch 4 | Step 1255 | loss: 0.4855399721342584 | accuracy: 0.7632472826086957 \n",
      "Epoch 4 | Step 1256 | loss: 0.4850640062322008 | accuracy: 0.7632978723404256 \n",
      "Epoch 4 | Step 1257 | loss: 0.4853552548835675 | accuracy: 0.7639973958333334 \n",
      "Epoch 4 | Step 1258 | loss: 0.48352926908707133 | accuracy: 0.765625 \n",
      "Epoch 4 | Step 1259 | loss: 0.4834047991037369 | accuracy: 0.7653125 \n",
      "Epoch 4 | Step 1260 | loss: 0.48495261867841083 | accuracy: 0.7647058823529411 \n",
      "Epoch 4 | Step 1261 | loss: 0.48731169276512587 | accuracy: 0.7635216346153846 \n",
      "Epoch 4 | Step 1262 | loss: 0.487107016567914 | accuracy: 0.7635613207547169 \n",
      "Epoch 4 | Step 1263 | loss: 0.48549591115227453 | accuracy: 0.7650462962962963 \n",
      "Epoch 4 | Step 1264 | loss: 0.4826831644231623 | accuracy: 0.7673295454545455 \n",
      "Epoch 4 | Step 1265 | loss: 0.4835991710424423 | accuracy: 0.7670200892857143 \n",
      "Epoch 4 | Step 1266 | loss: 0.48428804100605477 | accuracy: 0.7678179824561403 \n",
      "Epoch 4 | Step 1267 | loss: 0.48611812344912825 | accuracy: 0.7669719827586207 \n",
      "Epoch 4 | Step 1268 | loss: 0.4867485135288562 | accuracy: 0.767478813559322 \n",
      "Epoch 4 | Step 1269 | loss: 0.48653202106555304 | accuracy: 0.7666666666666667 \n",
      "Epoch 4 | Step 1270 | loss: 0.4872728718108818 | accuracy: 0.7663934426229508 \n",
      "Epoch 4 | Step 1271 | loss: 0.48715895654693725 | accuracy: 0.765625 \n",
      "Epoch 4 | Step 1272 | loss: 0.48699201525203767 | accuracy: 0.7653769841269841 \n",
      "Epoch 4 | Step 1273 | loss: 0.4853245038539171 | accuracy: 0.765380859375 \n",
      "Epoch 4 | Step 1274 | loss: 0.4865477396891667 | accuracy: 0.7646634615384615 \n",
      "Epoch 4 | Step 1275 | loss: 0.48482052259372943 | accuracy: 0.7658617424242424 \n",
      "Epoch 4 | Step 1276 | loss: 0.4848441886368082 | accuracy: 0.7653917910447762 \n",
      "Epoch 4 | Step 1277 | loss: 0.4841546096345958 | accuracy: 0.765625 \n",
      "Epoch 4 | Step 1278 | loss: 0.4857036104236824 | accuracy: 0.7649456521739131 \n",
      "Epoch 4 | Step 1279 | loss: 0.48827931157180243 | accuracy: 0.7631696428571428 \n",
      "Epoch 4 | Step 1280 | loss: 0.4887557176636978 | accuracy: 0.7632042253521126 \n",
      "Epoch 4 | Step 1281 | loss: 0.4880622824033101 | accuracy: 0.7641059027777778 \n",
      "Epoch 4 | Step 1282 | loss: 0.48790618450674295 | accuracy: 0.7647688356164384 \n",
      "Epoch 4 | Step 1283 | loss: 0.48836165867947245 | accuracy: 0.7643581081081081 \n",
      "Epoch 4 | Step 1284 | loss: 0.48937294840812684 | accuracy: 0.76375 \n",
      "Epoch 4 | Step 1285 | loss: 0.4881914336430399 | accuracy: 0.7650082236842105 \n",
      "Epoch 4 | Step 1286 | loss: 0.487551243661286 | accuracy: 0.7648133116883117 \n",
      "Epoch 4 | Step 1287 | loss: 0.4876328603579448 | accuracy: 0.7640224358974359 \n",
      "Epoch 4 | Step 1288 | loss: 0.4868128899532028 | accuracy: 0.7642405063291139 \n",
      "Epoch 4 | Step 1289 | loss: 0.48640504963696 | accuracy: 0.764453125 \n",
      "Epoch 4 | Step 1290 | loss: 0.4879020404668502 | accuracy: 0.7629243827160493 \n",
      "Epoch 4 | Step 1291 | loss: 0.4873132225943775 | accuracy: 0.7633384146341463 \n",
      "Epoch 4 | Step 1292 | loss: 0.48753657470266504 | accuracy: 0.7629894578313253 \n",
      "Epoch 4 | Step 1293 | loss: 0.4874088540673256 | accuracy: 0.7637648809523809 \n",
      "Epoch 4 | Step 1294 | loss: 0.4878125292413375 | accuracy: 0.7637867647058824 \n",
      "Epoch 4 | Step 1295 | loss: 0.4864331234333127 | accuracy: 0.7648982558139535 \n",
      "Epoch 4 | Step 1296 | loss: 0.48611463383696546 | accuracy: 0.7649066091954023 \n",
      "Epoch 4 | Step 1297 | loss: 0.48674535243348643 | accuracy: 0.7643821022727273 \n",
      "Epoch 4 | Step 1298 | loss: 0.48772078719031947 | accuracy: 0.7636938202247191 \n",
      "Epoch 4 | Step 1299 | loss: 0.48819680048359765 | accuracy: 0.7633680555555555 \n",
      "Epoch 4 | Step 1300 | loss: 0.4876863501229129 | accuracy: 0.7637362637362637 \n",
      "Epoch 4 | Step 1301 | loss: 0.48782256342794583 | accuracy: 0.7637567934782609 \n",
      "Epoch 4 | Step 1302 | loss: 0.48850949701442514 | accuracy: 0.7639448924731183 \n",
      "Epoch 4 | Step 1303 | loss: 0.48779758874406204 | accuracy: 0.7637965425531915 \n",
      "Epoch 4 | Step 1304 | loss: 0.48720813519076295 | accuracy: 0.7641447368421053 \n",
      "Epoch 4 | Step 1305 | loss: 0.48615853022783995 | accuracy: 0.7649739583333334 \n",
      "Epoch 4 | Step 1306 | loss: 0.4852846882392451 | accuracy: 0.7657860824742269 \n",
      "Epoch 4 | Step 1307 | loss: 0.4857609433178999 | accuracy: 0.7654655612244898 \n",
      "Epoch 4 | Step 1308 | loss: 0.4851117471251825 | accuracy: 0.765625 \n",
      "Epoch 4 | Step 1309 | loss: 0.4858280801773071 | accuracy: 0.76515625 \n",
      "Epoch 4 | Step 1310 | loss: 0.48622354481479907 | accuracy: 0.7651608910891089 \n",
      "Epoch 4 | Step 1311 | loss: 0.4865686776591282 | accuracy: 0.7645526960784313 \n",
      "Epoch 4 | Step 1312 | loss: 0.48720139843746296 | accuracy: 0.7641080097087378 \n",
      "Epoch 4 | Step 1313 | loss: 0.48661954041856986 | accuracy: 0.7647235576923077 \n",
      "Epoch 4 | Step 1314 | loss: 0.48695214333988374 | accuracy: 0.7641369047619048 \n",
      "Epoch 4 | Step 1315 | loss: 0.4866815397761903 | accuracy: 0.7642983490566038 \n",
      "Epoch 4 | Step 1316 | loss: 0.48637219205080906 | accuracy: 0.7646028037383178 \n",
      "Epoch 4 | Step 1317 | loss: 0.48675157874822617 | accuracy: 0.7647569444444444 \n",
      "Epoch 4 | Step 1318 | loss: 0.48573406163705596 | accuracy: 0.7654816513761468 \n",
      "Epoch 4 | Step 1319 | loss: 0.48566728125918995 | accuracy: 0.7651988636363637 \n",
      "Epoch 4 | Step 1320 | loss: 0.48692818321623244 | accuracy: 0.7642173423423423 \n",
      "Epoch 4 | Step 1321 | loss: 0.48764728382229805 | accuracy: 0.763671875 \n",
      "Epoch 4 | Step 1322 | loss: 0.4870841983145317 | accuracy: 0.7645188053097345 \n",
      "Epoch 4 | Step 1323 | loss: 0.48713143797297226 | accuracy: 0.7642543859649122 \n",
      "Epoch 4 | Step 1324 | loss: 0.48762158077696094 | accuracy: 0.7635869565217391 \n",
      "Epoch 4 | Step 1325 | loss: 0.48749512999222194 | accuracy: 0.7634698275862069 \n",
      "Epoch 4 | Step 1326 | loss: 0.4867618988212357 | accuracy: 0.7634882478632479 \n",
      "Epoch 4 | Step 1327 | loss: 0.4871731251478195 | accuracy: 0.7632415254237288 \n",
      "Epoch 4 | Step 1328 | loss: 0.48750093429028485 | accuracy: 0.7629989495798319 \n",
      "Epoch 4 | Step 1329 | loss: 0.48689964835842453 | accuracy: 0.7634114583333333 \n",
      "Epoch 4 | Step 1330 | loss: 0.4863761941756099 | accuracy: 0.7639462809917356 \n",
      "Epoch 4 | Step 1331 | loss: 0.48662512590650653 | accuracy: 0.7637038934426229 \n",
      "Epoch 4 | Step 1332 | loss: 0.48657808652738244 | accuracy: 0.7641006097560976 \n",
      "Epoch 4 | Step 1333 | loss: 0.4873795812168429 | accuracy: 0.7631048387096774 \n",
      "Epoch 4 | Step 1334 | loss: 0.48746762228012086 | accuracy: 0.763375 \n",
      "Epoch 4 | Step 1335 | loss: 0.48771164861936417 | accuracy: 0.7631448412698413 \n",
      "Epoch 4 | Step 1336 | loss: 0.48762602012927136 | accuracy: 0.7631643700787402 \n",
      "Epoch 4 | Step 1337 | loss: 0.48760959203355014 | accuracy: 0.76318359375 \n",
      "Epoch 4 | Step 1338 | loss: 0.4883296445820683 | accuracy: 0.7625968992248062 \n",
      "Epoch 4 | Step 1339 | loss: 0.48784462557389185 | accuracy: 0.7634615384615384 \n",
      "Epoch 4 | Step 1340 | loss: 0.4878741782585173 | accuracy: 0.7633587786259542 \n",
      "Epoch 4 | Step 1341 | loss: 0.48855768979498837 | accuracy: 0.7631392045454546 \n",
      "Epoch 4 | Step 1342 | loss: 0.48794482749207574 | accuracy: 0.7632753759398496 \n",
      "Epoch 4 | Step 1343 | loss: 0.4873074110764176 | accuracy: 0.7638759328358209 \n",
      "Epoch 4 | Step 1344 | loss: 0.48710374743850143 | accuracy: 0.7642361111111111 \n",
      "Epoch 4 | Step 1345 | loss: 0.48676664645180984 | accuracy: 0.7644761029411765 \n",
      "Epoch 4 | Step 1346 | loss: 0.487050801298044 | accuracy: 0.7641423357664233 \n",
      "Epoch 4 | Step 1347 | loss: 0.4863996715217397 | accuracy: 0.7647192028985508 \n",
      "Epoch 4 | Step 1348 | loss: 0.48670721461447025 | accuracy: 0.7647257194244604 \n",
      "Epoch 4 | Step 1349 | loss: 0.4869584703019687 | accuracy: 0.7642857142857142 \n",
      "Epoch 4 | Step 1350 | loss: 0.4871839646329271 | accuracy: 0.7639627659574468 \n",
      "Epoch 4 | Step 1351 | loss: 0.4869053695403354 | accuracy: 0.7640845070422535 \n",
      "Epoch 4 | Step 1352 | loss: 0.4863078339950188 | accuracy: 0.7644230769230769 \n",
      "Epoch 4 | Step 1353 | loss: 0.4860693487442202 | accuracy: 0.7643229166666665 \n",
      "Epoch 4 | Step 1354 | loss: 0.4854698047555726 | accuracy: 0.7647629310344826 \n",
      "Epoch 4 | Step 1355 | loss: 0.48599342838542103 | accuracy: 0.7642337328767121 \n",
      "Epoch 4 | Step 1356 | loss: 0.48609233368821697 | accuracy: 0.7641369047619045 \n",
      "Epoch 4 | Step 1357 | loss: 0.4858800895713471 | accuracy: 0.7644636824324322 \n",
      "Epoch 4 | Step 1358 | loss: 0.4856823156744042 | accuracy: 0.7647860738255031 \n",
      "Epoch 4 | Step 1359 | loss: 0.4852875616153081 | accuracy: 0.7648958333333331 \n",
      "Epoch 4 | Step 1360 | loss: 0.48514810401872294 | accuracy: 0.7650041390728475 \n",
      "Epoch 4 | Step 1361 | loss: 0.48588342043130023 | accuracy: 0.7649054276315788 \n",
      "Epoch 4 | Step 1362 | loss: 0.4863099995391821 | accuracy: 0.7648080065359475 \n",
      "Epoch 4 | Step 1363 | loss: 0.48599176515232434 | accuracy: 0.7650162337662336 \n",
      "Epoch 4 | Step 1364 | loss: 0.4851715164799844 | accuracy: 0.765524193548387 \n",
      "Epoch 4 | Step 1365 | loss: 0.4847962915515288 | accuracy: 0.7659254807692307 \n",
      "Epoch 4 | Step 1366 | loss: 0.48470886744511354 | accuracy: 0.7661226114649682 \n",
      "Epoch 4 | Step 1367 | loss: 0.48458050191402435 | accuracy: 0.7665150316455697 \n",
      "Epoch 4 | Step 1368 | loss: 0.48432840378779285 | accuracy: 0.7666077044025158 \n",
      "Epoch 4 | Step 1369 | loss: 0.48421168588101865 | accuracy: 0.76630859375 \n",
      "Epoch 4 | Step 1370 | loss: 0.48387976777479513 | accuracy: 0.7667895962732919 \n",
      "Epoch 4 | Step 1371 | loss: 0.4838503786811122 | accuracy: 0.7667824074074074 \n",
      "Epoch 4 | Step 1372 | loss: 0.48348371693693054 | accuracy: 0.7666794478527608 \n",
      "Epoch 4 | Step 1373 | loss: 0.48343166563569046 | accuracy: 0.766673018292683 \n",
      "Epoch 4 | Step 1374 | loss: 0.4834637775565639 | accuracy: 0.7668560606060607 \n",
      "Epoch 4 | Step 1375 | loss: 0.4843394433159426 | accuracy: 0.7662838855421688 \n",
      "Epoch 4 | Step 1376 | loss: 0.48405513381529713 | accuracy: 0.766747754491018 \n",
      "Epoch 4 | Step 1377 | loss: 0.48404004087760333 | accuracy: 0.7667410714285714 \n",
      "Epoch 4 | Step 1378 | loss: 0.4847096143036904 | accuracy: 0.7663646449704142 \n",
      "Epoch 4 | Step 1379 | loss: 0.4845100306412753 | accuracy: 0.7666360294117647 \n",
      "Epoch 4 | Step 1380 | loss: 0.4847200465829749 | accuracy: 0.7665387426900585 \n",
      "Epoch 4 | Step 1381 | loss: 0.4850079727380775 | accuracy: 0.7662609011627907 \n",
      "Epoch 4 | Step 1382 | loss: 0.4841293105155746 | accuracy: 0.7670700867052023 \n",
      "Epoch 4 | Step 1383 | loss: 0.4843979250083024 | accuracy: 0.7669719827586207 \n",
      "Epoch 4 | Step 1384 | loss: 0.48409939987318856 | accuracy: 0.7675 \n",
      "Epoch 4 | Step 1385 | loss: 0.4843251209028743 | accuracy: 0.7674893465909091 \n",
      "Epoch 4 | Step 1386 | loss: 0.4847716687426055 | accuracy: 0.7673022598870056 \n",
      "Epoch 4 | Step 1387 | loss: 0.4851253553387824 | accuracy: 0.7667661516853933 \n",
      "Epoch 4 | Step 1388 | loss: 0.4851091878707183 | accuracy: 0.7672835195530726 \n",
      "Epoch 4 | Step 1389 | loss: 0.4853274264269405 | accuracy: 0.7672743055555555 \n",
      "Epoch 4 | Step 1390 | loss: 0.48486635121851335 | accuracy: 0.767610497237569 \n",
      "Epoch 4 | Step 1391 | loss: 0.4842644915148452 | accuracy: 0.7681146978021978 \n",
      "Epoch 4 | Step 1392 | loss: 0.48408412526214056 | accuracy: 0.7682718579234973 \n",
      "Epoch 4 | Step 1393 | loss: 0.484449647852908 | accuracy: 0.7680876358695652 \n",
      "Epoch 4 | Step 1394 | loss: 0.4844126010263288 | accuracy: 0.7681587837837838 \n",
      "Epoch 4 | Step 1395 | loss: 0.484036396107366 | accuracy: 0.7683971774193549 \n",
      "Epoch 4 | Step 1396 | loss: 0.4845801252413561 | accuracy: 0.768048128342246 \n",
      "Epoch 4 | Step 1397 | loss: 0.4844328813413356 | accuracy: 0.7682014627659575 \n",
      "Epoch 4 | Step 1398 | loss: 0.4840734112199652 | accuracy: 0.7685185185185185 \n",
      "Epoch 4 | Step 1399 | loss: 0.4836780932388808 | accuracy: 0.76875 \n",
      "Epoch 4 | Step 1400 | loss: 0.4837300910063439 | accuracy: 0.7688972513089005 \n",
      "Epoch 4 | Step 1401 | loss: 0.4836769049676756 | accuracy: 0.768798828125 \n",
      "Epoch 4 | Step 1402 | loss: 0.48441251185891543 | accuracy: 0.7684585492227979 \n",
      "Epoch 4 | Step 1403 | loss: 0.4840605269695066 | accuracy: 0.7687661082474226 \n",
      "Epoch 4 | Step 1404 | loss: 0.48470818033585183 | accuracy: 0.7682692307692308 \n",
      "Epoch 4 | Step 1405 | loss: 0.4844103301970326 | accuracy: 0.7684948979591837 \n",
      "Epoch 4 | Step 1406 | loss: 0.4839892856360692 | accuracy: 0.7685596446700508 \n",
      "Epoch 4 | Step 1407 | loss: 0.4841140451455357 | accuracy: 0.7683869949494949 \n",
      "Epoch 4 | Step 1408 | loss: 0.4847300043657197 | accuracy: 0.7680590452261307 \n",
      "Epoch 4 | Step 1409 | loss: 0.48441050469875335 | accuracy: 0.768046875 \n",
      "Epoch 4 | Step 1410 | loss: 0.4840699692270649 | accuracy: 0.7682680348258707 \n",
      "Epoch 4 | Step 1411 | loss: 0.4842126714711142 | accuracy: 0.768332301980198 \n",
      "Epoch 4 | Step 1412 | loss: 0.4836551532369529 | accuracy: 0.7688577586206896 \n",
      "Epoch 4 | Step 1413 | loss: 0.48373691708433864 | accuracy: 0.7686887254901961 \n",
      "Epoch 4 | Step 1414 | loss: 0.4839383331740775 | accuracy: 0.7684451219512195 \n",
      "Epoch 4 | Step 1415 | loss: 0.4836374454706618 | accuracy: 0.7686589805825242 \n",
      "Epoch 4 | Step 1416 | loss: 0.48359463425074223 | accuracy: 0.7685688405797102 \n",
      "Epoch 4 | Step 1417 | loss: 0.4830568226484152 | accuracy: 0.7689302884615384 \n",
      "Epoch 4 | Step 1418 | loss: 0.4833586318641188 | accuracy: 0.7686901913875598 \n",
      "Epoch 4 | Step 1419 | loss: 0.4830695349545706 | accuracy: 0.7689732142857143 \n",
      "Epoch 4 | Step 1420 | loss: 0.48310062543475796 | accuracy: 0.7691795023696683 \n",
      "Epoch 4 | Step 1421 | loss: 0.4831213914560822 | accuracy: 0.7693838443396226 \n",
      "Epoch 4 | Step 1422 | loss: 0.4829623175898628 | accuracy: 0.7694395539906104 \n",
      "Epoch 4 | Step 1423 | loss: 0.48271500465468825 | accuracy: 0.7697867990654206 \n",
      "Epoch 4 | Step 1424 | loss: 0.48242357206899067 | accuracy: 0.7695494186046512 \n",
      "Epoch 4 | Step 1425 | loss: 0.48241554849125723 | accuracy: 0.7694589120370371 \n",
      "Epoch 4 | Step 1426 | loss: 0.4832618139031845 | accuracy: 0.768793202764977 \n",
      "Epoch 4 | Step 1427 | loss: 0.4831162189398337 | accuracy: 0.7690653669724771 \n",
      "Epoch 4 | Step 1428 | loss: 0.4829166343767349 | accuracy: 0.7690496575342466 \n",
      "Epoch 4 | Step 1429 | loss: 0.48286222463304346 | accuracy: 0.7690340909090909 \n",
      "Epoch 4 | Step 1430 | loss: 0.4823605371007013 | accuracy: 0.7693014705882353 \n",
      "Epoch 4 | Step 1431 | loss: 0.48205441008279987 | accuracy: 0.7697775900900901 \n",
      "Epoch 4 | Step 1432 | loss: 0.4821071811855641 | accuracy: 0.7697589686098655 \n",
      "Epoch 4 | Step 1433 | loss: 0.4820701695446457 | accuracy: 0.7698102678571429 \n",
      "Epoch 4 | Step 1434 | loss: 0.4827115101284451 | accuracy: 0.7693055555555556 \n",
      "Epoch 4 | Step 1435 | loss: 0.48278130168935895 | accuracy: 0.7694966814159292 \n",
      "Epoch 4 | Step 1436 | loss: 0.48275733978737817 | accuracy: 0.7694107929515418 \n",
      "Epoch 4 | Step 1437 | loss: 0.48240998831757326 | accuracy: 0.7696683114035088 \n",
      "Epoch 4 | Step 1438 | loss: 0.48201556289039843 | accuracy: 0.7700600436681223 \n",
      "Epoch 4 | Step 1439 | loss: 0.4814204825007397 | accuracy: 0.7703125 \n",
      "Epoch 4 | Step 1440 | loss: 0.4819650856447426 | accuracy: 0.7699540043290043 \n",
      "Epoch 4 | Step 1441 | loss: 0.4813805738913602 | accuracy: 0.7703394396551724 \n",
      "Epoch 4 | Step 1442 | loss: 0.48169558421736625 | accuracy: 0.7701180257510729 \n",
      "Epoch 4 | Step 1443 | loss: 0.4818938537540599 | accuracy: 0.7697649572649573 \n",
      "Epoch 4 | Step 1444 | loss: 0.48163062093105724 | accuracy: 0.7698803191489362 \n",
      "Epoch 4 | Step 1445 | loss: 0.4813307879839913 | accuracy: 0.7699284957627118 \n",
      "Epoch 4 | Step 1446 | loss: 0.4815281184413765 | accuracy: 0.7697784810126582 \n",
      "Epoch 4 | Step 1447 | loss: 0.48220859079801737 | accuracy: 0.7696297268907563 \n",
      "Epoch 4 | Step 1448 | loss: 0.48203068086292955 | accuracy: 0.7696783472803347 \n",
      "Epoch 4 | Step 1449 | loss: 0.48188018600145976 | accuracy: 0.76953125 \n",
      "Epoch 4 | Step 1450 | loss: 0.48207029811574215 | accuracy: 0.7693205394190872 \n",
      "Epoch 4 | Step 1451 | loss: 0.4823587135342527 | accuracy: 0.7691115702479339 \n",
      "Epoch 4 | Step 1452 | loss: 0.4822423388192683 | accuracy: 0.7693544238683128 \n",
      "Epoch 4 | Step 1453 | loss: 0.48176578835385747 | accuracy: 0.7697873975409836 \n",
      "Epoch 4 | Step 1454 | loss: 0.48188814824941206 | accuracy: 0.7697066326530613 \n",
      "Epoch 4 | Step 1455 | loss: 0.4816427156934893 | accuracy: 0.7696900406504065 \n",
      "Epoch 4 | Step 1456 | loss: 0.48144089331028433 | accuracy: 0.7696735829959515 \n",
      "Epoch 4 | Step 1457 | loss: 0.48145124664710415 | accuracy: 0.7697832661290323 \n",
      "Epoch 4 | Step 1458 | loss: 0.4819051433040435 | accuracy: 0.7694528112449799 \n",
      "Epoch 4 | Step 1459 | loss: 0.48149497985839845 | accuracy: 0.76975 \n",
      "Epoch 4 | Step 1460 | loss: 0.4817738737243105 | accuracy: 0.7694845617529881 \n",
      "Epoch 4 | Step 1461 | loss: 0.48194362885422176 | accuracy: 0.7693452380952381 \n",
      "Epoch 4 | Step 1462 | loss: 0.4817611579838478 | accuracy: 0.7696393280632411 \n",
      "Epoch 4 | Step 1463 | loss: 0.48163384515938795 | accuracy: 0.7695004921259843 \n",
      "Epoch 4 | Step 1464 | loss: 0.4814594412551207 | accuracy: 0.7696691176470588 \n",
      "Epoch 4 | Step 1465 | loss: 0.4813045687042177 | accuracy: 0.7696533203125 \n",
      "Epoch 4 | Step 1466 | loss: 0.48153184197756105 | accuracy: 0.7693944552529183 \n",
      "Epoch 4 | Step 1467 | loss: 0.4815121561057808 | accuracy: 0.7695009689922481 \n",
      "Epoch 4 | Step 1468 | loss: 0.481623235816661 | accuracy: 0.7694256756756757 \n",
      "Epoch 4 | Step 1469 | loss: 0.4816349241596002 | accuracy: 0.7693509615384615 \n",
      "Epoch 4 | Step 1470 | loss: 0.4814081308485448 | accuracy: 0.7695761494252874 \n",
      "Epoch 4 | Step 1471 | loss: 0.48187498736927525 | accuracy: 0.7692032442748091 \n",
      "Epoch 4 | Step 1472 | loss: 0.4815925707608575 | accuracy: 0.7696055133079848 \n",
      "Epoch 4 | Step 1473 | loss: 0.48117897298299905 | accuracy: 0.7699455492424242 \n",
      "Epoch 4 | Step 1474 | loss: 0.4809775340107252 | accuracy: 0.7701061320754717 \n",
      "Epoch 4 | Step 1475 | loss: 0.4810048425780203 | accuracy: 0.770265507518797 \n",
      "Epoch 4 | Step 1476 | loss: 0.4809346052814512 | accuracy: 0.7703066479400749 \n",
      "Epoch 4 | Step 1477 | loss: 0.4809409692438681 | accuracy: 0.7702308768656716 \n",
      "Epoch 4 | Step 1478 | loss: 0.4809084287584936 | accuracy: 0.7703299256505576 \n",
      "Epoch 4 | Step 1479 | loss: 0.4807542286537312 | accuracy: 0.7704861111111111 \n",
      "Epoch 4 | Step 1480 | loss: 0.4806180013501776 | accuracy: 0.7703528597785978 \n",
      "Epoch 4 | Step 1481 | loss: 0.4803919943378252 | accuracy: 0.7707375919117647 \n",
      "Epoch 4 | Step 1482 | loss: 0.48050347920302505 | accuracy: 0.7708905677655677 \n",
      "Epoch 4 | Step 1483 | loss: 0.4804814391545136 | accuracy: 0.7709283759124088 \n",
      "Epoch 4 | Step 1484 | loss: 0.4803295194018971 | accuracy: 0.7711363636363637 \n",
      "Epoch 4 | Step 1485 | loss: 0.4807798801988795 | accuracy: 0.7710031702898552 \n",
      "Epoch 4 | Step 1486 | loss: 0.48071704304605617 | accuracy: 0.7712093862815885 \n",
      "Epoch 4 | Step 1487 | loss: 0.4806139486299144 | accuracy: 0.7713017086330937 \n",
      "Epoch 4 | Step 1488 | loss: 0.48024457105598994 | accuracy: 0.7715053763440861 \n",
      "Epoch 4 | Step 1489 | loss: 0.48011267706751826 | accuracy: 0.7714843750000001 \n",
      "Epoch 4 | Step 1490 | loss: 0.48000824589322044 | accuracy: 0.7715747330960855 \n",
      "Epoch 4 | Step 1491 | loss: 0.4797382202554256 | accuracy: 0.7716644503546101 \n",
      "Epoch 4 | Step 1492 | loss: 0.4798482216289102 | accuracy: 0.7713670494699648 \n",
      "Epoch 4 | Step 1493 | loss: 0.4794783525063958 | accuracy: 0.7716219190140847 \n",
      "Epoch 4 | Step 1494 | loss: 0.47937659568953933 | accuracy: 0.7717105263157896 \n",
      "Epoch 4 | Step 1495 | loss: 0.47874382586329134 | accuracy: 0.7722355769230771 \n",
      "Epoch 4 | Step 1496 | loss: 0.47878564670941554 | accuracy: 0.7721036585365856 \n",
      "Epoch 4 | Step 1497 | loss: 0.47848423197865486 | accuracy: 0.7721896701388891 \n",
      "Epoch 4 | Step 1498 | loss: 0.47897552103319796 | accuracy: 0.771896626297578 \n",
      "Epoch 4 | Step 1499 | loss: 0.47863409724728817 | accuracy: 0.7721982758620691 \n",
      "Epoch 4 | Step 1500 | loss: 0.47915655784180894 | accuracy: 0.7717998281786943 \n",
      "Epoch 4 | Step 1501 | loss: 0.4790045226069346 | accuracy: 0.771832191780822 \n",
      "Epoch 4 | Step 1502 | loss: 0.478888120565805 | accuracy: 0.771917662116041 \n",
      "Epoch 4 | Step 1503 | loss: 0.4789804784821815 | accuracy: 0.7718962585034014 \n",
      "Epoch 4 | Step 1504 | loss: 0.47895081912056875 | accuracy: 0.7717161016949152 \n",
      "Epoch 4 | Step 1505 | loss: 0.47881942927031906 | accuracy: 0.7718538851351351 \n",
      "Epoch 4 | Step 1506 | loss: 0.4787316212951134 | accuracy: 0.7718855218855218 \n",
      "Epoch 4 | Step 1507 | loss: 0.4784759104051846 | accuracy: 0.7719169463087249 \n",
      "Epoch 4 | Step 1508 | loss: 0.47848078738088196 | accuracy: 0.7718436454849499 \n",
      "Epoch 4 | Step 1509 | loss: 0.4782850790023804 | accuracy: 0.7719270833333334 \n",
      "Epoch 4 | Step 1510 | loss: 0.47849765588278786 | accuracy: 0.7716465946843853 \n",
      "Epoch 4 | Step 1511 | loss: 0.478432798227727 | accuracy: 0.7717301324503312 \n",
      "Epoch 4 | Step 1512 | loss: 0.47825316047117655 | accuracy: 0.7718646864686469 \n",
      "Epoch 4 | Step 1513 | loss: 0.4784148771707949 | accuracy: 0.7714843750000001 \n",
      "Epoch 4 | Step 1514 | loss: 0.47820529048560095 | accuracy: 0.771516393442623 \n",
      "Epoch 4 | Step 1515 | loss: 0.47795453219631917 | accuracy: 0.7716503267973858 \n",
      "Epoch 4 | Step 1516 | loss: 0.4781596532473735 | accuracy: 0.7715289087947884 \n",
      "Epoch 4 | Step 1517 | loss: 0.4779143509539691 | accuracy: 0.7717126623376626 \n",
      "Epoch 4 | Step 1518 | loss: 0.4775899960192276 | accuracy: 0.7720469255663432 \n",
      "Epoch 4 | Step 1519 | loss: 0.4774392928807966 | accuracy: 0.772076612903226 \n",
      "Epoch 4 | Step 1520 | loss: 0.4772866934633715 | accuracy: 0.7721061093247591 \n",
      "Epoch 4 | Step 1521 | loss: 0.47720712194075954 | accuracy: 0.7720853365384618 \n",
      "Epoch 4 | Step 1522 | loss: 0.47694765493130914 | accuracy: 0.7721146166134188 \n",
      "Epoch 4 | Step 1523 | loss: 0.4770705576535243 | accuracy: 0.7720441878980895 \n",
      "Epoch 4 | Step 1524 | loss: 0.477248574060107 | accuracy: 0.7721726190476194 \n",
      "Epoch 4 | Step 1525 | loss: 0.4772789188766781 | accuracy: 0.7721518987341774 \n",
      "Epoch 4 | Step 1526 | loss: 0.47700663122468945 | accuracy: 0.7724763406940066 \n",
      "Epoch 4 | Step 1527 | loss: 0.47705445274616937 | accuracy: 0.7724547955974845 \n",
      "Epoch 4 | Step 1528 | loss: 0.47691419636567933 | accuracy: 0.7726293103448278 \n",
      "Epoch 4 | Step 1529 | loss: 0.47671391554176806 | accuracy: 0.7727539062500003 \n",
      "Epoch 4 | Step 1530 | loss: 0.47672059519268645 | accuracy: 0.7729264018691592 \n",
      "Epoch 4 | Step 1531 | loss: 0.4769662649179838 | accuracy: 0.7727581521739133 \n",
      "Epoch 4 | Step 1532 | loss: 0.4767280869624194 | accuracy: 0.7728811919504647 \n",
      "Epoch 4 | Step 1533 | loss: 0.4765996931143749 | accuracy: 0.7729070216049385 \n",
      "Epoch 4 | Step 1534 | loss: 0.4765308580031762 | accuracy: 0.7728846153846156 \n",
      "Epoch 4 | Step 1535 | loss: 0.4762800113737949 | accuracy: 0.7731978527607365 \n",
      "Epoch 4 | Step 1536 | loss: 0.4763127887103171 | accuracy: 0.773318042813456 \n",
      "Epoch 4 | Step 1537 | loss: 0.4764098882130006 | accuracy: 0.7732469512195125 \n",
      "Epoch 4 | Step 1538 | loss: 0.4768416146920445 | accuracy: 0.7729388297872343 \n",
      "Epoch 4 | Step 1539 | loss: 0.47690246872829667 | accuracy: 0.7729640151515154 \n",
      "Epoch 4 | Step 1540 | loss: 0.4768618257024137 | accuracy: 0.7728474320241694 \n",
      "Epoch 4 | Step 1541 | loss: 0.4766782020409423 | accuracy: 0.7729198042168677 \n",
      "Epoch 4 | Step 1542 | loss: 0.47663178189738736 | accuracy: 0.7728509759759762 \n",
      "Epoch 4 | Step 1543 | loss: 0.47663703507292055 | accuracy: 0.7728293413173655 \n",
      "Epoch 4 | Step 1544 | loss: 0.4764879719534917 | accuracy: 0.7729944029850748 \n",
      "Epoch 4 | Step 1545 | loss: 0.4762905758938619 | accuracy: 0.7731119791666669 \n",
      "Epoch 4 | Step 1546 | loss: 0.47642302610400167 | accuracy: 0.7730897626112762 \n",
      "Epoch 4 | Step 1547 | loss: 0.4762945897304095 | accuracy: 0.7732525887573967 \n",
      "Epoch 4 | Step 1548 | loss: 0.47617846393303886 | accuracy: 0.7733683628318586 \n",
      "Epoch 4 | Step 1549 | loss: 0.4758364100666607 | accuracy: 0.7734375000000002 \n",
      "Epoch 4 | Step 1550 | loss: 0.47543566999547293 | accuracy: 0.7736436950146629 \n",
      "Epoch 4 | Step 1551 | loss: 0.4753931362552252 | accuracy: 0.7736659356725147 \n",
      "Epoch 4 | Step 1552 | loss: 0.4753673133106343 | accuracy: 0.7736424927113704 \n",
      "Epoch 4 | Step 1553 | loss: 0.47506476055051006 | accuracy: 0.7738462936046513 \n",
      "Epoch 4 | Step 1554 | loss: 0.47520777384440105 | accuracy: 0.7738224637681161 \n",
      "Epoch 4 | Step 1555 | loss: 0.47510229860771597 | accuracy: 0.7737536127167631 \n",
      "Epoch 4 | Step 1556 | loss: 0.47469272161766846 | accuracy: 0.7740904178674354 \n",
      "Epoch 4 | Step 1557 | loss: 0.4749270152600332 | accuracy: 0.7739762931034484 \n",
      "Epoch 4 | Step 1558 | loss: 0.47480042411126516 | accuracy: 0.7741314469914041 \n",
      "Epoch 4 | Step 1559 | loss: 0.47458218625613624 | accuracy: 0.7742857142857145 \n",
      "Epoch 4 | Step 1560 | loss: 0.47433553360126635 | accuracy: 0.7744391025641028 \n",
      "Epoch 4 | Step 1561 | loss: 0.4742492759092288 | accuracy: 0.774591619318182 \n",
      "Epoch 4 | Step 1562 | loss: 0.47419776415014403 | accuracy: 0.7745662181303118 \n",
      "Epoch 4 | Step 1563 | loss: 0.4742004103579764 | accuracy: 0.7745409604519775 \n",
      "Epoch 4 | Step 1564 | loss: 0.47405145067564197 | accuracy: 0.7744718309859157 \n",
      "Epoch 4 | Step 1565 | loss: 0.4739005348823044 | accuracy: 0.7745347612359552 \n",
      "Epoch 4 | Step 1566 | loss: 0.4737154880658585 | accuracy: 0.7745973389355744 \n",
      "Epoch 4 | Step 1567 | loss: 0.4738822365439804 | accuracy: 0.7745286312849163 \n",
      "Epoch 4 | Step 1568 | loss: 0.4737504509000061 | accuracy: 0.7746779247910865 \n",
      "Epoch 4 | Step 1569 | loss: 0.4737252429955535 | accuracy: 0.7747395833333335 \n",
      "Epoch 4 | Step 1570 | loss: 0.4739649468346646 | accuracy: 0.7744979224376732 \n",
      "Epoch 4 | Step 1571 | loss: 0.473943912686564 | accuracy: 0.7744734116022101 \n",
      "Epoch 4 | Step 1572 | loss: 0.47404161711369663 | accuracy: 0.7743629476584024 \n",
      "Epoch 4 | Step 1573 | loss: 0.473879510311635 | accuracy: 0.7744247939560441 \n",
      "Epoch 4 | Step 1574 | loss: 0.47378618292612573 | accuracy: 0.7745719178082193 \n",
      "Epoch 4 | Step 1575 | loss: 0.47360081677554083 | accuracy: 0.7746755464480876 \n",
      "Epoch 4 | Step 1576 | loss: 0.4737235933785867 | accuracy: 0.774565735694823 \n",
      "Epoch 4 | Step 1577 | loss: 0.47355053703422134 | accuracy: 0.7746688179347828 \n",
      "Epoch 4 | Step 1578 | loss: 0.47356603615652254 | accuracy: 0.7746866531165313 \n",
      "Epoch 4 | Step 1579 | loss: 0.4736802106773531 | accuracy: 0.7744510135135136 \n",
      "Epoch 4 | Step 1580 | loss: 0.4737430365901752 | accuracy: 0.7743429919137468 \n",
      "Epoch 4 | Step 1581 | loss: 0.47398887798991257 | accuracy: 0.7743195564516131 \n",
      "Epoch 4 | Step 1582 | loss: 0.47396062973676995 | accuracy: 0.7742962466487937 \n",
      "Epoch 4 | Step 1583 | loss: 0.4737156275759406 | accuracy: 0.7743983957219253 \n",
      "Epoch 4 | Step 1584 | loss: 0.47348325022061666 | accuracy: 0.7745000000000002 \n",
      "Epoch 4 | Step 1585 | loss: 0.4734662359857813 | accuracy: 0.7743517287234044 \n",
      "Epoch 4 | Step 1586 | loss: 0.47336310828079914 | accuracy: 0.774370026525199 \n",
      "Epoch 4 | Step 1587 | loss: 0.4733683503967114 | accuracy: 0.7742642195767198 \n",
      "Epoch 4 | Step 1588 | loss: 0.4730580144004017 | accuracy: 0.7744887862796835 \n",
      "Epoch 4 | Step 1589 | loss: 0.4729844524672157 | accuracy: 0.7744243421052633 \n",
      "Epoch 4 | Step 1590 | loss: 0.4729037699424063 | accuracy: 0.7745242782152233 \n",
      "Epoch 4 | Step 1591 | loss: 0.4726228766260347 | accuracy: 0.7746645942408379 \n",
      "Epoch 4 | Step 1592 | loss: 0.47253697620359475 | accuracy: 0.7746001958224544 \n",
      "Epoch 4 | Step 1593 | loss: 0.4727153789717704 | accuracy: 0.7744547526041669 \n",
      "Epoch 4 | Step 1594 | loss: 0.47288195072830497 | accuracy: 0.7744318181818183 \n",
      "Epoch 4 | Step 1595 | loss: 0.4730836618595173 | accuracy: 0.7742470854922281 \n",
      "Epoch 4 | Step 1596 | loss: 0.4730561991686661 | accuracy: 0.774467054263566 \n",
      "Epoch 4 | Step 1597 | loss: 0.47292239318803414 | accuracy: 0.7745248067010311 \n",
      "Epoch 4 | Step 1598 | loss: 0.47309390315666294 | accuracy: 0.7744215938303344 \n",
      "Epoch 4 | Step 1599 | loss: 0.47290483583242465 | accuracy: 0.774559294871795 \n",
      "Epoch 4 | Step 1600 | loss: 0.47306841573751796 | accuracy: 0.7745364450127878 \n",
      "Epoch 4 | Step 1601 | loss: 0.4729783411841003 | accuracy: 0.7746332908163267 \n",
      "Epoch 4 | Step 1602 | loss: 0.4727578744785173 | accuracy: 0.7747694020356235 \n",
      "Epoch 4 | Step 1603 | loss: 0.47284858715413186 | accuracy: 0.7747461928934012 \n",
      "Epoch 4 | Step 1604 | loss: 0.4728861165952079 | accuracy: 0.774604430379747 \n",
      "Epoch 4 | Step 1605 | loss: 0.4727282075568883 | accuracy: 0.7746212121212123 \n",
      "Epoch 4 | Step 1606 | loss: 0.47292470046194734 | accuracy: 0.7744804785894208 \n",
      "Epoch 4 | Step 1607 | loss: 0.47297841580069844 | accuracy: 0.7743011934673368 \n",
      "Epoch 4 | Step 1608 | loss: 0.47279688842912065 | accuracy: 0.7744752506265665 \n",
      "Epoch 4 | Step 1609 | loss: 0.47298969715833666 | accuracy: 0.7742578125000001 \n",
      "Epoch 4 | Step 1610 | loss: 0.4730356077006333 | accuracy: 0.7743142144638405 \n",
      "Epoch 4 | Step 1611 | loss: 0.47333700102360093 | accuracy: 0.7740982587064678 \n",
      "Epoch 4 | Step 1612 | loss: 0.473196308015298 | accuracy: 0.7741454180061966 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5529975891113281 | accuracy: 0.671875 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5593712031841278 | accuracy: 0.6796875 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5260062515735626 | accuracy: 0.703125 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5292720720171928 | accuracy: 0.71875 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5264492213726044 | accuracy: 0.721875 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5238449027140936 | accuracy: 0.7213541666666666 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5188191405364445 | accuracy: 0.7321428571428571 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5138220451772213 | accuracy: 0.73046875 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.509225414858924 | accuracy: 0.7309027777777778 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5069803416728973 | accuracy: 0.7328125 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5052814944223925 | accuracy: 0.7357954545454546 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.4991108179092407 | accuracy: 0.7408854166666666 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5001592544408945 | accuracy: 0.7367788461538461 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.4970381643090929 | accuracy: 0.7399553571428571 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.490300448735555 | accuracy: 0.7447916666666666 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.48844030871987343 | accuracy: 0.74609375 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.49618297464707317 | accuracy: 0.7426470588235294 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.49285977085431415 | accuracy: 0.7421875 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.49590091015163223 | accuracy: 0.7442434210526315 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.49445624351501466 | accuracy: 0.746875 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.49493188517434256 | accuracy: 0.7492559523809523 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.4902134713801471 | accuracy: 0.7535511363636364 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.4939021999421327 | accuracy: 0.751358695652174 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.4973151149849097 | accuracy: 0.7493489583333334 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.49784225821495054 | accuracy: 0.750625 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.4934864491224289 | accuracy: 0.7530048076923077 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.4909731834023087 | accuracy: 0.7534722222222222 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.4881910468850817 | accuracy: 0.7550223214285714 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.4896160261384372 | accuracy: 0.7537715517241379 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.48977897663911185 | accuracy: 0.7552083333333334 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.4875219560438587 | accuracy: 0.7560483870967742 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.4830898689106107 | accuracy: 0.76025390625 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.48183033231532935 | accuracy: 0.7604166666666666 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.48761175046948824 | accuracy: 0.7578125 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.4862822541168758 | accuracy: 0.7580357142857143 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.4841787798537148 | accuracy: 0.7599826388888888 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.4855050122415697 | accuracy: 0.7605574324324325 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.48585157096385956 | accuracy: 0.7602796052631579 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.48465256507580096 | accuracy: 0.7604166666666666 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.48567496687173844 | accuracy: 0.76015625 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.48634619683754154 | accuracy: 0.7595274390243902 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.4840175736518133 | accuracy: 0.7604166666666666 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.4845069910204688 | accuracy: 0.7594476744186046 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.4847177463498982 | accuracy: 0.7588778409090909 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.4868271397219764 | accuracy: 0.7574728263749017 \n",
      "Epoch 5 | Step 1613 | loss: 0.392241895198822 | accuracy: 0.84375 \n",
      "Epoch 5 | Step 1614 | loss: 0.4579314887523651 | accuracy: 0.78125 \n",
      "Epoch 5 | Step 1615 | loss: 0.41371549169222516 | accuracy: 0.8125 \n",
      "Epoch 5 | Step 1616 | loss: 0.41015123575925827 | accuracy: 0.8125 \n",
      "Epoch 5 | Step 1617 | loss: 0.4170728802680969 | accuracy: 0.80625 \n",
      "Epoch 5 | Step 1618 | loss: 0.4226496418317159 | accuracy: 0.8072916666666666 \n",
      "Epoch 5 | Step 1619 | loss: 0.4294461693082537 | accuracy: 0.8058035714285714 \n",
      "Epoch 5 | Step 1620 | loss: 0.43974244594573975 | accuracy: 0.8046875 \n",
      "Epoch 5 | Step 1621 | loss: 0.4386500616868337 | accuracy: 0.7986111111111112 \n",
      "Epoch 5 | Step 1622 | loss: 0.45114990174770353 | accuracy: 0.7890625 \n",
      "Epoch 5 | Step 1623 | loss: 0.4485085823319175 | accuracy: 0.7869318181818182 \n",
      "Epoch 5 | Step 1624 | loss: 0.45849933723608655 | accuracy: 0.77734375 \n",
      "Epoch 5 | Step 1625 | loss: 0.45712031767918515 | accuracy: 0.7800480769230769 \n",
      "Epoch 5 | Step 1626 | loss: 0.46238724674497333 | accuracy: 0.7767857142857143 \n",
      "Epoch 5 | Step 1627 | loss: 0.4577091157436371 | accuracy: 0.78125 \n",
      "Epoch 5 | Step 1628 | loss: 0.4486794900149107 | accuracy: 0.7890625 \n",
      "Epoch 5 | Step 1629 | loss: 0.4452647847287795 | accuracy: 0.7913602941176471 \n",
      "Epoch 5 | Step 1630 | loss: 0.4502272440327538 | accuracy: 0.7873263888888888 \n",
      "Epoch 5 | Step 1631 | loss: 0.4476835210072367 | accuracy: 0.7886513157894737 \n",
      "Epoch 5 | Step 1632 | loss: 0.4476088896393776 | accuracy: 0.790625 \n",
      "Epoch 5 | Step 1633 | loss: 0.44919916135924204 | accuracy: 0.7872023809523809 \n",
      "Epoch 5 | Step 1634 | loss: 0.44783673774112354 | accuracy: 0.7897727272727273 \n",
      "Epoch 5 | Step 1635 | loss: 0.4441039238287055 | accuracy: 0.7907608695652174 \n",
      "Epoch 5 | Step 1636 | loss: 0.44356869782010716 | accuracy: 0.7903645833333334 \n",
      "Epoch 5 | Step 1637 | loss: 0.4395364928245544 | accuracy: 0.7925 \n",
      "Epoch 5 | Step 1638 | loss: 0.4405365288257599 | accuracy: 0.7908653846153846 \n",
      "Epoch 5 | Step 1639 | loss: 0.4401658320868457 | accuracy: 0.7910879629629629 \n",
      "Epoch 5 | Step 1640 | loss: 0.4349084198474884 | accuracy: 0.7957589285714286 \n",
      "Epoch 5 | Step 1641 | loss: 0.43418291211128235 | accuracy: 0.7952586206896551 \n",
      "Epoch 5 | Step 1642 | loss: 0.43570088942845664 | accuracy: 0.7953125 \n",
      "Epoch 5 | Step 1643 | loss: 0.43406707913644854 | accuracy: 0.795866935483871 \n",
      "Epoch 5 | Step 1644 | loss: 0.43633562605828047 | accuracy: 0.7939453125 \n",
      "Epoch 5 | Step 1645 | loss: 0.43922371846256836 | accuracy: 0.7935606060606061 \n",
      "Epoch 5 | Step 1646 | loss: 0.4401610966990976 | accuracy: 0.7927389705882353 \n",
      "Epoch 5 | Step 1647 | loss: 0.4413471494402204 | accuracy: 0.790625 \n",
      "Epoch 5 | Step 1648 | loss: 0.4429369891683261 | accuracy: 0.7899305555555556 \n",
      "Epoch 5 | Step 1649 | loss: 0.44065231729198145 | accuracy: 0.7909628378378378 \n",
      "Epoch 5 | Step 1650 | loss: 0.43966133029837356 | accuracy: 0.7915296052631579 \n",
      "Epoch 5 | Step 1651 | loss: 0.4385478626459073 | accuracy: 0.7924679487179487 \n",
      "Epoch 5 | Step 1652 | loss: 0.4371969893574715 | accuracy: 0.794140625 \n",
      "Epoch 5 | Step 1653 | loss: 0.4380987839000981 | accuracy: 0.7949695121951219 \n",
      "Epoch 5 | Step 1654 | loss: 0.43571761179538 | accuracy: 0.796875 \n",
      "Epoch 5 | Step 1655 | loss: 0.4343014872351358 | accuracy: 0.7965116279069767 \n",
      "Epoch 5 | Step 1656 | loss: 0.43354158103466034 | accuracy: 0.7965198863636364 \n",
      "Epoch 5 | Step 1657 | loss: 0.43534309466679894 | accuracy: 0.7951388888888888 \n",
      "Epoch 5 | Step 1658 | loss: 0.4360373039608416 | accuracy: 0.7941576086956522 \n",
      "Epoch 5 | Step 1659 | loss: 0.4354622934726959 | accuracy: 0.7945478723404256 \n",
      "Epoch 5 | Step 1660 | loss: 0.4358055517077446 | accuracy: 0.7942708333333334 \n",
      "Epoch 5 | Step 1661 | loss: 0.43373611508583537 | accuracy: 0.7955994897959183 \n",
      "Epoch 5 | Step 1662 | loss: 0.4339521676301956 | accuracy: 0.795 \n",
      "Epoch 5 | Step 1663 | loss: 0.4350060341404934 | accuracy: 0.7953431372549019 \n",
      "Epoch 5 | Step 1664 | loss: 0.4381021891648953 | accuracy: 0.7944711538461539 \n",
      "Epoch 5 | Step 1665 | loss: 0.4375583535095431 | accuracy: 0.7942216981132075 \n",
      "Epoch 5 | Step 1666 | loss: 0.4362536238299476 | accuracy: 0.7957175925925926 \n",
      "Epoch 5 | Step 1667 | loss: 0.43317144404758107 | accuracy: 0.7982954545454546 \n",
      "Epoch 5 | Step 1668 | loss: 0.43508406462413923 | accuracy: 0.7982700892857143 \n",
      "Epoch 5 | Step 1669 | loss: 0.4352051662771325 | accuracy: 0.7987938596491229 \n",
      "Epoch 5 | Step 1670 | loss: 0.43722649329695207 | accuracy: 0.7982219827586207 \n",
      "Epoch 5 | Step 1671 | loss: 0.43752376659441805 | accuracy: 0.798728813559322 \n",
      "Epoch 5 | Step 1672 | loss: 0.4377019847432772 | accuracy: 0.7986979166666667 \n",
      "Epoch 5 | Step 1673 | loss: 0.438727365654023 | accuracy: 0.7973872950819673 \n",
      "Epoch 5 | Step 1674 | loss: 0.4386390534139449 | accuracy: 0.7971270161290323 \n",
      "Epoch 5 | Step 1675 | loss: 0.4385464092095693 | accuracy: 0.796875 \n",
      "Epoch 5 | Step 1676 | loss: 0.43632160080596805 | accuracy: 0.798095703125 \n",
      "Epoch 5 | Step 1677 | loss: 0.4377572192595555 | accuracy: 0.7973557692307692 \n",
      "Epoch 5 | Step 1678 | loss: 0.4355004474972234 | accuracy: 0.7982954545454546 \n",
      "Epoch 5 | Step 1679 | loss: 0.43527807139638647 | accuracy: 0.7985074626865671 \n",
      "Epoch 5 | Step 1680 | loss: 0.4349641418632339 | accuracy: 0.7994025735294118 \n",
      "Epoch 5 | Step 1681 | loss: 0.43642281060633453 | accuracy: 0.7989130434782609 \n",
      "Epoch 5 | Step 1682 | loss: 0.4385962473494666 | accuracy: 0.7973214285714286 \n",
      "Epoch 5 | Step 1683 | loss: 0.4390330260068598 | accuracy: 0.7973151408450705 \n",
      "Epoch 5 | Step 1684 | loss: 0.4382887991766135 | accuracy: 0.7979600694444445 \n",
      "Epoch 5 | Step 1685 | loss: 0.43819610060077824 | accuracy: 0.798373287671233 \n",
      "Epoch 5 | Step 1686 | loss: 0.4384139071445207 | accuracy: 0.7983530405405407 \n",
      "Epoch 5 | Step 1687 | loss: 0.4393807828426361 | accuracy: 0.7979166666666667 \n",
      "Epoch 5 | Step 1688 | loss: 0.4385048915681086 | accuracy: 0.7987253289473685 \n",
      "Epoch 5 | Step 1689 | loss: 0.43796884239494027 | accuracy: 0.7987012987012988 \n",
      "Epoch 5 | Step 1690 | loss: 0.4380054833033146 | accuracy: 0.7976762820512822 \n",
      "Epoch 5 | Step 1691 | loss: 0.43711718841444086 | accuracy: 0.7976661392405064 \n",
      "Epoch 5 | Step 1692 | loss: 0.43636857233941556 | accuracy: 0.7982421875000001 \n",
      "Epoch 5 | Step 1693 | loss: 0.4379684943475841 | accuracy: 0.7970679012345679 \n",
      "Epoch 5 | Step 1694 | loss: 0.4375250448540943 | accuracy: 0.797827743902439 \n",
      "Epoch 5 | Step 1695 | loss: 0.4375430539429906 | accuracy: 0.797816265060241 \n",
      "Epoch 5 | Step 1696 | loss: 0.4380031643169267 | accuracy: 0.7979910714285714 \n",
      "Epoch 5 | Step 1697 | loss: 0.4385041170260485 | accuracy: 0.7979779411764706 \n",
      "Epoch 5 | Step 1698 | loss: 0.4374640060718669 | accuracy: 0.7986918604651163 \n",
      "Epoch 5 | Step 1699 | loss: 0.4371971768894415 | accuracy: 0.7986709770114943 \n",
      "Epoch 5 | Step 1700 | loss: 0.4377304583110593 | accuracy: 0.7984730113636364 \n",
      "Epoch 5 | Step 1701 | loss: 0.4381091393781512 | accuracy: 0.7975772471910112 \n",
      "Epoch 5 | Step 1702 | loss: 0.4385002705785963 | accuracy: 0.7975694444444444 \n",
      "Epoch 5 | Step 1703 | loss: 0.43818168849735467 | accuracy: 0.7977335164835165 \n",
      "Epoch 5 | Step 1704 | loss: 0.43895897917125537 | accuracy: 0.7972146739130435 \n",
      "Epoch 5 | Step 1705 | loss: 0.4402100514340144 | accuracy: 0.7967069892473119 \n",
      "Epoch 5 | Step 1706 | loss: 0.439333955975289 | accuracy: 0.7967087765957447 \n",
      "Epoch 5 | Step 1707 | loss: 0.4386870152071903 | accuracy: 0.7973684210526316 \n",
      "Epoch 5 | Step 1708 | loss: 0.43721719831228256 | accuracy: 0.7986653645833334 \n",
      "Epoch 5 | Step 1709 | loss: 0.4363090736964314 | accuracy: 0.7994523195876289 \n",
      "Epoch 5 | Step 1710 | loss: 0.43687440911117864 | accuracy: 0.7989477040816326 \n",
      "Epoch 5 | Step 1711 | loss: 0.4362971954273455 | accuracy: 0.7990845959595959 \n",
      "Epoch 5 | Step 1712 | loss: 0.43703527480363846 | accuracy: 0.79859375 \n",
      "Epoch 5 | Step 1713 | loss: 0.4373155127067377 | accuracy: 0.7987314356435643 \n",
      "Epoch 5 | Step 1714 | loss: 0.4375927477490668 | accuracy: 0.7984068627450981 \n",
      "Epoch 5 | Step 1715 | loss: 0.437913138889572 | accuracy: 0.7980885922330098 \n",
      "Epoch 5 | Step 1716 | loss: 0.43769487623985 | accuracy: 0.7985276442307693 \n",
      "Epoch 5 | Step 1717 | loss: 0.4383686497097924 | accuracy: 0.7980654761904762 \n",
      "Epoch 5 | Step 1718 | loss: 0.4379020777513396 | accuracy: 0.7982016509433962 \n",
      "Epoch 5 | Step 1719 | loss: 0.43782435844991807 | accuracy: 0.7983352803738317 \n",
      "Epoch 5 | Step 1720 | loss: 0.43856396277745563 | accuracy: 0.7980324074074074 \n",
      "Epoch 5 | Step 1721 | loss: 0.4373961110180671 | accuracy: 0.7985951834862385 \n",
      "Epoch 5 | Step 1722 | loss: 0.4375141756101088 | accuracy: 0.7985795454545455 \n",
      "Epoch 5 | Step 1723 | loss: 0.4384984207582903 | accuracy: 0.7975788288288288 \n",
      "Epoch 5 | Step 1724 | loss: 0.4393452852964401 | accuracy: 0.7972935267857143 \n",
      "Epoch 5 | Step 1725 | loss: 0.43881670326258226 | accuracy: 0.797566371681416 \n",
      "Epoch 5 | Step 1726 | loss: 0.4388848140574338 | accuracy: 0.7972861842105263 \n",
      "Epoch 5 | Step 1727 | loss: 0.4392622509728307 | accuracy: 0.7972826086956522 \n",
      "Epoch 5 | Step 1728 | loss: 0.4388768683219778 | accuracy: 0.7976831896551724 \n",
      "Epoch 5 | Step 1729 | loss: 0.43846011416524905 | accuracy: 0.7975427350427351 \n",
      "Epoch 5 | Step 1730 | loss: 0.43884790297281945 | accuracy: 0.7975370762711864 \n",
      "Epoch 5 | Step 1731 | loss: 0.4394160569215021 | accuracy: 0.7971376050420168 \n",
      "Epoch 5 | Step 1732 | loss: 0.4391078176597754 | accuracy: 0.7975260416666666 \n",
      "Epoch 5 | Step 1733 | loss: 0.43849449586277167 | accuracy: 0.7977789256198347 \n",
      "Epoch 5 | Step 1734 | loss: 0.4389784756253977 | accuracy: 0.797515368852459 \n",
      "Epoch 5 | Step 1735 | loss: 0.4389050285506055 | accuracy: 0.7976371951219512 \n",
      "Epoch 5 | Step 1736 | loss: 0.43971513524170847 | accuracy: 0.7967489919354839 \n",
      "Epoch 5 | Step 1737 | loss: 0.4395552628040314 | accuracy: 0.797125 \n",
      "Epoch 5 | Step 1738 | loss: 0.43971807545139674 | accuracy: 0.796875 \n",
      "Epoch 5 | Step 1739 | loss: 0.43973892387442703 | accuracy: 0.796751968503937 \n",
      "Epoch 5 | Step 1740 | loss: 0.4394890407565981 | accuracy: 0.7967529296875 \n",
      "Epoch 5 | Step 1741 | loss: 0.4403384584327077 | accuracy: 0.7960271317829457 \n",
      "Epoch 5 | Step 1742 | loss: 0.4398632363631175 | accuracy: 0.7966346153846153 \n",
      "Epoch 5 | Step 1743 | loss: 0.43975416212591506 | accuracy: 0.7965171755725191 \n",
      "Epoch 5 | Step 1744 | loss: 0.4402021463170196 | accuracy: 0.7961647727272727 \n",
      "Epoch 5 | Step 1745 | loss: 0.4396709611541347 | accuracy: 0.7965225563909775 \n",
      "Epoch 5 | Step 1746 | loss: 0.4390377793739091 | accuracy: 0.796991604477612 \n",
      "Epoch 5 | Step 1747 | loss: 0.4389953781057287 | accuracy: 0.797337962962963 \n",
      "Epoch 5 | Step 1748 | loss: 0.43886586979908104 | accuracy: 0.7976792279411765 \n",
      "Epoch 5 | Step 1749 | loss: 0.43944161999834713 | accuracy: 0.7972171532846716 \n",
      "Epoch 5 | Step 1750 | loss: 0.43892522480176843 | accuracy: 0.7974411231884058 \n",
      "Epoch 5 | Step 1751 | loss: 0.4391361674387678 | accuracy: 0.7974370503597122 \n",
      "Epoch 5 | Step 1752 | loss: 0.43957769083125253 | accuracy: 0.7969866071428572 \n",
      "Epoch 5 | Step 1753 | loss: 0.43981744148207047 | accuracy: 0.7966533687943262 \n",
      "Epoch 5 | Step 1754 | loss: 0.43960310308866096 | accuracy: 0.7964348591549296 \n",
      "Epoch 5 | Step 1755 | loss: 0.43925267916459304 | accuracy: 0.7967657342657343 \n",
      "Epoch 5 | Step 1756 | loss: 0.4389972881310516 | accuracy: 0.7967664930555556 \n",
      "Epoch 5 | Step 1757 | loss: 0.438611893612763 | accuracy: 0.7970905172413794 \n",
      "Epoch 5 | Step 1758 | loss: 0.43888627033527583 | accuracy: 0.7969820205479452 \n",
      "Epoch 5 | Step 1759 | loss: 0.439018747838987 | accuracy: 0.7969812925170068 \n",
      "Epoch 5 | Step 1760 | loss: 0.43865736654481374 | accuracy: 0.797191722972973 \n",
      "Epoch 5 | Step 1761 | loss: 0.4385621005656735 | accuracy: 0.7972944630872484 \n",
      "Epoch 5 | Step 1762 | loss: 0.43799582501252493 | accuracy: 0.7975000000000001 \n",
      "Epoch 5 | Step 1763 | loss: 0.43785778951171217 | accuracy: 0.7975993377483445 \n",
      "Epoch 5 | Step 1764 | loss: 0.438581500986689 | accuracy: 0.797388980263158 \n",
      "Epoch 5 | Step 1765 | loss: 0.439231420459311 | accuracy: 0.7974877450980393 \n",
      "Epoch 5 | Step 1766 | loss: 0.43875026044907506 | accuracy: 0.7977881493506495 \n",
      "Epoch 5 | Step 1767 | loss: 0.4376268436831813 | accuracy: 0.7983870967741936 \n",
      "Epoch 5 | Step 1768 | loss: 0.4371240708308342 | accuracy: 0.7986778846153847 \n",
      "Epoch 5 | Step 1769 | loss: 0.43690968641809597 | accuracy: 0.7989649681528663 \n",
      "Epoch 5 | Step 1770 | loss: 0.43672684325447564 | accuracy: 0.7992484177215191 \n",
      "Epoch 5 | Step 1771 | loss: 0.43644130379898743 | accuracy: 0.7992334905660379 \n",
      "Epoch 5 | Step 1772 | loss: 0.43629378993064166 | accuracy: 0.7991210937500002 \n",
      "Epoch 5 | Step 1773 | loss: 0.4359416195324489 | accuracy: 0.799398291925466 \n",
      "Epoch 5 | Step 1774 | loss: 0.4359567945386157 | accuracy: 0.798996913580247 \n",
      "Epoch 5 | Step 1775 | loss: 0.4355116535915188 | accuracy: 0.7992714723926382 \n",
      "Epoch 5 | Step 1776 | loss: 0.435408238594125 | accuracy: 0.7991615853658538 \n",
      "Epoch 5 | Step 1777 | loss: 0.4353144553574649 | accuracy: 0.7991477272727274 \n",
      "Epoch 5 | Step 1778 | loss: 0.4364030204982643 | accuracy: 0.798569277108434 \n",
      "Epoch 5 | Step 1779 | loss: 0.43608957207845356 | accuracy: 0.7990269461077846 \n",
      "Epoch 5 | Step 1780 | loss: 0.43591836875393275 | accuracy: 0.799107142857143 \n",
      "Epoch 5 | Step 1781 | loss: 0.4369048370412115 | accuracy: 0.7985392011834321 \n",
      "Epoch 5 | Step 1782 | loss: 0.4367866451249403 | accuracy: 0.7988051470588237 \n",
      "Epoch 5 | Step 1783 | loss: 0.43727825590741565 | accuracy: 0.7984283625730996 \n",
      "Epoch 5 | Step 1784 | loss: 0.4374961490894473 | accuracy: 0.7982376453488373 \n",
      "Epoch 5 | Step 1785 | loss: 0.4364376502229988 | accuracy: 0.7991329479768787 \n",
      "Epoch 5 | Step 1786 | loss: 0.4367100557034043 | accuracy: 0.7988505747126439 \n",
      "Epoch 5 | Step 1787 | loss: 0.43648946949413847 | accuracy: 0.7990178571428573 \n",
      "Epoch 5 | Step 1788 | loss: 0.4364567060362209 | accuracy: 0.7992720170454547 \n",
      "Epoch 5 | Step 1789 | loss: 0.43693790159656504 | accuracy: 0.7993467514124295 \n",
      "Epoch 5 | Step 1790 | loss: 0.4374663565265998 | accuracy: 0.7989817415730339 \n",
      "Epoch 5 | Step 1791 | loss: 0.4376360772375288 | accuracy: 0.7992318435754191 \n",
      "Epoch 5 | Step 1792 | loss: 0.43803589393695197 | accuracy: 0.7991319444444446 \n",
      "Epoch 5 | Step 1793 | loss: 0.43737603979216094 | accuracy: 0.7993784530386742 \n",
      "Epoch 5 | Step 1794 | loss: 0.43679865113981475 | accuracy: 0.7997939560439562 \n",
      "Epoch 5 | Step 1795 | loss: 0.4364699195317232 | accuracy: 0.7998633879781423 \n",
      "Epoch 5 | Step 1796 | loss: 0.4368082947381165 | accuracy: 0.7999320652173915 \n",
      "Epoch 5 | Step 1797 | loss: 0.4366340579213323 | accuracy: 0.8001689189189191 \n",
      "Epoch 5 | Step 1798 | loss: 0.43625536625103284 | accuracy: 0.8004872311827959 \n",
      "Epoch 5 | Step 1799 | loss: 0.43667849818652965 | accuracy: 0.8003843582887702 \n",
      "Epoch 5 | Step 1800 | loss: 0.43654090847740784 | accuracy: 0.8005319148936172 \n",
      "Epoch 5 | Step 1801 | loss: 0.43612387776374817 | accuracy: 0.8008432539682541 \n",
      "Epoch 5 | Step 1802 | loss: 0.4358711721081483 | accuracy: 0.8010690789473686 \n",
      "Epoch 5 | Step 1803 | loss: 0.4360247277776608 | accuracy: 0.8008835078534033 \n",
      "Epoch 5 | Step 1804 | loss: 0.4360866737551987 | accuracy: 0.8006998697916669 \n",
      "Epoch 5 | Step 1805 | loss: 0.43656708184301546 | accuracy: 0.8005181347150261 \n",
      "Epoch 5 | Step 1806 | loss: 0.43605413510627355 | accuracy: 0.8008215206185568 \n",
      "Epoch 5 | Step 1807 | loss: 0.4366256340956077 | accuracy: 0.8004807692307694 \n",
      "Epoch 5 | Step 1808 | loss: 0.43644227467629376 | accuracy: 0.800701530612245 \n",
      "Epoch 5 | Step 1809 | loss: 0.4361849859886363 | accuracy: 0.8006821065989849 \n",
      "Epoch 5 | Step 1810 | loss: 0.4364740928315153 | accuracy: 0.8005839646464648 \n",
      "Epoch 5 | Step 1811 | loss: 0.43691846159235315 | accuracy: 0.8005653266331659 \n",
      "Epoch 5 | Step 1812 | loss: 0.4366235564649105 | accuracy: 0.8006250000000001 \n",
      "Epoch 5 | Step 1813 | loss: 0.43634894223355536 | accuracy: 0.8006840796019902 \n",
      "Epoch 5 | Step 1814 | loss: 0.4365525732536127 | accuracy: 0.8006652227722774 \n",
      "Epoch 5 | Step 1815 | loss: 0.435997727322461 | accuracy: 0.8011083743842365 \n",
      "Epoch 5 | Step 1816 | loss: 0.43624064194805484 | accuracy: 0.80093443627451 \n",
      "Epoch 5 | Step 1817 | loss: 0.43633874509392717 | accuracy: 0.8007621951219513 \n",
      "Epoch 5 | Step 1818 | loss: 0.43606573314342684 | accuracy: 0.8008191747572817 \n",
      "Epoch 5 | Step 1819 | loss: 0.4359764203357236 | accuracy: 0.8007246376811595 \n",
      "Epoch 5 | Step 1820 | loss: 0.4354282199190213 | accuracy: 0.801081730769231 \n",
      "Epoch 5 | Step 1821 | loss: 0.4354945572369407 | accuracy: 0.801211124401914 \n",
      "Epoch 5 | Step 1822 | loss: 0.4350780731155759 | accuracy: 0.8014880952380954 \n",
      "Epoch 5 | Step 1823 | loss: 0.43510186813453927 | accuracy: 0.8016143364928912 \n",
      "Epoch 5 | Step 1824 | loss: 0.4353337540941418 | accuracy: 0.8015182783018869 \n",
      "Epoch 5 | Step 1825 | loss: 0.4351349393246879 | accuracy: 0.8015698356807514 \n",
      "Epoch 5 | Step 1826 | loss: 0.43484438231615263 | accuracy: 0.8019129672897197 \n",
      "Epoch 5 | Step 1827 | loss: 0.4346895140270854 | accuracy: 0.8016715116279071 \n",
      "Epoch 5 | Step 1828 | loss: 0.43484822246763444 | accuracy: 0.8016493055555557 \n",
      "Epoch 5 | Step 1829 | loss: 0.43556204918892155 | accuracy: 0.801123271889401 \n",
      "Epoch 5 | Step 1830 | loss: 0.4353812604869178 | accuracy: 0.8013188073394497 \n",
      "Epoch 5 | Step 1831 | loss: 0.4351244909033928 | accuracy: 0.8013698630136987 \n",
      "Epoch 5 | Step 1832 | loss: 0.43508427698503843 | accuracy: 0.8014204545454546 \n",
      "Epoch 5 | Step 1833 | loss: 0.4346733327904438 | accuracy: 0.8015412895927603 \n",
      "Epoch 5 | Step 1834 | loss: 0.4342802758957889 | accuracy: 0.8018721846846848 \n",
      "Epoch 5 | Step 1835 | loss: 0.4343508800048999 | accuracy: 0.8019198430493275 \n",
      "Epoch 5 | Step 1836 | loss: 0.43437467688428505 | accuracy: 0.8017578125000001 \n",
      "Epoch 5 | Step 1837 | loss: 0.4350613770220015 | accuracy: 0.8013194444444446 \n",
      "Epoch 5 | Step 1838 | loss: 0.43526205143569846 | accuracy: 0.8014380530973453 \n",
      "Epoch 5 | Step 1839 | loss: 0.4353045536295433 | accuracy: 0.8014179515418504 \n",
      "Epoch 5 | Step 1840 | loss: 0.4349850043654442 | accuracy: 0.8015350877192984 \n",
      "Epoch 5 | Step 1841 | loss: 0.4345913037462526 | accuracy: 0.8018558951965067 \n",
      "Epoch 5 | Step 1842 | loss: 0.4340287589508554 | accuracy: 0.8021059782608697 \n",
      "Epoch 5 | Step 1843 | loss: 0.4345055248314168 | accuracy: 0.8018127705627707 \n",
      "Epoch 5 | Step 1844 | loss: 0.4340071649900798 | accuracy: 0.8020608836206897 \n",
      "Epoch 5 | Step 1845 | loss: 0.4343117646904974 | accuracy: 0.8019045064377683 \n",
      "Epoch 5 | Step 1846 | loss: 0.43449870044859046 | accuracy: 0.8016826923076924 \n",
      "Epoch 5 | Step 1847 | loss: 0.4341898046909495 | accuracy: 0.8017952127659576 \n",
      "Epoch 5 | Step 1848 | loss: 0.434078084336499 | accuracy: 0.8018405720338985 \n",
      "Epoch 5 | Step 1849 | loss: 0.43423314926996515 | accuracy: 0.8016218354430381 \n",
      "Epoch 5 | Step 1850 | loss: 0.4348696321249008 | accuracy: 0.8014705882352943 \n",
      "Epoch 5 | Step 1851 | loss: 0.4348295110289522 | accuracy: 0.8014513598326362 \n",
      "Epoch 5 | Step 1852 | loss: 0.43471768585344156 | accuracy: 0.8013671875000001 \n",
      "Epoch 5 | Step 1853 | loss: 0.43500495068265194 | accuracy: 0.8010243775933611 \n",
      "Epoch 5 | Step 1854 | loss: 0.43515157908940116 | accuracy: 0.8010717975206613 \n",
      "Epoch 5 | Step 1855 | loss: 0.43490957760025933 | accuracy: 0.8012474279835392 \n",
      "Epoch 5 | Step 1856 | loss: 0.4342903607204312 | accuracy: 0.8016777663934428 \n",
      "Epoch 5 | Step 1857 | loss: 0.4342643760904974 | accuracy: 0.8015943877551022 \n",
      "Epoch 5 | Step 1858 | loss: 0.43396313318876717 | accuracy: 0.8017657520325204 \n",
      "Epoch 5 | Step 1859 | loss: 0.4337937052433307 | accuracy: 0.8020622469635629 \n",
      "Epoch 5 | Step 1860 | loss: 0.43399501267460083 | accuracy: 0.8021043346774195 \n",
      "Epoch 5 | Step 1861 | loss: 0.4344258857778756 | accuracy: 0.8017695783132531 \n",
      "Epoch 5 | Step 1862 | loss: 0.4340906670093536 | accuracy: 0.8019375000000001 \n",
      "Epoch 5 | Step 1863 | loss: 0.43430365889195904 | accuracy: 0.801855079681275 \n",
      "Epoch 5 | Step 1864 | loss: 0.4345937990953052 | accuracy: 0.8015252976190478 \n",
      "Epoch 5 | Step 1865 | loss: 0.4344899065409724 | accuracy: 0.80175395256917 \n",
      "Epoch 5 | Step 1866 | loss: 0.4344090885064733 | accuracy: 0.8016732283464568 \n",
      "Epoch 5 | Step 1867 | loss: 0.43423298059725296 | accuracy: 0.8018382352941178 \n",
      "Epoch 5 | Step 1868 | loss: 0.4341541377361864 | accuracy: 0.8016967773437501 \n",
      "Epoch 5 | Step 1869 | loss: 0.4343033893331016 | accuracy: 0.8014956225680935 \n",
      "Epoch 5 | Step 1870 | loss: 0.4342519631681516 | accuracy: 0.8015382751937986 \n",
      "Epoch 5 | Step 1871 | loss: 0.4343633574638588 | accuracy: 0.801399613899614 \n",
      "Epoch 5 | Step 1872 | loss: 0.4344484482820217 | accuracy: 0.8012620192307693 \n",
      "Epoch 5 | Step 1873 | loss: 0.4341602000011795 | accuracy: 0.8013649425287357 \n",
      "Epoch 5 | Step 1874 | loss: 0.434660178900675 | accuracy: 0.8012285305343513 \n",
      "Epoch 5 | Step 1875 | loss: 0.43438986487714965 | accuracy: 0.8013902091254754 \n",
      "Epoch 5 | Step 1876 | loss: 0.43403243521849316 | accuracy: 0.8016098484848486 \n",
      "Epoch 5 | Step 1877 | loss: 0.43387761802043556 | accuracy: 0.8015919811320755 \n",
      "Epoch 5 | Step 1878 | loss: 0.4339990341349652 | accuracy: 0.8016329887218047 \n",
      "Epoch 5 | Step 1879 | loss: 0.4338739824652225 | accuracy: 0.8017322097378278 \n",
      "Epoch 5 | Step 1880 | loss: 0.43390129751233913 | accuracy: 0.8015391791044777 \n",
      "Epoch 5 | Step 1881 | loss: 0.43387591561863414 | accuracy: 0.8016380111524165 \n",
      "Epoch 5 | Step 1882 | loss: 0.433880118087486 | accuracy: 0.8016203703703705 \n",
      "Epoch 5 | Step 1883 | loss: 0.4337455396062774 | accuracy: 0.8015452029520296 \n",
      "Epoch 5 | Step 1884 | loss: 0.4335629232227802 | accuracy: 0.8017578125000001 \n",
      "Epoch 5 | Step 1885 | loss: 0.4337297348312406 | accuracy: 0.8017971611721613 \n",
      "Epoch 5 | Step 1886 | loss: 0.43381092191612636 | accuracy: 0.8018362226277373 \n",
      "Epoch 5 | Step 1887 | loss: 0.43360385938124224 | accuracy: 0.8021022727272729 \n",
      "Epoch 5 | Step 1888 | loss: 0.43405845005443133 | accuracy: 0.8019701086956523 \n",
      "Epoch 5 | Step 1889 | loss: 0.43396794516257 | accuracy: 0.8022337545126356 \n",
      "Epoch 5 | Step 1890 | loss: 0.4337854907452631 | accuracy: 0.8023268884892089 \n",
      "Epoch 5 | Step 1891 | loss: 0.43349482541015927 | accuracy: 0.8024193548387099 \n",
      "Epoch 5 | Step 1892 | loss: 0.43341014363936015 | accuracy: 0.8023995535714288 \n",
      "Epoch 5 | Step 1893 | loss: 0.4333047787277724 | accuracy: 0.8025467081850536 \n",
      "Epoch 5 | Step 1894 | loss: 0.43302011880891544 | accuracy: 0.802637411347518 \n",
      "Epoch 5 | Step 1895 | loss: 0.4332050813802982 | accuracy: 0.8022857773851592 \n",
      "Epoch 5 | Step 1896 | loss: 0.4327746199470171 | accuracy: 0.8024317781690142 \n",
      "Epoch 5 | Step 1897 | loss: 0.43267490455978797 | accuracy: 0.8024122807017545 \n",
      "Epoch 5 | Step 1898 | loss: 0.4320758120580153 | accuracy: 0.8027207167832169 \n",
      "Epoch 5 | Step 1899 | loss: 0.43211703246478833 | accuracy: 0.8025370209059235 \n",
      "Epoch 5 | Step 1900 | loss: 0.4317935776586334 | accuracy: 0.8027343750000001 \n",
      "Epoch 5 | Step 1901 | loss: 0.4323781278100393 | accuracy: 0.802551903114187 \n",
      "Epoch 5 | Step 1902 | loss: 0.43196855968442455 | accuracy: 0.8029094827586208 \n",
      "Epoch 5 | Step 1903 | loss: 0.4325325024086995 | accuracy: 0.8026202749140895 \n",
      "Epoch 5 | Step 1904 | loss: 0.4323139263138379 | accuracy: 0.8027076198630138 \n",
      "Epoch 5 | Step 1905 | loss: 0.43227502571437953 | accuracy: 0.8027410409556315 \n",
      "Epoch 5 | Step 1906 | loss: 0.43240785588618036 | accuracy: 0.8027742346938777 \n",
      "Epoch 5 | Step 1907 | loss: 0.4323396051334122 | accuracy: 0.8026483050847458 \n",
      "Epoch 5 | Step 1908 | loss: 0.43226632224144157 | accuracy: 0.8027343750000001 \n",
      "Epoch 5 | Step 1909 | loss: 0.43212282125797336 | accuracy: 0.8029250841750842 \n",
      "Epoch 5 | Step 1910 | loss: 0.43195355158524223 | accuracy: 0.8030096476510068 \n",
      "Epoch 5 | Step 1911 | loss: 0.4319167216884651 | accuracy: 0.8030936454849499 \n",
      "Epoch 5 | Step 1912 | loss: 0.43166007290283837 | accuracy: 0.8033333333333335 \n",
      "Epoch 5 | Step 1913 | loss: 0.431956164365591 | accuracy: 0.8031042358803988 \n",
      "Epoch 5 | Step 1914 | loss: 0.43183682612235974 | accuracy: 0.8032388245033113 \n",
      "Epoch 5 | Step 1915 | loss: 0.4316446870663772 | accuracy: 0.8033725247524752 \n",
      "Epoch 5 | Step 1916 | loss: 0.4317922230417791 | accuracy: 0.8031455592105263 \n",
      "Epoch 5 | Step 1917 | loss: 0.43148233304258254 | accuracy: 0.8032274590163935 \n",
      "Epoch 5 | Step 1918 | loss: 0.4312841499747794 | accuracy: 0.8033088235294118 \n",
      "Epoch 5 | Step 1919 | loss: 0.43168117858299604 | accuracy: 0.8031351791530945 \n",
      "Epoch 5 | Step 1920 | loss: 0.43141531189540766 | accuracy: 0.8031655844155845 \n",
      "Epoch 5 | Step 1921 | loss: 0.4310796266620599 | accuracy: 0.8034486245954694 \n",
      "Epoch 5 | Step 1922 | loss: 0.4309401889001169 | accuracy: 0.8034274193548389 \n",
      "Epoch 5 | Step 1923 | loss: 0.43084155363285276 | accuracy: 0.8035570739549841 \n",
      "Epoch 5 | Step 1924 | loss: 0.4307888437731144 | accuracy: 0.8035857371794873 \n",
      "Epoch 5 | Step 1925 | loss: 0.43050856512194624 | accuracy: 0.8036641373801918 \n",
      "Epoch 5 | Step 1926 | loss: 0.43070427855108956 | accuracy: 0.8034932324840766 \n",
      "Epoch 5 | Step 1927 | loss: 0.4308970260241675 | accuracy: 0.8034722222222224 \n",
      "Epoch 5 | Step 1928 | loss: 0.43099070330963857 | accuracy: 0.8035007911392407 \n",
      "Epoch 5 | Step 1929 | loss: 0.43065952098331994 | accuracy: 0.8037756309148267 \n",
      "Epoch 5 | Step 1930 | loss: 0.43080825325827926 | accuracy: 0.8037047955974845 \n",
      "Epoch 5 | Step 1931 | loss: 0.43061984837242057 | accuracy: 0.803879310344828 \n",
      "Epoch 5 | Step 1932 | loss: 0.4304548225365579 | accuracy: 0.8039062500000004 \n",
      "Epoch 5 | Step 1933 | loss: 0.43039039575793664 | accuracy: 0.8039330218068539 \n",
      "Epoch 5 | Step 1934 | loss: 0.430778889830068 | accuracy: 0.8037655279503109 \n",
      "Epoch 5 | Step 1935 | loss: 0.4306094011655164 | accuracy: 0.8037925696594431 \n",
      "Epoch 5 | Step 1936 | loss: 0.43047052069946573 | accuracy: 0.8039158950617288 \n",
      "Epoch 5 | Step 1937 | loss: 0.4304604313006768 | accuracy: 0.8037500000000003 \n",
      "Epoch 5 | Step 1938 | loss: 0.4302665265791255 | accuracy: 0.8039685582822089 \n",
      "Epoch 5 | Step 1939 | loss: 0.4302345519765801 | accuracy: 0.8039468654434254 \n",
      "Epoch 5 | Step 1940 | loss: 0.4303142859986642 | accuracy: 0.8038776676829271 \n",
      "Epoch 5 | Step 1941 | loss: 0.4307744266595522 | accuracy: 0.8036664133738606 \n",
      "Epoch 5 | Step 1942 | loss: 0.43081395770564224 | accuracy: 0.8036931818181822 \n",
      "Epoch 5 | Step 1943 | loss: 0.4307981687189949 | accuracy: 0.8037197885196378 \n",
      "Epoch 5 | Step 1944 | loss: 0.43054778389183873 | accuracy: 0.8038874246987955 \n",
      "Epoch 5 | Step 1945 | loss: 0.4304191500574977 | accuracy: 0.8039132882882887 \n",
      "Epoch 5 | Step 1946 | loss: 0.4305617024084765 | accuracy: 0.8038922155688626 \n",
      "Epoch 5 | Step 1947 | loss: 0.43041627656168013 | accuracy: 0.8040111940298511 \n",
      "Epoch 5 | Step 1948 | loss: 0.43019477898875874 | accuracy: 0.8040829613095242 \n",
      "Epoch 5 | Step 1949 | loss: 0.4303070710037865 | accuracy: 0.8040615727002971 \n",
      "Epoch 5 | Step 1950 | loss: 0.4301533603809289 | accuracy: 0.8041327662721897 \n",
      "Epoch 5 | Step 1951 | loss: 0.42996865053795785 | accuracy: 0.8042035398230092 \n",
      "Epoch 5 | Step 1952 | loss: 0.42962566324893164 | accuracy: 0.8043198529411768 \n",
      "Epoch 5 | Step 1953 | loss: 0.42922676273804605 | accuracy: 0.804618768328446 \n",
      "Epoch 5 | Step 1954 | loss: 0.4291524719773677 | accuracy: 0.8046418128654974 \n",
      "Epoch 5 | Step 1955 | loss: 0.4290719496265445 | accuracy: 0.8046647230320703 \n",
      "Epoch 5 | Step 1956 | loss: 0.42875243454825046 | accuracy: 0.8048691860465119 \n",
      "Epoch 5 | Step 1957 | loss: 0.4289457261562347 | accuracy: 0.8048007246376815 \n",
      "Epoch 5 | Step 1958 | loss: 0.4288918344099398 | accuracy: 0.804822976878613 \n",
      "Epoch 5 | Step 1959 | loss: 0.42844361178469587 | accuracy: 0.8051152737752164 \n",
      "Epoch 5 | Step 1960 | loss: 0.4286052566663972 | accuracy: 0.8050915948275865 \n",
      "Epoch 5 | Step 1961 | loss: 0.42847596574307856 | accuracy: 0.8051575931232094 \n",
      "Epoch 5 | Step 1962 | loss: 0.42830269626208717 | accuracy: 0.8051339285714288 \n",
      "Epoch 5 | Step 1963 | loss: 0.42805341106873973 | accuracy: 0.8053329772079776 \n",
      "Epoch 5 | Step 1964 | loss: 0.42808902864767745 | accuracy: 0.8054865056818185 \n",
      "Epoch 5 | Step 1965 | loss: 0.42805321687679454 | accuracy: 0.8054621104815868 \n",
      "Epoch 5 | Step 1966 | loss: 0.42797734659943876 | accuracy: 0.8054819915254241 \n",
      "Epoch 5 | Step 1967 | loss: 0.4278324337072775 | accuracy: 0.8055457746478877 \n",
      "Epoch 5 | Step 1968 | loss: 0.42757897254791155 | accuracy: 0.8056969803370789 \n",
      "Epoch 5 | Step 1969 | loss: 0.42738813003238174 | accuracy: 0.8057160364145661 \n",
      "Epoch 5 | Step 1970 | loss: 0.42750430914609794 | accuracy: 0.8056040502793299 \n",
      "Epoch 5 | Step 1971 | loss: 0.4274805715323159 | accuracy: 0.8055797353760449 \n",
      "Epoch 5 | Step 1972 | loss: 0.4274563803440995 | accuracy: 0.8056857638888892 \n",
      "Epoch 5 | Step 1973 | loss: 0.42772941501847267 | accuracy: 0.8054882271468147 \n",
      "Epoch 5 | Step 1974 | loss: 0.4276039957670876 | accuracy: 0.8055507596685086 \n",
      "Epoch 5 | Step 1975 | loss: 0.42764062477537423 | accuracy: 0.8054838154269975 \n",
      "Epoch 5 | Step 1976 | loss: 0.4274545873586948 | accuracy: 0.805503090659341 \n",
      "Epoch 5 | Step 1977 | loss: 0.42730210496954724 | accuracy: 0.805607876712329 \n",
      "Epoch 5 | Step 1978 | loss: 0.4271142478686213 | accuracy: 0.8056693989071041 \n",
      "Epoch 5 | Step 1979 | loss: 0.4272477253256442 | accuracy: 0.8055602861035426 \n",
      "Epoch 5 | Step 1980 | loss: 0.4270549558265054 | accuracy: 0.8056216032608698 \n",
      "Epoch 5 | Step 1981 | loss: 0.4271137738615517 | accuracy: 0.8056402439024394 \n",
      "Epoch 5 | Step 1982 | loss: 0.4273638283884203 | accuracy: 0.8054054054054057 \n",
      "Epoch 5 | Step 1983 | loss: 0.4275259876026298 | accuracy: 0.8052560646900273 \n",
      "Epoch 5 | Step 1984 | loss: 0.4280075784171781 | accuracy: 0.8051075268817207 \n",
      "Epoch 5 | Step 1985 | loss: 0.42803527762359334 | accuracy: 0.8050854557640754 \n",
      "Epoch 5 | Step 1986 | loss: 0.42773189304027964 | accuracy: 0.8052306149732623 \n",
      "Epoch 5 | Step 1987 | loss: 0.4273610908985138 | accuracy: 0.8054583333333336 \n",
      "Epoch 5 | Step 1988 | loss: 0.4273109975013327 | accuracy: 0.8053108377659578 \n",
      "Epoch 5 | Step 1989 | loss: 0.42718878807376487 | accuracy: 0.8053713527851462 \n",
      "Epoch 5 | Step 1990 | loss: 0.42710954841797943 | accuracy: 0.805266203703704 \n",
      "Epoch 5 | Step 1991 | loss: 0.42676544205179945 | accuracy: 0.8054914248021111 \n",
      "Epoch 5 | Step 1992 | loss: 0.4266559837680114 | accuracy: 0.8055098684210529 \n",
      "Epoch 5 | Step 1993 | loss: 0.4264734975622082 | accuracy: 0.8056922572178481 \n",
      "Epoch 5 | Step 1994 | loss: 0.4261841996333986 | accuracy: 0.8057918848167542 \n",
      "Epoch 5 | Step 1995 | loss: 0.4261631265321537 | accuracy: 0.8057278067885121 \n",
      "Epoch 5 | Step 1996 | loss: 0.42631358839571476 | accuracy: 0.8056233723958336 \n",
      "Epoch 5 | Step 1997 | loss: 0.42646403653281073 | accuracy: 0.8056006493506497 \n",
      "Epoch 5 | Step 1998 | loss: 0.4266724961718129 | accuracy: 0.8055780440414511 \n",
      "Epoch 5 | Step 1999 | loss: 0.42674482892958077 | accuracy: 0.8057574289405688 \n",
      "Epoch 5 | Step 2000 | loss: 0.42656731528719677 | accuracy: 0.8058553479381446 \n",
      "Epoch 5 | Step 2001 | loss: 0.4267287220623928 | accuracy: 0.8057519280205658 \n",
      "Epoch 5 | Step 2002 | loss: 0.4264743545116522 | accuracy: 0.8058894230769234 \n",
      "Epoch 5 | Step 2003 | loss: 0.42663322408181015 | accuracy: 0.8058663682864453 \n",
      "Epoch 5 | Step 2004 | loss: 0.4265963552253587 | accuracy: 0.8059231505102044 \n",
      "Epoch 5 | Step 2005 | loss: 0.4263890808016896 | accuracy: 0.8061784351145042 \n",
      "Epoch 5 | Step 2006 | loss: 0.42661096791022923 | accuracy: 0.8060755076142135 \n",
      "Epoch 5 | Step 2007 | loss: 0.42661154066460044 | accuracy: 0.8060522151898737 \n",
      "Epoch 5 | Step 2008 | loss: 0.4264906363354789 | accuracy: 0.8059106691919194 \n",
      "Epoch 5 | Step 2009 | loss: 0.4266477896824892 | accuracy: 0.8058485516372799 \n",
      "Epoch 5 | Step 2010 | loss: 0.42671168060158965 | accuracy: 0.8058652638190957 \n",
      "Epoch 5 | Step 2011 | loss: 0.42653012290634307 | accuracy: 0.8059210526315792 \n",
      "Epoch 5 | Step 2012 | loss: 0.4267659811675549 | accuracy: 0.8057031250000003 \n",
      "Epoch 5 | Step 2013 | loss: 0.42672701220857234 | accuracy: 0.8057980049875314 \n",
      "Epoch 5 | Step 2014 | loss: 0.42710356629309965 | accuracy: 0.8055814676616918 \n",
      "Epoch 5 | Step 2015 | loss: 0.42690088649837316 | accuracy: 0.8057216351144666 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.5341353416442871 | accuracy: 0.6875 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.5420531928539276 | accuracy: 0.6953125 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.49861451983451843 | accuracy: 0.734375 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.5003269538283348 | accuracy: 0.74609375 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.49877925515174865 | accuracy: 0.74375 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.492239569624265 | accuracy: 0.7473958333333334 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4869301659720285 | accuracy: 0.7566964285714286 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4823252409696579 | accuracy: 0.7578125 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4771851864125993 | accuracy: 0.7604166666666666 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.47671888768672943 | accuracy: 0.7625 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.473854045976292 | accuracy: 0.7684659090909091 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.46740106244881946 | accuracy: 0.7721354166666666 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4693135435764606 | accuracy: 0.7692307692307693 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.46768765577248167 | accuracy: 0.7734375 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4605414609114329 | accuracy: 0.778125 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4590982757508755 | accuracy: 0.77734375 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.46810520747128653 | accuracy: 0.7720588235294118 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4649638599819607 | accuracy: 0.7708333333333334 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.467658635817076 | accuracy: 0.7713815789473685 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4657578691840172 | accuracy: 0.7718750000000001 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.46623384668713524 | accuracy: 0.7738095238095238 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.46192198314450006 | accuracy: 0.7762784090909091 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4658008723155312 | accuracy: 0.7724184782608695 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.46932247653603554 | accuracy: 0.7701822916666666 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4704330539703369 | accuracy: 0.77125 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.46578372900302595 | accuracy: 0.7740384615384616 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.463609093869174 | accuracy: 0.7748842592592593 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.46069987011807306 | accuracy: 0.7762276785714286 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4618686355393508 | accuracy: 0.775323275862069 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4616886427005132 | accuracy: 0.7776041666666667 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.45897774446395134 | accuracy: 0.7792338709677419 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.45432709250599146 | accuracy: 0.78271484375 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4531472542069175 | accuracy: 0.7836174242424242 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.45989743751638074 | accuracy: 0.7803308823529411 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.45868070806775774 | accuracy: 0.7803571428571429 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4563840900858243 | accuracy: 0.7816840277777778 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4579430971596692 | accuracy: 0.7820945945945946 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.45813694361009094 | accuracy: 0.7816611842105263 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.456718290463472 | accuracy: 0.7824519230769231 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4578950569033623 | accuracy: 0.7816406250000001 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.45879100154085856 | accuracy: 0.7804878048780488 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.456309417173976 | accuracy: 0.7819940476190477 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.45687948132670203 | accuracy: 0.7805232558139535 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4569639055566354 | accuracy: 0.7798295454545454 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.45918715596199033 | accuracy: 0.7784420291582743 \n",
      "Epoch 6 | Step 2016 | loss: 0.360170841217041 | accuracy: 0.828125 \n",
      "Epoch 6 | Step 2017 | loss: 0.4285932630300522 | accuracy: 0.7734375 \n",
      "Epoch 6 | Step 2018 | loss: 0.3791138331095378 | accuracy: 0.8125 \n",
      "Epoch 6 | Step 2019 | loss: 0.3705187514424324 | accuracy: 0.828125 \n",
      "Epoch 6 | Step 2020 | loss: 0.3729743957519531 | accuracy: 0.828125 \n",
      "Epoch 6 | Step 2021 | loss: 0.3808371027310689 | accuracy: 0.828125 \n",
      "Epoch 6 | Step 2022 | loss: 0.38370706353868755 | accuracy: 0.828125 \n",
      "Epoch 6 | Step 2023 | loss: 0.4016432538628578 | accuracy: 0.826171875 \n",
      "Epoch 6 | Step 2024 | loss: 0.398380802737342 | accuracy: 0.8263888888888888 \n",
      "Epoch 6 | Step 2025 | loss: 0.41139087080955505 | accuracy: 0.8171875 \n",
      "Epoch 6 | Step 2026 | loss: 0.4054630534215407 | accuracy: 0.8181818181818182 \n",
      "Epoch 6 | Step 2027 | loss: 0.4159326031804085 | accuracy: 0.8072916666666666 \n",
      "Epoch 6 | Step 2028 | loss: 0.4135538018666781 | accuracy: 0.8112980769230769 \n",
      "Epoch 6 | Step 2029 | loss: 0.41774268448352814 | accuracy: 0.8091517857142857 \n",
      "Epoch 6 | Step 2030 | loss: 0.41215341289838153 | accuracy: 0.8135416666666667 \n",
      "Epoch 6 | Step 2031 | loss: 0.4041412677615881 | accuracy: 0.8193359375 \n",
      "Epoch 6 | Step 2032 | loss: 0.40132712791947756 | accuracy: 0.8216911764705882 \n",
      "Epoch 6 | Step 2033 | loss: 0.4047275268369251 | accuracy: 0.8185763888888888 \n",
      "Epoch 6 | Step 2034 | loss: 0.4024752864712163 | accuracy: 0.8199013157894737 \n",
      "Epoch 6 | Step 2035 | loss: 0.4022379547357559 | accuracy: 0.8203125 \n",
      "Epoch 6 | Step 2036 | loss: 0.4023574690024058 | accuracy: 0.8191964285714286 \n",
      "Epoch 6 | Step 2037 | loss: 0.4009970738129182 | accuracy: 0.8196022727272727 \n",
      "Epoch 6 | Step 2038 | loss: 0.39699269766392914 | accuracy: 0.8213315217391305 \n",
      "Epoch 6 | Step 2039 | loss: 0.39670004944006604 | accuracy: 0.8216145833333334 \n",
      "Epoch 6 | Step 2040 | loss: 0.3927503681182861 | accuracy: 0.825625 \n",
      "Epoch 6 | Step 2041 | loss: 0.3953535889203732 | accuracy: 0.8227163461538461 \n",
      "Epoch 6 | Step 2042 | loss: 0.39458942634088023 | accuracy: 0.8229166666666666 \n",
      "Epoch 6 | Step 2043 | loss: 0.3880534682955061 | accuracy: 0.8270089285714286 \n",
      "Epoch 6 | Step 2044 | loss: 0.3872933367203022 | accuracy: 0.8265086206896551 \n",
      "Epoch 6 | Step 2045 | loss: 0.3886891583601634 | accuracy: 0.8265625 \n",
      "Epoch 6 | Step 2046 | loss: 0.3874246862626845 | accuracy: 0.828125 \n",
      "Epoch 6 | Step 2047 | loss: 0.3892767382785678 | accuracy: 0.828125 \n",
      "Epoch 6 | Step 2048 | loss: 0.39275431723305676 | accuracy: 0.8262310606060606 \n",
      "Epoch 6 | Step 2049 | loss: 0.39378898021052866 | accuracy: 0.8258272058823529 \n",
      "Epoch 6 | Step 2050 | loss: 0.3946808201926095 | accuracy: 0.8254464285714286 \n",
      "Epoch 6 | Step 2051 | loss: 0.3962306222981877 | accuracy: 0.8246527777777778 \n",
      "Epoch 6 | Step 2052 | loss: 0.3945506625884288 | accuracy: 0.8255912162162162 \n",
      "Epoch 6 | Step 2053 | loss: 0.3931296365825753 | accuracy: 0.8252467105263158 \n",
      "Epoch 6 | Step 2054 | loss: 0.3913104236125946 | accuracy: 0.8277243589743589 \n",
      "Epoch 6 | Step 2055 | loss: 0.3902419202029705 | accuracy: 0.828125 \n",
      "Epoch 6 | Step 2056 | loss: 0.39088968387464196 | accuracy: 0.8285060975609756 \n",
      "Epoch 6 | Step 2057 | loss: 0.38885814802987234 | accuracy: 0.8296130952380952 \n",
      "Epoch 6 | Step 2058 | loss: 0.3871669083140617 | accuracy: 0.8288517441860465 \n",
      "Epoch 6 | Step 2059 | loss: 0.386259873482314 | accuracy: 0.828125 \n",
      "Epoch 6 | Step 2060 | loss: 0.3886806911892361 | accuracy: 0.8260416666666667 \n",
      "Epoch 6 | Step 2061 | loss: 0.388763102500335 | accuracy: 0.8257472826086957 \n",
      "Epoch 6 | Step 2062 | loss: 0.38820135086140733 | accuracy: 0.8254654255319149 \n",
      "Epoch 6 | Step 2063 | loss: 0.38923985821505386 | accuracy: 0.8245442708333334 \n",
      "Epoch 6 | Step 2064 | loss: 0.3874441263627033 | accuracy: 0.8258928571428571 \n",
      "Epoch 6 | Step 2065 | loss: 0.3883036261796951 | accuracy: 0.825625 \n",
      "Epoch 6 | Step 2066 | loss: 0.3898586993123971 | accuracy: 0.8253676470588235 \n",
      "Epoch 6 | Step 2067 | loss: 0.39197554611242735 | accuracy: 0.8236177884615384 \n",
      "Epoch 6 | Step 2068 | loss: 0.3913923631299217 | accuracy: 0.8234080188679245 \n",
      "Epoch 6 | Step 2069 | loss: 0.3904894154380869 | accuracy: 0.8243634259259259 \n",
      "Epoch 6 | Step 2070 | loss: 0.3876988657496192 | accuracy: 0.8261363636363637 \n",
      "Epoch 6 | Step 2071 | loss: 0.3892550167760679 | accuracy: 0.826171875 \n",
      "Epoch 6 | Step 2072 | loss: 0.38906243835624893 | accuracy: 0.8264802631578947 \n",
      "Epoch 6 | Step 2073 | loss: 0.3913561200787281 | accuracy: 0.8254310344827587 \n",
      "Epoch 6 | Step 2074 | loss: 0.391782685104063 | accuracy: 0.8260063559322034 \n",
      "Epoch 6 | Step 2075 | loss: 0.39239014908671377 | accuracy: 0.82578125 \n",
      "Epoch 6 | Step 2076 | loss: 0.39325369552510686 | accuracy: 0.8245389344262295 \n",
      "Epoch 6 | Step 2077 | loss: 0.3932708638810342 | accuracy: 0.8243447580645161 \n",
      "Epoch 6 | Step 2078 | loss: 0.3927832271844622 | accuracy: 0.8246527777777778 \n",
      "Epoch 6 | Step 2079 | loss: 0.39064510981552303 | accuracy: 0.826171875 \n",
      "Epoch 6 | Step 2080 | loss: 0.39149100115666025 | accuracy: 0.8262019230769231 \n",
      "Epoch 6 | Step 2081 | loss: 0.3889944806243434 | accuracy: 0.8276515151515151 \n",
      "Epoch 6 | Step 2082 | loss: 0.3888696921405508 | accuracy: 0.8276585820895522 \n",
      "Epoch 6 | Step 2083 | loss: 0.38882750009789185 | accuracy: 0.8285845588235294 \n",
      "Epoch 6 | Step 2084 | loss: 0.39033691390700964 | accuracy: 0.8276721014492754 \n",
      "Epoch 6 | Step 2085 | loss: 0.39277486758572716 | accuracy: 0.8258928571428571 \n",
      "Epoch 6 | Step 2086 | loss: 0.39323012635741433 | accuracy: 0.8263644366197183 \n",
      "Epoch 6 | Step 2087 | loss: 0.3925517035855187 | accuracy: 0.8268229166666665 \n",
      "Epoch 6 | Step 2088 | loss: 0.39290574764552183 | accuracy: 0.8270547945205478 \n",
      "Epoch 6 | Step 2089 | loss: 0.39335109978108795 | accuracy: 0.8264358108108106 \n",
      "Epoch 6 | Step 2090 | loss: 0.39416623115539556 | accuracy: 0.8262499999999998 \n",
      "Epoch 6 | Step 2091 | loss: 0.39353100641777644 | accuracy: 0.8266858552631577 \n",
      "Epoch 6 | Step 2092 | loss: 0.39327621498665255 | accuracy: 0.826095779220779 \n",
      "Epoch 6 | Step 2093 | loss: 0.3930222113163044 | accuracy: 0.8255208333333331 \n",
      "Epoch 6 | Step 2094 | loss: 0.3922024335287795 | accuracy: 0.826147151898734 \n",
      "Epoch 6 | Step 2095 | loss: 0.39156131967902186 | accuracy: 0.8265624999999999 \n",
      "Epoch 6 | Step 2096 | loss: 0.3935418357083827 | accuracy: 0.8256172839506171 \n",
      "Epoch 6 | Step 2097 | loss: 0.392738806038368 | accuracy: 0.8258384146341462 \n",
      "Epoch 6 | Step 2098 | loss: 0.39302816627973536 | accuracy: 0.8254894578313251 \n",
      "Epoch 6 | Step 2099 | loss: 0.39343087446121944 | accuracy: 0.8257068452380951 \n",
      "Epoch 6 | Step 2100 | loss: 0.39373280370936675 | accuracy: 0.8259191176470586 \n",
      "Epoch 6 | Step 2101 | loss: 0.392789892679037 | accuracy: 0.8266715116279069 \n",
      "Epoch 6 | Step 2102 | loss: 0.39255163587372877 | accuracy: 0.8266882183908044 \n",
      "Epoch 6 | Step 2103 | loss: 0.3930889063260772 | accuracy: 0.8265269886363634 \n",
      "Epoch 6 | Step 2104 | loss: 0.3934411406517029 | accuracy: 0.8258426966292133 \n",
      "Epoch 6 | Step 2105 | loss: 0.3940531379646725 | accuracy: 0.8256944444444443 \n",
      "Epoch 6 | Step 2106 | loss: 0.39350303057785874 | accuracy: 0.8255494505494504 \n",
      "Epoch 6 | Step 2107 | loss: 0.39463100485179736 | accuracy: 0.8250679347826085 \n",
      "Epoch 6 | Step 2108 | loss: 0.39631732240799933 | accuracy: 0.8245967741935483 \n",
      "Epoch 6 | Step 2109 | loss: 0.39512959534817554 | accuracy: 0.8254654255319147 \n",
      "Epoch 6 | Step 2110 | loss: 0.394502844308552 | accuracy: 0.8258223684210525 \n",
      "Epoch 6 | Step 2111 | loss: 0.3931989340732495 | accuracy: 0.8266601562499999 \n",
      "Epoch 6 | Step 2112 | loss: 0.3924867857977287 | accuracy: 0.8269974226804122 \n",
      "Epoch 6 | Step 2113 | loss: 0.393341456444896 | accuracy: 0.8260522959183672 \n",
      "Epoch 6 | Step 2114 | loss: 0.3926163544558515 | accuracy: 0.8263888888888887 \n",
      "Epoch 6 | Step 2115 | loss: 0.3935679230093956 | accuracy: 0.8256249999999998 \n",
      "Epoch 6 | Step 2116 | loss: 0.3938912595852767 | accuracy: 0.8256497524752474 \n",
      "Epoch 6 | Step 2117 | loss: 0.39421005313302954 | accuracy: 0.8253676470588234 \n",
      "Epoch 6 | Step 2118 | loss: 0.39484589684356763 | accuracy: 0.8250910194174755 \n",
      "Epoch 6 | Step 2119 | loss: 0.39468833947410953 | accuracy: 0.8257211538461537 \n",
      "Epoch 6 | Step 2120 | loss: 0.395357137350809 | accuracy: 0.8252976190476189 \n",
      "Epoch 6 | Step 2121 | loss: 0.39482399005934876 | accuracy: 0.8254716981132074 \n",
      "Epoch 6 | Step 2122 | loss: 0.39484625804090057 | accuracy: 0.8253504672897195 \n",
      "Epoch 6 | Step 2123 | loss: 0.3955382718532174 | accuracy: 0.8247974537037036 \n",
      "Epoch 6 | Step 2124 | loss: 0.39448432145862405 | accuracy: 0.8252580275229356 \n",
      "Epoch 6 | Step 2125 | loss: 0.39476706223054364 | accuracy: 0.8251420454545453 \n",
      "Epoch 6 | Step 2126 | loss: 0.39594170155825914 | accuracy: 0.8241835585585584 \n",
      "Epoch 6 | Step 2127 | loss: 0.3969180477516992 | accuracy: 0.8235212053571427 \n",
      "Epoch 6 | Step 2128 | loss: 0.3965066539502777 | accuracy: 0.8238384955752212 \n",
      "Epoch 6 | Step 2129 | loss: 0.3966026123155627 | accuracy: 0.823876096491228 \n",
      "Epoch 6 | Step 2130 | loss: 0.3965966406075851 | accuracy: 0.8237771739130434 \n",
      "Epoch 6 | Step 2131 | loss: 0.39605076662425337 | accuracy: 0.8242187499999999 \n",
      "Epoch 6 | Step 2132 | loss: 0.3956553780625009 | accuracy: 0.8242521367521366 \n",
      "Epoch 6 | Step 2133 | loss: 0.3962742006879742 | accuracy: 0.8238877118644067 \n",
      "Epoch 6 | Step 2134 | loss: 0.3969400522588682 | accuracy: 0.8235294117647057 \n",
      "Epoch 6 | Step 2135 | loss: 0.39665134673317276 | accuracy: 0.8238281249999999 \n",
      "Epoch 6 | Step 2136 | loss: 0.3960491192242331 | accuracy: 0.8241219008264462 \n",
      "Epoch 6 | Step 2137 | loss: 0.3963827627604125 | accuracy: 0.824154713114754 \n",
      "Epoch 6 | Step 2138 | loss: 0.3961486104058056 | accuracy: 0.824441056910569 \n",
      "Epoch 6 | Step 2139 | loss: 0.3968273305123852 | accuracy: 0.8238407258064515 \n",
      "Epoch 6 | Step 2140 | loss: 0.39673161363601683 | accuracy: 0.8241249999999999 \n",
      "Epoch 6 | Step 2141 | loss: 0.39680278868902297 | accuracy: 0.8241567460317459 \n",
      "Epoch 6 | Step 2142 | loss: 0.3973559558860899 | accuracy: 0.8236958661417322 \n",
      "Epoch 6 | Step 2143 | loss: 0.3969455170445144 | accuracy: 0.8240966796874999 \n",
      "Epoch 6 | Step 2144 | loss: 0.39752556718597115 | accuracy: 0.8232800387596898 \n",
      "Epoch 6 | Step 2145 | loss: 0.3972734334377142 | accuracy: 0.8237980769230768 \n",
      "Epoch 6 | Step 2146 | loss: 0.39755028668250747 | accuracy: 0.8235925572519083 \n",
      "Epoch 6 | Step 2147 | loss: 0.3976900168892109 | accuracy: 0.823153409090909 \n",
      "Epoch 6 | Step 2148 | loss: 0.3972794671255843 | accuracy: 0.8233082706766917 \n",
      "Epoch 6 | Step 2149 | loss: 0.3967226261078422 | accuracy: 0.8235774253731343 \n",
      "Epoch 6 | Step 2150 | loss: 0.39680938190884063 | accuracy: 0.8237268518518519 \n",
      "Epoch 6 | Step 2151 | loss: 0.3967319201020634 | accuracy: 0.82421875 \n",
      "Epoch 6 | Step 2152 | loss: 0.3974060109496987 | accuracy: 0.8237910583941606 \n",
      "Epoch 6 | Step 2153 | loss: 0.3969347530948943 | accuracy: 0.8241621376811594 \n",
      "Epoch 6 | Step 2154 | loss: 0.3972849080459677 | accuracy: 0.8240782374100719 \n",
      "Epoch 6 | Step 2155 | loss: 0.39761565689529693 | accuracy: 0.8237723214285714 \n",
      "Epoch 6 | Step 2156 | loss: 0.3979466749843976 | accuracy: 0.8236923758865248 \n",
      "Epoch 6 | Step 2157 | loss: 0.3977689577240339 | accuracy: 0.823393485915493 \n",
      "Epoch 6 | Step 2158 | loss: 0.3972576502319816 | accuracy: 0.8239729020979021 \n",
      "Epoch 6 | Step 2159 | loss: 0.3972773187690311 | accuracy: 0.8237847222222222 \n",
      "Epoch 6 | Step 2160 | loss: 0.39691268513942585 | accuracy: 0.8241379310344827 \n",
      "Epoch 6 | Step 2161 | loss: 0.3971680947770811 | accuracy: 0.823951198630137 \n",
      "Epoch 6 | Step 2162 | loss: 0.3972825916851459 | accuracy: 0.8242984693877551 \n",
      "Epoch 6 | Step 2163 | loss: 0.39694026233376684 | accuracy: 0.8246410472972973 \n",
      "Epoch 6 | Step 2164 | loss: 0.3969592766073726 | accuracy: 0.8247692953020134 \n",
      "Epoch 6 | Step 2165 | loss: 0.39639471888542177 | accuracy: 0.8248958333333333 \n",
      "Epoch 6 | Step 2166 | loss: 0.39633759461491314 | accuracy: 0.8251241721854303 \n",
      "Epoch 6 | Step 2167 | loss: 0.3970006996471631 | accuracy: 0.8248355263157894 \n",
      "Epoch 6 | Step 2168 | loss: 0.39766349239287035 | accuracy: 0.8247549019607843 \n",
      "Epoch 6 | Step 2169 | loss: 0.3969827104698528 | accuracy: 0.8251826298701299 \n",
      "Epoch 6 | Step 2170 | loss: 0.3959603464411151 | accuracy: 0.8258064516129032 \n",
      "Epoch 6 | Step 2171 | loss: 0.3954814965717303 | accuracy: 0.8260216346153846 \n",
      "Epoch 6 | Step 2172 | loss: 0.3953007576382084 | accuracy: 0.8261345541401274 \n",
      "Epoch 6 | Step 2173 | loss: 0.3950901939710484 | accuracy: 0.826443829113924 \n",
      "Epoch 6 | Step 2174 | loss: 0.39491166942899325 | accuracy: 0.8264544025157232 \n",
      "Epoch 6 | Step 2175 | loss: 0.39463627180084576 | accuracy: 0.8265625 \n",
      "Epoch 6 | Step 2176 | loss: 0.39431974800847325 | accuracy: 0.826766304347826 \n",
      "Epoch 6 | Step 2177 | loss: 0.3944244698425869 | accuracy: 0.8264853395061729 \n",
      "Epoch 6 | Step 2178 | loss: 0.393715471303536 | accuracy: 0.8267829754601227 \n",
      "Epoch 6 | Step 2179 | loss: 0.39359169844083663 | accuracy: 0.8266958841463414 \n",
      "Epoch 6 | Step 2180 | loss: 0.3936149220574985 | accuracy: 0.8265151515151515 \n",
      "Epoch 6 | Step 2181 | loss: 0.3945800776043569 | accuracy: 0.8258659638554217 \n",
      "Epoch 6 | Step 2182 | loss: 0.3941684323335121 | accuracy: 0.8262537425149701 \n",
      "Epoch 6 | Step 2183 | loss: 0.39400261223670974 | accuracy: 0.8264508928571429 \n",
      "Epoch 6 | Step 2184 | loss: 0.395044851320735 | accuracy: 0.8261834319526628 \n",
      "Epoch 6 | Step 2185 | loss: 0.39497093321645954 | accuracy: 0.8264705882352941 \n",
      "Epoch 6 | Step 2186 | loss: 0.3954226708377313 | accuracy: 0.8262061403508771 \n",
      "Epoch 6 | Step 2187 | loss: 0.3956504123675268 | accuracy: 0.825672238372093 \n",
      "Epoch 6 | Step 2188 | loss: 0.39454335163783466 | accuracy: 0.8264089595375722 \n",
      "Epoch 6 | Step 2189 | loss: 0.39480692096825293 | accuracy: 0.8261494252873564 \n",
      "Epoch 6 | Step 2190 | loss: 0.39473937000547127 | accuracy: 0.8263392857142857 \n",
      "Epoch 6 | Step 2191 | loss: 0.3946304312822493 | accuracy: 0.8264382102272727 \n",
      "Epoch 6 | Step 2192 | loss: 0.395263583478281 | accuracy: 0.8261829096045198 \n",
      "Epoch 6 | Step 2193 | loss: 0.3955323475130488 | accuracy: 0.8261060393258427 \n",
      "Epoch 6 | Step 2194 | loss: 0.3954418168387599 | accuracy: 0.8262918994413407 \n",
      "Epoch 6 | Step 2195 | loss: 0.39584878434737514 | accuracy: 0.8260416666666667 \n",
      "Epoch 6 | Step 2196 | loss: 0.3952958728727055 | accuracy: 0.8262258287292817 \n",
      "Epoch 6 | Step 2197 | loss: 0.3947807966352818 | accuracy: 0.8265796703296703 \n",
      "Epoch 6 | Step 2198 | loss: 0.3943471286466212 | accuracy: 0.826844262295082 \n",
      "Epoch 6 | Step 2199 | loss: 0.39462791383266443 | accuracy: 0.826766304347826 \n",
      "Epoch 6 | Step 2200 | loss: 0.3945181347228385 | accuracy: 0.8267736486486487 \n",
      "Epoch 6 | Step 2201 | loss: 0.39422167084550336 | accuracy: 0.8269489247311828 \n",
      "Epoch 6 | Step 2202 | loss: 0.394709725112201 | accuracy: 0.8267881016042781 \n",
      "Epoch 6 | Step 2203 | loss: 0.39456389305439393 | accuracy: 0.8268783244680851 \n",
      "Epoch 6 | Step 2204 | loss: 0.3941499354347349 | accuracy: 0.8272156084656085 \n",
      "Epoch 6 | Step 2205 | loss: 0.3939447782541575 | accuracy: 0.8273848684210526 \n",
      "Epoch 6 | Step 2206 | loss: 0.39421536566699356 | accuracy: 0.8273887434554974 \n",
      "Epoch 6 | Step 2207 | loss: 0.39429176102081925 | accuracy: 0.8274739583333334 \n",
      "Epoch 6 | Step 2208 | loss: 0.3949839658070104 | accuracy: 0.8271534974093264 \n",
      "Epoch 6 | Step 2209 | loss: 0.3944032696104541 | accuracy: 0.8274001288659794 \n",
      "Epoch 6 | Step 2210 | loss: 0.3949878979951907 | accuracy: 0.8270032051282051 \n",
      "Epoch 6 | Step 2211 | loss: 0.3948158237094781 | accuracy: 0.8272480867346939 \n",
      "Epoch 6 | Step 2212 | loss: 0.394548972548567 | accuracy: 0.8273318527918782 \n",
      "Epoch 6 | Step 2213 | loss: 0.39481342169973577 | accuracy: 0.8270991161616161 \n",
      "Epoch 6 | Step 2214 | loss: 0.3953860482977862 | accuracy: 0.8268687185929648 \n",
      "Epoch 6 | Step 2215 | loss: 0.3950168296694755 | accuracy: 0.827265625 \n",
      "Epoch 6 | Step 2216 | loss: 0.3949277681201251 | accuracy: 0.8271144278606966 \n",
      "Epoch 6 | Step 2217 | loss: 0.3951996885018773 | accuracy: 0.8269647277227723 \n",
      "Epoch 6 | Step 2218 | loss: 0.39468037994037114 | accuracy: 0.8273552955665024 \n",
      "Epoch 6 | Step 2219 | loss: 0.3950216764328526 | accuracy: 0.8270526960784313 \n",
      "Epoch 6 | Step 2220 | loss: 0.3952419315896382 | accuracy: 0.8267530487804878 \n",
      "Epoch 6 | Step 2221 | loss: 0.3949845012241196 | accuracy: 0.8268355582524272 \n",
      "Epoch 6 | Step 2222 | loss: 0.39489035157189845 | accuracy: 0.8268417874396136 \n",
      "Epoch 6 | Step 2223 | loss: 0.3945488398178265 | accuracy: 0.8269981971153846 \n",
      "Epoch 6 | Step 2224 | loss: 0.394852973485107 | accuracy: 0.8270783492822966 \n",
      "Epoch 6 | Step 2225 | loss: 0.394422692486218 | accuracy: 0.8273809523809523 \n",
      "Epoch 6 | Step 2226 | loss: 0.39443005473127857 | accuracy: 0.8273104265402843 \n",
      "Epoch 6 | Step 2227 | loss: 0.39459999763178366 | accuracy: 0.8271668632075472 \n",
      "Epoch 6 | Step 2228 | loss: 0.39418244389860835 | accuracy: 0.8273180751173709 \n",
      "Epoch 6 | Step 2229 | loss: 0.3937583351246664 | accuracy: 0.827759929906542 \n",
      "Epoch 6 | Step 2230 | loss: 0.39386079242063116 | accuracy: 0.8275436046511628 \n",
      "Epoch 6 | Step 2231 | loss: 0.394230714412751 | accuracy: 0.8274016203703703 \n",
      "Epoch 6 | Step 2232 | loss: 0.39510972282853535 | accuracy: 0.8267569124423964 \n",
      "Epoch 6 | Step 2233 | loss: 0.39496648038199184 | accuracy: 0.8269065366972477 \n",
      "Epoch 6 | Step 2234 | loss: 0.39474576684437923 | accuracy: 0.826912100456621 \n",
      "Epoch 6 | Step 2235 | loss: 0.3947315153750506 | accuracy: 0.826846590909091 \n",
      "Epoch 6 | Step 2236 | loss: 0.3943041002049165 | accuracy: 0.827064479638009 \n",
      "Epoch 6 | Step 2237 | loss: 0.3940189874118512 | accuracy: 0.8274915540540541 \n",
      "Epoch 6 | Step 2238 | loss: 0.39420005264838176 | accuracy: 0.827564461883408 \n",
      "Epoch 6 | Step 2239 | loss: 0.39418283078287325 | accuracy: 0.8274274553571429 \n",
      "Epoch 6 | Step 2240 | loss: 0.39485035684373637 | accuracy: 0.8271527777777777 \n",
      "Epoch 6 | Step 2241 | loss: 0.3949774973160397 | accuracy: 0.8272953539823009 \n",
      "Epoch 6 | Step 2242 | loss: 0.3949742444548837 | accuracy: 0.8272301762114538 \n",
      "Epoch 6 | Step 2243 | loss: 0.3947476579954749 | accuracy: 0.827234100877193 \n",
      "Epoch 6 | Step 2244 | loss: 0.39432286214099693 | accuracy: 0.8275791484716157 \n",
      "Epoch 6 | Step 2245 | loss: 0.39387148178142045 | accuracy: 0.8277173913043478 \n",
      "Epoch 6 | Step 2246 | loss: 0.39441776611072155 | accuracy: 0.8275162337662337 \n",
      "Epoch 6 | Step 2247 | loss: 0.3938262891666642 | accuracy: 0.8277882543103449 \n",
      "Epoch 6 | Step 2248 | loss: 0.39395641743369364 | accuracy: 0.8277226394849786 \n",
      "Epoch 6 | Step 2249 | loss: 0.39407964598419315 | accuracy: 0.827590811965812 \n",
      "Epoch 6 | Step 2250 | loss: 0.3937633470017859 | accuracy: 0.8277925531914894 \n",
      "Epoch 6 | Step 2251 | loss: 0.3935959307571588 | accuracy: 0.8278601694915254 \n",
      "Epoch 6 | Step 2252 | loss: 0.3938374378510165 | accuracy: 0.8276635021097046 \n",
      "Epoch 6 | Step 2253 | loss: 0.39419353171056054 | accuracy: 0.8275997899159664 \n",
      "Epoch 6 | Step 2254 | loss: 0.3941051529790566 | accuracy: 0.8276019874476988 \n",
      "Epoch 6 | Step 2255 | loss: 0.3938622699429591 | accuracy: 0.8276041666666667 \n",
      "Epoch 6 | Step 2256 | loss: 0.3940794799337743 | accuracy: 0.8272173236514523 \n",
      "Epoch 6 | Step 2257 | loss: 0.394212940753984 | accuracy: 0.8271565082644629 \n",
      "Epoch 6 | Step 2258 | loss: 0.39410436901536 | accuracy: 0.8273533950617284 \n",
      "Epoch 6 | Step 2259 | loss: 0.3935233399760527 | accuracy: 0.8276127049180327 \n",
      "Epoch 6 | Step 2260 | loss: 0.3933623692210839 | accuracy: 0.8278061224489796 \n",
      "Epoch 6 | Step 2261 | loss: 0.3930470707213006 | accuracy: 0.8279344512195121 \n",
      "Epoch 6 | Step 2262 | loss: 0.39292007986350574 | accuracy: 0.8280617408906883 \n",
      "Epoch 6 | Step 2263 | loss: 0.39310787029324035 | accuracy: 0.8279989919354839 \n",
      "Epoch 6 | Step 2264 | loss: 0.3934652445067363 | accuracy: 0.8278112449799196 \n",
      "Epoch 6 | Step 2265 | loss: 0.3931410168409347 | accuracy: 0.827875 \n",
      "Epoch 6 | Step 2266 | loss: 0.3931873913305214 | accuracy: 0.8277514940239044 \n",
      "Epoch 6 | Step 2267 | loss: 0.39358780757775375 | accuracy: 0.8275049603174603 \n",
      "Epoch 6 | Step 2268 | loss: 0.3936441848164961 | accuracy: 0.8275691699604744 \n",
      "Epoch 6 | Step 2269 | loss: 0.39358853566364976 | accuracy: 0.8275098425196851 \n",
      "Epoch 6 | Step 2270 | loss: 0.39346633366509975 | accuracy: 0.8276348039215686 \n",
      "Epoch 6 | Step 2271 | loss: 0.39348722924478347 | accuracy: 0.82757568359375 \n",
      "Epoch 6 | Step 2272 | loss: 0.3936479985713958 | accuracy: 0.8272738326848249 \n",
      "Epoch 6 | Step 2273 | loss: 0.39381156053191924 | accuracy: 0.827156007751938 \n",
      "Epoch 6 | Step 2274 | loss: 0.3939721203448689 | accuracy: 0.8269787644787645 \n",
      "Epoch 6 | Step 2275 | loss: 0.3940559748273629 | accuracy: 0.8268629807692308 \n",
      "Epoch 6 | Step 2276 | loss: 0.3938013170185673 | accuracy: 0.8270474137931034 \n",
      "Epoch 6 | Step 2277 | loss: 0.3944316336899313 | accuracy: 0.8268129770992366 \n",
      "Epoch 6 | Step 2278 | loss: 0.39425694285236834 | accuracy: 0.8269367870722434 \n",
      "Epoch 6 | Step 2279 | loss: 0.39405804093588476 | accuracy: 0.8270004734848485 \n",
      "Epoch 6 | Step 2280 | loss: 0.3938947447066037 | accuracy: 0.8271226415094339 \n",
      "Epoch 6 | Step 2281 | loss: 0.39395842303458906 | accuracy: 0.8270676691729323 \n",
      "Epoch 6 | Step 2282 | loss: 0.3937588242555825 | accuracy: 0.827247191011236 \n",
      "Epoch 6 | Step 2283 | loss: 0.3937677022681307 | accuracy: 0.8271338619402985 \n",
      "Epoch 6 | Step 2284 | loss: 0.39363259243256093 | accuracy: 0.8271375464684015 \n",
      "Epoch 6 | Step 2285 | loss: 0.3936200943258073 | accuracy: 0.8272569444444445 \n",
      "Epoch 6 | Step 2286 | loss: 0.39356002310545235 | accuracy: 0.8272024907749078 \n",
      "Epoch 6 | Step 2287 | loss: 0.39337014209698223 | accuracy: 0.8273782169117648 \n",
      "Epoch 6 | Step 2288 | loss: 0.3935094249772501 | accuracy: 0.8273237179487181 \n",
      "Epoch 6 | Step 2289 | loss: 0.39368398759486894 | accuracy: 0.8273836678832118 \n",
      "Epoch 6 | Step 2290 | loss: 0.39345718394626267 | accuracy: 0.8275568181818183 \n",
      "Epoch 6 | Step 2291 | loss: 0.3938797292286071 | accuracy: 0.8273890398550726 \n",
      "Epoch 6 | Step 2292 | loss: 0.39373611360250393 | accuracy: 0.8275045126353792 \n",
      "Epoch 6 | Step 2293 | loss: 0.3935697536459929 | accuracy: 0.8275629496402879 \n",
      "Epoch 6 | Step 2294 | loss: 0.39324608797668126 | accuracy: 0.8277889784946237 \n",
      "Epoch 6 | Step 2295 | loss: 0.3931636239801134 | accuracy: 0.8276785714285715 \n",
      "Epoch 6 | Step 2296 | loss: 0.3929519845285449 | accuracy: 0.8277913701067616 \n",
      "Epoch 6 | Step 2297 | loss: 0.3927311318140503 | accuracy: 0.8277925531914895 \n",
      "Epoch 6 | Step 2298 | loss: 0.39269730543500536 | accuracy: 0.8276280918727916 \n",
      "Epoch 6 | Step 2299 | loss: 0.39230041499708734 | accuracy: 0.8279599471830987 \n",
      "Epoch 6 | Step 2300 | loss: 0.3922165125085596 | accuracy: 0.8279605263157895 \n",
      "Epoch 6 | Step 2301 | loss: 0.3916882577684375 | accuracy: 0.8281796328671329 \n",
      "Epoch 6 | Step 2302 | loss: 0.3917703170601914 | accuracy: 0.8280161149825785 \n",
      "Epoch 6 | Step 2303 | loss: 0.3914772032035721 | accuracy: 0.8280707465277779 \n",
      "Epoch 6 | Step 2304 | loss: 0.39212069070050454 | accuracy: 0.8279087370242215 \n",
      "Epoch 6 | Step 2305 | loss: 0.3918019080984181 | accuracy: 0.8281250000000001 \n",
      "Epoch 6 | Step 2306 | loss: 0.39233551934822314 | accuracy: 0.8278028350515465 \n",
      "Epoch 6 | Step 2307 | loss: 0.3922042220014415 | accuracy: 0.8278574486301371 \n",
      "Epoch 6 | Step 2308 | loss: 0.3921675772593696 | accuracy: 0.8279650170648465 \n",
      "Epoch 6 | Step 2309 | loss: 0.3923294977063224 | accuracy: 0.8278061224489797 \n",
      "Epoch 6 | Step 2310 | loss: 0.3922237000222933 | accuracy: 0.8275953389830509 \n",
      "Epoch 6 | Step 2311 | loss: 0.39227231984605654 | accuracy: 0.8277027027027029 \n",
      "Epoch 6 | Step 2312 | loss: 0.39214788452543387 | accuracy: 0.8278093434343436 \n",
      "Epoch 6 | Step 2313 | loss: 0.3919604343655925 | accuracy: 0.827915268456376 \n",
      "Epoch 6 | Step 2314 | loss: 0.39194877739734074 | accuracy: 0.8279682274247493 \n",
      "Epoch 6 | Step 2315 | loss: 0.39164134204387663 | accuracy: 0.8282291666666668 \n",
      "Epoch 6 | Step 2316 | loss: 0.39205105063131085 | accuracy: 0.8279692691029902 \n",
      "Epoch 6 | Step 2317 | loss: 0.39193916962241493 | accuracy: 0.8279697847682121 \n",
      "Epoch 6 | Step 2318 | loss: 0.3917437741662016 | accuracy: 0.8281765676567658 \n",
      "Epoch 6 | Step 2319 | loss: 0.39189784866022437 | accuracy: 0.8280222039473686 \n",
      "Epoch 6 | Step 2320 | loss: 0.3916944358192506 | accuracy: 0.8280737704918034 \n",
      "Epoch 6 | Step 2321 | loss: 0.3916091653061848 | accuracy: 0.8281250000000001 \n",
      "Epoch 6 | Step 2322 | loss: 0.39208722143685776 | accuracy: 0.8279214169381108 \n",
      "Epoch 6 | Step 2323 | loss: 0.39189630137248466 | accuracy: 0.8279728084415585 \n",
      "Epoch 6 | Step 2324 | loss: 0.39154544810261144 | accuracy: 0.8282261326860842 \n",
      "Epoch 6 | Step 2325 | loss: 0.3914429033956219 | accuracy: 0.8283770161290323 \n",
      "Epoch 6 | Step 2326 | loss: 0.3913262534371525 | accuracy: 0.8285771704180064 \n",
      "Epoch 6 | Step 2327 | loss: 0.39134119957303376 | accuracy: 0.8285256410256411 \n",
      "Epoch 6 | Step 2328 | loss: 0.391059397698972 | accuracy: 0.8286242012779552 \n",
      "Epoch 6 | Step 2329 | loss: 0.39135274243582574 | accuracy: 0.8285230891719745 \n",
      "Epoch 6 | Step 2330 | loss: 0.3917532940705616 | accuracy: 0.8284722222222223 \n",
      "Epoch 6 | Step 2331 | loss: 0.3917980458163007 | accuracy: 0.8285205696202531 \n",
      "Epoch 6 | Step 2332 | loss: 0.39154327019155954 | accuracy: 0.8286671924290221 \n",
      "Epoch 6 | Step 2333 | loss: 0.39172779707788663 | accuracy: 0.8285180817610063 \n",
      "Epoch 6 | Step 2334 | loss: 0.39167090531053206 | accuracy: 0.8285658307210031 \n",
      "Epoch 6 | Step 2335 | loss: 0.3914412235841154 | accuracy: 0.828662109375 \n",
      "Epoch 6 | Step 2336 | loss: 0.3914825519854405 | accuracy: 0.8286117601246106 \n",
      "Epoch 6 | Step 2337 | loss: 0.3918715747802153 | accuracy: 0.828513198757764 \n",
      "Epoch 6 | Step 2338 | loss: 0.391674449015697 | accuracy: 0.8285603715170279 \n",
      "Epoch 6 | Step 2339 | loss: 0.39157977194329824 | accuracy: 0.8286072530864198 \n",
      "Epoch 6 | Step 2340 | loss: 0.39160603266495914 | accuracy: 0.8284134615384615 \n",
      "Epoch 6 | Step 2341 | loss: 0.39142761969127526 | accuracy: 0.8286042944785276 \n",
      "Epoch 6 | Step 2342 | loss: 0.39147630789593435 | accuracy: 0.8286028287461774 \n",
      "Epoch 6 | Step 2343 | loss: 0.39151549902631 | accuracy: 0.8286013719512195 \n",
      "Epoch 6 | Step 2344 | loss: 0.3919487689766114 | accuracy: 0.8282674772036475 \n",
      "Epoch 6 | Step 2345 | loss: 0.3920297006766 | accuracy: 0.828219696969697 \n",
      "Epoch 6 | Step 2346 | loss: 0.392024507965566 | accuracy: 0.8282194108761329 \n",
      "Epoch 6 | Step 2347 | loss: 0.3918684329613144 | accuracy: 0.8283603162650602 \n",
      "Epoch 6 | Step 2348 | loss: 0.39174791221862065 | accuracy: 0.8285003753753754 \n",
      "Epoch 6 | Step 2349 | loss: 0.3918722315641219 | accuracy: 0.828499251497006 \n",
      "Epoch 6 | Step 2350 | loss: 0.3917264674136886 | accuracy: 0.828544776119403 \n",
      "Epoch 6 | Step 2351 | loss: 0.39150760234111814 | accuracy: 0.8286365327380952 \n",
      "Epoch 6 | Step 2352 | loss: 0.3916277956184363 | accuracy: 0.8285422848664689 \n",
      "Epoch 6 | Step 2353 | loss: 0.3916068492380118 | accuracy: 0.8287259615384616 \n",
      "Epoch 6 | Step 2354 | loss: 0.3914675004890181 | accuracy: 0.8288624631268436 \n",
      "Epoch 6 | Step 2355 | loss: 0.3910987571758381 | accuracy: 0.8289981617647059 \n",
      "Epoch 6 | Step 2356 | loss: 0.3907869397894726 | accuracy: 0.8291788856304986 \n",
      "Epoch 6 | Step 2357 | loss: 0.39069795721804174 | accuracy: 0.8291301169590644 \n",
      "Epoch 6 | Step 2358 | loss: 0.3906701486937852 | accuracy: 0.8290816326530612 \n",
      "Epoch 6 | Step 2359 | loss: 0.3903736582155836 | accuracy: 0.8291696947674418 \n",
      "Epoch 6 | Step 2360 | loss: 0.39050270664519143 | accuracy: 0.8291213768115943 \n",
      "Epoch 6 | Step 2361 | loss: 0.3904164238816739 | accuracy: 0.8292088150289018 \n",
      "Epoch 6 | Step 2362 | loss: 0.38999850743098613 | accuracy: 0.8294758645533141 \n",
      "Epoch 6 | Step 2363 | loss: 0.39036888449356455 | accuracy: 0.8292923850574713 \n",
      "Epoch 6 | Step 2364 | loss: 0.3902127857194587 | accuracy: 0.8293338108882522 \n",
      "Epoch 6 | Step 2365 | loss: 0.390040116395269 | accuracy: 0.8292410714285714 \n",
      "Epoch 6 | Step 2366 | loss: 0.3898143438871768 | accuracy: 0.8294159544159544 \n",
      "Epoch 6 | Step 2367 | loss: 0.3898858532986856 | accuracy: 0.8293235085227273 \n",
      "Epoch 6 | Step 2368 | loss: 0.3897338379543832 | accuracy: 0.8294529036827195 \n",
      "Epoch 6 | Step 2369 | loss: 0.3895923540753832 | accuracy: 0.829537429378531 \n",
      "Epoch 6 | Step 2370 | loss: 0.38948437940906455 | accuracy: 0.8295774647887324 \n",
      "Epoch 6 | Step 2371 | loss: 0.3892595121699771 | accuracy: 0.8296611657303371 \n",
      "Epoch 6 | Step 2372 | loss: 0.3891721483038252 | accuracy: 0.8297443977591037 \n",
      "Epoch 6 | Step 2373 | loss: 0.38929472863674147 | accuracy: 0.8295652932960894 \n",
      "Epoch 6 | Step 2374 | loss: 0.38919664068474397 | accuracy: 0.829691852367688 \n",
      "Epoch 6 | Step 2375 | loss: 0.3890880276759464 | accuracy: 0.8297309027777777 \n",
      "Epoch 6 | Step 2376 | loss: 0.389353160217528 | accuracy: 0.8294234764542936 \n",
      "Epoch 6 | Step 2377 | loss: 0.38929733568133557 | accuracy: 0.8294630524861878 \n",
      "Epoch 6 | Step 2378 | loss: 0.389309364409486 | accuracy: 0.8294593663911846 \n",
      "Epoch 6 | Step 2379 | loss: 0.38920298824598487 | accuracy: 0.8294986263736264 \n",
      "Epoch 6 | Step 2380 | loss: 0.3890871587681442 | accuracy: 0.8294948630136987 \n",
      "Epoch 6 | Step 2381 | loss: 0.3889185715405666 | accuracy: 0.8294911202185792 \n",
      "Epoch 6 | Step 2382 | loss: 0.3890559511710901 | accuracy: 0.8294448228882834 \n",
      "Epoch 6 | Step 2383 | loss: 0.3888780749200477 | accuracy: 0.8295686141304348 \n",
      "Epoch 6 | Step 2384 | loss: 0.3889780366808417 | accuracy: 0.8294800135501355 \n",
      "Epoch 6 | Step 2385 | loss: 0.3891553974634891 | accuracy: 0.8292652027027027 \n",
      "Epoch 6 | Step 2386 | loss: 0.3893402573875981 | accuracy: 0.8290515498652291 \n",
      "Epoch 6 | Step 2387 | loss: 0.38995973653690774 | accuracy: 0.8288390456989247 \n",
      "Epoch 6 | Step 2388 | loss: 0.390069725126747 | accuracy: 0.8287533512064343 \n",
      "Epoch 6 | Step 2389 | loss: 0.389795920507793 | accuracy: 0.8288352272727273 \n",
      "Epoch 6 | Step 2390 | loss: 0.38946690162022896 | accuracy: 0.8290416666666667 \n",
      "Epoch 6 | Step 2391 | loss: 0.3894887654546726 | accuracy: 0.8289145611702128 \n",
      "Epoch 6 | Step 2392 | loss: 0.38937218522835776 | accuracy: 0.828829575596817 \n",
      "Epoch 6 | Step 2393 | loss: 0.3893731375219959 | accuracy: 0.8286210317460317 \n",
      "Epoch 6 | Step 2394 | loss: 0.3890294454657621 | accuracy: 0.8287846306068601 \n",
      "Epoch 6 | Step 2395 | loss: 0.38885202313724304 | accuracy: 0.8288651315789474 \n",
      "Epoch 6 | Step 2396 | loss: 0.388709387050213 | accuracy: 0.8289452099737533 \n",
      "Epoch 6 | Step 2397 | loss: 0.3884500422714891 | accuracy: 0.8289839659685864 \n",
      "Epoch 6 | Step 2398 | loss: 0.3883367302212328 | accuracy: 0.8289817232375979 \n",
      "Epoch 6 | Step 2399 | loss: 0.3884105438676972 | accuracy: 0.8289794921875 \n",
      "Epoch 6 | Step 2400 | loss: 0.38864713071228607 | accuracy: 0.8288961038961039 \n",
      "Epoch 6 | Step 2401 | loss: 0.38893016315803614 | accuracy: 0.828732189119171 \n",
      "Epoch 6 | Step 2402 | loss: 0.38899911720623326 | accuracy: 0.8287709948320413 \n",
      "Epoch 6 | Step 2403 | loss: 0.3888261193774409 | accuracy: 0.8288498711340206 \n",
      "Epoch 6 | Step 2404 | loss: 0.3889719333624164 | accuracy: 0.8286873393316195 \n",
      "Epoch 6 | Step 2405 | loss: 0.3887751557123965 | accuracy: 0.8288461538461539 \n",
      "Epoch 6 | Step 2406 | loss: 0.38891718584253343 | accuracy: 0.8288043478260869 \n",
      "Epoch 6 | Step 2407 | loss: 0.3888384839709923 | accuracy: 0.8287228954081632 \n",
      "Epoch 6 | Step 2408 | loss: 0.3886491343871933 | accuracy: 0.828920165394402 \n",
      "Epoch 6 | Step 2409 | loss: 0.3887608257798373 | accuracy: 0.8288388324873096 \n",
      "Epoch 6 | Step 2410 | loss: 0.3887275962889948 | accuracy: 0.8289161392405063 \n",
      "Epoch 6 | Step 2411 | loss: 0.3886383090807933 | accuracy: 0.8287563131313131 \n",
      "Epoch 6 | Step 2412 | loss: 0.38876842056173505 | accuracy: 0.8285972921914357 \n",
      "Epoch 6 | Step 2413 | loss: 0.38895504154152594 | accuracy: 0.8285175879396985 \n",
      "Epoch 6 | Step 2414 | loss: 0.3887966652412461 | accuracy: 0.8286340852130326 \n",
      "Epoch 6 | Step 2415 | loss: 0.38902782447636114 | accuracy: 0.8284375 \n",
      "Epoch 6 | Step 2416 | loss: 0.3890682297603149 | accuracy: 0.8284756857855362 \n",
      "Epoch 6 | Step 2417 | loss: 0.38946843436404827 | accuracy: 0.828241604477612 \n",
      "Epoch 6 | Step 2418 | loss: 0.38932000843821907 | accuracy: 0.8283255433030519 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.5292806029319763 | accuracy: 0.703125 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.530938595533371 | accuracy: 0.703125 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4805901249249776 | accuracy: 0.7447916666666666 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.48021499067544937 | accuracy: 0.7578125 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.48031037449836733 | accuracy: 0.75625 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4708578884601593 | accuracy: 0.7604166666666666 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4648913655962263 | accuracy: 0.7678571428571429 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4594617709517479 | accuracy: 0.76953125 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4537951615121629 | accuracy: 0.7708333333333334 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.45447429120540617 | accuracy: 0.778125 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.45211657881736755 | accuracy: 0.7855113636363636 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4450989415248235 | accuracy: 0.7890625 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.446737860257809 | accuracy: 0.7872596153846154 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.44649410460676464 | accuracy: 0.7890625 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4391672690709432 | accuracy: 0.7927083333333333 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4379920344799757 | accuracy: 0.791015625 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.44773266070029316 | accuracy: 0.7876838235294118 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.44445477922757465 | accuracy: 0.7873263888888888 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4466073026782588 | accuracy: 0.787828947368421 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4440972775220871 | accuracy: 0.7875 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.444551618326278 | accuracy: 0.7886904761904762 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4408870515498248 | accuracy: 0.7911931818181818 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.44464700507081073 | accuracy: 0.7880434782608695 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4477038246889909 | accuracy: 0.7858072916666666 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.449535973072052 | accuracy: 0.785625 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4444785828773792 | accuracy: 0.7884615384615384 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4427579277091556 | accuracy: 0.7899305555555556 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4400445265429361 | accuracy: 0.7907366071428571 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.44124001264572144 | accuracy: 0.7898706896551724 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4412227362394333 | accuracy: 0.7916666666666666 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4379994792322959 | accuracy: 0.7933467741935484 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.433211425319314 | accuracy: 0.796875 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4321807198452227 | accuracy: 0.7987689393939394 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4389980111052008 | accuracy: 0.7950367647058824 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.43813120211873735 | accuracy: 0.7950892857142857 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.43562403900755775 | accuracy: 0.7964409722222222 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4373580837571943 | accuracy: 0.7964527027027027 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4376702794903203 | accuracy: 0.795641447368421 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4362336916801257 | accuracy: 0.796073717948718 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4375538147985935 | accuracy: 0.7953125 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.43882504977831027 | accuracy: 0.7934451219512195 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.43640181918938953 | accuracy: 0.7942708333333334 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.43690371998520783 | accuracy: 0.7928779069767442 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4371822029352188 | accuracy: 0.7922585227272727 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.43949320448769463 | accuracy: 0.7905948069360521 \n",
      "Epoch 7 | Step 2419 | loss: 0.33357128500938416 | accuracy: 0.859375 \n",
      "Epoch 7 | Step 2420 | loss: 0.3890061229467392 | accuracy: 0.8359375 \n",
      "Epoch 7 | Step 2421 | loss: 0.3458743194739024 | accuracy: 0.859375 \n",
      "Epoch 7 | Step 2422 | loss: 0.34410200268030167 | accuracy: 0.859375 \n",
      "Epoch 7 | Step 2423 | loss: 0.34110747575759887 | accuracy: 0.859375 \n",
      "Epoch 7 | Step 2424 | loss: 0.34948670864105225 | accuracy: 0.8541666666666666 \n",
      "Epoch 7 | Step 2425 | loss: 0.3534889646938869 | accuracy: 0.8549107142857143 \n",
      "Epoch 7 | Step 2426 | loss: 0.36948825418949127 | accuracy: 0.849609375 \n",
      "Epoch 7 | Step 2427 | loss: 0.3634063204129537 | accuracy: 0.8472222222222222 \n",
      "Epoch 7 | Step 2428 | loss: 0.3799370527267456 | accuracy: 0.8375 \n",
      "Epoch 7 | Step 2429 | loss: 0.37485319105061615 | accuracy: 0.8394886363636364 \n",
      "Epoch 7 | Step 2430 | loss: 0.3867508644858996 | accuracy: 0.8294270833333334 \n",
      "Epoch 7 | Step 2431 | loss: 0.38296184631494373 | accuracy: 0.8341346153846154 \n",
      "Epoch 7 | Step 2432 | loss: 0.3873595488922937 | accuracy: 0.8325892857142857 \n",
      "Epoch 7 | Step 2433 | loss: 0.38028319279352824 | accuracy: 0.8375 \n",
      "Epoch 7 | Step 2434 | loss: 0.37081361934542656 | accuracy: 0.8427734375 \n",
      "Epoch 7 | Step 2435 | loss: 0.3700754922979018 | accuracy: 0.84375 \n",
      "Epoch 7 | Step 2436 | loss: 0.37291187875800663 | accuracy: 0.8385416666666666 \n",
      "Epoch 7 | Step 2437 | loss: 0.37055412405415583 | accuracy: 0.8379934210526315 \n",
      "Epoch 7 | Step 2438 | loss: 0.3710961788892746 | accuracy: 0.8390625 \n",
      "Epoch 7 | Step 2439 | loss: 0.37175640605744864 | accuracy: 0.8363095238095238 \n",
      "Epoch 7 | Step 2440 | loss: 0.37133009189909155 | accuracy: 0.8373579545454546 \n",
      "Epoch 7 | Step 2441 | loss: 0.3687933553820071 | accuracy: 0.8383152173913043 \n",
      "Epoch 7 | Step 2442 | loss: 0.368079487234354 | accuracy: 0.8372395833333334 \n",
      "Epoch 7 | Step 2443 | loss: 0.3642692768573761 | accuracy: 0.84 \n",
      "Epoch 7 | Step 2444 | loss: 0.3667541008729201 | accuracy: 0.8377403846153846 \n",
      "Epoch 7 | Step 2445 | loss: 0.3668612043062846 | accuracy: 0.8379629629629629 \n",
      "Epoch 7 | Step 2446 | loss: 0.36085277050733566 | accuracy: 0.8415178571428571 \n",
      "Epoch 7 | Step 2447 | loss: 0.3602729285585469 | accuracy: 0.8415948275862069 \n",
      "Epoch 7 | Step 2448 | loss: 0.36201108594735465 | accuracy: 0.8411458333333334 \n",
      "Epoch 7 | Step 2449 | loss: 0.36097416858519277 | accuracy: 0.842741935483871 \n",
      "Epoch 7 | Step 2450 | loss: 0.3619709303602576 | accuracy: 0.84228515625 \n",
      "Epoch 7 | Step 2451 | loss: 0.3659142797643488 | accuracy: 0.8409090909090909 \n",
      "Epoch 7 | Step 2452 | loss: 0.36720609489609213 | accuracy: 0.8405330882352942 \n",
      "Epoch 7 | Step 2453 | loss: 0.3682320484093257 | accuracy: 0.8401785714285714 \n",
      "Epoch 7 | Step 2454 | loss: 0.3711223834090763 | accuracy: 0.8394097222222222 \n",
      "Epoch 7 | Step 2455 | loss: 0.3698555174711588 | accuracy: 0.8386824324324325 \n",
      "Epoch 7 | Step 2456 | loss: 0.36831001702107874 | accuracy: 0.8388157894736842 \n",
      "Epoch 7 | Step 2457 | loss: 0.365929467555804 | accuracy: 0.8413461538461539 \n",
      "Epoch 7 | Step 2458 | loss: 0.36453534439206114 | accuracy: 0.841796875 \n",
      "Epoch 7 | Step 2459 | loss: 0.36499032959705435 | accuracy: 0.8422256097560976 \n",
      "Epoch 7 | Step 2460 | loss: 0.36361077569779887 | accuracy: 0.8430059523809523 \n",
      "Epoch 7 | Step 2461 | loss: 0.3616968053717945 | accuracy: 0.8433866279069767 \n",
      "Epoch 7 | Step 2462 | loss: 0.36072682453827415 | accuracy: 0.8423295454545454 \n",
      "Epoch 7 | Step 2463 | loss: 0.3629776418209075 | accuracy: 0.840625 \n",
      "Epoch 7 | Step 2464 | loss: 0.3630916230056596 | accuracy: 0.8403532608695652 \n",
      "Epoch 7 | Step 2465 | loss: 0.36251856862230497 | accuracy: 0.8407579787234043 \n",
      "Epoch 7 | Step 2466 | loss: 0.3641697838902473 | accuracy: 0.8401692708333334 \n",
      "Epoch 7 | Step 2467 | loss: 0.36239016846734645 | accuracy: 0.8408801020408163 \n",
      "Epoch 7 | Step 2468 | loss: 0.3628395038843154 | accuracy: 0.840625 \n",
      "Epoch 7 | Step 2469 | loss: 0.3643447125659269 | accuracy: 0.8400735294117647 \n",
      "Epoch 7 | Step 2470 | loss: 0.3666235609696461 | accuracy: 0.8380408653846154 \n",
      "Epoch 7 | Step 2471 | loss: 0.36555814405657205 | accuracy: 0.8381485849056604 \n",
      "Epoch 7 | Step 2472 | loss: 0.3642357516067999 | accuracy: 0.8394097222222222 \n",
      "Epoch 7 | Step 2473 | loss: 0.36168552853844377 | accuracy: 0.8409090909090909 \n",
      "Epoch 7 | Step 2474 | loss: 0.3629790640303066 | accuracy: 0.8406808035714286 \n",
      "Epoch 7 | Step 2475 | loss: 0.3621300521649812 | accuracy: 0.8412828947368421 \n",
      "Epoch 7 | Step 2476 | loss: 0.36419150849868503 | accuracy: 0.8405172413793104 \n",
      "Epoch 7 | Step 2477 | loss: 0.36448275335764474 | accuracy: 0.8408368644067796 \n",
      "Epoch 7 | Step 2478 | loss: 0.36569536775350564 | accuracy: 0.8401041666666667 \n",
      "Epoch 7 | Step 2479 | loss: 0.366076863691455 | accuracy: 0.8393954918032787 \n",
      "Epoch 7 | Step 2480 | loss: 0.3661018869569224 | accuracy: 0.8389616935483871 \n",
      "Epoch 7 | Step 2481 | loss: 0.3656658203828902 | accuracy: 0.8392857142857143 \n",
      "Epoch 7 | Step 2482 | loss: 0.36338775535114104 | accuracy: 0.8408203125 \n",
      "Epoch 7 | Step 2483 | loss: 0.36401894665681395 | accuracy: 0.8408653846153846 \n",
      "Epoch 7 | Step 2484 | loss: 0.3616421252037539 | accuracy: 0.842092803030303 \n",
      "Epoch 7 | Step 2485 | loss: 0.3609890272813056 | accuracy: 0.8425839552238806 \n",
      "Epoch 7 | Step 2486 | loss: 0.3606184333124581 | accuracy: 0.8432904411764706 \n",
      "Epoch 7 | Step 2487 | loss: 0.36240486195985816 | accuracy: 0.8428442028985508 \n",
      "Epoch 7 | Step 2488 | loss: 0.3642147900802748 | accuracy: 0.8415178571428571 \n",
      "Epoch 7 | Step 2489 | loss: 0.36459091536595784 | accuracy: 0.8417693661971831 \n",
      "Epoch 7 | Step 2490 | loss: 0.3639952265140083 | accuracy: 0.8422309027777778 \n",
      "Epoch 7 | Step 2491 | loss: 0.3640332587369501 | accuracy: 0.8418236301369864 \n",
      "Epoch 7 | Step 2492 | loss: 0.36489116803214355 | accuracy: 0.8414273648648649 \n",
      "Epoch 7 | Step 2493 | loss: 0.3659252109130224 | accuracy: 0.8410416666666667 \n",
      "Epoch 7 | Step 2494 | loss: 0.36482316588884905 | accuracy: 0.8418996710526315 \n",
      "Epoch 7 | Step 2495 | loss: 0.36512083647313054 | accuracy: 0.8415178571428571 \n",
      "Epoch 7 | Step 2496 | loss: 0.3645201346431023 | accuracy: 0.8417467948717948 \n",
      "Epoch 7 | Step 2497 | loss: 0.3633131247155274 | accuracy: 0.8425632911392406 \n",
      "Epoch 7 | Step 2498 | loss: 0.36258627716451886 | accuracy: 0.8427734375 \n",
      "Epoch 7 | Step 2499 | loss: 0.36423072347670427 | accuracy: 0.8423996913580247 \n",
      "Epoch 7 | Step 2500 | loss: 0.36334981042437436 | accuracy: 0.8431783536585366 \n",
      "Epoch 7 | Step 2501 | loss: 0.36355957658175964 | accuracy: 0.842808734939759 \n",
      "Epoch 7 | Step 2502 | loss: 0.36380529385947047 | accuracy: 0.8430059523809523 \n",
      "Epoch 7 | Step 2503 | loss: 0.3640747012460933 | accuracy: 0.8433823529411765 \n",
      "Epoch 7 | Step 2504 | loss: 0.3633262000458185 | accuracy: 0.8439316860465116 \n",
      "Epoch 7 | Step 2505 | loss: 0.36302561304350006 | accuracy: 0.8439295977011494 \n",
      "Epoch 7 | Step 2506 | loss: 0.36318270201710134 | accuracy: 0.8439275568181818 \n",
      "Epoch 7 | Step 2507 | loss: 0.36344224633125777 | accuracy: 0.8435744382022472 \n",
      "Epoch 7 | Step 2508 | loss: 0.3638005135787858 | accuracy: 0.8430555555555556 \n",
      "Epoch 7 | Step 2509 | loss: 0.36325793983517113 | accuracy: 0.8430631868131868 \n",
      "Epoch 7 | Step 2510 | loss: 0.36475319561103114 | accuracy: 0.8425611413043478 \n",
      "Epoch 7 | Step 2511 | loss: 0.3660300414087952 | accuracy: 0.8420698924731183 \n",
      "Epoch 7 | Step 2512 | loss: 0.3648958816490275 | accuracy: 0.8425864361702128 \n",
      "Epoch 7 | Step 2513 | loss: 0.3643604355423074 | accuracy: 0.8429276315789473 \n",
      "Epoch 7 | Step 2514 | loss: 0.3630544768335919 | accuracy: 0.8435872395833334 \n",
      "Epoch 7 | Step 2515 | loss: 0.36236296164006304 | accuracy: 0.84375 \n",
      "Epoch 7 | Step 2516 | loss: 0.3631934284859774 | accuracy: 0.8431122448979592 \n",
      "Epoch 7 | Step 2517 | loss: 0.3622870220981463 | accuracy: 0.8434343434343434 \n",
      "Epoch 7 | Step 2518 | loss: 0.3631568856537342 | accuracy: 0.84296875 \n",
      "Epoch 7 | Step 2519 | loss: 0.36328183409601156 | accuracy: 0.8431311881188119 \n",
      "Epoch 7 | Step 2520 | loss: 0.3637838525807156 | accuracy: 0.8428308823529411 \n",
      "Epoch 7 | Step 2521 | loss: 0.3642024572902513 | accuracy: 0.8426881067961165 \n",
      "Epoch 7 | Step 2522 | loss: 0.3642797196427217 | accuracy: 0.8432992788461539 \n",
      "Epoch 7 | Step 2523 | loss: 0.3650452291681653 | accuracy: 0.8428571428571429 \n",
      "Epoch 7 | Step 2524 | loss: 0.36468669195782466 | accuracy: 0.8430129716981132 \n",
      "Epoch 7 | Step 2525 | loss: 0.364623637539204 | accuracy: 0.8431658878504673 \n",
      "Epoch 7 | Step 2526 | loss: 0.365319243873711 | accuracy: 0.8425925925925926 \n",
      "Epoch 7 | Step 2527 | loss: 0.36430448936213045 | accuracy: 0.8431766055045872 \n",
      "Epoch 7 | Step 2528 | loss: 0.36443119956688447 | accuracy: 0.8430397727272727 \n",
      "Epoch 7 | Step 2529 | loss: 0.3655999731104653 | accuracy: 0.8417792792792793 \n",
      "Epoch 7 | Step 2530 | loss: 0.36657855353717295 | accuracy: 0.8413783482142857 \n",
      "Epoch 7 | Step 2531 | loss: 0.36630611622755505 | accuracy: 0.8415376106194691 \n",
      "Epoch 7 | Step 2532 | loss: 0.3665478439968929 | accuracy: 0.8411458333333334 \n",
      "Epoch 7 | Step 2533 | loss: 0.36654936373233793 | accuracy: 0.8410326086956522 \n",
      "Epoch 7 | Step 2534 | loss: 0.3661609925329685 | accuracy: 0.8411907327586207 \n",
      "Epoch 7 | Step 2535 | loss: 0.36583491102752524 | accuracy: 0.8412126068376068 \n",
      "Epoch 7 | Step 2536 | loss: 0.3666156248773559 | accuracy: 0.8408368644067796 \n",
      "Epoch 7 | Step 2537 | loss: 0.3673276777277474 | accuracy: 0.8403361344537815 \n",
      "Epoch 7 | Step 2538 | loss: 0.36723597881694636 | accuracy: 0.8401041666666667 \n",
      "Epoch 7 | Step 2539 | loss: 0.36661210323660826 | accuracy: 0.8403925619834711 \n",
      "Epoch 7 | Step 2540 | loss: 0.36701491047612955 | accuracy: 0.8404200819672131 \n",
      "Epoch 7 | Step 2541 | loss: 0.36684325131458967 | accuracy: 0.8405741869918699 \n",
      "Epoch 7 | Step 2542 | loss: 0.367711600877585 | accuracy: 0.83984375 \n",
      "Epoch 7 | Step 2543 | loss: 0.3677155340909958 | accuracy: 0.839875 \n",
      "Epoch 7 | Step 2544 | loss: 0.36747271851414726 | accuracy: 0.839905753968254 \n",
      "Epoch 7 | Step 2545 | loss: 0.36804965760294844 | accuracy: 0.8394438976377953 \n",
      "Epoch 7 | Step 2546 | loss: 0.3676464915042743 | accuracy: 0.8399658203125 \n",
      "Epoch 7 | Step 2547 | loss: 0.3680128493281298 | accuracy: 0.8393895348837209 \n",
      "Epoch 7 | Step 2548 | loss: 0.3678685324696394 | accuracy: 0.8396634615384615 \n",
      "Epoch 7 | Step 2549 | loss: 0.3680455597074887 | accuracy: 0.839456106870229 \n",
      "Epoch 7 | Step 2550 | loss: 0.3680011030625213 | accuracy: 0.8394886363636364 \n",
      "Epoch 7 | Step 2551 | loss: 0.36751473050816613 | accuracy: 0.8396381578947368 \n",
      "Epoch 7 | Step 2552 | loss: 0.3668147015260227 | accuracy: 0.8401352611940298 \n",
      "Epoch 7 | Step 2553 | loss: 0.3669502870904075 | accuracy: 0.8402777777777778 \n",
      "Epoch 7 | Step 2554 | loss: 0.3668005710796398 | accuracy: 0.8406479779411765 \n",
      "Epoch 7 | Step 2555 | loss: 0.3676229801273694 | accuracy: 0.8403284671532847 \n",
      "Epoch 7 | Step 2556 | loss: 0.36718343835378037 | accuracy: 0.8406929347826086 \n",
      "Epoch 7 | Step 2557 | loss: 0.3675340693846023 | accuracy: 0.840714928057554 \n",
      "Epoch 7 | Step 2558 | loss: 0.36776156585131375 | accuracy: 0.8402901785714286 \n",
      "Epoch 7 | Step 2559 | loss: 0.36801534035104394 | accuracy: 0.840093085106383 \n",
      "Epoch 7 | Step 2560 | loss: 0.3678012012805738 | accuracy: 0.8401188380281691 \n",
      "Epoch 7 | Step 2561 | loss: 0.36739970097591834 | accuracy: 0.8405812937062938 \n",
      "Epoch 7 | Step 2562 | loss: 0.3672789839199848 | accuracy: 0.8406032986111112 \n",
      "Epoch 7 | Step 2563 | loss: 0.36697405093702784 | accuracy: 0.8408405172413793 \n",
      "Epoch 7 | Step 2564 | loss: 0.36710152489273523 | accuracy: 0.8409674657534246 \n",
      "Epoch 7 | Step 2565 | loss: 0.36710198284411927 | accuracy: 0.8413052721088435 \n",
      "Epoch 7 | Step 2566 | loss: 0.3666999099423757 | accuracy: 0.8414273648648649 \n",
      "Epoch 7 | Step 2567 | loss: 0.36666865286811096 | accuracy: 0.8415478187919463 \n",
      "Epoch 7 | Step 2568 | loss: 0.36598510056734096 | accuracy: 0.8419791666666666 \n",
      "Epoch 7 | Step 2569 | loss: 0.36583014700981176 | accuracy: 0.8420943708609271 \n",
      "Epoch 7 | Step 2570 | loss: 0.3663117998328649 | accuracy: 0.842002467105263 \n",
      "Epoch 7 | Step 2571 | loss: 0.36690550058885346 | accuracy: 0.8420138888888888 \n",
      "Epoch 7 | Step 2572 | loss: 0.36624045931286636 | accuracy: 0.8422280844155844 \n",
      "Epoch 7 | Step 2573 | loss: 0.36532125597999954 | accuracy: 0.842741935483871 \n",
      "Epoch 7 | Step 2574 | loss: 0.36472854505364727 | accuracy: 0.842948717948718 \n",
      "Epoch 7 | Step 2575 | loss: 0.364424850056126 | accuracy: 0.8429538216560509 \n",
      "Epoch 7 | Step 2576 | loss: 0.3641161112279833 | accuracy: 0.8432555379746836 \n",
      "Epoch 7 | Step 2577 | loss: 0.36396704839085653 | accuracy: 0.8432586477987422 \n",
      "Epoch 7 | Step 2578 | loss: 0.3636091054417195 | accuracy: 0.843359375 \n",
      "Epoch 7 | Step 2579 | loss: 0.36332117298745237 | accuracy: 0.843458850931677 \n",
      "Epoch 7 | Step 2580 | loss: 0.3635845074867027 | accuracy: 0.8430748456790124 \n",
      "Epoch 7 | Step 2581 | loss: 0.3630238392053208 | accuracy: 0.8431748466257669 \n",
      "Epoch 7 | Step 2582 | loss: 0.36279974796059666 | accuracy: 0.8431783536585366 \n",
      "Epoch 7 | Step 2583 | loss: 0.36283830304940556 | accuracy: 0.8429924242424243 \n",
      "Epoch 7 | Step 2584 | loss: 0.36398466317409506 | accuracy: 0.8424322289156626 \n",
      "Epoch 7 | Step 2585 | loss: 0.36347434861574357 | accuracy: 0.8427208083832335 \n",
      "Epoch 7 | Step 2586 | loss: 0.3632023690179701 | accuracy: 0.8427269345238095 \n",
      "Epoch 7 | Step 2587 | loss: 0.36447046996926424 | accuracy: 0.8421782544378699 \n",
      "Epoch 7 | Step 2588 | loss: 0.3643241720164524 | accuracy: 0.8422794117647059 \n",
      "Epoch 7 | Step 2589 | loss: 0.3648803156544591 | accuracy: 0.841922514619883 \n",
      "Epoch 7 | Step 2590 | loss: 0.36515281652641857 | accuracy: 0.8418422965116279 \n",
      "Epoch 7 | Step 2591 | loss: 0.36394164861971245 | accuracy: 0.8426661849710982 \n",
      "Epoch 7 | Step 2592 | loss: 0.36429164344551923 | accuracy: 0.8424030172413793 \n",
      "Epoch 7 | Step 2593 | loss: 0.3640969254289355 | accuracy: 0.8425 \n",
      "Epoch 7 | Step 2594 | loss: 0.3640380408614874 | accuracy: 0.8425958806818182 \n",
      "Epoch 7 | Step 2595 | loss: 0.3646296311569753 | accuracy: 0.8424258474576272 \n",
      "Epoch 7 | Step 2596 | loss: 0.36497144702445256 | accuracy: 0.8422577247191011 \n",
      "Epoch 7 | Step 2597 | loss: 0.36505813738487286 | accuracy: 0.8424406424581006 \n",
      "Epoch 7 | Step 2598 | loss: 0.36557816962401074 | accuracy: 0.8423611111111111 \n",
      "Epoch 7 | Step 2599 | loss: 0.36517279516926127 | accuracy: 0.8425414364640884 \n",
      "Epoch 7 | Step 2600 | loss: 0.36466673900792884 | accuracy: 0.8428056318681318 \n",
      "Epoch 7 | Step 2601 | loss: 0.3641829616059371 | accuracy: 0.8431523224043715 \n",
      "Epoch 7 | Step 2602 | loss: 0.36448892238347425 | accuracy: 0.843155570652174 \n",
      "Epoch 7 | Step 2603 | loss: 0.3645336038357503 | accuracy: 0.8431587837837838 \n",
      "Epoch 7 | Step 2604 | loss: 0.3642725034426617 | accuracy: 0.8431619623655914 \n",
      "Epoch 7 | Step 2605 | loss: 0.3646888055584647 | accuracy: 0.8429144385026738 \n",
      "Epoch 7 | Step 2606 | loss: 0.3646559474316049 | accuracy: 0.8430851063829787 \n",
      "Epoch 7 | Step 2607 | loss: 0.36423677395260523 | accuracy: 0.8433366402116402 \n",
      "Epoch 7 | Step 2608 | loss: 0.364192080654596 | accuracy: 0.843421052631579 \n",
      "Epoch 7 | Step 2609 | loss: 0.3645182496902206 | accuracy: 0.8431773560209425 \n",
      "Epoch 7 | Step 2610 | loss: 0.36466304554293555 | accuracy: 0.84326171875 \n",
      "Epoch 7 | Step 2611 | loss: 0.36528532137524894 | accuracy: 0.842940414507772 \n",
      "Epoch 7 | Step 2612 | loss: 0.3647164851427078 | accuracy: 0.8431056701030928 \n",
      "Epoch 7 | Step 2613 | loss: 0.3652743374690031 | accuracy: 0.8428685897435897 \n",
      "Epoch 7 | Step 2614 | loss: 0.3652596466091214 | accuracy: 0.8430325255102041 \n",
      "Epoch 7 | Step 2615 | loss: 0.36513495384739136 | accuracy: 0.8431154822335025 \n",
      "Epoch 7 | Step 2616 | loss: 0.3654851243652479 | accuracy: 0.8428819444444444 \n",
      "Epoch 7 | Step 2617 | loss: 0.3659983877860122 | accuracy: 0.8427292713567839 \n",
      "Epoch 7 | Step 2618 | loss: 0.3656739038228989 | accuracy: 0.843125 \n",
      "Epoch 7 | Step 2619 | loss: 0.3656704743110125 | accuracy: 0.8429726368159204 \n",
      "Epoch 7 | Step 2620 | loss: 0.3658936396978869 | accuracy: 0.8428991336633663 \n",
      "Epoch 7 | Step 2621 | loss: 0.36542044205618607 | accuracy: 0.8432881773399015 \n",
      "Epoch 7 | Step 2622 | loss: 0.3656524570257056 | accuracy: 0.8430606617647058 \n",
      "Epoch 7 | Step 2623 | loss: 0.36581919178730105 | accuracy: 0.8426829268292683 \n",
      "Epoch 7 | Step 2624 | loss: 0.3656917975365537 | accuracy: 0.8426122572815534 \n",
      "Epoch 7 | Step 2625 | loss: 0.36539820772438236 | accuracy: 0.8426177536231884 \n",
      "Epoch 7 | Step 2626 | loss: 0.364985055791644 | accuracy: 0.8427734375 \n",
      "Epoch 7 | Step 2627 | loss: 0.36523672852789957 | accuracy: 0.8428528708133971 \n",
      "Epoch 7 | Step 2628 | loss: 0.3647972576674961 | accuracy: 0.8430803571428571 \n",
      "Epoch 7 | Step 2629 | loss: 0.3646628685754622 | accuracy: 0.8430835308056872 \n",
      "Epoch 7 | Step 2630 | loss: 0.3650314788211067 | accuracy: 0.8428655660377359 \n",
      "Epoch 7 | Step 2631 | loss: 0.36459547631057776 | accuracy: 0.8429430751173709 \n",
      "Epoch 7 | Step 2632 | loss: 0.36431758342502274 | accuracy: 0.8430198598130841 \n",
      "Epoch 7 | Step 2633 | loss: 0.3644667852756589 | accuracy: 0.8427325581395348 \n",
      "Epoch 7 | Step 2634 | loss: 0.364921220474773 | accuracy: 0.8424479166666666 \n",
      "Epoch 7 | Step 2635 | loss: 0.36568091596875874 | accuracy: 0.8420938940092166 \n",
      "Epoch 7 | Step 2636 | loss: 0.36551040452007855 | accuracy: 0.8421731651376146 \n",
      "Epoch 7 | Step 2637 | loss: 0.3653130652425496 | accuracy: 0.8420376712328768 \n",
      "Epoch 7 | Step 2638 | loss: 0.36542274450713935 | accuracy: 0.8418323863636363 \n",
      "Epoch 7 | Step 2639 | loss: 0.36488927543433003 | accuracy: 0.8421238687782805 \n",
      "Epoch 7 | Step 2640 | loss: 0.36463679856545217 | accuracy: 0.8424127252252253 \n",
      "Epoch 7 | Step 2641 | loss: 0.3648198913832951 | accuracy: 0.8425588565022422 \n",
      "Epoch 7 | Step 2642 | loss: 0.364864595101348 | accuracy: 0.8425641741071429 \n",
      "Epoch 7 | Step 2643 | loss: 0.36551041854752436 | accuracy: 0.8421527777777778 \n",
      "Epoch 7 | Step 2644 | loss: 0.36581465259062507 | accuracy: 0.8420215707964602 \n",
      "Epoch 7 | Step 2645 | loss: 0.36579631275542507 | accuracy: 0.8419603524229075 \n",
      "Epoch 7 | Step 2646 | loss: 0.36561963367357586 | accuracy: 0.8417626096491229 \n",
      "Epoch 7 | Step 2647 | loss: 0.365132712510996 | accuracy: 0.8420442139737991 \n",
      "Epoch 7 | Step 2648 | loss: 0.36470012133536134 | accuracy: 0.8421875 \n",
      "Epoch 7 | Step 2649 | loss: 0.3651095005598935 | accuracy: 0.8421266233766234 \n",
      "Epoch 7 | Step 2650 | loss: 0.36454755568812636 | accuracy: 0.8424030172413793 \n",
      "Epoch 7 | Step 2651 | loss: 0.3647507576215932 | accuracy: 0.842274678111588 \n",
      "Epoch 7 | Step 2652 | loss: 0.364954018440002 | accuracy: 0.8423477564102564 \n",
      "Epoch 7 | Step 2653 | loss: 0.36461282917793764 | accuracy: 0.8426196808510639 \n",
      "Epoch 7 | Step 2654 | loss: 0.3645459751961595 | accuracy: 0.8426906779661016 \n",
      "Epoch 7 | Step 2655 | loss: 0.36471891315174504 | accuracy: 0.8426951476793249 \n",
      "Epoch 7 | Step 2656 | loss: 0.3650793524599877 | accuracy: 0.8425682773109243 \n",
      "Epoch 7 | Step 2657 | loss: 0.3650058873278327 | accuracy: 0.8426385983263598 \n",
      "Epoch 7 | Step 2658 | loss: 0.3647412570814292 | accuracy: 0.8427083333333333 \n",
      "Epoch 7 | Step 2659 | loss: 0.3650624649405974 | accuracy: 0.8423884854771784 \n",
      "Epoch 7 | Step 2660 | loss: 0.365140914670692 | accuracy: 0.8424586776859504 \n",
      "Epoch 7 | Step 2661 | loss: 0.3651006048844184 | accuracy: 0.8424639917695473 \n",
      "Epoch 7 | Step 2662 | loss: 0.3644834303709327 | accuracy: 0.8427894467213115 \n",
      "Epoch 7 | Step 2663 | loss: 0.3643396114816471 | accuracy: 0.842984693877551 \n",
      "Epoch 7 | Step 2664 | loss: 0.3639780710625455 | accuracy: 0.8430513211382114 \n",
      "Epoch 7 | Step 2665 | loss: 0.3637897964672521 | accuracy: 0.8431806680161943 \n",
      "Epoch 7 | Step 2666 | loss: 0.36406202938768173 | accuracy: 0.8431829637096774 \n",
      "Epoch 7 | Step 2667 | loss: 0.3644105751351659 | accuracy: 0.8429342369477911 \n",
      "Epoch 7 | Step 2668 | loss: 0.36407455706596376 | accuracy: 0.843125 \n",
      "Epoch 7 | Step 2669 | loss: 0.3643217318323979 | accuracy: 0.8430029880478087 \n",
      "Epoch 7 | Step 2670 | loss: 0.36454611650061985 | accuracy: 0.8427579365079365 \n",
      "Epoch 7 | Step 2671 | loss: 0.3645576960720092 | accuracy: 0.8427618577075099 \n",
      "Epoch 7 | Step 2672 | loss: 0.3645895227907211 | accuracy: 0.8428272637795275 \n",
      "Epoch 7 | Step 2673 | loss: 0.36447898792285544 | accuracy: 0.8428921568627451 \n",
      "Epoch 7 | Step 2674 | loss: 0.3645035437075421 | accuracy: 0.84271240234375 \n",
      "Epoch 7 | Step 2675 | loss: 0.3645250091061054 | accuracy: 0.8426556420233463 \n",
      "Epoch 7 | Step 2676 | loss: 0.36466445664102715 | accuracy: 0.8425387596899225 \n",
      "Epoch 7 | Step 2677 | loss: 0.3648115737097604 | accuracy: 0.8424227799227799 \n",
      "Epoch 7 | Step 2678 | loss: 0.36478202457611375 | accuracy: 0.8424278846153846 \n",
      "Epoch 7 | Step 2679 | loss: 0.36455209867250876 | accuracy: 0.8426724137931034 \n",
      "Epoch 7 | Step 2680 | loss: 0.3650886507434699 | accuracy: 0.8423783396946565 \n",
      "Epoch 7 | Step 2681 | loss: 0.36490945886296466 | accuracy: 0.8425023764258555 \n",
      "Epoch 7 | Step 2682 | loss: 0.3647271040262598 | accuracy: 0.8425662878787878 \n",
      "Epoch 7 | Step 2683 | loss: 0.3646286863201069 | accuracy: 0.8424528301886792 \n",
      "Epoch 7 | Step 2684 | loss: 0.36463245290114465 | accuracy: 0.8423402255639098 \n",
      "Epoch 7 | Step 2685 | loss: 0.3644667501083474 | accuracy: 0.8425210674157303 \n",
      "Epoch 7 | Step 2686 | loss: 0.36457479678427995 | accuracy: 0.8424090485074627 \n",
      "Epoch 7 | Step 2687 | loss: 0.36445844937877586 | accuracy: 0.8424140334572491 \n",
      "Epoch 7 | Step 2688 | loss: 0.3645540420655851 | accuracy: 0.8423611111111111 \n",
      "Epoch 7 | Step 2689 | loss: 0.3644698819771024 | accuracy: 0.8423662361623616 \n",
      "Epoch 7 | Step 2690 | loss: 0.3642764739034807 | accuracy: 0.8424287683823529 \n",
      "Epoch 7 | Step 2691 | loss: 0.3644478334175361 | accuracy: 0.8423763736263736 \n",
      "Epoch 7 | Step 2692 | loss: 0.36460182951749676 | accuracy: 0.8423243613138686 \n",
      "Epoch 7 | Step 2693 | loss: 0.3643483083898371 | accuracy: 0.8425 \n",
      "Epoch 7 | Step 2694 | loss: 0.36477697889010113 | accuracy: 0.8423346920289855 \n",
      "Epoch 7 | Step 2695 | loss: 0.3645965835678018 | accuracy: 0.8425090252707581 \n",
      "Epoch 7 | Step 2696 | loss: 0.3643489075864819 | accuracy: 0.8426258992805755 \n",
      "Epoch 7 | Step 2697 | loss: 0.36403421165695327 | accuracy: 0.8427979390681004 \n",
      "Epoch 7 | Step 2698 | loss: 0.3639107269900186 | accuracy: 0.8428013392857144 \n",
      "Epoch 7 | Step 2699 | loss: 0.36370233507343036 | accuracy: 0.8429715302491104 \n",
      "Epoch 7 | Step 2700 | loss: 0.3635059378459944 | accuracy: 0.842974290780142 \n",
      "Epoch 7 | Step 2701 | loss: 0.36346160344016004 | accuracy: 0.8428113957597174 \n",
      "Epoch 7 | Step 2702 | loss: 0.3630090041059843 | accuracy: 0.8431448063380282 \n",
      "Epoch 7 | Step 2703 | loss: 0.3629596596224266 | accuracy: 0.843201754385965 \n",
      "Epoch 7 | Step 2704 | loss: 0.36241060870510716 | accuracy: 0.8434768356643357 \n",
      "Epoch 7 | Step 2705 | loss: 0.36250552856963686 | accuracy: 0.8433144599303137 \n",
      "Epoch 7 | Step 2706 | loss: 0.36219947867923313 | accuracy: 0.843478732638889 \n",
      "Epoch 7 | Step 2707 | loss: 0.36291361700704766 | accuracy: 0.8432634083044984 \n",
      "Epoch 7 | Step 2708 | loss: 0.362615032956518 | accuracy: 0.8435344827586209 \n",
      "Epoch 7 | Step 2709 | loss: 0.3631418803098685 | accuracy: 0.8432130584192442 \n",
      "Epoch 7 | Step 2710 | loss: 0.3630011133747558 | accuracy: 0.8432148972602742 \n",
      "Epoch 7 | Step 2711 | loss: 0.36299101220056057 | accuracy: 0.8433233788395906 \n",
      "Epoch 7 | Step 2712 | loss: 0.3631713081176589 | accuracy: 0.8431653911564628 \n",
      "Epoch 7 | Step 2713 | loss: 0.3630559586872489 | accuracy: 0.8430084745762715 \n",
      "Epoch 7 | Step 2714 | loss: 0.36308448530129483 | accuracy: 0.8431165540540544 \n",
      "Epoch 7 | Step 2715 | loss: 0.3630175020558264 | accuracy: 0.8432239057239062 \n",
      "Epoch 7 | Step 2716 | loss: 0.3627975494069541 | accuracy: 0.8433305369127521 \n",
      "Epoch 7 | Step 2717 | loss: 0.3627755267165576 | accuracy: 0.8433319397993315 \n",
      "Epoch 7 | Step 2718 | loss: 0.3624303602178891 | accuracy: 0.8436458333333338 \n",
      "Epoch 7 | Step 2719 | loss: 0.36283349218558625 | accuracy: 0.8431789867109639 \n",
      "Epoch 7 | Step 2720 | loss: 0.3626685686261448 | accuracy: 0.8433360927152322 \n",
      "Epoch 7 | Step 2721 | loss: 0.36242474817206755 | accuracy: 0.8435437293729378 \n",
      "Epoch 7 | Step 2722 | loss: 0.36262771516646203 | accuracy: 0.8434416118421056 \n",
      "Epoch 7 | Step 2723 | loss: 0.36233912979970206 | accuracy: 0.8435450819672135 \n",
      "Epoch 7 | Step 2724 | loss: 0.362274690196405 | accuracy: 0.8435457516339873 \n",
      "Epoch 7 | Step 2725 | loss: 0.3627761794612151 | accuracy: 0.8432410423452772 \n",
      "Epoch 7 | Step 2726 | loss: 0.3625258009929161 | accuracy: 0.8433948863636367 \n",
      "Epoch 7 | Step 2727 | loss: 0.3622277069439008 | accuracy: 0.8436488673139162 \n",
      "Epoch 7 | Step 2728 | loss: 0.3622030078403411 | accuracy: 0.8438004032258068 \n",
      "Epoch 7 | Step 2729 | loss: 0.36209094006915565 | accuracy: 0.843850482315113 \n",
      "Epoch 7 | Step 2730 | loss: 0.3620482453933129 | accuracy: 0.8438000801282055 \n",
      "Epoch 7 | Step 2731 | loss: 0.3618009653144751 | accuracy: 0.843899760383387 \n",
      "Epoch 7 | Step 2732 | loss: 0.3620249910908899 | accuracy: 0.8437997611464971 \n",
      "Epoch 7 | Step 2733 | loss: 0.36240754364028804 | accuracy: 0.8437500000000003 \n",
      "Epoch 7 | Step 2734 | loss: 0.36242206564432455 | accuracy: 0.8437500000000003 \n",
      "Epoch 7 | Step 2735 | loss: 0.36214474304241334 | accuracy: 0.8438978706624609 \n",
      "Epoch 7 | Step 2736 | loss: 0.3622615383293643 | accuracy: 0.8437008647798746 \n",
      "Epoch 7 | Step 2737 | loss: 0.3621948658485771 | accuracy: 0.8437989811912229 \n",
      "Epoch 7 | Step 2738 | loss: 0.36203326852992174 | accuracy: 0.8438964843750003 \n",
      "Epoch 7 | Step 2739 | loss: 0.3620719591219477 | accuracy: 0.8437986760124614 \n",
      "Epoch 7 | Step 2740 | loss: 0.3624471470435954 | accuracy: 0.8437014751552798 \n",
      "Epoch 7 | Step 2741 | loss: 0.36220028784252906 | accuracy: 0.8437500000000003 \n",
      "Epoch 7 | Step 2742 | loss: 0.3620986209975348 | accuracy: 0.8437017746913584 \n",
      "Epoch 7 | Step 2743 | loss: 0.3621420160623697 | accuracy: 0.8435576923076926 \n",
      "Epoch 7 | Step 2744 | loss: 0.3619129508733749 | accuracy: 0.8436541411042948 \n",
      "Epoch 7 | Step 2745 | loss: 0.3619661123380748 | accuracy: 0.8436544342507649 \n",
      "Epoch 7 | Step 2746 | loss: 0.3620891225774113 | accuracy: 0.8436070884146345 \n",
      "Epoch 7 | Step 2747 | loss: 0.3625837441273373 | accuracy: 0.8432750759878422 \n",
      "Epoch 7 | Step 2748 | loss: 0.36263351097251423 | accuracy: 0.843323863636364 \n",
      "Epoch 7 | Step 2749 | loss: 0.36248091313413977 | accuracy: 0.8433723564954686 \n",
      "Epoch 7 | Step 2750 | loss: 0.3622915011393018 | accuracy: 0.843467620481928 \n",
      "Epoch 7 | Step 2751 | loss: 0.36224211264658973 | accuracy: 0.8435623123123126 \n",
      "Epoch 7 | Step 2752 | loss: 0.3623825533839756 | accuracy: 0.8434225299401201 \n",
      "Epoch 7 | Step 2753 | loss: 0.362241874612979 | accuracy: 0.8434235074626869 \n",
      "Epoch 7 | Step 2754 | loss: 0.36204838876922923 | accuracy: 0.8435639880952385 \n",
      "Epoch 7 | Step 2755 | loss: 0.3621593436961358 | accuracy: 0.8434718100890211 \n",
      "Epoch 7 | Step 2756 | loss: 0.3621241609020346 | accuracy: 0.8436113165680477 \n",
      "Epoch 7 | Step 2757 | loss: 0.3619497996867582 | accuracy: 0.8436117256637171 \n",
      "Epoch 7 | Step 2758 | loss: 0.36156856045126917 | accuracy: 0.8437959558823532 \n",
      "Epoch 7 | Step 2759 | loss: 0.361249306116286 | accuracy: 0.8439791055718479 \n",
      "Epoch 7 | Step 2760 | loss: 0.36120024223250957 | accuracy: 0.8438870614035091 \n",
      "Epoch 7 | Step 2761 | loss: 0.36106037611342734 | accuracy: 0.8438866618075805 \n",
      "Epoch 7 | Step 2762 | loss: 0.3608748803218438 | accuracy: 0.8439316860465119 \n",
      "Epoch 7 | Step 2763 | loss: 0.36107553394808295 | accuracy: 0.8437952898550728 \n",
      "Epoch 7 | Step 2764 | loss: 0.3610159797389384 | accuracy: 0.8438403179190754 \n",
      "Epoch 7 | Step 2765 | loss: 0.3606090426273237 | accuracy: 0.8440652017291069 \n",
      "Epoch 7 | Step 2766 | loss: 0.36095788775161775 | accuracy: 0.8439744971264371 \n",
      "Epoch 7 | Step 2767 | loss: 0.3608109339602015 | accuracy: 0.8440633954154731 \n",
      "Epoch 7 | Step 2768 | loss: 0.36076029309204655 | accuracy: 0.8439732142857146 \n",
      "Epoch 7 | Step 2769 | loss: 0.3604947881311434 | accuracy: 0.8442396723646727 \n",
      "Epoch 7 | Step 2770 | loss: 0.3605143035000022 | accuracy: 0.8441938920454549 \n",
      "Epoch 7 | Step 2771 | loss: 0.36040422691839624 | accuracy: 0.8443254249291788 \n",
      "Epoch 7 | Step 2772 | loss: 0.3602305560630595 | accuracy: 0.8443679378531077 \n",
      "Epoch 7 | Step 2773 | loss: 0.3600815639529431 | accuracy: 0.844454225352113 \n",
      "Epoch 7 | Step 2774 | loss: 0.35982178159978967 | accuracy: 0.8445400280898879 \n",
      "Epoch 7 | Step 2775 | loss: 0.359756440925999 | accuracy: 0.8446253501400564 \n",
      "Epoch 7 | Step 2776 | loss: 0.3599416600259324 | accuracy: 0.8444483240223467 \n",
      "Epoch 7 | Step 2777 | loss: 0.3598585118822402 | accuracy: 0.8445334261838443 \n",
      "Epoch 7 | Step 2778 | loss: 0.3598305096228919 | accuracy: 0.8445312500000003 \n",
      "Epoch 7 | Step 2779 | loss: 0.36001513555769793 | accuracy: 0.8442693905817178 \n",
      "Epoch 7 | Step 2780 | loss: 0.35995927156664403 | accuracy: 0.8442679558011053 \n",
      "Epoch 7 | Step 2781 | loss: 0.35990700224214367 | accuracy: 0.8442665289256202 \n",
      "Epoch 7 | Step 2782 | loss: 0.3597940344076892 | accuracy: 0.8442651098901102 \n",
      "Epoch 7 | Step 2783 | loss: 0.3596288988035021 | accuracy: 0.8443065068493154 \n",
      "Epoch 7 | Step 2784 | loss: 0.35945993319886643 | accuracy: 0.8443903688524593 \n",
      "Epoch 7 | Step 2785 | loss: 0.35960981875089615 | accuracy: 0.8442608991825616 \n",
      "Epoch 7 | Step 2786 | loss: 0.35942735919809876 | accuracy: 0.8443868885869569 \n",
      "Epoch 7 | Step 2787 | loss: 0.359527462623953 | accuracy: 0.8443851626016263 \n",
      "Epoch 7 | Step 2788 | loss: 0.3598149106309222 | accuracy: 0.8442145270270274 \n",
      "Epoch 7 | Step 2789 | loss: 0.3600437655603148 | accuracy: 0.844044811320755 \n",
      "Epoch 7 | Step 2790 | loss: 0.3607211361328762 | accuracy: 0.8437500000000003 \n",
      "Epoch 7 | Step 2791 | loss: 0.3608502259043524 | accuracy: 0.8437081099195713 \n",
      "Epoch 7 | Step 2792 | loss: 0.3605693383490977 | accuracy: 0.8438753342245993 \n",
      "Epoch 7 | Step 2793 | loss: 0.3602484444379808 | accuracy: 0.844166666666667 \n",
      "Epoch 7 | Step 2794 | loss: 0.36029945436785843 | accuracy: 0.8439577792553195 \n",
      "Epoch 7 | Step 2795 | loss: 0.3601393947471676 | accuracy: 0.8439986737400533 \n",
      "Epoch 7 | Step 2796 | loss: 0.36013776028440125 | accuracy: 0.8438740079365082 \n",
      "Epoch 7 | Step 2797 | loss: 0.3598078442516303 | accuracy: 0.8440385883905016 \n",
      "Epoch 7 | Step 2798 | loss: 0.3596170590504221 | accuracy: 0.8442023026315792 \n",
      "Epoch 7 | Step 2799 | loss: 0.35943442047268087 | accuracy: 0.8442421259842523 \n",
      "Epoch 7 | Step 2800 | loss: 0.35924559406429074 | accuracy: 0.8442408376963354 \n",
      "Epoch 7 | Step 2801 | loss: 0.3591878707897571 | accuracy: 0.844198759791123 \n",
      "Epoch 7 | Step 2802 | loss: 0.3592968529167897 | accuracy: 0.844156901041667 \n",
      "Epoch 7 | Step 2803 | loss: 0.3595386631690064 | accuracy: 0.84411525974026 \n",
      "Epoch 7 | Step 2804 | loss: 0.3598070931017709 | accuracy: 0.8439523963730573 \n",
      "Epoch 7 | Step 2805 | loss: 0.3598664727552918 | accuracy: 0.8440326227390184 \n",
      "Epoch 7 | Step 2806 | loss: 0.3596997882825199 | accuracy: 0.8441124355670107 \n",
      "Epoch 7 | Step 2807 | loss: 0.359905482372772 | accuracy: 0.8439910025706944 \n",
      "Epoch 7 | Step 2808 | loss: 0.35972326661531756 | accuracy: 0.8440705128205132 \n",
      "Epoch 7 | Step 2809 | loss: 0.3598818978309023 | accuracy: 0.8439897698209722 \n",
      "Epoch 7 | Step 2810 | loss: 0.35977168940007703 | accuracy: 0.8439891581632656 \n",
      "Epoch 7 | Step 2811 | loss: 0.3596068099330705 | accuracy: 0.8441873409669214 \n",
      "Epoch 7 | Step 2812 | loss: 0.35985214898580237 | accuracy: 0.844027601522843 \n",
      "Epoch 7 | Step 2813 | loss: 0.3597611842653421 | accuracy: 0.8440664556962029 \n",
      "Epoch 7 | Step 2814 | loss: 0.3596668884985978 | accuracy: 0.8440261994949498 \n",
      "Epoch 7 | Step 2815 | loss: 0.35980019540120145 | accuracy: 0.8439074307304789 \n",
      "Epoch 7 | Step 2816 | loss: 0.35996451004216434 | accuracy: 0.8437892587939702 \n",
      "Epoch 7 | Step 2817 | loss: 0.3598238292866782 | accuracy: 0.8439066416040103 \n",
      "Epoch 7 | Step 2818 | loss: 0.3600935359671713 | accuracy: 0.8437890625000003 \n",
      "Epoch 7 | Step 2819 | loss: 0.3601267486810686 | accuracy: 0.8438668952618457 \n",
      "Epoch 7 | Step 2820 | loss: 0.36056735196072087 | accuracy: 0.8436333955223884 \n",
      "Epoch 7 | Step 2821 | loss: 0.3603310222291475 | accuracy: 0.843764706521709 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.5124757289886475 | accuracy: 0.71875 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.5199711918830872 | accuracy: 0.7109375 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4669073820114136 | accuracy: 0.7604166666666666 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4663861244916916 | accuracy: 0.76953125 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4666033923625946 | accuracy: 0.765625 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4555515895287196 | accuracy: 0.7682291666666666 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.44984348331178936 | accuracy: 0.7767857142857143 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4448248967528343 | accuracy: 0.77734375 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.439971430434121 | accuracy: 0.7795138888888888 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4424671113491058 | accuracy: 0.7859375 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4409612742337314 | accuracy: 0.7911931818181818 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.433488962550958 | accuracy: 0.7942708333333334 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4363296123651358 | accuracy: 0.7896634615384616 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4370474474770682 | accuracy: 0.7901785714285714 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.42912873029708865 | accuracy: 0.7958333333333333 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.42794356122612953 | accuracy: 0.7939453125 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.437162367736592 | accuracy: 0.7913602941176471 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.43398631778028274 | accuracy: 0.7916666666666666 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4353969301048078 | accuracy: 0.7935855263157895 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4331617563962936 | accuracy: 0.7921875 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.43377440174420673 | accuracy: 0.7931547619047619 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.42986343801021576 | accuracy: 0.7961647727272727 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4335496723651886 | accuracy: 0.7934782608695652 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4359348801275094 | accuracy: 0.7923177083333334 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.43823412895202635 | accuracy: 0.791875 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4327884637392484 | accuracy: 0.7950721153846154 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.43090408267798247 | accuracy: 0.7962962962962963 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.42806096162114826 | accuracy: 0.7974330357142857 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4293562225226698 | accuracy: 0.7957974137931034 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.42938065628210703 | accuracy: 0.7963541666666667 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.42552316188812256 | accuracy: 0.7988911290322581 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.42050434090197086 | accuracy: 0.802734375 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.41915608445803326 | accuracy: 0.8044507575757576 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4265417693292393 | accuracy: 0.8010110294117647 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.42568627766200473 | accuracy: 0.8013392857142857 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4229687030116717 | accuracy: 0.8025173611111112 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4247293979734988 | accuracy: 0.8027871621621622 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4249308375935805 | accuracy: 0.8022203947368421 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4236416159532009 | accuracy: 0.8028846153846154 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.42532799243927 | accuracy: 0.80234375 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4270006694444796 | accuracy: 0.8010670731707317 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4246628617956525 | accuracy: 0.8020833333333334 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4250126307786897 | accuracy: 0.8012354651162791 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.42551556161858817 | accuracy: 0.8000710227272727 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.42790599862734474 | accuracy: 0.798233695824941 \n",
      "Epoch 8 | Step 2822 | loss: 0.3120034337043762 | accuracy: 0.859375 \n",
      "Epoch 8 | Step 2823 | loss: 0.3956787586212158 | accuracy: 0.828125 \n",
      "Epoch 8 | Step 2824 | loss: 0.3472760518391927 | accuracy: 0.859375 \n",
      "Epoch 8 | Step 2825 | loss: 0.33396299183368683 | accuracy: 0.859375 \n",
      "Epoch 8 | Step 2826 | loss: 0.33471025824546813 | accuracy: 0.85625 \n",
      "Epoch 8 | Step 2827 | loss: 0.344704066713651 | accuracy: 0.8541666666666666 \n",
      "Epoch 8 | Step 2828 | loss: 0.3436689419405801 | accuracy: 0.8571428571428571 \n",
      "Epoch 8 | Step 2829 | loss: 0.3582639768719673 | accuracy: 0.853515625 \n",
      "Epoch 8 | Step 2830 | loss: 0.3505432903766632 | accuracy: 0.8576388888888888 \n",
      "Epoch 8 | Step 2831 | loss: 0.3651727795600891 | accuracy: 0.8484375 \n",
      "Epoch 8 | Step 2832 | loss: 0.3591214662248438 | accuracy: 0.8522727272727273 \n",
      "Epoch 8 | Step 2833 | loss: 0.3726804082592328 | accuracy: 0.84375 \n",
      "Epoch 8 | Step 2834 | loss: 0.3683426769880148 | accuracy: 0.8497596153846154 \n",
      "Epoch 8 | Step 2835 | loss: 0.3729206791945866 | accuracy: 0.8504464285714286 \n",
      "Epoch 8 | Step 2836 | loss: 0.3661490917205811 | accuracy: 0.8552083333333333 \n",
      "Epoch 8 | Step 2837 | loss: 0.3563021942973137 | accuracy: 0.8603515625 \n",
      "Epoch 8 | Step 2838 | loss: 0.3529926959206076 | accuracy: 0.8612132352941176 \n",
      "Epoch 8 | Step 2839 | loss: 0.35493470231692 | accuracy: 0.8585069444444444 \n",
      "Epoch 8 | Step 2840 | loss: 0.352767770227633 | accuracy: 0.8560855263157895 \n",
      "Epoch 8 | Step 2841 | loss: 0.35258747488260267 | accuracy: 0.8578125 \n",
      "Epoch 8 | Step 2842 | loss: 0.3542037435940334 | accuracy: 0.8549107142857143 \n",
      "Epoch 8 | Step 2843 | loss: 0.3527548773722215 | accuracy: 0.8558238636363636 \n",
      "Epoch 8 | Step 2844 | loss: 0.3473942934171013 | accuracy: 0.858016304347826 \n",
      "Epoch 8 | Step 2845 | loss: 0.34572372771799564 | accuracy: 0.8567708333333334 \n",
      "Epoch 8 | Step 2846 | loss: 0.34182304501533506 | accuracy: 0.85875 \n",
      "Epoch 8 | Step 2847 | loss: 0.3431683343190413 | accuracy: 0.8575721153846154 \n",
      "Epoch 8 | Step 2848 | loss: 0.3422501605969888 | accuracy: 0.8582175925925926 \n",
      "Epoch 8 | Step 2849 | loss: 0.3361981511116028 | accuracy: 0.8610491071428571 \n",
      "Epoch 8 | Step 2850 | loss: 0.33508637341959724 | accuracy: 0.8615301724137931 \n",
      "Epoch 8 | Step 2851 | loss: 0.3364384412765503 | accuracy: 0.8604166666666667 \n",
      "Epoch 8 | Step 2852 | loss: 0.33509620351176106 | accuracy: 0.8613911290322581 \n",
      "Epoch 8 | Step 2853 | loss: 0.3364274585619569 | accuracy: 0.86083984375 \n",
      "Epoch 8 | Step 2854 | loss: 0.3417966862519582 | accuracy: 0.8584280303030303 \n",
      "Epoch 8 | Step 2855 | loss: 0.3428165465593338 | accuracy: 0.8579963235294118 \n",
      "Epoch 8 | Step 2856 | loss: 0.34273367864745 | accuracy: 0.8575892857142857 \n",
      "Epoch 8 | Step 2857 | loss: 0.3443441821469201 | accuracy: 0.8567708333333334 \n",
      "Epoch 8 | Step 2858 | loss: 0.34191418580106786 | accuracy: 0.8581081081081081 \n",
      "Epoch 8 | Step 2859 | loss: 0.3404173796114169 | accuracy: 0.8573190789473685 \n",
      "Epoch 8 | Step 2860 | loss: 0.338931163916221 | accuracy: 0.859375 \n",
      "Epoch 8 | Step 2861 | loss: 0.3375599592924118 | accuracy: 0.859765625 \n",
      "Epoch 8 | Step 2862 | loss: 0.33802408924916894 | accuracy: 0.8601371951219512 \n",
      "Epoch 8 | Step 2863 | loss: 0.3370094469615391 | accuracy: 0.8604910714285714 \n",
      "Epoch 8 | Step 2864 | loss: 0.33476040529650314 | accuracy: 0.8611918604651163 \n",
      "Epoch 8 | Step 2865 | loss: 0.3341468592936343 | accuracy: 0.8611505681818182 \n",
      "Epoch 8 | Step 2866 | loss: 0.3364928781986237 | accuracy: 0.859375 \n",
      "Epoch 8 | Step 2867 | loss: 0.3364666518957719 | accuracy: 0.859375 \n",
      "Epoch 8 | Step 2868 | loss: 0.33583586203291066 | accuracy: 0.859375 \n",
      "Epoch 8 | Step 2869 | loss: 0.3381096354375283 | accuracy: 0.8583984375 \n",
      "Epoch 8 | Step 2870 | loss: 0.33633672400396697 | accuracy: 0.859375 \n",
      "Epoch 8 | Step 2871 | loss: 0.3368543899059296 | accuracy: 0.859375 \n",
      "Epoch 8 | Step 2872 | loss: 0.33907127789422575 | accuracy: 0.8584558823529411 \n",
      "Epoch 8 | Step 2873 | loss: 0.3414330677344249 | accuracy: 0.8569711538461539 \n",
      "Epoch 8 | Step 2874 | loss: 0.34032530548437584 | accuracy: 0.8576061320754716 \n",
      "Epoch 8 | Step 2875 | loss: 0.33942000457534083 | accuracy: 0.8585069444444444 \n",
      "Epoch 8 | Step 2876 | loss: 0.33716555562886324 | accuracy: 0.8599431818181819 \n",
      "Epoch 8 | Step 2877 | loss: 0.3386637988899435 | accuracy: 0.8590959821428571 \n",
      "Epoch 8 | Step 2878 | loss: 0.33772303242432444 | accuracy: 0.8591008771929824 \n",
      "Epoch 8 | Step 2879 | loss: 0.3398507119252764 | accuracy: 0.857489224137931 \n",
      "Epoch 8 | Step 2880 | loss: 0.33985909668065734 | accuracy: 0.8580508474576272 \n",
      "Epoch 8 | Step 2881 | loss: 0.34127389192581176 | accuracy: 0.8572916666666667 \n",
      "Epoch 8 | Step 2882 | loss: 0.3420892587450684 | accuracy: 0.8565573770491803 \n",
      "Epoch 8 | Step 2883 | loss: 0.34227205524521487 | accuracy: 0.8566028225806451 \n",
      "Epoch 8 | Step 2884 | loss: 0.34189661958860973 | accuracy: 0.8571428571428571 \n",
      "Epoch 8 | Step 2885 | loss: 0.33981595770455897 | accuracy: 0.8583984375 \n",
      "Epoch 8 | Step 2886 | loss: 0.3400938031765131 | accuracy: 0.8584134615384615 \n",
      "Epoch 8 | Step 2887 | loss: 0.3376571892788916 | accuracy: 0.8596117424242424 \n",
      "Epoch 8 | Step 2888 | loss: 0.33684533656533083 | accuracy: 0.8596082089552238 \n",
      "Epoch 8 | Step 2889 | loss: 0.33658795102554206 | accuracy: 0.8600643382352942 \n",
      "Epoch 8 | Step 2890 | loss: 0.33780577001364337 | accuracy: 0.8598278985507246 \n",
      "Epoch 8 | Step 2891 | loss: 0.3397275639431817 | accuracy: 0.8587053571428571 \n",
      "Epoch 8 | Step 2892 | loss: 0.3405398906956256 | accuracy: 0.8584947183098591 \n",
      "Epoch 8 | Step 2893 | loss: 0.33962049956123036 | accuracy: 0.8589409722222222 \n",
      "Epoch 8 | Step 2894 | loss: 0.34046768407299094 | accuracy: 0.8585188356164384 \n",
      "Epoch 8 | Step 2895 | loss: 0.34126411740844315 | accuracy: 0.8576858108108109 \n",
      "Epoch 8 | Step 2896 | loss: 0.34277824680010477 | accuracy: 0.8570833333333333 \n",
      "Epoch 8 | Step 2897 | loss: 0.3416706107948956 | accuracy: 0.8575246710526315 \n",
      "Epoch 8 | Step 2898 | loss: 0.3417675344200877 | accuracy: 0.8573457792207793 \n",
      "Epoch 8 | Step 2899 | loss: 0.34123833439289 | accuracy: 0.8573717948717948 \n",
      "Epoch 8 | Step 2900 | loss: 0.3404427238657505 | accuracy: 0.8579905063291139 \n",
      "Epoch 8 | Step 2901 | loss: 0.3396807011216879 | accuracy: 0.8578125 \n",
      "Epoch 8 | Step 2902 | loss: 0.3420262737774555 | accuracy: 0.8566743827160493 \n",
      "Epoch 8 | Step 2903 | loss: 0.34110785293869855 | accuracy: 0.8572789634146342 \n",
      "Epoch 8 | Step 2904 | loss: 0.34129990762974843 | accuracy: 0.8571159638554217 \n",
      "Epoch 8 | Step 2905 | loss: 0.34152828547216596 | accuracy: 0.8571428571428571 \n",
      "Epoch 8 | Step 2906 | loss: 0.34192811671425316 | accuracy: 0.8575367647058824 \n",
      "Epoch 8 | Step 2907 | loss: 0.3409353758013526 | accuracy: 0.8581031976744186 \n",
      "Epoch 8 | Step 2908 | loss: 0.34089170618989 | accuracy: 0.8582974137931034 \n",
      "Epoch 8 | Step 2909 | loss: 0.3411126715893095 | accuracy: 0.8584872159090909 \n",
      "Epoch 8 | Step 2910 | loss: 0.34100341662931977 | accuracy: 0.8583216292134831 \n",
      "Epoch 8 | Step 2911 | loss: 0.341843698753251 | accuracy: 0.8578125 \n",
      "Epoch 8 | Step 2912 | loss: 0.34151727812630794 | accuracy: 0.8581730769230769 \n",
      "Epoch 8 | Step 2913 | loss: 0.3432444470084232 | accuracy: 0.8576766304347826 \n",
      "Epoch 8 | Step 2914 | loss: 0.34503988873574043 | accuracy: 0.8568548387096774 \n",
      "Epoch 8 | Step 2915 | loss: 0.3437251180727431 | accuracy: 0.8578789893617021 \n",
      "Epoch 8 | Step 2916 | loss: 0.3429513863827053 | accuracy: 0.8582236842105263 \n",
      "Epoch 8 | Step 2917 | loss: 0.34182886717220146 | accuracy: 0.8585611979166666 \n",
      "Epoch 8 | Step 2918 | loss: 0.34126347303390503 | accuracy: 0.8585695876288659 \n",
      "Epoch 8 | Step 2919 | loss: 0.3421373479828543 | accuracy: 0.8582589285714286 \n",
      "Epoch 8 | Step 2920 | loss: 0.34127351069691203 | accuracy: 0.8587436868686869 \n",
      "Epoch 8 | Step 2921 | loss: 0.3419822597503662 | accuracy: 0.85828125 \n",
      "Epoch 8 | Step 2922 | loss: 0.3420355216701432 | accuracy: 0.8584467821782178 \n",
      "Epoch 8 | Step 2923 | loss: 0.34221216393452064 | accuracy: 0.8583026960784313 \n",
      "Epoch 8 | Step 2924 | loss: 0.342642925318005 | accuracy: 0.8578580097087378 \n",
      "Epoch 8 | Step 2925 | loss: 0.34290351002262187 | accuracy: 0.8580228365384616 \n",
      "Epoch 8 | Step 2926 | loss: 0.3438041661466871 | accuracy: 0.8577380952380952 \n",
      "Epoch 8 | Step 2927 | loss: 0.34330011848008857 | accuracy: 0.8581957547169812 \n",
      "Epoch 8 | Step 2928 | loss: 0.343064390888838 | accuracy: 0.8582067757009346 \n",
      "Epoch 8 | Step 2929 | loss: 0.34403731177250546 | accuracy: 0.8576388888888888 \n",
      "Epoch 8 | Step 2930 | loss: 0.34310221056872553 | accuracy: 0.8580848623853211 \n",
      "Epoch 8 | Step 2931 | loss: 0.3431342215700583 | accuracy: 0.858096590909091 \n",
      "Epoch 8 | Step 2932 | loss: 0.3443732115330997 | accuracy: 0.8574042792792793 \n",
      "Epoch 8 | Step 2933 | loss: 0.3455405170097947 | accuracy: 0.8568638392857143 \n",
      "Epoch 8 | Step 2934 | loss: 0.34508257853773844 | accuracy: 0.8573008849557522 \n",
      "Epoch 8 | Step 2935 | loss: 0.3452233325755387 | accuracy: 0.8570449561403509 \n",
      "Epoch 8 | Step 2936 | loss: 0.344984691168951 | accuracy: 0.8567934782608696 \n",
      "Epoch 8 | Step 2937 | loss: 0.34441846287969885 | accuracy: 0.857354525862069 \n",
      "Epoch 8 | Step 2938 | loss: 0.34391445469143045 | accuracy: 0.8577724358974359 \n",
      "Epoch 8 | Step 2939 | loss: 0.3443941525736098 | accuracy: 0.8576536016949152 \n",
      "Epoch 8 | Step 2940 | loss: 0.34522959903007794 | accuracy: 0.8568802521008403 \n",
      "Epoch 8 | Step 2941 | loss: 0.3452462843308846 | accuracy: 0.85703125 \n",
      "Epoch 8 | Step 2942 | loss: 0.3445650251690021 | accuracy: 0.8571797520661157 \n",
      "Epoch 8 | Step 2943 | loss: 0.3448892412859885 | accuracy: 0.8570696721311475 \n",
      "Epoch 8 | Step 2944 | loss: 0.34480912498826904 | accuracy: 0.8568343495934959 \n",
      "Epoch 8 | Step 2945 | loss: 0.34569847812094995 | accuracy: 0.8563508064516129 \n",
      "Epoch 8 | Step 2946 | loss: 0.3458054925203323 | accuracy: 0.856375 \n",
      "Epoch 8 | Step 2947 | loss: 0.34548370481010465 | accuracy: 0.8563988095238095 \n",
      "Epoch 8 | Step 2948 | loss: 0.34618859462381346 | accuracy: 0.8558070866141733 \n",
      "Epoch 8 | Step 2949 | loss: 0.34582813072483987 | accuracy: 0.8563232421875 \n",
      "Epoch 8 | Step 2950 | loss: 0.346204147435898 | accuracy: 0.8556201550387597 \n",
      "Epoch 8 | Step 2951 | loss: 0.3460826705281551 | accuracy: 0.8560096153846154 \n",
      "Epoch 8 | Step 2952 | loss: 0.34629286097661227 | accuracy: 0.8559160305343512 \n",
      "Epoch 8 | Step 2953 | loss: 0.34616414175340626 | accuracy: 0.8559422348484849 \n",
      "Epoch 8 | Step 2954 | loss: 0.3456787266453406 | accuracy: 0.856203007518797 \n",
      "Epoch 8 | Step 2955 | loss: 0.3448669395562428 | accuracy: 0.8566930970149254 \n",
      "Epoch 8 | Step 2956 | loss: 0.3450247432346697 | accuracy: 0.8568287037037037 \n",
      "Epoch 8 | Step 2957 | loss: 0.34497235770172935 | accuracy: 0.8571920955882353 \n",
      "Epoch 8 | Step 2958 | loss: 0.3456077198260022 | accuracy: 0.8568658759124088 \n",
      "Epoch 8 | Step 2959 | loss: 0.3452054217889689 | accuracy: 0.8568840579710146 \n",
      "Epoch 8 | Step 2960 | loss: 0.34562597418431756 | accuracy: 0.8565647482014389 \n",
      "Epoch 8 | Step 2961 | loss: 0.34585987510425703 | accuracy: 0.8562500000000001 \n",
      "Epoch 8 | Step 2962 | loss: 0.34606602650584906 | accuracy: 0.8561613475177305 \n",
      "Epoch 8 | Step 2963 | loss: 0.3458807494648745 | accuracy: 0.856294014084507 \n",
      "Epoch 8 | Step 2964 | loss: 0.34546204390642526 | accuracy: 0.8565340909090909 \n",
      "Epoch 8 | Step 2965 | loss: 0.3454387062746618 | accuracy: 0.8564453125 \n",
      "Epoch 8 | Step 2966 | loss: 0.3448621008930535 | accuracy: 0.856573275862069 \n",
      "Epoch 8 | Step 2967 | loss: 0.345078232659869 | accuracy: 0.8564854452054794 \n",
      "Epoch 8 | Step 2968 | loss: 0.3450666857617242 | accuracy: 0.85671768707483 \n",
      "Epoch 8 | Step 2969 | loss: 0.34492496954830915 | accuracy: 0.8568412162162163 \n",
      "Epoch 8 | Step 2970 | loss: 0.3448876871558643 | accuracy: 0.8569630872483223 \n",
      "Epoch 8 | Step 2971 | loss: 0.3442061222592989 | accuracy: 0.8575 \n",
      "Epoch 8 | Step 2972 | loss: 0.3441490435245021 | accuracy: 0.8575124172185431 \n",
      "Epoch 8 | Step 2973 | loss: 0.34471825147537805 | accuracy: 0.857421875 \n",
      "Epoch 8 | Step 2974 | loss: 0.34521937594304675 | accuracy: 0.8574346405228758 \n",
      "Epoch 8 | Step 2975 | loss: 0.34438038307737995 | accuracy: 0.8577516233766234 \n",
      "Epoch 8 | Step 2976 | loss: 0.3433284209620568 | accuracy: 0.8581653225806452 \n",
      "Epoch 8 | Step 2977 | loss: 0.3426412918055669 | accuracy: 0.8584735576923077 \n",
      "Epoch 8 | Step 2978 | loss: 0.34230309069915943 | accuracy: 0.8584792993630573 \n",
      "Epoch 8 | Step 2979 | loss: 0.3420291106346287 | accuracy: 0.858682753164557 \n",
      "Epoch 8 | Step 2980 | loss: 0.34193055968989366 | accuracy: 0.858687106918239 \n",
      "Epoch 8 | Step 2981 | loss: 0.34161991672590375 | accuracy: 0.85888671875 \n",
      "Epoch 8 | Step 2982 | loss: 0.34124047535917035 | accuracy: 0.858889751552795 \n",
      "Epoch 8 | Step 2983 | loss: 0.3412899857869855 | accuracy: 0.8588927469135802 \n",
      "Epoch 8 | Step 2984 | loss: 0.3406200462872266 | accuracy: 0.8590874233128835 \n",
      "Epoch 8 | Step 2985 | loss: 0.34041582965632766 | accuracy: 0.8589939024390244 \n",
      "Epoch 8 | Step 2986 | loss: 0.3404214010997252 | accuracy: 0.8587121212121213 \n",
      "Epoch 8 | Step 2987 | loss: 0.3416245670383235 | accuracy: 0.8581513554216867 \n",
      "Epoch 8 | Step 2988 | loss: 0.3409968403998963 | accuracy: 0.8585329341317365 \n",
      "Epoch 8 | Step 2989 | loss: 0.34067583367938087 | accuracy: 0.8584449404761905 \n",
      "Epoch 8 | Step 2990 | loss: 0.34183370255859646 | accuracy: 0.8581730769230769 \n",
      "Epoch 8 | Step 2991 | loss: 0.3417449819691041 | accuracy: 0.8581801470588235 \n",
      "Epoch 8 | Step 2992 | loss: 0.34223800949883043 | accuracy: 0.8577302631578947 \n",
      "Epoch 8 | Step 2993 | loss: 0.34245239544746486 | accuracy: 0.8577398255813954 \n",
      "Epoch 8 | Step 2994 | loss: 0.34115889608170946 | accuracy: 0.8584718208092486 \n",
      "Epoch 8 | Step 2995 | loss: 0.34148287764568436 | accuracy: 0.8580280172413793 \n",
      "Epoch 8 | Step 2996 | loss: 0.34128856326852525 | accuracy: 0.858125 \n",
      "Epoch 8 | Step 2997 | loss: 0.3412542899393223 | accuracy: 0.8582208806818182 \n",
      "Epoch 8 | Step 2998 | loss: 0.34169620502803283 | accuracy: 0.8580508474576272 \n",
      "Epoch 8 | Step 2999 | loss: 0.3419430152921194 | accuracy: 0.8578827247191011 \n",
      "Epoch 8 | Step 3000 | loss: 0.34200615248533595 | accuracy: 0.8579783519553073 \n",
      "Epoch 8 | Step 3001 | loss: 0.3424177806410524 | accuracy: 0.8578125 \n",
      "Epoch 8 | Step 3002 | loss: 0.34194361348507807 | accuracy: 0.8579074585635359 \n",
      "Epoch 8 | Step 3003 | loss: 0.3413939081378035 | accuracy: 0.8580872252747253 \n",
      "Epoch 8 | Step 3004 | loss: 0.34093202039843695 | accuracy: 0.8586065573770492 \n",
      "Epoch 8 | Step 3005 | loss: 0.3410592544014039 | accuracy: 0.8586956521739131 \n",
      "Epoch 8 | Step 3006 | loss: 0.34116697746354174 | accuracy: 0.8586148648648648 \n",
      "Epoch 8 | Step 3007 | loss: 0.34106243810346043 | accuracy: 0.8586189516129032 \n",
      "Epoch 8 | Step 3008 | loss: 0.34146205547021663 | accuracy: 0.8583723262032086 \n",
      "Epoch 8 | Step 3009 | loss: 0.3413818236044112 | accuracy: 0.8585438829787234 \n",
      "Epoch 8 | Step 3010 | loss: 0.3409970106271208 | accuracy: 0.8587962962962963 \n",
      "Epoch 8 | Step 3011 | loss: 0.3409091596540651 | accuracy: 0.8587993421052632 \n",
      "Epoch 8 | Step 3012 | loss: 0.34126057175441554 | accuracy: 0.8587205497382199 \n",
      "Epoch 8 | Step 3013 | loss: 0.34152264567092055 | accuracy: 0.8587239583333334 \n",
      "Epoch 8 | Step 3014 | loss: 0.34199353187813036 | accuracy: 0.8584844559585493 \n",
      "Epoch 8 | Step 3015 | loss: 0.341503157520417 | accuracy: 0.8586501288659794 \n",
      "Epoch 8 | Step 3016 | loss: 0.3420465398293274 | accuracy: 0.8584134615384615 \n",
      "Epoch 8 | Step 3017 | loss: 0.3420507387087052 | accuracy: 0.8585778061224489 \n",
      "Epoch 8 | Step 3018 | loss: 0.34200545865569615 | accuracy: 0.858502538071066 \n",
      "Epoch 8 | Step 3019 | loss: 0.3422394252636215 | accuracy: 0.8581912878787878 \n",
      "Epoch 8 | Step 3020 | loss: 0.34282520151318013 | accuracy: 0.8582757537688442 \n",
      "Epoch 8 | Step 3021 | loss: 0.3424846010655164 | accuracy: 0.8584375 \n",
      "Epoch 8 | Step 3022 | loss: 0.3425825972906985 | accuracy: 0.8583644278606966 \n",
      "Epoch 8 | Step 3023 | loss: 0.3428112384263831 | accuracy: 0.8583694306930693 \n",
      "Epoch 8 | Step 3024 | loss: 0.3423845106598191 | accuracy: 0.8586822660098522 \n",
      "Epoch 8 | Step 3025 | loss: 0.34256927559480943 | accuracy: 0.8584558823529411 \n",
      "Epoch 8 | Step 3026 | loss: 0.342806249638883 | accuracy: 0.858155487804878 \n",
      "Epoch 8 | Step 3027 | loss: 0.34265480118179775 | accuracy: 0.8583131067961165 \n",
      "Epoch 8 | Step 3028 | loss: 0.3423242277425268 | accuracy: 0.8584692028985508 \n",
      "Epoch 8 | Step 3029 | loss: 0.34192995891834677 | accuracy: 0.8585486778846154 \n",
      "Epoch 8 | Step 3030 | loss: 0.34204821388402046 | accuracy: 0.8585526315789473 \n",
      "Epoch 8 | Step 3031 | loss: 0.3415463093490827 | accuracy: 0.8587053571428571 \n",
      "Epoch 8 | Step 3032 | loss: 0.3414015660494989 | accuracy: 0.8586344786729858 \n",
      "Epoch 8 | Step 3033 | loss: 0.3416810065929619 | accuracy: 0.8583431603773585 \n",
      "Epoch 8 | Step 3034 | loss: 0.3412866227923424 | accuracy: 0.8583480046948356 \n",
      "Epoch 8 | Step 3035 | loss: 0.3409607071325043 | accuracy: 0.8585718457943925 \n",
      "Epoch 8 | Step 3036 | loss: 0.34116307060385853 | accuracy: 0.8585029069767441 \n",
      "Epoch 8 | Step 3037 | loss: 0.34164110633234174 | accuracy: 0.8582175925925926 \n",
      "Epoch 8 | Step 3038 | loss: 0.342182466168008 | accuracy: 0.8577908986175116 \n",
      "Epoch 8 | Step 3039 | loss: 0.34198751601330724 | accuracy: 0.8578698394495413 \n",
      "Epoch 8 | Step 3040 | loss: 0.34183973761181846 | accuracy: 0.8578053652968036 \n",
      "Epoch 8 | Step 3041 | loss: 0.34188081019304006 | accuracy: 0.8576704545454545 \n",
      "Epoch 8 | Step 3042 | loss: 0.3414388949649905 | accuracy: 0.8578902714932126 \n",
      "Epoch 8 | Step 3043 | loss: 0.34116804579625254 | accuracy: 0.8581081081081081 \n",
      "Epoch 8 | Step 3044 | loss: 0.3412760172055975 | accuracy: 0.8581838565022422 \n",
      "Epoch 8 | Step 3045 | loss: 0.3412409449395324 | accuracy: 0.8581891741071429 \n",
      "Epoch 8 | Step 3046 | loss: 0.341835443774859 | accuracy: 0.8578472222222222 \n",
      "Epoch 8 | Step 3047 | loss: 0.34200530077240104 | accuracy: 0.8577848451327433 \n",
      "Epoch 8 | Step 3048 | loss: 0.3419698838489171 | accuracy: 0.8577918502202643 \n",
      "Epoch 8 | Step 3049 | loss: 0.3417381063234387 | accuracy: 0.8575246710526315 \n",
      "Epoch 8 | Step 3050 | loss: 0.3412114547069416 | accuracy: 0.8577374454148472 \n",
      "Epoch 8 | Step 3051 | loss: 0.3407301379934601 | accuracy: 0.8578125 \n",
      "Epoch 8 | Step 3052 | loss: 0.34114713502394683 | accuracy: 0.8577516233766234 \n",
      "Epoch 8 | Step 3053 | loss: 0.3405601057898381 | accuracy: 0.8579606681034483 \n",
      "Epoch 8 | Step 3054 | loss: 0.34056938327689024 | accuracy: 0.8578326180257511 \n",
      "Epoch 8 | Step 3055 | loss: 0.3407284434661905 | accuracy: 0.8578392094017094 \n",
      "Epoch 8 | Step 3056 | loss: 0.3403384884621234 | accuracy: 0.8581781914893617 \n",
      "Epoch 8 | Step 3057 | loss: 0.3403280270049127 | accuracy: 0.858249470338983 \n",
      "Epoch 8 | Step 3058 | loss: 0.3405592056769358 | accuracy: 0.8581223628691983 \n",
      "Epoch 8 | Step 3059 | loss: 0.34100705447818047 | accuracy: 0.8579963235294118 \n",
      "Epoch 8 | Step 3060 | loss: 0.3408581837700001 | accuracy: 0.8580674686192469 \n",
      "Epoch 8 | Step 3061 | loss: 0.34058662516375376 | accuracy: 0.8581380208333333 \n",
      "Epoch 8 | Step 3062 | loss: 0.34085286158249084 | accuracy: 0.8579486514522822 \n",
      "Epoch 8 | Step 3063 | loss: 0.3407935730435631 | accuracy: 0.8579545454545454 \n",
      "Epoch 8 | Step 3064 | loss: 0.34074222833040807 | accuracy: 0.8580889917695473 \n",
      "Epoch 8 | Step 3065 | loss: 0.3400633421833397 | accuracy: 0.8584784836065574 \n",
      "Epoch 8 | Step 3066 | loss: 0.33985410101559693 | accuracy: 0.858609693877551 \n",
      "Epoch 8 | Step 3067 | loss: 0.33954508178602383 | accuracy: 0.8586763211382114 \n",
      "Epoch 8 | Step 3068 | loss: 0.33927399330293595 | accuracy: 0.8588056680161943 \n",
      "Epoch 8 | Step 3069 | loss: 0.3394994214177131 | accuracy: 0.8587449596774194 \n",
      "Epoch 8 | Step 3070 | loss: 0.3397285707265018 | accuracy: 0.8586219879518072 \n",
      "Epoch 8 | Step 3071 | loss: 0.33937472617626185 | accuracy: 0.858875 \n",
      "Epoch 8 | Step 3072 | loss: 0.3395796862256479 | accuracy: 0.8587524900398407 \n",
      "Epoch 8 | Step 3073 | loss: 0.33982217028027484 | accuracy: 0.8585069444444444 \n",
      "Epoch 8 | Step 3074 | loss: 0.33988142343377875 | accuracy: 0.8585721343873518 \n",
      "Epoch 8 | Step 3075 | loss: 0.33987101231973 | accuracy: 0.8585752952755905 \n",
      "Epoch 8 | Step 3076 | loss: 0.3397890925407409 | accuracy: 0.8586397058823529 \n",
      "Epoch 8 | Step 3077 | loss: 0.3398989173583686 | accuracy: 0.85845947265625 \n",
      "Epoch 8 | Step 3078 | loss: 0.339983027500865 | accuracy: 0.8583414396887159 \n",
      "Epoch 8 | Step 3079 | loss: 0.3400866575250329 | accuracy: 0.8583454457364341 \n",
      "Epoch 8 | Step 3080 | loss: 0.34022111586622283 | accuracy: 0.8581081081081081 \n",
      "Epoch 8 | Step 3081 | loss: 0.34023825319913714 | accuracy: 0.8579927884615385 \n",
      "Epoch 8 | Step 3082 | loss: 0.34002086360335804 | accuracy: 0.8581776819923371 \n",
      "Epoch 8 | Step 3083 | loss: 0.34057400256167836 | accuracy: 0.8578840648854962 \n",
      "Epoch 8 | Step 3084 | loss: 0.34034541419250425 | accuracy: 0.857949144486692 \n",
      "Epoch 8 | Step 3085 | loss: 0.34019073731068405 | accuracy: 0.8580137310606061 \n",
      "Epoch 8 | Step 3086 | loss: 0.3400675890580663 | accuracy: 0.8579599056603774 \n",
      "Epoch 8 | Step 3087 | loss: 0.34007193764349564 | accuracy: 0.8578477443609023 \n",
      "Epoch 8 | Step 3088 | loss: 0.33985543061284973 | accuracy: 0.8579705056179775 \n",
      "Epoch 8 | Step 3089 | loss: 0.3399677956059796 | accuracy: 0.8578591417910447 \n",
      "Epoch 8 | Step 3090 | loss: 0.33991157055787424 | accuracy: 0.8578647769516727 \n",
      "Epoch 8 | Step 3091 | loss: 0.3400336747920071 | accuracy: 0.8578124999999999 \n",
      "Epoch 8 | Step 3092 | loss: 0.3400392989830776 | accuracy: 0.8577029520295202 \n",
      "Epoch 8 | Step 3093 | loss: 0.3398703338907044 | accuracy: 0.8578239889705881 \n",
      "Epoch 8 | Step 3094 | loss: 0.34008791256736914 | accuracy: 0.8577152014652014 \n",
      "Epoch 8 | Step 3095 | loss: 0.34031474829590225 | accuracy: 0.8577782846715328 \n",
      "Epoch 8 | Step 3096 | loss: 0.3401016342639922 | accuracy: 0.857840909090909 \n",
      "Epoch 8 | Step 3097 | loss: 0.3405102710577024 | accuracy: 0.8575067934782609 \n",
      "Epoch 8 | Step 3098 | loss: 0.34036892448091327 | accuracy: 0.8575699458483754 \n",
      "Epoch 8 | Step 3099 | loss: 0.340130863429831 | accuracy: 0.8576326438848921 \n",
      "Epoch 8 | Step 3100 | loss: 0.3398888756297394 | accuracy: 0.8577508960573477 \n",
      "Epoch 8 | Step 3101 | loss: 0.33980572585548663 | accuracy: 0.8577566964285714 \n",
      "Epoch 8 | Step 3102 | loss: 0.3396912064416552 | accuracy: 0.8578180604982206 \n",
      "Epoch 8 | Step 3103 | loss: 0.33947561723543385 | accuracy: 0.8578235815602837 \n",
      "Epoch 8 | Step 3104 | loss: 0.33942818157243215 | accuracy: 0.857773851590106 \n",
      "Epoch 8 | Step 3105 | loss: 0.3389487246077664 | accuracy: 0.8579995598591549 \n",
      "Epoch 8 | Step 3106 | loss: 0.3389325840954194 | accuracy: 0.8580043859649122 \n",
      "Epoch 8 | Step 3107 | loss: 0.3383871775928076 | accuracy: 0.8582277097902098 \n",
      "Epoch 8 | Step 3108 | loss: 0.33840057175956945 | accuracy: 0.8581772648083623 \n",
      "Epoch 8 | Step 3109 | loss: 0.338120550279402 | accuracy: 0.858181423611111 \n",
      "Epoch 8 | Step 3110 | loss: 0.3386305422622027 | accuracy: 0.8579692906574393 \n",
      "Epoch 8 | Step 3111 | loss: 0.33839360326528545 | accuracy: 0.8581896551724137 \n",
      "Epoch 8 | Step 3112 | loss: 0.33886721315457646 | accuracy: 0.8580863402061856 \n",
      "Epoch 8 | Step 3113 | loss: 0.3387847451416596 | accuracy: 0.8579837328767124 \n",
      "Epoch 8 | Step 3114 | loss: 0.3387818051177893 | accuracy: 0.8580951365187713 \n",
      "Epoch 8 | Step 3115 | loss: 0.33899513196174785 | accuracy: 0.8579400510204082 \n",
      "Epoch 8 | Step 3116 | loss: 0.3388298191761566 | accuracy: 0.8578389830508475 \n",
      "Epoch 8 | Step 3117 | loss: 0.3388607339379755 | accuracy: 0.8579497466216216 \n",
      "Epoch 8 | Step 3118 | loss: 0.3387565806959615 | accuracy: 0.8580071548821548 \n",
      "Epoch 8 | Step 3119 | loss: 0.3386042173576835 | accuracy: 0.858169043624161 \n",
      "Epoch 8 | Step 3120 | loss: 0.33859541169975116 | accuracy: 0.8581208193979933 \n",
      "Epoch 8 | Step 3121 | loss: 0.3383132622142633 | accuracy: 0.8583333333333333 \n",
      "Epoch 8 | Step 3122 | loss: 0.3387088584048407 | accuracy: 0.8579734219269103 \n",
      "Epoch 8 | Step 3123 | loss: 0.33850776374537417 | accuracy: 0.8580815397350994 \n",
      "Epoch 8 | Step 3124 | loss: 0.33828046096630215 | accuracy: 0.8582920792079208 \n",
      "Epoch 8 | Step 3125 | loss: 0.3384846626829944 | accuracy: 0.858141447368421 \n",
      "Epoch 8 | Step 3126 | loss: 0.3382918330001049 | accuracy: 0.8582479508196721 \n",
      "Epoch 8 | Step 3127 | loss: 0.33824643195649373 | accuracy: 0.8582005718954249 \n",
      "Epoch 8 | Step 3128 | loss: 0.3388837645321793 | accuracy: 0.8579499185667753 \n",
      "Epoch 8 | Step 3129 | loss: 0.3386854505674405 | accuracy: 0.858005275974026 \n",
      "Epoch 8 | Step 3130 | loss: 0.3383436130667195 | accuracy: 0.8581614077669902 \n",
      "Epoch 8 | Step 3131 | loss: 0.33833556107936363 | accuracy: 0.8582157258064517 \n",
      "Epoch 8 | Step 3132 | loss: 0.33830604608802545 | accuracy: 0.858269694533762 \n",
      "Epoch 8 | Step 3133 | loss: 0.3382909220571701 | accuracy: 0.8582732371794872 \n",
      "Epoch 8 | Step 3134 | loss: 0.33801082138436284 | accuracy: 0.8584764376996805 \n",
      "Epoch 8 | Step 3135 | loss: 0.33826305902307957 | accuracy: 0.8584295382165605 \n",
      "Epoch 8 | Step 3136 | loss: 0.3386490712090144 | accuracy: 0.8583333333333333 \n",
      "Epoch 8 | Step 3137 | loss: 0.3386366502205027 | accuracy: 0.8582871835443038 \n",
      "Epoch 8 | Step 3138 | loss: 0.3383626692490622 | accuracy: 0.8584384858044164 \n",
      "Epoch 8 | Step 3139 | loss: 0.3384729430735486 | accuracy: 0.8582448899371069 \n",
      "Epoch 8 | Step 3140 | loss: 0.3384108905881923 | accuracy: 0.8582974137931034 \n",
      "Epoch 8 | Step 3141 | loss: 0.33822253867983815 | accuracy: 0.858349609375 \n",
      "Epoch 8 | Step 3142 | loss: 0.3382753639763389 | accuracy: 0.8583041277258567 \n",
      "Epoch 8 | Step 3143 | loss: 0.33861068122505394 | accuracy: 0.8582104037267081 \n",
      "Epoch 8 | Step 3144 | loss: 0.338407406589195 | accuracy: 0.8582140092879257 \n",
      "Epoch 8 | Step 3145 | loss: 0.3382928929763075 | accuracy: 0.8581693672839507 \n",
      "Epoch 8 | Step 3146 | loss: 0.3383353687249696 | accuracy: 0.8579807692307693 \n",
      "Epoch 8 | Step 3147 | loss: 0.33818690871899837 | accuracy: 0.8580809049079755 \n",
      "Epoch 8 | Step 3148 | loss: 0.3382730778386468 | accuracy: 0.8580370795107034 \n",
      "Epoch 8 | Step 3149 | loss: 0.3383154647379386 | accuracy: 0.8580887957317073 \n",
      "Epoch 8 | Step 3150 | loss: 0.33878395758501295 | accuracy: 0.8578077507598785 \n",
      "Epoch 8 | Step 3151 | loss: 0.3387717080838752 | accuracy: 0.857717803030303 \n",
      "Epoch 8 | Step 3152 | loss: 0.3386236766854081 | accuracy: 0.8578644259818731 \n",
      "Epoch 8 | Step 3153 | loss: 0.3384861184890011 | accuracy: 0.8580101656626506 \n",
      "Epoch 8 | Step 3154 | loss: 0.33840714122082016 | accuracy: 0.8580142642642643 \n",
      "Epoch 8 | Step 3155 | loss: 0.3385647729842248 | accuracy: 0.8578779940119761 \n",
      "Epoch 8 | Step 3156 | loss: 0.3383433956708481 | accuracy: 0.857929104477612 \n",
      "Epoch 8 | Step 3157 | loss: 0.3381555952309143 | accuracy: 0.8579799107142857 \n",
      "Epoch 8 | Step 3158 | loss: 0.33819760174355096 | accuracy: 0.8579840504451038 \n",
      "Epoch 8 | Step 3159 | loss: 0.33817340195531675 | accuracy: 0.8580806213017751 \n",
      "Epoch 8 | Step 3160 | loss: 0.33802281324490685 | accuracy: 0.8581305309734514 \n",
      "Epoch 8 | Step 3161 | loss: 0.33767201203633757 | accuracy: 0.8582720588235294 \n",
      "Epoch 8 | Step 3162 | loss: 0.3374584590322461 | accuracy: 0.858366935483871 \n",
      "Epoch 8 | Step 3163 | loss: 0.33737695038492915 | accuracy: 0.8583241959064327 \n",
      "Epoch 8 | Step 3164 | loss: 0.3371774755396579 | accuracy: 0.8583272594752187 \n",
      "Epoch 8 | Step 3165 | loss: 0.33700300948044587 | accuracy: 0.858375726744186 \n",
      "Epoch 8 | Step 3166 | loss: 0.3370782788680947 | accuracy: 0.8582427536231884 \n",
      "Epoch 8 | Step 3167 | loss: 0.33704329781621867 | accuracy: 0.8583363439306358 \n",
      "Epoch 8 | Step 3168 | loss: 0.33668001275241205 | accuracy: 0.8585194524495677 \n",
      "Epoch 8 | Step 3169 | loss: 0.33709039359257137 | accuracy: 0.8583872126436781 \n",
      "Epoch 8 | Step 3170 | loss: 0.336979092448352 | accuracy: 0.8584348137535817 \n",
      "Epoch 8 | Step 3171 | loss: 0.3369137930870056 | accuracy: 0.8584375 \n",
      "Epoch 8 | Step 3172 | loss: 0.33666786347698957 | accuracy: 0.858573717948718 \n",
      "Epoch 8 | Step 3173 | loss: 0.3367381390522826 | accuracy: 0.8585316051136364 \n",
      "Epoch 8 | Step 3174 | loss: 0.33658313151797215 | accuracy: 0.8586225212464589 \n",
      "Epoch 8 | Step 3175 | loss: 0.33637421860196487 | accuracy: 0.8586687853107344 \n",
      "Epoch 8 | Step 3176 | loss: 0.33626404790811126 | accuracy: 0.8587588028169014 \n",
      "Epoch 8 | Step 3177 | loss: 0.3360407764322301 | accuracy: 0.8588483146067416 \n",
      "Epoch 8 | Step 3178 | loss: 0.3359855604605847 | accuracy: 0.858937324929972 \n",
      "Epoch 8 | Step 3179 | loss: 0.33609079224104305 | accuracy: 0.8588512569832403 \n",
      "Epoch 8 | Step 3180 | loss: 0.33592384572148637 | accuracy: 0.8589397632311978 \n",
      "Epoch 8 | Step 3181 | loss: 0.33583677179283544 | accuracy: 0.858984375 \n",
      "Epoch 8 | Step 3182 | loss: 0.3360435361677257 | accuracy: 0.8587690443213296 \n",
      "Epoch 8 | Step 3183 | loss: 0.3359858686752738 | accuracy: 0.8588138812154696 \n",
      "Epoch 8 | Step 3184 | loss: 0.3359422967782031 | accuracy: 0.8587723829201102 \n",
      "Epoch 8 | Step 3185 | loss: 0.33589664961282995 | accuracy: 0.8587311126373627 \n",
      "Epoch 8 | Step 3186 | loss: 0.335712230777087 | accuracy: 0.858861301369863 \n",
      "Epoch 8 | Step 3187 | loss: 0.33552356789020865 | accuracy: 0.8589053961748634 \n",
      "Epoch 8 | Step 3188 | loss: 0.3355614213267851 | accuracy: 0.8588215258855586 \n",
      "Epoch 8 | Step 3189 | loss: 0.3353564671200252 | accuracy: 0.8589504076086957 \n",
      "Epoch 8 | Step 3190 | loss: 0.3354817025545164 | accuracy: 0.8589092140921409 \n",
      "Epoch 8 | Step 3191 | loss: 0.33582336781798156 | accuracy: 0.8586993243243243 \n",
      "Epoch 8 | Step 3192 | loss: 0.33602872410553136 | accuracy: 0.8584905660377359 \n",
      "Epoch 8 | Step 3193 | loss: 0.33666435308674303 | accuracy: 0.8582409274193549 \n",
      "Epoch 8 | Step 3194 | loss: 0.3367892580441429 | accuracy: 0.8581601876675603 \n",
      "Epoch 8 | Step 3195 | loss: 0.3364930261265145 | accuracy: 0.8583305481283422 \n",
      "Epoch 8 | Step 3196 | loss: 0.3361754663785296 | accuracy: 0.8585416666666666 \n",
      "Epoch 8 | Step 3197 | loss: 0.3361312987163977 | accuracy: 0.8584607712765957 \n",
      "Epoch 8 | Step 3198 | loss: 0.33602866973105383 | accuracy: 0.85842175066313 \n",
      "Epoch 8 | Step 3199 | loss: 0.33603397358662207 | accuracy: 0.8583416005291006 \n",
      "Epoch 8 | Step 3200 | loss: 0.3357094104025795 | accuracy: 0.8584680079155673 \n",
      "Epoch 8 | Step 3201 | loss: 0.33553672330944134 | accuracy: 0.8585526315789473 \n",
      "Epoch 8 | Step 3202 | loss: 0.33540797687265167 | accuracy: 0.858636811023622 \n",
      "Epoch 8 | Step 3203 | loss: 0.3352045175760826 | accuracy: 0.8586387434554974 \n",
      "Epoch 8 | Step 3204 | loss: 0.3351598005381948 | accuracy: 0.8585590731070496 \n",
      "Epoch 8 | Step 3205 | loss: 0.335243397625163 | accuracy: 0.8584391276041666 \n",
      "Epoch 8 | Step 3206 | loss: 0.3354701358002499 | accuracy: 0.8583603896103896 \n",
      "Epoch 8 | Step 3207 | loss: 0.3356820007525575 | accuracy: 0.8583225388601037 \n",
      "Epoch 8 | Step 3208 | loss: 0.3357925776209324 | accuracy: 0.858406007751938 \n",
      "Epoch 8 | Step 3209 | loss: 0.3356431757973639 | accuracy: 0.8584085051546392 \n",
      "Epoch 8 | Step 3210 | loss: 0.3358385964347033 | accuracy: 0.8583306555269923 \n",
      "Epoch 8 | Step 3211 | loss: 0.33568205474278845 | accuracy: 0.8583333333333333 \n",
      "Epoch 8 | Step 3212 | loss: 0.335784637943253 | accuracy: 0.8582960358056266 \n",
      "Epoch 8 | Step 3213 | loss: 0.33568329082763904 | accuracy: 0.8582987882653061 \n",
      "Epoch 8 | Step 3214 | loss: 0.33553931867803305 | accuracy: 0.8583810432569975 \n",
      "Epoch 8 | Step 3215 | loss: 0.3357239361039271 | accuracy: 0.8581852791878173 \n",
      "Epoch 8 | Step 3216 | loss: 0.3356334349777123 | accuracy: 0.8582674050632911 \n",
      "Epoch 8 | Step 3217 | loss: 0.33552159218475053 | accuracy: 0.858270202020202 \n",
      "Epoch 8 | Step 3218 | loss: 0.33567294088058547 | accuracy: 0.8581549118387909 \n",
      "Epoch 8 | Step 3219 | loss: 0.3359294749384547 | accuracy: 0.8580009422110553 \n",
      "Epoch 8 | Step 3220 | loss: 0.33576741149849737 | accuracy: 0.8580435463659147 \n",
      "Epoch 8 | Step 3221 | loss: 0.336003742739558 | accuracy: 0.8579296875 \n",
      "Epoch 8 | Step 3222 | loss: 0.3359774305041589 | accuracy: 0.8580112219451371 \n",
      "Epoch 8 | Step 3223 | loss: 0.3363936857797611 | accuracy: 0.8578591417910447 \n",
      "Epoch 8 | Step 3224 | loss: 0.3361453041249408 | accuracy: 0.8580407183756011 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.5145552158355713 | accuracy: 0.734375 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.519106924533844 | accuracy: 0.7265625 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4633818070093791 | accuracy: 0.7708333333333334 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4608544185757637 | accuracy: 0.77734375 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.46227540373802184 | accuracy: 0.778125 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.45103777945041656 | accuracy: 0.7786458333333334 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4440781729561942 | accuracy: 0.7879464285714286 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.437524750828743 | accuracy: 0.787109375 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.43197577198346454 | accuracy: 0.7934027777777778 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.43483407199382784 | accuracy: 0.7984375 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.43443693356080487 | accuracy: 0.8025568181818182 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.42677491158246994 | accuracy: 0.8033854166666666 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4289304820390848 | accuracy: 0.8016826923076923 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.430834812777383 | accuracy: 0.8024553571428571 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4222427864869436 | accuracy: 0.8083333333333333 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4209092427045107 | accuracy: 0.8076171875 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.43081114747945 | accuracy: 0.8051470588235294 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4272511551777522 | accuracy: 0.8064236111111112 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4280647541347303 | accuracy: 0.8075657894736842 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.42520294040441514 | accuracy: 0.8078125 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.425374421335402 | accuracy: 0.8087797619047619 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.42150111902843823 | accuracy: 0.8110795454545454 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.42479249705439026 | accuracy: 0.8091032608695652 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4268335762123267 | accuracy: 0.8079427083333334 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4297108781337738 | accuracy: 0.80625 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4238628836778494 | accuracy: 0.8094951923076923 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.42218810430279485 | accuracy: 0.8101851851851852 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.41913762795073645 | accuracy: 0.8119419642857143 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4205589643840132 | accuracy: 0.8098060344827587 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4208671967188517 | accuracy: 0.8098958333333334 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4166962629364383 | accuracy: 0.8119959677419355 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4115906562656164 | accuracy: 0.81494140625 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.41027884952949756 | accuracy: 0.8162878787878788 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.41776124168844786 | accuracy: 0.8129595588235294 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.41693518076624186 | accuracy: 0.8129464285714286 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4139418080449104 | accuracy: 0.8142361111111112 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.41577183717005955 | accuracy: 0.8146114864864865 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.41604702645226527 | accuracy: 0.8133223684210527 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4147641223210555 | accuracy: 0.8137019230769231 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4167498894035816 | accuracy: 0.812890625 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4187030712278878 | accuracy: 0.8113567073170732 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4163337931746528 | accuracy: 0.8128720238095238 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.41659348787263384 | accuracy: 0.8121366279069767 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.417492884803902 | accuracy: 0.8107244318181818 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4201464103327857 | accuracy: 0.8091334541638692 \n",
      "Epoch 9 | Step 3225 | loss: 0.2904245853424072 | accuracy: 0.90625 \n",
      "Epoch 9 | Step 3226 | loss: 0.35784830152988434 | accuracy: 0.875 \n",
      "Epoch 9 | Step 3227 | loss: 0.3146864026784897 | accuracy: 0.8854166666666666 \n",
      "Epoch 9 | Step 3228 | loss: 0.31306256726384163 | accuracy: 0.8828125 \n",
      "Epoch 9 | Step 3229 | loss: 0.3089791387319565 | accuracy: 0.88125 \n",
      "Epoch 9 | Step 3230 | loss: 0.318960539996624 | accuracy: 0.8723958333333334 \n",
      "Epoch 9 | Step 3231 | loss: 0.32132434632096973 | accuracy: 0.8727678571428571 \n",
      "Epoch 9 | Step 3232 | loss: 0.339172737672925 | accuracy: 0.87109375 \n",
      "Epoch 9 | Step 3233 | loss: 0.33214711977375877 | accuracy: 0.875 \n",
      "Epoch 9 | Step 3234 | loss: 0.3454849377274513 | accuracy: 0.865625 \n",
      "Epoch 9 | Step 3235 | loss: 0.3412515453316949 | accuracy: 0.8664772727272727 \n",
      "Epoch 9 | Step 3236 | loss: 0.3522530657549699 | accuracy: 0.8567708333333334 \n",
      "Epoch 9 | Step 3237 | loss: 0.3438306565468128 | accuracy: 0.8629807692307693 \n",
      "Epoch 9 | Step 3238 | loss: 0.3480151295661926 | accuracy: 0.8627232142857143 \n",
      "Epoch 9 | Step 3239 | loss: 0.3407629837592443 | accuracy: 0.8677083333333333 \n",
      "Epoch 9 | Step 3240 | loss: 0.33084322419017553 | accuracy: 0.8720703125 \n",
      "Epoch 9 | Step 3241 | loss: 0.32835902448962717 | accuracy: 0.8731617647058824 \n",
      "Epoch 9 | Step 3242 | loss: 0.32933271676301956 | accuracy: 0.8715277777777778 \n",
      "Epoch 9 | Step 3243 | loss: 0.3265898925693412 | accuracy: 0.8725328947368421 \n",
      "Epoch 9 | Step 3244 | loss: 0.3272115968167782 | accuracy: 0.87421875 \n",
      "Epoch 9 | Step 3245 | loss: 0.3280084367309298 | accuracy: 0.8720238095238095 \n",
      "Epoch 9 | Step 3246 | loss: 0.32747235284610227 | accuracy: 0.8728693181818182 \n",
      "Epoch 9 | Step 3247 | loss: 0.32296611627806787 | accuracy: 0.8743206521739131 \n",
      "Epoch 9 | Step 3248 | loss: 0.32048666663467884 | accuracy: 0.8736979166666666 \n",
      "Epoch 9 | Step 3249 | loss: 0.31694236934185027 | accuracy: 0.875 \n",
      "Epoch 9 | Step 3250 | loss: 0.318776809825347 | accuracy: 0.8725961538461539 \n",
      "Epoch 9 | Step 3251 | loss: 0.3195493602090412 | accuracy: 0.8721064814814815 \n",
      "Epoch 9 | Step 3252 | loss: 0.3137167915701866 | accuracy: 0.875 \n",
      "Epoch 9 | Step 3253 | loss: 0.31161084565623054 | accuracy: 0.8755387931034483 \n",
      "Epoch 9 | Step 3254 | loss: 0.31261384586493174 | accuracy: 0.875 \n",
      "Epoch 9 | Step 3255 | loss: 0.31120781360134003 | accuracy: 0.876008064516129 \n",
      "Epoch 9 | Step 3256 | loss: 0.3120961580425501 | accuracy: 0.8759765625 \n",
      "Epoch 9 | Step 3257 | loss: 0.3170443285595287 | accuracy: 0.875 \n",
      "Epoch 9 | Step 3258 | loss: 0.3190004781765096 | accuracy: 0.8754595588235294 \n",
      "Epoch 9 | Step 3259 | loss: 0.31944736242294314 | accuracy: 0.875 \n",
      "Epoch 9 | Step 3260 | loss: 0.32179662750826943 | accuracy: 0.8736979166666666 \n",
      "Epoch 9 | Step 3261 | loss: 0.31965967126794764 | accuracy: 0.8733108108108109 \n",
      "Epoch 9 | Step 3262 | loss: 0.3184649552169599 | accuracy: 0.8725328947368421 \n",
      "Epoch 9 | Step 3263 | loss: 0.3167616984783075 | accuracy: 0.8745993589743589 \n",
      "Epoch 9 | Step 3264 | loss: 0.3154652275145054 | accuracy: 0.874609375 \n",
      "Epoch 9 | Step 3265 | loss: 0.31561989609788105 | accuracy: 0.8746189024390244 \n",
      "Epoch 9 | Step 3266 | loss: 0.3154409414245969 | accuracy: 0.875 \n",
      "Epoch 9 | Step 3267 | loss: 0.31319992278897485 | accuracy: 0.8757267441860465 \n",
      "Epoch 9 | Step 3268 | loss: 0.3124119686809453 | accuracy: 0.8753551136363636 \n",
      "Epoch 9 | Step 3269 | loss: 0.3149463170104556 | accuracy: 0.8739583333333333 \n",
      "Epoch 9 | Step 3270 | loss: 0.31545360451159266 | accuracy: 0.873641304347826 \n",
      "Epoch 9 | Step 3271 | loss: 0.3147464775024576 | accuracy: 0.8730053191489362 \n",
      "Epoch 9 | Step 3272 | loss: 0.3163514925787846 | accuracy: 0.8714192708333334 \n",
      "Epoch 9 | Step 3273 | loss: 0.31434447424752365 | accuracy: 0.8727678571428571 \n",
      "Epoch 9 | Step 3274 | loss: 0.31504488825798027 | accuracy: 0.8725 \n",
      "Epoch 9 | Step 3275 | loss: 0.3175684418164047 | accuracy: 0.8713235294117647 \n",
      "Epoch 9 | Step 3276 | loss: 0.3199115527363923 | accuracy: 0.8698918269230769 \n",
      "Epoch 9 | Step 3277 | loss: 0.3188162277329642 | accuracy: 0.8702830188679245 \n",
      "Epoch 9 | Step 3278 | loss: 0.31803591163070105 | accuracy: 0.8709490740740741 \n",
      "Epoch 9 | Step 3279 | loss: 0.3161900439045645 | accuracy: 0.871875 \n",
      "Epoch 9 | Step 3280 | loss: 0.3180203379264899 | accuracy: 0.87109375 \n",
      "Epoch 9 | Step 3281 | loss: 0.31718062361081434 | accuracy: 0.8711622807017544 \n",
      "Epoch 9 | Step 3282 | loss: 0.3193014217861767 | accuracy: 0.8698814655172413 \n",
      "Epoch 9 | Step 3283 | loss: 0.3191759793435112 | accuracy: 0.8702330508474576 \n",
      "Epoch 9 | Step 3284 | loss: 0.32081057578325267 | accuracy: 0.8690104166666667 \n",
      "Epoch 9 | Step 3285 | loss: 0.32112836007212026 | accuracy: 0.867827868852459 \n",
      "Epoch 9 | Step 3286 | loss: 0.3209923976852047 | accuracy: 0.8676915322580645 \n",
      "Epoch 9 | Step 3287 | loss: 0.32060070264907103 | accuracy: 0.8680555555555556 \n",
      "Epoch 9 | Step 3288 | loss: 0.3182237588334828 | accuracy: 0.869384765625 \n",
      "Epoch 9 | Step 3289 | loss: 0.3185360209299967 | accuracy: 0.8692307692307693 \n",
      "Epoch 9 | Step 3290 | loss: 0.3159977398586995 | accuracy: 0.8702651515151515 \n",
      "Epoch 9 | Step 3291 | loss: 0.3151064028046024 | accuracy: 0.8708022388059702 \n",
      "Epoch 9 | Step 3292 | loss: 0.31499174434472527 | accuracy: 0.8713235294117647 \n",
      "Epoch 9 | Step 3293 | loss: 0.3159339926812959 | accuracy: 0.870697463768116 \n",
      "Epoch 9 | Step 3294 | loss: 0.31764803379774087 | accuracy: 0.8696428571428572 \n",
      "Epoch 9 | Step 3295 | loss: 0.3185356903663823 | accuracy: 0.8694982394366197 \n",
      "Epoch 9 | Step 3296 | loss: 0.31772121186885566 | accuracy: 0.8700086805555556 \n",
      "Epoch 9 | Step 3297 | loss: 0.3184027118633871 | accuracy: 0.8694349315068494 \n",
      "Epoch 9 | Step 3298 | loss: 0.3192443672466922 | accuracy: 0.8690878378378378 \n",
      "Epoch 9 | Step 3299 | loss: 0.3202949537833531 | accuracy: 0.86875 \n",
      "Epoch 9 | Step 3300 | loss: 0.31959160044789303 | accuracy: 0.8692434210526315 \n",
      "Epoch 9 | Step 3301 | loss: 0.3202770934863523 | accuracy: 0.8689123376623377 \n",
      "Epoch 9 | Step 3302 | loss: 0.3193931738153481 | accuracy: 0.8689903846153846 \n",
      "Epoch 9 | Step 3303 | loss: 0.3187195241828507 | accuracy: 0.8692642405063291 \n",
      "Epoch 9 | Step 3304 | loss: 0.31818466130644074 | accuracy: 0.869140625 \n",
      "Epoch 9 | Step 3305 | loss: 0.3196142766578697 | accuracy: 0.8682484567901234 \n",
      "Epoch 9 | Step 3306 | loss: 0.3186880673577145 | accuracy: 0.8685213414634146 \n",
      "Epoch 9 | Step 3307 | loss: 0.31905256732400633 | accuracy: 0.8682228915662651 \n",
      "Epoch 9 | Step 3308 | loss: 0.3192819410136767 | accuracy: 0.8677455357142857 \n",
      "Epoch 9 | Step 3309 | loss: 0.31960998107405264 | accuracy: 0.868014705882353 \n",
      "Epoch 9 | Step 3310 | loss: 0.3186285980912142 | accuracy: 0.8684593023255814 \n",
      "Epoch 9 | Step 3311 | loss: 0.31841519098172244 | accuracy: 0.869073275862069 \n",
      "Epoch 9 | Step 3312 | loss: 0.3184952922165394 | accuracy: 0.869140625 \n",
      "Epoch 9 | Step 3313 | loss: 0.31826420814803474 | accuracy: 0.8688553370786517 \n",
      "Epoch 9 | Step 3314 | loss: 0.3187774813837475 | accuracy: 0.8682291666666667 \n",
      "Epoch 9 | Step 3315 | loss: 0.3183821862215524 | accuracy: 0.8681318681318682 \n",
      "Epoch 9 | Step 3316 | loss: 0.32037995464127994 | accuracy: 0.8675271739130435 \n",
      "Epoch 9 | Step 3317 | loss: 0.3225710542612178 | accuracy: 0.8665994623655914 \n",
      "Epoch 9 | Step 3318 | loss: 0.3214419384269004 | accuracy: 0.8675199468085106 \n",
      "Epoch 9 | Step 3319 | loss: 0.32061540892249657 | accuracy: 0.8675986842105263 \n",
      "Epoch 9 | Step 3320 | loss: 0.3194084389445682 | accuracy: 0.8681640625 \n",
      "Epoch 9 | Step 3321 | loss: 0.31862998392778574 | accuracy: 0.8685567010309279 \n",
      "Epoch 9 | Step 3322 | loss: 0.3196670694314704 | accuracy: 0.8676658163265306 \n",
      "Epoch 9 | Step 3323 | loss: 0.3187652967794977 | accuracy: 0.8683712121212122 \n",
      "Epoch 9 | Step 3324 | loss: 0.31946261167526246 | accuracy: 0.86796875 \n",
      "Epoch 9 | Step 3325 | loss: 0.31944068617159777 | accuracy: 0.8680383663366337 \n",
      "Epoch 9 | Step 3326 | loss: 0.31976785700695187 | accuracy: 0.867953431372549 \n",
      "Epoch 9 | Step 3327 | loss: 0.31988995052078395 | accuracy: 0.867870145631068 \n",
      "Epoch 9 | Step 3328 | loss: 0.32007237151265144 | accuracy: 0.8683894230769231 \n",
      "Epoch 9 | Step 3329 | loss: 0.32092352509498595 | accuracy: 0.8681547619047619 \n",
      "Epoch 9 | Step 3330 | loss: 0.3202614595867553 | accuracy: 0.8683667452830188 \n",
      "Epoch 9 | Step 3331 | loss: 0.3204704832250827 | accuracy: 0.8682827102803738 \n",
      "Epoch 9 | Step 3332 | loss: 0.3214296833784492 | accuracy: 0.8679108796296297 \n",
      "Epoch 9 | Step 3333 | loss: 0.3202305538665264 | accuracy: 0.8684059633027523 \n",
      "Epoch 9 | Step 3334 | loss: 0.32017904100092975 | accuracy: 0.868465909090909 \n",
      "Epoch 9 | Step 3335 | loss: 0.3212717783612174 | accuracy: 0.8676801801801802 \n",
      "Epoch 9 | Step 3336 | loss: 0.3223765464499593 | accuracy: 0.8670479910714286 \n",
      "Epoch 9 | Step 3337 | loss: 0.32208195394646805 | accuracy: 0.8672566371681416 \n",
      "Epoch 9 | Step 3338 | loss: 0.3220875656657052 | accuracy: 0.8673245614035088 \n",
      "Epoch 9 | Step 3339 | loss: 0.3216373843991238 | accuracy: 0.8675271739130435 \n",
      "Epoch 9 | Step 3340 | loss: 0.32102542357711955 | accuracy: 0.8679956896551724 \n",
      "Epoch 9 | Step 3341 | loss: 0.3207442168241892 | accuracy: 0.8683226495726496 \n",
      "Epoch 9 | Step 3342 | loss: 0.32123911671214184 | accuracy: 0.8679819915254238 \n",
      "Epoch 9 | Step 3343 | loss: 0.3220954553670242 | accuracy: 0.8673844537815126 \n",
      "Epoch 9 | Step 3344 | loss: 0.32202511417369045 | accuracy: 0.8673177083333333 \n",
      "Epoch 9 | Step 3345 | loss: 0.3212700642583784 | accuracy: 0.8675103305785123 \n",
      "Epoch 9 | Step 3346 | loss: 0.3217388097135747 | accuracy: 0.8673155737704918 \n",
      "Epoch 9 | Step 3347 | loss: 0.3215650558713975 | accuracy: 0.8672510162601627 \n",
      "Epoch 9 | Step 3348 | loss: 0.3224551664485085 | accuracy: 0.8668094758064516 \n",
      "Epoch 9 | Step 3349 | loss: 0.32246661269664767 | accuracy: 0.86675 \n",
      "Epoch 9 | Step 3350 | loss: 0.3220161780241936 | accuracy: 0.8670634920634921 \n",
      "Epoch 9 | Step 3351 | loss: 0.3227172685185755 | accuracy: 0.8663877952755905 \n",
      "Epoch 9 | Step 3352 | loss: 0.3222997196717188 | accuracy: 0.8668212890625 \n",
      "Epoch 9 | Step 3353 | loss: 0.3224220683639364 | accuracy: 0.8665213178294574 \n",
      "Epoch 9 | Step 3354 | loss: 0.32233317024432695 | accuracy: 0.8668269230769231 \n",
      "Epoch 9 | Step 3355 | loss: 0.3225949287187052 | accuracy: 0.8671278625954199 \n",
      "Epoch 9 | Step 3356 | loss: 0.32251807178060216 | accuracy: 0.8670691287878788 \n",
      "Epoch 9 | Step 3357 | loss: 0.32216210416833263 | accuracy: 0.8671287593984962 \n",
      "Epoch 9 | Step 3358 | loss: 0.3214669689091284 | accuracy: 0.8675373134328358 \n",
      "Epoch 9 | Step 3359 | loss: 0.32178814510504405 | accuracy: 0.8677083333333333 \n",
      "Epoch 9 | Step 3360 | loss: 0.3217615514774533 | accuracy: 0.8679917279411765 \n",
      "Epoch 9 | Step 3361 | loss: 0.3225652274206607 | accuracy: 0.8674726277372263 \n",
      "Epoch 9 | Step 3362 | loss: 0.32215049722488376 | accuracy: 0.8674139492753624 \n",
      "Epoch 9 | Step 3363 | loss: 0.3226426997416311 | accuracy: 0.8667940647482015 \n",
      "Epoch 9 | Step 3364 | loss: 0.3227976995919432 | accuracy: 0.8665178571428572 \n",
      "Epoch 9 | Step 3365 | loss: 0.3229383068515899 | accuracy: 0.8663563829787235 \n",
      "Epoch 9 | Step 3366 | loss: 0.32262948648610584 | accuracy: 0.8665272887323945 \n",
      "Epoch 9 | Step 3367 | loss: 0.32228501537046234 | accuracy: 0.8669143356643357 \n",
      "Epoch 9 | Step 3368 | loss: 0.3223872452767359 | accuracy: 0.8667534722222223 \n",
      "Epoch 9 | Step 3369 | loss: 0.3220358954421405 | accuracy: 0.8667025862068967 \n",
      "Epoch 9 | Step 3370 | loss: 0.32218432620371856 | accuracy: 0.8666523972602741 \n",
      "Epoch 9 | Step 3371 | loss: 0.3222768386813248 | accuracy: 0.8667091836734695 \n",
      "Epoch 9 | Step 3372 | loss: 0.3220114241782072 | accuracy: 0.8667652027027027 \n",
      "Epoch 9 | Step 3373 | loss: 0.3220883654868042 | accuracy: 0.8669253355704698 \n",
      "Epoch 9 | Step 3374 | loss: 0.3213973770538965 | accuracy: 0.8672916666666667 \n",
      "Epoch 9 | Step 3375 | loss: 0.32133255889084156 | accuracy: 0.867135761589404 \n",
      "Epoch 9 | Step 3376 | loss: 0.32178191683794316 | accuracy: 0.8672902960526315 \n",
      "Epoch 9 | Step 3377 | loss: 0.32226949754883255 | accuracy: 0.8673406862745098 \n",
      "Epoch 9 | Step 3378 | loss: 0.3215341515742339 | accuracy: 0.8674918831168831 \n",
      "Epoch 9 | Step 3379 | loss: 0.32060474051583193 | accuracy: 0.8680443548387097 \n",
      "Epoch 9 | Step 3380 | loss: 0.3198688889925296 | accuracy: 0.8683894230769231 \n",
      "Epoch 9 | Step 3381 | loss: 0.31959837542218 | accuracy: 0.8683320063694268 \n",
      "Epoch 9 | Step 3382 | loss: 0.3193353746510758 | accuracy: 0.8684731012658228 \n",
      "Epoch 9 | Step 3383 | loss: 0.3193531763628593 | accuracy: 0.8684158805031447 \n",
      "Epoch 9 | Step 3384 | loss: 0.31915385164320464 | accuracy: 0.8685546875 \n",
      "Epoch 9 | Step 3385 | loss: 0.3189186039178267 | accuracy: 0.8686917701863354 \n",
      "Epoch 9 | Step 3386 | loss: 0.31919904016418216 | accuracy: 0.8685378086419753 \n",
      "Epoch 9 | Step 3387 | loss: 0.3184290659025402 | accuracy: 0.8689608895705522 \n",
      "Epoch 9 | Step 3388 | loss: 0.3182042885299135 | accuracy: 0.8688071646341463 \n",
      "Epoch 9 | Step 3389 | loss: 0.31817887416391655 | accuracy: 0.868655303030303 \n",
      "Epoch 9 | Step 3390 | loss: 0.3193768191947994 | accuracy: 0.8680346385542169 \n",
      "Epoch 9 | Step 3391 | loss: 0.31880053431687944 | accuracy: 0.8682634730538922 \n",
      "Epoch 9 | Step 3392 | loss: 0.3185141863567487 | accuracy: 0.8681175595238095 \n",
      "Epoch 9 | Step 3393 | loss: 0.3198003754813289 | accuracy: 0.8677884615384616 \n",
      "Epoch 9 | Step 3394 | loss: 0.31980482515166775 | accuracy: 0.8677389705882353 \n",
      "Epoch 9 | Step 3395 | loss: 0.320251328031919 | accuracy: 0.8674159356725146 \n",
      "Epoch 9 | Step 3396 | loss: 0.3205816823729248 | accuracy: 0.8672783430232558 \n",
      "Epoch 9 | Step 3397 | loss: 0.3193550956559318 | accuracy: 0.8679552023121387 \n",
      "Epoch 9 | Step 3398 | loss: 0.3196516210834184 | accuracy: 0.8679058908045977 \n",
      "Epoch 9 | Step 3399 | loss: 0.31948896978582636 | accuracy: 0.868125 \n",
      "Epoch 9 | Step 3400 | loss: 0.31926777510141763 | accuracy: 0.8685191761363636 \n",
      "Epoch 9 | Step 3401 | loss: 0.319715656213841 | accuracy: 0.8684675141242938 \n",
      "Epoch 9 | Step 3402 | loss: 0.3198197439647791 | accuracy: 0.8685042134831461 \n",
      "Epoch 9 | Step 3403 | loss: 0.3198642863075159 | accuracy: 0.8686277932960894 \n",
      "Epoch 9 | Step 3404 | loss: 0.32024790073434495 | accuracy: 0.8684027777777777 \n",
      "Epoch 9 | Step 3405 | loss: 0.31974200542131165 | accuracy: 0.8686118784530387 \n",
      "Epoch 9 | Step 3406 | loss: 0.3192979732712545 | accuracy: 0.8689903846153846 \n",
      "Epoch 9 | Step 3407 | loss: 0.31884693032731104 | accuracy: 0.8693647540983607 \n",
      "Epoch 9 | Step 3408 | loss: 0.31897632478047955 | accuracy: 0.8693953804347826 \n",
      "Epoch 9 | Step 3409 | loss: 0.31913087279409963 | accuracy: 0.8693412162162162 \n",
      "Epoch 9 | Step 3410 | loss: 0.3189876807793493 | accuracy: 0.8693716397849462 \n",
      "Epoch 9 | Step 3411 | loss: 0.3193162572097012 | accuracy: 0.8692346256684492 \n",
      "Epoch 9 | Step 3412 | loss: 0.31909209798942206 | accuracy: 0.8695146276595744 \n",
      "Epoch 9 | Step 3413 | loss: 0.31876267398160585 | accuracy: 0.8697916666666666 \n",
      "Epoch 9 | Step 3414 | loss: 0.31870167780863595 | accuracy: 0.8698190789473684 \n",
      "Epoch 9 | Step 3415 | loss: 0.319092946136809 | accuracy: 0.8696825916230366 \n",
      "Epoch 9 | Step 3416 | loss: 0.3191581172092506 | accuracy: 0.86962890625 \n",
      "Epoch 9 | Step 3417 | loss: 0.31964977656930205 | accuracy: 0.8693329015544041 \n",
      "Epoch 9 | Step 3418 | loss: 0.3191832322435279 | accuracy: 0.8694426546391752 \n",
      "Epoch 9 | Step 3419 | loss: 0.3196983623198972 | accuracy: 0.869150641025641 \n",
      "Epoch 9 | Step 3420 | loss: 0.31959747583890424 | accuracy: 0.8692602040816326 \n",
      "Epoch 9 | Step 3421 | loss: 0.3196919749533462 | accuracy: 0.8691307106598984 \n",
      "Epoch 9 | Step 3422 | loss: 0.32002449381833104 | accuracy: 0.868844696969697 \n",
      "Epoch 9 | Step 3423 | loss: 0.32050129366879465 | accuracy: 0.8687185929648241 \n",
      "Epoch 9 | Step 3424 | loss: 0.3202026222646234 | accuracy: 0.868984375 \n",
      "Epoch 9 | Step 3425 | loss: 0.32045588090052035 | accuracy: 0.8687810945273632 \n",
      "Epoch 9 | Step 3426 | loss: 0.3207048131982877 | accuracy: 0.8687345297029703 \n",
      "Epoch 9 | Step 3427 | loss: 0.3202665684552026 | accuracy: 0.869073275862069 \n",
      "Epoch 9 | Step 3428 | loss: 0.3204345095391365 | accuracy: 0.8689491421568627 \n",
      "Epoch 9 | Step 3429 | loss: 0.3206107710919727 | accuracy: 0.8685975609756098 \n",
      "Epoch 9 | Step 3430 | loss: 0.3203901961011792 | accuracy: 0.8687044902912622 \n",
      "Epoch 9 | Step 3431 | loss: 0.32012133653037195 | accuracy: 0.8688103864734299 \n",
      "Epoch 9 | Step 3432 | loss: 0.3198067802362715 | accuracy: 0.8687650240384616 \n",
      "Epoch 9 | Step 3433 | loss: 0.3199848595418426 | accuracy: 0.8688696172248804 \n",
      "Epoch 9 | Step 3434 | loss: 0.31951024674233913 | accuracy: 0.8689732142857143 \n",
      "Epoch 9 | Step 3435 | loss: 0.3194857412039949 | accuracy: 0.8689277251184834 \n",
      "Epoch 9 | Step 3436 | loss: 0.31973069287695954 | accuracy: 0.8687352594339622 \n",
      "Epoch 9 | Step 3437 | loss: 0.31925027009466983 | accuracy: 0.8689113849765259 \n",
      "Epoch 9 | Step 3438 | loss: 0.31897006218678464 | accuracy: 0.8690128504672897 \n",
      "Epoch 9 | Step 3439 | loss: 0.3193118782930594 | accuracy: 0.8688226744186046 \n",
      "Epoch 9 | Step 3440 | loss: 0.3198390162929339 | accuracy: 0.8686342592592593 \n",
      "Epoch 9 | Step 3441 | loss: 0.3203956108488793 | accuracy: 0.8683035714285714 \n",
      "Epoch 9 | Step 3442 | loss: 0.32010933004934833 | accuracy: 0.8684059633027523 \n",
      "Epoch 9 | Step 3443 | loss: 0.31994118333951505 | accuracy: 0.8682220319634704 \n",
      "Epoch 9 | Step 3444 | loss: 0.32008470093662067 | accuracy: 0.8681107954545455 \n",
      "Epoch 9 | Step 3445 | loss: 0.31965725292447444 | accuracy: 0.8684954751131222 \n",
      "Epoch 9 | Step 3446 | loss: 0.3193005752993058 | accuracy: 0.8688063063063063 \n",
      "Epoch 9 | Step 3447 | loss: 0.3195312787599091 | accuracy: 0.8689041479820628 \n",
      "Epoch 9 | Step 3448 | loss: 0.3194494903353706 | accuracy: 0.8690011160714286 \n",
      "Epoch 9 | Step 3449 | loss: 0.3200117374791037 | accuracy: 0.8686805555555556 \n",
      "Epoch 9 | Step 3450 | loss: 0.3203524000349296 | accuracy: 0.8685702433628318 \n",
      "Epoch 9 | Step 3451 | loss: 0.3204001502055952 | accuracy: 0.8685297356828194 \n",
      "Epoch 9 | Step 3452 | loss: 0.3203077616921641 | accuracy: 0.8683525219298246 \n",
      "Epoch 9 | Step 3453 | loss: 0.319793777629798 | accuracy: 0.8687227074235808 \n",
      "Epoch 9 | Step 3454 | loss: 0.3194505826934522 | accuracy: 0.8688179347826087 \n",
      "Epoch 9 | Step 3455 | loss: 0.3197965705162517 | accuracy: 0.8687094155844156 \n",
      "Epoch 9 | Step 3456 | loss: 0.3192211234749389 | accuracy: 0.8688712284482759 \n",
      "Epoch 9 | Step 3457 | loss: 0.3193347633780326 | accuracy: 0.8687634120171673 \n",
      "Epoch 9 | Step 3458 | loss: 0.3194764211264429 | accuracy: 0.8685897435897436 \n",
      "Epoch 9 | Step 3459 | loss: 0.319085032128273 | accuracy: 0.8688829787234043 \n",
      "Epoch 9 | Step 3460 | loss: 0.31910490964428834 | accuracy: 0.869041313559322 \n",
      "Epoch 9 | Step 3461 | loss: 0.31938557333081063 | accuracy: 0.868868670886076 \n",
      "Epoch 9 | Step 3462 | loss: 0.3197515323883343 | accuracy: 0.8688944327731093 \n",
      "Epoch 9 | Step 3463 | loss: 0.3195701495872879 | accuracy: 0.8691161087866108 \n",
      "Epoch 9 | Step 3464 | loss: 0.31928110805650534 | accuracy: 0.8692708333333333 \n",
      "Epoch 9 | Step 3465 | loss: 0.31956605965665746 | accuracy: 0.8690352697095436 \n",
      "Epoch 9 | Step 3466 | loss: 0.31967701054801606 | accuracy: 0.8689953512396694 \n",
      "Epoch 9 | Step 3467 | loss: 0.31967812285992325 | accuracy: 0.8690843621399177 \n",
      "Epoch 9 | Step 3468 | loss: 0.31902770209507847 | accuracy: 0.8694287909836066 \n",
      "Epoch 9 | Step 3469 | loss: 0.318682461186331 | accuracy: 0.8696428571428572 \n",
      "Epoch 9 | Step 3470 | loss: 0.3183324150438229 | accuracy: 0.8697916666666666 \n",
      "Epoch 9 | Step 3471 | loss: 0.3180311181646608 | accuracy: 0.8699392712550608 \n",
      "Epoch 9 | Step 3472 | loss: 0.31829135606606146 | accuracy: 0.8698336693548387 \n",
      "Epoch 9 | Step 3473 | loss: 0.3184407322880732 | accuracy: 0.8697289156626506 \n",
      "Epoch 9 | Step 3474 | loss: 0.318099176943302 | accuracy: 0.8699375 \n",
      "Epoch 9 | Step 3475 | loss: 0.31836544487818286 | accuracy: 0.8698954183266933 \n",
      "Epoch 9 | Step 3476 | loss: 0.3186206769730362 | accuracy: 0.8698536706349206 \n",
      "Epoch 9 | Step 3477 | loss: 0.3187548048764819 | accuracy: 0.8697504940711462 \n",
      "Epoch 9 | Step 3478 | loss: 0.3187502869588182 | accuracy: 0.8697711614173228 \n",
      "Epoch 9 | Step 3479 | loss: 0.3185802134228686 | accuracy: 0.8699142156862745 \n",
      "Epoch 9 | Step 3480 | loss: 0.3186620819033122 | accuracy: 0.86981201171875 \n",
      "Epoch 9 | Step 3481 | loss: 0.318747078688228 | accuracy: 0.8697714007782101 \n",
      "Epoch 9 | Step 3482 | loss: 0.3188906719171722 | accuracy: 0.8696705426356589 \n",
      "Epoch 9 | Step 3483 | loss: 0.3189764156880064 | accuracy: 0.8695101351351351 \n",
      "Epoch 9 | Step 3484 | loss: 0.3189792598096222 | accuracy: 0.8694711538461538 \n",
      "Epoch 9 | Step 3485 | loss: 0.31873401616953323 | accuracy: 0.8695522030651341 \n",
      "Epoch 9 | Step 3486 | loss: 0.319240942768013 | accuracy: 0.8692151717557252 \n",
      "Epoch 9 | Step 3487 | loss: 0.3190983819984209 | accuracy: 0.8692965779467681 \n",
      "Epoch 9 | Step 3488 | loss: 0.3189618023620408 | accuracy: 0.8693181818181818 \n",
      "Epoch 9 | Step 3489 | loss: 0.3188408307871726 | accuracy: 0.8691627358490566 \n",
      "Epoch 9 | Step 3490 | loss: 0.3189088888746453 | accuracy: 0.8690084586466166 \n",
      "Epoch 9 | Step 3491 | loss: 0.31863228714421427 | accuracy: 0.8691479400749064 \n",
      "Epoch 9 | Step 3492 | loss: 0.3188203347485455 | accuracy: 0.8688782649253731 \n",
      "Epoch 9 | Step 3493 | loss: 0.3187612829155193 | accuracy: 0.868842936802974 \n",
      "Epoch 9 | Step 3494 | loss: 0.3187924584856738 | accuracy: 0.8686921296296296 \n",
      "Epoch 9 | Step 3495 | loss: 0.3187115498134569 | accuracy: 0.868715405904059 \n",
      "Epoch 9 | Step 3496 | loss: 0.31847826774944255 | accuracy: 0.8688534007352942 \n",
      "Epoch 9 | Step 3497 | loss: 0.3186203833028072 | accuracy: 0.8688186813186813 \n",
      "Epoch 9 | Step 3498 | loss: 0.31879951244723165 | accuracy: 0.8688982664233577 \n",
      "Epoch 9 | Step 3499 | loss: 0.3185454598340119 | accuracy: 0.8690340909090909 \n",
      "Epoch 9 | Step 3500 | loss: 0.3188981788529864 | accuracy: 0.8688292572463768 \n",
      "Epoch 9 | Step 3501 | loss: 0.31871654485967593 | accuracy: 0.8688515342960289 \n",
      "Epoch 9 | Step 3502 | loss: 0.31846379547667997 | accuracy: 0.8689298561151079 \n",
      "Epoch 9 | Step 3503 | loss: 0.3182396205095405 | accuracy: 0.8690076164874552 \n",
      "Epoch 9 | Step 3504 | loss: 0.3182708049459115 | accuracy: 0.8688058035714286 \n",
      "Epoch 9 | Step 3505 | loss: 0.31812666637617476 | accuracy: 0.868827846975089 \n",
      "Epoch 9 | Step 3506 | loss: 0.31787477798284347 | accuracy: 0.8688497340425532 \n",
      "Epoch 9 | Step 3507 | loss: 0.3178436608175505 | accuracy: 0.8688162544169611 \n",
      "Epoch 9 | Step 3508 | loss: 0.31744174360179545 | accuracy: 0.8691131161971831 \n",
      "Epoch 9 | Step 3509 | loss: 0.3174095749332192 | accuracy: 0.8690241228070176 \n",
      "Epoch 9 | Step 3510 | loss: 0.3168727285065849 | accuracy: 0.869263548951049 \n",
      "Epoch 9 | Step 3511 | loss: 0.31686063816946125 | accuracy: 0.8691202090592335 \n",
      "Epoch 9 | Step 3512 | loss: 0.31655316489438196 | accuracy: 0.8692491319444444 \n",
      "Epoch 9 | Step 3513 | loss: 0.3171166410495664 | accuracy: 0.8691068339100346 \n",
      "Epoch 9 | Step 3514 | loss: 0.3168964374681997 | accuracy: 0.8693426724137931 \n",
      "Epoch 9 | Step 3515 | loss: 0.3173997467735787 | accuracy: 0.8692547250859106 \n",
      "Epoch 9 | Step 3516 | loss: 0.31731484248621805 | accuracy: 0.869220890410959 \n",
      "Epoch 9 | Step 3517 | loss: 0.31733018597238283 | accuracy: 0.8692939419795223 \n",
      "Epoch 9 | Step 3518 | loss: 0.3175040694321092 | accuracy: 0.8692070578231293 \n",
      "Epoch 9 | Step 3519 | loss: 0.317363077200065 | accuracy: 0.8692796610169492 \n",
      "Epoch 9 | Step 3520 | loss: 0.3174708149320368 | accuracy: 0.8692989864864865 \n",
      "Epoch 9 | Step 3521 | loss: 0.31744698221836004 | accuracy: 0.8694234006734006 \n",
      "Epoch 9 | Step 3522 | loss: 0.31725862272233746 | accuracy: 0.8695469798657718 \n",
      "Epoch 9 | Step 3523 | loss: 0.3172439421499052 | accuracy: 0.869617474916388 \n",
      "Epoch 9 | Step 3524 | loss: 0.3169309890766936 | accuracy: 0.86984375 \n",
      "Epoch 9 | Step 3525 | loss: 0.31728884295569676 | accuracy: 0.8695494186046512 \n",
      "Epoch 9 | Step 3526 | loss: 0.31705360084969453 | accuracy: 0.8697226821192053 \n",
      "Epoch 9 | Step 3527 | loss: 0.3168762396074362 | accuracy: 0.869894801980198 \n",
      "Epoch 9 | Step 3528 | loss: 0.3169377724591052 | accuracy: 0.8698087993421053 \n",
      "Epoch 9 | Step 3529 | loss: 0.31673346318182377 | accuracy: 0.8698770491803278 \n",
      "Epoch 9 | Step 3530 | loss: 0.3166919135385088 | accuracy: 0.8698427287581699 \n",
      "Epoch 9 | Step 3531 | loss: 0.3173754258924663 | accuracy: 0.8695032573289903 \n",
      "Epoch 9 | Step 3532 | loss: 0.3171317674122846 | accuracy: 0.869622564935065 \n",
      "Epoch 9 | Step 3533 | loss: 0.3167976195951109 | accuracy: 0.8697411003236246 \n",
      "Epoch 9 | Step 3534 | loss: 0.31679748662056445 | accuracy: 0.8698084677419354 \n",
      "Epoch 9 | Step 3535 | loss: 0.3167626630646621 | accuracy: 0.8698754019292605 \n",
      "Epoch 9 | Step 3536 | loss: 0.3167325817048548 | accuracy: 0.869941907051282 \n",
      "Epoch 9 | Step 3537 | loss: 0.31650710672425747 | accuracy: 0.8701078274760383 \n",
      "Epoch 9 | Step 3538 | loss: 0.3168326587339114 | accuracy: 0.8700736464968153 \n",
      "Epoch 9 | Step 3539 | loss: 0.31712692706357853 | accuracy: 0.8699404761904762 \n",
      "Epoch 9 | Step 3540 | loss: 0.3171491165987297 | accuracy: 0.8698575949367089 \n",
      "Epoch 9 | Step 3541 | loss: 0.3168529684799325 | accuracy: 0.870070977917981 \n",
      "Epoch 9 | Step 3542 | loss: 0.31700370821562934 | accuracy: 0.8698408018867925 \n",
      "Epoch 9 | Step 3543 | loss: 0.31696493096859835 | accuracy: 0.86985697492163 \n",
      "Epoch 9 | Step 3544 | loss: 0.31676093237474545 | accuracy: 0.87001953125 \n",
      "Epoch 9 | Step 3545 | loss: 0.31686129311906197 | accuracy: 0.8699863707165109 \n",
      "Epoch 9 | Step 3546 | loss: 0.3172672053116447 | accuracy: 0.8698078416149069 \n",
      "Epoch 9 | Step 3547 | loss: 0.3169897878686708 | accuracy: 0.8699690402476781 \n",
      "Epoch 9 | Step 3548 | loss: 0.3167601328481125 | accuracy: 0.8699845679012346 \n",
      "Epoch 9 | Step 3549 | loss: 0.3168366820537125 | accuracy: 0.8698076923076923 \n",
      "Epoch 9 | Step 3550 | loss: 0.31674782195888396 | accuracy: 0.8698715490797546 \n",
      "Epoch 9 | Step 3551 | loss: 0.3168319383983581 | accuracy: 0.8697916666666666 \n",
      "Epoch 9 | Step 3552 | loss: 0.31688964171562234 | accuracy: 0.8698075457317073 \n",
      "Epoch 9 | Step 3553 | loss: 0.31738111109537903 | accuracy: 0.8694433890577508 \n",
      "Epoch 9 | Step 3554 | loss: 0.3173527767712418 | accuracy: 0.8693181818181818 \n",
      "Epoch 9 | Step 3555 | loss: 0.3171803991329992 | accuracy: 0.8694769637462235 \n",
      "Epoch 9 | Step 3556 | loss: 0.317091414143881 | accuracy: 0.8695406626506024 \n",
      "Epoch 9 | Step 3557 | loss: 0.31700690967721606 | accuracy: 0.8695570570570571 \n",
      "Epoch 9 | Step 3558 | loss: 0.31720428128620803 | accuracy: 0.8694797904191617 \n",
      "Epoch 9 | Step 3559 | loss: 0.31698273420333845 | accuracy: 0.8695429104477612 \n",
      "Epoch 9 | Step 3560 | loss: 0.3168293582718995 | accuracy: 0.8696056547619048 \n",
      "Epoch 9 | Step 3561 | loss: 0.31695384954486455 | accuracy: 0.8695752967359051 \n",
      "Epoch 9 | Step 3562 | loss: 0.3169593765185428 | accuracy: 0.869637573964497 \n",
      "Epoch 9 | Step 3563 | loss: 0.3167951950984717 | accuracy: 0.8696533923303835 \n",
      "Epoch 9 | Step 3564 | loss: 0.31641380186466594 | accuracy: 0.8698069852941176 \n",
      "Epoch 9 | Step 3565 | loss: 0.3161725400567403 | accuracy: 0.8699596774193549 \n",
      "Epoch 9 | Step 3566 | loss: 0.3161114221166447 | accuracy: 0.8698373538011696 \n",
      "Epoch 9 | Step 3567 | loss: 0.3158645673760866 | accuracy: 0.8699435131195336 \n",
      "Epoch 9 | Step 3568 | loss: 0.3157107938774102 | accuracy: 0.8700036337209303 \n",
      "Epoch 9 | Step 3569 | loss: 0.31586532899435 | accuracy: 0.8698822463768116 \n",
      "Epoch 9 | Step 3570 | loss: 0.3159141956984651 | accuracy: 0.8698970375722543 \n",
      "Epoch 9 | Step 3571 | loss: 0.315514359204501 | accuracy: 0.8700468299711815 \n",
      "Epoch 9 | Step 3572 | loss: 0.3159233301278502 | accuracy: 0.8699263649425287 \n",
      "Epoch 9 | Step 3573 | loss: 0.3158083736127972 | accuracy: 0.8699409025787965 \n",
      "Epoch 9 | Step 3574 | loss: 0.31572776168584804 | accuracy: 0.87 \n",
      "Epoch 9 | Step 3575 | loss: 0.3154765598454704 | accuracy: 0.870147792022792 \n",
      "Epoch 9 | Step 3576 | loss: 0.3156200794672422 | accuracy: 0.8701171875 \n",
      "Epoch 9 | Step 3577 | loss: 0.3154065898981038 | accuracy: 0.8702195467422096 \n",
      "Epoch 9 | Step 3578 | loss: 0.31518811867230334 | accuracy: 0.870365466101695 \n",
      "Epoch 9 | Step 3579 | loss: 0.31501152234178176 | accuracy: 0.8704665492957746 \n",
      "Epoch 9 | Step 3580 | loss: 0.31477643373642056 | accuracy: 0.8705670646067416 \n",
      "Epoch 9 | Step 3581 | loss: 0.31474562686364504 | accuracy: 0.8706670168067226 \n",
      "Epoch 9 | Step 3582 | loss: 0.3148817229370829 | accuracy: 0.8705045391061452 \n",
      "Epoch 9 | Step 3583 | loss: 0.3147374675466487 | accuracy: 0.8705170612813371 \n",
      "Epoch 9 | Step 3584 | loss: 0.3145991348558 | accuracy: 0.8705729166666667 \n",
      "Epoch 9 | Step 3585 | loss: 0.31476147939293647 | accuracy: 0.870325484764543 \n",
      "Epoch 9 | Step 3586 | loss: 0.3147238611516371 | accuracy: 0.8702952348066298 \n",
      "Epoch 9 | Step 3587 | loss: 0.31468426910313674 | accuracy: 0.8703942837465565 \n",
      "Epoch 9 | Step 3588 | loss: 0.3146157556182734 | accuracy: 0.8704069368131868 \n",
      "Epoch 9 | Step 3589 | loss: 0.3143921238918825 | accuracy: 0.8705907534246575 \n",
      "Epoch 9 | Step 3590 | loss: 0.3141857307872483 | accuracy: 0.8705601092896175 \n",
      "Epoch 9 | Step 3591 | loss: 0.3141747046800008 | accuracy: 0.8704870572207084 \n",
      "Epoch 9 | Step 3592 | loss: 0.3140129065950925 | accuracy: 0.8705842391304348 \n",
      "Epoch 9 | Step 3593 | loss: 0.314181088310916 | accuracy: 0.8705538617886179 \n",
      "Epoch 9 | Step 3594 | loss: 0.3144713693776644 | accuracy: 0.8703547297297297 \n",
      "Epoch 9 | Step 3595 | loss: 0.314606485220621 | accuracy: 0.8702830188679245 \n",
      "Epoch 9 | Step 3596 | loss: 0.3152964232509493 | accuracy: 0.870085685483871 \n",
      "Epoch 9 | Step 3597 | loss: 0.3154338675353864 | accuracy: 0.8699731903485255 \n",
      "Epoch 9 | Step 3598 | loss: 0.31515322418455116 | accuracy: 0.8701119652406417 \n",
      "Epoch 9 | Step 3599 | loss: 0.3148326116402942 | accuracy: 0.8703333333333333 \n",
      "Epoch 9 | Step 3600 | loss: 0.3148310207464592 | accuracy: 0.870345744680851 \n",
      "Epoch 9 | Step 3601 | loss: 0.31467666763525726 | accuracy: 0.8704409814323607 \n",
      "Epoch 9 | Step 3602 | loss: 0.31467671897360866 | accuracy: 0.8702876984126984 \n",
      "Epoch 9 | Step 3603 | loss: 0.314393036794851 | accuracy: 0.8703825857519789 \n",
      "Epoch 9 | Step 3604 | loss: 0.31418618438275214 | accuracy: 0.8705592105263158 \n",
      "Epoch 9 | Step 3605 | loss: 0.31402558225189897 | accuracy: 0.87061187664042 \n",
      "Epoch 9 | Step 3606 | loss: 0.3137994509638914 | accuracy: 0.8706642670157068 \n",
      "Epoch 9 | Step 3607 | loss: 0.31375448514680615 | accuracy: 0.8705939947780679 \n",
      "Epoch 9 | Step 3608 | loss: 0.3137717886129392 | accuracy: 0.87060546875 \n",
      "Epoch 9 | Step 3609 | loss: 0.3140434643277872 | accuracy: 0.8704951298701299 \n",
      "Epoch 9 | Step 3610 | loss: 0.31423418258601493 | accuracy: 0.8703853626943006 \n",
      "Epoch 9 | Step 3611 | loss: 0.31430216618748574 | accuracy: 0.870437661498708 \n",
      "Epoch 9 | Step 3612 | loss: 0.31419249305251923 | accuracy: 0.8704896907216495 \n",
      "Epoch 9 | Step 3613 | loss: 0.3144173840094346 | accuracy: 0.8703004498714653 \n",
      "Epoch 9 | Step 3614 | loss: 0.31431416758359987 | accuracy: 0.8703125 \n",
      "Epoch 9 | Step 3615 | loss: 0.3144169719246645 | accuracy: 0.87028452685422 \n",
      "Epoch 9 | Step 3616 | loss: 0.3142857237966083 | accuracy: 0.8703762755102041 \n",
      "Epoch 9 | Step 3617 | loss: 0.3140685732734717 | accuracy: 0.8705470737913485 \n",
      "Epoch 9 | Step 3618 | loss: 0.3142589798130963 | accuracy: 0.8703997461928934 \n",
      "Epoch 9 | Step 3619 | loss: 0.314161763538288 | accuracy: 0.8704509493670886 \n",
      "Epoch 9 | Step 3620 | loss: 0.3140353986410178 | accuracy: 0.870541351010101 \n",
      "Epoch 9 | Step 3621 | loss: 0.3141637494041576 | accuracy: 0.8704345088161209 \n",
      "Epoch 9 | Step 3622 | loss: 0.3143513824172953 | accuracy: 0.8702496859296482 \n",
      "Epoch 9 | Step 3623 | loss: 0.31420733240015214 | accuracy: 0.8702615914786967 \n",
      "Epoch 9 | Step 3624 | loss: 0.31450812250375737 | accuracy: 0.8701171875 \n",
      "Epoch 9 | Step 3625 | loss: 0.31452664108644984 | accuracy: 0.8702072942643392 \n",
      "Epoch 9 | Step 3626 | loss: 0.3149093058127075 | accuracy: 0.8700637437810945 \n",
      "Epoch 9 | Step 3627 | loss: 0.31458679037561477 | accuracy: 0.8703006010493333 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.5147146582603455 | accuracy: 0.75 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.5228271484375 | accuracy: 0.734375 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4642645517985026 | accuracy: 0.7708333333333334 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4607539549469948 | accuracy: 0.77734375 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.46304298043251035 | accuracy: 0.78125 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4510974685351054 | accuracy: 0.7838541666666666 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4433197719710214 | accuracy: 0.7946428571428571 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4356689527630806 | accuracy: 0.794921875 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4297801653544108 | accuracy: 0.8003472222222222 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.43257167339324953 | accuracy: 0.803125 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.43302957036278467 | accuracy: 0.8068181818181818 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.42508166283369064 | accuracy: 0.80859375 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4276246932836679 | accuracy: 0.8064903846153846 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4302737670285361 | accuracy: 0.8058035714285714 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4207318882147471 | accuracy: 0.8114583333333333 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4191816244274378 | accuracy: 0.8115234375 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.42953086425276366 | accuracy: 0.8088235294117647 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4256402204434077 | accuracy: 0.8116319444444444 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.42568386385315343 | accuracy: 0.8125 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4225375890731812 | accuracy: 0.81484375 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.42254593400728135 | accuracy: 0.8162202380952381 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.41851711679588666 | accuracy: 0.8181818181818182 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.42153114080429077 | accuracy: 0.8158967391304348 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4230549323062102 | accuracy: 0.814453125 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4265162169933319 | accuracy: 0.81125 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.42027470010977525 | accuracy: 0.8143028846153846 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4187061168529369 | accuracy: 0.8153935185185185 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4153348132967949 | accuracy: 0.8169642857142857 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4170236895824301 | accuracy: 0.8162715517241379 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.41764283577601113 | accuracy: 0.815625 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.41308892734589114 | accuracy: 0.8175403225806451 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.407744025811553 | accuracy: 0.82080078125 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4062468147639072 | accuracy: 0.821969696969697 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4142415374517441 | accuracy: 0.8189338235294118 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4134308729852949 | accuracy: 0.81875 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4101391103532579 | accuracy: 0.8198784722222222 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.41202304894859726 | accuracy: 0.8205236486486487 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4122604484620847 | accuracy: 0.819078947368421 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.41091748002247935 | accuracy: 0.8193108974358975 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.41318889036774636 | accuracy: 0.817578125 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.415361217609266 | accuracy: 0.8159298780487805 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4130327311300096 | accuracy: 0.8169642857142857 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4132231584815092 | accuracy: 0.8164970930232558 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4144841730594635 | accuracy: 0.8149857954545454 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.41737249030007256 | accuracy: 0.8137832125027974 \n",
      "Epoch 10 | Step 3628 | loss: 0.2272321730852127 | accuracy: 0.90625 \n",
      "Epoch 10 | Step 3629 | loss: 0.3120933696627617 | accuracy: 0.859375 \n",
      "Epoch 10 | Step 3630 | loss: 0.27845075726509094 | accuracy: 0.8854166666666666 \n",
      "Epoch 10 | Step 3631 | loss: 0.27851635217666626 | accuracy: 0.89453125 \n",
      "Epoch 10 | Step 3632 | loss: 0.2813695013523102 | accuracy: 0.8875 \n",
      "Epoch 10 | Step 3633 | loss: 0.30451055864493054 | accuracy: 0.8776041666666666 \n",
      "Epoch 10 | Step 3634 | loss: 0.30522850155830383 | accuracy: 0.8772321428571429 \n",
      "Epoch 10 | Step 3635 | loss: 0.32275497168302536 | accuracy: 0.876953125 \n",
      "Epoch 10 | Step 3636 | loss: 0.31683549616071915 | accuracy: 0.8802083333333334 \n",
      "Epoch 10 | Step 3637 | loss: 0.3311280459165573 | accuracy: 0.8703125 \n",
      "Epoch 10 | Step 3638 | loss: 0.32650079239498486 | accuracy: 0.8735795454545454 \n",
      "Epoch 10 | Step 3639 | loss: 0.3350433185696602 | accuracy: 0.8671875 \n",
      "Epoch 10 | Step 3640 | loss: 0.32801540883687824 | accuracy: 0.8713942307692307 \n",
      "Epoch 10 | Step 3641 | loss: 0.3319665076477187 | accuracy: 0.8705357142857143 \n",
      "Epoch 10 | Step 3642 | loss: 0.3245249142249425 | accuracy: 0.875 \n",
      "Epoch 10 | Step 3643 | loss: 0.31464742589741945 | accuracy: 0.8798828125 \n",
      "Epoch 10 | Step 3644 | loss: 0.31270672205616445 | accuracy: 0.8786764705882353 \n",
      "Epoch 10 | Step 3645 | loss: 0.3135925672120518 | accuracy: 0.875 \n",
      "Epoch 10 | Step 3646 | loss: 0.3106051079536739 | accuracy: 0.8766447368421053 \n",
      "Epoch 10 | Step 3647 | loss: 0.31179462298750876 | accuracy: 0.878125 \n",
      "Epoch 10 | Step 3648 | loss: 0.3128112178473246 | accuracy: 0.8764880952380952 \n",
      "Epoch 10 | Step 3649 | loss: 0.31208950213410636 | accuracy: 0.8764204545454546 \n",
      "Epoch 10 | Step 3650 | loss: 0.3078310243461443 | accuracy: 0.8777173913043478 \n",
      "Epoch 10 | Step 3651 | loss: 0.30492668102184933 | accuracy: 0.8782552083333334 \n",
      "Epoch 10 | Step 3652 | loss: 0.3014627993106842 | accuracy: 0.880625 \n",
      "Epoch 10 | Step 3653 | loss: 0.30252088835606206 | accuracy: 0.8786057692307693 \n",
      "Epoch 10 | Step 3654 | loss: 0.3034527787455806 | accuracy: 0.8784722222222222 \n",
      "Epoch 10 | Step 3655 | loss: 0.2973139264753887 | accuracy: 0.8822544642857143 \n",
      "Epoch 10 | Step 3656 | loss: 0.29533092009610146 | accuracy: 0.8825431034482759 \n",
      "Epoch 10 | Step 3657 | loss: 0.29638725121816 | accuracy: 0.8822916666666667 \n",
      "Epoch 10 | Step 3658 | loss: 0.29520707553432834 | accuracy: 0.8840725806451613 \n",
      "Epoch 10 | Step 3659 | loss: 0.29647703003138304 | accuracy: 0.88427734375 \n",
      "Epoch 10 | Step 3660 | loss: 0.30196760639999853 | accuracy: 0.8825757575757576 \n",
      "Epoch 10 | Step 3661 | loss: 0.3026026487350464 | accuracy: 0.8828125 \n",
      "Epoch 10 | Step 3662 | loss: 0.3030965830598559 | accuracy: 0.8825892857142857 \n",
      "Epoch 10 | Step 3663 | loss: 0.3052949574258592 | accuracy: 0.8819444444444444 \n",
      "Epoch 10 | Step 3664 | loss: 0.3026881777756923 | accuracy: 0.8821790540540541 \n",
      "Epoch 10 | Step 3665 | loss: 0.3011607355193088 | accuracy: 0.8824013157894737 \n",
      "Epoch 10 | Step 3666 | loss: 0.29975667901528186 | accuracy: 0.8838141025641025 \n",
      "Epoch 10 | Step 3667 | loss: 0.29922779500484464 | accuracy: 0.88359375 \n",
      "Epoch 10 | Step 3668 | loss: 0.2994770676624484 | accuracy: 0.8826219512195121 \n",
      "Epoch 10 | Step 3669 | loss: 0.29883405566215515 | accuracy: 0.8835565476190477 \n",
      "Epoch 10 | Step 3670 | loss: 0.2966785659623701 | accuracy: 0.8844476744186046 \n",
      "Epoch 10 | Step 3671 | loss: 0.2963437241586772 | accuracy: 0.8842329545454546 \n",
      "Epoch 10 | Step 3672 | loss: 0.29859269857406623 | accuracy: 0.8826388888888889 \n",
      "Epoch 10 | Step 3673 | loss: 0.2989780624275623 | accuracy: 0.8824728260869565 \n",
      "Epoch 10 | Step 3674 | loss: 0.29788872916647735 | accuracy: 0.8826462765957447 \n",
      "Epoch 10 | Step 3675 | loss: 0.299001698071758 | accuracy: 0.8815104166666666 \n",
      "Epoch 10 | Step 3676 | loss: 0.2967517360740779 | accuracy: 0.8826530612244898 \n",
      "Epoch 10 | Step 3677 | loss: 0.2974876037240029 | accuracy: 0.8821875 \n",
      "Epoch 10 | Step 3678 | loss: 0.29946877412936274 | accuracy: 0.8808210784313726 \n",
      "Epoch 10 | Step 3679 | loss: 0.301572310523345 | accuracy: 0.8798076923076923 \n",
      "Epoch 10 | Step 3680 | loss: 0.3007455324789264 | accuracy: 0.8797169811320755 \n",
      "Epoch 10 | Step 3681 | loss: 0.3002030929481542 | accuracy: 0.8799189814814815 \n",
      "Epoch 10 | Step 3682 | loss: 0.2985667981884697 | accuracy: 0.8806818181818182 \n",
      "Epoch 10 | Step 3683 | loss: 0.30010855463998665 | accuracy: 0.8800223214285714 \n",
      "Epoch 10 | Step 3684 | loss: 0.29919975133318655 | accuracy: 0.8804824561403509 \n",
      "Epoch 10 | Step 3685 | loss: 0.3009259682790987 | accuracy: 0.8790409482758621 \n",
      "Epoch 10 | Step 3686 | loss: 0.30099069491281355 | accuracy: 0.878707627118644 \n",
      "Epoch 10 | Step 3687 | loss: 0.3029654227197171 | accuracy: 0.878125 \n",
      "Epoch 10 | Step 3688 | loss: 0.30289784000545256 | accuracy: 0.8770491803278688 \n",
      "Epoch 10 | Step 3689 | loss: 0.3028581692807137 | accuracy: 0.8765120967741935 \n",
      "Epoch 10 | Step 3690 | loss: 0.3026706706436854 | accuracy: 0.8767361111111112 \n",
      "Epoch 10 | Step 3691 | loss: 0.30067087500356143 | accuracy: 0.87744140625 \n",
      "Epoch 10 | Step 3692 | loss: 0.3011424612540466 | accuracy: 0.8771634615384616 \n",
      "Epoch 10 | Step 3693 | loss: 0.2988737383575151 | accuracy: 0.8783143939393939 \n",
      "Epoch 10 | Step 3694 | loss: 0.2979929387124617 | accuracy: 0.8784981343283582 \n",
      "Epoch 10 | Step 3695 | loss: 0.2976234772187822 | accuracy: 0.87890625 \n",
      "Epoch 10 | Step 3696 | loss: 0.29845672651477484 | accuracy: 0.8783967391304348 \n",
      "Epoch 10 | Step 3697 | loss: 0.30012246391602926 | accuracy: 0.8774553571428572 \n",
      "Epoch 10 | Step 3698 | loss: 0.3009779669449363 | accuracy: 0.8769806338028169 \n",
      "Epoch 10 | Step 3699 | loss: 0.3000173856400781 | accuracy: 0.8773871527777778 \n",
      "Epoch 10 | Step 3700 | loss: 0.30051046426165595 | accuracy: 0.8771404109589042 \n",
      "Epoch 10 | Step 3701 | loss: 0.3015132407481606 | accuracy: 0.8766891891891891 \n",
      "Epoch 10 | Step 3702 | loss: 0.3026666953166326 | accuracy: 0.87625 \n",
      "Epoch 10 | Step 3703 | loss: 0.3018847574528895 | accuracy: 0.8766447368421053 \n",
      "Epoch 10 | Step 3704 | loss: 0.30236212348009084 | accuracy: 0.8764204545454546 \n",
      "Epoch 10 | Step 3705 | loss: 0.30166307512002116 | accuracy: 0.8766025641025641 \n",
      "Epoch 10 | Step 3706 | loss: 0.3007364056155652 | accuracy: 0.8769778481012658 \n",
      "Epoch 10 | Step 3707 | loss: 0.30015275385230783 | accuracy: 0.87734375 \n",
      "Epoch 10 | Step 3708 | loss: 0.30168413766372354 | accuracy: 0.876929012345679 \n",
      "Epoch 10 | Step 3709 | loss: 0.30076126045570145 | accuracy: 0.8776676829268293 \n",
      "Epoch 10 | Step 3710 | loss: 0.3010863448122898 | accuracy: 0.8774472891566265 \n",
      "Epoch 10 | Step 3711 | loss: 0.3010868343214194 | accuracy: 0.8777901785714286 \n",
      "Epoch 10 | Step 3712 | loss: 0.30133411200607524 | accuracy: 0.878125 \n",
      "Epoch 10 | Step 3713 | loss: 0.30038151994001033 | accuracy: 0.8784520348837209 \n",
      "Epoch 10 | Step 3714 | loss: 0.30016232924214725 | accuracy: 0.8787715517241379 \n",
      "Epoch 10 | Step 3715 | loss: 0.3003871466287158 | accuracy: 0.8790838068181818 \n",
      "Epoch 10 | Step 3716 | loss: 0.3002259133571989 | accuracy: 0.8788623595505618 \n",
      "Epoch 10 | Step 3717 | loss: 0.30079702685276666 | accuracy: 0.8784722222222222 \n",
      "Epoch 10 | Step 3718 | loss: 0.3005669190660938 | accuracy: 0.8782623626373627 \n",
      "Epoch 10 | Step 3719 | loss: 0.302802429413018 | accuracy: 0.8777173913043478 \n",
      "Epoch 10 | Step 3720 | loss: 0.30502690182578174 | accuracy: 0.8768481182795699 \n",
      "Epoch 10 | Step 3721 | loss: 0.3038947981722811 | accuracy: 0.8776595744680851 \n",
      "Epoch 10 | Step 3722 | loss: 0.3029968324460481 | accuracy: 0.8779605263157895 \n",
      "Epoch 10 | Step 3723 | loss: 0.302162977711608 | accuracy: 0.87841796875 \n",
      "Epoch 10 | Step 3724 | loss: 0.30153369166187405 | accuracy: 0.8785438144329897 \n",
      "Epoch 10 | Step 3725 | loss: 0.30273541230328227 | accuracy: 0.8778698979591837 \n",
      "Epoch 10 | Step 3726 | loss: 0.30201732796249964 | accuracy: 0.8781565656565656 \n",
      "Epoch 10 | Step 3727 | loss: 0.30249975666403767 | accuracy: 0.8778125 \n",
      "Epoch 10 | Step 3728 | loss: 0.30245010053167243 | accuracy: 0.8777846534653465 \n",
      "Epoch 10 | Step 3729 | loss: 0.302779779276427 | accuracy: 0.8776041666666666 \n",
      "Epoch 10 | Step 3730 | loss: 0.30302608027620215 | accuracy: 0.8774271844660194 \n",
      "Epoch 10 | Step 3731 | loss: 0.303268829647165 | accuracy: 0.8777043269230769 \n",
      "Epoch 10 | Step 3732 | loss: 0.3041892657677332 | accuracy: 0.8773809523809524 \n",
      "Epoch 10 | Step 3733 | loss: 0.3037262315738875 | accuracy: 0.8779481132075472 \n",
      "Epoch 10 | Step 3734 | loss: 0.30378988789063743 | accuracy: 0.8779205607476636 \n",
      "Epoch 10 | Step 3735 | loss: 0.304698380469172 | accuracy: 0.8773148148148148 \n",
      "Epoch 10 | Step 3736 | loss: 0.3036981369924107 | accuracy: 0.877723623853211 \n",
      "Epoch 10 | Step 3737 | loss: 0.3035263102162967 | accuracy: 0.8776988636363636 \n",
      "Epoch 10 | Step 3738 | loss: 0.3044185133667679 | accuracy: 0.8775337837837838 \n",
      "Epoch 10 | Step 3739 | loss: 0.30528209890638075 | accuracy: 0.876953125 \n",
      "Epoch 10 | Step 3740 | loss: 0.3049484180138174 | accuracy: 0.8770741150442478 \n",
      "Epoch 10 | Step 3741 | loss: 0.30488667127333186 | accuracy: 0.8770559210526315 \n",
      "Epoch 10 | Step 3742 | loss: 0.3044268926848535 | accuracy: 0.8771739130434782 \n",
      "Epoch 10 | Step 3743 | loss: 0.30383102698572745 | accuracy: 0.8775592672413793 \n",
      "Epoch 10 | Step 3744 | loss: 0.30340381998282206 | accuracy: 0.8778044871794872 \n",
      "Epoch 10 | Step 3745 | loss: 0.3040618123644489 | accuracy: 0.8772510593220338 \n",
      "Epoch 10 | Step 3746 | loss: 0.30463191942006596 | accuracy: 0.8768382352941176 \n",
      "Epoch 10 | Step 3747 | loss: 0.30461343154311177 | accuracy: 0.8766927083333333 \n",
      "Epoch 10 | Step 3748 | loss: 0.3038646474111178 | accuracy: 0.8770661157024794 \n",
      "Epoch 10 | Step 3749 | loss: 0.30429867142048034 | accuracy: 0.8767930327868853 \n",
      "Epoch 10 | Step 3750 | loss: 0.30416263664156434 | accuracy: 0.8766514227642277 \n",
      "Epoch 10 | Step 3751 | loss: 0.30492483716337904 | accuracy: 0.8762600806451613 \n",
      "Epoch 10 | Step 3752 | loss: 0.30516103303432457 | accuracy: 0.87625 \n",
      "Epoch 10 | Step 3753 | loss: 0.3045476814584126 | accuracy: 0.8762400793650794 \n",
      "Epoch 10 | Step 3754 | loss: 0.3052621291378351 | accuracy: 0.8756151574803149 \n",
      "Epoch 10 | Step 3755 | loss: 0.3047908162698149 | accuracy: 0.8759765625 \n",
      "Epoch 10 | Step 3756 | loss: 0.30489293572514553 | accuracy: 0.8758478682170543 \n",
      "Epoch 10 | Step 3757 | loss: 0.3049905724250353 | accuracy: 0.8758413461538461 \n",
      "Epoch 10 | Step 3758 | loss: 0.3051332754033212 | accuracy: 0.8759541984732825 \n",
      "Epoch 10 | Step 3759 | loss: 0.3050842264836484 | accuracy: 0.8761837121212122 \n",
      "Epoch 10 | Step 3760 | loss: 0.3045505251651419 | accuracy: 0.8765272556390977 \n",
      "Epoch 10 | Step 3761 | loss: 0.30387496692475985 | accuracy: 0.8768656716417911 \n",
      "Epoch 10 | Step 3762 | loss: 0.30408642634197514 | accuracy: 0.8769675925925926 \n",
      "Epoch 10 | Step 3763 | loss: 0.3040213910314966 | accuracy: 0.8772977941176471 \n",
      "Epoch 10 | Step 3764 | loss: 0.304881680294545 | accuracy: 0.8770529197080292 \n",
      "Epoch 10 | Step 3765 | loss: 0.3045188064376513 | accuracy: 0.8772644927536232 \n",
      "Epoch 10 | Step 3766 | loss: 0.3049037065222966 | accuracy: 0.877023381294964 \n",
      "Epoch 10 | Step 3767 | loss: 0.3048685504921845 | accuracy: 0.8768973214285715 \n",
      "Epoch 10 | Step 3768 | loss: 0.30500008039017934 | accuracy: 0.87677304964539 \n",
      "Epoch 10 | Step 3769 | loss: 0.30481630889043 | accuracy: 0.8768705985915493 \n",
      "Epoch 10 | Step 3770 | loss: 0.3043488149459545 | accuracy: 0.8771853146853147 \n",
      "Epoch 10 | Step 3771 | loss: 0.3043870389875438 | accuracy: 0.876953125 \n",
      "Epoch 10 | Step 3772 | loss: 0.3039742855162456 | accuracy: 0.8768318965517241 \n",
      "Epoch 10 | Step 3773 | loss: 0.3041467549253816 | accuracy: 0.877033390410959 \n",
      "Epoch 10 | Step 3774 | loss: 0.30422396491579456 | accuracy: 0.8772321428571429 \n",
      "Epoch 10 | Step 3775 | loss: 0.3038862278131214 | accuracy: 0.8774282094594594 \n",
      "Epoch 10 | Step 3776 | loss: 0.3039616601379126 | accuracy: 0.87751677852349 \n",
      "Epoch 10 | Step 3777 | loss: 0.30316310733556745 | accuracy: 0.8778125 \n",
      "Epoch 10 | Step 3778 | loss: 0.30317194345376347 | accuracy: 0.8778973509933775 \n",
      "Epoch 10 | Step 3779 | loss: 0.30362864397466177 | accuracy: 0.8778782894736842 \n",
      "Epoch 10 | Step 3780 | loss: 0.30410038149045177 | accuracy: 0.877859477124183 \n",
      "Epoch 10 | Step 3781 | loss: 0.30328045495144723 | accuracy: 0.8782467532467533 \n",
      "Epoch 10 | Step 3782 | loss: 0.3024368723553995 | accuracy: 0.8784274193548387 \n",
      "Epoch 10 | Step 3783 | loss: 0.3016722357043852 | accuracy: 0.8788060897435898 \n",
      "Epoch 10 | Step 3784 | loss: 0.30152175153137006 | accuracy: 0.878781847133758 \n",
      "Epoch 10 | Step 3785 | loss: 0.3012088278803644 | accuracy: 0.8788568037974683 \n",
      "Epoch 10 | Step 3786 | loss: 0.3011715948206823 | accuracy: 0.8787342767295597 \n",
      "Epoch 10 | Step 3787 | loss: 0.3008809575811028 | accuracy: 0.87890625 \n",
      "Epoch 10 | Step 3788 | loss: 0.3005404927715751 | accuracy: 0.8788819875776398 \n",
      "Epoch 10 | Step 3789 | loss: 0.3006540825705469 | accuracy: 0.8786651234567902 \n",
      "Epoch 10 | Step 3790 | loss: 0.2998833448791796 | accuracy: 0.8788343558282209 \n",
      "Epoch 10 | Step 3791 | loss: 0.29960706711905755 | accuracy: 0.8788109756097561 \n",
      "Epoch 10 | Step 3792 | loss: 0.29949067587202244 | accuracy: 0.8786931818181818 \n",
      "Epoch 10 | Step 3793 | loss: 0.30066491169742793 | accuracy: 0.8780120481927711 \n",
      "Epoch 10 | Step 3794 | loss: 0.3000198958698147 | accuracy: 0.8782747005988024 \n",
      "Epoch 10 | Step 3795 | loss: 0.29972917435779456 | accuracy: 0.8780691964285714 \n",
      "Epoch 10 | Step 3796 | loss: 0.30104498847349154 | accuracy: 0.8775887573964497 \n",
      "Epoch 10 | Step 3797 | loss: 0.30098087866516676 | accuracy: 0.8776654411764706 \n",
      "Epoch 10 | Step 3798 | loss: 0.30141971569660814 | accuracy: 0.8771929824561403 \n",
      "Epoch 10 | Step 3799 | loss: 0.3018181522398494 | accuracy: 0.8769985465116279 \n",
      "Epoch 10 | Step 3800 | loss: 0.3006212135529243 | accuracy: 0.8776192196531792 \n",
      "Epoch 10 | Step 3801 | loss: 0.30087077356446756 | accuracy: 0.8776939655172413 \n",
      "Epoch 10 | Step 3802 | loss: 0.3006344168101039 | accuracy: 0.8778571428571429 \n",
      "Epoch 10 | Step 3803 | loss: 0.3005009506490421 | accuracy: 0.8781072443181818 \n",
      "Epoch 10 | Step 3804 | loss: 0.3009621758161292 | accuracy: 0.8780014124293786 \n",
      "Epoch 10 | Step 3805 | loss: 0.3009196539524567 | accuracy: 0.8780723314606742 \n",
      "Epoch 10 | Step 3806 | loss: 0.3009864537659305 | accuracy: 0.8781424581005587 \n",
      "Epoch 10 | Step 3807 | loss: 0.3014009774972996 | accuracy: 0.8778645833333333 \n",
      "Epoch 10 | Step 3808 | loss: 0.3009263704741858 | accuracy: 0.878021408839779 \n",
      "Epoch 10 | Step 3809 | loss: 0.30058543961290485 | accuracy: 0.878176510989011 \n",
      "Epoch 10 | Step 3810 | loss: 0.30019468643137676 | accuracy: 0.8785860655737705 \n",
      "Epoch 10 | Step 3811 | loss: 0.30034908964096213 | accuracy: 0.8785665760869565 \n",
      "Epoch 10 | Step 3812 | loss: 0.300359351288628 | accuracy: 0.8784628378378379 \n",
      "Epoch 10 | Step 3813 | loss: 0.3003555023942584 | accuracy: 0.8783602150537635 \n",
      "Epoch 10 | Step 3814 | loss: 0.30048496252234613 | accuracy: 0.8783422459893048 \n",
      "Epoch 10 | Step 3815 | loss: 0.3004065958505616 | accuracy: 0.8785738031914894 \n",
      "Epoch 10 | Step 3816 | loss: 0.2999890217626537 | accuracy: 0.87880291005291 \n",
      "Epoch 10 | Step 3817 | loss: 0.29996952096882623 | accuracy: 0.8788651315789474 \n",
      "Epoch 10 | Step 3818 | loss: 0.3002519226433095 | accuracy: 0.8788448952879581 \n",
      "Epoch 10 | Step 3819 | loss: 0.3004503459281599 | accuracy: 0.8787434895833334 \n",
      "Epoch 10 | Step 3820 | loss: 0.3008609842991582 | accuracy: 0.8784812176165803 \n",
      "Epoch 10 | Step 3821 | loss: 0.3003649525344372 | accuracy: 0.8787854381443299 \n",
      "Epoch 10 | Step 3822 | loss: 0.3007873351375262 | accuracy: 0.8784455128205129 \n",
      "Epoch 10 | Step 3823 | loss: 0.300797329227231 | accuracy: 0.8785873724489796 \n",
      "Epoch 10 | Step 3824 | loss: 0.3010380406897081 | accuracy: 0.8784105329949239 \n",
      "Epoch 10 | Step 3825 | loss: 0.30138136096524476 | accuracy: 0.8780776515151515 \n",
      "Epoch 10 | Step 3826 | loss: 0.301944347894072 | accuracy: 0.8779051507537688 \n",
      "Epoch 10 | Step 3827 | loss: 0.3017722667381168 | accuracy: 0.878046875 \n",
      "Epoch 10 | Step 3828 | loss: 0.30204409238562663 | accuracy: 0.8778762437810945 \n",
      "Epoch 10 | Step 3829 | loss: 0.30228389456573107 | accuracy: 0.877862004950495 \n",
      "Epoch 10 | Step 3830 | loss: 0.30190083652441146 | accuracy: 0.8783097290640394 \n",
      "Epoch 10 | Step 3831 | loss: 0.3020369689911605 | accuracy: 0.878140318627451 \n",
      "Epoch 10 | Step 3832 | loss: 0.30216589166623803 | accuracy: 0.8778963414634147 \n",
      "Epoch 10 | Step 3833 | loss: 0.302007857493116 | accuracy: 0.8780339805825242 \n",
      "Epoch 10 | Step 3834 | loss: 0.3017231101791065 | accuracy: 0.8782457729468599 \n",
      "Epoch 10 | Step 3835 | loss: 0.3013629115616474 | accuracy: 0.8783052884615384 \n",
      "Epoch 10 | Step 3836 | loss: 0.30149352183324885 | accuracy: 0.8783642344497608 \n",
      "Epoch 10 | Step 3837 | loss: 0.30096926635929533 | accuracy: 0.8785714285714286 \n",
      "Epoch 10 | Step 3838 | loss: 0.3008384541100802 | accuracy: 0.878702606635071 \n",
      "Epoch 10 | Step 3839 | loss: 0.30114114273972126 | accuracy: 0.8785377358490566 \n",
      "Epoch 10 | Step 3840 | loss: 0.300664667267475 | accuracy: 0.8786678403755869 \n",
      "Epoch 10 | Step 3841 | loss: 0.3004229325348531 | accuracy: 0.8787967289719626 \n",
      "Epoch 10 | Step 3842 | loss: 0.30078175695136555 | accuracy: 0.8787063953488372 \n",
      "Epoch 10 | Step 3843 | loss: 0.3012849394990892 | accuracy: 0.8784722222222222 \n",
      "Epoch 10 | Step 3844 | loss: 0.30183942406545605 | accuracy: 0.878096198156682 \n",
      "Epoch 10 | Step 3845 | loss: 0.30158908101260135 | accuracy: 0.8781536697247706 \n",
      "Epoch 10 | Step 3846 | loss: 0.30144112509543514 | accuracy: 0.8779965753424658 \n",
      "Epoch 10 | Step 3847 | loss: 0.30161056081679755 | accuracy: 0.8778409090909091 \n",
      "Epoch 10 | Step 3848 | loss: 0.30117964471492314 | accuracy: 0.8781815610859729 \n",
      "Epoch 10 | Step 3849 | loss: 0.3008407297636477 | accuracy: 0.8783783783783784 \n",
      "Epoch 10 | Step 3850 | loss: 0.30111498679681764 | accuracy: 0.8784332959641256 \n",
      "Epoch 10 | Step 3851 | loss: 0.30111949368646124 | accuracy: 0.8785574776785714 \n",
      "Epoch 10 | Step 3852 | loss: 0.3015887017713655 | accuracy: 0.8783333333333333 \n",
      "Epoch 10 | Step 3853 | loss: 0.30188180331503417 | accuracy: 0.8782494469026548 \n",
      "Epoch 10 | Step 3854 | loss: 0.3018860097170403 | accuracy: 0.8780974669603524 \n",
      "Epoch 10 | Step 3855 | loss: 0.301809184220538 | accuracy: 0.8778097587719298 \n",
      "Epoch 10 | Step 3856 | loss: 0.30136707200624036 | accuracy: 0.8780704148471615 \n",
      "Epoch 10 | Step 3857 | loss: 0.301067481254754 | accuracy: 0.8781929347826087 \n",
      "Epoch 10 | Step 3858 | loss: 0.30140933371854567 | accuracy: 0.8781114718614719 \n",
      "Epoch 10 | Step 3859 | loss: 0.30087640987516495 | accuracy: 0.8783674568965517 \n",
      "Epoch 10 | Step 3860 | loss: 0.30094579223527435 | accuracy: 0.8782188841201717 \n",
      "Epoch 10 | Step 3861 | loss: 0.30098515255456315 | accuracy: 0.8782051282051282 \n",
      "Epoch 10 | Step 3862 | loss: 0.30065503047501807 | accuracy: 0.8784574468085107 \n",
      "Epoch 10 | Step 3863 | loss: 0.30069656382804216 | accuracy: 0.8785752118644068 \n",
      "Epoch 10 | Step 3864 | loss: 0.3009859416869624 | accuracy: 0.8784282700421941 \n",
      "Epoch 10 | Step 3865 | loss: 0.3013484787602887 | accuracy: 0.8784138655462185 \n",
      "Epoch 10 | Step 3866 | loss: 0.30104137773169654 | accuracy: 0.8785303347280334 \n",
      "Epoch 10 | Step 3867 | loss: 0.30066805956885234 | accuracy: 0.8787109375 \n",
      "Epoch 10 | Step 3868 | loss: 0.30090999878417424 | accuracy: 0.8784362033195021 \n",
      "Epoch 10 | Step 3869 | loss: 0.3010722309166244 | accuracy: 0.8784220041322314 \n",
      "Epoch 10 | Step 3870 | loss: 0.3010648007316846 | accuracy: 0.8784722222222222 \n",
      "Epoch 10 | Step 3871 | loss: 0.3003874591811272 | accuracy: 0.8787781762295082 \n",
      "Epoch 10 | Step 3872 | loss: 0.29993881458530636 | accuracy: 0.8790178571428572 \n",
      "Epoch 10 | Step 3873 | loss: 0.299646525757342 | accuracy: 0.8790650406504065 \n",
      "Epoch 10 | Step 3874 | loss: 0.2993038369395474 | accuracy: 0.8792383603238867 \n",
      "Epoch 10 | Step 3875 | loss: 0.2995905406592836 | accuracy: 0.8790952620967742 \n",
      "Epoch 10 | Step 3876 | loss: 0.29966149467181985 | accuracy: 0.8790160642570282 \n",
      "Epoch 10 | Step 3877 | loss: 0.2992890644967558 | accuracy: 0.87925 \n",
      "Epoch 10 | Step 3878 | loss: 0.2994501240165587 | accuracy: 0.8791085657370518 \n",
      "Epoch 10 | Step 3879 | loss: 0.29964491875753535 | accuracy: 0.8790302579365079 \n",
      "Epoch 10 | Step 3880 | loss: 0.2996452372712582 | accuracy: 0.8789525691699605 \n",
      "Epoch 10 | Step 3881 | loss: 0.29962233597720717 | accuracy: 0.8788754921259843 \n",
      "Epoch 10 | Step 3882 | loss: 0.29941800636988075 | accuracy: 0.8790441176470588 \n",
      "Epoch 10 | Step 3883 | loss: 0.2994263811560815 | accuracy: 0.87890625 \n",
      "Epoch 10 | Step 3884 | loss: 0.29944650640399556 | accuracy: 0.8788910505836576 \n",
      "Epoch 10 | Step 3885 | loss: 0.2996550580385583 | accuracy: 0.8788154069767442 \n",
      "Epoch 10 | Step 3886 | loss: 0.29971938108500384 | accuracy: 0.8786800193050193 \n",
      "Epoch 10 | Step 3887 | loss: 0.2997418397034592 | accuracy: 0.8787259615384615 \n",
      "Epoch 10 | Step 3888 | loss: 0.2996048990394422 | accuracy: 0.8788912835249042 \n",
      "Epoch 10 | Step 3889 | loss: 0.30010735490963675 | accuracy: 0.878518606870229 \n",
      "Epoch 10 | Step 3890 | loss: 0.29998117280210396 | accuracy: 0.8784458174904943 \n",
      "Epoch 10 | Step 3891 | loss: 0.299862836600479 | accuracy: 0.8784327651515151 \n",
      "Epoch 10 | Step 3892 | loss: 0.299686265244799 | accuracy: 0.8783018867924528 \n",
      "Epoch 10 | Step 3893 | loss: 0.2997122573057065 | accuracy: 0.8782894736842105 \n",
      "Epoch 10 | Step 3894 | loss: 0.2994643594609219 | accuracy: 0.8783356741573034 \n",
      "Epoch 10 | Step 3895 | loss: 0.2996316482938494 | accuracy: 0.8780900186567164 \n",
      "Epoch 10 | Step 3896 | loss: 0.29956012629111034 | accuracy: 0.8781366171003717 \n",
      "Epoch 10 | Step 3897 | loss: 0.2996231073306668 | accuracy: 0.878125 \n",
      "Epoch 10 | Step 3898 | loss: 0.2995667287949268 | accuracy: 0.8781134686346863 \n",
      "Epoch 10 | Step 3899 | loss: 0.2993458411656322 | accuracy: 0.8783318014705882 \n",
      "Epoch 10 | Step 3900 | loss: 0.2994745355986415 | accuracy: 0.8784340659340659 \n",
      "Epoch 10 | Step 3901 | loss: 0.29964752198897154 | accuracy: 0.8784785583941606 \n",
      "Epoch 10 | Step 3902 | loss: 0.2994006882201543 | accuracy: 0.8785227272727273 \n",
      "Epoch 10 | Step 3903 | loss: 0.29981255307253735 | accuracy: 0.8783401268115942 \n",
      "Epoch 10 | Step 3904 | loss: 0.29958974903563745 | accuracy: 0.8783844765342961 \n",
      "Epoch 10 | Step 3905 | loss: 0.29937111074439926 | accuracy: 0.8784847122302158 \n",
      "Epoch 10 | Step 3906 | loss: 0.29912162438622525 | accuracy: 0.878584229390681 \n",
      "Epoch 10 | Step 3907 | loss: 0.2990881210193039 | accuracy: 0.8785714285714286 \n",
      "Epoch 10 | Step 3908 | loss: 0.298947002672428 | accuracy: 0.8786143238434164 \n",
      "Epoch 10 | Step 3909 | loss: 0.2986498879572602 | accuracy: 0.8787123226950355 \n",
      "Epoch 10 | Step 3910 | loss: 0.2985820567807967 | accuracy: 0.8786992049469966 \n",
      "Epoch 10 | Step 3911 | loss: 0.2981635077371145 | accuracy: 0.8789612676056339 \n",
      "Epoch 10 | Step 3912 | loss: 0.29809462817614546 | accuracy: 0.8788925438596492 \n",
      "Epoch 10 | Step 3913 | loss: 0.29759497177246574 | accuracy: 0.8790974650349651 \n",
      "Epoch 10 | Step 3914 | loss: 0.2976353147459778 | accuracy: 0.8790287456445994 \n",
      "Epoch 10 | Step 3915 | loss: 0.2972546563638996 | accuracy: 0.8791775173611112 \n",
      "Epoch 10 | Step 3916 | loss: 0.2978544368514966 | accuracy: 0.8791089965397924 \n",
      "Epoch 10 | Step 3917 | loss: 0.2976907785853436 | accuracy: 0.8792564655172413 \n",
      "Epoch 10 | Step 3918 | loss: 0.29824118385302656 | accuracy: 0.8790807560137457 \n",
      "Epoch 10 | Step 3919 | loss: 0.29814546568038536 | accuracy: 0.8790667808219178 \n",
      "Epoch 10 | Step 3920 | loss: 0.2981696839066089 | accuracy: 0.879106228668942 \n",
      "Epoch 10 | Step 3921 | loss: 0.29826942767922576 | accuracy: 0.8789859693877551 \n",
      "Epoch 10 | Step 3922 | loss: 0.2981180151892921 | accuracy: 0.8790783898305085 \n",
      "Epoch 10 | Step 3923 | loss: 0.2981499292812235 | accuracy: 0.8791701858108109 \n",
      "Epoch 10 | Step 3924 | loss: 0.2981142932768623 | accuracy: 0.8792087542087542 \n",
      "Epoch 10 | Step 3925 | loss: 0.29787229369050705 | accuracy: 0.8794043624161074 \n",
      "Epoch 10 | Step 3926 | loss: 0.29782157775052015 | accuracy: 0.8793896321070234 \n",
      "Epoch 10 | Step 3927 | loss: 0.29750867165625094 | accuracy: 0.8794791666666667 \n",
      "Epoch 10 | Step 3928 | loss: 0.29790126235283093 | accuracy: 0.8792566445182725 \n",
      "Epoch 10 | Step 3929 | loss: 0.2976593601930615 | accuracy: 0.8794495033112583 \n",
      "Epoch 10 | Step 3930 | loss: 0.2974947389252115 | accuracy: 0.8795895214521452 \n",
      "Epoch 10 | Step 3931 | loss: 0.2976018394539623 | accuracy: 0.8794716282894737 \n",
      "Epoch 10 | Step 3932 | loss: 0.29744352695883297 | accuracy: 0.8794569672131147 \n",
      "Epoch 10 | Step 3933 | loss: 0.29747183978849767 | accuracy: 0.8794424019607843 \n",
      "Epoch 10 | Step 3934 | loss: 0.29815280668024907 | accuracy: 0.8791734527687296 \n",
      "Epoch 10 | Step 3935 | loss: 0.2979519624843613 | accuracy: 0.8792613636363636 \n",
      "Epoch 10 | Step 3936 | loss: 0.297673489693492 | accuracy: 0.879298139158576 \n",
      "Epoch 10 | Step 3937 | loss: 0.2976884729679554 | accuracy: 0.8792842741935484 \n",
      "Epoch 10 | Step 3938 | loss: 0.2976576188800803 | accuracy: 0.8793207395498392 \n",
      "Epoch 10 | Step 3939 | loss: 0.29765801917379486 | accuracy: 0.8793569711538461 \n",
      "Epoch 10 | Step 3940 | loss: 0.2974590253763306 | accuracy: 0.8794928115015974 \n",
      "Epoch 10 | Step 3941 | loss: 0.29773359363720686 | accuracy: 0.8794287420382165 \n",
      "Epoch 10 | Step 3942 | loss: 0.2982072732987859 | accuracy: 0.8793154761904762 \n",
      "Epoch 10 | Step 3943 | loss: 0.29813783891687673 | accuracy: 0.8793018196202531 \n",
      "Epoch 10 | Step 3944 | loss: 0.2978642996788402 | accuracy: 0.8794854100946372 \n",
      "Epoch 10 | Step 3945 | loss: 0.2980640982541274 | accuracy: 0.8792747641509434 \n",
      "Epoch 10 | Step 3946 | loss: 0.2979846515672334 | accuracy: 0.8794083072100314 \n",
      "Epoch 10 | Step 3947 | loss: 0.297788677061908 | accuracy: 0.879541015625 \n",
      "Epoch 10 | Step 3948 | loss: 0.2978301126034089 | accuracy: 0.8794781931464174 \n",
      "Epoch 10 | Step 3949 | loss: 0.2982398452734725 | accuracy: 0.8793672360248447 \n",
      "Epoch 10 | Step 3950 | loss: 0.29801337732342376 | accuracy: 0.8794988390092879 \n",
      "Epoch 10 | Step 3951 | loss: 0.2978118022236927 | accuracy: 0.8794849537037037 \n",
      "Epoch 10 | Step 3952 | loss: 0.29798908112140804 | accuracy: 0.879423076923077 \n",
      "Epoch 10 | Step 3953 | loss: 0.2978099778157436 | accuracy: 0.8794574386503068 \n",
      "Epoch 10 | Step 3954 | loss: 0.2979290723937367 | accuracy: 0.8794438073394495 \n",
      "Epoch 10 | Step 3955 | loss: 0.2979490121644808 | accuracy: 0.8794778963414634 \n",
      "Epoch 10 | Step 3956 | loss: 0.2984220502179082 | accuracy: 0.8792268237082067 \n",
      "Epoch 10 | Step 3957 | loss: 0.2984002505965305 | accuracy: 0.8792613636363636 \n",
      "Epoch 10 | Step 3958 | loss: 0.2982103673578029 | accuracy: 0.8793429003021148 \n",
      "Epoch 10 | Step 3959 | loss: 0.29810073381536695 | accuracy: 0.8794239457831325 \n",
      "Epoch 10 | Step 3960 | loss: 0.29797328370916953 | accuracy: 0.8795045045045045 \n",
      "Epoch 10 | Step 3961 | loss: 0.2981127931730833 | accuracy: 0.8793974550898204 \n",
      "Epoch 10 | Step 3962 | loss: 0.29787641392270137 | accuracy: 0.8793843283582089 \n",
      "Epoch 10 | Step 3963 | loss: 0.2977903890866964 | accuracy: 0.8794177827380952 \n",
      "Epoch 10 | Step 3964 | loss: 0.2979196991207692 | accuracy: 0.8793583086053413 \n",
      "Epoch 10 | Step 3965 | loss: 0.29795956490396047 | accuracy: 0.8794378698224852 \n",
      "Epoch 10 | Step 3966 | loss: 0.2977742407921493 | accuracy: 0.8795169616519174 \n",
      "Epoch 10 | Step 3967 | loss: 0.297426399128402 | accuracy: 0.8796415441176471 \n",
      "Epoch 10 | Step 3968 | loss: 0.29715116354814375 | accuracy: 0.8797653958944281 \n",
      "Epoch 10 | Step 3969 | loss: 0.29701939044378656 | accuracy: 0.8797514619883041 \n",
      "Epoch 10 | Step 3970 | loss: 0.2968005239311877 | accuracy: 0.8798742711370262 \n",
      "Epoch 10 | Step 3971 | loss: 0.29660853056973496 | accuracy: 0.879905523255814 \n",
      "Epoch 10 | Step 3972 | loss: 0.2967287051288978 | accuracy: 0.8797554347826086 \n",
      "Epoch 10 | Step 3973 | loss: 0.29666930486614995 | accuracy: 0.8797868497109826 \n",
      "Epoch 10 | Step 3974 | loss: 0.296330428668848 | accuracy: 0.8799531700288185 \n",
      "Epoch 10 | Step 3975 | loss: 0.2967643063601063 | accuracy: 0.8798491379310345 \n",
      "Epoch 10 | Step 3976 | loss: 0.2966191119869322 | accuracy: 0.8799247851002865 \n",
      "Epoch 10 | Step 3977 | loss: 0.296515945898635 | accuracy: 0.8799553571428571 \n",
      "Epoch 10 | Step 3978 | loss: 0.29626625451521993 | accuracy: 0.8801638176638177 \n",
      "Epoch 10 | Step 3979 | loss: 0.2965121987826106 | accuracy: 0.8801047585227273 \n",
      "Epoch 10 | Step 3980 | loss: 0.296289118698062 | accuracy: 0.8801345609065155 \n",
      "Epoch 10 | Step 3981 | loss: 0.29603832743346353 | accuracy: 0.8802524717514124 \n",
      "Epoch 10 | Step 3982 | loss: 0.29588132028428604 | accuracy: 0.8802816901408451 \n",
      "Epoch 10 | Step 3983 | loss: 0.2956901864682356 | accuracy: 0.8803985252808989 \n",
      "Epoch 10 | Step 3984 | loss: 0.29568736390823747 | accuracy: 0.8804709383753502 \n",
      "Epoch 10 | Step 3985 | loss: 0.2957051161406094 | accuracy: 0.8804993016759777 \n",
      "Epoch 10 | Step 3986 | loss: 0.29547213829410446 | accuracy: 0.8805710306406686 \n",
      "Epoch 10 | Step 3987 | loss: 0.2952400356738104 | accuracy: 0.8806857638888889 \n",
      "Epoch 10 | Step 3988 | loss: 0.29540649966602517 | accuracy: 0.8805401662049861 \n",
      "Epoch 10 | Step 3989 | loss: 0.2953040466659307 | accuracy: 0.8806111878453039 \n",
      "Epoch 10 | Step 3990 | loss: 0.29524177692563747 | accuracy: 0.8805957300275482 \n",
      "Epoch 10 | Step 3991 | loss: 0.2951998913885801 | accuracy: 0.8805374313186813 \n",
      "Epoch 10 | Step 3992 | loss: 0.2949437812378963 | accuracy: 0.8806506849315069 \n",
      "Epoch 10 | Step 3993 | loss: 0.2948032953659369 | accuracy: 0.8805925546448088 \n",
      "Epoch 10 | Step 3994 | loss: 0.2947418152758148 | accuracy: 0.8805773160762943 \n",
      "Epoch 10 | Step 3995 | loss: 0.29456338847218017 | accuracy: 0.8806470788043478 \n",
      "Epoch 10 | Step 3996 | loss: 0.2947534913333452 | accuracy: 0.880589430894309 \n",
      "Epoch 10 | Step 3997 | loss: 0.29512313066704865 | accuracy: 0.8804054054054054 \n",
      "Epoch 10 | Step 3998 | loss: 0.29522257370527877 | accuracy: 0.8803908355795148 \n",
      "Epoch 10 | Step 3999 | loss: 0.2958843906920765 | accuracy: 0.8800823252688172 \n",
      "Epoch 10 | Step 4000 | loss: 0.2960054284965386 | accuracy: 0.8800268096514745 \n",
      "Epoch 10 | Step 4001 | loss: 0.2957486889379867 | accuracy: 0.8801387032085561 \n",
      "Epoch 10 | Step 4002 | loss: 0.2954368924895924 | accuracy: 0.880375 \n",
      "Epoch 10 | Step 4003 | loss: 0.2953948271361756 | accuracy: 0.8802775930851063 \n",
      "Epoch 10 | Step 4004 | loss: 0.29525596743316185 | accuracy: 0.8802635941644562 \n",
      "Epoch 10 | Step 4005 | loss: 0.2953395088395431 | accuracy: 0.8801669973544973 \n",
      "Epoch 10 | Step 4006 | loss: 0.29504399015359345 | accuracy: 0.8802358179419525 \n",
      "Epoch 10 | Step 4007 | loss: 0.2948187919627681 | accuracy: 0.88046875 \n",
      "Epoch 10 | Step 4008 | loss: 0.29470862223329214 | accuracy: 0.880495406824147 \n",
      "Epoch 10 | Step 4009 | loss: 0.2945304106316331 | accuracy: 0.8805628272251309 \n",
      "Epoch 10 | Step 4010 | loss: 0.29444540984559014 | accuracy: 0.8805075065274152 \n",
      "Epoch 10 | Step 4011 | loss: 0.2944897734366049 | accuracy: 0.8804931640625 \n",
      "Epoch 10 | Step 4012 | loss: 0.294807076976671 | accuracy: 0.8803977272727272 \n",
      "Epoch 10 | Step 4013 | loss: 0.29507784273263105 | accuracy: 0.8803027849740933 \n",
      "Epoch 10 | Step 4014 | loss: 0.29519060660317287 | accuracy: 0.8803294573643411 \n",
      "Epoch 10 | Step 4015 | loss: 0.29506041798932664 | accuracy: 0.8803157216494846 \n",
      "Epoch 10 | Step 4016 | loss: 0.29525621911477323 | accuracy: 0.8801413881748072 \n",
      "Epoch 10 | Step 4017 | loss: 0.2951980757980776 | accuracy: 0.8801282051282051 \n",
      "Epoch 10 | Step 4018 | loss: 0.2953456284101968 | accuracy: 0.8801150895140665 \n",
      "Epoch 10 | Step 4019 | loss: 0.2952298511541925 | accuracy: 0.8801419005102041 \n",
      "Epoch 10 | Step 4020 | loss: 0.29500152100512705 | accuracy: 0.8802878498727735 \n",
      "Epoch 10 | Step 4021 | loss: 0.2951813257928126 | accuracy: 0.8801554568527918 \n",
      "Epoch 10 | Step 4022 | loss: 0.29511701987136785 | accuracy: 0.8802215189873418 \n",
      "Epoch 10 | Step 4023 | loss: 0.29503127979585037 | accuracy: 0.8802477904040404 \n",
      "Epoch 10 | Step 4024 | loss: 0.29515073793736174 | accuracy: 0.8801164987405542 \n",
      "Epoch 10 | Step 4025 | loss: 0.2953872424760957 | accuracy: 0.8800251256281407 \n",
      "Epoch 10 | Step 4026 | loss: 0.2952161747448727 | accuracy: 0.8800908521303258 \n",
      "Epoch 10 | Step 4027 | loss: 0.2954668358154597 | accuracy: 0.8799609375 \n",
      "Epoch 10 | Step 4028 | loss: 0.29546869196870995 | accuracy: 0.8799875311720698 \n",
      "Epoch 10 | Step 4029 | loss: 0.29588202363000604 | accuracy: 0.8797419154228856 \n",
      "Epoch 10 | Step 4030 | loss: 0.29564223512452553 | accuracy: 0.8798691923210106 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.5123262405395508 | accuracy: 0.75 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.5246591866016388 | accuracy: 0.7421875 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.46529070536295575 | accuracy: 0.7708333333333334 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4598122388124466 | accuracy: 0.77734375 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4625710129737854 | accuracy: 0.778125 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4508068412542343 | accuracy: 0.78125 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.442591198853084 | accuracy: 0.7901785714285714 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.43403245508670807 | accuracy: 0.794921875 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.42811787128448486 | accuracy: 0.8003472222222222 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4313545286655426 | accuracy: 0.803125 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.43231012604453345 | accuracy: 0.8068181818181818 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4241417348384857 | accuracy: 0.8111979166666666 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.42771916206066424 | accuracy: 0.8076923076923077 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4310730908598219 | accuracy: 0.8069196428571429 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.42098002235094706 | accuracy: 0.8125 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.419514836743474 | accuracy: 0.814453125 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4301064733196707 | accuracy: 0.8115808823529411 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.42631127933661145 | accuracy: 0.8133680555555556 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.42569512128829956 | accuracy: 0.8149671052631579 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4225358709692955 | accuracy: 0.81640625 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.422648515020098 | accuracy: 0.8177083333333334 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.41825202107429504 | accuracy: 0.8196022727272727 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4211150006107662 | accuracy: 0.8172554347826086 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.42214015995462734 | accuracy: 0.8170572916666666 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.42588488936424257 | accuracy: 0.81375 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4193230982010181 | accuracy: 0.8167067307692307 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.41767410768402946 | accuracy: 0.8188657407407407 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.41395481888736996 | accuracy: 0.8203125 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4158119908694563 | accuracy: 0.8195043103448276 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.41654558380444845 | accuracy: 0.8192708333333333 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4117030972434628 | accuracy: 0.8210685483870968 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4062999654561281 | accuracy: 0.82421875 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4046063974048152 | accuracy: 0.8252840909090909 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4130405827480204 | accuracy: 0.8221507352941176 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4120730587414333 | accuracy: 0.8214285714285714 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4085068023867077 | accuracy: 0.8224826388888888 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4103611441882881 | accuracy: 0.8230574324324325 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4103871576095882 | accuracy: 0.8223684210526315 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.40897808243066835 | accuracy: 0.8225160256410257 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.41142624989151955 | accuracy: 0.820703125 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4138158450766308 | accuracy: 0.8189786585365854 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.41149247473194484 | accuracy: 0.8203125 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4114952378494795 | accuracy: 0.8197674418604651 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.41301864792000165 | accuracy: 0.8185369318181818 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4159835894902547 | accuracy: 0.8172554347250197 \n",
      "Epoch 11 | Step 4031 | loss: 0.22275829315185547 | accuracy: 0.921875 \n",
      "Epoch 11 | Step 4032 | loss: 0.30856333673000336 | accuracy: 0.8828125 \n",
      "Epoch 11 | Step 4033 | loss: 0.2762173265218735 | accuracy: 0.9010416666666666 \n",
      "Epoch 11 | Step 4034 | loss: 0.27140871062874794 | accuracy: 0.8984375 \n",
      "Epoch 11 | Step 4035 | loss: 0.2685885578393936 | accuracy: 0.890625 \n",
      "Epoch 11 | Step 4036 | loss: 0.2861991698543231 | accuracy: 0.8802083333333334 \n",
      "Epoch 11 | Step 4037 | loss: 0.28901007984365734 | accuracy: 0.8839285714285714 \n",
      "Epoch 11 | Step 4038 | loss: 0.3043561112135649 | accuracy: 0.8828125 \n",
      "Epoch 11 | Step 4039 | loss: 0.29614228506882984 | accuracy: 0.8871527777777778 \n",
      "Epoch 11 | Step 4040 | loss: 0.31075398474931715 | accuracy: 0.878125 \n",
      "Epoch 11 | Step 4041 | loss: 0.3076264221559871 | accuracy: 0.8778409090909091 \n",
      "Epoch 11 | Step 4042 | loss: 0.31700244918465614 | accuracy: 0.87109375 \n",
      "Epoch 11 | Step 4043 | loss: 0.31161661675343144 | accuracy: 0.875 \n",
      "Epoch 11 | Step 4044 | loss: 0.31526175886392593 | accuracy: 0.8738839285714286 \n",
      "Epoch 11 | Step 4045 | loss: 0.3074377208948135 | accuracy: 0.8791666666666667 \n",
      "Epoch 11 | Step 4046 | loss: 0.29735911544412374 | accuracy: 0.8837890625 \n",
      "Epoch 11 | Step 4047 | loss: 0.2942160359200309 | accuracy: 0.8823529411764706 \n",
      "Epoch 11 | Step 4048 | loss: 0.29385710176494384 | accuracy: 0.8819444444444444 \n",
      "Epoch 11 | Step 4049 | loss: 0.29115753503222214 | accuracy: 0.884046052631579 \n",
      "Epoch 11 | Step 4050 | loss: 0.29268639609217645 | accuracy: 0.88515625 \n",
      "Epoch 11 | Step 4051 | loss: 0.29298919226442066 | accuracy: 0.8839285714285714 \n",
      "Epoch 11 | Step 4052 | loss: 0.29293041811747983 | accuracy: 0.8849431818181818 \n",
      "Epoch 11 | Step 4053 | loss: 0.2888079978849577 | accuracy: 0.8865489130434783 \n",
      "Epoch 11 | Step 4054 | loss: 0.28492470396061736 | accuracy: 0.8873697916666666 \n",
      "Epoch 11 | Step 4055 | loss: 0.2818879759311676 | accuracy: 0.88875 \n",
      "Epoch 11 | Step 4056 | loss: 0.28284386831980485 | accuracy: 0.8870192307692307 \n",
      "Epoch 11 | Step 4057 | loss: 0.2841878864500258 | accuracy: 0.8865740740740741 \n",
      "Epoch 11 | Step 4058 | loss: 0.2788641287812165 | accuracy: 0.8889508928571429 \n",
      "Epoch 11 | Step 4059 | loss: 0.27740580151821004 | accuracy: 0.8890086206896551 \n",
      "Epoch 11 | Step 4060 | loss: 0.2783817768096924 | accuracy: 0.8890625 \n",
      "Epoch 11 | Step 4061 | loss: 0.2776518944771059 | accuracy: 0.890625 \n",
      "Epoch 11 | Step 4062 | loss: 0.27877969667315483 | accuracy: 0.89111328125 \n",
      "Epoch 11 | Step 4063 | loss: 0.2834303460337899 | accuracy: 0.8887310606060606 \n",
      "Epoch 11 | Step 4064 | loss: 0.2845564852742588 | accuracy: 0.8897058823529411 \n",
      "Epoch 11 | Step 4065 | loss: 0.2850441770894187 | accuracy: 0.8901785714285714 \n",
      "Epoch 11 | Step 4066 | loss: 0.2875053899155723 | accuracy: 0.8893229166666666 \n",
      "Epoch 11 | Step 4067 | loss: 0.28540879447717926 | accuracy: 0.8893581081081081 \n",
      "Epoch 11 | Step 4068 | loss: 0.28398613827793223 | accuracy: 0.889391447368421 \n",
      "Epoch 11 | Step 4069 | loss: 0.2821161456597157 | accuracy: 0.8910256410256411 \n",
      "Epoch 11 | Step 4070 | loss: 0.2814562678337097 | accuracy: 0.890625 \n",
      "Epoch 11 | Step 4071 | loss: 0.28163436200560593 | accuracy: 0.8902439024390244 \n",
      "Epoch 11 | Step 4072 | loss: 0.2812316524130957 | accuracy: 0.890625 \n",
      "Epoch 11 | Step 4073 | loss: 0.2792320882165154 | accuracy: 0.8913517441860465 \n",
      "Epoch 11 | Step 4074 | loss: 0.27829196202484036 | accuracy: 0.8916903409090909 \n",
      "Epoch 11 | Step 4075 | loss: 0.28013260795010453 | accuracy: 0.8902777777777777 \n",
      "Epoch 11 | Step 4076 | loss: 0.2804506489116212 | accuracy: 0.8899456521739131 \n",
      "Epoch 11 | Step 4077 | loss: 0.27920412985568344 | accuracy: 0.890625 \n",
      "Epoch 11 | Step 4078 | loss: 0.2804905284817019 | accuracy: 0.8896484375 \n",
      "Epoch 11 | Step 4079 | loss: 0.2784042619929021 | accuracy: 0.890625 \n",
      "Epoch 11 | Step 4080 | loss: 0.27914882779121386 | accuracy: 0.89 \n",
      "Epoch 11 | Step 4081 | loss: 0.2815675834814706 | accuracy: 0.8890931372549019 \n",
      "Epoch 11 | Step 4082 | loss: 0.28386147950704266 | accuracy: 0.8879206730769231 \n",
      "Epoch 11 | Step 4083 | loss: 0.28278488061338086 | accuracy: 0.8879716981132075 \n",
      "Epoch 11 | Step 4084 | loss: 0.28238222692851656 | accuracy: 0.8883101851851852 \n",
      "Epoch 11 | Step 4085 | loss: 0.28150128776376887 | accuracy: 0.8889204545454545 \n",
      "Epoch 11 | Step 4086 | loss: 0.2827266087489468 | accuracy: 0.8883928571428571 \n",
      "Epoch 11 | Step 4087 | loss: 0.28196756071165974 | accuracy: 0.8887061403508771 \n",
      "Epoch 11 | Step 4088 | loss: 0.28357850811604784 | accuracy: 0.8871228448275862 \n",
      "Epoch 11 | Step 4089 | loss: 0.28379246516753037 | accuracy: 0.8877118644067796 \n",
      "Epoch 11 | Step 4090 | loss: 0.2856340241928894 | accuracy: 0.8869791666666667 \n",
      "Epoch 11 | Step 4091 | loss: 0.28561119295534526 | accuracy: 0.8865266393442623 \n",
      "Epoch 11 | Step 4092 | loss: 0.2854162269542293 | accuracy: 0.8863407258064516 \n",
      "Epoch 11 | Step 4093 | loss: 0.2849846347456885 | accuracy: 0.8864087301587301 \n",
      "Epoch 11 | Step 4094 | loss: 0.2826810786500572 | accuracy: 0.88720703125 \n",
      "Epoch 11 | Step 4095 | loss: 0.2829025231874905 | accuracy: 0.8872596153846154 \n",
      "Epoch 11 | Step 4096 | loss: 0.28068712240818766 | accuracy: 0.8882575757575758 \n",
      "Epoch 11 | Step 4097 | loss: 0.2797161807764821 | accuracy: 0.8885261194029851 \n",
      "Epoch 11 | Step 4098 | loss: 0.27946599748204726 | accuracy: 0.8887867647058824 \n",
      "Epoch 11 | Step 4099 | loss: 0.2802081401797307 | accuracy: 0.8883605072463768 \n",
      "Epoch 11 | Step 4100 | loss: 0.2819032996892928 | accuracy: 0.8879464285714286 \n",
      "Epoch 11 | Step 4101 | loss: 0.2827465299149633 | accuracy: 0.8873239436619719 \n",
      "Epoch 11 | Step 4102 | loss: 0.28192462647954614 | accuracy: 0.8875868055555556 \n",
      "Epoch 11 | Step 4103 | loss: 0.282479799773595 | accuracy: 0.8874143835616438 \n",
      "Epoch 11 | Step 4104 | loss: 0.2830559043465433 | accuracy: 0.887035472972973 \n",
      "Epoch 11 | Step 4105 | loss: 0.28417113860448195 | accuracy: 0.8866666666666667 \n",
      "Epoch 11 | Step 4106 | loss: 0.28337952318160153 | accuracy: 0.8869243421052632 \n",
      "Epoch 11 | Step 4107 | loss: 0.2841221401830772 | accuracy: 0.8867694805194806 \n",
      "Epoch 11 | Step 4108 | loss: 0.28348615479010797 | accuracy: 0.8870192307692307 \n",
      "Epoch 11 | Step 4109 | loss: 0.28239031456693814 | accuracy: 0.8872626582278481 \n",
      "Epoch 11 | Step 4110 | loss: 0.28211776874959466 | accuracy: 0.8873046875 \n",
      "Epoch 11 | Step 4111 | loss: 0.2835876533278712 | accuracy: 0.8865740740740741 \n",
      "Epoch 11 | Step 4112 | loss: 0.2827307018564968 | accuracy: 0.8868140243902439 \n",
      "Epoch 11 | Step 4113 | loss: 0.2830483719527002 | accuracy: 0.8866716867469879 \n",
      "Epoch 11 | Step 4114 | loss: 0.28343169213760455 | accuracy: 0.88671875 \n",
      "Epoch 11 | Step 4115 | loss: 0.28370292537352604 | accuracy: 0.8869485294117647 \n",
      "Epoch 11 | Step 4116 | loss: 0.28271690600140137 | accuracy: 0.8871729651162791 \n",
      "Epoch 11 | Step 4117 | loss: 0.282377089919715 | accuracy: 0.8875718390804598 \n",
      "Epoch 11 | Step 4118 | loss: 0.2827465913512489 | accuracy: 0.8877840909090909 \n",
      "Epoch 11 | Step 4119 | loss: 0.28243455357765873 | accuracy: 0.8878160112359551 \n",
      "Epoch 11 | Step 4120 | loss: 0.2830204486846923 | accuracy: 0.8875 \n",
      "Epoch 11 | Step 4121 | loss: 0.2827851254861432 | accuracy: 0.8877060439560439 \n",
      "Epoch 11 | Step 4122 | loss: 0.28487162259609794 | accuracy: 0.8870584239130435 \n",
      "Epoch 11 | Step 4123 | loss: 0.28720404864639354 | accuracy: 0.8860887096774194 \n",
      "Epoch 11 | Step 4124 | loss: 0.28603710693881856 | accuracy: 0.886968085106383 \n",
      "Epoch 11 | Step 4125 | loss: 0.28518033513897334 | accuracy: 0.8875 \n",
      "Epoch 11 | Step 4126 | loss: 0.28438291590039916 | accuracy: 0.8878580729166666 \n",
      "Epoch 11 | Step 4127 | loss: 0.28373761275379916 | accuracy: 0.8880476804123711 \n",
      "Epoch 11 | Step 4128 | loss: 0.2847315513966034 | accuracy: 0.8875956632653061 \n",
      "Epoch 11 | Step 4129 | loss: 0.2839459322317681 | accuracy: 0.8880997474747475 \n",
      "Epoch 11 | Step 4130 | loss: 0.2843212676048278 | accuracy: 0.88765625 \n",
      "Epoch 11 | Step 4131 | loss: 0.2844292087720171 | accuracy: 0.8876856435643564 \n",
      "Epoch 11 | Step 4132 | loss: 0.284606176848505 | accuracy: 0.8872549019607843 \n",
      "Epoch 11 | Step 4133 | loss: 0.28477987994268095 | accuracy: 0.8869842233009708 \n",
      "Epoch 11 | Step 4134 | loss: 0.28511834689057786 | accuracy: 0.8873197115384616 \n",
      "Epoch 11 | Step 4135 | loss: 0.2859124850659143 | accuracy: 0.8870535714285714 \n",
      "Epoch 11 | Step 4136 | loss: 0.28551283703660063 | accuracy: 0.8870872641509434 \n",
      "Epoch 11 | Step 4137 | loss: 0.28582757154357763 | accuracy: 0.8869742990654206 \n",
      "Epoch 11 | Step 4138 | loss: 0.28660545332564247 | accuracy: 0.8864293981481481 \n",
      "Epoch 11 | Step 4139 | loss: 0.2855178735671787 | accuracy: 0.8871846330275229 \n",
      "Epoch 11 | Step 4140 | loss: 0.2855680766430768 | accuracy: 0.8870738636363636 \n",
      "Epoch 11 | Step 4141 | loss: 0.28657790132471034 | accuracy: 0.8865427927927928 \n",
      "Epoch 11 | Step 4142 | loss: 0.2875386247677462 | accuracy: 0.8861607142857143 \n",
      "Epoch 11 | Step 4143 | loss: 0.28717899625807736 | accuracy: 0.8863384955752213 \n",
      "Epoch 11 | Step 4144 | loss: 0.2872528173682982 | accuracy: 0.8859649122807017 \n",
      "Epoch 11 | Step 4145 | loss: 0.2866749002881672 | accuracy: 0.8862771739130435 \n",
      "Epoch 11 | Step 4146 | loss: 0.28588410299913636 | accuracy: 0.8868534482758621 \n",
      "Epoch 11 | Step 4147 | loss: 0.28549652311027557 | accuracy: 0.8872863247863247 \n",
      "Epoch 11 | Step 4148 | loss: 0.2859381731536429 | accuracy: 0.886917372881356 \n",
      "Epoch 11 | Step 4149 | loss: 0.2866602696540977 | accuracy: 0.8862920168067226 \n",
      "Epoch 11 | Step 4150 | loss: 0.2867690005650123 | accuracy: 0.8861979166666667 \n",
      "Epoch 11 | Step 4151 | loss: 0.2860842576204253 | accuracy: 0.8863636363636364 \n",
      "Epoch 11 | Step 4152 | loss: 0.2865774289506381 | accuracy: 0.8858862704918032 \n",
      "Epoch 11 | Step 4153 | loss: 0.28633476030535815 | accuracy: 0.8859247967479674 \n",
      "Epoch 11 | Step 4154 | loss: 0.28721228890842004 | accuracy: 0.8854586693548387 \n",
      "Epoch 11 | Step 4155 | loss: 0.2870403411388397 | accuracy: 0.885375 \n",
      "Epoch 11 | Step 4156 | loss: 0.28630558484130436 | accuracy: 0.8856646825396826 \n",
      "Epoch 11 | Step 4157 | loss: 0.2868606063324635 | accuracy: 0.8852116141732284 \n",
      "Epoch 11 | Step 4158 | loss: 0.286470816237852 | accuracy: 0.885498046875 \n",
      "Epoch 11 | Step 4159 | loss: 0.28656362493832904 | accuracy: 0.8854166666666666 \n",
      "Epoch 11 | Step 4160 | loss: 0.28663394749164584 | accuracy: 0.8853365384615385 \n",
      "Epoch 11 | Step 4161 | loss: 0.286952217571608 | accuracy: 0.8850190839694656 \n",
      "Epoch 11 | Step 4162 | loss: 0.2869113444378882 | accuracy: 0.885061553030303 \n",
      "Epoch 11 | Step 4163 | loss: 0.2864198274630353 | accuracy: 0.8853383458646616 \n",
      "Epoch 11 | Step 4164 | loss: 0.28568656753693056 | accuracy: 0.8858442164179104 \n",
      "Epoch 11 | Step 4165 | loss: 0.28596894597565686 | accuracy: 0.8859953703703703 \n",
      "Epoch 11 | Step 4166 | loss: 0.28607034146347465 | accuracy: 0.8861443014705882 \n",
      "Epoch 11 | Step 4167 | loss: 0.2868880262992678 | accuracy: 0.8858348540145985 \n",
      "Epoch 11 | Step 4168 | loss: 0.28657626339058945 | accuracy: 0.8858695652173914 \n",
      "Epoch 11 | Step 4169 | loss: 0.2871378899263821 | accuracy: 0.885341726618705 \n",
      "Epoch 11 | Step 4170 | loss: 0.2870985362146582 | accuracy: 0.88515625 \n",
      "Epoch 11 | Step 4171 | loss: 0.2872215332925742 | accuracy: 0.8848625886524822 \n",
      "Epoch 11 | Step 4172 | loss: 0.28697715332390555 | accuracy: 0.8849031690140845 \n",
      "Epoch 11 | Step 4173 | loss: 0.2864533626324647 | accuracy: 0.8851617132867133 \n",
      "Epoch 11 | Step 4174 | loss: 0.28641298982418245 | accuracy: 0.8850911458333334 \n",
      "Epoch 11 | Step 4175 | loss: 0.2861591937213108 | accuracy: 0.8850215517241379 \n",
      "Epoch 11 | Step 4176 | loss: 0.28636945355428406 | accuracy: 0.8851669520547946 \n",
      "Epoch 11 | Step 4177 | loss: 0.28645909967876615 | accuracy: 0.8853103741496599 \n",
      "Epoch 11 | Step 4178 | loss: 0.2863668622197332 | accuracy: 0.8852407094594594 \n",
      "Epoch 11 | Step 4179 | loss: 0.286388558229344 | accuracy: 0.8853817114093959 \n",
      "Epoch 11 | Step 4180 | loss: 0.28550029546022415 | accuracy: 0.8858333333333334 \n",
      "Epoch 11 | Step 4181 | loss: 0.28553841021281995 | accuracy: 0.8858650662251656 \n",
      "Epoch 11 | Step 4182 | loss: 0.2860474530607462 | accuracy: 0.885999177631579 \n",
      "Epoch 11 | Step 4183 | loss: 0.28653538743265317 | accuracy: 0.8859272875816994 \n",
      "Epoch 11 | Step 4184 | loss: 0.2857737451211199 | accuracy: 0.8862621753246753 \n",
      "Epoch 11 | Step 4185 | loss: 0.2851194982567142 | accuracy: 0.8865927419354839 \n",
      "Epoch 11 | Step 4186 | loss: 0.2842458292650871 | accuracy: 0.8869190705128205 \n",
      "Epoch 11 | Step 4187 | loss: 0.28402638596713925 | accuracy: 0.8869426751592356 \n",
      "Epoch 11 | Step 4188 | loss: 0.283751818198192 | accuracy: 0.8869659810126582 \n",
      "Epoch 11 | Step 4189 | loss: 0.28368621389820897 | accuracy: 0.8869889937106918 \n",
      "Epoch 11 | Step 4190 | loss: 0.2835106397047639 | accuracy: 0.88701171875 \n",
      "Epoch 11 | Step 4191 | loss: 0.28314026847759394 | accuracy: 0.8870341614906833 \n",
      "Epoch 11 | Step 4192 | loss: 0.2832805804080434 | accuracy: 0.8868634259259259 \n",
      "Epoch 11 | Step 4193 | loss: 0.2824244286202215 | accuracy: 0.8873657975460123 \n",
      "Epoch 11 | Step 4194 | loss: 0.2820469349077563 | accuracy: 0.8872903963414634 \n",
      "Epoch 11 | Step 4195 | loss: 0.2820269934155725 | accuracy: 0.8872159090909091 \n",
      "Epoch 11 | Step 4196 | loss: 0.283189918711243 | accuracy: 0.8867658132530121 \n",
      "Epoch 11 | Step 4197 | loss: 0.2824986274549348 | accuracy: 0.8870696107784432 \n",
      "Epoch 11 | Step 4198 | loss: 0.2822856532321091 | accuracy: 0.8868117559523809 \n",
      "Epoch 11 | Step 4199 | loss: 0.2835619103979078 | accuracy: 0.8861871301775148 \n",
      "Epoch 11 | Step 4200 | loss: 0.2835144635509043 | accuracy: 0.8862132352941177 \n",
      "Epoch 11 | Step 4201 | loss: 0.283803880737539 | accuracy: 0.8860562865497076 \n",
      "Epoch 11 | Step 4202 | loss: 0.28409941979618963 | accuracy: 0.8859011627906976 \n",
      "Epoch 11 | Step 4203 | loss: 0.2829053724087732 | accuracy: 0.8865606936416185 \n",
      "Epoch 11 | Step 4204 | loss: 0.28303093300468624 | accuracy: 0.8865840517241379 \n",
      "Epoch 11 | Step 4205 | loss: 0.2828053864410946 | accuracy: 0.8867857142857143 \n",
      "Epoch 11 | Step 4206 | loss: 0.282711733640595 | accuracy: 0.8870738636363636 \n",
      "Epoch 11 | Step 4207 | loss: 0.2831273769254739 | accuracy: 0.8870056497175142 \n",
      "Epoch 11 | Step 4208 | loss: 0.283153196064274 | accuracy: 0.8870259831460674 \n",
      "Epoch 11 | Step 4209 | loss: 0.2832220513061439 | accuracy: 0.8871333798882681 \n",
      "Epoch 11 | Step 4210 | loss: 0.28367217116885723 | accuracy: 0.8869791666666667 \n",
      "Epoch 11 | Step 4211 | loss: 0.283281212188921 | accuracy: 0.887085635359116 \n",
      "Epoch 11 | Step 4212 | loss: 0.28284405122746487 | accuracy: 0.887448489010989 \n",
      "Epoch 11 | Step 4213 | loss: 0.2823856284872431 | accuracy: 0.8878927595628415 \n",
      "Epoch 11 | Step 4214 | loss: 0.2826157614750707 | accuracy: 0.8879925271739131 \n",
      "Epoch 11 | Step 4215 | loss: 0.2827445871926644 | accuracy: 0.8877533783783784 \n",
      "Epoch 11 | Step 4216 | loss: 0.28267450206061856 | accuracy: 0.8877688172043011 \n",
      "Epoch 11 | Step 4217 | loss: 0.28284964053069855 | accuracy: 0.8877840909090909 \n",
      "Epoch 11 | Step 4218 | loss: 0.2828587162843411 | accuracy: 0.8880485372340425 \n",
      "Epoch 11 | Step 4219 | loss: 0.28239602465478214 | accuracy: 0.8882275132275133 \n",
      "Epoch 11 | Step 4220 | loss: 0.2823443241809545 | accuracy: 0.8881578947368421 \n",
      "Epoch 11 | Step 4221 | loss: 0.2825723547898039 | accuracy: 0.8880071989528796 \n",
      "Epoch 11 | Step 4222 | loss: 0.28287980674455576 | accuracy: 0.8878580729166666 \n",
      "Epoch 11 | Step 4223 | loss: 0.28331458197974185 | accuracy: 0.8876295336787565 \n",
      "Epoch 11 | Step 4224 | loss: 0.28278638860306804 | accuracy: 0.887806056701031 \n",
      "Epoch 11 | Step 4225 | loss: 0.28317842307763236 | accuracy: 0.8875 \n",
      "Epoch 11 | Step 4226 | loss: 0.2832908809032977 | accuracy: 0.8874362244897959 \n",
      "Epoch 11 | Step 4227 | loss: 0.2834638285304085 | accuracy: 0.8872144670050761 \n",
      "Epoch 11 | Step 4228 | loss: 0.2837163559866675 | accuracy: 0.8869160353535354 \n",
      "Epoch 11 | Step 4229 | loss: 0.28415368662108137 | accuracy: 0.886699120603015 \n",
      "Epoch 11 | Step 4230 | loss: 0.2839432628452779 | accuracy: 0.886796875 \n",
      "Epoch 11 | Step 4231 | loss: 0.28432469166333413 | accuracy: 0.8865827114427861 \n",
      "Epoch 11 | Step 4232 | loss: 0.28447851641933525 | accuracy: 0.8865253712871287 \n",
      "Epoch 11 | Step 4233 | loss: 0.2841165654471356 | accuracy: 0.8869304187192119 \n",
      "Epoch 11 | Step 4234 | loss: 0.28412161197732483 | accuracy: 0.8868719362745098 \n",
      "Epoch 11 | Step 4235 | loss: 0.2843218024184065 | accuracy: 0.8867378048780488 \n",
      "Epoch 11 | Step 4236 | loss: 0.28424329665100695 | accuracy: 0.8867566747572816 \n",
      "Epoch 11 | Step 4237 | loss: 0.28388373344992673 | accuracy: 0.8869263285024155 \n",
      "Epoch 11 | Step 4238 | loss: 0.28352725949998087 | accuracy: 0.8870943509615384 \n",
      "Epoch 11 | Step 4239 | loss: 0.2835852319829202 | accuracy: 0.8871112440191388 \n",
      "Epoch 11 | Step 4240 | loss: 0.28316468986726945 | accuracy: 0.8872767857142857 \n",
      "Epoch 11 | Step 4241 | loss: 0.2830526001786734 | accuracy: 0.887292654028436 \n",
      "Epoch 11 | Step 4242 | loss: 0.283278088454368 | accuracy: 0.8873083726415094 \n",
      "Epoch 11 | Step 4243 | loss: 0.2828086974195472 | accuracy: 0.8874706572769953 \n",
      "Epoch 11 | Step 4244 | loss: 0.28258660588866086 | accuracy: 0.8877774532710281 \n",
      "Epoch 11 | Step 4245 | loss: 0.28300622424413996 | accuracy: 0.8876453488372092 \n",
      "Epoch 11 | Step 4246 | loss: 0.28367406157431785 | accuracy: 0.8872974537037037 \n",
      "Epoch 11 | Step 4247 | loss: 0.2841840438579085 | accuracy: 0.8871687788018433 \n",
      "Epoch 11 | Step 4248 | loss: 0.2839551847598969 | accuracy: 0.8873279816513762 \n",
      "Epoch 11 | Step 4249 | loss: 0.28385271703543735 | accuracy: 0.8872716894977168 \n",
      "Epoch 11 | Step 4250 | loss: 0.28391513208096686 | accuracy: 0.8870738636363636 \n",
      "Epoch 11 | Step 4251 | loss: 0.28350034983179695 | accuracy: 0.887302036199095 \n",
      "Epoch 11 | Step 4252 | loss: 0.28316620938681275 | accuracy: 0.887598536036036 \n",
      "Epoch 11 | Step 4253 | loss: 0.28329656684077914 | accuracy: 0.8876121076233184 \n",
      "Epoch 11 | Step 4254 | loss: 0.28315634420141583 | accuracy: 0.8876953125 \n",
      "Epoch 11 | Step 4255 | loss: 0.2835628432035447 | accuracy: 0.8874305555555555 \n",
      "Epoch 11 | Step 4256 | loss: 0.28381613510108633 | accuracy: 0.8873064159292036 \n",
      "Epoch 11 | Step 4257 | loss: 0.2839468785188272 | accuracy: 0.8872522026431718 \n",
      "Epoch 11 | Step 4258 | loss: 0.28388974403864464 | accuracy: 0.8872669956140351 \n",
      "Epoch 11 | Step 4259 | loss: 0.2834147973612407 | accuracy: 0.8875545851528385 \n",
      "Epoch 11 | Step 4260 | loss: 0.2831938174107801 | accuracy: 0.8875679347826086 \n",
      "Epoch 11 | Step 4261 | loss: 0.2835233311503481 | accuracy: 0.8873782467532467 \n",
      "Epoch 11 | Step 4262 | loss: 0.28310088768344505 | accuracy: 0.8875269396551724 \n",
      "Epoch 11 | Step 4263 | loss: 0.2831022925515032 | accuracy: 0.8874061158798283 \n",
      "Epoch 11 | Step 4264 | loss: 0.28319540931883025 | accuracy: 0.8873530982905983 \n",
      "Epoch 11 | Step 4265 | loss: 0.2828974141719494 | accuracy: 0.8875664893617021 \n",
      "Epoch 11 | Step 4266 | loss: 0.28288461293204364 | accuracy: 0.8877118644067796 \n",
      "Epoch 11 | Step 4267 | loss: 0.2832368507918427 | accuracy: 0.8875263713080169 \n",
      "Epoch 11 | Step 4268 | loss: 0.2836300499048554 | accuracy: 0.8874080882352942 \n",
      "Epoch 11 | Step 4269 | loss: 0.28336402524465304 | accuracy: 0.8874215481171548 \n",
      "Epoch 11 | Step 4270 | loss: 0.28304861355572947 | accuracy: 0.8876302083333333 \n",
      "Epoch 11 | Step 4271 | loss: 0.28323931856026796 | accuracy: 0.8875778008298755 \n",
      "Epoch 11 | Step 4272 | loss: 0.2834421310666179 | accuracy: 0.887525826446281 \n",
      "Epoch 11 | Step 4273 | loss: 0.2833932313776802 | accuracy: 0.8876671810699589 \n",
      "Epoch 11 | Step 4274 | loss: 0.28275104318974453 | accuracy: 0.887999487704918 \n",
      "Epoch 11 | Step 4275 | loss: 0.28246032559141826 | accuracy: 0.8882015306122449 \n",
      "Epoch 11 | Step 4276 | loss: 0.2822080530771396 | accuracy: 0.8882748983739838 \n",
      "Epoch 11 | Step 4277 | loss: 0.28183613717556005 | accuracy: 0.8884741902834008 \n",
      "Epoch 11 | Step 4278 | loss: 0.282100644743731 | accuracy: 0.8883568548387096 \n",
      "Epoch 11 | Step 4279 | loss: 0.28209791215787455 | accuracy: 0.8883659638554217 \n",
      "Epoch 11 | Step 4280 | loss: 0.28182165634632117 | accuracy: 0.888625 \n",
      "Epoch 11 | Step 4281 | loss: 0.28199826056263844 | accuracy: 0.8885707171314741 \n",
      "Epoch 11 | Step 4282 | loss: 0.28215225904233876 | accuracy: 0.8883928571428571 \n",
      "Epoch 11 | Step 4283 | loss: 0.28220597097996203 | accuracy: 0.8883399209486166 \n",
      "Epoch 11 | Step 4284 | loss: 0.2822428071123409 | accuracy: 0.8882874015748031 \n",
      "Epoch 11 | Step 4285 | loss: 0.28202757227654557 | accuracy: 0.8884803921568627 \n",
      "Epoch 11 | Step 4286 | loss: 0.28206058626528835 | accuracy: 0.8883056640625 \n",
      "Epoch 11 | Step 4287 | loss: 0.28203934164362665 | accuracy: 0.888193093385214 \n",
      "Epoch 11 | Step 4288 | loss: 0.2822301693895991 | accuracy: 0.8880813953488372 \n",
      "Epoch 11 | Step 4289 | loss: 0.2821847864329585 | accuracy: 0.888030888030888 \n",
      "Epoch 11 | Step 4290 | loss: 0.28213969491995305 | accuracy: 0.8881009615384615 \n",
      "Epoch 11 | Step 4291 | loss: 0.2819693186730718 | accuracy: 0.8882902298850575 \n",
      "Epoch 11 | Step 4292 | loss: 0.28248728368118525 | accuracy: 0.8881202290076335 \n",
      "Epoch 11 | Step 4293 | loss: 0.28237253756124264 | accuracy: 0.888129752851711 \n",
      "Epoch 11 | Step 4294 | loss: 0.282282205580762 | accuracy: 0.8881392045454546 \n",
      "Epoch 11 | Step 4295 | loss: 0.2821153805503306 | accuracy: 0.8881485849056604 \n",
      "Epoch 11 | Step 4296 | loss: 0.28212763419500875 | accuracy: 0.8883341165413534 \n",
      "Epoch 11 | Step 4297 | loss: 0.2818810544098808 | accuracy: 0.8884012172284644 \n",
      "Epoch 11 | Step 4298 | loss: 0.2820565254052184 | accuracy: 0.8882929104477612 \n",
      "Epoch 11 | Step 4299 | loss: 0.28194822238058853 | accuracy: 0.8883015799256505 \n",
      "Epoch 11 | Step 4300 | loss: 0.28205072498983813 | accuracy: 0.8882523148148148 \n",
      "Epoch 11 | Step 4301 | loss: 0.2820813728984432 | accuracy: 0.8882610701107011 \n",
      "Epoch 11 | Step 4302 | loss: 0.2819303445079748 | accuracy: 0.8883846507352942 \n",
      "Epoch 11 | Step 4303 | loss: 0.28197823601327976 | accuracy: 0.8884500915750916 \n",
      "Epoch 11 | Step 4304 | loss: 0.28205754482833145 | accuracy: 0.8885150547445255 \n",
      "Epoch 11 | Step 4305 | loss: 0.28187204220078216 | accuracy: 0.8885227272727273 \n",
      "Epoch 11 | Step 4306 | loss: 0.28219649595194973 | accuracy: 0.8883038949275363 \n",
      "Epoch 11 | Step 4307 | loss: 0.28204758077967473 | accuracy: 0.888312274368231 \n",
      "Epoch 11 | Step 4308 | loss: 0.28180885052295046 | accuracy: 0.8884330035971223 \n",
      "Epoch 11 | Step 4309 | loss: 0.28164826221363526 | accuracy: 0.8884968637992832 \n",
      "Epoch 11 | Step 4310 | loss: 0.2816299712019308 | accuracy: 0.8883928571428571 \n",
      "Epoch 11 | Step 4311 | loss: 0.2815606669386935 | accuracy: 0.8884564056939501 \n",
      "Epoch 11 | Step 4312 | loss: 0.2812263250139589 | accuracy: 0.8885195035460992 \n",
      "Epoch 11 | Step 4313 | loss: 0.281120694146982 | accuracy: 0.8884717314487631 \n",
      "Epoch 11 | Step 4314 | loss: 0.28075520012160426 | accuracy: 0.888644366197183 \n",
      "Epoch 11 | Step 4315 | loss: 0.2807267258041784 | accuracy: 0.8885416666666666 \n",
      "Epoch 11 | Step 4316 | loss: 0.28026157617568975 | accuracy: 0.8887674825174824 \n",
      "Epoch 11 | Step 4317 | loss: 0.2803876223464461 | accuracy: 0.8887195121951218 \n",
      "Epoch 11 | Step 4318 | loss: 0.2800058119205965 | accuracy: 0.8889431423611109 \n",
      "Epoch 11 | Step 4319 | loss: 0.2806967776333172 | accuracy: 0.8888408304498268 \n",
      "Epoch 11 | Step 4320 | loss: 0.28057536421150997 | accuracy: 0.8889547413793102 \n",
      "Epoch 11 | Step 4321 | loss: 0.2810044637865217 | accuracy: 0.8887457044673538 \n",
      "Epoch 11 | Step 4322 | loss: 0.2809431928477875 | accuracy: 0.8888591609589039 \n",
      "Epoch 11 | Step 4323 | loss: 0.2809357612613118 | accuracy: 0.8888651877133104 \n",
      "Epoch 11 | Step 4324 | loss: 0.281045539748101 | accuracy: 0.8887648809523807 \n",
      "Epoch 11 | Step 4325 | loss: 0.28087887460902583 | accuracy: 0.8889300847457625 \n",
      "Epoch 11 | Step 4326 | loss: 0.2809012106342895 | accuracy: 0.8889885979729728 \n",
      "Epoch 11 | Step 4327 | loss: 0.2807981597654747 | accuracy: 0.889046717171717 \n",
      "Epoch 11 | Step 4328 | loss: 0.280652778660691 | accuracy: 0.8891568791946307 \n",
      "Epoch 11 | Step 4329 | loss: 0.28055964315615367 | accuracy: 0.8893185618729095 \n",
      "Epoch 11 | Step 4330 | loss: 0.28018895740310346 | accuracy: 0.8895312499999998 \n",
      "Epoch 11 | Step 4331 | loss: 0.2806175389262132 | accuracy: 0.8892234219269101 \n",
      "Epoch 11 | Step 4332 | loss: 0.2804089706662474 | accuracy: 0.8894350165562912 \n",
      "Epoch 11 | Step 4333 | loss: 0.2802195954244128 | accuracy: 0.8895936468646862 \n",
      "Epoch 11 | Step 4334 | loss: 0.28030473209525403 | accuracy: 0.8894942434210524 \n",
      "Epoch 11 | Step 4335 | loss: 0.280115342189054 | accuracy: 0.889497950819672 \n",
      "Epoch 11 | Step 4336 | loss: 0.2801717934168242 | accuracy: 0.8893995098039214 \n",
      "Epoch 11 | Step 4337 | loss: 0.2808865269445829 | accuracy: 0.8891490228013027 \n",
      "Epoch 11 | Step 4338 | loss: 0.2806356469435351 | accuracy: 0.8893060064935063 \n",
      "Epoch 11 | Step 4339 | loss: 0.28040990648146197 | accuracy: 0.889360841423948 \n",
      "Epoch 11 | Step 4340 | loss: 0.28049074920915784 | accuracy: 0.8893649193548385 \n",
      "Epoch 11 | Step 4341 | loss: 0.28051147363193546 | accuracy: 0.8894694533762056 \n",
      "Epoch 11 | Step 4342 | loss: 0.28050872272787947 | accuracy: 0.889523237179487 \n",
      "Epoch 11 | Step 4343 | loss: 0.2803435178515248 | accuracy: 0.8897264376996803 \n",
      "Epoch 11 | Step 4344 | loss: 0.2807159209801892 | accuracy: 0.8895800159235667 \n",
      "Epoch 11 | Step 4345 | loss: 0.28115822554580744 | accuracy: 0.8894841269841268 \n",
      "Epoch 11 | Step 4346 | loss: 0.2810996150762974 | accuracy: 0.889487737341772 \n",
      "Epoch 11 | Step 4347 | loss: 0.28087871895415545 | accuracy: 0.889639195583596 \n",
      "Epoch 11 | Step 4348 | loss: 0.28112863196329496 | accuracy: 0.889445754716981 \n",
      "Epoch 11 | Step 4349 | loss: 0.28106967338760813 | accuracy: 0.8894984326018807 \n",
      "Epoch 11 | Step 4350 | loss: 0.28083947626873845 | accuracy: 0.8895996093749998 \n",
      "Epoch 11 | Step 4351 | loss: 0.28090621294262247 | accuracy: 0.8895054517133955 \n",
      "Epoch 11 | Step 4352 | loss: 0.28127947560748695 | accuracy: 0.8894118788819874 \n",
      "Epoch 11 | Step 4353 | loss: 0.28102374159883786 | accuracy: 0.8895123839009286 \n",
      "Epoch 11 | Step 4354 | loss: 0.28075791706825476 | accuracy: 0.8896122685185184 \n",
      "Epoch 11 | Step 4355 | loss: 0.2808421942362418 | accuracy: 0.8895192307692306 \n",
      "Epoch 11 | Step 4356 | loss: 0.2806546030783214 | accuracy: 0.8896184815950918 \n",
      "Epoch 11 | Step 4357 | loss: 0.2807666729531886 | accuracy: 0.8895259938837918 \n",
      "Epoch 11 | Step 4358 | loss: 0.28082088726322824 | accuracy: 0.889481707317073 \n",
      "Epoch 11 | Step 4359 | loss: 0.28133225060523825 | accuracy: 0.8892002279635257 \n",
      "Epoch 11 | Step 4360 | loss: 0.2812902636600263 | accuracy: 0.8892045454545453 \n",
      "Epoch 11 | Step 4361 | loss: 0.28115055914911974 | accuracy: 0.8892560422960724 \n",
      "Epoch 11 | Step 4362 | loss: 0.28106937624783396 | accuracy: 0.8892601656626504 \n",
      "Epoch 11 | Step 4363 | loss: 0.2808910212717256 | accuracy: 0.8893581081081079 \n",
      "Epoch 11 | Step 4364 | loss: 0.28111264493294097 | accuracy: 0.8892683383233532 \n",
      "Epoch 11 | Step 4365 | loss: 0.28083146921734303 | accuracy: 0.8893656716417909 \n",
      "Epoch 11 | Step 4366 | loss: 0.2806576272650133 | accuracy: 0.8894624255952379 \n",
      "Epoch 11 | Step 4367 | loss: 0.28070865315039706 | accuracy: 0.8894658753709197 \n",
      "Epoch 11 | Step 4368 | loss: 0.28074495904368046 | accuracy: 0.8895155325443785 \n",
      "Epoch 11 | Step 4369 | loss: 0.28061966022207313 | accuracy: 0.8895188053097344 \n",
      "Epoch 11 | Step 4370 | loss: 0.28020770093973935 | accuracy: 0.889705882352941 \n",
      "Epoch 11 | Step 4371 | loss: 0.28001274880775595 | accuracy: 0.8898002199413488 \n",
      "Epoch 11 | Step 4372 | loss: 0.2798882708040593 | accuracy: 0.8898483187134502 \n",
      "Epoch 11 | Step 4373 | loss: 0.27966648831138097 | accuracy: 0.890032798833819 \n",
      "Epoch 11 | Step 4374 | loss: 0.2794877545864775 | accuracy: 0.890034520348837 \n",
      "Epoch 11 | Step 4375 | loss: 0.2795124367095421 | accuracy: 0.8899909420289853 \n",
      "Epoch 11 | Step 4376 | loss: 0.27952607738317087 | accuracy: 0.8900379335260113 \n",
      "Epoch 11 | Step 4377 | loss: 0.2791660632025611 | accuracy: 0.8902197406340056 \n",
      "Epoch 11 | Step 4378 | loss: 0.27960872731503394 | accuracy: 0.8900862068965516 \n",
      "Epoch 11 | Step 4379 | loss: 0.2794977277517318 | accuracy: 0.8900877507163322 \n",
      "Epoch 11 | Step 4380 | loss: 0.2793718779512814 | accuracy: 0.8901785714285713 \n",
      "Epoch 11 | Step 4381 | loss: 0.2791163270120267 | accuracy: 0.8903579059829059 \n",
      "Epoch 11 | Step 4382 | loss: 0.27926028248938645 | accuracy: 0.8903142755681817 \n",
      "Epoch 11 | Step 4383 | loss: 0.2790869345239471 | accuracy: 0.8903151558073653 \n",
      "Epoch 11 | Step 4384 | loss: 0.2788283257918842 | accuracy: 0.8903601694915253 \n",
      "Epoch 11 | Step 4385 | loss: 0.27866558247888584 | accuracy: 0.8904049295774646 \n",
      "Epoch 11 | Step 4386 | loss: 0.2784255012200119 | accuracy: 0.8904933286516852 \n",
      "Epoch 11 | Step 4387 | loss: 0.27843609118328033 | accuracy: 0.8904499299719887 \n",
      "Epoch 11 | Step 4388 | loss: 0.27844260691264483 | accuracy: 0.8904067737430166 \n",
      "Epoch 11 | Step 4389 | loss: 0.2782291880806176 | accuracy: 0.890450905292479 \n",
      "Epoch 11 | Step 4390 | loss: 0.27803088501095763 | accuracy: 0.8904947916666666 \n",
      "Epoch 11 | Step 4391 | loss: 0.278165792659379 | accuracy: 0.8903653047091411 \n",
      "Epoch 11 | Step 4392 | loss: 0.27814221736146594 | accuracy: 0.8903660220994474 \n",
      "Epoch 11 | Step 4393 | loss: 0.2780887626583582 | accuracy: 0.8904097796143249 \n",
      "Epoch 11 | Step 4394 | loss: 0.278005451782719 | accuracy: 0.8904103708791207 \n",
      "Epoch 11 | Step 4395 | loss: 0.27773112017814416 | accuracy: 0.8904965753424656 \n",
      "Epoch 11 | Step 4396 | loss: 0.27759722693533184 | accuracy: 0.8904542349726774 \n",
      "Epoch 11 | Step 4397 | loss: 0.27745329363307114 | accuracy: 0.8904972752043595 \n",
      "Epoch 11 | Step 4398 | loss: 0.27720225476862287 | accuracy: 0.8906249999999999 \n",
      "Epoch 11 | Step 4399 | loss: 0.27742750191591614 | accuracy: 0.8905826558265582 \n",
      "Epoch 11 | Step 4400 | loss: 0.27762460640153364 | accuracy: 0.8904138513513512 \n",
      "Epoch 11 | Step 4401 | loss: 0.27773971285299465 | accuracy: 0.8903301886792452 \n",
      "Epoch 11 | Step 4402 | loss: 0.27843358059243484 | accuracy: 0.8899949596774192 \n",
      "Epoch 11 | Step 4403 | loss: 0.27854679373090446 | accuracy: 0.8898709785522787 \n",
      "Epoch 11 | Step 4404 | loss: 0.27839944575400266 | accuracy: 0.8899147727272726 \n",
      "Epoch 11 | Step 4405 | loss: 0.27813079361120846 | accuracy: 0.8901249999999998 \n",
      "Epoch 11 | Step 4406 | loss: 0.2781425173533088 | accuracy: 0.8900432180851062 \n",
      "Epoch 11 | Step 4407 | loss: 0.2780599653009393 | accuracy: 0.8900862068965516 \n",
      "Epoch 11 | Step 4408 | loss: 0.27815710319570747 | accuracy: 0.8899636243386242 \n",
      "Epoch 11 | Step 4409 | loss: 0.2778586656405616 | accuracy: 0.8900478232189972 \n",
      "Epoch 11 | Step 4410 | loss: 0.27762104555180184 | accuracy: 0.8902138157894736 \n",
      "Epoch 11 | Step 4411 | loss: 0.27744835595602735 | accuracy: 0.8902148950131232 \n",
      "Epoch 11 | Step 4412 | loss: 0.2772241865933252 | accuracy: 0.8902568717277486 \n",
      "Epoch 11 | Step 4413 | loss: 0.277095158868919 | accuracy: 0.8902578328981722 \n",
      "Epoch 11 | Step 4414 | loss: 0.2771775842023391 | accuracy: 0.8902180989583331 \n",
      "Epoch 11 | Step 4415 | loss: 0.27745470327216293 | accuracy: 0.8901379870129869 \n",
      "Epoch 11 | Step 4416 | loss: 0.2777431553972816 | accuracy: 0.8899773316062175 \n",
      "Epoch 11 | Step 4417 | loss: 0.27784113813124256 | accuracy: 0.890019379844961 \n",
      "Epoch 11 | Step 4418 | loss: 0.27769659401983315 | accuracy: 0.890061211340206 \n",
      "Epoch 11 | Step 4419 | loss: 0.2779062439742614 | accuracy: 0.8899019922879176 \n",
      "Epoch 11 | Step 4420 | loss: 0.27787288301266144 | accuracy: 0.8899439102564101 \n",
      "Epoch 11 | Step 4421 | loss: 0.2780216241355441 | accuracy: 0.8899056905370842 \n",
      "Epoch 11 | Step 4422 | loss: 0.2778582818121933 | accuracy: 0.8900271045918365 \n",
      "Epoch 11 | Step 4423 | loss: 0.2776212114793349 | accuracy: 0.8901479007633586 \n",
      "Epoch 11 | Step 4424 | loss: 0.2777894402140287 | accuracy: 0.8900301395939085 \n",
      "Epoch 11 | Step 4425 | loss: 0.27767266001127927 | accuracy: 0.8900712025316454 \n",
      "Epoch 11 | Step 4426 | loss: 0.27759860572640327 | accuracy: 0.890112058080808 \n",
      "Epoch 11 | Step 4427 | loss: 0.277683795737079 | accuracy: 0.8899952770780855 \n",
      "Epoch 11 | Step 4428 | loss: 0.2779349113004889 | accuracy: 0.8898790829145727 \n",
      "Epoch 11 | Step 4429 | loss: 0.27779444589053165 | accuracy: 0.8899201127819547 \n",
      "Epoch 11 | Step 4430 | loss: 0.27803720042109475 | accuracy: 0.8897656249999999 \n",
      "Epoch 11 | Step 4431 | loss: 0.2780430265644243 | accuracy: 0.8897288029925186 \n",
      "Epoch 11 | Step 4432 | loss: 0.27847787448719347 | accuracy: 0.8895366915422884 \n",
      "Epoch 11 | Step 4433 | loss: 0.2781830396752793 | accuracy: 0.8896396637850303 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.5223729610443115 | accuracy: 0.765625 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.5348496437072754 | accuracy: 0.765625 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.47278791666030884 | accuracy: 0.7864583333333334 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4643935486674309 | accuracy: 0.7890625 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4684715449810028 | accuracy: 0.790625 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.456881249944369 | accuracy: 0.7942708333333334 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.44725105592182707 | accuracy: 0.7991071428571429 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.43752752244472504 | accuracy: 0.802734375 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.43113111787372166 | accuracy: 0.8072916666666666 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.43383684754371643 | accuracy: 0.809375 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.43557762557810004 | accuracy: 0.8125 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.42738691717386246 | accuracy: 0.81640625 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4313025497473203 | accuracy: 0.8137019230769231 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.435496775167329 | accuracy: 0.8125 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4246625860532125 | accuracy: 0.81875 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.42324576899409294 | accuracy: 0.8212890625 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.43443749231450696 | accuracy: 0.8180147058823529 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4304296059740914 | accuracy: 0.8185763888888888 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.42906473028032405 | accuracy: 0.8199013157894737 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4253483384847641 | accuracy: 0.82109375 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4251511962640853 | accuracy: 0.8221726190476191 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.420655066316778 | accuracy: 0.8238636363636364 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.42336932861286664 | accuracy: 0.8213315217391305 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4238634916643302 | accuracy: 0.8216145833333334 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.42794236063957214 | accuracy: 0.818125 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4211007528580152 | accuracy: 0.8209134615384616 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4196130567126804 | accuracy: 0.8229166666666666 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.41561086795159746 | accuracy: 0.8247767857142857 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4176782904000118 | accuracy: 0.8243534482758621 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4186357935269674 | accuracy: 0.8234375 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4136852256713375 | accuracy: 0.8256048387096774 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.40814662352204323 | accuracy: 0.828125 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4064371080109567 | accuracy: 0.8295454545454546 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.41523966719122496 | accuracy: 0.8267463235294118 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.41418109110423496 | accuracy: 0.8258928571428571 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.41034606844186783 | accuracy: 0.8276909722222222 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.41220360269417633 | accuracy: 0.8277027027027027 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4123475182997553 | accuracy: 0.8264802631578947 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4107851049838922 | accuracy: 0.8269230769230769 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.41346936821937563 | accuracy: 0.824609375 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.41587593788053934 | accuracy: 0.8227896341463414 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4136567179645811 | accuracy: 0.8240327380952381 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4135152080724406 | accuracy: 0.8234011627906976 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.41539225524122064 | accuracy: 0.8217329545454546 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4185671223534478 | accuracy: 0.8203804347250196 \n",
      "Epoch 12 | Step 4434 | loss: 0.21105650067329407 | accuracy: 0.9375 \n",
      "Epoch 12 | Step 4435 | loss: 0.28602170944213867 | accuracy: 0.890625 \n",
      "Epoch 12 | Step 4436 | loss: 0.25652273495992023 | accuracy: 0.90625 \n",
      "Epoch 12 | Step 4437 | loss: 0.2573467344045639 | accuracy: 0.90625 \n",
      "Epoch 12 | Step 4438 | loss: 0.2560663938522339 | accuracy: 0.903125 \n",
      "Epoch 12 | Step 4439 | loss: 0.2734133203824361 | accuracy: 0.890625 \n",
      "Epoch 12 | Step 4440 | loss: 0.27371852312769207 | accuracy: 0.8928571428571429 \n",
      "Epoch 12 | Step 4441 | loss: 0.2865511029958725 | accuracy: 0.890625 \n",
      "Epoch 12 | Step 4442 | loss: 0.28045811586909825 | accuracy: 0.8940972222222222 \n",
      "Epoch 12 | Step 4443 | loss: 0.294332480430603 | accuracy: 0.8828125 \n",
      "Epoch 12 | Step 4444 | loss: 0.29321211034601385 | accuracy: 0.8806818181818182 \n",
      "Epoch 12 | Step 4445 | loss: 0.3011577179034551 | accuracy: 0.87109375 \n",
      "Epoch 12 | Step 4446 | loss: 0.2933898659852835 | accuracy: 0.8762019230769231 \n",
      "Epoch 12 | Step 4447 | loss: 0.2960021878991808 | accuracy: 0.8772321428571429 \n",
      "Epoch 12 | Step 4448 | loss: 0.2894048899412155 | accuracy: 0.8822916666666667 \n",
      "Epoch 12 | Step 4449 | loss: 0.2790006217546761 | accuracy: 0.8857421875 \n",
      "Epoch 12 | Step 4450 | loss: 0.2763828972683233 | accuracy: 0.8869485294117647 \n",
      "Epoch 12 | Step 4451 | loss: 0.2764679396318065 | accuracy: 0.8862847222222222 \n",
      "Epoch 12 | Step 4452 | loss: 0.2734407904116731 | accuracy: 0.8881578947368421 \n",
      "Epoch 12 | Step 4453 | loss: 0.27526517026126385 | accuracy: 0.8890625 \n",
      "Epoch 12 | Step 4454 | loss: 0.2755325830408505 | accuracy: 0.8876488095238095 \n",
      "Epoch 12 | Step 4455 | loss: 0.27543483911590144 | accuracy: 0.8884943181818182 \n",
      "Epoch 12 | Step 4456 | loss: 0.2716300652726837 | accuracy: 0.8899456521739131 \n",
      "Epoch 12 | Step 4457 | loss: 0.2676025750115514 | accuracy: 0.8919270833333334 \n",
      "Epoch 12 | Step 4458 | loss: 0.2648321804404259 | accuracy: 0.8925 \n",
      "Epoch 12 | Step 4459 | loss: 0.26493118330836296 | accuracy: 0.8918269230769231 \n",
      "Epoch 12 | Step 4460 | loss: 0.2654417816687513 | accuracy: 0.8929398148148148 \n",
      "Epoch 12 | Step 4461 | loss: 0.26010473711150034 | accuracy: 0.8962053571428571 \n",
      "Epoch 12 | Step 4462 | loss: 0.25844692464532526 | accuracy: 0.8960129310344828 \n",
      "Epoch 12 | Step 4463 | loss: 0.25886836349964143 | accuracy: 0.8958333333333334 \n",
      "Epoch 12 | Step 4464 | loss: 0.25917623696788666 | accuracy: 0.8961693548387096 \n",
      "Epoch 12 | Step 4465 | loss: 0.2601541122421622 | accuracy: 0.896484375 \n",
      "Epoch 12 | Step 4466 | loss: 0.2650800356359193 | accuracy: 0.8953598484848485 \n",
      "Epoch 12 | Step 4467 | loss: 0.26597105930833254 | accuracy: 0.8961397058823529 \n",
      "Epoch 12 | Step 4468 | loss: 0.2656779382910047 | accuracy: 0.8964285714285715 \n",
      "Epoch 12 | Step 4469 | loss: 0.2683912706043985 | accuracy: 0.8953993055555556 \n",
      "Epoch 12 | Step 4470 | loss: 0.26599210822904434 | accuracy: 0.8965371621621622 \n",
      "Epoch 12 | Step 4471 | loss: 0.2650196528748462 | accuracy: 0.8967927631578947 \n",
      "Epoch 12 | Step 4472 | loss: 0.2634974485024428 | accuracy: 0.8982371794871795 \n",
      "Epoch 12 | Step 4473 | loss: 0.2629159327596426 | accuracy: 0.898828125 \n",
      "Epoch 12 | Step 4474 | loss: 0.26313828440701087 | accuracy: 0.8990091463414634 \n",
      "Epoch 12 | Step 4475 | loss: 0.2627170671309743 | accuracy: 0.8995535714285714 \n",
      "Epoch 12 | Step 4476 | loss: 0.26080389182234914 | accuracy: 0.9004360465116279 \n",
      "Epoch 12 | Step 4477 | loss: 0.26003182781013573 | accuracy: 0.9002130681818182 \n",
      "Epoch 12 | Step 4478 | loss: 0.26214171548684434 | accuracy: 0.8996527777777777 \n",
      "Epoch 12 | Step 4479 | loss: 0.2619402146209841 | accuracy: 0.8991168478260869 \n",
      "Epoch 12 | Step 4480 | loss: 0.2610573131353297 | accuracy: 0.8992686170212766 \n",
      "Epoch 12 | Step 4481 | loss: 0.262749210310479 | accuracy: 0.8984375 \n",
      "Epoch 12 | Step 4482 | loss: 0.26047886664770087 | accuracy: 0.8995535714285714 \n",
      "Epoch 12 | Step 4483 | loss: 0.26134120136499406 | accuracy: 0.899375 \n",
      "Epoch 12 | Step 4484 | loss: 0.2637125542935203 | accuracy: 0.8985906862745098 \n",
      "Epoch 12 | Step 4485 | loss: 0.2662334083937682 | accuracy: 0.8972355769230769 \n",
      "Epoch 12 | Step 4486 | loss: 0.2648579981529488 | accuracy: 0.8974056603773585 \n",
      "Epoch 12 | Step 4487 | loss: 0.264241349917871 | accuracy: 0.8975694444444444 \n",
      "Epoch 12 | Step 4488 | loss: 0.2637879382480275 | accuracy: 0.8982954545454546 \n",
      "Epoch 12 | Step 4489 | loss: 0.26544670015573507 | accuracy: 0.8981584821428571 \n",
      "Epoch 12 | Step 4490 | loss: 0.26461811546693775 | accuracy: 0.8983004385964912 \n",
      "Epoch 12 | Step 4491 | loss: 0.2659557451461924 | accuracy: 0.8973599137931034 \n",
      "Epoch 12 | Step 4492 | loss: 0.26598025328021946 | accuracy: 0.8980402542372882 \n",
      "Epoch 12 | Step 4493 | loss: 0.2677867258588474 | accuracy: 0.8971354166666666 \n",
      "Epoch 12 | Step 4494 | loss: 0.26786299123138685 | accuracy: 0.8965163934426229 \n",
      "Epoch 12 | Step 4495 | loss: 0.2680619128288762 | accuracy: 0.8964213709677419 \n",
      "Epoch 12 | Step 4496 | loss: 0.2675583135514033 | accuracy: 0.8963293650793651 \n",
      "Epoch 12 | Step 4497 | loss: 0.2656177764292807 | accuracy: 0.897216796875 \n",
      "Epoch 12 | Step 4498 | loss: 0.26608467033276195 | accuracy: 0.8971153846153846 \n",
      "Epoch 12 | Step 4499 | loss: 0.2642298941359376 | accuracy: 0.8979640151515151 \n",
      "Epoch 12 | Step 4500 | loss: 0.26330715106494396 | accuracy: 0.898320895522388 \n",
      "Epoch 12 | Step 4501 | loss: 0.2631297194782426 | accuracy: 0.8984375 \n",
      "Epoch 12 | Step 4502 | loss: 0.26418548476868786 | accuracy: 0.8978713768115942 \n",
      "Epoch 12 | Step 4503 | loss: 0.2657343992165157 | accuracy: 0.8973214285714286 \n",
      "Epoch 12 | Step 4504 | loss: 0.26661408954942734 | accuracy: 0.8965669014084507 \n",
      "Epoch 12 | Step 4505 | loss: 0.265928031048841 | accuracy: 0.8967013888888888 \n",
      "Epoch 12 | Step 4506 | loss: 0.26685773611885233 | accuracy: 0.896404109589041 \n",
      "Epoch 12 | Step 4507 | loss: 0.2676892375221124 | accuracy: 0.8961148648648649 \n",
      "Epoch 12 | Step 4508 | loss: 0.26847937365372976 | accuracy: 0.895625 \n",
      "Epoch 12 | Step 4509 | loss: 0.26747508229393707 | accuracy: 0.895764802631579 \n",
      "Epoch 12 | Step 4510 | loss: 0.26823682483140526 | accuracy: 0.895698051948052 \n",
      "Epoch 12 | Step 4511 | loss: 0.2674471886876302 | accuracy: 0.8960336538461539 \n",
      "Epoch 12 | Step 4512 | loss: 0.2666545574423633 | accuracy: 0.8959651898734177 \n",
      "Epoch 12 | Step 4513 | loss: 0.2661822225898504 | accuracy: 0.89609375 \n",
      "Epoch 12 | Step 4514 | loss: 0.267781897827431 | accuracy: 0.8956404320987654 \n",
      "Epoch 12 | Step 4515 | loss: 0.2668230330071798 | accuracy: 0.8963414634146342 \n",
      "Epoch 12 | Step 4516 | loss: 0.2672740142029452 | accuracy: 0.8962725903614458 \n",
      "Epoch 12 | Step 4517 | loss: 0.2673103529072943 | accuracy: 0.8963913690476191 \n",
      "Epoch 12 | Step 4518 | loss: 0.26772637717864095 | accuracy: 0.8966911764705883 \n",
      "Epoch 12 | Step 4519 | loss: 0.2665727155846219 | accuracy: 0.896984011627907 \n",
      "Epoch 12 | Step 4520 | loss: 0.2662960061396676 | accuracy: 0.8972701149425287 \n",
      "Epoch 12 | Step 4521 | loss: 0.26659468493678357 | accuracy: 0.8973721590909091 \n",
      "Epoch 12 | Step 4522 | loss: 0.2666455801953091 | accuracy: 0.8971207865168539 \n",
      "Epoch 12 | Step 4523 | loss: 0.26710039112302997 | accuracy: 0.896875 \n",
      "Epoch 12 | Step 4524 | loss: 0.2671043463460692 | accuracy: 0.8968063186813187 \n",
      "Epoch 12 | Step 4525 | loss: 0.26897175059370376 | accuracy: 0.8962296195652174 \n",
      "Epoch 12 | Step 4526 | loss: 0.27106554469754623 | accuracy: 0.8953293010752689 \n",
      "Epoch 12 | Step 4527 | loss: 0.2699884493300256 | accuracy: 0.8959441489361702 \n",
      "Epoch 12 | Step 4528 | loss: 0.26920488586551267 | accuracy: 0.8962171052631579 \n",
      "Epoch 12 | Step 4529 | loss: 0.26834506075829273 | accuracy: 0.8963216145833334 \n",
      "Epoch 12 | Step 4530 | loss: 0.26769956792752775 | accuracy: 0.8967461340206185 \n",
      "Epoch 12 | Step 4531 | loss: 0.2688380759589527 | accuracy: 0.8960459183673469 \n",
      "Epoch 12 | Step 4532 | loss: 0.2681349007168203 | accuracy: 0.8963068181818182 \n",
      "Epoch 12 | Step 4533 | loss: 0.2686782863736154 | accuracy: 0.8959375 \n",
      "Epoch 12 | Step 4534 | loss: 0.2687828080488905 | accuracy: 0.895884900990099 \n",
      "Epoch 12 | Step 4535 | loss: 0.26904168403616147 | accuracy: 0.8955269607843137 \n",
      "Epoch 12 | Step 4536 | loss: 0.2689520305800207 | accuracy: 0.8954793689320388 \n",
      "Epoch 12 | Step 4537 | loss: 0.2691180410866555 | accuracy: 0.8955829326923077 \n",
      "Epoch 12 | Step 4538 | loss: 0.26983644706862325 | accuracy: 0.8952380952380953 \n",
      "Epoch 12 | Step 4539 | loss: 0.2694137620757212 | accuracy: 0.8953419811320755 \n",
      "Epoch 12 | Step 4540 | loss: 0.26945684933773834 | accuracy: 0.8952978971962616 \n",
      "Epoch 12 | Step 4541 | loss: 0.27033035470931627 | accuracy: 0.8949652777777778 \n",
      "Epoch 12 | Step 4542 | loss: 0.269323752424039 | accuracy: 0.8954988532110092 \n",
      "Epoch 12 | Step 4543 | loss: 0.26918182278221314 | accuracy: 0.8954545454545455 \n",
      "Epoch 12 | Step 4544 | loss: 0.27009595850029516 | accuracy: 0.8951295045045045 \n",
      "Epoch 12 | Step 4545 | loss: 0.2710033762933953 | accuracy: 0.8948102678571429 \n",
      "Epoch 12 | Step 4546 | loss: 0.2707394451166677 | accuracy: 0.8949115044247787 \n",
      "Epoch 12 | Step 4547 | loss: 0.27056655235457844 | accuracy: 0.8947368421052632 \n",
      "Epoch 12 | Step 4548 | loss: 0.26996252083260086 | accuracy: 0.8948369565217391 \n",
      "Epoch 12 | Step 4549 | loss: 0.2693177622197004 | accuracy: 0.8953394396551724 \n",
      "Epoch 12 | Step 4550 | loss: 0.26892710254233115 | accuracy: 0.8955662393162394 \n",
      "Epoch 12 | Step 4551 | loss: 0.2692861464821687 | accuracy: 0.8949947033898306 \n",
      "Epoch 12 | Step 4552 | loss: 0.2698264837014576 | accuracy: 0.8944327731092437 \n",
      "Epoch 12 | Step 4553 | loss: 0.2699353529761236 | accuracy: 0.894140625 \n",
      "Epoch 12 | Step 4554 | loss: 0.2691266364302518 | accuracy: 0.8946280991735537 \n",
      "Epoch 12 | Step 4555 | loss: 0.2698751648918528 | accuracy: 0.8942110655737705 \n",
      "Epoch 12 | Step 4556 | loss: 0.26972070021357974 | accuracy: 0.8940548780487805 \n",
      "Epoch 12 | Step 4557 | loss: 0.27067966975512053 | accuracy: 0.8936491935483871 \n",
      "Epoch 12 | Step 4558 | loss: 0.27058454298973095 | accuracy: 0.893625 \n",
      "Epoch 12 | Step 4559 | loss: 0.26983671316078744 | accuracy: 0.8939732142857143 \n",
      "Epoch 12 | Step 4560 | loss: 0.27039113406121273 | accuracy: 0.8933316929133859 \n",
      "Epoch 12 | Step 4561 | loss: 0.26994496292900305 | accuracy: 0.8936767578125 \n",
      "Epoch 12 | Step 4562 | loss: 0.26987867172836344 | accuracy: 0.893531976744186 \n",
      "Epoch 12 | Step 4563 | loss: 0.2701624965438477 | accuracy: 0.893389423076923 \n",
      "Epoch 12 | Step 4564 | loss: 0.2704434803196493 | accuracy: 0.8931297709923665 \n",
      "Epoch 12 | Step 4565 | loss: 0.27032504377491556 | accuracy: 0.8933475378787878 \n",
      "Epoch 12 | Step 4566 | loss: 0.2697578304468242 | accuracy: 0.8936795112781954 \n",
      "Epoch 12 | Step 4567 | loss: 0.26908279432734455 | accuracy: 0.8938899253731343 \n",
      "Epoch 12 | Step 4568 | loss: 0.26937759441358083 | accuracy: 0.8938657407407408 \n",
      "Epoch 12 | Step 4569 | loss: 0.26968002308379213 | accuracy: 0.8940716911764706 \n",
      "Epoch 12 | Step 4570 | loss: 0.27050183952724854 | accuracy: 0.8935903284671532 \n",
      "Epoch 12 | Step 4571 | loss: 0.27028069299632235 | accuracy: 0.8935688405797102 \n",
      "Epoch 12 | Step 4572 | loss: 0.27071591043215015 | accuracy: 0.8934352517985612 \n",
      "Epoch 12 | Step 4573 | loss: 0.27063123913747933 | accuracy: 0.8934151785714287 \n",
      "Epoch 12 | Step 4574 | loss: 0.2706978639178243 | accuracy: 0.8931737588652483 \n",
      "Epoch 12 | Step 4575 | loss: 0.27030909586120666 | accuracy: 0.893155809859155 \n",
      "Epoch 12 | Step 4576 | loss: 0.26977422791761124 | accuracy: 0.8934659090909092 \n",
      "Epoch 12 | Step 4577 | loss: 0.26970833705531233 | accuracy: 0.8933376736111112 \n",
      "Epoch 12 | Step 4578 | loss: 0.2693657170081961 | accuracy: 0.8933189655172413 \n",
      "Epoch 12 | Step 4579 | loss: 0.2695686408918198 | accuracy: 0.893193493150685 \n",
      "Epoch 12 | Step 4580 | loss: 0.26940844395533714 | accuracy: 0.8933886054421769 \n",
      "Epoch 12 | Step 4581 | loss: 0.2694275636930724 | accuracy: 0.8932643581081081 \n",
      "Epoch 12 | Step 4582 | loss: 0.2695585247254212 | accuracy: 0.893246644295302 \n",
      "Epoch 12 | Step 4583 | loss: 0.26875478784243273 | accuracy: 0.8935416666666667 \n",
      "Epoch 12 | Step 4584 | loss: 0.2689261748301273 | accuracy: 0.8935223509933775 \n",
      "Epoch 12 | Step 4585 | loss: 0.26938644247619736 | accuracy: 0.8934004934210527 \n",
      "Epoch 12 | Step 4586 | loss: 0.26993469046611424 | accuracy: 0.8933823529411765 \n",
      "Epoch 12 | Step 4587 | loss: 0.2691821275012835 | accuracy: 0.8936688311688312 \n",
      "Epoch 12 | Step 4588 | loss: 0.26852369366153606 | accuracy: 0.8940524193548387 \n",
      "Epoch 12 | Step 4589 | loss: 0.2676429670208541 | accuracy: 0.8944310897435898 \n",
      "Epoch 12 | Step 4590 | loss: 0.2675063132670276 | accuracy: 0.8945063694267515 \n",
      "Epoch 12 | Step 4591 | loss: 0.2671638978055762 | accuracy: 0.8946795886075949 \n",
      "Epoch 12 | Step 4592 | loss: 0.26716290461192355 | accuracy: 0.8946540880503144 \n",
      "Epoch 12 | Step 4593 | loss: 0.2669654101133348 | accuracy: 0.8947265625 \n",
      "Epoch 12 | Step 4594 | loss: 0.26656330603620293 | accuracy: 0.8947981366459627 \n",
      "Epoch 12 | Step 4595 | loss: 0.2667125804740707 | accuracy: 0.8947723765432098 \n",
      "Epoch 12 | Step 4596 | loss: 0.2658427507142349 | accuracy: 0.8953220858895705 \n",
      "Epoch 12 | Step 4597 | loss: 0.2654960523927358 | accuracy: 0.8953887195121951 \n",
      "Epoch 12 | Step 4598 | loss: 0.2653732398694213 | accuracy: 0.8952651515151515 \n",
      "Epoch 12 | Step 4599 | loss: 0.26645385945238276 | accuracy: 0.8949548192771084 \n",
      "Epoch 12 | Step 4600 | loss: 0.265805000985811 | accuracy: 0.8953031437125748 \n",
      "Epoch 12 | Step 4601 | loss: 0.26544540983048237 | accuracy: 0.8950892857142857 \n",
      "Epoch 12 | Step 4602 | loss: 0.2668862544308754 | accuracy: 0.8946005917159763 \n",
      "Epoch 12 | Step 4603 | loss: 0.26678083525861024 | accuracy: 0.8947610294117647 \n",
      "Epoch 12 | Step 4604 | loss: 0.2672307090888248 | accuracy: 0.8944627192982456 \n",
      "Epoch 12 | Step 4605 | loss: 0.2674477050557388 | accuracy: 0.8943495639534884 \n",
      "Epoch 12 | Step 4606 | loss: 0.2663181681681232 | accuracy: 0.8949602601156069 \n",
      "Epoch 12 | Step 4607 | loss: 0.26644298699737984 | accuracy: 0.8951149425287356 \n",
      "Epoch 12 | Step 4608 | loss: 0.26617372393608113 | accuracy: 0.8951785714285714 \n",
      "Epoch 12 | Step 4609 | loss: 0.26592605459419183 | accuracy: 0.8954190340909091 \n",
      "Epoch 12 | Step 4610 | loss: 0.26621740366106 | accuracy: 0.8953919491525424 \n",
      "Epoch 12 | Step 4611 | loss: 0.2661549187778089 | accuracy: 0.8954529494382022 \n",
      "Epoch 12 | Step 4612 | loss: 0.26613185808645295 | accuracy: 0.8956005586592178 \n",
      "Epoch 12 | Step 4613 | loss: 0.266395719183816 | accuracy: 0.8953125 \n",
      "Epoch 12 | Step 4614 | loss: 0.2659796543048892 | accuracy: 0.8953729281767956 \n",
      "Epoch 12 | Step 4615 | loss: 0.2655202273156618 | accuracy: 0.8956902472527473 \n",
      "Epoch 12 | Step 4616 | loss: 0.26506858111404996 | accuracy: 0.896089480874317 \n",
      "Epoch 12 | Step 4617 | loss: 0.2652292655699928 | accuracy: 0.8961447010869565 \n",
      "Epoch 12 | Step 4618 | loss: 0.2654932821924624 | accuracy: 0.8958614864864864 \n",
      "Epoch 12 | Step 4619 | loss: 0.2655259478957424 | accuracy: 0.8957493279569892 \n",
      "Epoch 12 | Step 4620 | loss: 0.26562436530615574 | accuracy: 0.8956383689839572 \n",
      "Epoch 12 | Step 4621 | loss: 0.26562761063588447 | accuracy: 0.8958610372340425 \n",
      "Epoch 12 | Step 4622 | loss: 0.2652435519550214 | accuracy: 0.8960813492063492 \n",
      "Epoch 12 | Step 4623 | loss: 0.2653343399104321 | accuracy: 0.8959703947368421 \n",
      "Epoch 12 | Step 4624 | loss: 0.26565050743325236 | accuracy: 0.8959424083769634 \n",
      "Epoch 12 | Step 4625 | loss: 0.2659000559554748 | accuracy: 0.8958333333333334 \n",
      "Epoch 12 | Step 4626 | loss: 0.266362389366244 | accuracy: 0.8955634715025906 \n",
      "Epoch 12 | Step 4627 | loss: 0.2659187006581692 | accuracy: 0.8957796391752577 \n",
      "Epoch 12 | Step 4628 | loss: 0.26621791323026045 | accuracy: 0.8954326923076923 \n",
      "Epoch 12 | Step 4629 | loss: 0.266271549676146 | accuracy: 0.8954878826530612 \n",
      "Epoch 12 | Step 4630 | loss: 0.26651006952155076 | accuracy: 0.8953045685279187 \n",
      "Epoch 12 | Step 4631 | loss: 0.2668645506856419 | accuracy: 0.8951231060606061 \n",
      "Epoch 12 | Step 4632 | loss: 0.2673016711695112 | accuracy: 0.8949434673366834 \n",
      "Epoch 12 | Step 4633 | loss: 0.2671138661354782 | accuracy: 0.895078125 \n",
      "Epoch 12 | Step 4634 | loss: 0.2675458491589895 | accuracy: 0.8947450248756219 \n",
      "Epoch 12 | Step 4635 | loss: 0.26780880640934035 | accuracy: 0.8946472772277227 \n",
      "Epoch 12 | Step 4636 | loss: 0.2674495627727417 | accuracy: 0.8948583743842364 \n",
      "Epoch 12 | Step 4637 | loss: 0.2674160756024662 | accuracy: 0.8948376225490197 \n",
      "Epoch 12 | Step 4638 | loss: 0.2676512626613061 | accuracy: 0.8946646341463415 \n",
      "Epoch 12 | Step 4639 | loss: 0.2676362176832646 | accuracy: 0.8947208737864077 \n",
      "Epoch 12 | Step 4640 | loss: 0.26734468470449063 | accuracy: 0.8948520531400966 \n",
      "Epoch 12 | Step 4641 | loss: 0.2671327139609138 | accuracy: 0.8949068509615384 \n",
      "Epoch 12 | Step 4642 | loss: 0.2672154112010484 | accuracy: 0.8948863636363636 \n",
      "Epoch 12 | Step 4643 | loss: 0.26671827414206123 | accuracy: 0.8951636904761905 \n",
      "Epoch 12 | Step 4644 | loss: 0.26661861140581133 | accuracy: 0.8951421800947867 \n",
      "Epoch 12 | Step 4645 | loss: 0.26691285211522653 | accuracy: 0.8950471698113207 \n",
      "Epoch 12 | Step 4646 | loss: 0.26638881526362757 | accuracy: 0.8953931924882629 \n",
      "Epoch 12 | Step 4647 | loss: 0.2662674725473487 | accuracy: 0.8954439252336449 \n",
      "Epoch 12 | Step 4648 | loss: 0.2666862726904628 | accuracy: 0.8953488372093024 \n",
      "Epoch 12 | Step 4649 | loss: 0.2673512627543126 | accuracy: 0.8951099537037037 \n",
      "Epoch 12 | Step 4650 | loss: 0.26786569372025537 | accuracy: 0.8949452764976958 \n",
      "Epoch 12 | Step 4651 | loss: 0.2675779563024507 | accuracy: 0.8950688073394495 \n",
      "Epoch 12 | Step 4652 | loss: 0.2674482664152915 | accuracy: 0.8950485159817352 \n",
      "Epoch 12 | Step 4653 | loss: 0.26751765480095724 | accuracy: 0.8949573863636363 \n",
      "Epoch 12 | Step 4654 | loss: 0.26709216138626146 | accuracy: 0.895079185520362 \n",
      "Epoch 12 | Step 4655 | loss: 0.2667083102572075 | accuracy: 0.8953406531531531 \n",
      "Epoch 12 | Step 4656 | loss: 0.2668853332643555 | accuracy: 0.8953195067264574 \n",
      "Epoch 12 | Step 4657 | loss: 0.2667895685216149 | accuracy: 0.8955078125 \n",
      "Epoch 12 | Step 4658 | loss: 0.26707785665988953 | accuracy: 0.8954861111111111 \n",
      "Epoch 12 | Step 4659 | loss: 0.26736482496546465 | accuracy: 0.8953263274336283 \n",
      "Epoch 12 | Step 4660 | loss: 0.26739137819947684 | accuracy: 0.8953744493392071 \n",
      "Epoch 12 | Step 4661 | loss: 0.2673848728208169 | accuracy: 0.8952850877192983 \n",
      "Epoch 12 | Step 4662 | loss: 0.26688917358629605 | accuracy: 0.8954694323144105 \n",
      "Epoch 12 | Step 4663 | loss: 0.26665873812592583 | accuracy: 0.8955842391304348 \n",
      "Epoch 12 | Step 4664 | loss: 0.26703914677425933 | accuracy: 0.8954274891774892 \n",
      "Epoch 12 | Step 4665 | loss: 0.266587844889226 | accuracy: 0.8956088362068966 \n",
      "Epoch 12 | Step 4666 | loss: 0.26660728601682887 | accuracy: 0.8953862660944206 \n",
      "Epoch 12 | Step 4667 | loss: 0.26678273610324976 | accuracy: 0.8953659188034188 \n",
      "Epoch 12 | Step 4668 | loss: 0.2665385028783315 | accuracy: 0.8955452127659574 \n",
      "Epoch 12 | Step 4669 | loss: 0.2665677506918628 | accuracy: 0.8957229872881356 \n",
      "Epoch 12 | Step 4670 | loss: 0.2669847349200071 | accuracy: 0.8956355485232067 \n",
      "Epoch 12 | Step 4671 | loss: 0.2672991754502813 | accuracy: 0.895483193277311 \n",
      "Epoch 12 | Step 4672 | loss: 0.26691174351271263 | accuracy: 0.8955936192468619 \n",
      "Epoch 12 | Step 4673 | loss: 0.2665457493936026 | accuracy: 0.8957682291666667 \n",
      "Epoch 12 | Step 4674 | loss: 0.26687214378252105 | accuracy: 0.8955523858921162 \n",
      "Epoch 12 | Step 4675 | loss: 0.2669597638170585 | accuracy: 0.895467458677686 \n",
      "Epoch 12 | Step 4676 | loss: 0.2669249855809745 | accuracy: 0.8955118312757202 \n",
      "Epoch 12 | Step 4677 | loss: 0.2663132729711106 | accuracy: 0.8957479508196722 \n",
      "Epoch 12 | Step 4678 | loss: 0.2658452037645849 | accuracy: 0.8959183673469387 \n",
      "Epoch 12 | Step 4679 | loss: 0.26557041316982244 | accuracy: 0.8959603658536586 \n",
      "Epoch 12 | Step 4680 | loss: 0.26522923565586604 | accuracy: 0.8961285425101214 \n",
      "Epoch 12 | Step 4681 | loss: 0.26546593298835175 | accuracy: 0.8960433467741935 \n",
      "Epoch 12 | Step 4682 | loss: 0.26543097132181104 | accuracy: 0.8961470883534136 \n",
      "Epoch 12 | Step 4683 | loss: 0.2651912623047832 | accuracy: 0.8963125 \n",
      "Epoch 12 | Step 4684 | loss: 0.26535503696872925 | accuracy: 0.8962275896414342 \n",
      "Epoch 12 | Step 4685 | loss: 0.26551126339842435 | accuracy: 0.8960813492063492 \n",
      "Epoch 12 | Step 4686 | loss: 0.26551959855047647 | accuracy: 0.895998023715415 \n",
      "Epoch 12 | Step 4687 | loss: 0.26555477029929986 | accuracy: 0.8959153543307087 \n",
      "Epoch 12 | Step 4688 | loss: 0.2653057583406863 | accuracy: 0.8960784313725491 \n",
      "Epoch 12 | Step 4689 | loss: 0.2653066474013034 | accuracy: 0.89593505859375 \n",
      "Epoch 12 | Step 4690 | loss: 0.2652470119848329 | accuracy: 0.8959751945525292 \n",
      "Epoch 12 | Step 4691 | loss: 0.26536840957033575 | accuracy: 0.8958938953488372 \n",
      "Epoch 12 | Step 4692 | loss: 0.2652811886721139 | accuracy: 0.8958132239382239 \n",
      "Epoch 12 | Step 4693 | loss: 0.2652343904742831 | accuracy: 0.8958533653846154 \n",
      "Epoch 12 | Step 4694 | loss: 0.26506959604120833 | accuracy: 0.8960129310344828 \n",
      "Epoch 12 | Step 4695 | loss: 0.2655113358761521 | accuracy: 0.8956345419847328 \n",
      "Epoch 12 | Step 4696 | loss: 0.26539377040962786 | accuracy: 0.8956749049429658 \n",
      "Epoch 12 | Step 4697 | loss: 0.2653044509616768 | accuracy: 0.8956557765151515 \n",
      "Epoch 12 | Step 4698 | loss: 0.2651219026097715 | accuracy: 0.8956367924528302 \n",
      "Epoch 12 | Step 4699 | loss: 0.2649940264628349 | accuracy: 0.8957354323308271 \n",
      "Epoch 12 | Step 4700 | loss: 0.2647400186972675 | accuracy: 0.8958333333333334 \n",
      "Epoch 12 | Step 4701 | loss: 0.2649422886211484 | accuracy: 0.8956389925373134 \n",
      "Epoch 12 | Step 4702 | loss: 0.2648464491708574 | accuracy: 0.8957365241635687 \n",
      "Epoch 12 | Step 4703 | loss: 0.2650159639892758 | accuracy: 0.8957175925925925 \n",
      "Epoch 12 | Step 4704 | loss: 0.2650123376577986 | accuracy: 0.8955834870848708 \n",
      "Epoch 12 | Step 4705 | loss: 0.26493199333986844 | accuracy: 0.8956801470588234 \n",
      "Epoch 12 | Step 4706 | loss: 0.26493409352424846 | accuracy: 0.8957188644688643 \n",
      "Epoch 12 | Step 4707 | loss: 0.2650943785688306 | accuracy: 0.895814324817518 \n",
      "Epoch 12 | Step 4708 | loss: 0.2648651092702695 | accuracy: 0.8958522727272725 \n",
      "Epoch 12 | Step 4709 | loss: 0.26519252845774555 | accuracy: 0.8956068840579708 \n",
      "Epoch 12 | Step 4710 | loss: 0.2649361038251047 | accuracy: 0.8957017148014439 \n",
      "Epoch 12 | Step 4711 | loss: 0.2647298764196234 | accuracy: 0.8957958633093525 \n",
      "Epoch 12 | Step 4712 | loss: 0.26455310868319676 | accuracy: 0.8958333333333333 \n",
      "Epoch 12 | Step 4713 | loss: 0.26460255166249647 | accuracy: 0.8957031249999999 \n",
      "Epoch 12 | Step 4714 | loss: 0.26448821528314304 | accuracy: 0.895851868327402 \n",
      "Epoch 12 | Step 4715 | loss: 0.26409672633975984 | accuracy: 0.8959441489361701 \n",
      "Epoch 12 | Step 4716 | loss: 0.26398566096705206 | accuracy: 0.8959805653710247 \n",
      "Epoch 12 | Step 4717 | loss: 0.26360779628157643 | accuracy: 0.896181778169014 \n",
      "Epoch 12 | Step 4718 | loss: 0.2636005016272531 | accuracy: 0.8960526315789473 \n",
      "Epoch 12 | Step 4719 | loss: 0.2631372302458006 | accuracy: 0.8961975524475524 \n",
      "Epoch 12 | Step 4720 | loss: 0.2631153275846192 | accuracy: 0.8962325783972126 \n",
      "Epoch 12 | Step 4721 | loss: 0.2626922112993071 | accuracy: 0.8964301215277778 \n",
      "Epoch 12 | Step 4722 | loss: 0.263288042949558 | accuracy: 0.8963559688581315 \n",
      "Epoch 12 | Step 4723 | loss: 0.26321577959019593 | accuracy: 0.8964439655172414 \n",
      "Epoch 12 | Step 4724 | loss: 0.2636037695756076 | accuracy: 0.8962091924398625 \n",
      "Epoch 12 | Step 4725 | loss: 0.26347250705712494 | accuracy: 0.8963505993150684 \n",
      "Epoch 12 | Step 4726 | loss: 0.2634686816471025 | accuracy: 0.896384385665529 \n",
      "Epoch 12 | Step 4727 | loss: 0.26357438572410047 | accuracy: 0.8962585034013606 \n",
      "Epoch 12 | Step 4728 | loss: 0.2633625841241775 | accuracy: 0.8963453389830508 \n",
      "Epoch 12 | Step 4729 | loss: 0.2634027163825328 | accuracy: 0.8963788006756757 \n",
      "Epoch 12 | Step 4730 | loss: 0.2633618819292149 | accuracy: 0.8964120370370371 \n",
      "Epoch 12 | Step 4731 | loss: 0.2632667603308726 | accuracy: 0.8965499161073825 \n",
      "Epoch 12 | Step 4732 | loss: 0.26309481681788677 | accuracy: 0.896686872909699 \n",
      "Epoch 12 | Step 4733 | loss: 0.2627720675369107 | accuracy: 0.896875 \n",
      "Epoch 12 | Step 4734 | loss: 0.26317377101345346 | accuracy: 0.8966465946843853 \n",
      "Epoch 12 | Step 4735 | loss: 0.26290023766013987 | accuracy: 0.8968336092715232 \n",
      "Epoch 12 | Step 4736 | loss: 0.2627309118658799 | accuracy: 0.8969678217821783 \n",
      "Epoch 12 | Step 4737 | loss: 0.2628274733984944 | accuracy: 0.8968441611842105 \n",
      "Epoch 12 | Step 4738 | loss: 0.26263732563276787 | accuracy: 0.8969262295081967 \n",
      "Epoch 12 | Step 4739 | loss: 0.26270577287167535 | accuracy: 0.8969056372549019 \n",
      "Epoch 12 | Step 4740 | loss: 0.2635007216701293 | accuracy: 0.8966815960912052 \n",
      "Epoch 12 | Step 4741 | loss: 0.2632533100421555 | accuracy: 0.8968141233766234 \n",
      "Epoch 12 | Step 4742 | loss: 0.26298547615704054 | accuracy: 0.8968446601941747 \n",
      "Epoch 12 | Step 4743 | loss: 0.2630842854419065 | accuracy: 0.8968245967741936 \n",
      "Epoch 12 | Step 4744 | loss: 0.2631093018787086 | accuracy: 0.8970056270096463 \n",
      "Epoch 12 | Step 4745 | loss: 0.2631569362890265 | accuracy: 0.8969851762820513 \n",
      "Epoch 12 | Step 4746 | loss: 0.26293607770254085 | accuracy: 0.8971645367412141 \n",
      "Epoch 12 | Step 4747 | loss: 0.26328243851471883 | accuracy: 0.8970441878980892 \n",
      "Epoch 12 | Step 4748 | loss: 0.2638256005351508 | accuracy: 0.8969742063492063 \n",
      "Epoch 12 | Step 4749 | loss: 0.2636931638551666 | accuracy: 0.8970035601265823 \n",
      "Epoch 12 | Step 4750 | loss: 0.26345497680011254 | accuracy: 0.8971805993690851 \n",
      "Epoch 12 | Step 4751 | loss: 0.2636057107516057 | accuracy: 0.897061713836478 \n",
      "Epoch 12 | Step 4752 | loss: 0.2635393297317262 | accuracy: 0.8971884796238244 \n",
      "Epoch 12 | Step 4753 | loss: 0.2633278324268761 | accuracy: 0.897265625 \n",
      "Epoch 12 | Step 4754 | loss: 0.2633865574995679 | accuracy: 0.897196261682243 \n",
      "Epoch 12 | Step 4755 | loss: 0.26375117194578535 | accuracy: 0.8971758540372671 \n",
      "Epoch 12 | Step 4756 | loss: 0.26354915895513725 | accuracy: 0.8972523219814241 \n",
      "Epoch 12 | Step 4757 | loss: 0.2633152072444376 | accuracy: 0.8974247685185185 \n",
      "Epoch 12 | Step 4758 | loss: 0.2634243861528545 | accuracy: 0.8973076923076924 \n",
      "Epoch 12 | Step 4759 | loss: 0.26327046240034296 | accuracy: 0.8973830521472392 \n",
      "Epoch 12 | Step 4760 | loss: 0.26335698967679944 | accuracy: 0.8973146024464832 \n",
      "Epoch 12 | Step 4761 | loss: 0.2634017308492488 | accuracy: 0.8972942073170732 \n",
      "Epoch 12 | Step 4762 | loss: 0.2639193305672123 | accuracy: 0.8969414893617021 \n",
      "Epoch 12 | Step 4763 | loss: 0.26381849484010195 | accuracy: 0.8970170454545454 \n",
      "Epoch 12 | Step 4764 | loss: 0.26365123783713756 | accuracy: 0.8970449395770392 \n",
      "Epoch 12 | Step 4765 | loss: 0.2636400334626797 | accuracy: 0.8971197289156626 \n",
      "Epoch 12 | Step 4766 | loss: 0.26351870046005615 | accuracy: 0.8971471471471472 \n",
      "Epoch 12 | Step 4767 | loss: 0.2637602325506555 | accuracy: 0.8970340568862275 \n",
      "Epoch 12 | Step 4768 | loss: 0.26338730623473006 | accuracy: 0.8972481343283583 \n",
      "Epoch 12 | Step 4769 | loss: 0.26328252473225217 | accuracy: 0.8973214285714286 \n",
      "Epoch 12 | Step 4770 | loss: 0.26341273854500485 | accuracy: 0.8973015578635015 \n",
      "Epoch 12 | Step 4771 | loss: 0.26346689766857073 | accuracy: 0.8973742603550295 \n",
      "Epoch 12 | Step 4772 | loss: 0.2633514171328871 | accuracy: 0.8974004424778761 \n",
      "Epoch 12 | Step 4773 | loss: 0.26301369658287865 | accuracy: 0.8975183823529411 \n",
      "Epoch 12 | Step 4774 | loss: 0.2628314659392732 | accuracy: 0.8975898093841642 \n",
      "Epoch 12 | Step 4775 | loss: 0.26268924249891684 | accuracy: 0.8976151315789473 \n",
      "Epoch 12 | Step 4776 | loss: 0.2624014104246749 | accuracy: 0.8977314139941691 \n",
      "Epoch 12 | Step 4777 | loss: 0.26223218454004754 | accuracy: 0.8978015988372093 \n",
      "Epoch 12 | Step 4778 | loss: 0.2623130856648739 | accuracy: 0.8977355072463769 \n",
      "Epoch 12 | Step 4779 | loss: 0.2622598090957358 | accuracy: 0.8978504335260116 \n",
      "Epoch 12 | Step 4780 | loss: 0.26197921280730385 | accuracy: 0.8979646974063401 \n",
      "Epoch 12 | Step 4781 | loss: 0.2624906568263457 | accuracy: 0.897808908045977 \n",
      "Epoch 12 | Step 4782 | loss: 0.2624569582648813 | accuracy: 0.8977883237822349 \n",
      "Epoch 12 | Step 4783 | loss: 0.262376096248627 | accuracy: 0.8978571428571429 \n",
      "Epoch 12 | Step 4784 | loss: 0.2621695179375491 | accuracy: 0.8980146011396012 \n",
      "Epoch 12 | Step 4785 | loss: 0.26240827329456834 | accuracy: 0.8979048295454546 \n",
      "Epoch 12 | Step 4786 | loss: 0.26222210903005655 | accuracy: 0.8979284702549575 \n",
      "Epoch 12 | Step 4787 | loss: 0.2619942845513594 | accuracy: 0.8980402542372882 \n",
      "Epoch 12 | Step 4788 | loss: 0.26186603379081697 | accuracy: 0.8981073943661971 \n",
      "Epoch 12 | Step 4789 | loss: 0.2616884702963108 | accuracy: 0.8981741573033708 \n",
      "Epoch 12 | Step 4790 | loss: 0.26169137990608293 | accuracy: 0.8981530112044818 \n",
      "Epoch 12 | Step 4791 | loss: 0.2617287196676827 | accuracy: 0.8980010474860335 \n",
      "Epoch 12 | Step 4792 | loss: 0.2615077101669606 | accuracy: 0.8980675487465181 \n",
      "Epoch 12 | Step 4793 | loss: 0.26124728259940966 | accuracy: 0.8982204861111112 \n",
      "Epoch 12 | Step 4794 | loss: 0.26140075067569035 | accuracy: 0.8981128808864266 \n",
      "Epoch 12 | Step 4795 | loss: 0.26130468550637304 | accuracy: 0.8981785220994475 \n",
      "Epoch 12 | Step 4796 | loss: 0.26123141622576196 | accuracy: 0.8982438016528925 \n",
      "Epoch 12 | Step 4797 | loss: 0.26115595987373674 | accuracy: 0.898179945054945 \n",
      "Epoch 12 | Step 4798 | loss: 0.260879960941942 | accuracy: 0.8982876712328767 \n",
      "Epoch 12 | Step 4799 | loss: 0.2608015211553524 | accuracy: 0.8982667349726776 \n",
      "Epoch 12 | Step 4800 | loss: 0.2607272793145533 | accuracy: 0.8982884877384196 \n",
      "Epoch 12 | Step 4801 | loss: 0.2605085203667052 | accuracy: 0.8983101222826086 \n",
      "Epoch 12 | Step 4802 | loss: 0.26075133705526854 | accuracy: 0.8983316395663956 \n",
      "Epoch 12 | Step 4803 | loss: 0.2610746193576506 | accuracy: 0.8981418918918919 \n",
      "Epoch 12 | Step 4804 | loss: 0.26115297893629585 | accuracy: 0.8981637466307277 \n",
      "Epoch 12 | Step 4805 | loss: 0.26189490055204745 | accuracy: 0.8978074596774194 \n",
      "Epoch 12 | Step 4806 | loss: 0.2619599789460929 | accuracy: 0.8977463136729222 \n",
      "Epoch 12 | Step 4807 | loss: 0.26176211194080495 | accuracy: 0.8977690508021391 \n",
      "Epoch 12 | Step 4808 | loss: 0.2615134809414549 | accuracy: 0.8979583333333333 \n",
      "Epoch 12 | Step 4809 | loss: 0.2613270033864268 | accuracy: 0.8979803856382979 \n",
      "Epoch 12 | Step 4810 | loss: 0.26120312547494023 | accuracy: 0.8980852122015915 \n",
      "Epoch 12 | Step 4811 | loss: 0.2613380370789738 | accuracy: 0.8980241402116402 \n",
      "Epoch 12 | Step 4812 | loss: 0.2610647161356066 | accuracy: 0.8980458443271768 \n",
      "Epoch 12 | Step 4813 | loss: 0.26085619930374027 | accuracy: 0.8981907894736842 \n",
      "Epoch 12 | Step 4814 | loss: 0.2606870386544178 | accuracy: 0.8982119422572179 \n",
      "Epoch 12 | Step 4815 | loss: 0.26049562617746347 | accuracy: 0.8982329842931938 \n",
      "Epoch 12 | Step 4816 | loss: 0.2604003219473769 | accuracy: 0.8981723237597912 \n",
      "Epoch 12 | Step 4817 | loss: 0.26042951449441437 | accuracy: 0.898193359375 \n",
      "Epoch 12 | Step 4818 | loss: 0.26073896002459857 | accuracy: 0.8980519480519481 \n",
      "Epoch 12 | Step 4819 | loss: 0.2609544885899739 | accuracy: 0.8979922279792746 \n",
      "Epoch 12 | Step 4820 | loss: 0.26106741215831575 | accuracy: 0.8980135658914729 \n",
      "Epoch 12 | Step 4821 | loss: 0.2609144704243574 | accuracy: 0.8981153350515464 \n",
      "Epoch 12 | Step 4822 | loss: 0.26112017977819985 | accuracy: 0.8980157455012854 \n",
      "Epoch 12 | Step 4823 | loss: 0.261028935817572 | accuracy: 0.8980368589743589 \n",
      "Epoch 12 | Step 4824 | loss: 0.2611665852996702 | accuracy: 0.8980179028132992 \n",
      "Epoch 12 | Step 4825 | loss: 0.2610184693594979 | accuracy: 0.8981584821428571 \n",
      "Epoch 12 | Step 4826 | loss: 0.2608123894866189 | accuracy: 0.8982188295165394 \n",
      "Epoch 12 | Step 4827 | loss: 0.2609913562457576 | accuracy: 0.8980409263959391 \n",
      "Epoch 12 | Step 4828 | loss: 0.2608859828378583 | accuracy: 0.8980617088607595 \n",
      "Epoch 12 | Step 4829 | loss: 0.26078375605772264 | accuracy: 0.8981218434343434 \n",
      "Epoch 12 | Step 4830 | loss: 0.26090435698741055 | accuracy: 0.8979455289672544 \n",
      "Epoch 12 | Step 4831 | loss: 0.2611224978937578 | accuracy: 0.8978093592964824 \n",
      "Epoch 12 | Step 4832 | loss: 0.26095492544030807 | accuracy: 0.8978696741854637 \n",
      "Epoch 12 | Step 4833 | loss: 0.26117492087185407 | accuracy: 0.8977734375 \n",
      "Epoch 12 | Step 4834 | loss: 0.26116774898217526 | accuracy: 0.8977945760598504 \n",
      "Epoch 12 | Step 4835 | loss: 0.2615514059564963 | accuracy: 0.8975824004975125 \n",
      "Epoch 12 | Step 4836 | loss: 0.2612356794235431 | accuracy: 0.89775097325777 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.5187874436378479 | accuracy: 0.765625 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.5371914207935333 | accuracy: 0.7578125 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.47647043069203693 | accuracy: 0.7760416666666666 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.467340849339962 | accuracy: 0.78125 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4722109377384186 | accuracy: 0.78125 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4594700088103612 | accuracy: 0.7890625 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.44980493613651823 | accuracy: 0.7946428571428571 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4398117884993553 | accuracy: 0.798828125 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.43375975555843777 | accuracy: 0.8055555555555556 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.43654994666576385 | accuracy: 0.8078125 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.43924157456918195 | accuracy: 0.8096590909090909 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.430839645365874 | accuracy: 0.8138020833333334 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.43616100687247056 | accuracy: 0.8100961538461539 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.44075751517500195 | accuracy: 0.8091517857142857 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4295855065186818 | accuracy: 0.815625 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4282858297228813 | accuracy: 0.8173828125 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.43980270974776325 | accuracy: 0.8125 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.43584200077586704 | accuracy: 0.8133680555555556 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.434098482131958 | accuracy: 0.8149671052631579 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4303747773170471 | accuracy: 0.81640625 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4305553436279297 | accuracy: 0.8162202380952381 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.42571841044859454 | accuracy: 0.8181818181818182 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.42802346789318585 | accuracy: 0.8158967391304348 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.42822037761410076 | accuracy: 0.8157552083333334 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4324480760097504 | accuracy: 0.8125 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.42514634877443314 | accuracy: 0.8155048076923077 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4234376753921862 | accuracy: 0.8177083333333334 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4188996101064341 | accuracy: 0.8197544642857143 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.42100300408642866 | accuracy: 0.8195043103448276 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.42203986793756487 | accuracy: 0.81875 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4168910062120807 | accuracy: 0.8210685483870968 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4112653839401901 | accuracy: 0.82421875 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.40922310812906787 | accuracy: 0.8262310606060606 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.41845891011111874 | accuracy: 0.8230698529411765 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4172642116035734 | accuracy: 0.8227678571428572 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4132090024650097 | accuracy: 0.8246527777777778 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4149222917653419 | accuracy: 0.825168918918919 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4149331909261252 | accuracy: 0.824013157894737 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4133023913854208 | accuracy: 0.8249198717948718 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4161363963037729 | accuracy: 0.82265625 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.41876298952393415 | accuracy: 0.821265243902439 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4166212993718329 | accuracy: 0.8225446428571429 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.41628119592056717 | accuracy: 0.8219476744186046 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.41845149106600066 | accuracy: 0.8210227272727273 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4217265251610014 | accuracy: 0.8192028986083136 \n",
      "Epoch 13 | Step 4837 | loss: 0.1853741705417633 | accuracy: 0.9375 \n",
      "Epoch 13 | Step 4838 | loss: 0.2778024822473526 | accuracy: 0.890625 \n",
      "Epoch 13 | Step 4839 | loss: 0.24551560978094736 | accuracy: 0.90625 \n",
      "Epoch 13 | Step 4840 | loss: 0.24516450986266136 | accuracy: 0.90625 \n",
      "Epoch 13 | Step 4841 | loss: 0.24227965474128724 | accuracy: 0.90625 \n",
      "Epoch 13 | Step 4842 | loss: 0.2619309574365616 | accuracy: 0.890625 \n",
      "Epoch 13 | Step 4843 | loss: 0.265075010912759 | accuracy: 0.8928571428571429 \n",
      "Epoch 13 | Step 4844 | loss: 0.28003187850117683 | accuracy: 0.890625 \n",
      "Epoch 13 | Step 4845 | loss: 0.2719363437758552 | accuracy: 0.8958333333333334 \n",
      "Epoch 13 | Step 4846 | loss: 0.28345142900943754 | accuracy: 0.884375 \n",
      "Epoch 13 | Step 4847 | loss: 0.2825343663042242 | accuracy: 0.8806818181818182 \n",
      "Epoch 13 | Step 4848 | loss: 0.29070770740509033 | accuracy: 0.87109375 \n",
      "Epoch 13 | Step 4849 | loss: 0.28488589708621687 | accuracy: 0.8774038461538461 \n",
      "Epoch 13 | Step 4850 | loss: 0.28823721621717724 | accuracy: 0.8783482142857143 \n",
      "Epoch 13 | Step 4851 | loss: 0.28116785883903506 | accuracy: 0.8833333333333333 \n",
      "Epoch 13 | Step 4852 | loss: 0.2710435027256608 | accuracy: 0.8896484375 \n",
      "Epoch 13 | Step 4853 | loss: 0.2676854615702349 | accuracy: 0.8915441176470589 \n",
      "Epoch 13 | Step 4854 | loss: 0.2660561319854524 | accuracy: 0.8914930555555556 \n",
      "Epoch 13 | Step 4855 | loss: 0.26235347829366984 | accuracy: 0.8947368421052632 \n",
      "Epoch 13 | Step 4856 | loss: 0.2645541772246361 | accuracy: 0.89609375 \n",
      "Epoch 13 | Step 4857 | loss: 0.26459779200099764 | accuracy: 0.8958333333333334 \n",
      "Epoch 13 | Step 4858 | loss: 0.2639568231322549 | accuracy: 0.8963068181818182 \n",
      "Epoch 13 | Step 4859 | loss: 0.26156861237857654 | accuracy: 0.8960597826086957 \n",
      "Epoch 13 | Step 4860 | loss: 0.25708019236723584 | accuracy: 0.8984375 \n",
      "Epoch 13 | Step 4861 | loss: 0.25336658596992495 | accuracy: 0.900625 \n",
      "Epoch 13 | Step 4862 | loss: 0.2533337405094734 | accuracy: 0.9002403846153846 \n",
      "Epoch 13 | Step 4863 | loss: 0.253298732969496 | accuracy: 0.8998842592592593 \n",
      "Epoch 13 | Step 4864 | loss: 0.24808722973934244 | accuracy: 0.9029017857142857 \n",
      "Epoch 13 | Step 4865 | loss: 0.24613401730512754 | accuracy: 0.9019396551724138 \n",
      "Epoch 13 | Step 4866 | loss: 0.2467923146982988 | accuracy: 0.9015625 \n",
      "Epoch 13 | Step 4867 | loss: 0.24624463218835096 | accuracy: 0.9027217741935484 \n",
      "Epoch 13 | Step 4868 | loss: 0.2471830516587943 | accuracy: 0.90283203125 \n",
      "Epoch 13 | Step 4869 | loss: 0.25167295494765946 | accuracy: 0.9015151515151515 \n",
      "Epoch 13 | Step 4870 | loss: 0.25272724273450237 | accuracy: 0.9021139705882353 \n",
      "Epoch 13 | Step 4871 | loss: 0.25197760654347284 | accuracy: 0.9022321428571428 \n",
      "Epoch 13 | Step 4872 | loss: 0.25389196909964085 | accuracy: 0.9014756944444444 \n",
      "Epoch 13 | Step 4873 | loss: 0.25128319879641403 | accuracy: 0.902027027027027 \n",
      "Epoch 13 | Step 4874 | loss: 0.2503562363746919 | accuracy: 0.9025493421052632 \n",
      "Epoch 13 | Step 4875 | loss: 0.24867944285655633 | accuracy: 0.9034455128205128 \n",
      "Epoch 13 | Step 4876 | loss: 0.24792145062237977 | accuracy: 0.903125 \n",
      "Epoch 13 | Step 4877 | loss: 0.24813708317715946 | accuracy: 0.9024390243902439 \n",
      "Epoch 13 | Step 4878 | loss: 0.2480829767882824 | accuracy: 0.9032738095238095 \n",
      "Epoch 13 | Step 4879 | loss: 0.2462664043834043 | accuracy: 0.9037063953488372 \n",
      "Epoch 13 | Step 4880 | loss: 0.24503938464278524 | accuracy: 0.9041193181818182 \n",
      "Epoch 13 | Step 4881 | loss: 0.24712036467260784 | accuracy: 0.903125 \n",
      "Epoch 13 | Step 4882 | loss: 0.24745015233107234 | accuracy: 0.9028532608695652 \n",
      "Epoch 13 | Step 4883 | loss: 0.24628388992649444 | accuracy: 0.9035904255319149 \n",
      "Epoch 13 | Step 4884 | loss: 0.24750483703489104 | accuracy: 0.9029947916666666 \n",
      "Epoch 13 | Step 4885 | loss: 0.24525767093410297 | accuracy: 0.9043367346938775 \n",
      "Epoch 13 | Step 4886 | loss: 0.245982154160738 | accuracy: 0.9040625 \n",
      "Epoch 13 | Step 4887 | loss: 0.24871770380174413 | accuracy: 0.9028799019607843 \n",
      "Epoch 13 | Step 4888 | loss: 0.25074245795034444 | accuracy: 0.9017427884615384 \n",
      "Epoch 13 | Step 4889 | loss: 0.2496690717789362 | accuracy: 0.902122641509434 \n",
      "Epoch 13 | Step 4890 | loss: 0.24915871313876575 | accuracy: 0.9021990740740741 \n",
      "Epoch 13 | Step 4891 | loss: 0.24889047159390015 | accuracy: 0.9028409090909091 \n",
      "Epoch 13 | Step 4892 | loss: 0.2507963213803513 | accuracy: 0.90234375 \n",
      "Epoch 13 | Step 4893 | loss: 0.25006347149610525 | accuracy: 0.9024122807017544 \n",
      "Epoch 13 | Step 4894 | loss: 0.25126809588280224 | accuracy: 0.9019396551724138 \n",
      "Epoch 13 | Step 4895 | loss: 0.2517226458353512 | accuracy: 0.9017478813559322 \n",
      "Epoch 13 | Step 4896 | loss: 0.2536945664634308 | accuracy: 0.90078125 \n",
      "Epoch 13 | Step 4897 | loss: 0.25370099786363676 | accuracy: 0.8998463114754098 \n",
      "Epoch 13 | Step 4898 | loss: 0.2533849274679539 | accuracy: 0.9002016129032258 \n",
      "Epoch 13 | Step 4899 | loss: 0.25326975908071286 | accuracy: 0.9000496031746031 \n",
      "Epoch 13 | Step 4900 | loss: 0.2514073773054407 | accuracy: 0.900634765625 \n",
      "Epoch 13 | Step 4901 | loss: 0.25171229736163075 | accuracy: 0.9007211538461538 \n",
      "Epoch 13 | Step 4902 | loss: 0.24991831081834717 | accuracy: 0.9015151515151515 \n",
      "Epoch 13 | Step 4903 | loss: 0.24906747788190853 | accuracy: 0.9018190298507462 \n",
      "Epoch 13 | Step 4904 | loss: 0.24869639875695995 | accuracy: 0.9018841911764706 \n",
      "Epoch 13 | Step 4905 | loss: 0.2496793478511383 | accuracy: 0.9012681159420289 \n",
      "Epoch 13 | Step 4906 | loss: 0.25113223674041896 | accuracy: 0.9008928571428572 \n",
      "Epoch 13 | Step 4907 | loss: 0.25252245272129364 | accuracy: 0.9000880281690141 \n",
      "Epoch 13 | Step 4908 | loss: 0.2517442602871194 | accuracy: 0.900390625 \n",
      "Epoch 13 | Step 4909 | loss: 0.2523866551992012 | accuracy: 0.9002568493150684 \n",
      "Epoch 13 | Step 4910 | loss: 0.25308190195544356 | accuracy: 0.8999155405405406 \n",
      "Epoch 13 | Step 4911 | loss: 0.25419863690932604 | accuracy: 0.8995833333333333 \n",
      "Epoch 13 | Step 4912 | loss: 0.2532089133992008 | accuracy: 0.899671052631579 \n",
      "Epoch 13 | Step 4913 | loss: 0.25418566118974206 | accuracy: 0.8993506493506493 \n",
      "Epoch 13 | Step 4914 | loss: 0.2535332747950005 | accuracy: 0.8998397435897436 \n",
      "Epoch 13 | Step 4915 | loss: 0.2526353061010567 | accuracy: 0.8999208860759493 \n",
      "Epoch 13 | Step 4916 | loss: 0.2520190992392601 | accuracy: 0.9001953125 \n",
      "Epoch 13 | Step 4917 | loss: 0.25341481568268803 | accuracy: 0.8996913580246914 \n",
      "Epoch 13 | Step 4918 | loss: 0.2524106383505393 | accuracy: 0.9001524390243902 \n",
      "Epoch 13 | Step 4919 | loss: 0.2527503189013667 | accuracy: 0.8998493975903614 \n",
      "Epoch 13 | Step 4920 | loss: 0.2526322494127922 | accuracy: 0.8999255952380952 \n",
      "Epoch 13 | Step 4921 | loss: 0.25302496631355864 | accuracy: 0.9001838235294117 \n",
      "Epoch 13 | Step 4922 | loss: 0.2517890702326632 | accuracy: 0.9007994186046512 \n",
      "Epoch 13 | Step 4923 | loss: 0.2514377292031531 | accuracy: 0.9008620689655172 \n",
      "Epoch 13 | Step 4924 | loss: 0.2520118722353471 | accuracy: 0.9009232954545454 \n",
      "Epoch 13 | Step 4925 | loss: 0.25185447370403286 | accuracy: 0.9008075842696629 \n",
      "Epoch 13 | Step 4926 | loss: 0.2524374356700316 | accuracy: 0.9005208333333333 \n",
      "Epoch 13 | Step 4927 | loss: 0.25231075229553085 | accuracy: 0.9004120879120879 \n",
      "Epoch 13 | Step 4928 | loss: 0.2543378486095564 | accuracy: 0.899796195652174 \n",
      "Epoch 13 | Step 4929 | loss: 0.2565711484320703 | accuracy: 0.8990255376344086 \n",
      "Epoch 13 | Step 4930 | loss: 0.255623766320183 | accuracy: 0.8994348404255319 \n",
      "Epoch 13 | Step 4931 | loss: 0.25465912073850644 | accuracy: 0.8998355263157894 \n",
      "Epoch 13 | Step 4932 | loss: 0.253854380377258 | accuracy: 0.9000651041666666 \n",
      "Epoch 13 | Step 4933 | loss: 0.2533948081209489 | accuracy: 0.9004510309278351 \n",
      "Epoch 13 | Step 4934 | loss: 0.25463832952842436 | accuracy: 0.900031887755102 \n",
      "Epoch 13 | Step 4935 | loss: 0.25397933199249145 | accuracy: 0.90072601010101 \n",
      "Epoch 13 | Step 4936 | loss: 0.25445197828114047 | accuracy: 0.90046875 \n",
      "Epoch 13 | Step 4937 | loss: 0.25449786571287886 | accuracy: 0.900680693069307 \n",
      "Epoch 13 | Step 4938 | loss: 0.2548109439804275 | accuracy: 0.9004289215686274 \n",
      "Epoch 13 | Step 4939 | loss: 0.25478928217899466 | accuracy: 0.9004854368932039 \n",
      "Epoch 13 | Step 4940 | loss: 0.25498215374178623 | accuracy: 0.9008413461538461 \n",
      "Epoch 13 | Step 4941 | loss: 0.2558910370582627 | accuracy: 0.9004464285714285 \n",
      "Epoch 13 | Step 4942 | loss: 0.2556309844103625 | accuracy: 0.9003537735849056 \n",
      "Epoch 13 | Step 4943 | loss: 0.2557502099983047 | accuracy: 0.9002628504672897 \n",
      "Epoch 13 | Step 4944 | loss: 0.25661428665949254 | accuracy: 0.8998842592592593 \n",
      "Epoch 13 | Step 4945 | loss: 0.25565752872359876 | accuracy: 0.9003727064220184 \n",
      "Epoch 13 | Step 4946 | loss: 0.25550180301070224 | accuracy: 0.9002840909090909 \n",
      "Epoch 13 | Step 4947 | loss: 0.25641702672651234 | accuracy: 0.8997747747747747 \n",
      "Epoch 13 | Step 4948 | loss: 0.2572674161222365 | accuracy: 0.8994140625 \n",
      "Epoch 13 | Step 4949 | loss: 0.2569639777055885 | accuracy: 0.8996128318584071 \n",
      "Epoch 13 | Step 4950 | loss: 0.2567887059821372 | accuracy: 0.8995339912280702 \n",
      "Epoch 13 | Step 4951 | loss: 0.25621739943390315 | accuracy: 0.8998641304347826 \n",
      "Epoch 13 | Step 4952 | loss: 0.25553124931094984 | accuracy: 0.9001885775862069 \n",
      "Epoch 13 | Step 4953 | loss: 0.2549846939678886 | accuracy: 0.9005074786324786 \n",
      "Epoch 13 | Step 4954 | loss: 0.2555026617216863 | accuracy: 0.9001588983050848 \n",
      "Epoch 13 | Step 4955 | loss: 0.256001784333161 | accuracy: 0.8996848739495799 \n",
      "Epoch 13 | Step 4956 | loss: 0.2561473474527399 | accuracy: 0.8994791666666667 \n",
      "Epoch 13 | Step 4957 | loss: 0.25535654091884286 | accuracy: 0.900051652892562 \n",
      "Epoch 13 | Step 4958 | loss: 0.2558638964642267 | accuracy: 0.8995901639344263 \n",
      "Epoch 13 | Step 4959 | loss: 0.25559797537762946 | accuracy: 0.8996443089430894 \n",
      "Epoch 13 | Step 4960 | loss: 0.25644111459053337 | accuracy: 0.8991935483870968 \n",
      "Epoch 13 | Step 4961 | loss: 0.2563113617300988 | accuracy: 0.899125 \n",
      "Epoch 13 | Step 4962 | loss: 0.25557774949877987 | accuracy: 0.8993055555555556 \n",
      "Epoch 13 | Step 4963 | loss: 0.2559146717425407 | accuracy: 0.8989911417322834 \n",
      "Epoch 13 | Step 4964 | loss: 0.25550389703130355 | accuracy: 0.899169921875 \n",
      "Epoch 13 | Step 4965 | loss: 0.25534426455580916 | accuracy: 0.8991036821705426 \n",
      "Epoch 13 | Step 4966 | loss: 0.2555748217954086 | accuracy: 0.8989182692307692 \n",
      "Epoch 13 | Step 4967 | loss: 0.2557678086725811 | accuracy: 0.898854961832061 \n",
      "Epoch 13 | Step 4968 | loss: 0.2556518556155039 | accuracy: 0.8991477272727273 \n",
      "Epoch 13 | Step 4969 | loss: 0.25498726779132863 | accuracy: 0.8995535714285714 \n",
      "Epoch 13 | Step 4970 | loss: 0.2543222502207579 | accuracy: 0.8998367537313433 \n",
      "Epoch 13 | Step 4971 | loss: 0.25460073423606383 | accuracy: 0.8997685185185185 \n",
      "Epoch 13 | Step 4972 | loss: 0.25487602639066825 | accuracy: 0.9000459558823529 \n",
      "Epoch 13 | Step 4973 | loss: 0.2557374570165238 | accuracy: 0.8997490875912408 \n",
      "Epoch 13 | Step 4974 | loss: 0.255625204709561 | accuracy: 0.8999094202898551 \n",
      "Epoch 13 | Step 4975 | loss: 0.25624887479080577 | accuracy: 0.8993929856115108 \n",
      "Epoch 13 | Step 4976 | loss: 0.256126268580556 | accuracy: 0.8994419642857143 \n",
      "Epoch 13 | Step 4977 | loss: 0.2562866459818597 | accuracy: 0.8991578014184397 \n",
      "Epoch 13 | Step 4978 | loss: 0.2560039845255899 | accuracy: 0.898987676056338 \n",
      "Epoch 13 | Step 4979 | loss: 0.25550005084776384 | accuracy: 0.899256993006993 \n",
      "Epoch 13 | Step 4980 | loss: 0.25547989866592824 | accuracy: 0.8990885416666666 \n",
      "Epoch 13 | Step 4981 | loss: 0.2550924873043751 | accuracy: 0.8990301724137931 \n",
      "Epoch 13 | Step 4982 | loss: 0.2553046327849774 | accuracy: 0.8991866438356164 \n",
      "Epoch 13 | Step 4983 | loss: 0.255396188572556 | accuracy: 0.8993409863945578 \n",
      "Epoch 13 | Step 4984 | loss: 0.25528869531243237 | accuracy: 0.899387668918919 \n",
      "Epoch 13 | Step 4985 | loss: 0.25539308801393384 | accuracy: 0.8994337248322147 \n",
      "Epoch 13 | Step 4986 | loss: 0.2546104349195958 | accuracy: 0.8997916666666667 \n",
      "Epoch 13 | Step 4987 | loss: 0.2548288414316462 | accuracy: 0.8997309602649006 \n",
      "Epoch 13 | Step 4988 | loss: 0.2553478857306274 | accuracy: 0.899671052631579 \n",
      "Epoch 13 | Step 4989 | loss: 0.2559118521661541 | accuracy: 0.8996119281045751 \n",
      "Epoch 13 | Step 4990 | loss: 0.2551173599219168 | accuracy: 0.8998579545454546 \n",
      "Epoch 13 | Step 4991 | loss: 0.2545370270648311 | accuracy: 0.900100806451613 \n",
      "Epoch 13 | Step 4992 | loss: 0.2535575529417167 | accuracy: 0.9005408653846154 \n",
      "Epoch 13 | Step 4993 | loss: 0.2534393789187359 | accuracy: 0.9006767515923567 \n",
      "Epoch 13 | Step 4994 | loss: 0.25314164421037794 | accuracy: 0.9009098101265823 \n",
      "Epoch 13 | Step 4995 | loss: 0.25318941806659767 | accuracy: 0.9007468553459119 \n",
      "Epoch 13 | Step 4996 | loss: 0.2530787788797171 | accuracy: 0.90087890625 \n",
      "Epoch 13 | Step 4997 | loss: 0.252858778565937 | accuracy: 0.9010093167701864 \n",
      "Epoch 13 | Step 4998 | loss: 0.2529639585610526 | accuracy: 0.9010416666666666 \n",
      "Epoch 13 | Step 4999 | loss: 0.2521102751142409 | accuracy: 0.9015529141104295 \n",
      "Epoch 13 | Step 5000 | loss: 0.2517889473678136 | accuracy: 0.9015815548780488 \n",
      "Epoch 13 | Step 5001 | loss: 0.25163547803055164 | accuracy: 0.9016098484848485 \n",
      "Epoch 13 | Step 5002 | loss: 0.25274689235242026 | accuracy: 0.9012612951807228 \n",
      "Epoch 13 | Step 5003 | loss: 0.25207561102812887 | accuracy: 0.9015718562874252 \n",
      "Epoch 13 | Step 5004 | loss: 0.2517285129676264 | accuracy: 0.9014136904761905 \n",
      "Epoch 13 | Step 5005 | loss: 0.2531039354187498 | accuracy: 0.9009800295857988 \n",
      "Epoch 13 | Step 5006 | loss: 0.25313151101855685 | accuracy: 0.9009191176470588 \n",
      "Epoch 13 | Step 5007 | loss: 0.253544270033725 | accuracy: 0.9007675438596491 \n",
      "Epoch 13 | Step 5008 | loss: 0.2538690784469595 | accuracy: 0.9005268895348837 \n",
      "Epoch 13 | Step 5009 | loss: 0.2527871351969037 | accuracy: 0.9011018786127167 \n",
      "Epoch 13 | Step 5010 | loss: 0.2528184316195977 | accuracy: 0.9010416666666666 \n",
      "Epoch 13 | Step 5011 | loss: 0.2525277798942158 | accuracy: 0.9010714285714285 \n",
      "Epoch 13 | Step 5012 | loss: 0.25243446116589696 | accuracy: 0.9013671875 \n",
      "Epoch 13 | Step 5013 | loss: 0.2527054952783774 | accuracy: 0.9013064971751412 \n",
      "Epoch 13 | Step 5014 | loss: 0.25258150240511046 | accuracy: 0.9013342696629213 \n",
      "Epoch 13 | Step 5015 | loss: 0.25260691015913506 | accuracy: 0.9014490223463687 \n",
      "Epoch 13 | Step 5016 | loss: 0.2530608199950722 | accuracy: 0.9012152777777778 \n",
      "Epoch 13 | Step 5017 | loss: 0.25273283603935615 | accuracy: 0.9012430939226519 \n",
      "Epoch 13 | Step 5018 | loss: 0.25223257969860197 | accuracy: 0.9014423076923077 \n",
      "Epoch 13 | Step 5019 | loss: 0.2518128714844829 | accuracy: 0.9018101092896175 \n",
      "Epoch 13 | Step 5020 | loss: 0.2519152243419186 | accuracy: 0.9018342391304348 \n",
      "Epoch 13 | Step 5021 | loss: 0.2520073853231765 | accuracy: 0.9016047297297297 \n",
      "Epoch 13 | Step 5022 | loss: 0.2520653747663062 | accuracy: 0.9015456989247311 \n",
      "Epoch 13 | Step 5023 | loss: 0.2520786977627061 | accuracy: 0.9018215240641712 \n",
      "Epoch 13 | Step 5024 | loss: 0.2520258248724202 | accuracy: 0.9019281914893617 \n",
      "Epoch 13 | Step 5025 | loss: 0.25156202332841027 | accuracy: 0.9021164021164021 \n",
      "Epoch 13 | Step 5026 | loss: 0.2516913674771786 | accuracy: 0.9019736842105263 \n",
      "Epoch 13 | Step 5027 | loss: 0.2519517605295356 | accuracy: 0.9019960732984293 \n",
      "Epoch 13 | Step 5028 | loss: 0.25229368517951417 | accuracy: 0.90185546875 \n",
      "Epoch 13 | Step 5029 | loss: 0.2526361287952705 | accuracy: 0.9017163212435233 \n",
      "Epoch 13 | Step 5030 | loss: 0.25209932063811835 | accuracy: 0.9019007731958762 \n",
      "Epoch 13 | Step 5031 | loss: 0.2523041300666638 | accuracy: 0.9016826923076923 \n",
      "Epoch 13 | Step 5032 | loss: 0.2524832485965928 | accuracy: 0.9016262755102041 \n",
      "Epoch 13 | Step 5033 | loss: 0.2526696761928234 | accuracy: 0.9014118020304569 \n",
      "Epoch 13 | Step 5034 | loss: 0.25282644491755596 | accuracy: 0.9011205808080808 \n",
      "Epoch 13 | Step 5035 | loss: 0.25326139831812533 | accuracy: 0.9009108040201005 \n",
      "Epoch 13 | Step 5036 | loss: 0.25316581118851894 | accuracy: 0.9009375 \n",
      "Epoch 13 | Step 5037 | loss: 0.253623481598956 | accuracy: 0.9006529850746269 \n",
      "Epoch 13 | Step 5038 | loss: 0.253862787775769 | accuracy: 0.9005259900990099 \n",
      "Epoch 13 | Step 5039 | loss: 0.2535561846174629 | accuracy: 0.9007081280788177 \n",
      "Epoch 13 | Step 5040 | loss: 0.2534449446362022 | accuracy: 0.9006587009803921 \n",
      "Epoch 13 | Step 5041 | loss: 0.2536132431248338 | accuracy: 0.9005335365853658 \n",
      "Epoch 13 | Step 5042 | loss: 0.25358165022962287 | accuracy: 0.900561286407767 \n",
      "Epoch 13 | Step 5043 | loss: 0.25325548990769076 | accuracy: 0.9007397342995169 \n",
      "Epoch 13 | Step 5044 | loss: 0.2529670034821789 | accuracy: 0.9008413461538461 \n",
      "Epoch 13 | Step 5045 | loss: 0.25299480931753165 | accuracy: 0.9007924641148325 \n",
      "Epoch 13 | Step 5046 | loss: 0.25252720312703214 | accuracy: 0.900967261904762 \n",
      "Epoch 13 | Step 5047 | loss: 0.25235645010431784 | accuracy: 0.9011404028436019 \n",
      "Epoch 13 | Step 5048 | loss: 0.2526156837296372 | accuracy: 0.9009433962264151 \n",
      "Epoch 13 | Step 5049 | loss: 0.25211180575156983 | accuracy: 0.9011883802816901 \n",
      "Epoch 13 | Step 5050 | loss: 0.25192727876183013 | accuracy: 0.9013580607476636 \n",
      "Epoch 13 | Step 5051 | loss: 0.25241381390843265 | accuracy: 0.901235465116279 \n",
      "Epoch 13 | Step 5052 | loss: 0.2531655611884261 | accuracy: 0.9009693287037037 \n",
      "Epoch 13 | Step 5053 | loss: 0.25361676867793764 | accuracy: 0.9008496543778802 \n",
      "Epoch 13 | Step 5054 | loss: 0.2533502132042284 | accuracy: 0.9009461009174312 \n",
      "Epoch 13 | Step 5055 | loss: 0.2532679258620356 | accuracy: 0.9008276255707762 \n",
      "Epoch 13 | Step 5056 | loss: 0.253331014480103 | accuracy: 0.9007102272727273 \n",
      "Epoch 13 | Step 5057 | loss: 0.252871906629245 | accuracy: 0.9008766968325792 \n",
      "Epoch 13 | Step 5058 | loss: 0.2525432455848464 | accuracy: 0.9011120495495496 \n",
      "Epoch 13 | Step 5059 | loss: 0.25265324954361107 | accuracy: 0.9011350896860987 \n",
      "Epoch 13 | Step 5060 | loss: 0.25259029116880666 | accuracy: 0.9011579241071429 \n",
      "Epoch 13 | Step 5061 | loss: 0.2527961498830052 | accuracy: 0.9010416666666666 \n",
      "Epoch 13 | Step 5062 | loss: 0.25299336553543 | accuracy: 0.9009264380530974 \n",
      "Epoch 13 | Step 5063 | loss: 0.2530830280305529 | accuracy: 0.9008810572687225 \n",
      "Epoch 13 | Step 5064 | loss: 0.25306063148666874 | accuracy: 0.9009046052631579 \n",
      "Epoch 13 | Step 5065 | loss: 0.25270103103599156 | accuracy: 0.9010644104803494 \n",
      "Epoch 13 | Step 5066 | loss: 0.25252703671222126 | accuracy: 0.9010869565217391 \n",
      "Epoch 13 | Step 5067 | loss: 0.2528127520566893 | accuracy: 0.9008387445887446 \n",
      "Epoch 13 | Step 5068 | loss: 0.25249269582202705 | accuracy: 0.9009294181034483 \n",
      "Epoch 13 | Step 5069 | loss: 0.2524356413872455 | accuracy: 0.9008181330472103 \n",
      "Epoch 13 | Step 5070 | loss: 0.25253868360932036 | accuracy: 0.9007077991452992 \n",
      "Epoch 13 | Step 5071 | loss: 0.252289528257035 | accuracy: 0.9009308510638298 \n",
      "Epoch 13 | Step 5072 | loss: 0.2523270649361911 | accuracy: 0.9010195974576272 \n",
      "Epoch 13 | Step 5073 | loss: 0.2527183224820384 | accuracy: 0.9009098101265823 \n",
      "Epoch 13 | Step 5074 | loss: 0.2531344170267339 | accuracy: 0.9008009453781513 \n",
      "Epoch 13 | Step 5075 | loss: 0.2528870979549992 | accuracy: 0.9008891213389121 \n",
      "Epoch 13 | Step 5076 | loss: 0.2525452697960036 | accuracy: 0.9009765625 \n",
      "Epoch 13 | Step 5077 | loss: 0.2527489091783635 | accuracy: 0.9009336099585062 \n",
      "Epoch 13 | Step 5078 | loss: 0.2529563579615972 | accuracy: 0.9007618801652892 \n",
      "Epoch 13 | Step 5079 | loss: 0.25289775060160136 | accuracy: 0.9008487654320988 \n",
      "Epoch 13 | Step 5080 | loss: 0.2522050714517223 | accuracy: 0.9011910860655737 \n",
      "Epoch 13 | Step 5081 | loss: 0.25170472027087665 | accuracy: 0.9014668367346939 \n",
      "Epoch 13 | Step 5082 | loss: 0.25150530452166114 | accuracy: 0.9014862804878049 \n",
      "Epoch 13 | Step 5083 | loss: 0.251147744204351 | accuracy: 0.901632085020243 \n",
      "Epoch 13 | Step 5084 | loss: 0.25133155184167016 | accuracy: 0.9015246975806451 \n",
      "Epoch 13 | Step 5085 | loss: 0.2513559510310488 | accuracy: 0.9016064257028112 \n",
      "Epoch 13 | Step 5086 | loss: 0.25107731699943514 | accuracy: 0.9018125 \n",
      "Epoch 13 | Step 5087 | loss: 0.25130852142653115 | accuracy: 0.9017679282868526 \n",
      "Epoch 13 | Step 5088 | loss: 0.25132799728049143 | accuracy: 0.9017237103174603 \n",
      "Epoch 13 | Step 5089 | loss: 0.25130557560402383 | accuracy: 0.901556324110672 \n",
      "Epoch 13 | Step 5090 | loss: 0.25131389481110805 | accuracy: 0.9014517716535433 \n",
      "Epoch 13 | Step 5091 | loss: 0.25108554193786514 | accuracy: 0.901593137254902 \n",
      "Epoch 13 | Step 5092 | loss: 0.25112603796878796 | accuracy: 0.9014892578125 \n",
      "Epoch 13 | Step 5093 | loss: 0.2511182120685908 | accuracy: 0.9014469844357976 \n",
      "Epoch 13 | Step 5094 | loss: 0.25128610923077677 | accuracy: 0.9014050387596899 \n",
      "Epoch 13 | Step 5095 | loss: 0.2511300279481988 | accuracy: 0.901363416988417 \n",
      "Epoch 13 | Step 5096 | loss: 0.2510180300244915 | accuracy: 0.9015024038461539 \n",
      "Epoch 13 | Step 5097 | loss: 0.2507660843974326 | accuracy: 0.9017001915708812 \n",
      "Epoch 13 | Step 5098 | loss: 0.2512583084802588 | accuracy: 0.9013000954198473 \n",
      "Epoch 13 | Step 5099 | loss: 0.2510947702955381 | accuracy: 0.9012595057034221 \n",
      "Epoch 13 | Step 5100 | loss: 0.25099304600646977 | accuracy: 0.9013967803030303 \n",
      "Epoch 13 | Step 5101 | loss: 0.25080274917044704 | accuracy: 0.9014150943396226 \n",
      "Epoch 13 | Step 5102 | loss: 0.25070464291742844 | accuracy: 0.9015507518796992 \n",
      "Epoch 13 | Step 5103 | loss: 0.25039862978101196 | accuracy: 0.9015683520599251 \n",
      "Epoch 13 | Step 5104 | loss: 0.2506712067371871 | accuracy: 0.9014109141791045 \n",
      "Epoch 13 | Step 5105 | loss: 0.2505628369665498 | accuracy: 0.9014869888475836 \n",
      "Epoch 13 | Step 5106 | loss: 0.25070551418595816 | accuracy: 0.9015046296296296 \n",
      "Epoch 13 | Step 5107 | loss: 0.25067614695242824 | accuracy: 0.901464483394834 \n",
      "Epoch 13 | Step 5108 | loss: 0.2505554774885666 | accuracy: 0.9016544117647058 \n",
      "Epoch 13 | Step 5109 | loss: 0.2505850081260385 | accuracy: 0.9017284798534798 \n",
      "Epoch 13 | Step 5110 | loss: 0.25081759288798255 | accuracy: 0.9018020072992701 \n",
      "Epoch 13 | Step 5111 | loss: 0.2506313928690821 | accuracy: 0.901875 \n",
      "Epoch 13 | Step 5112 | loss: 0.25100931903158386 | accuracy: 0.9017210144927537 \n",
      "Epoch 13 | Step 5113 | loss: 0.250751083508295 | accuracy: 0.9017373646209387 \n",
      "Epoch 13 | Step 5114 | loss: 0.2505313596493904 | accuracy: 0.9018098021582733 \n",
      "Epoch 13 | Step 5115 | loss: 0.25036377585276026 | accuracy: 0.9018257168458781 \n",
      "Epoch 13 | Step 5116 | loss: 0.25036291325730914 | accuracy: 0.9016183035714286 \n",
      "Epoch 13 | Step 5117 | loss: 0.25026384218731784 | accuracy: 0.9016903914590747 \n",
      "Epoch 13 | Step 5118 | loss: 0.24983765470220662 | accuracy: 0.9018727836879432 \n",
      "Epoch 13 | Step 5119 | loss: 0.24969114926594282 | accuracy: 0.9018882508833922 \n",
      "Epoch 13 | Step 5120 | loss: 0.2493297043190873 | accuracy: 0.9021236795774648 \n",
      "Epoch 13 | Step 5121 | loss: 0.24929415902547644 | accuracy: 0.9020833333333333 \n",
      "Epoch 13 | Step 5122 | loss: 0.24880145445882831 | accuracy: 0.9022071678321678 \n",
      "Epoch 13 | Step 5123 | loss: 0.2488401801899748 | accuracy: 0.9022756968641115 \n",
      "Epoch 13 | Step 5124 | loss: 0.24838152085430895 | accuracy: 0.9024522569444444 \n",
      "Epoch 13 | Step 5125 | loss: 0.24900155602132548 | accuracy: 0.9023572664359861 \n",
      "Epoch 13 | Step 5126 | loss: 0.24890188212538564 | accuracy: 0.9024245689655173 \n",
      "Epoch 13 | Step 5127 | loss: 0.24947063248489296 | accuracy: 0.9022229381443299 \n",
      "Epoch 13 | Step 5128 | loss: 0.2493831617630097 | accuracy: 0.90234375 \n",
      "Epoch 13 | Step 5129 | loss: 0.24937841497081922 | accuracy: 0.9023570819112628 \n",
      "Epoch 13 | Step 5130 | loss: 0.24949093038837092 | accuracy: 0.9023703231292517 \n",
      "Epoch 13 | Step 5131 | loss: 0.24931356818494127 | accuracy: 0.9023834745762712 \n",
      "Epoch 13 | Step 5132 | loss: 0.24939924662278287 | accuracy: 0.9022909628378378 \n",
      "Epoch 13 | Step 5133 | loss: 0.24928299347659932 | accuracy: 0.9023569023569024 \n",
      "Epoch 13 | Step 5134 | loss: 0.2492383918756204 | accuracy: 0.9024748322147651 \n",
      "Epoch 13 | Step 5135 | loss: 0.24905475049612888 | accuracy: 0.9025397157190636 \n",
      "Epoch 13 | Step 5136 | loss: 0.2487561036398011 | accuracy: 0.90265625 \n",
      "Epoch 13 | Step 5137 | loss: 0.2491393450932247 | accuracy: 0.9024605481727574 \n",
      "Epoch 13 | Step 5138 | loss: 0.24893285173750057 | accuracy: 0.9026283112582781 \n",
      "Epoch 13 | Step 5139 | loss: 0.2487874796534133 | accuracy: 0.9027949669966997 \n",
      "Epoch 13 | Step 5140 | loss: 0.24881391337533507 | accuracy: 0.9027035361842105 \n",
      "Epoch 13 | Step 5141 | loss: 0.24869147204473346 | accuracy: 0.9027151639344262 \n",
      "Epoch 13 | Step 5142 | loss: 0.24872771614030273 | accuracy: 0.9026756535947712 \n",
      "Epoch 13 | Step 5143 | loss: 0.2495263483654402 | accuracy: 0.9023819218241043 \n",
      "Epoch 13 | Step 5144 | loss: 0.2493454160579998 | accuracy: 0.902546672077922 \n",
      "Epoch 13 | Step 5145 | loss: 0.24912863210277628 | accuracy: 0.9025586569579288 \n",
      "Epoch 13 | Step 5146 | loss: 0.24933702217475037 | accuracy: 0.9025201612903225 \n",
      "Epoch 13 | Step 5147 | loss: 0.2493365243843895 | accuracy: 0.9025823954983923 \n",
      "Epoch 13 | Step 5148 | loss: 0.2493227397640926 | accuracy: 0.9025941506410257 \n",
      "Epoch 13 | Step 5149 | loss: 0.2491057927187637 | accuracy: 0.9027555910543131 \n",
      "Epoch 13 | Step 5150 | loss: 0.24937050554687787 | accuracy: 0.9026174363057324 \n",
      "Epoch 13 | Step 5151 | loss: 0.24987305249013575 | accuracy: 0.9024305555555555 \n",
      "Epoch 13 | Step 5152 | loss: 0.24974789949063236 | accuracy: 0.9024426424050633 \n",
      "Epoch 13 | Step 5153 | loss: 0.24953346107190316 | accuracy: 0.9025532334384858 \n",
      "Epoch 13 | Step 5154 | loss: 0.24971265085744385 | accuracy: 0.9024665880503144 \n",
      "Epoch 13 | Step 5155 | loss: 0.2496221002226337 | accuracy: 0.9025764106583072 \n",
      "Epoch 13 | Step 5156 | loss: 0.2494502435205502 | accuracy: 0.90263671875 \n",
      "Epoch 13 | Step 5157 | loss: 0.24950831448456187 | accuracy: 0.9026479750778816 \n",
      "Epoch 13 | Step 5158 | loss: 0.24987741839719094 | accuracy: 0.9026591614906833 \n",
      "Epoch 13 | Step 5159 | loss: 0.24971142035242921 | accuracy: 0.902767027863777 \n",
      "Epoch 13 | Step 5160 | loss: 0.24943250861524777 | accuracy: 0.9029224537037037 \n",
      "Epoch 13 | Step 5161 | loss: 0.24960057334257985 | accuracy: 0.9028846153846154 \n",
      "Epoch 13 | Step 5162 | loss: 0.24942754686701496 | accuracy: 0.9029907975460123 \n",
      "Epoch 13 | Step 5163 | loss: 0.24957019940519895 | accuracy: 0.9028574159021406 \n",
      "Epoch 13 | Step 5164 | loss: 0.24960463141977038 | accuracy: 0.9028201219512195 \n",
      "Epoch 13 | Step 5165 | loss: 0.2501107208136365 | accuracy: 0.9024506079027356 \n",
      "Epoch 13 | Step 5166 | loss: 0.25000971151572265 | accuracy: 0.9025568181818182 \n",
      "Epoch 13 | Step 5167 | loss: 0.2498654569428851 | accuracy: 0.9025207703927492 \n",
      "Epoch 13 | Step 5168 | loss: 0.2498086832059792 | accuracy: 0.9025320030120482 \n",
      "Epoch 13 | Step 5169 | loss: 0.24971138717265437 | accuracy: 0.9025900900900901 \n",
      "Epoch 13 | Step 5170 | loss: 0.24985663916268727 | accuracy: 0.9024607035928144 \n",
      "Epoch 13 | Step 5171 | loss: 0.24953804156228657 | accuracy: 0.9025652985074627 \n",
      "Epoch 13 | Step 5172 | loss: 0.24937089490482472 | accuracy: 0.9026227678571429 \n",
      "Epoch 13 | Step 5173 | loss: 0.24945044882308107 | accuracy: 0.9025871661721068 \n",
      "Epoch 13 | Step 5174 | loss: 0.2495249040953857 | accuracy: 0.9025980029585798 \n",
      "Epoch 13 | Step 5175 | loss: 0.24943220520881051 | accuracy: 0.9026548672566371 \n",
      "Epoch 13 | Step 5176 | loss: 0.2491103069966328 | accuracy: 0.9027573529411764 \n",
      "Epoch 13 | Step 5177 | loss: 0.2489356121752966 | accuracy: 0.9027675953079178 \n",
      "Epoch 13 | Step 5178 | loss: 0.24882464452880845 | accuracy: 0.9028691520467836 \n",
      "Epoch 13 | Step 5179 | loss: 0.24861326216348037 | accuracy: 0.9030156705539358 \n",
      "Epoch 13 | Step 5180 | loss: 0.24840130698109067 | accuracy: 0.9030704941860465 \n",
      "Epoch 13 | Step 5181 | loss: 0.24851172469232372 | accuracy: 0.9029438405797101 \n",
      "Epoch 13 | Step 5182 | loss: 0.2484740400202355 | accuracy: 0.9029533959537572 \n",
      "Epoch 13 | Step 5183 | loss: 0.24816208706379603 | accuracy: 0.9030529538904899 \n",
      "Epoch 13 | Step 5184 | loss: 0.24854499613330946 | accuracy: 0.9028825431034483 \n",
      "Epoch 13 | Step 5185 | loss: 0.248468923940187 | accuracy: 0.9028921919770774 \n",
      "Epoch 13 | Step 5186 | loss: 0.24836136986102356 | accuracy: 0.9029910714285714 \n",
      "Epoch 13 | Step 5187 | loss: 0.24817165208083591 | accuracy: 0.9031784188034188 \n",
      "Epoch 13 | Step 5188 | loss: 0.24831058764406883 | accuracy: 0.9031427556818182 \n",
      "Epoch 13 | Step 5189 | loss: 0.24811885776077364 | accuracy: 0.9031958215297451 \n",
      "Epoch 13 | Step 5190 | loss: 0.24788617727867607 | accuracy: 0.9032927259887006 \n",
      "Epoch 13 | Step 5191 | loss: 0.24771408386213659 | accuracy: 0.9033450704225352 \n",
      "Epoch 13 | Step 5192 | loss: 0.24749962158835986 | accuracy: 0.9034410112359551 \n",
      "Epoch 13 | Step 5193 | loss: 0.24756486803627129 | accuracy: 0.9035364145658263 \n",
      "Epoch 13 | Step 5194 | loss: 0.24757675012812913 | accuracy: 0.9034567039106145 \n",
      "Epoch 13 | Step 5195 | loss: 0.2473203145320367 | accuracy: 0.903508008356546 \n",
      "Epoch 13 | Step 5196 | loss: 0.24704738199296905 | accuracy: 0.9036892361111111 \n",
      "Epoch 13 | Step 5197 | loss: 0.24721580345462213 | accuracy: 0.9035664819944599 \n",
      "Epoch 13 | Step 5198 | loss: 0.2470983509900489 | accuracy: 0.9036602209944752 \n",
      "Epoch 13 | Step 5199 | loss: 0.24702093635298314 | accuracy: 0.9036673553719008 \n",
      "Epoch 13 | Step 5200 | loss: 0.24696983509584422 | accuracy: 0.9036744505494505 \n",
      "Epoch 13 | Step 5201 | loss: 0.2467009356781226 | accuracy: 0.9038527397260274 \n",
      "Epoch 13 | Step 5202 | loss: 0.24668135491958063 | accuracy: 0.9036885245901639 \n",
      "Epoch 13 | Step 5203 | loss: 0.24654837555635184 | accuracy: 0.9037806539509536 \n",
      "Epoch 13 | Step 5204 | loss: 0.24636998138916863 | accuracy: 0.9038298233695652 \n",
      "Epoch 13 | Step 5205 | loss: 0.2465535352021696 | accuracy: 0.9038363821138211 \n",
      "Epoch 13 | Step 5206 | loss: 0.24676516907843365 | accuracy: 0.9036739864864864 \n",
      "Epoch 13 | Step 5207 | loss: 0.24689577208616 | accuracy: 0.9037230458221024 \n",
      "Epoch 13 | Step 5208 | loss: 0.24755836148015253 | accuracy: 0.903351814516129 \n",
      "Epoch 13 | Step 5209 | loss: 0.2475866190190288 | accuracy: 0.9033595844504021 \n",
      "Epoch 13 | Step 5210 | loss: 0.2474364913043808 | accuracy: 0.9033673128342246 \n",
      "Epoch 13 | Step 5211 | loss: 0.24723215530316017 | accuracy: 0.9035 \n",
      "Epoch 13 | Step 5212 | loss: 0.24715581435234604 | accuracy: 0.903548869680851 \n",
      "Epoch 13 | Step 5213 | loss: 0.2470983304972672 | accuracy: 0.9035145888594165 \n",
      "Epoch 13 | Step 5214 | loss: 0.24719463968797317 | accuracy: 0.9034391534391535 \n",
      "Epoch 13 | Step 5215 | loss: 0.24693342078093783 | accuracy: 0.9034877968337731 \n",
      "Epoch 13 | Step 5216 | loss: 0.24667543747315263 | accuracy: 0.9036595394736842 \n",
      "Epoch 13 | Step 5217 | loss: 0.24652620338470585 | accuracy: 0.9037073490813649 \n",
      "Epoch 13 | Step 5218 | loss: 0.24632247449605857 | accuracy: 0.9037958115183246 \n",
      "Epoch 13 | Step 5219 | loss: 0.24624315909944047 | accuracy: 0.9038430156657964 \n",
      "Epoch 13 | Step 5220 | loss: 0.24621177823670812 | accuracy: 0.9038492838541666 \n",
      "Epoch 13 | Step 5221 | loss: 0.24652879882555484 | accuracy: 0.9037337662337662 \n",
      "Epoch 13 | Step 5222 | loss: 0.246767488110405 | accuracy: 0.9036188471502591 \n",
      "Epoch 13 | Step 5223 | loss: 0.24685668354271592 | accuracy: 0.9036660206718347 \n",
      "Epoch 13 | Step 5224 | loss: 0.24669232689919526 | accuracy: 0.9037934922680413 \n",
      "Epoch 13 | Step 5225 | loss: 0.24683597632192997 | accuracy: 0.9036793059125964 \n",
      "Epoch 13 | Step 5226 | loss: 0.24679338956872604 | accuracy: 0.9037259615384615 \n",
      "Epoch 13 | Step 5227 | loss: 0.24692746038403335 | accuracy: 0.9036924552429667 \n",
      "Epoch 13 | Step 5228 | loss: 0.2467328130020473 | accuracy: 0.9038185586734694 \n",
      "Epoch 13 | Step 5229 | loss: 0.2465241625905035 | accuracy: 0.9038645038167938 \n",
      "Epoch 13 | Step 5230 | loss: 0.2467313348528393 | accuracy: 0.9036722715736041 \n",
      "Epoch 13 | Step 5231 | loss: 0.2466101110547402 | accuracy: 0.9036787974683544 \n",
      "Epoch 13 | Step 5232 | loss: 0.24654065266326805 | accuracy: 0.9037247474747475 \n",
      "Epoch 13 | Step 5233 | loss: 0.24663591991068415 | accuracy: 0.9036523929471033 \n",
      "Epoch 13 | Step 5234 | loss: 0.24689871460274218 | accuracy: 0.9034233668341709 \n",
      "Epoch 13 | Step 5235 | loss: 0.24670267357189835 | accuracy: 0.9035087719298246 \n",
      "Epoch 13 | Step 5236 | loss: 0.24695095134899003 | accuracy: 0.9034375 \n",
      "Epoch 13 | Step 5237 | loss: 0.246939931817334 | accuracy: 0.9034834788029925 \n",
      "Epoch 13 | Step 5238 | loss: 0.247352375486745 | accuracy: 0.9032960199004975 \n",
      "Epoch 13 | Step 5239 | loss: 0.24700428761782167 | accuracy: 0.9034504149451149 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.5311283469200134 | accuracy: 0.765625 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.5484193861484528 | accuracy: 0.765625 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.48551417390505475 | accuracy: 0.7760416666666666 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.47319305688142776 | accuracy: 0.78515625 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4792061626911163 | accuracy: 0.784375 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4671684801578522 | accuracy: 0.7864583333333334 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.45649756278310505 | accuracy: 0.7924107142857143 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.44609520956873894 | accuracy: 0.796875 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.44009796116087174 | accuracy: 0.8020833333333334 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.44191079437732694 | accuracy: 0.80625 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4456731947985562 | accuracy: 0.8082386363636364 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4374266614516576 | accuracy: 0.8125 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4429600559748136 | accuracy: 0.8076923076923077 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4481357421193804 | accuracy: 0.8069196428571429 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4366681436697642 | accuracy: 0.8135416666666667 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.43544359877705574 | accuracy: 0.8154296875 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4475711128290962 | accuracy: 0.8115808823529411 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4434215757581923 | accuracy: 0.8116319444444444 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4412568917399959 | accuracy: 0.8125 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4372881829738617 | accuracy: 0.81484375 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.43742319090025766 | accuracy: 0.8139880952380952 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4322128214619376 | accuracy: 0.8160511363636364 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.43421102606731915 | accuracy: 0.8145380434782609 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4339570179581642 | accuracy: 0.814453125 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4381830620765686 | accuracy: 0.81125 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4303930023541817 | accuracy: 0.8137019230769231 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.42869283314104434 | accuracy: 0.8159722222222222 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.42389773364577976 | accuracy: 0.8180803571428571 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.42624334014695264 | accuracy: 0.8173491379310345 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.427433180809021 | accuracy: 0.8161458333333333 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4220832595902105 | accuracy: 0.8190524193548387 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4163902197033167 | accuracy: 0.822265625 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4142633288195639 | accuracy: 0.8243371212121212 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.423699471003869 | accuracy: 0.8221507352941176 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4224458966936384 | accuracy: 0.8214285714285714 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4179472169942326 | accuracy: 0.8233506944444444 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.41969194122262904 | accuracy: 0.823902027027027 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.41968634724617004 | accuracy: 0.8227796052631579 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.417842896320881 | accuracy: 0.8237179487179487 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.420770350843668 | accuracy: 0.821484375 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4235044841359301 | accuracy: 0.8201219512195121 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4214814809106645 | accuracy: 0.8214285714285714 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4210061361623365 | accuracy: 0.8212209302325582 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.42344520037824457 | accuracy: 0.8199573863636364 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4268963058789571 | accuracy: 0.8186443236139086 \n",
      "Epoch 14 | Step 5240 | loss: 0.17077237367630005 | accuracy: 0.96875 \n",
      "Epoch 14 | Step 5241 | loss: 0.27258796989917755 | accuracy: 0.90625 \n",
      "Epoch 14 | Step 5242 | loss: 0.24112939834594727 | accuracy: 0.9166666666666666 \n",
      "Epoch 14 | Step 5243 | loss: 0.238789614289999 | accuracy: 0.9140625 \n",
      "Epoch 14 | Step 5244 | loss: 0.23656332790851592 | accuracy: 0.909375 \n",
      "Epoch 14 | Step 5245 | loss: 0.2536945367852847 | accuracy: 0.8984375 \n",
      "Epoch 14 | Step 5246 | loss: 0.2574400412184851 | accuracy: 0.9040178571428571 \n",
      "Epoch 14 | Step 5247 | loss: 0.274720286950469 | accuracy: 0.900390625 \n",
      "Epoch 14 | Step 5248 | loss: 0.26716941595077515 | accuracy: 0.9045138888888888 \n",
      "Epoch 14 | Step 5249 | loss: 0.27761130332946776 | accuracy: 0.89375 \n",
      "Epoch 14 | Step 5250 | loss: 0.2757604176347906 | accuracy: 0.890625 \n",
      "Epoch 14 | Step 5251 | loss: 0.28153004745642346 | accuracy: 0.88671875 \n",
      "Epoch 14 | Step 5252 | loss: 0.2739506375331145 | accuracy: 0.890625 \n",
      "Epoch 14 | Step 5253 | loss: 0.27661191884960445 | accuracy: 0.8895089285714286 \n",
      "Epoch 14 | Step 5254 | loss: 0.26919014354546866 | accuracy: 0.89375 \n",
      "Epoch 14 | Step 5255 | loss: 0.2592605035752058 | accuracy: 0.8994140625 \n",
      "Epoch 14 | Step 5256 | loss: 0.2553354501724243 | accuracy: 0.9025735294117647 \n",
      "Epoch 14 | Step 5257 | loss: 0.25310569090975654 | accuracy: 0.9036458333333334 \n",
      "Epoch 14 | Step 5258 | loss: 0.2506709208613948 | accuracy: 0.9046052631578947 \n",
      "Epoch 14 | Step 5259 | loss: 0.2532038420438767 | accuracy: 0.9046875 \n",
      "Epoch 14 | Step 5260 | loss: 0.2531267404556275 | accuracy: 0.9040178571428571 \n",
      "Epoch 14 | Step 5261 | loss: 0.25247567621144384 | accuracy: 0.9041193181818182 \n",
      "Epoch 14 | Step 5262 | loss: 0.2502193003892899 | accuracy: 0.9042119565217391 \n",
      "Epoch 14 | Step 5263 | loss: 0.24524763536949956 | accuracy: 0.9069010416666666 \n",
      "Epoch 14 | Step 5264 | loss: 0.24222370326519016 | accuracy: 0.908125 \n",
      "Epoch 14 | Step 5265 | loss: 0.24271270002310097 | accuracy: 0.9080528846153846 \n",
      "Epoch 14 | Step 5266 | loss: 0.2426403931997441 | accuracy: 0.9079861111111112 \n",
      "Epoch 14 | Step 5267 | loss: 0.23753522948494982 | accuracy: 0.9107142857142857 \n",
      "Epoch 14 | Step 5268 | loss: 0.2355927159560138 | accuracy: 0.9094827586206896 \n",
      "Epoch 14 | Step 5269 | loss: 0.236191916714112 | accuracy: 0.909375 \n",
      "Epoch 14 | Step 5270 | loss: 0.2362044052250924 | accuracy: 0.9102822580645161 \n",
      "Epoch 14 | Step 5271 | loss: 0.23663004650734368 | accuracy: 0.91015625 \n",
      "Epoch 14 | Step 5272 | loss: 0.24119095255931222 | accuracy: 0.9086174242424242 \n",
      "Epoch 14 | Step 5273 | loss: 0.24221697252462893 | accuracy: 0.9090073529411765 \n",
      "Epoch 14 | Step 5274 | loss: 0.24126687284026826 | accuracy: 0.9089285714285714 \n",
      "Epoch 14 | Step 5275 | loss: 0.24300395593874985 | accuracy: 0.9084201388888888 \n",
      "Epoch 14 | Step 5276 | loss: 0.24057569072858706 | accuracy: 0.9096283783783784 \n",
      "Epoch 14 | Step 5277 | loss: 0.23942169998037188 | accuracy: 0.9103618421052632 \n",
      "Epoch 14 | Step 5278 | loss: 0.23770358719122717 | accuracy: 0.9110576923076923 \n",
      "Epoch 14 | Step 5279 | loss: 0.2375294966623187 | accuracy: 0.911328125 \n",
      "Epoch 14 | Step 5280 | loss: 0.2372263377396072 | accuracy: 0.911204268292683 \n",
      "Epoch 14 | Step 5281 | loss: 0.2370290115830444 | accuracy: 0.9114583333333334 \n",
      "Epoch 14 | Step 5282 | loss: 0.23516612673221632 | accuracy: 0.9120639534883721 \n",
      "Epoch 14 | Step 5283 | loss: 0.2336302005093206 | accuracy: 0.9122869318181818 \n",
      "Epoch 14 | Step 5284 | loss: 0.2354590712322129 | accuracy: 0.9114583333333334 \n",
      "Epoch 14 | Step 5285 | loss: 0.23600444958909697 | accuracy: 0.9106657608695652 \n",
      "Epoch 14 | Step 5286 | loss: 0.23491316637460222 | accuracy: 0.910904255319149 \n",
      "Epoch 14 | Step 5287 | loss: 0.23601239904140434 | accuracy: 0.91015625 \n",
      "Epoch 14 | Step 5288 | loss: 0.23391933115769406 | accuracy: 0.9113520408163265 \n",
      "Epoch 14 | Step 5289 | loss: 0.23469310954213143 | accuracy: 0.91125 \n",
      "Epoch 14 | Step 5290 | loss: 0.23777107237016454 | accuracy: 0.9099264705882353 \n",
      "Epoch 14 | Step 5291 | loss: 0.24037275420358548 | accuracy: 0.9086538461538461 \n",
      "Epoch 14 | Step 5292 | loss: 0.23946731059618717 | accuracy: 0.9089033018867925 \n",
      "Epoch 14 | Step 5293 | loss: 0.23887436271265702 | accuracy: 0.9091435185185185 \n",
      "Epoch 14 | Step 5294 | loss: 0.2385513344948942 | accuracy: 0.9096590909090909 \n",
      "Epoch 14 | Step 5295 | loss: 0.24062047486326524 | accuracy: 0.9093191964285714 \n",
      "Epoch 14 | Step 5296 | loss: 0.23975192807745516 | accuracy: 0.9100877192982456 \n",
      "Epoch 14 | Step 5297 | loss: 0.24100286834712686 | accuracy: 0.9092133620689655 \n",
      "Epoch 14 | Step 5298 | loss: 0.24104533395019628 | accuracy: 0.909957627118644 \n",
      "Epoch 14 | Step 5299 | loss: 0.24236318704982598 | accuracy: 0.9091145833333333 \n",
      "Epoch 14 | Step 5300 | loss: 0.24226115265342055 | accuracy: 0.9085553278688525 \n",
      "Epoch 14 | Step 5301 | loss: 0.24208382769457756 | accuracy: 0.9085181451612904 \n",
      "Epoch 14 | Step 5302 | loss: 0.24190871216475018 | accuracy: 0.908234126984127 \n",
      "Epoch 14 | Step 5303 | loss: 0.24005007441155612 | accuracy: 0.9091796875 \n",
      "Epoch 14 | Step 5304 | loss: 0.24055143755215866 | accuracy: 0.9091346153846154 \n",
      "Epoch 14 | Step 5305 | loss: 0.23871387800935542 | accuracy: 0.9095643939393939 \n",
      "Epoch 14 | Step 5306 | loss: 0.2377213603302614 | accuracy: 0.909981343283582 \n",
      "Epoch 14 | Step 5307 | loss: 0.23736792550805738 | accuracy: 0.9099264705882353 \n",
      "Epoch 14 | Step 5308 | loss: 0.23842651483373364 | accuracy: 0.9089673913043478 \n",
      "Epoch 14 | Step 5309 | loss: 0.23943278289266995 | accuracy: 0.9089285714285714 \n",
      "Epoch 14 | Step 5310 | loss: 0.2404930798310629 | accuracy: 0.9082306338028169 \n",
      "Epoch 14 | Step 5311 | loss: 0.23962180657933155 | accuracy: 0.9086371527777778 \n",
      "Epoch 14 | Step 5312 | loss: 0.24037747687264666 | accuracy: 0.9083904109589042 \n",
      "Epoch 14 | Step 5313 | loss: 0.2408969983257152 | accuracy: 0.9081503378378378 \n",
      "Epoch 14 | Step 5314 | loss: 0.2419122279683749 | accuracy: 0.9077083333333333 \n",
      "Epoch 14 | Step 5315 | loss: 0.24112338092374175 | accuracy: 0.9078947368421053 \n",
      "Epoch 14 | Step 5316 | loss: 0.2422900942045373 | accuracy: 0.9074675324675324 \n",
      "Epoch 14 | Step 5317 | loss: 0.24142006240212 | accuracy: 0.9078525641025641 \n",
      "Epoch 14 | Step 5318 | loss: 0.24064716027130054 | accuracy: 0.9076344936708861 \n",
      "Epoch 14 | Step 5319 | loss: 0.24031677590683104 | accuracy: 0.9078125 \n",
      "Epoch 14 | Step 5320 | loss: 0.24127897592606368 | accuracy: 0.9076003086419753 \n",
      "Epoch 14 | Step 5321 | loss: 0.24028979814270648 | accuracy: 0.9079649390243902 \n",
      "Epoch 14 | Step 5322 | loss: 0.24062911600592624 | accuracy: 0.9079442771084337 \n",
      "Epoch 14 | Step 5323 | loss: 0.2407088583956162 | accuracy: 0.9077380952380952 \n",
      "Epoch 14 | Step 5324 | loss: 0.24099571275360443 | accuracy: 0.9079044117647059 \n",
      "Epoch 14 | Step 5325 | loss: 0.23979304410343946 | accuracy: 0.9084302325581395 \n",
      "Epoch 14 | Step 5326 | loss: 0.23940857225793533 | accuracy: 0.9085847701149425 \n",
      "Epoch 14 | Step 5327 | loss: 0.23949938038872046 | accuracy: 0.9085582386363636 \n",
      "Epoch 14 | Step 5328 | loss: 0.2392421265164118 | accuracy: 0.9083567415730337 \n",
      "Epoch 14 | Step 5329 | loss: 0.23977925587031576 | accuracy: 0.9081597222222222 \n",
      "Epoch 14 | Step 5330 | loss: 0.23979231330392126 | accuracy: 0.9081387362637363 \n",
      "Epoch 14 | Step 5331 | loss: 0.24182971186288024 | accuracy: 0.9074388586956522 \n",
      "Epoch 14 | Step 5332 | loss: 0.24404633309571974 | accuracy: 0.9067540322580645 \n",
      "Epoch 14 | Step 5333 | loss: 0.24297928342476804 | accuracy: 0.9074135638297872 \n",
      "Epoch 14 | Step 5334 | loss: 0.24199534113469875 | accuracy: 0.9077302631578947 \n",
      "Epoch 14 | Step 5335 | loss: 0.24128121642085412 | accuracy: 0.9078776041666666 \n",
      "Epoch 14 | Step 5336 | loss: 0.2406654031467192 | accuracy: 0.9081829896907216 \n",
      "Epoch 14 | Step 5337 | loss: 0.2419745085038701 | accuracy: 0.9075255102040817 \n",
      "Epoch 14 | Step 5338 | loss: 0.2411384398136476 | accuracy: 0.9083017676767676 \n",
      "Epoch 14 | Step 5339 | loss: 0.2415985020250082 | accuracy: 0.90796875 \n",
      "Epoch 14 | Step 5340 | loss: 0.24147138375752042 | accuracy: 0.9081064356435643 \n",
      "Epoch 14 | Step 5341 | loss: 0.24169108293512287 | accuracy: 0.9077818627450981 \n",
      "Epoch 14 | Step 5342 | loss: 0.24156210904271858 | accuracy: 0.9077669902912622 \n",
      "Epoch 14 | Step 5343 | loss: 0.24189997270989877 | accuracy: 0.9080528846153846 \n",
      "Epoch 14 | Step 5344 | loss: 0.24278477891570047 | accuracy: 0.9077380952380952 \n",
      "Epoch 14 | Step 5345 | loss: 0.24250908526328374 | accuracy: 0.9078714622641509 \n",
      "Epoch 14 | Step 5346 | loss: 0.24272361474337978 | accuracy: 0.9077102803738317 \n",
      "Epoch 14 | Step 5347 | loss: 0.2435955067889558 | accuracy: 0.9072627314814815 \n",
      "Epoch 14 | Step 5348 | loss: 0.24269643788217404 | accuracy: 0.9078268348623854 \n",
      "Epoch 14 | Step 5349 | loss: 0.24242899004708637 | accuracy: 0.9076704545454546 \n",
      "Epoch 14 | Step 5350 | loss: 0.24348484550241953 | accuracy: 0.9070945945945946 \n",
      "Epoch 14 | Step 5351 | loss: 0.24423159918348705 | accuracy: 0.9065290178571429 \n",
      "Epoch 14 | Step 5352 | loss: 0.2437941526285315 | accuracy: 0.9066648230088495 \n",
      "Epoch 14 | Step 5353 | loss: 0.24369856669453152 | accuracy: 0.9065241228070176 \n",
      "Epoch 14 | Step 5354 | loss: 0.24307786219793817 | accuracy: 0.9066576086956522 \n",
      "Epoch 14 | Step 5355 | loss: 0.24252824812870602 | accuracy: 0.9069234913793104 \n",
      "Epoch 14 | Step 5356 | loss: 0.2420214546414522 | accuracy: 0.9071848290598291 \n",
      "Epoch 14 | Step 5357 | loss: 0.24223810124952913 | accuracy: 0.9069120762711864 \n",
      "Epoch 14 | Step 5358 | loss: 0.2427701591318395 | accuracy: 0.9061186974789915 \n",
      "Epoch 14 | Step 5359 | loss: 0.2428839923813939 | accuracy: 0.905859375 \n",
      "Epoch 14 | Step 5360 | loss: 0.24213321094424273 | accuracy: 0.906379132231405 \n",
      "Epoch 14 | Step 5361 | loss: 0.24242774623095012 | accuracy: 0.9058657786885246 \n",
      "Epoch 14 | Step 5362 | loss: 0.24227508642082293 | accuracy: 0.9059959349593496 \n",
      "Epoch 14 | Step 5363 | loss: 0.24329510913981545 | accuracy: 0.9056199596774194 \n",
      "Epoch 14 | Step 5364 | loss: 0.24340549784898757 | accuracy: 0.905375 \n",
      "Epoch 14 | Step 5365 | loss: 0.24266433047633323 | accuracy: 0.9057539682539683 \n",
      "Epoch 14 | Step 5366 | loss: 0.24322411599825686 | accuracy: 0.905388779527559 \n",
      "Epoch 14 | Step 5367 | loss: 0.24281827657250687 | accuracy: 0.9056396484375 \n",
      "Epoch 14 | Step 5368 | loss: 0.2426746354200119 | accuracy: 0.9055232558139535 \n",
      "Epoch 14 | Step 5369 | loss: 0.2428554888528127 | accuracy: 0.9054086538461539 \n",
      "Epoch 14 | Step 5370 | loss: 0.24320914255071233 | accuracy: 0.9052958015267175 \n",
      "Epoch 14 | Step 5371 | loss: 0.2430880693436572 | accuracy: 0.9054214015151515 \n",
      "Epoch 14 | Step 5372 | loss: 0.24256589599794015 | accuracy: 0.9057800751879699 \n",
      "Epoch 14 | Step 5373 | loss: 0.24182064180721097 | accuracy: 0.9060167910447762 \n",
      "Epoch 14 | Step 5374 | loss: 0.2420157571081762 | accuracy: 0.9060185185185186 \n",
      "Epoch 14 | Step 5375 | loss: 0.24238211940973997 | accuracy: 0.9061351102941176 \n",
      "Epoch 14 | Step 5376 | loss: 0.24317318478422442 | accuracy: 0.9057937956204379 \n",
      "Epoch 14 | Step 5377 | loss: 0.24293886184476424 | accuracy: 0.9060235507246377 \n",
      "Epoch 14 | Step 5378 | loss: 0.24347097941225382 | accuracy: 0.9058003597122302 \n",
      "Epoch 14 | Step 5379 | loss: 0.24319245011678764 | accuracy: 0.9058035714285714 \n",
      "Epoch 14 | Step 5380 | loss: 0.24311220799143432 | accuracy: 0.9056959219858155 \n",
      "Epoch 14 | Step 5381 | loss: 0.24280101611790522 | accuracy: 0.9058098591549296 \n",
      "Epoch 14 | Step 5382 | loss: 0.24215945856762933 | accuracy: 0.9060314685314685 \n",
      "Epoch 14 | Step 5383 | loss: 0.2421870636753738 | accuracy: 0.9059244791666666 \n",
      "Epoch 14 | Step 5384 | loss: 0.24186510489932422 | accuracy: 0.9058189655172414 \n",
      "Epoch 14 | Step 5385 | loss: 0.24217039678398877 | accuracy: 0.9060359589041096 \n",
      "Epoch 14 | Step 5386 | loss: 0.24238786025314915 | accuracy: 0.9061437074829932 \n",
      "Epoch 14 | Step 5387 | loss: 0.24229172350385705 | accuracy: 0.9060388513513513 \n",
      "Epoch 14 | Step 5388 | loss: 0.24241345155759145 | accuracy: 0.9060402684563759 \n",
      "Epoch 14 | Step 5389 | loss: 0.24155511101086935 | accuracy: 0.9065625 \n",
      "Epoch 14 | Step 5390 | loss: 0.24165164694091343 | accuracy: 0.9064569536423841 \n",
      "Epoch 14 | Step 5391 | loss: 0.2420574705067434 | accuracy: 0.90625 \n",
      "Epoch 14 | Step 5392 | loss: 0.24266492327054343 | accuracy: 0.9061478758169934 \n",
      "Epoch 14 | Step 5393 | loss: 0.24190989688232348 | accuracy: 0.906351461038961 \n",
      "Epoch 14 | Step 5394 | loss: 0.2413145854588478 | accuracy: 0.9066532258064516 \n",
      "Epoch 14 | Step 5395 | loss: 0.24032817895595843 | accuracy: 0.9071514423076923 \n",
      "Epoch 14 | Step 5396 | loss: 0.24033718048387273 | accuracy: 0.9072452229299363 \n",
      "Epoch 14 | Step 5397 | loss: 0.24001692725887783 | accuracy: 0.9075356012658228 \n",
      "Epoch 14 | Step 5398 | loss: 0.2400402806277545 | accuracy: 0.9073309748427673 \n",
      "Epoch 14 | Step 5399 | loss: 0.2398769985884428 | accuracy: 0.90732421875 \n",
      "Epoch 14 | Step 5400 | loss: 0.2395446786414022 | accuracy: 0.9073175465838509 \n",
      "Epoch 14 | Step 5401 | loss: 0.2396474144892928 | accuracy: 0.9074074074074074 \n",
      "Epoch 14 | Step 5402 | loss: 0.23875362380333473 | accuracy: 0.9077837423312883 \n",
      "Epoch 14 | Step 5403 | loss: 0.23830740085643967 | accuracy: 0.9077743902439024 \n",
      "Epoch 14 | Step 5404 | loss: 0.2382238151900696 | accuracy: 0.9077651515151515 \n",
      "Epoch 14 | Step 5405 | loss: 0.2393699856138373 | accuracy: 0.9073795180722891 \n",
      "Epoch 14 | Step 5406 | loss: 0.23866983382644769 | accuracy: 0.9076534431137725 \n",
      "Epoch 14 | Step 5407 | loss: 0.23838018342143014 | accuracy: 0.9074590773809523 \n",
      "Epoch 14 | Step 5408 | loss: 0.23975994160189432 | accuracy: 0.9071745562130178 \n",
      "Epoch 14 | Step 5409 | loss: 0.23970185001106822 | accuracy: 0.9072610294117647 \n",
      "Epoch 14 | Step 5410 | loss: 0.2400548178375813 | accuracy: 0.9071637426900585 \n",
      "Epoch 14 | Step 5411 | loss: 0.24035741951923037 | accuracy: 0.9070675872093024 \n",
      "Epoch 14 | Step 5412 | loss: 0.23930166170776235 | accuracy: 0.9075144508670521 \n",
      "Epoch 14 | Step 5413 | loss: 0.23946184605017476 | accuracy: 0.9074173850574713 \n",
      "Epoch 14 | Step 5414 | loss: 0.23913704003606523 | accuracy: 0.9075 \n",
      "Epoch 14 | Step 5415 | loss: 0.2390009747310118 | accuracy: 0.9076704545454546 \n",
      "Epoch 14 | Step 5416 | loss: 0.23929047584533691 | accuracy: 0.9077507062146892 \n",
      "Epoch 14 | Step 5417 | loss: 0.23926252963837613 | accuracy: 0.9077422752808989 \n",
      "Epoch 14 | Step 5418 | loss: 0.23935167266669885 | accuracy: 0.9078212290502793 \n",
      "Epoch 14 | Step 5419 | loss: 0.23958075245221455 | accuracy: 0.9076388888888889 \n",
      "Epoch 14 | Step 5420 | loss: 0.23905804992051413 | accuracy: 0.9078038674033149 \n",
      "Epoch 14 | Step 5421 | loss: 0.238460857625846 | accuracy: 0.9080528846153846 \n",
      "Epoch 14 | Step 5422 | loss: 0.2381483655158288 | accuracy: 0.90838456284153 \n",
      "Epoch 14 | Step 5423 | loss: 0.2382868883078513 | accuracy: 0.9083729619565217 \n",
      "Epoch 14 | Step 5424 | loss: 0.23831289926090757 | accuracy: 0.9081925675675676 \n",
      "Epoch 14 | Step 5425 | loss: 0.23829416361867742 | accuracy: 0.9080981182795699 \n",
      "Epoch 14 | Step 5426 | loss: 0.23842462331534706 | accuracy: 0.9081717914438503 \n",
      "Epoch 14 | Step 5427 | loss: 0.2385418193930007 | accuracy: 0.9082446808510638 \n",
      "Epoch 14 | Step 5428 | loss: 0.23797483821079213 | accuracy: 0.9083994708994709 \n",
      "Epoch 14 | Step 5429 | loss: 0.23807881874473472 | accuracy: 0.9083059210526315 \n",
      "Epoch 14 | Step 5430 | loss: 0.23824453533319903 | accuracy: 0.9082951570680629 \n",
      "Epoch 14 | Step 5431 | loss: 0.23843762488104403 | accuracy: 0.908203125 \n",
      "Epoch 14 | Step 5432 | loss: 0.23900316424011567 | accuracy: 0.9080310880829016 \n",
      "Epoch 14 | Step 5433 | loss: 0.23857003266049415 | accuracy: 0.9082635309278351 \n",
      "Epoch 14 | Step 5434 | loss: 0.23886311955941028 | accuracy: 0.9080128205128205 \n",
      "Epoch 14 | Step 5435 | loss: 0.23890898308279562 | accuracy: 0.9080038265306123 \n",
      "Epoch 14 | Step 5436 | loss: 0.23913418195271854 | accuracy: 0.9076776649746193 \n",
      "Epoch 14 | Step 5437 | loss: 0.2393595790772727 | accuracy: 0.907354797979798 \n",
      "Epoch 14 | Step 5438 | loss: 0.23981198720896063 | accuracy: 0.9071922110552764 \n",
      "Epoch 14 | Step 5439 | loss: 0.23973655804991723 | accuracy: 0.9071875 \n",
      "Epoch 14 | Step 5440 | loss: 0.24019322051337702 | accuracy: 0.9067941542288557 \n",
      "Epoch 14 | Step 5441 | loss: 0.24040592631491103 | accuracy: 0.9066367574257426 \n",
      "Epoch 14 | Step 5442 | loss: 0.24013048234244286 | accuracy: 0.9067887931034483 \n",
      "Epoch 14 | Step 5443 | loss: 0.24000859625783622 | accuracy: 0.9067861519607843 \n",
      "Epoch 14 | Step 5444 | loss: 0.2400936007499695 | accuracy: 0.9067073170731708 \n",
      "Epoch 14 | Step 5445 | loss: 0.24012110461887803 | accuracy: 0.9067050970873787 \n",
      "Epoch 14 | Step 5446 | loss: 0.23981301076170328 | accuracy: 0.9067783816425121 \n",
      "Epoch 14 | Step 5447 | loss: 0.23943700132748255 | accuracy: 0.9068509615384616 \n",
      "Epoch 14 | Step 5448 | loss: 0.239520967790955 | accuracy: 0.9066238038277512 \n",
      "Epoch 14 | Step 5449 | loss: 0.2390223878480139 | accuracy: 0.9068452380952381 \n",
      "Epoch 14 | Step 5450 | loss: 0.238831367467252 | accuracy: 0.9070645734597157 \n",
      "Epoch 14 | Step 5451 | loss: 0.2392681230492187 | accuracy: 0.9069870283018868 \n",
      "Epoch 14 | Step 5452 | loss: 0.23868774426794948 | accuracy: 0.9072769953051644 \n",
      "Epoch 14 | Step 5453 | loss: 0.23850233236623702 | accuracy: 0.907491238317757 \n",
      "Epoch 14 | Step 5454 | loss: 0.2389792541778365 | accuracy: 0.9074127906976744 \n",
      "Epoch 14 | Step 5455 | loss: 0.2395212669270458 | accuracy: 0.9073350694444444 \n",
      "Epoch 14 | Step 5456 | loss: 0.23988121140250412 | accuracy: 0.9073300691244239 \n",
      "Epoch 14 | Step 5457 | loss: 0.2395718214230253 | accuracy: 0.9073967889908257 \n",
      "Epoch 14 | Step 5458 | loss: 0.2395789695725049 | accuracy: 0.9072488584474886 \n",
      "Epoch 14 | Step 5459 | loss: 0.23965919061817906 | accuracy: 0.90703125 \n",
      "Epoch 14 | Step 5460 | loss: 0.23929119423638642 | accuracy: 0.9071691176470589 \n",
      "Epoch 14 | Step 5461 | loss: 0.2389428776328091 | accuracy: 0.9073761261261262 \n",
      "Epoch 14 | Step 5462 | loss: 0.23906820688413397 | accuracy: 0.9073710762331838 \n",
      "Epoch 14 | Step 5463 | loss: 0.23888170250159288 | accuracy: 0.9075055803571429 \n",
      "Epoch 14 | Step 5464 | loss: 0.23915712803602218 | accuracy: 0.9074305555555555 \n",
      "Epoch 14 | Step 5465 | loss: 0.23929288188836215 | accuracy: 0.9074253318584071 \n",
      "Epoch 14 | Step 5466 | loss: 0.23929287923196338 | accuracy: 0.907351321585903 \n",
      "Epoch 14 | Step 5467 | loss: 0.23929055574301042 | accuracy: 0.9074150219298246 \n",
      "Epoch 14 | Step 5468 | loss: 0.23888305288345013 | accuracy: 0.9076146288209607 \n",
      "Epoch 14 | Step 5469 | loss: 0.23873806573126627 | accuracy: 0.9076766304347826 \n",
      "Epoch 14 | Step 5470 | loss: 0.23907048829319158 | accuracy: 0.9074675324675324 \n",
      "Epoch 14 | Step 5471 | loss: 0.23881071192565664 | accuracy: 0.9075296336206896 \n",
      "Epoch 14 | Step 5472 | loss: 0.23884143462892254 | accuracy: 0.9073900214592274 \n",
      "Epoch 14 | Step 5473 | loss: 0.23889451770064157 | accuracy: 0.9073183760683761 \n",
      "Epoch 14 | Step 5474 | loss: 0.23860421646782692 | accuracy: 0.9075797872340425 \n",
      "Epoch 14 | Step 5475 | loss: 0.23866717817293384 | accuracy: 0.9076403601694916 \n",
      "Epoch 14 | Step 5476 | loss: 0.2390723264607196 | accuracy: 0.9075026371308017 \n",
      "Epoch 14 | Step 5477 | loss: 0.2394925390659761 | accuracy: 0.9073660714285714 \n",
      "Epoch 14 | Step 5478 | loss: 0.23911526577866726 | accuracy: 0.9074267782426778 \n",
      "Epoch 14 | Step 5479 | loss: 0.2387715135080119 | accuracy: 0.9075520833333334 \n",
      "Epoch 14 | Step 5480 | loss: 0.23895792573443092 | accuracy: 0.9074818464730291 \n",
      "Epoch 14 | Step 5481 | loss: 0.2390105117512636 | accuracy: 0.9074767561983471 \n",
      "Epoch 14 | Step 5482 | loss: 0.23888189210690589 | accuracy: 0.9075360082304527 \n",
      "Epoch 14 | Step 5483 | loss: 0.23826316084529534 | accuracy: 0.9077868852459017 \n",
      "Epoch 14 | Step 5484 | loss: 0.23780606468113102 | accuracy: 0.9080357142857143 \n",
      "Epoch 14 | Step 5485 | loss: 0.2376076501559436 | accuracy: 0.9080919715447154 \n",
      "Epoch 14 | Step 5486 | loss: 0.23722981381030217 | accuracy: 0.908211032388664 \n",
      "Epoch 14 | Step 5487 | loss: 0.23740692136268463 | accuracy: 0.908203125 \n",
      "Epoch 14 | Step 5488 | loss: 0.23731427074196826 | accuracy: 0.9083207831325302 \n",
      "Epoch 14 | Step 5489 | loss: 0.23708972609043122 | accuracy: 0.9085 \n",
      "Epoch 14 | Step 5490 | loss: 0.23723298691183448 | accuracy: 0.9083665338645418 \n",
      "Epoch 14 | Step 5491 | loss: 0.23719386224235808 | accuracy: 0.9082961309523809 \n",
      "Epoch 14 | Step 5492 | loss: 0.23716157197716678 | accuracy: 0.9082880434782609 \n",
      "Epoch 14 | Step 5493 | loss: 0.23714659327831794 | accuracy: 0.9082185039370079 \n",
      "Epoch 14 | Step 5494 | loss: 0.236854721401252 | accuracy: 0.9083946078431373 \n",
      "Epoch 14 | Step 5495 | loss: 0.2368930540396832 | accuracy: 0.9083251953125 \n",
      "Epoch 14 | Step 5496 | loss: 0.2368748860020582 | accuracy: 0.9082563229571985 \n",
      "Epoch 14 | Step 5497 | loss: 0.23702823301387388 | accuracy: 0.908187984496124 \n",
      "Epoch 14 | Step 5498 | loss: 0.2367984017925373 | accuracy: 0.9082408301158301 \n",
      "Epoch 14 | Step 5499 | loss: 0.23672046655645737 | accuracy: 0.9083533653846154 \n",
      "Epoch 14 | Step 5500 | loss: 0.23650226231050675 | accuracy: 0.9085249042145593 \n",
      "Epoch 14 | Step 5501 | loss: 0.23692296269058272 | accuracy: 0.9081583969465649 \n",
      "Epoch 14 | Step 5502 | loss: 0.23682657819057146 | accuracy: 0.9081511406844106 \n",
      "Epoch 14 | Step 5503 | loss: 0.2366689478583408 | accuracy: 0.9082623106060606 \n",
      "Epoch 14 | Step 5504 | loss: 0.23653511826722126 | accuracy: 0.908254716981132 \n",
      "Epoch 14 | Step 5505 | loss: 0.23646086241517747 | accuracy: 0.9083646616541353 \n",
      "Epoch 14 | Step 5506 | loss: 0.23617969269163153 | accuracy: 0.9084737827715356 \n",
      "Epoch 14 | Step 5507 | loss: 0.23652857486436615 | accuracy: 0.9082322761194029 \n",
      "Epoch 14 | Step 5508 | loss: 0.23646675083495428 | accuracy: 0.9081668215613383 \n",
      "Epoch 14 | Step 5509 | loss: 0.23654885054738434 | accuracy: 0.9080439814814815 \n",
      "Epoch 14 | Step 5510 | loss: 0.23656782683851094 | accuracy: 0.9079797047970479 \n",
      "Epoch 14 | Step 5511 | loss: 0.23646988544393988 | accuracy: 0.9081456801470589 \n",
      "Epoch 14 | Step 5512 | loss: 0.2364767345535013 | accuracy: 0.9082532051282052 \n",
      "Epoch 14 | Step 5513 | loss: 0.23671861384471837 | accuracy: 0.9083029197080292 \n",
      "Epoch 14 | Step 5514 | loss: 0.23649505431001835 | accuracy: 0.9082954545454546 \n",
      "Epoch 14 | Step 5515 | loss: 0.2368411302998446 | accuracy: 0.9081182065217391 \n",
      "Epoch 14 | Step 5516 | loss: 0.23657781004044984 | accuracy: 0.9081678700361011 \n",
      "Epoch 14 | Step 5517 | loss: 0.23633877504214967 | accuracy: 0.9083295863309353 \n",
      "Epoch 14 | Step 5518 | loss: 0.23615702741034997 | accuracy: 0.9084341397849462 \n",
      "Epoch 14 | Step 5519 | loss: 0.23620104544929096 | accuracy: 0.9083705357142857 \n",
      "Epoch 14 | Step 5520 | loss: 0.23611009746683875 | accuracy: 0.9084185943060499 \n",
      "Epoch 14 | Step 5521 | loss: 0.23567156879403067 | accuracy: 0.9086325354609929 \n",
      "Epoch 14 | Step 5522 | loss: 0.23561926796874394 | accuracy: 0.9085689045936396 \n",
      "Epoch 14 | Step 5523 | loss: 0.23526845190306783 | accuracy: 0.9087808098591549 \n",
      "Epoch 14 | Step 5524 | loss: 0.23516912334843687 | accuracy: 0.9087719298245615 \n",
      "Epoch 14 | Step 5525 | loss: 0.2347190475964046 | accuracy: 0.9089270104895105 \n",
      "Epoch 14 | Step 5526 | loss: 0.23475202346928029 | accuracy: 0.9089176829268293 \n",
      "Epoch 14 | Step 5527 | loss: 0.2342967549080236 | accuracy: 0.9091254340277778 \n",
      "Epoch 14 | Step 5528 | loss: 0.23502883477503866 | accuracy: 0.9090614186851211 \n",
      "Epoch 14 | Step 5529 | loss: 0.23499797862665406 | accuracy: 0.9091056034482758 \n",
      "Epoch 14 | Step 5530 | loss: 0.2353683887529619 | accuracy: 0.9089347079037801 \n",
      "Epoch 14 | Step 5531 | loss: 0.23526392685734246 | accuracy: 0.9090325342465754 \n",
      "Epoch 14 | Step 5532 | loss: 0.2352524836875066 | accuracy: 0.9090763651877133 \n",
      "Epoch 14 | Step 5533 | loss: 0.23532537028801684 | accuracy: 0.9089604591836735 \n",
      "Epoch 14 | Step 5534 | loss: 0.23509619940640564 | accuracy: 0.9089512711864407 \n",
      "Epoch 14 | Step 5535 | loss: 0.23514609323260752 | accuracy: 0.9089421452702703 \n",
      "Epoch 14 | Step 5536 | loss: 0.23507902595631602 | accuracy: 0.9089856902356902 \n",
      "Epoch 14 | Step 5537 | loss: 0.23499160587487605 | accuracy: 0.9090813758389261 \n",
      "Epoch 14 | Step 5538 | loss: 0.23478836730670768 | accuracy: 0.9091764214046822 \n",
      "Epoch 14 | Step 5539 | loss: 0.23445752275486786 | accuracy: 0.909375 \n",
      "Epoch 14 | Step 5540 | loss: 0.23473219204681656 | accuracy: 0.9092088870431894 \n",
      "Epoch 14 | Step 5541 | loss: 0.23451320888684285 | accuracy: 0.9093025662251656 \n",
      "Epoch 14 | Step 5542 | loss: 0.2344281864982627 | accuracy: 0.9093956270627063 \n",
      "Epoch 14 | Step 5543 | loss: 0.2344518625667613 | accuracy: 0.9093338815789473 \n",
      "Epoch 14 | Step 5544 | loss: 0.23430842329732707 | accuracy: 0.909375 \n",
      "Epoch 14 | Step 5545 | loss: 0.23438269691237437 | accuracy: 0.9093137254901961 \n",
      "Epoch 14 | Step 5546 | loss: 0.23522253982504338 | accuracy: 0.9090492671009772 \n",
      "Epoch 14 | Step 5547 | loss: 0.23501808813156247 | accuracy: 0.9091923701298701 \n",
      "Epoch 14 | Step 5548 | loss: 0.23480464173269888 | accuracy: 0.9092334142394822 \n",
      "Epoch 14 | Step 5549 | loss: 0.23491026727903275 | accuracy: 0.9092237903225806 \n",
      "Epoch 14 | Step 5550 | loss: 0.23492688005281032 | accuracy: 0.9093649517684887 \n",
      "Epoch 14 | Step 5551 | loss: 0.23487220630527306 | accuracy: 0.909354967948718 \n",
      "Epoch 14 | Step 5552 | loss: 0.2346889599205587 | accuracy: 0.9094948083067093 \n",
      "Epoch 14 | Step 5553 | loss: 0.23493238132755467 | accuracy: 0.9093849522292994 \n",
      "Epoch 14 | Step 5554 | loss: 0.23547516330367044 | accuracy: 0.9092261904761905 \n",
      "Epoch 14 | Step 5555 | loss: 0.23540860468733915 | accuracy: 0.9091673259493671 \n",
      "Epoch 14 | Step 5556 | loss: 0.2351944047710873 | accuracy: 0.9093059936908517 \n",
      "Epoch 14 | Step 5557 | loss: 0.23532880137457787 | accuracy: 0.9091981132075472 \n",
      "Epoch 14 | Step 5558 | loss: 0.2353313704222721 | accuracy: 0.9092378526645768 \n",
      "Epoch 14 | Step 5559 | loss: 0.23520192133728415 | accuracy: 0.90927734375 \n",
      "Epoch 14 | Step 5560 | loss: 0.2351951597960567 | accuracy: 0.9092679127725857 \n",
      "Epoch 14 | Step 5561 | loss: 0.23558343305998708 | accuracy: 0.9092100155279503 \n",
      "Epoch 14 | Step 5562 | loss: 0.23539414796574565 | accuracy: 0.9092976006191951 \n",
      "Epoch 14 | Step 5563 | loss: 0.23511323321288752 | accuracy: 0.9094810956790124 \n",
      "Epoch 14 | Step 5564 | loss: 0.23527854632872802 | accuracy: 0.9094711538461538 \n",
      "Epoch 14 | Step 5565 | loss: 0.23509999526881734 | accuracy: 0.9095571319018405 \n",
      "Epoch 14 | Step 5566 | loss: 0.23531888368388565 | accuracy: 0.9094036697247706 \n",
      "Epoch 14 | Step 5567 | loss: 0.2353657961300597 | accuracy: 0.9093940548780488 \n",
      "Epoch 14 | Step 5568 | loss: 0.23580512732810888 | accuracy: 0.9090995440729484 \n",
      "Epoch 14 | Step 5569 | loss: 0.23568287218610445 | accuracy: 0.909185606060606 \n",
      "Epoch 14 | Step 5570 | loss: 0.23551869322616167 | accuracy: 0.9092239425981873 \n",
      "Epoch 14 | Step 5571 | loss: 0.2355085382664419 | accuracy: 0.909214984939759 \n",
      "Epoch 14 | Step 5572 | loss: 0.2353897261413726 | accuracy: 0.909253003003003 \n",
      "Epoch 14 | Step 5573 | loss: 0.23564902235737104 | accuracy: 0.9091504491017964 \n",
      "Epoch 14 | Step 5574 | loss: 0.2353251012181168 | accuracy: 0.9092817164179104 \n",
      "Epoch 14 | Step 5575 | loss: 0.23514050087847171 | accuracy: 0.9093656994047619 \n",
      "Epoch 14 | Step 5576 | loss: 0.23521463331995804 | accuracy: 0.9093100890207715 \n",
      "Epoch 14 | Step 5577 | loss: 0.23532427355823432 | accuracy: 0.9093010355029586 \n",
      "Epoch 14 | Step 5578 | loss: 0.2351987331797943 | accuracy: 0.9093842182890856 \n",
      "Epoch 14 | Step 5579 | loss: 0.23490315051201513 | accuracy: 0.9095128676470589 \n",
      "Epoch 14 | Step 5580 | loss: 0.23472056415511017 | accuracy: 0.9095949413489736 \n",
      "Epoch 14 | Step 5581 | loss: 0.23460119712161043 | accuracy: 0.9096765350877193 \n",
      "Epoch 14 | Step 5582 | loss: 0.2343683961572522 | accuracy: 0.9098032069970845 \n",
      "Epoch 14 | Step 5583 | loss: 0.23417731892144264 | accuracy: 0.9098382994186046 \n",
      "Epoch 14 | Step 5584 | loss: 0.23423197543707447 | accuracy: 0.9097373188405797 \n",
      "Epoch 14 | Step 5585 | loss: 0.23421372255751852 | accuracy: 0.9097272398843931 \n",
      "Epoch 14 | Step 5586 | loss: 0.2339398984392026 | accuracy: 0.9098072766570605 \n",
      "Epoch 14 | Step 5587 | loss: 0.2344134333275858 | accuracy: 0.9097072557471264 \n",
      "Epoch 14 | Step 5588 | loss: 0.23438019301197932 | accuracy: 0.9096525787965616 \n",
      "Epoch 14 | Step 5589 | loss: 0.23420153458203588 | accuracy: 0.9097321428571429 \n",
      "Epoch 14 | Step 5590 | loss: 0.2340013261067222 | accuracy: 0.9098557692307693 \n",
      "Epoch 14 | Step 5591 | loss: 0.23430357638492502 | accuracy: 0.9098011363636364 \n",
      "Epoch 14 | Step 5592 | loss: 0.23405145330317634 | accuracy: 0.9098353399433428 \n",
      "Epoch 14 | Step 5593 | loss: 0.23379573686900784 | accuracy: 0.9100459039548022 \n",
      "Epoch 14 | Step 5594 | loss: 0.23358456826126073 | accuracy: 0.9101232394366198 \n",
      "Epoch 14 | Step 5595 | loss: 0.23335822313772828 | accuracy: 0.9102001404494382 \n",
      "Epoch 14 | Step 5596 | loss: 0.2334057758210086 | accuracy: 0.9102766106442577 \n",
      "Epoch 14 | Step 5597 | loss: 0.2333922024670593 | accuracy: 0.9102653631284916 \n",
      "Epoch 14 | Step 5598 | loss: 0.2331669272694083 | accuracy: 0.9103412256267409 \n",
      "Epoch 14 | Step 5599 | loss: 0.23290700289524263 | accuracy: 0.9105034722222223 \n",
      "Epoch 14 | Step 5600 | loss: 0.2329671523041012 | accuracy: 0.9104051246537396 \n",
      "Epoch 14 | Step 5601 | loss: 0.23282482633521542 | accuracy: 0.9103936464088398 \n",
      "Epoch 14 | Step 5602 | loss: 0.23270884223959662 | accuracy: 0.9104252754820936 \n",
      "Epoch 14 | Step 5603 | loss: 0.23258487771746222 | accuracy: 0.9104567307692307 \n",
      "Epoch 14 | Step 5604 | loss: 0.2322812887903762 | accuracy: 0.9105736301369863 \n",
      "Epoch 14 | Step 5605 | loss: 0.2322258059281469 | accuracy: 0.9105191256830601 \n",
      "Epoch 14 | Step 5606 | loss: 0.23206462794331179 | accuracy: 0.9105926430517711 \n",
      "Epoch 14 | Step 5607 | loss: 0.23186543207291677 | accuracy: 0.9106233016304348 \n",
      "Epoch 14 | Step 5608 | loss: 0.23209964813094153 | accuracy: 0.9106114498644986 \n",
      "Epoch 14 | Step 5609 | loss: 0.23230892182201954 | accuracy: 0.9105152027027027 \n",
      "Epoch 14 | Step 5610 | loss: 0.23239544969845333 | accuracy: 0.9105879380053908 \n",
      "Epoch 14 | Step 5611 | loss: 0.23301508393819614 | accuracy: 0.9102402553763441 \n",
      "Epoch 14 | Step 5612 | loss: 0.23302132630316247 | accuracy: 0.9102295576407506 \n",
      "Epoch 14 | Step 5613 | loss: 0.23285235882921015 | accuracy: 0.9102606951871658 \n",
      "Epoch 14 | Step 5614 | loss: 0.23260942987600963 | accuracy: 0.9104583333333334 \n",
      "Epoch 14 | Step 5615 | loss: 0.23245334966068573 | accuracy: 0.9104471409574468 \n",
      "Epoch 14 | Step 5616 | loss: 0.23236691441871127 | accuracy: 0.9104360079575596 \n",
      "Epoch 14 | Step 5617 | loss: 0.23253522951293876 | accuracy: 0.9103422619047619 \n",
      "Epoch 14 | Step 5618 | loss: 0.23232036022995267 | accuracy: 0.9104139182058048 \n",
      "Epoch 14 | Step 5619 | loss: 0.23209790058041874 | accuracy: 0.9105674342105263 \n",
      "Epoch 14 | Step 5620 | loss: 0.23198463269106046 | accuracy: 0.9105561023622047 \n",
      "Epoch 14 | Step 5621 | loss: 0.23176416754722595 | accuracy: 0.9106266361256544 \n",
      "Epoch 14 | Step 5622 | loss: 0.2316242296530746 | accuracy: 0.9106968015665796 \n",
      "Epoch 14 | Step 5623 | loss: 0.2316431374832367 | accuracy: 0.9106852213541666 \n",
      "Epoch 14 | Step 5624 | loss: 0.23196815434214357 | accuracy: 0.9105519480519481 \n",
      "Epoch 14 | Step 5625 | loss: 0.23219843351624792 | accuracy: 0.9104193652849741 \n",
      "Epoch 14 | Step 5626 | loss: 0.23231372233355077 | accuracy: 0.9104489664082688 \n",
      "Epoch 14 | Step 5627 | loss: 0.23214776729492798 | accuracy: 0.910558956185567 \n",
      "Epoch 14 | Step 5628 | loss: 0.23238576017798984 | accuracy: 0.9104675449871465 \n",
      "Epoch 14 | Step 5629 | loss: 0.2323817103337019 | accuracy: 0.9104967948717949 \n",
      "Epoch 14 | Step 5630 | loss: 0.23248508214340796 | accuracy: 0.910406010230179 \n",
      "Epoch 14 | Step 5631 | loss: 0.23230950553350302 | accuracy: 0.910514987244898 \n",
      "Epoch 14 | Step 5632 | loss: 0.23215328611945377 | accuracy: 0.910583651399491 \n",
      "Epoch 14 | Step 5633 | loss: 0.23237509227494904 | accuracy: 0.9105329949238579 \n",
      "Epoch 14 | Step 5634 | loss: 0.2322731137275696 | accuracy: 0.9106012658227848 \n",
      "Epoch 14 | Step 5635 | loss: 0.2321788247938108 | accuracy: 0.9106297348484849 \n",
      "Epoch 14 | Step 5636 | loss: 0.23223074519964548 | accuracy: 0.9105793450881612 \n",
      "Epoch 14 | Step 5637 | loss: 0.23241479110777677 | accuracy: 0.9104506909547738 \n",
      "Epoch 14 | Step 5638 | loss: 0.23222297224633975 | accuracy: 0.9105576441102757 \n",
      "Epoch 14 | Step 5639 | loss: 0.2324678360298276 | accuracy: 0.91046875 \n",
      "Epoch 14 | Step 5640 | loss: 0.23244625474895325 | accuracy: 0.910458229426434 \n",
      "Epoch 14 | Step 5641 | loss: 0.23282955153219737 | accuracy: 0.910331156716418 \n",
      "Epoch 14 | Step 5642 | loss: 0.23246245803519455 | accuracy: 0.9104680948458593 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.5438729524612427 | accuracy: 0.75 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.5597985684871674 | accuracy: 0.7734375 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.49464072783788043 | accuracy: 0.78125 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.480054147541523 | accuracy: 0.796875 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4878802478313446 | accuracy: 0.796875 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.47649329404036206 | accuracy: 0.7994791666666666 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.46527494277272907 | accuracy: 0.8035714285714286 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.45443736389279366 | accuracy: 0.80859375 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.44840656717618305 | accuracy: 0.8125 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.44914808571338655 | accuracy: 0.815625 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4535478245128285 | accuracy: 0.8167613636363636 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4455123196045558 | accuracy: 0.8190104166666666 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4514232873916626 | accuracy: 0.8137019230769231 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.45817552294049946 | accuracy: 0.8125 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4463431795438131 | accuracy: 0.81875 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4452946577221155 | accuracy: 0.8203125 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4578006600632387 | accuracy: 0.8161764705882353 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4531477739413579 | accuracy: 0.8168402777777778 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.45028036205392136 | accuracy: 0.8182565789473685 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4459090232849121 | accuracy: 0.8203125 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.44524548876853215 | accuracy: 0.8199404761904762 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.43998913873325696 | accuracy: 0.8210227272727273 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.44158045234887494 | accuracy: 0.8192934782608695 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.44085295622547466 | accuracy: 0.8196614583333334 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.44532002329826353 | accuracy: 0.816875 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.437169869358723 | accuracy: 0.8191105769230769 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.43593087792396545 | accuracy: 0.8194444444444444 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4307012196098055 | accuracy: 0.8214285714285714 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.43309441928205816 | accuracy: 0.8205818965517241 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4343932370344798 | accuracy: 0.81875 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.42887602506145356 | accuracy: 0.8220766129032258 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4231363250873983 | accuracy: 0.8251953125 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4209377056721485 | accuracy: 0.8271780303030303 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4302420874728876 | accuracy: 0.8249080882352942 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.42879225398812976 | accuracy: 0.8241071428571428 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4240030037860076 | accuracy: 0.8259548611111112 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4257030748837703 | accuracy: 0.8264358108108109 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.425798935717658 | accuracy: 0.8252467105263158 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.42374664048353833 | accuracy: 0.8269230769230769 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4270525213330984 | accuracy: 0.825 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.42998936372559243 | accuracy: 0.823170731707317 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4280317244785173 | accuracy: 0.8244047619047619 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4274616646905278 | accuracy: 0.8234011627906976 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.430331619287079 | accuracy: 0.8220880681818182 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4337813248236974 | accuracy: 0.8207276569472419 \n",
      "Epoch 15 | Step 5643 | loss: 0.1392161101102829 | accuracy: 0.96875 \n",
      "Epoch 15 | Step 5644 | loss: 0.23694951087236404 | accuracy: 0.9375 \n",
      "Epoch 15 | Step 5645 | loss: 0.21127726137638092 | accuracy: 0.9427083333333334 \n",
      "Epoch 15 | Step 5646 | loss: 0.22010289505124092 | accuracy: 0.93359375 \n",
      "Epoch 15 | Step 5647 | loss: 0.2189079135656357 | accuracy: 0.928125 \n",
      "Epoch 15 | Step 5648 | loss: 0.2353156035145124 | accuracy: 0.9192708333333334 \n",
      "Epoch 15 | Step 5649 | loss: 0.24038191139698029 | accuracy: 0.9196428571428571 \n",
      "Epoch 15 | Step 5650 | loss: 0.2603421900421381 | accuracy: 0.916015625 \n",
      "Epoch 15 | Step 5651 | loss: 0.2532394362820519 | accuracy: 0.9166666666666666 \n",
      "Epoch 15 | Step 5652 | loss: 0.2627220332622528 | accuracy: 0.9078125 \n",
      "Epoch 15 | Step 5653 | loss: 0.2634980895302512 | accuracy: 0.9048295454545454 \n",
      "Epoch 15 | Step 5654 | loss: 0.26752110570669174 | accuracy: 0.8984375 \n",
      "Epoch 15 | Step 5655 | loss: 0.26064958709936875 | accuracy: 0.9026442307692307 \n",
      "Epoch 15 | Step 5656 | loss: 0.26400335345949444 | accuracy: 0.9029017857142857 \n",
      "Epoch 15 | Step 5657 | loss: 0.25704168279965717 | accuracy: 0.9083333333333333 \n",
      "Epoch 15 | Step 5658 | loss: 0.24808093439787623 | accuracy: 0.9130859375 \n",
      "Epoch 15 | Step 5659 | loss: 0.24401861779830036 | accuracy: 0.9163602941176471 \n",
      "Epoch 15 | Step 5660 | loss: 0.24147668812010023 | accuracy: 0.9184027777777778 \n",
      "Epoch 15 | Step 5661 | loss: 0.2394696693671377 | accuracy: 0.9185855263157895 \n",
      "Epoch 15 | Step 5662 | loss: 0.24214440882205962 | accuracy: 0.91796875 \n",
      "Epoch 15 | Step 5663 | loss: 0.2415489178328287 | accuracy: 0.9166666666666666 \n",
      "Epoch 15 | Step 5664 | loss: 0.24104956672950226 | accuracy: 0.9169034090909091 \n",
      "Epoch 15 | Step 5665 | loss: 0.23870671767255533 | accuracy: 0.9164402173913043 \n",
      "Epoch 15 | Step 5666 | loss: 0.23377071879804134 | accuracy: 0.919921875 \n",
      "Epoch 15 | Step 5667 | loss: 0.2306186228990555 | accuracy: 0.920625 \n",
      "Epoch 15 | Step 5668 | loss: 0.23049167257088882 | accuracy: 0.9188701923076923 \n",
      "Epoch 15 | Step 5669 | loss: 0.230893948563823 | accuracy: 0.9189814814814815 \n",
      "Epoch 15 | Step 5670 | loss: 0.22575378364750318 | accuracy: 0.9213169642857143 \n",
      "Epoch 15 | Step 5671 | loss: 0.22362531772975264 | accuracy: 0.9207974137931034 \n",
      "Epoch 15 | Step 5672 | loss: 0.2243024875720342 | accuracy: 0.9197916666666667 \n",
      "Epoch 15 | Step 5673 | loss: 0.22455326011103968 | accuracy: 0.920866935483871 \n",
      "Epoch 15 | Step 5674 | loss: 0.2248060586862266 | accuracy: 0.92041015625 \n",
      "Epoch 15 | Step 5675 | loss: 0.2280974808064374 | accuracy: 0.9190340909090909 \n",
      "Epoch 15 | Step 5676 | loss: 0.2296621321755297 | accuracy: 0.9191176470588235 \n",
      "Epoch 15 | Step 5677 | loss: 0.22868217613015857 | accuracy: 0.9191964285714286 \n",
      "Epoch 15 | Step 5678 | loss: 0.23038507542676395 | accuracy: 0.91796875 \n",
      "Epoch 15 | Step 5679 | loss: 0.2275059144641902 | accuracy: 0.9193412162162162 \n",
      "Epoch 15 | Step 5680 | loss: 0.22685068865355693 | accuracy: 0.9194078947368421 \n",
      "Epoch 15 | Step 5681 | loss: 0.22554148905552351 | accuracy: 0.9194711538461539 \n",
      "Epoch 15 | Step 5682 | loss: 0.22533354703336955 | accuracy: 0.919140625 \n",
      "Epoch 15 | Step 5683 | loss: 0.22491502125815646 | accuracy: 0.9192073170731707 \n",
      "Epoch 15 | Step 5684 | loss: 0.2243034007648627 | accuracy: 0.9196428571428571 \n",
      "Epoch 15 | Step 5685 | loss: 0.22225195602622144 | accuracy: 0.9200581395348837 \n",
      "Epoch 15 | Step 5686 | loss: 0.22098828462714498 | accuracy: 0.9204545454545454 \n",
      "Epoch 15 | Step 5687 | loss: 0.22226478738917244 | accuracy: 0.9194444444444444 \n",
      "Epoch 15 | Step 5688 | loss: 0.22290957832466002 | accuracy: 0.9188179347826086 \n",
      "Epoch 15 | Step 5689 | loss: 0.22218083526859891 | accuracy: 0.9192154255319149 \n",
      "Epoch 15 | Step 5690 | loss: 0.22349663963541389 | accuracy: 0.9189453125 \n",
      "Epoch 15 | Step 5691 | loss: 0.2211882800472026 | accuracy: 0.9199617346938775 \n",
      "Epoch 15 | Step 5692 | loss: 0.22246305286884308 | accuracy: 0.9196875 \n",
      "Epoch 15 | Step 5693 | loss: 0.22541024930336895 | accuracy: 0.9181985294117647 \n",
      "Epoch 15 | Step 5694 | loss: 0.22753217357855576 | accuracy: 0.9170673076923077 \n",
      "Epoch 15 | Step 5695 | loss: 0.22609438901802278 | accuracy: 0.9174528301886793 \n",
      "Epoch 15 | Step 5696 | loss: 0.2259704887315079 | accuracy: 0.9172453703703703 \n",
      "Epoch 15 | Step 5697 | loss: 0.22588590735738928 | accuracy: 0.9176136363636364 \n",
      "Epoch 15 | Step 5698 | loss: 0.227932677471212 | accuracy: 0.9171316964285714 \n",
      "Epoch 15 | Step 5699 | loss: 0.2269903575642067 | accuracy: 0.9177631578947368 \n",
      "Epoch 15 | Step 5700 | loss: 0.22798695980474867 | accuracy: 0.9175646551724138 \n",
      "Epoch 15 | Step 5701 | loss: 0.22834334257295577 | accuracy: 0.9179025423728814 \n",
      "Epoch 15 | Step 5702 | loss: 0.22969101642568907 | accuracy: 0.9169270833333333 \n",
      "Epoch 15 | Step 5703 | loss: 0.22936627635213194 | accuracy: 0.9162397540983607 \n",
      "Epoch 15 | Step 5704 | loss: 0.2289273664355278 | accuracy: 0.9165826612903226 \n",
      "Epoch 15 | Step 5705 | loss: 0.22889201390364813 | accuracy: 0.9161706349206349 \n",
      "Epoch 15 | Step 5706 | loss: 0.22716754220891744 | accuracy: 0.9169921875 \n",
      "Epoch 15 | Step 5707 | loss: 0.2279133541079668 | accuracy: 0.916826923076923 \n",
      "Epoch 15 | Step 5708 | loss: 0.22625239690144858 | accuracy: 0.9171401515151515 \n",
      "Epoch 15 | Step 5709 | loss: 0.22525653154102723 | accuracy: 0.9176772388059702 \n",
      "Epoch 15 | Step 5710 | loss: 0.2248722783782903 | accuracy: 0.9177389705882353 \n",
      "Epoch 15 | Step 5711 | loss: 0.22568374051563983 | accuracy: 0.9168931159420289 \n",
      "Epoch 15 | Step 5712 | loss: 0.22670213707855771 | accuracy: 0.9167410714285714 \n",
      "Epoch 15 | Step 5713 | loss: 0.2276699832627471 | accuracy: 0.9163732394366197 \n",
      "Epoch 15 | Step 5714 | loss: 0.2269084021035168 | accuracy: 0.9164496527777778 \n",
      "Epoch 15 | Step 5715 | loss: 0.22754553756485246 | accuracy: 0.916095890410959 \n",
      "Epoch 15 | Step 5716 | loss: 0.22799646955084157 | accuracy: 0.9155405405405406 \n",
      "Epoch 15 | Step 5717 | loss: 0.22885634005069733 | accuracy: 0.9154166666666667 \n",
      "Epoch 15 | Step 5718 | loss: 0.22791756846402822 | accuracy: 0.9159128289473685 \n",
      "Epoch 15 | Step 5719 | loss: 0.22920801190586834 | accuracy: 0.9153814935064936 \n",
      "Epoch 15 | Step 5720 | loss: 0.22846715247783905 | accuracy: 0.9156650641025641 \n",
      "Epoch 15 | Step 5721 | loss: 0.22750724474840525 | accuracy: 0.9155458860759493 \n",
      "Epoch 15 | Step 5722 | loss: 0.22706569042056798 | accuracy: 0.915625 \n",
      "Epoch 15 | Step 5723 | loss: 0.22814253726859152 | accuracy: 0.9151234567901234 \n",
      "Epoch 15 | Step 5724 | loss: 0.22731798941769252 | accuracy: 0.9155868902439024 \n",
      "Epoch 15 | Step 5725 | loss: 0.22772917600281267 | accuracy: 0.9156626506024096 \n",
      "Epoch 15 | Step 5726 | loss: 0.22769212332509814 | accuracy: 0.9159226190476191 \n",
      "Epoch 15 | Step 5727 | loss: 0.22814456715303308 | accuracy: 0.9158088235294117 \n",
      "Epoch 15 | Step 5728 | loss: 0.22691242864658667 | accuracy: 0.9164244186046512 \n",
      "Epoch 15 | Step 5729 | loss: 0.22668927188577323 | accuracy: 0.9164870689655172 \n",
      "Epoch 15 | Step 5730 | loss: 0.22706452249126 | accuracy: 0.9163707386363636 \n",
      "Epoch 15 | Step 5731 | loss: 0.22686548145969263 | accuracy: 0.9159058988764045 \n",
      "Epoch 15 | Step 5732 | loss: 0.2277272452910741 | accuracy: 0.9154513888888889 \n",
      "Epoch 15 | Step 5733 | loss: 0.22760718307652317 | accuracy: 0.915521978021978 \n",
      "Epoch 15 | Step 5734 | loss: 0.22964558717997177 | accuracy: 0.9149116847826086 \n",
      "Epoch 15 | Step 5735 | loss: 0.23211875557899475 | accuracy: 0.9141465053763441 \n",
      "Epoch 15 | Step 5736 | loss: 0.23112369011691275 | accuracy: 0.914561170212766 \n",
      "Epoch 15 | Step 5737 | loss: 0.23015309211454893 | accuracy: 0.9148026315789474 \n",
      "Epoch 15 | Step 5738 | loss: 0.22965179461364946 | accuracy: 0.9148763020833334 \n",
      "Epoch 15 | Step 5739 | loss: 0.2292639293621496 | accuracy: 0.915270618556701 \n",
      "Epoch 15 | Step 5740 | loss: 0.23049698587583037 | accuracy: 0.9145408163265306 \n",
      "Epoch 15 | Step 5741 | loss: 0.22987904060970654 | accuracy: 0.9147727272727273 \n",
      "Epoch 15 | Step 5742 | loss: 0.23028607577085494 | accuracy: 0.9146875 \n",
      "Epoch 15 | Step 5743 | loss: 0.23039134938528041 | accuracy: 0.9147586633663366 \n",
      "Epoch 15 | Step 5744 | loss: 0.2305965223440937 | accuracy: 0.9145220588235294 \n",
      "Epoch 15 | Step 5745 | loss: 0.23041196080666143 | accuracy: 0.9144417475728155 \n",
      "Epoch 15 | Step 5746 | loss: 0.2306969089863392 | accuracy: 0.9146634615384616 \n",
      "Epoch 15 | Step 5747 | loss: 0.23133707997344788 | accuracy: 0.9144345238095238 \n",
      "Epoch 15 | Step 5748 | loss: 0.23087096636025412 | accuracy: 0.9143573113207547 \n",
      "Epoch 15 | Step 5749 | loss: 0.23109164137706578 | accuracy: 0.9142815420560748 \n",
      "Epoch 15 | Step 5750 | loss: 0.2318239234111927 | accuracy: 0.9140625 \n",
      "Epoch 15 | Step 5751 | loss: 0.23084674720917273 | accuracy: 0.9145642201834863 \n",
      "Epoch 15 | Step 5752 | loss: 0.23060882795940746 | accuracy: 0.9142045454545454 \n",
      "Epoch 15 | Step 5753 | loss: 0.23149945419113915 | accuracy: 0.9137105855855856 \n",
      "Epoch 15 | Step 5754 | loss: 0.23213548346289567 | accuracy: 0.9133649553571429 \n",
      "Epoch 15 | Step 5755 | loss: 0.2317288818612563 | accuracy: 0.9137168141592921 \n",
      "Epoch 15 | Step 5756 | loss: 0.2315227517433334 | accuracy: 0.9135142543859649 \n",
      "Epoch 15 | Step 5757 | loss: 0.23073381729747938 | accuracy: 0.9139945652173913 \n",
      "Epoch 15 | Step 5758 | loss: 0.23025754402423726 | accuracy: 0.9143318965517241 \n",
      "Epoch 15 | Step 5759 | loss: 0.22973952359623379 | accuracy: 0.9145299145299145 \n",
      "Epoch 15 | Step 5760 | loss: 0.22992131492849124 | accuracy: 0.9141949152542372 \n",
      "Epoch 15 | Step 5761 | loss: 0.23044555953570775 | accuracy: 0.9136029411764706 \n",
      "Epoch 15 | Step 5762 | loss: 0.23064706847071648 | accuracy: 0.9134114583333334 \n",
      "Epoch 15 | Step 5763 | loss: 0.22980534488504584 | accuracy: 0.9139979338842975 \n",
      "Epoch 15 | Step 5764 | loss: 0.2302842540819137 | accuracy: 0.9135502049180327 \n",
      "Epoch 15 | Step 5765 | loss: 0.22997368072591176 | accuracy: 0.913744918699187 \n",
      "Epoch 15 | Step 5766 | loss: 0.23098032500955365 | accuracy: 0.9131804435483871 \n",
      "Epoch 15 | Step 5767 | loss: 0.23090696239471437 | accuracy: 0.913 \n",
      "Epoch 15 | Step 5768 | loss: 0.23016882900680816 | accuracy: 0.9134424603174603 \n",
      "Epoch 15 | Step 5769 | loss: 0.2304611059389715 | accuracy: 0.9130167322834646 \n",
      "Epoch 15 | Step 5770 | loss: 0.23005627805832773 | accuracy: 0.9130859375 \n",
      "Epoch 15 | Step 5771 | loss: 0.22968312866928042 | accuracy: 0.9130329457364341 \n",
      "Epoch 15 | Step 5772 | loss: 0.229908257493606 | accuracy: 0.9128605769230769 \n",
      "Epoch 15 | Step 5773 | loss: 0.23034477688884006 | accuracy: 0.9126908396946565 \n",
      "Epoch 15 | Step 5774 | loss: 0.23015792882352165 | accuracy: 0.9128787878787878 \n",
      "Epoch 15 | Step 5775 | loss: 0.22963357856847288 | accuracy: 0.9131813909774437 \n",
      "Epoch 15 | Step 5776 | loss: 0.22896261168504828 | accuracy: 0.9132462686567165 \n",
      "Epoch 15 | Step 5777 | loss: 0.22934524913628895 | accuracy: 0.9130787037037038 \n",
      "Epoch 15 | Step 5778 | loss: 0.2299744941513328 | accuracy: 0.9131433823529412 \n",
      "Epoch 15 | Step 5779 | loss: 0.2307587088677135 | accuracy: 0.9127509124087593 \n",
      "Epoch 15 | Step 5780 | loss: 0.23055966565574426 | accuracy: 0.9129302536231885 \n",
      "Epoch 15 | Step 5781 | loss: 0.23099254189635351 | accuracy: 0.912769784172662 \n",
      "Epoch 15 | Step 5782 | loss: 0.23076839415090425 | accuracy: 0.9128348214285715 \n",
      "Epoch 15 | Step 5783 | loss: 0.23075838852013256 | accuracy: 0.9127881205673759 \n",
      "Epoch 15 | Step 5784 | loss: 0.23040637394911806 | accuracy: 0.9128521126760564 \n",
      "Epoch 15 | Step 5785 | loss: 0.2298174700536928 | accuracy: 0.9130244755244755 \n",
      "Epoch 15 | Step 5786 | loss: 0.22973001882847813 | accuracy: 0.9130859375 \n",
      "Epoch 15 | Step 5787 | loss: 0.2295720252497443 | accuracy: 0.9129310344827586 \n",
      "Epoch 15 | Step 5788 | loss: 0.22972387463262636 | accuracy: 0.9130993150684932 \n",
      "Epoch 15 | Step 5789 | loss: 0.22975943627811612 | accuracy: 0.9131590136054422 \n",
      "Epoch 15 | Step 5790 | loss: 0.22971982901563515 | accuracy: 0.9130067567567568 \n",
      "Epoch 15 | Step 5791 | loss: 0.22993460287583756 | accuracy: 0.9129614093959731 \n",
      "Epoch 15 | Step 5792 | loss: 0.22909665529926618 | accuracy: 0.9134375 \n",
      "Epoch 15 | Step 5793 | loss: 0.22936360473861758 | accuracy: 0.9133899006622517 \n",
      "Epoch 15 | Step 5794 | loss: 0.2294704245011273 | accuracy: 0.913342927631579 \n",
      "Epoch 15 | Step 5795 | loss: 0.23004880620568408 | accuracy: 0.9130923202614379 \n",
      "Epoch 15 | Step 5796 | loss: 0.22926671106319924 | accuracy: 0.9133522727272727 \n",
      "Epoch 15 | Step 5797 | loss: 0.2286325058629436 | accuracy: 0.9137096774193548 \n",
      "Epoch 15 | Step 5798 | loss: 0.22761504337764704 | accuracy: 0.9140625 \n",
      "Epoch 15 | Step 5799 | loss: 0.22756214995103277 | accuracy: 0.9141122611464968 \n",
      "Epoch 15 | Step 5800 | loss: 0.22720791111829913 | accuracy: 0.9143591772151899 \n",
      "Epoch 15 | Step 5801 | loss: 0.22724471241235733 | accuracy: 0.9142099056603774 \n",
      "Epoch 15 | Step 5802 | loss: 0.2271130918059498 | accuracy: 0.91416015625 \n",
      "Epoch 15 | Step 5803 | loss: 0.2268080364750779 | accuracy: 0.9142080745341615 \n",
      "Epoch 15 | Step 5804 | loss: 0.22676488163846512 | accuracy: 0.9143518518518519 \n",
      "Epoch 15 | Step 5805 | loss: 0.2258966905207722 | accuracy: 0.9147814417177914 \n",
      "Epoch 15 | Step 5806 | loss: 0.22553610238360194 | accuracy: 0.9148246951219512 \n",
      "Epoch 15 | Step 5807 | loss: 0.22538594151988173 | accuracy: 0.9146780303030303 \n",
      "Epoch 15 | Step 5808 | loss: 0.22643568573227849 | accuracy: 0.9143448795180723 \n",
      "Epoch 15 | Step 5809 | loss: 0.225677371471228 | accuracy: 0.9146706586826348 \n",
      "Epoch 15 | Step 5810 | loss: 0.2254185847760666 | accuracy: 0.9144345238095238 \n",
      "Epoch 15 | Step 5811 | loss: 0.2266905922332459 | accuracy: 0.9141087278106509 \n",
      "Epoch 15 | Step 5812 | loss: 0.2266572504359133 | accuracy: 0.9141544117647059 \n",
      "Epoch 15 | Step 5813 | loss: 0.22688750086123483 | accuracy: 0.9141995614035088 \n",
      "Epoch 15 | Step 5814 | loss: 0.22720034030634303 | accuracy: 0.9140625 \n",
      "Epoch 15 | Step 5815 | loss: 0.22617606947876814 | accuracy: 0.9145592485549133 \n",
      "Epoch 15 | Step 5816 | loss: 0.2262058752192848 | accuracy: 0.9146012931034483 \n",
      "Epoch 15 | Step 5817 | loss: 0.2258720611674445 | accuracy: 0.9148214285714286 \n",
      "Epoch 15 | Step 5818 | loss: 0.22560462965206665 | accuracy: 0.9149502840909091 \n",
      "Epoch 15 | Step 5819 | loss: 0.22581050911192166 | accuracy: 0.914989406779661 \n",
      "Epoch 15 | Step 5820 | loss: 0.22576391763901443 | accuracy: 0.9150280898876404 \n",
      "Epoch 15 | Step 5821 | loss: 0.22599627135852196 | accuracy: 0.9150663407821229 \n",
      "Epoch 15 | Step 5822 | loss: 0.22621992230415344 | accuracy: 0.91484375 \n",
      "Epoch 15 | Step 5823 | loss: 0.22578160341273354 | accuracy: 0.9150552486187845 \n",
      "Epoch 15 | Step 5824 | loss: 0.22524831059214834 | accuracy: 0.9152644230769231 \n",
      "Epoch 15 | Step 5825 | loss: 0.22484290493967754 | accuracy: 0.915556693989071 \n",
      "Epoch 15 | Step 5826 | loss: 0.22488447100571965 | accuracy: 0.9155910326086957 \n",
      "Epoch 15 | Step 5827 | loss: 0.22497700968304196 | accuracy: 0.9153716216216217 \n",
      "Epoch 15 | Step 5828 | loss: 0.22500199031445287 | accuracy: 0.9153225806451613 \n",
      "Epoch 15 | Step 5829 | loss: 0.2250813542999686 | accuracy: 0.9154411764705882 \n",
      "Epoch 15 | Step 5830 | loss: 0.2253287657302745 | accuracy: 0.9155585106382979 \n",
      "Epoch 15 | Step 5831 | loss: 0.22487174479103594 | accuracy: 0.9158399470899471 \n",
      "Epoch 15 | Step 5832 | loss: 0.2250117934848133 | accuracy: 0.9157894736842105 \n",
      "Epoch 15 | Step 5833 | loss: 0.22528565125003536 | accuracy: 0.915821335078534 \n",
      "Epoch 15 | Step 5834 | loss: 0.22542283691776296 | accuracy: 0.9158528645833334 \n",
      "Epoch 15 | Step 5835 | loss: 0.2258083682140538 | accuracy: 0.9156411917098446 \n",
      "Epoch 15 | Step 5836 | loss: 0.225341898110724 | accuracy: 0.9159149484536082 \n",
      "Epoch 15 | Step 5837 | loss: 0.22559473560406612 | accuracy: 0.9157852564102564 \n",
      "Epoch 15 | Step 5838 | loss: 0.2257318358336176 | accuracy: 0.9157366071428571 \n",
      "Epoch 15 | Step 5839 | loss: 0.2259399316032526 | accuracy: 0.9154505076142132 \n",
      "Epoch 15 | Step 5840 | loss: 0.22615334828092595 | accuracy: 0.915167297979798 \n",
      "Epoch 15 | Step 5841 | loss: 0.226675536764327 | accuracy: 0.9149654522613065 \n",
      "Epoch 15 | Step 5842 | loss: 0.22659801036119462 | accuracy: 0.915 \n",
      "Epoch 15 | Step 5843 | loss: 0.22699800029915956 | accuracy: 0.9145677860696517 \n",
      "Epoch 15 | Step 5844 | loss: 0.22733012815513234 | accuracy: 0.914371905940594 \n",
      "Epoch 15 | Step 5845 | loss: 0.22703262157921722 | accuracy: 0.9145628078817734 \n",
      "Epoch 15 | Step 5846 | loss: 0.22687979919068954 | accuracy: 0.9145220588235294 \n",
      "Epoch 15 | Step 5847 | loss: 0.22694587402227448 | accuracy: 0.9143292682926829 \n",
      "Epoch 15 | Step 5848 | loss: 0.22706186930531436 | accuracy: 0.9143658980582524 \n",
      "Epoch 15 | Step 5849 | loss: 0.22677836246824495 | accuracy: 0.9144021739130435 \n",
      "Epoch 15 | Step 5850 | loss: 0.22653691090929967 | accuracy: 0.9144381009615384 \n",
      "Epoch 15 | Step 5851 | loss: 0.22650573277872715 | accuracy: 0.9143241626794258 \n",
      "Epoch 15 | Step 5852 | loss: 0.22601441638100714 | accuracy: 0.9147321428571429 \n",
      "Epoch 15 | Step 5853 | loss: 0.22582091486425762 | accuracy: 0.9149140995260664 \n",
      "Epoch 15 | Step 5854 | loss: 0.2262822027265463 | accuracy: 0.9147995283018868 \n",
      "Epoch 15 | Step 5855 | loss: 0.22573489129123553 | accuracy: 0.9151261737089202 \n",
      "Epoch 15 | Step 5856 | loss: 0.2256082136566951 | accuracy: 0.9153767523364486 \n",
      "Epoch 15 | Step 5857 | loss: 0.22600419233704722 | accuracy: 0.9152616279069767 \n",
      "Epoch 15 | Step 5858 | loss: 0.22652817107047196 | accuracy: 0.9151475694444444 \n",
      "Epoch 15 | Step 5859 | loss: 0.22691214651144045 | accuracy: 0.9150345622119815 \n",
      "Epoch 15 | Step 5860 | loss: 0.22661423891646051 | accuracy: 0.9151376146788991 \n",
      "Epoch 15 | Step 5861 | loss: 0.22659673732301416 | accuracy: 0.9150256849315068 \n",
      "Epoch 15 | Step 5862 | loss: 0.22670403857800095 | accuracy: 0.9149147727272727 \n",
      "Epoch 15 | Step 5863 | loss: 0.22627557244370966 | accuracy: 0.9150169683257918 \n",
      "Epoch 15 | Step 5864 | loss: 0.22591401626532143 | accuracy: 0.9151886261261262 \n",
      "Epoch 15 | Step 5865 | loss: 0.22602618118171736 | accuracy: 0.9152886771300448 \n",
      "Epoch 15 | Step 5866 | loss: 0.22593513267513896 | accuracy: 0.9153878348214286 \n",
      "Epoch 15 | Step 5867 | loss: 0.22618944926394358 | accuracy: 0.9152083333333333 \n",
      "Epoch 15 | Step 5868 | loss: 0.2264219468739708 | accuracy: 0.9151686946902655 \n",
      "Epoch 15 | Step 5869 | loss: 0.22636007314080184 | accuracy: 0.9151982378854625 \n",
      "Epoch 15 | Step 5870 | loss: 0.2263181203355392 | accuracy: 0.9152275219298246 \n",
      "Epoch 15 | Step 5871 | loss: 0.22602443901342076 | accuracy: 0.9153247816593887 \n",
      "Epoch 15 | Step 5872 | loss: 0.2258707092831964 | accuracy: 0.9153532608695653 \n",
      "Epoch 15 | Step 5873 | loss: 0.22616983901757698 | accuracy: 0.9151785714285714 \n",
      "Epoch 15 | Step 5874 | loss: 0.2259227312009396 | accuracy: 0.9152074353448276 \n",
      "Epoch 15 | Step 5875 | loss: 0.2258673336820541 | accuracy: 0.9151019313304721 \n",
      "Epoch 15 | Step 5876 | loss: 0.22595661404168504 | accuracy: 0.9150641025641025 \n",
      "Epoch 15 | Step 5877 | loss: 0.22579054315673544 | accuracy: 0.9152925531914894 \n",
      "Epoch 15 | Step 5878 | loss: 0.22591603159020512 | accuracy: 0.9153866525423728 \n",
      "Epoch 15 | Step 5879 | loss: 0.22615389849691955 | accuracy: 0.9152162447257384 \n",
      "Epoch 15 | Step 5880 | loss: 0.2266124345737846 | accuracy: 0.9149816176470589 \n",
      "Epoch 15 | Step 5881 | loss: 0.2262642061548253 | accuracy: 0.915010460251046 \n",
      "Epoch 15 | Step 5882 | loss: 0.22587188168739278 | accuracy: 0.9151692708333333 \n",
      "Epoch 15 | Step 5883 | loss: 0.2260609927946601 | accuracy: 0.9150674273858921 \n",
      "Epoch 15 | Step 5884 | loss: 0.2262496264451299 | accuracy: 0.9150955578512396 \n",
      "Epoch 15 | Step 5885 | loss: 0.22611174327723774 | accuracy: 0.9151877572016461 \n",
      "Epoch 15 | Step 5886 | loss: 0.2255201331171833 | accuracy: 0.9154713114754098 \n",
      "Epoch 15 | Step 5887 | loss: 0.22504349670239857 | accuracy: 0.9157525510204082 \n",
      "Epoch 15 | Step 5888 | loss: 0.2248849761255873 | accuracy: 0.9157774390243902 \n",
      "Epoch 15 | Step 5889 | loss: 0.22446509574347662 | accuracy: 0.9159286437246964 \n",
      "Epoch 15 | Step 5890 | loss: 0.22466517017493326 | accuracy: 0.9157636088709677 \n",
      "Epoch 15 | Step 5891 | loss: 0.22456563123498097 | accuracy: 0.9158509036144579 \n",
      "Epoch 15 | Step 5892 | loss: 0.22439774584770203 | accuracy: 0.915875 \n",
      "Epoch 15 | Step 5893 | loss: 0.22451719392343347 | accuracy: 0.9157744023904383 \n",
      "Epoch 15 | Step 5894 | loss: 0.2245367540726586 | accuracy: 0.9156746031746031 \n",
      "Epoch 15 | Step 5895 | loss: 0.22439808383760715 | accuracy: 0.9156373517786561 \n",
      "Epoch 15 | Step 5896 | loss: 0.22437104177991235 | accuracy: 0.9155388779527559 \n",
      "Epoch 15 | Step 5897 | loss: 0.22410497455035938 | accuracy: 0.915625 \n",
      "Epoch 15 | Step 5898 | loss: 0.2240741468849592 | accuracy: 0.91558837890625 \n",
      "Epoch 15 | Step 5899 | loss: 0.22400276194750568 | accuracy: 0.915612840466926 \n",
      "Epoch 15 | Step 5900 | loss: 0.22416026428226352 | accuracy: 0.9155765503875969 \n",
      "Epoch 15 | Step 5901 | loss: 0.2238924088510307 | accuracy: 0.915661196911197 \n",
      "Epoch 15 | Step 5902 | loss: 0.2237816552703197 | accuracy: 0.9156850961538462 \n",
      "Epoch 15 | Step 5903 | loss: 0.22365661981690432 | accuracy: 0.9158285440613027 \n",
      "Epoch 15 | Step 5904 | loss: 0.22402485221169377 | accuracy: 0.915613072519084 \n",
      "Epoch 15 | Step 5905 | loss: 0.22398145581832857 | accuracy: 0.9156962927756654 \n",
      "Epoch 15 | Step 5906 | loss: 0.22390282933007588 | accuracy: 0.915719696969697 \n",
      "Epoch 15 | Step 5907 | loss: 0.22369072971478948 | accuracy: 0.9158018867924528 \n",
      "Epoch 15 | Step 5908 | loss: 0.22356122866609043 | accuracy: 0.9158834586466166 \n",
      "Epoch 15 | Step 5909 | loss: 0.22320810691470958 | accuracy: 0.9160229400749064 \n",
      "Epoch 15 | Step 5910 | loss: 0.2235645485569292 | accuracy: 0.9158115671641791 \n",
      "Epoch 15 | Step 5911 | loss: 0.2236265931209224 | accuracy: 0.9157760223048327 \n",
      "Epoch 15 | Step 5912 | loss: 0.22378208019115306 | accuracy: 0.9156828703703703 \n",
      "Epoch 15 | Step 5913 | loss: 0.2237622366180279 | accuracy: 0.9156480627306273 \n",
      "Epoch 15 | Step 5914 | loss: 0.2236519221435575 | accuracy: 0.9157858455882353 \n",
      "Epoch 15 | Step 5915 | loss: 0.22370503608123724 | accuracy: 0.9158653846153846 \n",
      "Epoch 15 | Step 5916 | loss: 0.22395767293272228 | accuracy: 0.9159443430656934 \n",
      "Epoch 15 | Step 5917 | loss: 0.2237136495113373 | accuracy: 0.9160227272727273 \n",
      "Epoch 15 | Step 5918 | loss: 0.22395967810914136 | accuracy: 0.9159307065217391 \n",
      "Epoch 15 | Step 5919 | loss: 0.22368557218610163 | accuracy: 0.9160649819494585 \n",
      "Epoch 15 | Step 5920 | loss: 0.22352851353746525 | accuracy: 0.9161420863309353 \n",
      "Epoch 15 | Step 5921 | loss: 0.22336242879377044 | accuracy: 0.9161626344086021 \n",
      "Epoch 15 | Step 5922 | loss: 0.22342469191976955 | accuracy: 0.9161272321428572 \n",
      "Epoch 15 | Step 5923 | loss: 0.22333775561475244 | accuracy: 0.9161476868327402 \n",
      "Epoch 15 | Step 5924 | loss: 0.22295381789300459 | accuracy: 0.9162788120567376 \n",
      "Epoch 15 | Step 5925 | loss: 0.22283333202975378 | accuracy: 0.9162985865724381 \n",
      "Epoch 15 | Step 5926 | loss: 0.22249760447253644 | accuracy: 0.9164832746478874 \n",
      "Epoch 15 | Step 5927 | loss: 0.22237311863062675 | accuracy: 0.9165021929824562 \n",
      "Epoch 15 | Step 5928 | loss: 0.2219044698493464 | accuracy: 0.9167395104895105 \n",
      "Epoch 15 | Step 5929 | loss: 0.2220378314576498 | accuracy: 0.9167574041811847 \n",
      "Epoch 15 | Step 5930 | loss: 0.22157077550784582 | accuracy: 0.9169921875 \n",
      "Epoch 15 | Step 5931 | loss: 0.2220485940266233 | accuracy: 0.9169009515570934 \n",
      "Epoch 15 | Step 5932 | loss: 0.22199967732203418 | accuracy: 0.9169181034482758 \n",
      "Epoch 15 | Step 5933 | loss: 0.222229037421061 | accuracy: 0.9167740549828178 \n",
      "Epoch 15 | Step 5934 | loss: 0.2221257442429866 | accuracy: 0.916898544520548 \n",
      "Epoch 15 | Step 5935 | loss: 0.22202223501209514 | accuracy: 0.9169688566552902 \n",
      "Epoch 15 | Step 5936 | loss: 0.222095467074185 | accuracy: 0.9168792517006803 \n",
      "Epoch 15 | Step 5937 | loss: 0.22194495925963936 | accuracy: 0.9167902542372881 \n",
      "Epoch 15 | Step 5938 | loss: 0.2220429972166548 | accuracy: 0.9167546452702703 \n",
      "Epoch 15 | Step 5939 | loss: 0.22189384887013772 | accuracy: 0.9169297138047138 \n",
      "Epoch 15 | Step 5940 | loss: 0.22181789474499305 | accuracy: 0.9169987416107382 \n",
      "Epoch 15 | Step 5941 | loss: 0.2216059363456474 | accuracy: 0.9171195652173914 \n",
      "Epoch 15 | Step 5942 | loss: 0.2212591371933619 | accuracy: 0.9172916666666666 \n",
      "Epoch 15 | Step 5943 | loss: 0.22152172637936285 | accuracy: 0.9171511627906976 \n",
      "Epoch 15 | Step 5944 | loss: 0.22130273400947748 | accuracy: 0.9172702814569537 \n",
      "Epoch 15 | Step 5945 | loss: 0.22116998649469696 | accuracy: 0.9173886138613861 \n",
      "Epoch 15 | Step 5946 | loss: 0.2211652713778772 | accuracy: 0.9173005756578947 \n",
      "Epoch 15 | Step 5947 | loss: 0.22107951005951304 | accuracy: 0.9173155737704918 \n",
      "Epoch 15 | Step 5948 | loss: 0.22122329463756163 | accuracy: 0.9172794117647058 \n",
      "Epoch 15 | Step 5949 | loss: 0.2220275302080844 | accuracy: 0.916989006514658 \n",
      "Epoch 15 | Step 5950 | loss: 0.22192175308992337 | accuracy: 0.9171570616883117 \n",
      "Epoch 15 | Step 5951 | loss: 0.22169803975083682 | accuracy: 0.9171217637540453 \n",
      "Epoch 15 | Step 5952 | loss: 0.22180082221185007 | accuracy: 0.9170866935483871 \n",
      "Epoch 15 | Step 5953 | loss: 0.22183104223568723 | accuracy: 0.9171020900321544 \n",
      "Epoch 15 | Step 5954 | loss: 0.2218118732651839 | accuracy: 0.9170673076923077 \n",
      "Epoch 15 | Step 5955 | loss: 0.2216191334179796 | accuracy: 0.9171825079872205 \n",
      "Epoch 15 | Step 5956 | loss: 0.22195542793554865 | accuracy: 0.9170481687898089 \n",
      "Epoch 15 | Step 5957 | loss: 0.2225249246472404 | accuracy: 0.9169642857142857 \n",
      "Epoch 15 | Step 5958 | loss: 0.22240745361092723 | accuracy: 0.9169798259493671 \n",
      "Epoch 15 | Step 5959 | loss: 0.22219490605385897 | accuracy: 0.9170938485804416 \n",
      "Epoch 15 | Step 5960 | loss: 0.2223961723019492 | accuracy: 0.9169614779874213 \n",
      "Epoch 15 | Step 5961 | loss: 0.22238927747949164 | accuracy: 0.9170258620689655 \n",
      "Epoch 15 | Step 5962 | loss: 0.22219500355422497 | accuracy: 0.9169921875 \n",
      "Epoch 15 | Step 5963 | loss: 0.22218277521222551 | accuracy: 0.9169100467289719 \n",
      "Epoch 15 | Step 5964 | loss: 0.22257923200633956 | accuracy: 0.9168769409937888 \n",
      "Epoch 15 | Step 5965 | loss: 0.22237834458934264 | accuracy: 0.9169407894736842 \n",
      "Epoch 15 | Step 5966 | loss: 0.22211089776253995 | accuracy: 0.9171006944444444 \n",
      "Epoch 15 | Step 5967 | loss: 0.22234978134815508 | accuracy: 0.9169711538461538 \n",
      "Epoch 15 | Step 5968 | loss: 0.22212488967582492 | accuracy: 0.9171299846625767 \n",
      "Epoch 15 | Step 5969 | loss: 0.22227586682783354 | accuracy: 0.9170011467889908 \n",
      "Epoch 15 | Step 5970 | loss: 0.2223332423898505 | accuracy: 0.916968368902439 \n",
      "Epoch 15 | Step 5971 | loss: 0.22291289206514966 | accuracy: 0.9166508358662614 \n",
      "Epoch 15 | Step 5972 | loss: 0.2228225702137658 | accuracy: 0.9167140151515152 \n",
      "Epoch 15 | Step 5973 | loss: 0.22269353644185197 | accuracy: 0.9167296072507553 \n",
      "Epoch 15 | Step 5974 | loss: 0.22271669651549983 | accuracy: 0.9166980421686747 \n",
      "Epoch 15 | Step 5975 | loss: 0.22259489015057995 | accuracy: 0.9167605105105106 \n",
      "Epoch 15 | Step 5976 | loss: 0.222788749429994 | accuracy: 0.9166354790419161 \n",
      "Epoch 15 | Step 5977 | loss: 0.2224457617126294 | accuracy: 0.9167444029850746 \n",
      "Epoch 15 | Step 5978 | loss: 0.22225755506328174 | accuracy: 0.9168526785714286 \n",
      "Epoch 15 | Step 5979 | loss: 0.22226089584013828 | accuracy: 0.9167748516320475 \n",
      "Epoch 15 | Step 5980 | loss: 0.22236337014556637 | accuracy: 0.9167899408284024 \n",
      "Epoch 15 | Step 5981 | loss: 0.22231618352344254 | accuracy: 0.9168510324483776 \n",
      "Epoch 15 | Step 5982 | loss: 0.22198931671240751 | accuracy: 0.9170036764705882 \n",
      "Epoch 15 | Step 5983 | loss: 0.22187987288946281 | accuracy: 0.9170179618768328 \n",
      "Epoch 15 | Step 5984 | loss: 0.22173130381525608 | accuracy: 0.91703216374269 \n",
      "Epoch 15 | Step 5985 | loss: 0.22149774188898047 | accuracy: 0.9171373906705539 \n",
      "Epoch 15 | Step 5986 | loss: 0.221307851070928 | accuracy: 0.9171057412790697 \n",
      "Epoch 15 | Step 5987 | loss: 0.2213541587193807 | accuracy: 0.9169836956521739 \n",
      "Epoch 15 | Step 5988 | loss: 0.2213287812609204 | accuracy: 0.9170429913294798 \n",
      "Epoch 15 | Step 5989 | loss: 0.22107910860855917 | accuracy: 0.9171019452449568 \n",
      "Epoch 15 | Step 5990 | loss: 0.22152386768453422 | accuracy: 0.9169809626436781 \n",
      "Epoch 15 | Step 5991 | loss: 0.22146261041519635 | accuracy: 0.9169949856733525 \n",
      "Epoch 15 | Step 5992 | loss: 0.22133976204054695 | accuracy: 0.9170982142857143 \n",
      "Epoch 15 | Step 5993 | loss: 0.22117212244927714 | accuracy: 0.9172453703703703 \n",
      "Epoch 15 | Step 5994 | loss: 0.22143452521413565 | accuracy: 0.9171697443181818 \n",
      "Epoch 15 | Step 5995 | loss: 0.22123986279998217 | accuracy: 0.9171830736543909 \n",
      "Epoch 15 | Step 5996 | loss: 0.22098806399410054 | accuracy: 0.917284604519774 \n",
      "Epoch 15 | Step 5997 | loss: 0.2208046301569737 | accuracy: 0.9173855633802817 \n",
      "Epoch 15 | Step 5998 | loss: 0.220573396704505 | accuracy: 0.9174420646067416 \n",
      "Epoch 15 | Step 5999 | loss: 0.22060967071884485 | accuracy: 0.917454481792717 \n",
      "Epoch 15 | Step 6000 | loss: 0.22061041334654366 | accuracy: 0.9173795391061452 \n",
      "Epoch 15 | Step 6001 | loss: 0.22033716325225272 | accuracy: 0.9175226323119777 \n",
      "Epoch 15 | Step 6002 | loss: 0.2200599567550752 | accuracy: 0.9176649305555555 \n",
      "Epoch 15 | Step 6003 | loss: 0.2201151817500426 | accuracy: 0.9175467451523546 \n",
      "Epoch 15 | Step 6004 | loss: 0.22000702633136543 | accuracy: 0.917601864640884 \n",
      "Epoch 15 | Step 6005 | loss: 0.21986770303535066 | accuracy: 0.9176997245179064 \n",
      "Epoch 15 | Step 6006 | loss: 0.21971203695859884 | accuracy: 0.9177541208791209 \n",
      "Epoch 15 | Step 6007 | loss: 0.21943229373595485 | accuracy: 0.9178938356164383 \n",
      "Epoch 15 | Step 6008 | loss: 0.21934713905707734 | accuracy: 0.9178620218579235 \n",
      "Epoch 15 | Step 6009 | loss: 0.21915046998606716 | accuracy: 0.9179155313351499 \n",
      "Epoch 15 | Step 6010 | loss: 0.2189125742803773 | accuracy: 0.9180112092391305 \n",
      "Epoch 15 | Step 6011 | loss: 0.21915602984871 | accuracy: 0.9180216802168022 \n",
      "Epoch 15 | Step 6012 | loss: 0.21935697916794467 | accuracy: 0.9179054054054054 \n",
      "Epoch 15 | Step 6013 | loss: 0.21943943011712513 | accuracy: 0.9179582210242587 \n",
      "Epoch 15 | Step 6014 | loss: 0.22004161965382354 | accuracy: 0.9177167338709677 \n",
      "Epoch 15 | Step 6015 | loss: 0.2200588580550521 | accuracy: 0.9176859919571045 \n",
      "Epoch 15 | Step 6016 | loss: 0.21996275078565042 | accuracy: 0.917697192513369 \n",
      "Epoch 15 | Step 6017 | loss: 0.2198090870976448 | accuracy: 0.9178333333333333 \n",
      "Epoch 15 | Step 6018 | loss: 0.21963236225332985 | accuracy: 0.9178856382978723 \n",
      "Epoch 15 | Step 6019 | loss: 0.21949723760155215 | accuracy: 0.9179376657824934 \n",
      "Epoch 15 | Step 6020 | loss: 0.21967852038760033 | accuracy: 0.9177827380952381 \n",
      "Epoch 15 | Step 6021 | loss: 0.2194790120450362 | accuracy: 0.9178759894459103 \n",
      "Epoch 15 | Step 6022 | loss: 0.21925029725228484 | accuracy: 0.91796875 \n",
      "Epoch 15 | Step 6023 | loss: 0.21907960611769534 | accuracy: 0.9180200131233596 \n",
      "Epoch 15 | Step 6024 | loss: 0.21891282477381965 | accuracy: 0.9180301047120419 \n",
      "Epoch 15 | Step 6025 | loss: 0.21879060428307512 | accuracy: 0.9180401436031331 \n",
      "Epoch 15 | Step 6026 | loss: 0.21883369813440368 | accuracy: 0.9180094401041666 \n",
      "Epoch 15 | Step 6027 | loss: 0.2192836604528613 | accuracy: 0.9178165584415584 \n",
      "Epoch 15 | Step 6028 | loss: 0.2195118445073076 | accuracy: 0.9177865932642487 \n",
      "Epoch 15 | Step 6029 | loss: 0.21967068709221305 | accuracy: 0.9177971576227391 \n",
      "Epoch 15 | Step 6030 | loss: 0.21948397783658555 | accuracy: 0.9178882087628866 \n",
      "Epoch 15 | Step 6031 | loss: 0.21965853530904014 | accuracy: 0.9178582904884319 \n",
      "Epoch 15 | Step 6032 | loss: 0.21959661495609162 | accuracy: 0.9179086538461538 \n",
      "Epoch 15 | Step 6033 | loss: 0.21970527310429327 | accuracy: 0.9177589514066496 \n",
      "Epoch 15 | Step 6034 | loss: 0.21951759825175515 | accuracy: 0.9178491709183674 \n",
      "Epoch 15 | Step 6035 | loss: 0.21932117191662315 | accuracy: 0.9178991730279898 \n",
      "Epoch 15 | Step 6036 | loss: 0.21945399244500297 | accuracy: 0.9177506345177665 \n",
      "Epoch 15 | Step 6037 | loss: 0.2193312258094172 | accuracy: 0.9177610759493671 \n",
      "Epoch 15 | Step 6038 | loss: 0.21928106167475986 | accuracy: 0.9178109217171717 \n",
      "Epoch 15 | Step 6039 | loss: 0.2193575905875235 | accuracy: 0.9178211586901763 \n",
      "Epoch 15 | Step 6040 | loss: 0.2195471340799751 | accuracy: 0.917713567839196 \n",
      "Epoch 15 | Step 6041 | loss: 0.2193683584344417 | accuracy: 0.9178023182957393 \n",
      "Epoch 15 | Step 6042 | loss: 0.21965515857562423 | accuracy: 0.9177734375 \n",
      "Epoch 15 | Step 6043 | loss: 0.21964450758368595 | accuracy: 0.9177447007481296 \n",
      "Epoch 15 | Step 6044 | loss: 0.2199954395900615 | accuracy: 0.9175995024875622 \n",
      "Epoch 15 | Step 6045 | loss: 0.21963947824671606 | accuracy: 0.917803970223325 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.5520108938217163 | accuracy: 0.734375 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.5668375194072723 | accuracy: 0.765625 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.5026806990305582 | accuracy: 0.78125 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4841902479529381 | accuracy: 0.796875 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4914343416690826 | accuracy: 0.796875 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.48107726375261944 | accuracy: 0.796875 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.46973091789654325 | accuracy: 0.8013392857142857 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.45886532962322235 | accuracy: 0.806640625 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4536527891953786 | accuracy: 0.8107638888888888 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.45315939784049986 | accuracy: 0.8140625 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.45799032666466455 | accuracy: 0.8139204545454546 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4505564520756404 | accuracy: 0.8190104166666666 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.45625849870535046 | accuracy: 0.8149038461538461 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.46324150051389423 | accuracy: 0.8136160714285714 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.45191678404808044 | accuracy: 0.81875 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4514395631849766 | accuracy: 0.8203125 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4644101437400369 | accuracy: 0.8170955882352942 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4591675367620256 | accuracy: 0.8185763888888888 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.45557223181975515 | accuracy: 0.819078947368421 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.45059583634138106 | accuracy: 0.821875 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.44964814469927833 | accuracy: 0.8229166666666666 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.44459715621037915 | accuracy: 0.8224431818181818 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.44590159084485925 | accuracy: 0.8206521739130435 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.44465020919839543 | accuracy: 0.8216145833333334 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.44952536225318906 | accuracy: 0.819375 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4413210107729985 | accuracy: 0.8209134615384616 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4405029427122187 | accuracy: 0.8206018518518519 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4352048209735325 | accuracy: 0.8231026785714286 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.43756102693491966 | accuracy: 0.822198275862069 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.43935447931289673 | accuracy: 0.8208333333333333 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4336190560171681 | accuracy: 0.8240927419354839 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4278915701434016 | accuracy: 0.82666015625 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.42587796485785284 | accuracy: 0.828125 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.435385046636357 | accuracy: 0.8258272058823529 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.43407741785049436 | accuracy: 0.825 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4289567197362582 | accuracy: 0.8268229166666666 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.43057484481785746 | accuracy: 0.8272804054054054 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.430455124691913 | accuracy: 0.8264802631578947 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.42832383131369567 | accuracy: 0.828125 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4316817671060562 | accuracy: 0.826171875 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.434346640982279 | accuracy: 0.8246951219512195 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.43250108261903125 | accuracy: 0.8258928571428571 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.43180124634920164 | accuracy: 0.825218023255814 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.43489447845654056 | accuracy: 0.82421875 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.43834120631217954 | accuracy: 0.8232940819528368 \n",
      "Epoch 16 | Step 6046 | loss: 0.13214270770549774 | accuracy: 0.953125 \n",
      "Epoch 16 | Step 6047 | loss: 0.23160793632268906 | accuracy: 0.9140625 \n",
      "Epoch 16 | Step 6048 | loss: 0.20702450474103293 | accuracy: 0.9270833333333334 \n",
      "Epoch 16 | Step 6049 | loss: 0.20673973858356476 | accuracy: 0.92578125 \n",
      "Epoch 16 | Step 6050 | loss: 0.20251523852348327 | accuracy: 0.928125 \n",
      "Epoch 16 | Step 6051 | loss: 0.2234939287106196 | accuracy: 0.9166666666666666 \n",
      "Epoch 16 | Step 6052 | loss: 0.2288119409765516 | accuracy: 0.9174107142857143 \n",
      "Epoch 16 | Step 6053 | loss: 0.24356995895504951 | accuracy: 0.916015625 \n",
      "Epoch 16 | Step 6054 | loss: 0.23768538071049583 | accuracy: 0.9184027777777778 \n",
      "Epoch 16 | Step 6055 | loss: 0.24642664641141893 | accuracy: 0.9109375 \n",
      "Epoch 16 | Step 6056 | loss: 0.2471046136184172 | accuracy: 0.90625 \n",
      "Epoch 16 | Step 6057 | loss: 0.2508912521104018 | accuracy: 0.8997395833333334 \n",
      "Epoch 16 | Step 6058 | loss: 0.24500537721010354 | accuracy: 0.9050480769230769 \n",
      "Epoch 16 | Step 6059 | loss: 0.24761649008308137 | accuracy: 0.9051339285714286 \n",
      "Epoch 16 | Step 6060 | loss: 0.24167622923851012 | accuracy: 0.9104166666666667 \n",
      "Epoch 16 | Step 6061 | loss: 0.23201220063492656 | accuracy: 0.9150390625 \n",
      "Epoch 16 | Step 6062 | loss: 0.22760003848987467 | accuracy: 0.9172794117647058 \n",
      "Epoch 16 | Step 6063 | loss: 0.224820327013731 | accuracy: 0.9192708333333334 \n",
      "Epoch 16 | Step 6064 | loss: 0.223029042152982 | accuracy: 0.9202302631578947 \n",
      "Epoch 16 | Step 6065 | loss: 0.226526502892375 | accuracy: 0.9203125 \n",
      "Epoch 16 | Step 6066 | loss: 0.2259792128489131 | accuracy: 0.9203869047619048 \n",
      "Epoch 16 | Step 6067 | loss: 0.2259859838946299 | accuracy: 0.9211647727272727 \n",
      "Epoch 16 | Step 6068 | loss: 0.22447232804868533 | accuracy: 0.920516304347826 \n",
      "Epoch 16 | Step 6069 | loss: 0.21947915510584912 | accuracy: 0.923828125 \n",
      "Epoch 16 | Step 6070 | loss: 0.21649959772825242 | accuracy: 0.925 \n",
      "Epoch 16 | Step 6071 | loss: 0.21628141431854322 | accuracy: 0.9242788461538461 \n",
      "Epoch 16 | Step 6072 | loss: 0.2171352265609635 | accuracy: 0.9253472222222222 \n",
      "Epoch 16 | Step 6073 | loss: 0.21256501307444914 | accuracy: 0.9274553571428571 \n",
      "Epoch 16 | Step 6074 | loss: 0.21004339667229815 | accuracy: 0.927801724137931 \n",
      "Epoch 16 | Step 6075 | loss: 0.21031739935278893 | accuracy: 0.9270833333333334 \n",
      "Epoch 16 | Step 6076 | loss: 0.21068309800278756 | accuracy: 0.9274193548387096 \n",
      "Epoch 16 | Step 6077 | loss: 0.21129103261046112 | accuracy: 0.9267578125 \n",
      "Epoch 16 | Step 6078 | loss: 0.21369498855236804 | accuracy: 0.9256628787878788 \n",
      "Epoch 16 | Step 6079 | loss: 0.21514224984190045 | accuracy: 0.9255514705882353 \n",
      "Epoch 16 | Step 6080 | loss: 0.21366916107279912 | accuracy: 0.9258928571428572 \n",
      "Epoch 16 | Step 6081 | loss: 0.21518087614741588 | accuracy: 0.9249131944444444 \n",
      "Epoch 16 | Step 6082 | loss: 0.212619307476121 | accuracy: 0.9256756756756757 \n",
      "Epoch 16 | Step 6083 | loss: 0.21196070352667257 | accuracy: 0.9259868421052632 \n",
      "Epoch 16 | Step 6084 | loss: 0.21055968105793 | accuracy: 0.9258814102564102 \n",
      "Epoch 16 | Step 6085 | loss: 0.21039543002843858 | accuracy: 0.92578125 \n",
      "Epoch 16 | Step 6086 | loss: 0.210307166343782 | accuracy: 0.9249237804878049 \n",
      "Epoch 16 | Step 6087 | loss: 0.21029013288872583 | accuracy: 0.9252232142857143 \n",
      "Epoch 16 | Step 6088 | loss: 0.2083262212054674 | accuracy: 0.9255087209302325 \n",
      "Epoch 16 | Step 6089 | loss: 0.20633952116424387 | accuracy: 0.9254261363636364 \n",
      "Epoch 16 | Step 6090 | loss: 0.2077161431312561 | accuracy: 0.9243055555555556 \n",
      "Epoch 16 | Step 6091 | loss: 0.20808787384758826 | accuracy: 0.9245923913043478 \n",
      "Epoch 16 | Step 6092 | loss: 0.20700326815564582 | accuracy: 0.9245345744680851 \n",
      "Epoch 16 | Step 6093 | loss: 0.2078251192967097 | accuracy: 0.9241536458333334 \n",
      "Epoch 16 | Step 6094 | loss: 0.20582082882827643 | accuracy: 0.9250637755102041 \n",
      "Epoch 16 | Step 6095 | loss: 0.20691411569714546 | accuracy: 0.9246875 \n",
      "Epoch 16 | Step 6096 | loss: 0.2107950923781769 | accuracy: 0.9237132352941176 \n",
      "Epoch 16 | Step 6097 | loss: 0.21253813989460468 | accuracy: 0.9221754807692307 \n",
      "Epoch 16 | Step 6098 | loss: 0.21137572079896927 | accuracy: 0.9224646226415094 \n",
      "Epoch 16 | Step 6099 | loss: 0.21133596960593154 | accuracy: 0.9224537037037037 \n",
      "Epoch 16 | Step 6100 | loss: 0.2111537980762395 | accuracy: 0.9227272727272727 \n",
      "Epoch 16 | Step 6101 | loss: 0.21321364744965518 | accuracy: 0.9221540178571429 \n",
      "Epoch 16 | Step 6102 | loss: 0.21229548320958488 | accuracy: 0.9226973684210527 \n",
      "Epoch 16 | Step 6103 | loss: 0.21319355340353374 | accuracy: 0.9229525862068966 \n",
      "Epoch 16 | Step 6104 | loss: 0.21356486301806013 | accuracy: 0.9231991525423728 \n",
      "Epoch 16 | Step 6105 | loss: 0.2150157768279314 | accuracy: 0.9221354166666667 \n",
      "Epoch 16 | Step 6106 | loss: 0.21470912155069288 | accuracy: 0.9223872950819673 \n",
      "Epoch 16 | Step 6107 | loss: 0.21473928264552547 | accuracy: 0.9223790322580645 \n",
      "Epoch 16 | Step 6108 | loss: 0.21484962401408997 | accuracy: 0.921875 \n",
      "Epoch 16 | Step 6109 | loss: 0.21346148138400167 | accuracy: 0.92236328125 \n",
      "Epoch 16 | Step 6110 | loss: 0.21431403652979777 | accuracy: 0.9223557692307692 \n",
      "Epoch 16 | Step 6111 | loss: 0.2128268199210817 | accuracy: 0.9225852272727273 \n",
      "Epoch 16 | Step 6112 | loss: 0.21179758401504203 | accuracy: 0.9230410447761194 \n",
      "Epoch 16 | Step 6113 | loss: 0.2112766099984155 | accuracy: 0.9232536764705882 \n",
      "Epoch 16 | Step 6114 | loss: 0.2123884911770406 | accuracy: 0.9221014492753623 \n",
      "Epoch 16 | Step 6115 | loss: 0.21315804879580225 | accuracy: 0.9220982142857143 \n",
      "Epoch 16 | Step 6116 | loss: 0.21405925077032034 | accuracy: 0.9214348591549296 \n",
      "Epoch 16 | Step 6117 | loss: 0.21316391219281486 | accuracy: 0.9216579861111112 \n",
      "Epoch 16 | Step 6118 | loss: 0.21406160631816679 | accuracy: 0.9210188356164384 \n",
      "Epoch 16 | Step 6119 | loss: 0.21445837264528142 | accuracy: 0.9210304054054054 \n",
      "Epoch 16 | Step 6120 | loss: 0.21498195300499592 | accuracy: 0.9210416666666666 \n",
      "Epoch 16 | Step 6121 | loss: 0.21391330865260796 | accuracy: 0.9214638157894737 \n",
      "Epoch 16 | Step 6122 | loss: 0.2154044208007973 | accuracy: 0.9208603896103896 \n",
      "Epoch 16 | Step 6123 | loss: 0.2147190890824183 | accuracy: 0.921073717948718 \n",
      "Epoch 16 | Step 6124 | loss: 0.21393744600347323 | accuracy: 0.9210838607594937 \n",
      "Epoch 16 | Step 6125 | loss: 0.21395204188302155 | accuracy: 0.92109375 \n",
      "Epoch 16 | Step 6126 | loss: 0.2148719372020827 | accuracy: 0.9211033950617284 \n",
      "Epoch 16 | Step 6127 | loss: 0.21392176291201168 | accuracy: 0.9216844512195121 \n",
      "Epoch 16 | Step 6128 | loss: 0.21448304288717635 | accuracy: 0.921875 \n",
      "Epoch 16 | Step 6129 | loss: 0.2143228422140791 | accuracy: 0.9220610119047619 \n",
      "Epoch 16 | Step 6130 | loss: 0.21481690117541477 | accuracy: 0.9220588235294118 \n",
      "Epoch 16 | Step 6131 | loss: 0.21364784543943954 | accuracy: 0.9227834302325582 \n",
      "Epoch 16 | Step 6132 | loss: 0.213301603393308 | accuracy: 0.9229525862068966 \n",
      "Epoch 16 | Step 6133 | loss: 0.21346246527338567 | accuracy: 0.9229403409090909 \n",
      "Epoch 16 | Step 6134 | loss: 0.21312554942423034 | accuracy: 0.9224016853932584 \n",
      "Epoch 16 | Step 6135 | loss: 0.2138241772022512 | accuracy: 0.9220486111111111 \n",
      "Epoch 16 | Step 6136 | loss: 0.21365870494436429 | accuracy: 0.9220467032967034 \n",
      "Epoch 16 | Step 6137 | loss: 0.21574430888437704 | accuracy: 0.9211956521739131 \n",
      "Epoch 16 | Step 6138 | loss: 0.21823026392088138 | accuracy: 0.9203629032258065 \n",
      "Epoch 16 | Step 6139 | loss: 0.21720860050396712 | accuracy: 0.9208776595744681 \n",
      "Epoch 16 | Step 6140 | loss: 0.21646047728626347 | accuracy: 0.9210526315789473 \n",
      "Epoch 16 | Step 6141 | loss: 0.21586675313301382 | accuracy: 0.9210611979166666 \n",
      "Epoch 16 | Step 6142 | loss: 0.21548077425698642 | accuracy: 0.9212306701030928 \n",
      "Epoch 16 | Step 6143 | loss: 0.21689663637353446 | accuracy: 0.9205994897959183 \n",
      "Epoch 16 | Step 6144 | loss: 0.21638634146162955 | accuracy: 0.920770202020202 \n",
      "Epoch 16 | Step 6145 | loss: 0.21680834688246248 | accuracy: 0.920625 \n",
      "Epoch 16 | Step 6146 | loss: 0.2169726831045481 | accuracy: 0.9204826732673267 \n",
      "Epoch 16 | Step 6147 | loss: 0.21701148758624111 | accuracy: 0.9204963235294118 \n",
      "Epoch 16 | Step 6148 | loss: 0.21681989620900846 | accuracy: 0.9203580097087378 \n",
      "Epoch 16 | Step 6149 | loss: 0.21711114715211663 | accuracy: 0.9206730769230769 \n",
      "Epoch 16 | Step 6150 | loss: 0.2179192081093788 | accuracy: 0.9203869047619048 \n",
      "Epoch 16 | Step 6151 | loss: 0.21735079185861458 | accuracy: 0.9204009433962265 \n",
      "Epoch 16 | Step 6152 | loss: 0.2176918147184024 | accuracy: 0.920268691588785 \n",
      "Epoch 16 | Step 6153 | loss: 0.21857213304826503 | accuracy: 0.9198495370370371 \n",
      "Epoch 16 | Step 6154 | loss: 0.21758294611349016 | accuracy: 0.9202981651376146 \n",
      "Epoch 16 | Step 6155 | loss: 0.21713782426985825 | accuracy: 0.9204545454545454 \n",
      "Epoch 16 | Step 6156 | loss: 0.2182595562022011 | accuracy: 0.9199042792792793 \n",
      "Epoch 16 | Step 6157 | loss: 0.21887497377714937 | accuracy: 0.9195033482142857 \n",
      "Epoch 16 | Step 6158 | loss: 0.2186668093225597 | accuracy: 0.9196626106194691 \n",
      "Epoch 16 | Step 6159 | loss: 0.21835978355324057 | accuracy: 0.9198190789473685 \n",
      "Epoch 16 | Step 6160 | loss: 0.21768380947734994 | accuracy: 0.9201086956521739 \n",
      "Epoch 16 | Step 6161 | loss: 0.21717565378238413 | accuracy: 0.9203933189655172 \n",
      "Epoch 16 | Step 6162 | loss: 0.21663161628266683 | accuracy: 0.9205395299145299 \n",
      "Epoch 16 | Step 6163 | loss: 0.21666910309912793 | accuracy: 0.9204184322033898 \n",
      "Epoch 16 | Step 6164 | loss: 0.21713041307545505 | accuracy: 0.9199054621848739 \n",
      "Epoch 16 | Step 6165 | loss: 0.2173188840349515 | accuracy: 0.9196614583333333 \n",
      "Epoch 16 | Step 6166 | loss: 0.2165503035153239 | accuracy: 0.9201962809917356 \n",
      "Epoch 16 | Step 6167 | loss: 0.2169343691136016 | accuracy: 0.9198258196721312 \n",
      "Epoch 16 | Step 6168 | loss: 0.21679597947655652 | accuracy: 0.9199695121951219 \n",
      "Epoch 16 | Step 6169 | loss: 0.21782567568363678 | accuracy: 0.9196068548387096 \n",
      "Epoch 16 | Step 6170 | loss: 0.21786631810665127 | accuracy: 0.919375 \n",
      "Epoch 16 | Step 6171 | loss: 0.21718210407665794 | accuracy: 0.9197668650793651 \n",
      "Epoch 16 | Step 6172 | loss: 0.21745476337868394 | accuracy: 0.9194143700787402 \n",
      "Epoch 16 | Step 6173 | loss: 0.21712738845963028 | accuracy: 0.9195556640625 \n",
      "Epoch 16 | Step 6174 | loss: 0.21680401600608526 | accuracy: 0.9196947674418605 \n",
      "Epoch 16 | Step 6175 | loss: 0.2170282844167489 | accuracy: 0.9194711538461539 \n",
      "Epoch 16 | Step 6176 | loss: 0.21749859308923472 | accuracy: 0.9192509541984732 \n",
      "Epoch 16 | Step 6177 | loss: 0.21734167974103577 | accuracy: 0.9195075757575758 \n",
      "Epoch 16 | Step 6178 | loss: 0.21704756250058796 | accuracy: 0.9197603383458647 \n",
      "Epoch 16 | Step 6179 | loss: 0.2162619085787837 | accuracy: 0.9201259328358209 \n",
      "Epoch 16 | Step 6180 | loss: 0.21661817712916265 | accuracy: 0.9199074074074074 \n",
      "Epoch 16 | Step 6181 | loss: 0.21700328013257067 | accuracy: 0.919921875 \n",
      "Epoch 16 | Step 6182 | loss: 0.21764675582194848 | accuracy: 0.9195939781021898 \n",
      "Epoch 16 | Step 6183 | loss: 0.21750767782762429 | accuracy: 0.919723731884058 \n",
      "Epoch 16 | Step 6184 | loss: 0.2180728150679053 | accuracy: 0.919626798561151 \n",
      "Epoch 16 | Step 6185 | loss: 0.21777669526636598 | accuracy: 0.9197544642857143 \n",
      "Epoch 16 | Step 6186 | loss: 0.2175754834468483 | accuracy: 0.9197695035460993 \n",
      "Epoch 16 | Step 6187 | loss: 0.21715882257886335 | accuracy: 0.9197843309859155 \n",
      "Epoch 16 | Step 6188 | loss: 0.21660408591265445 | accuracy: 0.9201267482517482 \n",
      "Epoch 16 | Step 6189 | loss: 0.21654253530626497 | accuracy: 0.9201388888888888 \n",
      "Epoch 16 | Step 6190 | loss: 0.21650891196111152 | accuracy: 0.9199353448275862 \n",
      "Epoch 16 | Step 6191 | loss: 0.21683071079115346 | accuracy: 0.9200556506849316 \n",
      "Epoch 16 | Step 6192 | loss: 0.2168406834509097 | accuracy: 0.9201743197278912 \n",
      "Epoch 16 | Step 6193 | loss: 0.21690331042014263 | accuracy: 0.9200802364864865 \n",
      "Epoch 16 | Step 6194 | loss: 0.21697219571211193 | accuracy: 0.9199874161073825 \n",
      "Epoch 16 | Step 6195 | loss: 0.21614142710963885 | accuracy: 0.9204166666666667 \n",
      "Epoch 16 | Step 6196 | loss: 0.2164233908649312 | accuracy: 0.9203228476821192 \n",
      "Epoch 16 | Step 6197 | loss: 0.21672331438841005 | accuracy: 0.9201274671052632 \n",
      "Epoch 16 | Step 6198 | loss: 0.21724848648886275 | accuracy: 0.9200367647058824 \n",
      "Epoch 16 | Step 6199 | loss: 0.2165297298365599 | accuracy: 0.9202516233766234 \n",
      "Epoch 16 | Step 6200 | loss: 0.21594500661857666 | accuracy: 0.9205645161290322 \n",
      "Epoch 16 | Step 6201 | loss: 0.21501888100726482 | accuracy: 0.9209735576923077 \n",
      "Epoch 16 | Step 6202 | loss: 0.21508732888918775 | accuracy: 0.9209792993630573 \n",
      "Epoch 16 | Step 6203 | loss: 0.21488190041501312 | accuracy: 0.921182753164557 \n",
      "Epoch 16 | Step 6204 | loss: 0.21500141951460508 | accuracy: 0.9210888364779874 \n",
      "Epoch 16 | Step 6205 | loss: 0.21479063606821 | accuracy: 0.92119140625 \n",
      "Epoch 16 | Step 6206 | loss: 0.21445363385151633 | accuracy: 0.921389751552795 \n",
      "Epoch 16 | Step 6207 | loss: 0.21459346756707004 | accuracy: 0.9214891975308642 \n",
      "Epoch 16 | Step 6208 | loss: 0.21378095237755337 | accuracy: 0.9219708588957055 \n",
      "Epoch 16 | Step 6209 | loss: 0.21345124529992662 | accuracy: 0.9220655487804879 \n",
      "Epoch 16 | Step 6210 | loss: 0.21332353245128285 | accuracy: 0.921875 \n",
      "Epoch 16 | Step 6211 | loss: 0.21442569235721268 | accuracy: 0.9215926204819277 \n",
      "Epoch 16 | Step 6212 | loss: 0.21372104293393518 | accuracy: 0.921875 \n",
      "Epoch 16 | Step 6213 | loss: 0.2133734276340831 | accuracy: 0.9217819940476191 \n",
      "Epoch 16 | Step 6214 | loss: 0.21460311180917468 | accuracy: 0.9214127218934911 \n",
      "Epoch 16 | Step 6215 | loss: 0.2144076369702816 | accuracy: 0.9214154411764706 \n",
      "Epoch 16 | Step 6216 | loss: 0.2146340881784757 | accuracy: 0.9214181286549707 \n",
      "Epoch 16 | Step 6217 | loss: 0.21492911559031452 | accuracy: 0.9211482558139535 \n",
      "Epoch 16 | Step 6218 | loss: 0.21402788599360886 | accuracy: 0.9216040462427746 \n",
      "Epoch 16 | Step 6219 | loss: 0.2140958598418825 | accuracy: 0.9216954022988506 \n",
      "Epoch 16 | Step 6220 | loss: 0.21378537933741298 | accuracy: 0.921875 \n",
      "Epoch 16 | Step 6221 | loss: 0.21361745747906918 | accuracy: 0.9220525568181818 \n",
      "Epoch 16 | Step 6222 | loss: 0.21374876483601365 | accuracy: 0.9220515536723164 \n",
      "Epoch 16 | Step 6223 | loss: 0.21372601111534606 | accuracy: 0.9220505617977528 \n",
      "Epoch 16 | Step 6224 | loss: 0.21383355297772577 | accuracy: 0.9220495810055865 \n",
      "Epoch 16 | Step 6225 | loss: 0.2139609320089221 | accuracy: 0.9219618055555555 \n",
      "Epoch 16 | Step 6226 | loss: 0.21356619044479744 | accuracy: 0.9221339779005525 \n",
      "Epoch 16 | Step 6227 | loss: 0.21300539683427785 | accuracy: 0.9223042582417582 \n",
      "Epoch 16 | Step 6228 | loss: 0.2126628335341404 | accuracy: 0.9225580601092896 \n",
      "Epoch 16 | Step 6229 | loss: 0.21268554062218123 | accuracy: 0.922469429347826 \n",
      "Epoch 16 | Step 6230 | loss: 0.21260832997189985 | accuracy: 0.9222972972972973 \n",
      "Epoch 16 | Step 6231 | loss: 0.21271362898731103 | accuracy: 0.9222110215053764 \n",
      "Epoch 16 | Step 6232 | loss: 0.21288003901985877 | accuracy: 0.9222092245989305 \n",
      "Epoch 16 | Step 6233 | loss: 0.2132136422863349 | accuracy: 0.9222074468085106 \n",
      "Epoch 16 | Step 6234 | loss: 0.21277192871643122 | accuracy: 0.9223710317460317 \n",
      "Epoch 16 | Step 6235 | loss: 0.21288155072221632 | accuracy: 0.9222861842105263 \n",
      "Epoch 16 | Step 6236 | loss: 0.21319945295053627 | accuracy: 0.9221204188481675 \n",
      "Epoch 16 | Step 6237 | loss: 0.2134783240617253 | accuracy: 0.9222005208333334 \n",
      "Epoch 16 | Step 6238 | loss: 0.21387342658916902 | accuracy: 0.9220369170984456 \n",
      "Epoch 16 | Step 6239 | loss: 0.2134546411521349 | accuracy: 0.922277706185567 \n",
      "Epoch 16 | Step 6240 | loss: 0.2137532594685371 | accuracy: 0.9221153846153847 \n",
      "Epoch 16 | Step 6241 | loss: 0.21397713280986158 | accuracy: 0.9220344387755102 \n",
      "Epoch 16 | Step 6242 | loss: 0.21423196730199198 | accuracy: 0.921875 \n",
      "Epoch 16 | Step 6243 | loss: 0.21441162142413434 | accuracy: 0.9216382575757576 \n",
      "Epoch 16 | Step 6244 | loss: 0.21491322114165104 | accuracy: 0.9214038944723618 \n",
      "Epoch 16 | Step 6245 | loss: 0.2148846341483295 | accuracy: 0.921328125 \n",
      "Epoch 16 | Step 6246 | loss: 0.2153884227114234 | accuracy: 0.9209421641791045 \n",
      "Epoch 16 | Step 6247 | loss: 0.21555263215288667 | accuracy: 0.9207147277227723 \n",
      "Epoch 16 | Step 6248 | loss: 0.21523576128879204 | accuracy: 0.9208743842364532 \n",
      "Epoch 16 | Step 6249 | loss: 0.2150765540370462 | accuracy: 0.9210324754901961 \n",
      "Epoch 16 | Step 6250 | loss: 0.2151483271725294 | accuracy: 0.9208079268292683 \n",
      "Epoch 16 | Step 6251 | loss: 0.21510690325889195 | accuracy: 0.9208131067961165 \n",
      "Epoch 16 | Step 6252 | loss: 0.21483775395630061 | accuracy: 0.9208182367149759 \n",
      "Epoch 16 | Step 6253 | loss: 0.21449203536702463 | accuracy: 0.9209735576923077 \n",
      "Epoch 16 | Step 6254 | loss: 0.2144433870091678 | accuracy: 0.9208283492822966 \n",
      "Epoch 16 | Step 6255 | loss: 0.2140080633440188 | accuracy: 0.9209821428571429 \n",
      "Epoch 16 | Step 6256 | loss: 0.21377761646116514 | accuracy: 0.9211344786729858 \n",
      "Epoch 16 | Step 6257 | loss: 0.21422297077007452 | accuracy: 0.9209905660377359 \n",
      "Epoch 16 | Step 6258 | loss: 0.2136708920375562 | accuracy: 0.9212881455399061 \n",
      "Epoch 16 | Step 6259 | loss: 0.21352619571593878 | accuracy: 0.9215829439252337 \n",
      "Epoch 16 | Step 6260 | loss: 0.21397876113999723 | accuracy: 0.9214389534883721 \n",
      "Epoch 16 | Step 6261 | loss: 0.21439380583318848 | accuracy: 0.9212962962962963 \n",
      "Epoch 16 | Step 6262 | loss: 0.2147299139009368 | accuracy: 0.9211549539170507 \n",
      "Epoch 16 | Step 6263 | loss: 0.21442933809524828 | accuracy: 0.9212299311926605 \n",
      "Epoch 16 | Step 6264 | loss: 0.21427926201730557 | accuracy: 0.9212328767123288 \n",
      "Epoch 16 | Step 6265 | loss: 0.2142927070740949 | accuracy: 0.92109375 \n",
      "Epoch 16 | Step 6266 | loss: 0.21393746371924607 | accuracy: 0.9211679864253394 \n",
      "Epoch 16 | Step 6267 | loss: 0.2136059106570912 | accuracy: 0.9213823198198198 \n",
      "Epoch 16 | Step 6268 | loss: 0.21360745556619135 | accuracy: 0.92152466367713 \n",
      "Epoch 16 | Step 6269 | loss: 0.21347427013928869 | accuracy: 0.9216657366071429 \n",
      "Epoch 16 | Step 6270 | loss: 0.21367613267567423 | accuracy: 0.9215277777777777 \n",
      "Epoch 16 | Step 6271 | loss: 0.21383897490403822 | accuracy: 0.9215293141592921 \n",
      "Epoch 16 | Step 6272 | loss: 0.21379182226791782 | accuracy: 0.9215308370044053 \n",
      "Epoch 16 | Step 6273 | loss: 0.21378413658066278 | accuracy: 0.9215323464912281 \n",
      "Epoch 16 | Step 6274 | loss: 0.21348299136523596 | accuracy: 0.9215338427947598 \n",
      "Epoch 16 | Step 6275 | loss: 0.21337195892372857 | accuracy: 0.9215353260869565 \n",
      "Epoch 16 | Step 6276 | loss: 0.21355835246768864 | accuracy: 0.9214015151515151 \n",
      "Epoch 16 | Step 6277 | loss: 0.2133652804066138 | accuracy: 0.9213362068965517 \n",
      "Epoch 16 | Step 6278 | loss: 0.21329091980158005 | accuracy: 0.9213385193133047 \n",
      "Epoch 16 | Step 6279 | loss: 0.21341860197229773 | accuracy: 0.921340811965812 \n",
      "Epoch 16 | Step 6280 | loss: 0.21322646589672312 | accuracy: 0.9215425531914894 \n",
      "Epoch 16 | Step 6281 | loss: 0.2134619733255546 | accuracy: 0.9216101694915254 \n",
      "Epoch 16 | Step 6282 | loss: 0.21369823667256138 | accuracy: 0.9214135021097046 \n",
      "Epoch 16 | Step 6283 | loss: 0.21399888488612756 | accuracy: 0.9212184873949579 \n",
      "Epoch 16 | Step 6284 | loss: 0.21356918673697375 | accuracy: 0.921286610878661 \n",
      "Epoch 16 | Step 6285 | loss: 0.2131729506732275 | accuracy: 0.9214192708333333 \n",
      "Epoch 16 | Step 6286 | loss: 0.21333288548212823 | accuracy: 0.9213563278008299 \n",
      "Epoch 16 | Step 6287 | loss: 0.21348777741255345 | accuracy: 0.9213584710743802 \n",
      "Epoch 16 | Step 6288 | loss: 0.21340160533295247 | accuracy: 0.9213605967078189 \n",
      "Epoch 16 | Step 6289 | loss: 0.21282070647680856 | accuracy: 0.9216188524590164 \n",
      "Epoch 16 | Step 6290 | loss: 0.21235809808178824 | accuracy: 0.921875 \n",
      "Epoch 16 | Step 6291 | loss: 0.21222493968661724 | accuracy: 0.921875 \n",
      "Epoch 16 | Step 6292 | loss: 0.2118181112535328 | accuracy: 0.9219382591093117 \n",
      "Epoch 16 | Step 6293 | loss: 0.21204051367878432 | accuracy: 0.9217489919354839 \n",
      "Epoch 16 | Step 6294 | loss: 0.21200667798938042 | accuracy: 0.9218122489959839 \n",
      "Epoch 16 | Step 6295 | loss: 0.21182490549981595 | accuracy: 0.921875 \n",
      "Epoch 16 | Step 6296 | loss: 0.21189943453170865 | accuracy: 0.9217504980079682 \n",
      "Epoch 16 | Step 6297 | loss: 0.21190358720542418 | accuracy: 0.9215649801587301 \n",
      "Epoch 16 | Step 6298 | loss: 0.21178988651501332 | accuracy: 0.9215662055335968 \n",
      "Epoch 16 | Step 6299 | loss: 0.21180360164405324 | accuracy: 0.9214443897637795 \n",
      "Epoch 16 | Step 6300 | loss: 0.21153594516948157 | accuracy: 0.9215686274509803 \n",
      "Epoch 16 | Step 6301 | loss: 0.21153601315745618 | accuracy: 0.92156982421875 \n",
      "Epoch 16 | Step 6302 | loss: 0.21144734269392165 | accuracy: 0.9215710116731517 \n",
      "Epoch 16 | Step 6303 | loss: 0.21164786294391452 | accuracy: 0.9215721899224806 \n",
      "Epoch 16 | Step 6304 | loss: 0.21133297548043223 | accuracy: 0.9216336872586872 \n",
      "Epoch 16 | Step 6305 | loss: 0.21115448456257582 | accuracy: 0.9217548076923077 \n",
      "Epoch 16 | Step 6306 | loss: 0.21095280290734722 | accuracy: 0.921875 \n",
      "Epoch 16 | Step 6307 | loss: 0.21139314365466588 | accuracy: 0.9216960877862596 \n",
      "Epoch 16 | Step 6308 | loss: 0.21133373863286845 | accuracy: 0.9217561787072244 \n",
      "Epoch 16 | Step 6309 | loss: 0.21124723473225127 | accuracy: 0.9218158143939394 \n",
      "Epoch 16 | Step 6310 | loss: 0.2111875145362233 | accuracy: 0.9218160377358491 \n",
      "Epoch 16 | Step 6311 | loss: 0.21107837197867999 | accuracy: 0.9219337406015038 \n",
      "Epoch 16 | Step 6312 | loss: 0.2106744216036484 | accuracy: 0.9220505617977528 \n",
      "Epoch 16 | Step 6313 | loss: 0.21097717955430498 | accuracy: 0.921816697761194 \n",
      "Epoch 16 | Step 6314 | loss: 0.21095803622364112 | accuracy: 0.921875 \n",
      "Epoch 16 | Step 6315 | loss: 0.21112907041830045 | accuracy: 0.9216435185185186 \n",
      "Epoch 16 | Step 6316 | loss: 0.2111324703533931 | accuracy: 0.9215867158671587 \n",
      "Epoch 16 | Step 6317 | loss: 0.21104716261684456 | accuracy: 0.9217026654411765 \n",
      "Epoch 16 | Step 6318 | loss: 0.21113161643073236 | accuracy: 0.9218177655677655 \n",
      "Epoch 16 | Step 6319 | loss: 0.2113581053287226 | accuracy: 0.9218749999999999 \n",
      "Epoch 16 | Step 6320 | loss: 0.21116292784159835 | accuracy: 0.9218749999999999 \n",
      "Epoch 16 | Step 6321 | loss: 0.21133489597696756 | accuracy: 0.9218749999999999 \n",
      "Epoch 16 | Step 6322 | loss: 0.21112216636538506 | accuracy: 0.9219878158844764 \n",
      "Epoch 16 | Step 6323 | loss: 0.21099544175826818 | accuracy: 0.9221560251798561 \n",
      "Epoch 16 | Step 6324 | loss: 0.210962757081007 | accuracy: 0.922155017921147 \n",
      "Epoch 16 | Step 6325 | loss: 0.2110849213254239 | accuracy: 0.9220424107142857 \n",
      "Epoch 16 | Step 6326 | loss: 0.21094681533365062 | accuracy: 0.9222086298932385 \n",
      "Epoch 16 | Step 6327 | loss: 0.21056189901915423 | accuracy: 0.922373670212766 \n",
      "Epoch 16 | Step 6328 | loss: 0.21034675658854912 | accuracy: 0.9223719081272085 \n",
      "Epoch 16 | Step 6329 | loss: 0.210058596155698 | accuracy: 0.9225352112676056 \n",
      "Epoch 16 | Step 6330 | loss: 0.20993384385579508 | accuracy: 0.9225877192982456 \n",
      "Epoch 16 | Step 6331 | loss: 0.20952257960774262 | accuracy: 0.9226398601398601 \n",
      "Epoch 16 | Step 6332 | loss: 0.20959118080004163 | accuracy: 0.9226371951219512 \n",
      "Epoch 16 | Step 6333 | loss: 0.2090866227711861 | accuracy: 0.9228515625 \n",
      "Epoch 16 | Step 6334 | loss: 0.20983177489217586 | accuracy: 0.9227400519031141 \n",
      "Epoch 16 | Step 6335 | loss: 0.20984915575847538 | accuracy: 0.9227370689655172 \n",
      "Epoch 16 | Step 6336 | loss: 0.2100930107290187 | accuracy: 0.9226267182130584 \n",
      "Epoch 16 | Step 6337 | loss: 0.21005829978632184 | accuracy: 0.922677654109589 \n",
      "Epoch 16 | Step 6338 | loss: 0.2100119838306724 | accuracy: 0.9227815699658704 \n",
      "Epoch 16 | Step 6339 | loss: 0.21011278118152596 | accuracy: 0.9227784863945578 \n",
      "Epoch 16 | Step 6340 | loss: 0.2099141494576203 | accuracy: 0.9227754237288136 \n",
      "Epoch 16 | Step 6341 | loss: 0.21001048394906754 | accuracy: 0.9227195945945946 \n",
      "Epoch 16 | Step 6342 | loss: 0.20990590669641182 | accuracy: 0.9228219696969697 \n",
      "Epoch 16 | Step 6343 | loss: 0.20990265684589837 | accuracy: 0.9228187919463087 \n",
      "Epoch 16 | Step 6344 | loss: 0.20971667072595554 | accuracy: 0.9228678929765887 \n",
      "Epoch 16 | Step 6345 | loss: 0.20935728951046856 | accuracy: 0.9230729166666667 \n",
      "Epoch 16 | Step 6346 | loss: 0.20962713974407335 | accuracy: 0.9229132059800664 \n",
      "Epoch 16 | Step 6347 | loss: 0.2093723626400263 | accuracy: 0.9230132450331126 \n",
      "Epoch 16 | Step 6348 | loss: 0.20927360362493155 | accuracy: 0.9231126237623762 \n",
      "Epoch 16 | Step 6349 | loss: 0.20921625783912043 | accuracy: 0.923108552631579 \n",
      "Epoch 16 | Step 6350 | loss: 0.20913154032142425 | accuracy: 0.9231045081967213 \n",
      "Epoch 16 | Step 6351 | loss: 0.2093317365407748 | accuracy: 0.9230494281045751 \n",
      "Epoch 16 | Step 6352 | loss: 0.21010141311280103 | accuracy: 0.9227911237785016 \n",
      "Epoch 16 | Step 6353 | loss: 0.21000954875262903 | accuracy: 0.9228896103896104 \n",
      "Epoch 16 | Step 6354 | loss: 0.2098200020160296 | accuracy: 0.9228863268608414 \n",
      "Epoch 16 | Step 6355 | loss: 0.2099054366710685 | accuracy: 0.9228326612903226 \n",
      "Epoch 16 | Step 6356 | loss: 0.20998789929452424 | accuracy: 0.9228295819935691 \n",
      "Epoch 16 | Step 6357 | loss: 0.20993566803204317 | accuracy: 0.9227764423076923 \n",
      "Epoch 16 | Step 6358 | loss: 0.20974443880275787 | accuracy: 0.9228734025559105 \n",
      "Epoch 16 | Step 6359 | loss: 0.21005934499393975 | accuracy: 0.9228702229299363 \n",
      "Epoch 16 | Step 6360 | loss: 0.21063201790527683 | accuracy: 0.9227678571428571 \n",
      "Epoch 16 | Step 6361 | loss: 0.21049106666888986 | accuracy: 0.9228639240506329 \n",
      "Epoch 16 | Step 6362 | loss: 0.2102701069217186 | accuracy: 0.9229593848580442 \n",
      "Epoch 16 | Step 6363 | loss: 0.2105662976772342 | accuracy: 0.9228577044025157 \n",
      "Epoch 16 | Step 6364 | loss: 0.2106028213092712 | accuracy: 0.922903605015674 \n",
      "Epoch 16 | Step 6365 | loss: 0.2104156470275483 | accuracy: 0.92294921875 \n",
      "Epoch 16 | Step 6366 | loss: 0.2104332976600276 | accuracy: 0.9228485202492211 \n",
      "Epoch 16 | Step 6367 | loss: 0.2108672997387854 | accuracy: 0.922748447204969 \n",
      "Epoch 16 | Step 6368 | loss: 0.2106633582051508 | accuracy: 0.9228424922600619 \n",
      "Epoch 16 | Step 6369 | loss: 0.21037696795193125 | accuracy: 0.9230324074074074 \n",
      "Epoch 16 | Step 6370 | loss: 0.21057578596931228 | accuracy: 0.9229326923076923 \n",
      "Epoch 16 | Step 6371 | loss: 0.2103518476264059 | accuracy: 0.923073236196319 \n",
      "Epoch 16 | Step 6372 | loss: 0.21056009588666275 | accuracy: 0.9229262232415902 \n",
      "Epoch 16 | Step 6373 | loss: 0.21051936893065157 | accuracy: 0.922923018292683 \n",
      "Epoch 16 | Step 6374 | loss: 0.211074790659737 | accuracy: 0.9225873860182371 \n",
      "Epoch 16 | Step 6375 | loss: 0.21100382783421956 | accuracy: 0.9226799242424243 \n",
      "Epoch 16 | Step 6376 | loss: 0.21089218355422645 | accuracy: 0.9226774924471299 \n",
      "Epoch 16 | Step 6377 | loss: 0.2108561802453484 | accuracy: 0.9226750753012049 \n",
      "Epoch 16 | Step 6378 | loss: 0.2107035980948635 | accuracy: 0.9227665165165165 \n",
      "Epoch 16 | Step 6379 | loss: 0.21081807853620557 | accuracy: 0.9226702844311377 \n",
      "Epoch 16 | Step 6380 | loss: 0.2105313936832235 | accuracy: 0.9228078358208955 \n",
      "Epoch 16 | Step 6381 | loss: 0.21030074966672269 | accuracy: 0.9228980654761905 \n",
      "Epoch 16 | Step 6382 | loss: 0.21028731667190692 | accuracy: 0.9228022997032641 \n",
      "Epoch 16 | Step 6383 | loss: 0.2103882164490469 | accuracy: 0.9228457840236687 \n",
      "Epoch 16 | Step 6384 | loss: 0.21034387247444597 | accuracy: 0.9228890117994101 \n",
      "Epoch 16 | Step 6385 | loss: 0.2100438897552735 | accuracy: 0.9230238970588235 \n",
      "Epoch 16 | Step 6386 | loss: 0.20991586366138493 | accuracy: 0.9230205278592375 \n",
      "Epoch 16 | Step 6387 | loss: 0.20977357956880358 | accuracy: 0.9230628654970761 \n",
      "Epoch 16 | Step 6388 | loss: 0.2095325873627085 | accuracy: 0.9231505102040817 \n",
      "Epoch 16 | Step 6389 | loss: 0.2093208866562087 | accuracy: 0.9232376453488372 \n",
      "Epoch 16 | Step 6390 | loss: 0.20931397684026448 | accuracy: 0.9231884057971015 \n",
      "Epoch 16 | Step 6391 | loss: 0.20931508933662327 | accuracy: 0.9232297687861272 \n",
      "Epoch 16 | Step 6392 | loss: 0.20913174532632997 | accuracy: 0.9232258645533141 \n",
      "Epoch 16 | Step 6393 | loss: 0.2095871995813373 | accuracy: 0.9230872844827587 \n",
      "Epoch 16 | Step 6394 | loss: 0.20950736420330474 | accuracy: 0.9230390401146131 \n",
      "Epoch 16 | Step 6395 | loss: 0.20938495749873767 | accuracy: 0.9230803571428572 \n",
      "Epoch 16 | Step 6396 | loss: 0.2092333852374485 | accuracy: 0.9231659544159544 \n",
      "Epoch 16 | Step 6397 | loss: 0.20956515024458475 | accuracy: 0.9231178977272727 \n",
      "Epoch 16 | Step 6398 | loss: 0.2093270062957032 | accuracy: 0.9232029036827195 \n",
      "Epoch 16 | Step 6399 | loss: 0.2090447042979257 | accuracy: 0.923243290960452 \n",
      "Epoch 16 | Step 6400 | loss: 0.20885450509442402 | accuracy: 0.9232834507042254 \n",
      "Epoch 16 | Step 6401 | loss: 0.2086870542758803 | accuracy: 0.9233233848314607 \n",
      "Epoch 16 | Step 6402 | loss: 0.2087544474218572 | accuracy: 0.9233630952380952 \n",
      "Epoch 16 | Step 6403 | loss: 0.20868246503923518 | accuracy: 0.9234025837988827 \n",
      "Epoch 16 | Step 6404 | loss: 0.20845620472160548 | accuracy: 0.9235288997214485 \n",
      "Epoch 16 | Step 6405 | loss: 0.208201856797354 | accuracy: 0.9236545138888889 \n",
      "Epoch 16 | Step 6406 | loss: 0.2082451664200284 | accuracy: 0.9235630193905817 \n",
      "Epoch 16 | Step 6407 | loss: 0.20812759528873037 | accuracy: 0.923644682320442 \n",
      "Epoch 16 | Step 6408 | loss: 0.20796545823784562 | accuracy: 0.9237258953168044 \n",
      "Epoch 16 | Step 6409 | loss: 0.2078312607686761 | accuracy: 0.9237208104395604 \n",
      "Epoch 16 | Step 6410 | loss: 0.20756794803150705 | accuracy: 0.9238869863013699 \n",
      "Epoch 16 | Step 6411 | loss: 0.2075270254857064 | accuracy: 0.9237961065573771 \n",
      "Epoch 16 | Step 6412 | loss: 0.20733432249452818 | accuracy: 0.9238760217983651 \n",
      "Epoch 16 | Step 6413 | loss: 0.20717960552555378 | accuracy: 0.9239130434782609 \n",
      "Epoch 16 | Step 6414 | loss: 0.20739443391198056 | accuracy: 0.9239075203252033 \n",
      "Epoch 16 | Step 6415 | loss: 0.2076399706203389 | accuracy: 0.9238175675675676 \n",
      "Epoch 16 | Step 6416 | loss: 0.20766486778774987 | accuracy: 0.9238965633423181 \n",
      "Epoch 16 | Step 6417 | loss: 0.20820715495695663 | accuracy: 0.9237231182795699 \n",
      "Epoch 16 | Step 6418 | loss: 0.20819517467720253 | accuracy: 0.923718163538874 \n",
      "Epoch 16 | Step 6419 | loss: 0.20806422440165814 | accuracy: 0.9237550133689839 \n",
      "Epoch 16 | Step 6420 | loss: 0.20788338678081822 | accuracy: 0.9239166666666667 \n",
      "Epoch 16 | Step 6421 | loss: 0.20770941643995483 | accuracy: 0.9239112367021277 \n",
      "Epoch 16 | Step 6422 | loss: 0.20763695640217714 | accuracy: 0.9238643899204244 \n",
      "Epoch 16 | Step 6423 | loss: 0.20784707845400557 | accuracy: 0.9237351190476191 \n",
      "Epoch 16 | Step 6424 | loss: 0.20768051742917623 | accuracy: 0.9238126649076517 \n",
      "Epoch 16 | Step 6425 | loss: 0.20748138675760275 | accuracy: 0.9239309210526315 \n",
      "Epoch 16 | Step 6426 | loss: 0.20736187693523603 | accuracy: 0.9239665354330708 \n",
      "Epoch 16 | Step 6427 | loss: 0.20716160131101513 | accuracy: 0.923961060209424 \n",
      "Epoch 16 | Step 6428 | loss: 0.20700359162594872 | accuracy: 0.9240372062663186 \n",
      "Epoch 16 | Step 6429 | loss: 0.20704785646133428 | accuracy: 0.9239908854166666 \n",
      "Epoch 16 | Step 6430 | loss: 0.20737098738938176 | accuracy: 0.9238636363636363 \n",
      "Epoch 16 | Step 6431 | loss: 0.2075239947750932 | accuracy: 0.9238584844559585 \n",
      "Epoch 16 | Step 6432 | loss: 0.20769776982430949 | accuracy: 0.9238533591731266 \n",
      "Epoch 16 | Step 6433 | loss: 0.20748669754944196 | accuracy: 0.9239288015463918 \n",
      "Epoch 16 | Step 6434 | loss: 0.2075829969905795 | accuracy: 0.9239235218508998 \n",
      "Epoch 16 | Step 6435 | loss: 0.2075362792095312 | accuracy: 0.9239182692307693 \n",
      "Epoch 16 | Step 6436 | loss: 0.20761125762482427 | accuracy: 0.9238730818414322 \n",
      "Epoch 16 | Step 6437 | loss: 0.20738648008365101 | accuracy: 0.9239875637755102 \n",
      "Epoch 16 | Step 6438 | loss: 0.20721495372383036 | accuracy: 0.9240219465648855 \n",
      "Epoch 16 | Step 6439 | loss: 0.20728211200365856 | accuracy: 0.9239371827411168 \n",
      "Epoch 16 | Step 6440 | loss: 0.20715180674119835 | accuracy: 0.9239715189873418 \n",
      "Epoch 16 | Step 6441 | loss: 0.20711516029192034 | accuracy: 0.9240056818181818 \n",
      "Epoch 16 | Step 6442 | loss: 0.20715592164424257 | accuracy: 0.924000314861461 \n",
      "Epoch 16 | Step 6443 | loss: 0.20736595453816137 | accuracy: 0.9238771984924623 \n",
      "Epoch 16 | Step 6444 | loss: 0.2071873226802898 | accuracy: 0.9239113408521303 \n",
      "Epoch 16 | Step 6445 | loss: 0.2073875149432569 | accuracy: 0.9238671875 \n",
      "Epoch 16 | Step 6446 | loss: 0.20734187504485652 | accuracy: 0.9238622194513716 \n",
      "Epoch 16 | Step 6447 | loss: 0.20773117560244608 | accuracy: 0.923701803482587 \n",
      "Epoch 16 | Step 6448 | loss: 0.20736833977935917 | accuracy: 0.9238911290322581 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.5817004442214966 | accuracy: 0.734375 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.5940514206886292 | accuracy: 0.765625 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.524633139371872 | accuracy: 0.78125 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.5026668831706047 | accuracy: 0.796875 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.5113097608089447 | accuracy: 0.796875 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.5019268840551376 | accuracy: 0.796875 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.48873406648635864 | accuracy: 0.8013392857142857 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4771592877805233 | accuracy: 0.806640625 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.47127120362387764 | accuracy: 0.8107638888888888 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.46947007775306704 | accuracy: 0.8140625 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4746550592509183 | accuracy: 0.8125 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4669745738307635 | accuracy: 0.8177083333333334 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.472887600843723 | accuracy: 0.8137019230769231 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4809603712388447 | accuracy: 0.8113839285714286 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.46847952405611676 | accuracy: 0.8166666666666667 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4685219507664442 | accuracy: 0.8173828125 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4822571891195634 | accuracy: 0.8143382352941176 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4765729606151581 | accuracy: 0.8168402777777778 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.47243720449899373 | accuracy: 0.8174342105263158 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.46688742786645887 | accuracy: 0.8203125 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.46541676492918105 | accuracy: 0.8214285714285714 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.460043880072507 | accuracy: 0.8210227272727273 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4609539340371671 | accuracy: 0.8199728260869565 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.45980192100008327 | accuracy: 0.8216145833333334 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.46510428071022036 | accuracy: 0.819375 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.45652808191684574 | accuracy: 0.8215144230769231 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4564198768801159 | accuracy: 0.8217592592592593 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.45047936535307337 | accuracy: 0.82421875 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4529406412922103 | accuracy: 0.8232758620689655 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4552872742215792 | accuracy: 0.821875 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4492904414092341 | accuracy: 0.8251008064516129 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.44329396029934287 | accuracy: 0.82763671875 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.44126549317981256 | accuracy: 0.8290719696969697 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.45096513146863265 | accuracy: 0.8267463235294118 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.44969005712441035 | accuracy: 0.8258928571428571 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.44403134162227315 | accuracy: 0.8276909722222222 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.44540135159685806 | accuracy: 0.8277027027027027 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.44536515168453517 | accuracy: 0.826891447368421 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4432494139824158 | accuracy: 0.8285256410256411 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4472191590815783 | accuracy: 0.8265625 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.45014496438386964 | accuracy: 0.8250762195121951 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.44816176699740545 | accuracy: 0.8262648809523809 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.44729259714137676 | accuracy: 0.8255813953488372 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4506924616342241 | accuracy: 0.8245738636363636 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.45439673430389826 | accuracy: 0.823641304175059 \n",
      "Epoch 17 | Step 6449 | loss: 0.1152639165520668 | accuracy: 0.96875 \n",
      "Epoch 17 | Step 6450 | loss: 0.20587718859314919 | accuracy: 0.9296875 \n",
      "Epoch 17 | Step 6451 | loss: 0.1865138237675031 | accuracy: 0.9322916666666666 \n",
      "Epoch 17 | Step 6452 | loss: 0.1976082269102335 | accuracy: 0.9296875 \n",
      "Epoch 17 | Step 6453 | loss: 0.189926315844059 | accuracy: 0.928125 \n",
      "Epoch 17 | Step 6454 | loss: 0.21426191056768099 | accuracy: 0.9166666666666666 \n",
      "Epoch 17 | Step 6455 | loss: 0.22161638417414256 | accuracy: 0.9196428571428571 \n",
      "Epoch 17 | Step 6456 | loss: 0.2380726346746087 | accuracy: 0.91796875 \n",
      "Epoch 17 | Step 6457 | loss: 0.23301594373252657 | accuracy: 0.9201388888888888 \n",
      "Epoch 17 | Step 6458 | loss: 0.23849250003695488 | accuracy: 0.9140625 \n",
      "Epoch 17 | Step 6459 | loss: 0.2380794185129079 | accuracy: 0.9119318181818182 \n",
      "Epoch 17 | Step 6460 | loss: 0.23867723159492016 | accuracy: 0.9114583333333334 \n",
      "Epoch 17 | Step 6461 | loss: 0.23318006040958258 | accuracy: 0.9158653846153846 \n",
      "Epoch 17 | Step 6462 | loss: 0.23631440794893674 | accuracy: 0.9151785714285714 \n",
      "Epoch 17 | Step 6463 | loss: 0.23011826127767562 | accuracy: 0.9197916666666667 \n",
      "Epoch 17 | Step 6464 | loss: 0.2209932510741055 | accuracy: 0.923828125 \n",
      "Epoch 17 | Step 6465 | loss: 0.21637370086768093 | accuracy: 0.9264705882352942 \n",
      "Epoch 17 | Step 6466 | loss: 0.21418537572026253 | accuracy: 0.9279513888888888 \n",
      "Epoch 17 | Step 6467 | loss: 0.21271506383230812 | accuracy: 0.9292763157894737 \n",
      "Epoch 17 | Step 6468 | loss: 0.21708102189004422 | accuracy: 0.92890625 \n",
      "Epoch 17 | Step 6469 | loss: 0.21610278068553834 | accuracy: 0.9293154761904762 \n",
      "Epoch 17 | Step 6470 | loss: 0.21559321304613893 | accuracy: 0.9303977272727273 \n",
      "Epoch 17 | Step 6471 | loss: 0.2147551376534545 | accuracy: 0.9293478260869565 \n",
      "Epoch 17 | Step 6472 | loss: 0.20988892391324043 | accuracy: 0.931640625 \n",
      "Epoch 17 | Step 6473 | loss: 0.20633013397455216 | accuracy: 0.933125 \n",
      "Epoch 17 | Step 6474 | loss: 0.20537846850661132 | accuracy: 0.9326923076923077 \n",
      "Epoch 17 | Step 6475 | loss: 0.20500713724780967 | accuracy: 0.9334490740740741 \n",
      "Epoch 17 | Step 6476 | loss: 0.20056663400360517 | accuracy: 0.9352678571428571 \n",
      "Epoch 17 | Step 6477 | loss: 0.19859069071967025 | accuracy: 0.9348060344827587 \n",
      "Epoch 17 | Step 6478 | loss: 0.19988708843787512 | accuracy: 0.9338541666666667 \n",
      "Epoch 17 | Step 6479 | loss: 0.20069398226276522 | accuracy: 0.9339717741935484 \n",
      "Epoch 17 | Step 6480 | loss: 0.2015687171369791 | accuracy: 0.93310546875 \n",
      "Epoch 17 | Step 6481 | loss: 0.20371134804956842 | accuracy: 0.9318181818181818 \n",
      "Epoch 17 | Step 6482 | loss: 0.20496688826995738 | accuracy: 0.9319852941176471 \n",
      "Epoch 17 | Step 6483 | loss: 0.2041377318756921 | accuracy: 0.9316964285714285 \n",
      "Epoch 17 | Step 6484 | loss: 0.2060479020906819 | accuracy: 0.9305555555555556 \n",
      "Epoch 17 | Step 6485 | loss: 0.20309068041073308 | accuracy: 0.9320101351351351 \n",
      "Epoch 17 | Step 6486 | loss: 0.20201152112138898 | accuracy: 0.9321546052631579 \n",
      "Epoch 17 | Step 6487 | loss: 0.2005036513392742 | accuracy: 0.9326923076923077 \n",
      "Epoch 17 | Step 6488 | loss: 0.20033325608819724 | accuracy: 0.93203125 \n",
      "Epoch 17 | Step 6489 | loss: 0.20016220738975013 | accuracy: 0.9310213414634146 \n",
      "Epoch 17 | Step 6490 | loss: 0.1997948886737937 | accuracy: 0.9319196428571429 \n",
      "Epoch 17 | Step 6491 | loss: 0.1977902917667877 | accuracy: 0.9324127906976745 \n",
      "Epoch 17 | Step 6492 | loss: 0.19634982063011688 | accuracy: 0.9325284090909091 \n",
      "Epoch 17 | Step 6493 | loss: 0.1973380274242825 | accuracy: 0.9315972222222222 \n",
      "Epoch 17 | Step 6494 | loss: 0.19738759424375452 | accuracy: 0.9320652173913043 \n",
      "Epoch 17 | Step 6495 | loss: 0.19704083242314926 | accuracy: 0.9321808510638298 \n",
      "Epoch 17 | Step 6496 | loss: 0.19786473487814268 | accuracy: 0.9319661458333334 \n",
      "Epoch 17 | Step 6497 | loss: 0.1958433158543645 | accuracy: 0.9330357142857143 \n",
      "Epoch 17 | Step 6498 | loss: 0.19717030346393585 | accuracy: 0.9325 \n",
      "Epoch 17 | Step 6499 | loss: 0.20014809042799706 | accuracy: 0.9310661764705882 \n",
      "Epoch 17 | Step 6500 | loss: 0.20188300540814033 | accuracy: 0.9296875 \n",
      "Epoch 17 | Step 6501 | loss: 0.2010028213262558 | accuracy: 0.9295400943396226 \n",
      "Epoch 17 | Step 6502 | loss: 0.20036799239891548 | accuracy: 0.9299768518518519 \n",
      "Epoch 17 | Step 6503 | loss: 0.2009212550791827 | accuracy: 0.9295454545454546 \n",
      "Epoch 17 | Step 6504 | loss: 0.20258467883935996 | accuracy: 0.9294084821428571 \n",
      "Epoch 17 | Step 6505 | loss: 0.20210844931895272 | accuracy: 0.9292763157894737 \n",
      "Epoch 17 | Step 6506 | loss: 0.20264184526328383 | accuracy: 0.9294181034482759 \n",
      "Epoch 17 | Step 6507 | loss: 0.2030743150892904 | accuracy: 0.9298199152542372 \n",
      "Epoch 17 | Step 6508 | loss: 0.2048202189306418 | accuracy: 0.9286458333333333 \n",
      "Epoch 17 | Step 6509 | loss: 0.2043539034050019 | accuracy: 0.9285348360655737 \n",
      "Epoch 17 | Step 6510 | loss: 0.20387651603068074 | accuracy: 0.928679435483871 \n",
      "Epoch 17 | Step 6511 | loss: 0.2039799645306572 | accuracy: 0.9285714285714286 \n",
      "Epoch 17 | Step 6512 | loss: 0.20255563070531934 | accuracy: 0.928955078125 \n",
      "Epoch 17 | Step 6513 | loss: 0.20392341510607645 | accuracy: 0.9283653846153846 \n",
      "Epoch 17 | Step 6514 | loss: 0.202490830737533 | accuracy: 0.9285037878787878 \n",
      "Epoch 17 | Step 6515 | loss: 0.20136890304622365 | accuracy: 0.9288712686567164 \n",
      "Epoch 17 | Step 6516 | loss: 0.2008651389795191 | accuracy: 0.9292279411764706 \n",
      "Epoch 17 | Step 6517 | loss: 0.20187018271805585 | accuracy: 0.9291213768115942 \n",
      "Epoch 17 | Step 6518 | loss: 0.2029077925852367 | accuracy: 0.9287946428571429 \n",
      "Epoch 17 | Step 6519 | loss: 0.20395914265807247 | accuracy: 0.9282570422535211 \n",
      "Epoch 17 | Step 6520 | loss: 0.20310168982379967 | accuracy: 0.9286024305555556 \n",
      "Epoch 17 | Step 6521 | loss: 0.20356718277278013 | accuracy: 0.928082191780822 \n",
      "Epoch 17 | Step 6522 | loss: 0.2039464778594069 | accuracy: 0.9277871621621622 \n",
      "Epoch 17 | Step 6523 | loss: 0.20471283614635472 | accuracy: 0.9277083333333334 \n",
      "Epoch 17 | Step 6524 | loss: 0.20371386251951523 | accuracy: 0.9280427631578947 \n",
      "Epoch 17 | Step 6525 | loss: 0.205296390629434 | accuracy: 0.9273538961038961 \n",
      "Epoch 17 | Step 6526 | loss: 0.20487154962924814 | accuracy: 0.9274839743589743 \n",
      "Epoch 17 | Step 6527 | loss: 0.20416392272786255 | accuracy: 0.9274129746835443 \n",
      "Epoch 17 | Step 6528 | loss: 0.20413491707295184 | accuracy: 0.92734375 \n",
      "Epoch 17 | Step 6529 | loss: 0.2051356580154396 | accuracy: 0.9274691358024691 \n",
      "Epoch 17 | Step 6530 | loss: 0.20422906573952704 | accuracy: 0.9279725609756098 \n",
      "Epoch 17 | Step 6531 | loss: 0.20471444133534494 | accuracy: 0.9278990963855421 \n",
      "Epoch 17 | Step 6532 | loss: 0.20467829686545194 | accuracy: 0.9278273809523809 \n",
      "Epoch 17 | Step 6533 | loss: 0.205146640013246 | accuracy: 0.9277573529411764 \n",
      "Epoch 17 | Step 6534 | loss: 0.2039619620109714 | accuracy: 0.9284156976744186 \n",
      "Epoch 17 | Step 6535 | loss: 0.20386931882507503 | accuracy: 0.9285201149425287 \n",
      "Epoch 17 | Step 6536 | loss: 0.20412945561110976 | accuracy: 0.9284446022727273 \n",
      "Epoch 17 | Step 6537 | loss: 0.20380753027589138 | accuracy: 0.9280196629213483 \n",
      "Epoch 17 | Step 6538 | loss: 0.20465300894445848 | accuracy: 0.9274305555555555 \n",
      "Epoch 17 | Step 6539 | loss: 0.20488707999606712 | accuracy: 0.9273695054945055 \n",
      "Epoch 17 | Step 6540 | loss: 0.20688489856927295 | accuracy: 0.9268002717391305 \n",
      "Epoch 17 | Step 6541 | loss: 0.20942009168286482 | accuracy: 0.9259072580645161 \n",
      "Epoch 17 | Step 6542 | loss: 0.20853510847751133 | accuracy: 0.9261968085106383 \n",
      "Epoch 17 | Step 6543 | loss: 0.20760537754548228 | accuracy: 0.9264802631578948 \n",
      "Epoch 17 | Step 6544 | loss: 0.20721947906228408 | accuracy: 0.9264322916666666 \n",
      "Epoch 17 | Step 6545 | loss: 0.20684570803777463 | accuracy: 0.9263853092783505 \n",
      "Epoch 17 | Step 6546 | loss: 0.20795435101097948 | accuracy: 0.9257015306122449 \n",
      "Epoch 17 | Step 6547 | loss: 0.20735779412166042 | accuracy: 0.9259785353535354 \n",
      "Epoch 17 | Step 6548 | loss: 0.2080213171988726 | accuracy: 0.9259375 \n",
      "Epoch 17 | Step 6549 | loss: 0.20823432660043834 | accuracy: 0.9258972772277227 \n",
      "Epoch 17 | Step 6550 | loss: 0.20850786267250196 | accuracy: 0.9257046568627451 \n",
      "Epoch 17 | Step 6551 | loss: 0.20805492252111438 | accuracy: 0.9258191747572816 \n",
      "Epoch 17 | Step 6552 | loss: 0.20821373444050553 | accuracy: 0.9260817307692307 \n",
      "Epoch 17 | Step 6553 | loss: 0.20876941389980774 | accuracy: 0.9255952380952381 \n",
      "Epoch 17 | Step 6554 | loss: 0.20838599771542374 | accuracy: 0.9254127358490566 \n",
      "Epoch 17 | Step 6555 | loss: 0.20877751478246442 | accuracy: 0.9250876168224299 \n",
      "Epoch 17 | Step 6556 | loss: 0.2094374968911763 | accuracy: 0.9246238425925926 \n",
      "Epoch 17 | Step 6557 | loss: 0.20849651180276085 | accuracy: 0.9250286697247706 \n",
      "Epoch 17 | Step 6558 | loss: 0.20816747424277396 | accuracy: 0.9248579545454545 \n",
      "Epoch 17 | Step 6559 | loss: 0.20897214759040528 | accuracy: 0.9244087837837838 \n",
      "Epoch 17 | Step 6560 | loss: 0.20951193823878259 | accuracy: 0.9241071428571429 \n",
      "Epoch 17 | Step 6561 | loss: 0.20925220636139932 | accuracy: 0.9242256637168141 \n",
      "Epoch 17 | Step 6562 | loss: 0.2090867189200301 | accuracy: 0.9242050438596491 \n",
      "Epoch 17 | Step 6563 | loss: 0.20845957424329678 | accuracy: 0.9245923913043478 \n",
      "Epoch 17 | Step 6564 | loss: 0.20804611734788997 | accuracy: 0.9248383620689655 \n",
      "Epoch 17 | Step 6565 | loss: 0.20747659782059175 | accuracy: 0.9250801282051282 \n",
      "Epoch 17 | Step 6566 | loss: 0.2075626434663595 | accuracy: 0.9249205508474576 \n",
      "Epoch 17 | Step 6567 | loss: 0.2078477984466473 | accuracy: 0.9245010504201681 \n",
      "Epoch 17 | Step 6568 | loss: 0.20789914019405845 | accuracy: 0.92421875 \n",
      "Epoch 17 | Step 6569 | loss: 0.20725075309434215 | accuracy: 0.9245867768595041 \n",
      "Epoch 17 | Step 6570 | loss: 0.20754215023556696 | accuracy: 0.9241803278688525 \n",
      "Epoch 17 | Step 6571 | loss: 0.2071175661271181 | accuracy: 0.9242886178861789 \n",
      "Epoch 17 | Step 6572 | loss: 0.2080841474235058 | accuracy: 0.9238911290322581 \n",
      "Epoch 17 | Step 6573 | loss: 0.20813184213638308 | accuracy: 0.923625 \n",
      "Epoch 17 | Step 6574 | loss: 0.20748947466176657 | accuracy: 0.923859126984127 \n",
      "Epoch 17 | Step 6575 | loss: 0.20771093068160412 | accuracy: 0.9234744094488189 \n",
      "Epoch 17 | Step 6576 | loss: 0.20744144963100555 | accuracy: 0.923583984375 \n",
      "Epoch 17 | Step 6577 | loss: 0.20702890208525254 | accuracy: 0.9236918604651163 \n",
      "Epoch 17 | Step 6578 | loss: 0.2071674506251629 | accuracy: 0.9236778846153846 \n",
      "Epoch 17 | Step 6579 | loss: 0.20748091472014218 | accuracy: 0.9236641221374046 \n",
      "Epoch 17 | Step 6580 | loss: 0.20734788883816116 | accuracy: 0.9240056818181818 \n",
      "Epoch 17 | Step 6581 | loss: 0.20675017511037957 | accuracy: 0.9242246240601504 \n",
      "Epoch 17 | Step 6582 | loss: 0.2060306568755143 | accuracy: 0.9245569029850746 \n",
      "Epoch 17 | Step 6583 | loss: 0.20650188133672434 | accuracy: 0.9243055555555556 \n",
      "Epoch 17 | Step 6584 | loss: 0.2070341369356303 | accuracy: 0.9242876838235294 \n",
      "Epoch 17 | Step 6585 | loss: 0.20755271760434132 | accuracy: 0.9240419708029197 \n",
      "Epoch 17 | Step 6586 | loss: 0.20743633747316792 | accuracy: 0.9241394927536232 \n",
      "Epoch 17 | Step 6587 | loss: 0.20805186831908262 | accuracy: 0.923898381294964 \n",
      "Epoch 17 | Step 6588 | loss: 0.2076770431761231 | accuracy: 0.9239955357142857 \n",
      "Epoch 17 | Step 6589 | loss: 0.20753045216308422 | accuracy: 0.9239804964539007 \n",
      "Epoch 17 | Step 6590 | loss: 0.20723420921975463 | accuracy: 0.9241857394366197 \n",
      "Epoch 17 | Step 6591 | loss: 0.20661812197495177 | accuracy: 0.9246066433566433 \n",
      "Epoch 17 | Step 6592 | loss: 0.20644148252904418 | accuracy: 0.9246961805555556 \n",
      "Epoch 17 | Step 6593 | loss: 0.2060850553471467 | accuracy: 0.9245689655172413 \n",
      "Epoch 17 | Step 6594 | loss: 0.20635731212080344 | accuracy: 0.9247645547945206 \n",
      "Epoch 17 | Step 6595 | loss: 0.20632093161547269 | accuracy: 0.9247448979591837 \n",
      "Epoch 17 | Step 6596 | loss: 0.20641236993912107 | accuracy: 0.9246199324324325 \n",
      "Epoch 17 | Step 6597 | loss: 0.20659088368383832 | accuracy: 0.924496644295302 \n",
      "Epoch 17 | Step 6598 | loss: 0.20578598697980247 | accuracy: 0.9248958333333334 \n",
      "Epoch 17 | Step 6599 | loss: 0.20614988045976654 | accuracy: 0.9247723509933775 \n",
      "Epoch 17 | Step 6600 | loss: 0.2061892436131051 | accuracy: 0.9248560855263158 \n",
      "Epoch 17 | Step 6601 | loss: 0.20701503773140753 | accuracy: 0.9246323529411765 \n",
      "Epoch 17 | Step 6602 | loss: 0.2063717567301416 | accuracy: 0.9248173701298701 \n",
      "Epoch 17 | Step 6603 | loss: 0.20576527378251477 | accuracy: 0.9251008064516129 \n",
      "Epoch 17 | Step 6604 | loss: 0.2047731216089466 | accuracy: 0.9255809294871795 \n",
      "Epoch 17 | Step 6605 | loss: 0.2047857282220558 | accuracy: 0.9255573248407644 \n",
      "Epoch 17 | Step 6606 | loss: 0.20450672193701508 | accuracy: 0.9256329113924051 \n",
      "Epoch 17 | Step 6607 | loss: 0.2046911059263742 | accuracy: 0.9255110062893082 \n",
      "Epoch 17 | Step 6608 | loss: 0.20456215438898653 | accuracy: 0.9255859375 \n",
      "Epoch 17 | Step 6609 | loss: 0.20416256292543797 | accuracy: 0.9258540372670807 \n",
      "Epoch 17 | Step 6610 | loss: 0.2041988850881656 | accuracy: 0.9260223765432098 \n",
      "Epoch 17 | Step 6611 | loss: 0.2033525892516221 | accuracy: 0.926476226993865 \n",
      "Epoch 17 | Step 6612 | loss: 0.20293803865135443 | accuracy: 0.9265434451219512 \n",
      "Epoch 17 | Step 6613 | loss: 0.20295533788475123 | accuracy: 0.9263257575757575 \n",
      "Epoch 17 | Step 6614 | loss: 0.2038876467934215 | accuracy: 0.9260165662650602 \n",
      "Epoch 17 | Step 6615 | loss: 0.2031333046535889 | accuracy: 0.9262724550898204 \n",
      "Epoch 17 | Step 6616 | loss: 0.2028272746884752 | accuracy: 0.9263392857142857 \n",
      "Epoch 17 | Step 6617 | loss: 0.2041071102067211 | accuracy: 0.9260355029585798 \n",
      "Epoch 17 | Step 6618 | loss: 0.2041380252689123 | accuracy: 0.9261029411764706 \n",
      "Epoch 17 | Step 6619 | loss: 0.20447945087189562 | accuracy: 0.926078216374269 \n",
      "Epoch 17 | Step 6620 | loss: 0.2046886341819583 | accuracy: 0.9259629360465116 \n",
      "Epoch 17 | Step 6621 | loss: 0.20375607927152187 | accuracy: 0.9263908959537572 \n",
      "Epoch 17 | Step 6622 | loss: 0.20379145865210857 | accuracy: 0.9263649425287356 \n",
      "Epoch 17 | Step 6623 | loss: 0.2034779403252261 | accuracy: 0.9266071428571429 \n",
      "Epoch 17 | Step 6624 | loss: 0.20335893927734683 | accuracy: 0.9267578125 \n",
      "Epoch 17 | Step 6625 | loss: 0.2034817037651431 | accuracy: 0.9267302259887006 \n",
      "Epoch 17 | Step 6626 | loss: 0.20341962854262818 | accuracy: 0.9267029494382022 \n",
      "Epoch 17 | Step 6627 | loss: 0.20362654047388604 | accuracy: 0.9266759776536313 \n",
      "Epoch 17 | Step 6628 | loss: 0.2036711361880104 | accuracy: 0.9266493055555556 \n",
      "Epoch 17 | Step 6629 | loss: 0.20326595191550517 | accuracy: 0.9268819060773481 \n",
      "Epoch 17 | Step 6630 | loss: 0.20264575526036405 | accuracy: 0.9271119505494505 \n",
      "Epoch 17 | Step 6631 | loss: 0.20235378871279988 | accuracy: 0.927339480874317 \n",
      "Epoch 17 | Step 6632 | loss: 0.20249526139915638 | accuracy: 0.9273947010869565 \n",
      "Epoch 17 | Step 6633 | loss: 0.20253493522067328 | accuracy: 0.9272804054054054 \n",
      "Epoch 17 | Step 6634 | loss: 0.20254591886474882 | accuracy: 0.9273353494623656 \n",
      "Epoch 17 | Step 6635 | loss: 0.20253561909265697 | accuracy: 0.9274732620320856 \n",
      "Epoch 17 | Step 6636 | loss: 0.2027549165241579 | accuracy: 0.9275265957446809 \n",
      "Epoch 17 | Step 6637 | loss: 0.20223861855883446 | accuracy: 0.927744708994709 \n",
      "Epoch 17 | Step 6638 | loss: 0.20228384092058005 | accuracy: 0.9276315789473685 \n",
      "Epoch 17 | Step 6639 | loss: 0.2025203937518347 | accuracy: 0.927601439790576 \n",
      "Epoch 17 | Step 6640 | loss: 0.20267173851607367 | accuracy: 0.9276529947916666 \n",
      "Epoch 17 | Step 6641 | loss: 0.20304153915591192 | accuracy: 0.9275420984455959 \n",
      "Epoch 17 | Step 6642 | loss: 0.20258664072865679 | accuracy: 0.9277545103092784 \n",
      "Epoch 17 | Step 6643 | loss: 0.20281142533207552 | accuracy: 0.9276442307692307 \n",
      "Epoch 17 | Step 6644 | loss: 0.20299788642370578 | accuracy: 0.9276147959183674 \n",
      "Epoch 17 | Step 6645 | loss: 0.2030983180148045 | accuracy: 0.9275856598984772 \n",
      "Epoch 17 | Step 6646 | loss: 0.2033283645945667 | accuracy: 0.92739898989899 \n",
      "Epoch 17 | Step 6647 | loss: 0.2037414053464355 | accuracy: 0.9272141959798995 \n",
      "Epoch 17 | Step 6648 | loss: 0.20369068341329694 | accuracy: 0.9271875 \n",
      "Epoch 17 | Step 6649 | loss: 0.2041805597272382 | accuracy: 0.9268501243781094 \n",
      "Epoch 17 | Step 6650 | loss: 0.20437260121475942 | accuracy: 0.9267481435643564 \n",
      "Epoch 17 | Step 6651 | loss: 0.2040366329472934 | accuracy: 0.9269550492610837 \n",
      "Epoch 17 | Step 6652 | loss: 0.2039026426808799 | accuracy: 0.9270067401960784 \n",
      "Epoch 17 | Step 6653 | loss: 0.20403639559702175 | accuracy: 0.926829268292683 \n",
      "Epoch 17 | Step 6654 | loss: 0.20409875444489198 | accuracy: 0.9267293689320388 \n",
      "Epoch 17 | Step 6655 | loss: 0.20381968790566288 | accuracy: 0.9267814009661836 \n",
      "Epoch 17 | Step 6656 | loss: 0.2034808662540924 | accuracy: 0.9269080528846154 \n",
      "Epoch 17 | Step 6657 | loss: 0.20351722111043177 | accuracy: 0.9268092105263158 \n",
      "Epoch 17 | Step 6658 | loss: 0.20304033626757917 | accuracy: 0.9270833333333334 \n",
      "Epoch 17 | Step 6659 | loss: 0.20271200674334408 | accuracy: 0.9272067535545023 \n",
      "Epoch 17 | Step 6660 | loss: 0.20306446218757696 | accuracy: 0.9271816037735849 \n",
      "Epoch 17 | Step 6661 | loss: 0.20253810568104888 | accuracy: 0.927450117370892 \n",
      "Epoch 17 | Step 6662 | loss: 0.2023820595241317 | accuracy: 0.927570093457944 \n",
      "Epoch 17 | Step 6663 | loss: 0.202738262834244 | accuracy: 0.9273982558139535 \n",
      "Epoch 17 | Step 6664 | loss: 0.20320730623616665 | accuracy: 0.9272280092592593 \n",
      "Epoch 17 | Step 6665 | loss: 0.20353012269337056 | accuracy: 0.9272033410138248 \n",
      "Epoch 17 | Step 6666 | loss: 0.20324566305845704 | accuracy: 0.927322247706422 \n",
      "Epoch 17 | Step 6667 | loss: 0.2030719357572462 | accuracy: 0.9272973744292238 \n",
      "Epoch 17 | Step 6668 | loss: 0.20307166334241628 | accuracy: 0.9272017045454546 \n",
      "Epoch 17 | Step 6669 | loss: 0.20277522620639649 | accuracy: 0.9272483031674208 \n",
      "Epoch 17 | Step 6670 | loss: 0.20249642030679965 | accuracy: 0.9274352477477478 \n",
      "Epoch 17 | Step 6671 | loss: 0.20246870035614667 | accuracy: 0.9275504484304933 \n",
      "Epoch 17 | Step 6672 | loss: 0.20234133145173214 | accuracy: 0.9275948660714286 \n",
      "Epoch 17 | Step 6673 | loss: 0.20251511052250862 | accuracy: 0.9275 \n",
      "Epoch 17 | Step 6674 | loss: 0.20253101184107034 | accuracy: 0.9275442477876106 \n",
      "Epoch 17 | Step 6675 | loss: 0.20249266392399562 | accuracy: 0.9275881057268722 \n",
      "Epoch 17 | Step 6676 | loss: 0.20258670628659034 | accuracy: 0.9274945175438597 \n",
      "Epoch 17 | Step 6677 | loss: 0.20235052075253304 | accuracy: 0.9276064410480349 \n",
      "Epoch 17 | Step 6678 | loss: 0.20229486345272998 | accuracy: 0.9277173913043478 \n",
      "Epoch 17 | Step 6679 | loss: 0.20232051670615808 | accuracy: 0.9276244588744589 \n",
      "Epoch 17 | Step 6680 | loss: 0.20219898347518053 | accuracy: 0.9275323275862069 \n",
      "Epoch 17 | Step 6681 | loss: 0.20210669923557745 | accuracy: 0.9275751072961373 \n",
      "Epoch 17 | Step 6682 | loss: 0.20228958156946888 | accuracy: 0.9275507478632479 \n",
      "Epoch 17 | Step 6683 | loss: 0.20214564021914563 | accuracy: 0.9277260638297873 \n",
      "Epoch 17 | Step 6684 | loss: 0.20231641432807101 | accuracy: 0.9277674788135594 \n",
      "Epoch 17 | Step 6685 | loss: 0.20249645338091166 | accuracy: 0.927676687763713 \n",
      "Epoch 17 | Step 6686 | loss: 0.20295246641989015 | accuracy: 0.9274553571428571 \n",
      "Epoch 17 | Step 6687 | loss: 0.20255213475564035 | accuracy: 0.9274973849372385 \n",
      "Epoch 17 | Step 6688 | loss: 0.20220857043750584 | accuracy: 0.9276041666666667 \n",
      "Epoch 17 | Step 6689 | loss: 0.20234298302610385 | accuracy: 0.9274507261410788 \n",
      "Epoch 17 | Step 6690 | loss: 0.20241549560292202 | accuracy: 0.9274276859504132 \n",
      "Epoch 17 | Step 6691 | loss: 0.20227475383092838 | accuracy: 0.9274691358024691 \n",
      "Epoch 17 | Step 6692 | loss: 0.20169592838062614 | accuracy: 0.9277023565573771 \n",
      "Epoch 17 | Step 6693 | loss: 0.20120603655065808 | accuracy: 0.9279336734693877 \n",
      "Epoch 17 | Step 6694 | loss: 0.20107419794894815 | accuracy: 0.9279725609756098 \n",
      "Epoch 17 | Step 6695 | loss: 0.2006817126744672 | accuracy: 0.9280743927125507 \n",
      "Epoch 17 | Step 6696 | loss: 0.2008985564292919 | accuracy: 0.9279233870967742 \n",
      "Epoch 17 | Step 6697 | loss: 0.20085626819646024 | accuracy: 0.9280245983935743 \n",
      "Epoch 17 | Step 6698 | loss: 0.20071006205677985 | accuracy: 0.9280625 \n",
      "Epoch 17 | Step 6699 | loss: 0.20077550901003569 | accuracy: 0.9280378486055777 \n",
      "Epoch 17 | Step 6700 | loss: 0.20076277979191334 | accuracy: 0.9279513888888888 \n",
      "Epoch 17 | Step 6701 | loss: 0.2005167622045566 | accuracy: 0.9279891304347826 \n",
      "Epoch 17 | Step 6702 | loss: 0.20039477260915314 | accuracy: 0.9279650590551181 \n",
      "Epoch 17 | Step 6703 | loss: 0.20009110304070454 | accuracy: 0.928125 \n",
      "Epoch 17 | Step 6704 | loss: 0.20008949845214374 | accuracy: 0.9281005859375 \n",
      "Epoch 17 | Step 6705 | loss: 0.20000414025574806 | accuracy: 0.928137159533074 \n",
      "Epoch 17 | Step 6706 | loss: 0.20016160650655282 | accuracy: 0.9279917635658915 \n",
      "Epoch 17 | Step 6707 | loss: 0.19986703474088985 | accuracy: 0.928028474903475 \n",
      "Epoch 17 | Step 6708 | loss: 0.19966412725356908 | accuracy: 0.9281850961538461 \n",
      "Epoch 17 | Step 6709 | loss: 0.19952624613754594 | accuracy: 0.9282806513409961 \n",
      "Epoch 17 | Step 6710 | loss: 0.1999347637627871 | accuracy: 0.9280176526717557 \n",
      "Epoch 17 | Step 6711 | loss: 0.1999294318740359 | accuracy: 0.9280537072243346 \n",
      "Epoch 17 | Step 6712 | loss: 0.19992660002952273 | accuracy: 0.9280894886363636 \n",
      "Epoch 17 | Step 6713 | loss: 0.19980316758155822 | accuracy: 0.928125 \n",
      "Epoch 17 | Step 6714 | loss: 0.19974675937030548 | accuracy: 0.9282189849624061 \n",
      "Epoch 17 | Step 6715 | loss: 0.19936202552992752 | accuracy: 0.9283707865168539 \n",
      "Epoch 17 | Step 6716 | loss: 0.19968005617274276 | accuracy: 0.9281133395522388 \n",
      "Epoch 17 | Step 6717 | loss: 0.19973000415971287 | accuracy: 0.928032063197026 \n",
      "Epoch 17 | Step 6718 | loss: 0.1998465944495466 | accuracy: 0.9278935185185185 \n",
      "Epoch 17 | Step 6719 | loss: 0.19981816672201086 | accuracy: 0.9278713099630996 \n",
      "Epoch 17 | Step 6720 | loss: 0.19980277397724636 | accuracy: 0.9279641544117647 \n",
      "Epoch 17 | Step 6721 | loss: 0.1998555186740208 | accuracy: 0.9279990842490843 \n",
      "Epoch 17 | Step 6722 | loss: 0.20017968479843035 | accuracy: 0.9280337591240876 \n",
      "Epoch 17 | Step 6723 | loss: 0.19996727230873976 | accuracy: 0.9280681818181818 \n",
      "Epoch 17 | Step 6724 | loss: 0.20018892727144386 | accuracy: 0.9280457427536232 \n",
      "Epoch 17 | Step 6725 | loss: 0.1999646645536922 | accuracy: 0.9280798736462094 \n",
      "Epoch 17 | Step 6726 | loss: 0.1998036843892053 | accuracy: 0.9282261690647482 \n",
      "Epoch 17 | Step 6727 | loss: 0.19968204464643233 | accuracy: 0.9282594086021505 \n",
      "Epoch 17 | Step 6728 | loss: 0.19975191208400897 | accuracy: 0.928125 \n",
      "Epoch 17 | Step 6729 | loss: 0.1996629004535726 | accuracy: 0.9282695729537367 \n",
      "Epoch 17 | Step 6730 | loss: 0.1993056890812326 | accuracy: 0.9284131205673759 \n",
      "Epoch 17 | Step 6731 | loss: 0.19920040946124723 | accuracy: 0.9283348056537103 \n",
      "Epoch 17 | Step 6732 | loss: 0.19887981513961103 | accuracy: 0.9285321302816901 \n",
      "Epoch 17 | Step 6733 | loss: 0.1987918588937375 | accuracy: 0.9285635964912281 \n",
      "Epoch 17 | Step 6734 | loss: 0.19833250057238802 | accuracy: 0.9287587412587412 \n",
      "Epoch 17 | Step 6735 | loss: 0.19834642589922985 | accuracy: 0.9288436411149826 \n",
      "Epoch 17 | Step 6736 | loss: 0.1978979365796679 | accuracy: 0.9290364583333334 \n",
      "Epoch 17 | Step 6737 | loss: 0.19881632186756004 | accuracy: 0.9289035467128027 \n",
      "Epoch 17 | Step 6738 | loss: 0.19876922744101494 | accuracy: 0.9289331896551725 \n",
      "Epoch 17 | Step 6739 | loss: 0.19897082432643656 | accuracy: 0.9288552405498282 \n",
      "Epoch 17 | Step 6740 | loss: 0.19885974030380382 | accuracy: 0.9289383561643836 \n",
      "Epoch 17 | Step 6741 | loss: 0.19883107162579744 | accuracy: 0.9289675767918089 \n",
      "Epoch 17 | Step 6742 | loss: 0.19889210438241767 | accuracy: 0.9288903061224489 \n",
      "Epoch 17 | Step 6743 | loss: 0.19869721855147413 | accuracy: 0.9288665254237288 \n",
      "Epoch 17 | Step 6744 | loss: 0.19879109649037996 | accuracy: 0.9287901182432432 \n",
      "Epoch 17 | Step 6745 | loss: 0.1987349414564544 | accuracy: 0.9289246632996633 \n",
      "Epoch 17 | Step 6746 | loss: 0.19876620688494423 | accuracy: 0.9289010067114094 \n",
      "Epoch 17 | Step 6747 | loss: 0.19860143720306284 | accuracy: 0.9289297658862876 \n",
      "Epoch 17 | Step 6748 | loss: 0.19826056924959026 | accuracy: 0.9290625 \n",
      "Epoch 17 | Step 6749 | loss: 0.19848299321047097 | accuracy: 0.9289348006644518 \n",
      "Epoch 17 | Step 6750 | loss: 0.1982659585773945 | accuracy: 0.9290666390728477 \n",
      "Epoch 17 | Step 6751 | loss: 0.19814311132671025 | accuracy: 0.9291460396039604 \n",
      "Epoch 17 | Step 6752 | loss: 0.19812002324646244 | accuracy: 0.9291221217105263 \n",
      "Epoch 17 | Step 6753 | loss: 0.19810398648508262 | accuracy: 0.9290983606557377 \n",
      "Epoch 17 | Step 6754 | loss: 0.19827248367900943 | accuracy: 0.9290236928104575 \n",
      "Epoch 17 | Step 6755 | loss: 0.19910442574307666 | accuracy: 0.9287968241042345 \n",
      "Epoch 17 | Step 6756 | loss: 0.19902491204247075 | accuracy: 0.9288758116883117 \n",
      "Epoch 17 | Step 6757 | loss: 0.1988297135939876 | accuracy: 0.9288531553398058 \n",
      "Epoch 17 | Step 6758 | loss: 0.1989513338813859 | accuracy: 0.9287802419354839 \n",
      "Epoch 17 | Step 6759 | loss: 0.19912934171521016 | accuracy: 0.9287077974276527 \n",
      "Epoch 17 | Step 6760 | loss: 0.19910602044696232 | accuracy: 0.9286858974358975 \n",
      "Epoch 17 | Step 6761 | loss: 0.1989381508752942 | accuracy: 0.9287639776357828 \n",
      "Epoch 17 | Step 6762 | loss: 0.19914991624510975 | accuracy: 0.9287420382165605 \n",
      "Epoch 17 | Step 6763 | loss: 0.19979381639333 | accuracy: 0.9286210317460317 \n",
      "Epoch 17 | Step 6764 | loss: 0.1996515111974146 | accuracy: 0.9286985759493671 \n",
      "Epoch 17 | Step 6765 | loss: 0.19952295887451443 | accuracy: 0.9287756309148265 \n",
      "Epoch 17 | Step 6766 | loss: 0.19975198189136367 | accuracy: 0.9286556603773585 \n",
      "Epoch 17 | Step 6767 | loss: 0.1998730473991098 | accuracy: 0.9286833855799373 \n",
      "Epoch 17 | Step 6768 | loss: 0.19979098073672502 | accuracy: 0.928662109375 \n",
      "Epoch 17 | Step 6769 | loss: 0.1997903307139688 | accuracy: 0.928494937694704 \n",
      "Epoch 17 | Step 6770 | loss: 0.2001534534028228 | accuracy: 0.9284258540372671 \n",
      "Epoch 17 | Step 6771 | loss: 0.20001507942613803 | accuracy: 0.9284055727554179 \n",
      "Epoch 17 | Step 6772 | loss: 0.1997450311196807 | accuracy: 0.9285783179012346 \n",
      "Epoch 17 | Step 6773 | loss: 0.20001186240177887 | accuracy: 0.9284615384615384 \n",
      "Epoch 17 | Step 6774 | loss: 0.199804727993677 | accuracy: 0.9286330521472392 \n",
      "Epoch 17 | Step 6775 | loss: 0.19997458809286084 | accuracy: 0.9285168195718655 \n",
      "Epoch 17 | Step 6776 | loss: 0.19995716184650253 | accuracy: 0.9285442073170732 \n",
      "Epoch 17 | Step 6777 | loss: 0.20048530393005504 | accuracy: 0.928238981762918 \n",
      "Epoch 17 | Step 6778 | loss: 0.20042156385201396 | accuracy: 0.9282670454545454 \n",
      "Epoch 17 | Step 6779 | loss: 0.2003334658248547 | accuracy: 0.9282477341389728 \n",
      "Epoch 17 | Step 6780 | loss: 0.20036666788699398 | accuracy: 0.9282285391566265 \n",
      "Epoch 17 | Step 6781 | loss: 0.20016487535682168 | accuracy: 0.9282563813813813 \n",
      "Epoch 17 | Step 6782 | loss: 0.200384946439616 | accuracy: 0.9280969311377245 \n",
      "Epoch 17 | Step 6783 | loss: 0.200067068414012 | accuracy: 0.9281716417910447 \n",
      "Epoch 17 | Step 6784 | loss: 0.19983806039783217 | accuracy: 0.9282924107142857 \n",
      "Epoch 17 | Step 6785 | loss: 0.19987870023229357 | accuracy: 0.9282733679525222 \n",
      "Epoch 17 | Step 6786 | loss: 0.19997667657905782 | accuracy: 0.9283006656804734 \n",
      "Epoch 17 | Step 6787 | loss: 0.19991924651077012 | accuracy: 0.928327802359882 \n",
      "Epoch 17 | Step 6788 | loss: 0.19962426215848503 | accuracy: 0.9284466911764706 \n",
      "Epoch 17 | Step 6789 | loss: 0.1994754954997745 | accuracy: 0.9285648826979472 \n",
      "Epoch 17 | Step 6790 | loss: 0.19927922834516965 | accuracy: 0.9286366959064327 \n",
      "Epoch 17 | Step 6791 | loss: 0.19905204143451186 | accuracy: 0.9287080903790087 \n",
      "Epoch 17 | Step 6792 | loss: 0.1988182028019151 | accuracy: 0.9287790697674418 \n",
      "Epoch 17 | Step 6793 | loss: 0.1988765513551408 | accuracy: 0.9287137681159421 \n",
      "Epoch 17 | Step 6794 | loss: 0.1988116155211636 | accuracy: 0.9288294797687862 \n",
      "Epoch 17 | Step 6795 | loss: 0.19860238287737458 | accuracy: 0.9288994956772334 \n",
      "Epoch 17 | Step 6796 | loss: 0.19922252012224034 | accuracy: 0.9286997126436781 \n",
      "Epoch 17 | Step 6797 | loss: 0.1992247524780667 | accuracy: 0.9286353868194842 \n",
      "Epoch 17 | Step 6798 | loss: 0.19906823162521634 | accuracy: 0.92875 \n",
      "Epoch 17 | Step 6799 | loss: 0.19889479090175738 | accuracy: 0.9288639601139601 \n",
      "Epoch 17 | Step 6800 | loss: 0.19926080078055913 | accuracy: 0.9287109375 \n",
      "Epoch 17 | Step 6801 | loss: 0.1990380232715742 | accuracy: 0.9287800991501416 \n",
      "Epoch 17 | Step 6802 | loss: 0.19875579653570882 | accuracy: 0.9288930084745762 \n",
      "Epoch 17 | Step 6803 | loss: 0.1985551733576076 | accuracy: 0.9289612676056338 \n",
      "Epoch 17 | Step 6804 | loss: 0.19840171889224079 | accuracy: 0.9289852528089888 \n",
      "Epoch 17 | Step 6805 | loss: 0.1985240306298272 | accuracy: 0.9290528711484594 \n",
      "Epoch 17 | Step 6806 | loss: 0.19849775929274505 | accuracy: 0.929076466480447 \n",
      "Epoch 17 | Step 6807 | loss: 0.19824885151512445 | accuracy: 0.9291869777158774 \n",
      "Epoch 17 | Step 6808 | loss: 0.19797130595478746 | accuracy: 0.929296875 \n",
      "Epoch 17 | Step 6809 | loss: 0.1980536358425822 | accuracy: 0.9291897506925207 \n",
      "Epoch 17 | Step 6810 | loss: 0.19795717850574474 | accuracy: 0.9292558701657458 \n",
      "Epoch 17 | Step 6811 | loss: 0.19783848503568613 | accuracy: 0.9293216253443526 \n",
      "Epoch 17 | Step 6812 | loss: 0.19764287082048562 | accuracy: 0.9293440934065934 \n",
      "Epoch 17 | Step 6813 | loss: 0.1973764981104903 | accuracy: 0.9294520547945205 \n",
      "Epoch 17 | Step 6814 | loss: 0.19731769562174714 | accuracy: 0.929474043715847 \n",
      "Epoch 17 | Step 6815 | loss: 0.19707688892244968 | accuracy: 0.9295810626702997 \n",
      "Epoch 17 | Step 6816 | loss: 0.19691533064874617 | accuracy: 0.9296025815217391 \n",
      "Epoch 17 | Step 6817 | loss: 0.19708668285107547 | accuracy: 0.9296239837398373 \n",
      "Epoch 17 | Step 6818 | loss: 0.19733422740891174 | accuracy: 0.9294763513513513 \n",
      "Epoch 17 | Step 6819 | loss: 0.19737535028284128 | accuracy: 0.9294979784366577 \n",
      "Epoch 17 | Step 6820 | loss: 0.19792426742052519 | accuracy: 0.9293094758064516 \n",
      "Epoch 17 | Step 6821 | loss: 0.19785631925426922 | accuracy: 0.9293314343163539 \n",
      "Epoch 17 | Step 6822 | loss: 0.19777699798983048 | accuracy: 0.929269719251337 \n",
      "Epoch 17 | Step 6823 | loss: 0.19761499337355296 | accuracy: 0.9294166666666667 \n",
      "Epoch 17 | Step 6824 | loss: 0.19738953364418543 | accuracy: 0.9295212765957447 \n",
      "Epoch 17 | Step 6825 | loss: 0.19727433741646042 | accuracy: 0.9295009946949602 \n",
      "Epoch 17 | Step 6826 | loss: 0.19742216676394775 | accuracy: 0.9293981481481481 \n",
      "Epoch 17 | Step 6827 | loss: 0.19722600214399574 | accuracy: 0.9295019788918206 \n",
      "Epoch 17 | Step 6828 | loss: 0.19698480704897328 | accuracy: 0.9295641447368421 \n",
      "Epoch 17 | Step 6829 | loss: 0.19683860879870538 | accuracy: 0.9295849737532809 \n",
      "Epoch 17 | Step 6830 | loss: 0.19664276674077774 | accuracy: 0.9296056937172775 \n",
      "Epoch 17 | Step 6831 | loss: 0.19645629350494778 | accuracy: 0.9296671018276762 \n",
      "Epoch 17 | Step 6832 | loss: 0.1964931547214898 | accuracy: 0.9296468098958334 \n",
      "Epoch 17 | Step 6833 | loss: 0.19685392164951795 | accuracy: 0.9295048701298702 \n",
      "Epoch 17 | Step 6834 | loss: 0.19699775109096512 | accuracy: 0.929485103626943 \n",
      "Epoch 17 | Step 6835 | loss: 0.19713327979779674 | accuracy: 0.9294654392764858 \n",
      "Epoch 17 | Step 6836 | loss: 0.19687221706220784 | accuracy: 0.9295666881443299 \n",
      "Epoch 17 | Step 6837 | loss: 0.19700253756769517 | accuracy: 0.9295469151670951 \n",
      "Epoch 17 | Step 6838 | loss: 0.1969183780826055 | accuracy: 0.9296073717948717 \n",
      "Epoch 17 | Step 6839 | loss: 0.19699072853073746 | accuracy: 0.9295875959079284 \n",
      "Epoch 17 | Step 6840 | loss: 0.19683978375883734 | accuracy: 0.9296476403061225 \n",
      "Epoch 17 | Step 6841 | loss: 0.19667088450821302 | accuracy: 0.92966762086514 \n",
      "Epoch 17 | Step 6842 | loss: 0.19671510810476875 | accuracy: 0.9296081852791879 \n",
      "Epoch 17 | Step 6843 | loss: 0.19658168339276616 | accuracy: 0.9296677215189874 \n",
      "Epoch 17 | Step 6844 | loss: 0.1965014132285359 | accuracy: 0.9296875 \n",
      "Epoch 17 | Step 6845 | loss: 0.1965465994565853 | accuracy: 0.9297071788413098 \n",
      "Epoch 17 | Step 6846 | loss: 0.19661802506476792 | accuracy: 0.9296875 \n",
      "Epoch 17 | Step 6847 | loss: 0.19647892039820067 | accuracy: 0.9297462406015038 \n",
      "Epoch 17 | Step 6848 | loss: 0.19673180364072324 | accuracy: 0.9296875 \n",
      "Epoch 17 | Step 6849 | loss: 0.19667151299052107 | accuracy: 0.9297069825436409 \n",
      "Epoch 17 | Step 6850 | loss: 0.1970178644677893 | accuracy: 0.929570895522388 \n",
      "Epoch 17 | Step 6851 | loss: 0.19667206144436417 | accuracy: 0.9297456575682382 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.6010863780975342 | accuracy: 0.765625 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.6112595200538635 | accuracy: 0.78125 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.5423051516215006 | accuracy: 0.7916666666666666 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.5160291492938995 | accuracy: 0.8046875 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.526672649383545 | accuracy: 0.803125 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.5173825770616531 | accuracy: 0.8020833333333334 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.5044904351234436 | accuracy: 0.8058035714285714 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4931354448199272 | accuracy: 0.810546875 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4887547360526191 | accuracy: 0.8142361111111112 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.48636349439620974 | accuracy: 0.815625 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4919625629078258 | accuracy: 0.8153409090909091 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4845801889896393 | accuracy: 0.8203125 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4919615204517658 | accuracy: 0.8149038461538461 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.499647068125861 | accuracy: 0.8147321428571429 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4870138943195343 | accuracy: 0.81875 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.48743741400539875 | accuracy: 0.8193359375 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.5010694878942826 | accuracy: 0.8161764705882353 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4951580481396781 | accuracy: 0.8177083333333334 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.49045518668074356 | accuracy: 0.8182565789473685 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4847381427884102 | accuracy: 0.82109375 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4833140004248846 | accuracy: 0.8221726190476191 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.47728802128271625 | accuracy: 0.8224431818181818 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.47848536398099817 | accuracy: 0.8213315217391305 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4769810152550538 | accuracy: 0.822265625 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.48232181191444395 | accuracy: 0.82 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4739202776780495 | accuracy: 0.8227163461538461 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.47404294102280226 | accuracy: 0.8229166666666666 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4680092047367777 | accuracy: 0.8253348214285714 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.47100878070140706 | accuracy: 0.8248922413793104 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.47369243403275807 | accuracy: 0.8239583333333333 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4672968416444717 | accuracy: 0.827116935483871 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4613017961382866 | accuracy: 0.82958984375 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4590213063991431 | accuracy: 0.8309659090909091 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.469563587623484 | accuracy: 0.8285845588235294 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.46824927500316077 | accuracy: 0.8276785714285714 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.46183547584546936 | accuracy: 0.829861111111111 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4633051789290196 | accuracy: 0.8289695945945945 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4628879588685538 | accuracy: 0.8281249999999999 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4607100337743759 | accuracy: 0.8297275641025641 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.46496159620583055 | accuracy: 0.82734375 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.46832301013353395 | accuracy: 0.8258384146341463 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.46612131347258884 | accuracy: 0.8270089285714286 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4650271482938944 | accuracy: 0.8270348837209303 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4686269966716116 | accuracy: 0.8259943181818182 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4724992569949892 | accuracy: 0.8250301930639479 \n",
      "Epoch 18 | Step 6852 | loss: 0.1262143850326538 | accuracy: 0.953125 \n",
      "Epoch 18 | Step 6853 | loss: 0.2240571230649948 | accuracy: 0.9296875 \n",
      "Epoch 18 | Step 6854 | loss: 0.19468440115451813 | accuracy: 0.9322916666666666 \n",
      "Epoch 18 | Step 6855 | loss: 0.19931576028466225 | accuracy: 0.9296875 \n",
      "Epoch 18 | Step 6856 | loss: 0.1882338583469391 | accuracy: 0.928125 \n",
      "Epoch 18 | Step 6857 | loss: 0.20424482226371765 | accuracy: 0.9140625 \n",
      "Epoch 18 | Step 6858 | loss: 0.21155173437935965 | accuracy: 0.9151785714285714 \n",
      "Epoch 18 | Step 6859 | loss: 0.2234751582145691 | accuracy: 0.9140625 \n",
      "Epoch 18 | Step 6860 | loss: 0.21779271132416195 | accuracy: 0.9166666666666666 \n",
      "Epoch 18 | Step 6861 | loss: 0.225615431368351 | accuracy: 0.9109375 \n",
      "Epoch 18 | Step 6862 | loss: 0.22722542827779596 | accuracy: 0.9119318181818182 \n",
      "Epoch 18 | Step 6863 | loss: 0.2288303611179193 | accuracy: 0.9114583333333334 \n",
      "Epoch 18 | Step 6864 | loss: 0.223029850767209 | accuracy: 0.9158653846153846 \n",
      "Epoch 18 | Step 6865 | loss: 0.22588694202048437 | accuracy: 0.9151785714285714 \n",
      "Epoch 18 | Step 6866 | loss: 0.22044418454170228 | accuracy: 0.9197916666666667 \n",
      "Epoch 18 | Step 6867 | loss: 0.21213110582903028 | accuracy: 0.923828125 \n",
      "Epoch 18 | Step 6868 | loss: 0.2059284987695077 | accuracy: 0.9264705882352942 \n",
      "Epoch 18 | Step 6869 | loss: 0.2034937230249246 | accuracy: 0.9279513888888888 \n",
      "Epoch 18 | Step 6870 | loss: 0.2021676980351147 | accuracy: 0.9292763157894737 \n",
      "Epoch 18 | Step 6871 | loss: 0.20592472441494464 | accuracy: 0.92890625 \n",
      "Epoch 18 | Step 6872 | loss: 0.20470978709913434 | accuracy: 0.9293154761904762 \n",
      "Epoch 18 | Step 6873 | loss: 0.20527323978868398 | accuracy: 0.9296875 \n",
      "Epoch 18 | Step 6874 | loss: 0.20428187983191531 | accuracy: 0.9286684782608695 \n",
      "Epoch 18 | Step 6875 | loss: 0.19896142091602087 | accuracy: 0.931640625 \n",
      "Epoch 18 | Step 6876 | loss: 0.19590698033571244 | accuracy: 0.9325 \n",
      "Epoch 18 | Step 6877 | loss: 0.1951873660660707 | accuracy: 0.9308894230769231 \n",
      "Epoch 18 | Step 6878 | loss: 0.19475175854232576 | accuracy: 0.9317129629629629 \n",
      "Epoch 18 | Step 6879 | loss: 0.19032246034060205 | accuracy: 0.93359375 \n",
      "Epoch 18 | Step 6880 | loss: 0.18838486280934563 | accuracy: 0.9337284482758621 \n",
      "Epoch 18 | Step 6881 | loss: 0.18953843911488852 | accuracy: 0.9328125 \n",
      "Epoch 18 | Step 6882 | loss: 0.18991403185552166 | accuracy: 0.9329637096774194 \n",
      "Epoch 18 | Step 6883 | loss: 0.19059127429500222 | accuracy: 0.9326171875 \n",
      "Epoch 18 | Step 6884 | loss: 0.1931281898057822 | accuracy: 0.931344696969697 \n",
      "Epoch 18 | Step 6885 | loss: 0.19461961616488063 | accuracy: 0.9306066176470589 \n",
      "Epoch 18 | Step 6886 | loss: 0.19362436703273228 | accuracy: 0.93125 \n",
      "Epoch 18 | Step 6887 | loss: 0.1960243077741729 | accuracy: 0.9292534722222222 \n",
      "Epoch 18 | Step 6888 | loss: 0.1930636451453776 | accuracy: 0.9307432432432432 \n",
      "Epoch 18 | Step 6889 | loss: 0.19236015469620102 | accuracy: 0.9317434210526315 \n",
      "Epoch 18 | Step 6890 | loss: 0.19071363695921043 | accuracy: 0.9322916666666666 \n",
      "Epoch 18 | Step 6891 | loss: 0.1905873181298375 | accuracy: 0.93203125 \n",
      "Epoch 18 | Step 6892 | loss: 0.189784524099129 | accuracy: 0.9314024390243902 \n",
      "Epoch 18 | Step 6893 | loss: 0.1896824196335815 | accuracy: 0.9319196428571429 \n",
      "Epoch 18 | Step 6894 | loss: 0.18804144945948623 | accuracy: 0.9324127906976745 \n",
      "Epoch 18 | Step 6895 | loss: 0.18646562692116608 | accuracy: 0.9332386363636364 \n",
      "Epoch 18 | Step 6896 | loss: 0.18738032595978843 | accuracy: 0.9322916666666666 \n",
      "Epoch 18 | Step 6897 | loss: 0.18773145633547203 | accuracy: 0.9327445652173914 \n",
      "Epoch 18 | Step 6898 | loss: 0.1867797347776433 | accuracy: 0.932845744680851 \n",
      "Epoch 18 | Step 6899 | loss: 0.18772030885641774 | accuracy: 0.9322916666666666 \n",
      "Epoch 18 | Step 6900 | loss: 0.18575196698003885 | accuracy: 0.9330357142857143 \n",
      "Epoch 18 | Step 6901 | loss: 0.18704323142766952 | accuracy: 0.9325 \n",
      "Epoch 18 | Step 6902 | loss: 0.1901923567056656 | accuracy: 0.9313725490196079 \n",
      "Epoch 18 | Step 6903 | loss: 0.1923086726321624 | accuracy: 0.9305889423076923 \n",
      "Epoch 18 | Step 6904 | loss: 0.19148101952840696 | accuracy: 0.9310141509433962 \n",
      "Epoch 18 | Step 6905 | loss: 0.19120124810271794 | accuracy: 0.9314236111111112 \n",
      "Epoch 18 | Step 6906 | loss: 0.19191658334298567 | accuracy: 0.930965909090909 \n",
      "Epoch 18 | Step 6907 | loss: 0.19400342819946154 | accuracy: 0.9302455357142857 \n",
      "Epoch 18 | Step 6908 | loss: 0.19336468948606858 | accuracy: 0.9306469298245614 \n",
      "Epoch 18 | Step 6909 | loss: 0.1940864018838981 | accuracy: 0.9310344827586207 \n",
      "Epoch 18 | Step 6910 | loss: 0.194699199775518 | accuracy: 0.9311440677966102 \n",
      "Epoch 18 | Step 6911 | loss: 0.19595413381854693 | accuracy: 0.9302083333333333 \n",
      "Epoch 18 | Step 6912 | loss: 0.1954640831615104 | accuracy: 0.930327868852459 \n",
      "Epoch 18 | Step 6913 | loss: 0.1952402214369466 | accuracy: 0.930695564516129 \n",
      "Epoch 18 | Step 6914 | loss: 0.1950785449099919 | accuracy: 0.9305555555555556 \n",
      "Epoch 18 | Step 6915 | loss: 0.19385714817326516 | accuracy: 0.93115234375 \n",
      "Epoch 18 | Step 6916 | loss: 0.1944827594436132 | accuracy: 0.9310096153846154 \n",
      "Epoch 18 | Step 6917 | loss: 0.19318661533973433 | accuracy: 0.9311079545454546 \n",
      "Epoch 18 | Step 6918 | loss: 0.191913258228729 | accuracy: 0.9316697761194029 \n",
      "Epoch 18 | Step 6919 | loss: 0.19142858070485733 | accuracy: 0.9319852941176471 \n",
      "Epoch 18 | Step 6920 | loss: 0.19237412361131198 | accuracy: 0.931838768115942 \n",
      "Epoch 18 | Step 6921 | loss: 0.19355266307081495 | accuracy: 0.9316964285714285 \n",
      "Epoch 18 | Step 6922 | loss: 0.1949225021919734 | accuracy: 0.9313380281690141 \n",
      "Epoch 18 | Step 6923 | loss: 0.1937426377294792 | accuracy: 0.9318576388888888 \n",
      "Epoch 18 | Step 6924 | loss: 0.1943745169125191 | accuracy: 0.9315068493150684 \n",
      "Epoch 18 | Step 6925 | loss: 0.19462388965326385 | accuracy: 0.9311655405405406 \n",
      "Epoch 18 | Step 6926 | loss: 0.19511298328638077 | accuracy: 0.9310416666666667 \n",
      "Epoch 18 | Step 6927 | loss: 0.19390519826035751 | accuracy: 0.9315378289473685 \n",
      "Epoch 18 | Step 6928 | loss: 0.1955086604341284 | accuracy: 0.9310064935064936 \n",
      "Epoch 18 | Step 6929 | loss: 0.19503161693230653 | accuracy: 0.9310897435897436 \n",
      "Epoch 18 | Step 6930 | loss: 0.19420586790465103 | accuracy: 0.9311708860759493 \n",
      "Epoch 18 | Step 6931 | loss: 0.1946075288578868 | accuracy: 0.9310546875 \n",
      "Epoch 18 | Step 6932 | loss: 0.19545446520234333 | accuracy: 0.9309413580246914 \n",
      "Epoch 18 | Step 6933 | loss: 0.19470306304169865 | accuracy: 0.9314024390243902 \n",
      "Epoch 18 | Step 6934 | loss: 0.19512685828180198 | accuracy: 0.9312876506024096 \n",
      "Epoch 18 | Step 6935 | loss: 0.19523918415818894 | accuracy: 0.9313616071428571 \n",
      "Epoch 18 | Step 6936 | loss: 0.19578560503090128 | accuracy: 0.9310661764705882 \n",
      "Epoch 18 | Step 6937 | loss: 0.1945307508630808 | accuracy: 0.9316860465116279 \n",
      "Epoch 18 | Step 6938 | loss: 0.19463073256714591 | accuracy: 0.931573275862069 \n",
      "Epoch 18 | Step 6939 | loss: 0.19490969138727945 | accuracy: 0.9314630681818182 \n",
      "Epoch 18 | Step 6940 | loss: 0.19457657543126117 | accuracy: 0.9311797752808989 \n",
      "Epoch 18 | Step 6941 | loss: 0.1953612426088916 | accuracy: 0.9302083333333333 \n",
      "Epoch 18 | Step 6942 | loss: 0.19556784687133935 | accuracy: 0.9301167582417582 \n",
      "Epoch 18 | Step 6943 | loss: 0.19766476126792637 | accuracy: 0.9293478260869565 \n",
      "Epoch 18 | Step 6944 | loss: 0.20029342935610844 | accuracy: 0.9282594086021505 \n",
      "Epoch 18 | Step 6945 | loss: 0.19945778119120192 | accuracy: 0.9286901595744681 \n",
      "Epoch 18 | Step 6946 | loss: 0.19860314248423827 | accuracy: 0.9289473684210526 \n",
      "Epoch 18 | Step 6947 | loss: 0.19809013907797635 | accuracy: 0.9288736979166666 \n",
      "Epoch 18 | Step 6948 | loss: 0.19770601046146805 | accuracy: 0.9288015463917526 \n",
      "Epoch 18 | Step 6949 | loss: 0.19907493091055325 | accuracy: 0.9282525510204082 \n",
      "Epoch 18 | Step 6950 | loss: 0.19837693516353164 | accuracy: 0.9288194444444444 \n",
      "Epoch 18 | Step 6951 | loss: 0.1988064084202051 | accuracy: 0.92875 \n",
      "Epoch 18 | Step 6952 | loss: 0.19896956739744337 | accuracy: 0.9288366336633663 \n",
      "Epoch 18 | Step 6953 | loss: 0.1992062687435571 | accuracy: 0.9287683823529411 \n",
      "Epoch 18 | Step 6954 | loss: 0.19879590965879773 | accuracy: 0.9288531553398058 \n",
      "Epoch 18 | Step 6955 | loss: 0.19919366668909788 | accuracy: 0.9289362980769231 \n",
      "Epoch 18 | Step 6956 | loss: 0.19987871923616954 | accuracy: 0.9287202380952381 \n",
      "Epoch 18 | Step 6957 | loss: 0.19933310045667416 | accuracy: 0.9288030660377359 \n",
      "Epoch 18 | Step 6958 | loss: 0.1999069336001004 | accuracy: 0.928446261682243 \n",
      "Epoch 18 | Step 6959 | loss: 0.20049448428606545 | accuracy: 0.9280960648148148 \n",
      "Epoch 18 | Step 6960 | loss: 0.19948201257427897 | accuracy: 0.9286123853211009 \n",
      "Epoch 18 | Step 6961 | loss: 0.1991332665763118 | accuracy: 0.928409090909091 \n",
      "Epoch 18 | Step 6962 | loss: 0.20006491868077098 | accuracy: 0.9279279279279279 \n",
      "Epoch 18 | Step 6963 | loss: 0.20063601826716745 | accuracy: 0.9275948660714286 \n",
      "Epoch 18 | Step 6964 | loss: 0.20028973753209664 | accuracy: 0.927820796460177 \n",
      "Epoch 18 | Step 6965 | loss: 0.20017048801507867 | accuracy: 0.9279057017543859 \n",
      "Epoch 18 | Step 6966 | loss: 0.1992825366232706 | accuracy: 0.9283967391304347 \n",
      "Epoch 18 | Step 6967 | loss: 0.19881366251100754 | accuracy: 0.9286099137931034 \n",
      "Epoch 18 | Step 6968 | loss: 0.19827004662181577 | accuracy: 0.9288194444444444 \n",
      "Epoch 18 | Step 6969 | loss: 0.19817076566613326 | accuracy: 0.9288930084745762 \n",
      "Epoch 18 | Step 6970 | loss: 0.19826057384244533 | accuracy: 0.928702731092437 \n",
      "Epoch 18 | Step 6971 | loss: 0.19843495556463797 | accuracy: 0.928515625 \n",
      "Epoch 18 | Step 6972 | loss: 0.19784854888177114 | accuracy: 0.9289772727272727 \n",
      "Epoch 18 | Step 6973 | loss: 0.19827837222179429 | accuracy: 0.9286629098360656 \n",
      "Epoch 18 | Step 6974 | loss: 0.19799847022546985 | accuracy: 0.9288617886178862 \n",
      "Epoch 18 | Step 6975 | loss: 0.19891752236552776 | accuracy: 0.9284274193548387 \n",
      "Epoch 18 | Step 6976 | loss: 0.19911249834299088 | accuracy: 0.92825 \n",
      "Epoch 18 | Step 6977 | loss: 0.19842835480258578 | accuracy: 0.9284474206349206 \n",
      "Epoch 18 | Step 6978 | loss: 0.19859963197877087 | accuracy: 0.9283956692913385 \n",
      "Epoch 18 | Step 6979 | loss: 0.19821498030796647 | accuracy: 0.9283447265625 \n",
      "Epoch 18 | Step 6980 | loss: 0.19773283150306967 | accuracy: 0.9285368217054264 \n",
      "Epoch 18 | Step 6981 | loss: 0.19803414413562187 | accuracy: 0.9284855769230769 \n",
      "Epoch 18 | Step 6982 | loss: 0.19859912491026727 | accuracy: 0.9283158396946565 \n",
      "Epoch 18 | Step 6983 | loss: 0.1983884179005117 | accuracy: 0.9286221590909091 \n",
      "Epoch 18 | Step 6984 | loss: 0.19786128917134793 | accuracy: 0.9288063909774437 \n",
      "Epoch 18 | Step 6985 | loss: 0.19718858999992483 | accuracy: 0.9291044776119404 \n",
      "Epoch 18 | Step 6986 | loss: 0.19730308574658853 | accuracy: 0.9290509259259261 \n",
      "Epoch 18 | Step 6987 | loss: 0.19793853306156747 | accuracy: 0.9289981617647061 \n",
      "Epoch 18 | Step 6988 | loss: 0.19838665164735195 | accuracy: 0.9289461678832119 \n",
      "Epoch 18 | Step 6989 | loss: 0.19836780439684357 | accuracy: 0.9290081521739133 \n",
      "Epoch 18 | Step 6990 | loss: 0.19904493717409724 | accuracy: 0.9288444244604318 \n",
      "Epoch 18 | Step 6991 | loss: 0.1986421627657754 | accuracy: 0.9289062500000002 \n",
      "Epoch 18 | Step 6992 | loss: 0.19842402858937042 | accuracy: 0.9290780141843974 \n",
      "Epoch 18 | Step 6993 | loss: 0.19817946704340655 | accuracy: 0.9292473591549297 \n",
      "Epoch 18 | Step 6994 | loss: 0.1975711412675731 | accuracy: 0.9295236013986016 \n",
      "Epoch 18 | Step 6995 | loss: 0.19731676231862771 | accuracy: 0.9295789930555558 \n",
      "Epoch 18 | Step 6996 | loss: 0.19719271521116125 | accuracy: 0.929418103448276 \n",
      "Epoch 18 | Step 6997 | loss: 0.1973294975516731 | accuracy: 0.929580479452055 \n",
      "Epoch 18 | Step 6998 | loss: 0.19733774362980913 | accuracy: 0.9295280612244899 \n",
      "Epoch 18 | Step 6999 | loss: 0.19724237027804595 | accuracy: 0.9293707770270272 \n",
      "Epoch 18 | Step 7000 | loss: 0.19727937122119354 | accuracy: 0.9293204697986579 \n",
      "Epoch 18 | Step 7001 | loss: 0.19651733810702962 | accuracy: 0.9296875000000002 \n",
      "Epoch 18 | Step 7002 | loss: 0.19671998133525156 | accuracy: 0.9296357615894042 \n",
      "Epoch 18 | Step 7003 | loss: 0.1967271610996441 | accuracy: 0.9297902960526317 \n",
      "Epoch 18 | Step 7004 | loss: 0.19743394710464418 | accuracy: 0.9295343137254903 \n",
      "Epoch 18 | Step 7005 | loss: 0.19671827506322367 | accuracy: 0.9296875000000002 \n",
      "Epoch 18 | Step 7006 | loss: 0.19617676273469004 | accuracy: 0.9299395161290325 \n",
      "Epoch 18 | Step 7007 | loss: 0.1952375661199674 | accuracy: 0.930388621794872 \n",
      "Epoch 18 | Step 7008 | loss: 0.19515954456321757 | accuracy: 0.9304339171974524 \n",
      "Epoch 18 | Step 7009 | loss: 0.19495695371982422 | accuracy: 0.9305775316455698 \n",
      "Epoch 18 | Step 7010 | loss: 0.19524884566008674 | accuracy: 0.9304245283018869 \n",
      "Epoch 18 | Step 7011 | loss: 0.1950496361125261 | accuracy: 0.9304687500000002 \n",
      "Epoch 18 | Step 7012 | loss: 0.1947160636693795 | accuracy: 0.9307065217391306 \n",
      "Epoch 18 | Step 7013 | loss: 0.19467617980675936 | accuracy: 0.9308449074074076 \n",
      "Epoch 18 | Step 7014 | loss: 0.19390835110212398 | accuracy: 0.9311733128834357 \n",
      "Epoch 18 | Step 7015 | loss: 0.19354106408612032 | accuracy: 0.9313071646341465 \n",
      "Epoch 18 | Step 7016 | loss: 0.19333062655094901 | accuracy: 0.9312500000000001 \n",
      "Epoch 18 | Step 7017 | loss: 0.1943539581654302 | accuracy: 0.9309111445783135 \n",
      "Epoch 18 | Step 7018 | loss: 0.1936788331873403 | accuracy: 0.9311377245508984 \n",
      "Epoch 18 | Step 7019 | loss: 0.19332678842225248 | accuracy: 0.9311755952380955 \n",
      "Epoch 18 | Step 7020 | loss: 0.19462642898044646 | accuracy: 0.9308431952662723 \n",
      "Epoch 18 | Step 7021 | loss: 0.19467264795128042 | accuracy: 0.9308823529411766 \n",
      "Epoch 18 | Step 7022 | loss: 0.19504499657635108 | accuracy: 0.9308296783625732 \n",
      "Epoch 18 | Step 7023 | loss: 0.19536115051528746 | accuracy: 0.9305959302325583 \n",
      "Epoch 18 | Step 7024 | loss: 0.1944644454586713 | accuracy: 0.9309971098265898 \n",
      "Epoch 18 | Step 7025 | loss: 0.19447012074377348 | accuracy: 0.9309446839080462 \n",
      "Epoch 18 | Step 7026 | loss: 0.1941341776507242 | accuracy: 0.9312500000000001 \n",
      "Epoch 18 | Step 7027 | loss: 0.19395995529537854 | accuracy: 0.9312855113636366 \n",
      "Epoch 18 | Step 7028 | loss: 0.19413331454083074 | accuracy: 0.9312323446327685 \n",
      "Epoch 18 | Step 7029 | loss: 0.19388568250650773 | accuracy: 0.9313553370786518 \n",
      "Epoch 18 | Step 7030 | loss: 0.1940684389302185 | accuracy: 0.9313023743016762 \n",
      "Epoch 18 | Step 7031 | loss: 0.1940940962897407 | accuracy: 0.9311631944444446 \n",
      "Epoch 18 | Step 7032 | loss: 0.1937701525115177 | accuracy: 0.9313708563535913 \n",
      "Epoch 18 | Step 7033 | loss: 0.19312773276488862 | accuracy: 0.931662087912088 \n",
      "Epoch 18 | Step 7034 | loss: 0.19288148507068723 | accuracy: 0.9318647540983608 \n",
      "Epoch 18 | Step 7035 | loss: 0.1929286001655071 | accuracy: 0.9319802989130437 \n",
      "Epoch 18 | Step 7036 | loss: 0.19289086235536115 | accuracy: 0.9320101351351353 \n",
      "Epoch 18 | Step 7037 | loss: 0.19294061007038243 | accuracy: 0.9320396505376346 \n",
      "Epoch 18 | Step 7038 | loss: 0.19299795673811504 | accuracy: 0.932235962566845 \n",
      "Epoch 18 | Step 7039 | loss: 0.1932848896434967 | accuracy: 0.9322639627659576 \n",
      "Epoch 18 | Step 7040 | loss: 0.19276153702269158 | accuracy: 0.9324570105820107 \n",
      "Epoch 18 | Step 7041 | loss: 0.19293404448973508 | accuracy: 0.9324835526315791 \n",
      "Epoch 18 | Step 7042 | loss: 0.19321405489719354 | accuracy: 0.9325098167539269 \n",
      "Epoch 18 | Step 7043 | loss: 0.19355283669816956 | accuracy: 0.9325358072916669 \n",
      "Epoch 18 | Step 7044 | loss: 0.19379078755106954 | accuracy: 0.9324805699481866 \n",
      "Epoch 18 | Step 7045 | loss: 0.1934435643332521 | accuracy: 0.932667525773196 \n",
      "Epoch 18 | Step 7046 | loss: 0.19362182815869652 | accuracy: 0.9325320512820514 \n",
      "Epoch 18 | Step 7047 | loss: 0.19390369381527514 | accuracy: 0.9323979591836736 \n",
      "Epoch 18 | Step 7048 | loss: 0.19404969390878826 | accuracy: 0.9323445431472083 \n",
      "Epoch 18 | Step 7049 | loss: 0.1942613752502384 | accuracy: 0.9320549242424244 \n",
      "Epoch 18 | Step 7050 | loss: 0.19468634781525965 | accuracy: 0.9318467336683418 \n",
      "Epoch 18 | Step 7051 | loss: 0.19462340205907824 | accuracy: 0.9317968750000002 \n",
      "Epoch 18 | Step 7052 | loss: 0.19509719897858543 | accuracy: 0.9314365671641792 \n",
      "Epoch 18 | Step 7053 | loss: 0.1953954765997311 | accuracy: 0.9312345297029705 \n",
      "Epoch 18 | Step 7054 | loss: 0.1950637258479161 | accuracy: 0.9313423645320198 \n",
      "Epoch 18 | Step 7055 | loss: 0.19487172650063742 | accuracy: 0.9314491421568629 \n",
      "Epoch 18 | Step 7056 | loss: 0.19491729830823298 | accuracy: 0.9313262195121953 \n",
      "Epoch 18 | Step 7057 | loss: 0.19496079809168013 | accuracy: 0.9313561893203884 \n",
      "Epoch 18 | Step 7058 | loss: 0.19470558016772435 | accuracy: 0.9314613526570049 \n",
      "Epoch 18 | Step 7059 | loss: 0.1944093889771746 | accuracy: 0.9316406250000001 \n",
      "Epoch 18 | Step 7060 | loss: 0.1943577734762402 | accuracy: 0.9315938995215313 \n",
      "Epoch 18 | Step 7061 | loss: 0.19386756260480204 | accuracy: 0.9318452380952382 \n",
      "Epoch 18 | Step 7062 | loss: 0.19366989320064612 | accuracy: 0.9319460900473935 \n",
      "Epoch 18 | Step 7063 | loss: 0.19412224279400317 | accuracy: 0.9318248820754719 \n",
      "Epoch 18 | Step 7064 | loss: 0.1935916082679946 | accuracy: 0.9321449530516434 \n",
      "Epoch 18 | Step 7065 | loss: 0.19344373632257233 | accuracy: 0.932389018691589 \n",
      "Epoch 18 | Step 7066 | loss: 0.19389309300932778 | accuracy: 0.9321947674418606 \n",
      "Epoch 18 | Step 7067 | loss: 0.19442479712543667 | accuracy: 0.932002314814815 \n",
      "Epoch 18 | Step 7068 | loss: 0.1947159926462833 | accuracy: 0.9319556451612905 \n",
      "Epoch 18 | Step 7069 | loss: 0.19439361794689383 | accuracy: 0.9321244266055048 \n",
      "Epoch 18 | Step 7070 | loss: 0.19417166073708778 | accuracy: 0.9321489726027399 \n",
      "Epoch 18 | Step 7071 | loss: 0.19409899538890885 | accuracy: 0.9321022727272729 \n",
      "Epoch 18 | Step 7072 | loss: 0.19369541516535965 | accuracy: 0.9321973981900453 \n",
      "Epoch 18 | Step 7073 | loss: 0.1934060402348772 | accuracy: 0.9323620495495497 \n",
      "Epoch 18 | Step 7074 | loss: 0.1933527079331501 | accuracy: 0.9325252242152468 \n",
      "Epoch 18 | Step 7075 | loss: 0.1932071218865791 | accuracy: 0.9326869419642858 \n",
      "Epoch 18 | Step 7076 | loss: 0.19339892708592948 | accuracy: 0.9325694444444446 \n",
      "Epoch 18 | Step 7077 | loss: 0.19348226563461063 | accuracy: 0.9325221238938054 \n",
      "Epoch 18 | Step 7078 | loss: 0.1934077460400859 | accuracy: 0.9325440528634362 \n",
      "Epoch 18 | Step 7079 | loss: 0.19347743216183105 | accuracy: 0.9324972587719299 \n",
      "Epoch 18 | Step 7080 | loss: 0.19315618556399536 | accuracy: 0.9326555676855897 \n",
      "Epoch 18 | Step 7081 | loss: 0.19309044784825785 | accuracy: 0.9327445652173915 \n",
      "Epoch 18 | Step 7082 | loss: 0.1931886183364051 | accuracy: 0.9326298701298702 \n",
      "Epoch 18 | Step 7083 | loss: 0.1930323439040061 | accuracy: 0.9325161637931035 \n",
      "Epoch 18 | Step 7084 | loss: 0.19291497786157635 | accuracy: 0.9324704935622319 \n",
      "Epoch 18 | Step 7085 | loss: 0.19304368867833394 | accuracy: 0.9324919871794873 \n",
      "Epoch 18 | Step 7086 | loss: 0.19290891638461583 | accuracy: 0.9326462765957448 \n",
      "Epoch 18 | Step 7087 | loss: 0.19292601879875543 | accuracy: 0.9327330508474577 \n",
      "Epoch 18 | Step 7088 | loss: 0.19318047329343324 | accuracy: 0.93268723628692 \n",
      "Epoch 18 | Step 7089 | loss: 0.19354929756216646 | accuracy: 0.9324448529411766 \n",
      "Epoch 18 | Step 7090 | loss: 0.19314432907927487 | accuracy: 0.9324660041841005 \n",
      "Epoch 18 | Step 7091 | loss: 0.19277224298566584 | accuracy: 0.9326171875000001 \n",
      "Epoch 18 | Step 7092 | loss: 0.1929106857643088 | accuracy: 0.9325077800829876 \n",
      "Epoch 18 | Step 7093 | loss: 0.19300559132306047 | accuracy: 0.9324638429752067 \n",
      "Epoch 18 | Step 7094 | loss: 0.19291614094143544 | accuracy: 0.9326131687242799 \n",
      "Epoch 18 | Step 7095 | loss: 0.1923171453880238 | accuracy: 0.9328893442622952 \n",
      "Epoch 18 | Step 7096 | loss: 0.1918487023486167 | accuracy: 0.9330994897959185 \n",
      "Epoch 18 | Step 7097 | loss: 0.1917621646137015 | accuracy: 0.933053861788618 \n",
      "Epoch 18 | Step 7098 | loss: 0.1913612289014857 | accuracy: 0.9331983805668017 \n",
      "Epoch 18 | Step 7099 | loss: 0.19151954979245223 | accuracy: 0.9330267137096775 \n",
      "Epoch 18 | Step 7100 | loss: 0.1914904717370928 | accuracy: 0.9331074297188756 \n",
      "Epoch 18 | Step 7101 | loss: 0.19130105067789557 | accuracy: 0.9331250000000001 \n",
      "Epoch 18 | Step 7102 | loss: 0.19130947575922985 | accuracy: 0.9330801792828687 \n",
      "Epoch 18 | Step 7103 | loss: 0.19131879031007729 | accuracy: 0.9329737103174605 \n",
      "Epoch 18 | Step 7104 | loss: 0.1910615053484327 | accuracy: 0.9329916007905139 \n",
      "Epoch 18 | Step 7105 | loss: 0.19093981498163048 | accuracy: 0.9329478346456694 \n",
      "Epoch 18 | Step 7106 | loss: 0.1905730968450799 | accuracy: 0.9330882352941178 \n",
      "Epoch 18 | Step 7107 | loss: 0.19050914443505465 | accuracy: 0.9330444335937501 \n",
      "Epoch 18 | Step 7108 | loss: 0.19044642386675348 | accuracy: 0.933000972762646 \n",
      "Epoch 18 | Step 7109 | loss: 0.1906169916741377 | accuracy: 0.9328367248062016 \n",
      "Epoch 18 | Step 7110 | loss: 0.19026567428786326 | accuracy: 0.9328547297297298 \n",
      "Epoch 18 | Step 7111 | loss: 0.19010306586726355 | accuracy: 0.9329326923076924 \n",
      "Epoch 18 | Step 7112 | loss: 0.1899277584563042 | accuracy: 0.9330100574712645 \n",
      "Epoch 18 | Step 7113 | loss: 0.19028639516132026 | accuracy: 0.9328482824427483 \n",
      "Epoch 18 | Step 7114 | loss: 0.19026155046013826 | accuracy: 0.9329253802281371 \n",
      "Epoch 18 | Step 7115 | loss: 0.19021609726107935 | accuracy: 0.9329427083333336 \n",
      "Epoch 18 | Step 7116 | loss: 0.19017944753451171 | accuracy: 0.9329599056603776 \n",
      "Epoch 18 | Step 7117 | loss: 0.19004790307043642 | accuracy: 0.9330357142857145 \n",
      "Epoch 18 | Step 7118 | loss: 0.18967931964591653 | accuracy: 0.933169475655431 \n",
      "Epoch 18 | Step 7119 | loss: 0.18999299444536225 | accuracy: 0.9329524253731345 \n",
      "Epoch 18 | Step 7120 | loss: 0.18998798150499963 | accuracy: 0.9329112453531601 \n",
      "Epoch 18 | Step 7121 | loss: 0.19013754685443865 | accuracy: 0.9328125000000002 \n",
      "Epoch 18 | Step 7122 | loss: 0.19012579012565953 | accuracy: 0.9327721402214023 \n",
      "Epoch 18 | Step 7123 | loss: 0.1900752813363558 | accuracy: 0.9328469669117648 \n",
      "Epoch 18 | Step 7124 | loss: 0.19008354666632615 | accuracy: 0.9329212454212455 \n",
      "Epoch 18 | Step 7125 | loss: 0.19033635025640044 | accuracy: 0.9329379562043797 \n",
      "Epoch 18 | Step 7126 | loss: 0.1901142557507212 | accuracy: 0.9328977272727272 \n",
      "Epoch 18 | Step 7127 | loss: 0.19022227228497685 | accuracy: 0.9328577898550725 \n",
      "Epoch 18 | Step 7128 | loss: 0.18997650506102653 | accuracy: 0.9329309566787004 \n",
      "Epoch 18 | Step 7129 | loss: 0.18984543635315607 | accuracy: 0.9330598021582733 \n",
      "Epoch 18 | Step 7130 | loss: 0.189686728060566 | accuracy: 0.9330757168458781 \n",
      "Epoch 18 | Step 7131 | loss: 0.18975982752495582 | accuracy: 0.9328683035714286 \n",
      "Epoch 18 | Step 7132 | loss: 0.18961737515716368 | accuracy: 0.9329959964412812 \n",
      "Epoch 18 | Step 7133 | loss: 0.18927331529029298 | accuracy: 0.9330673758865248 \n",
      "Epoch 18 | Step 7134 | loss: 0.18912478829915028 | accuracy: 0.9330830388692579 \n",
      "Epoch 18 | Step 7135 | loss: 0.18883090422974086 | accuracy: 0.9332086267605634 \n",
      "Epoch 18 | Step 7136 | loss: 0.18866350032519877 | accuracy: 0.9332785087719299 \n",
      "Epoch 18 | Step 7137 | loss: 0.18825773205738383 | accuracy: 0.933402534965035 \n",
      "Epoch 18 | Step 7138 | loss: 0.18831833131377704 | accuracy: 0.9334168118466899 \n",
      "Epoch 18 | Step 7139 | loss: 0.18783497176547015 | accuracy: 0.9336480034722222 \n",
      "Epoch 18 | Step 7140 | loss: 0.188657189606589 | accuracy: 0.9335532006920415 \n",
      "Epoch 18 | Step 7141 | loss: 0.1886380245202574 | accuracy: 0.9335129310344827 \n",
      "Epoch 18 | Step 7142 | loss: 0.18882023384378535 | accuracy: 0.9334192439862543 \n",
      "Epoch 18 | Step 7143 | loss: 0.18878382406108182 | accuracy: 0.9334867294520548 \n",
      "Epoch 18 | Step 7144 | loss: 0.18871863641531395 | accuracy: 0.9335004266211604 \n",
      "Epoch 18 | Step 7145 | loss: 0.18886903468139318 | accuracy: 0.9334077380952381 \n",
      "Epoch 18 | Step 7146 | loss: 0.18863352688692384 | accuracy: 0.9334216101694915 \n",
      "Epoch 18 | Step 7147 | loss: 0.1887671933383555 | accuracy: 0.933277027027027 \n",
      "Epoch 18 | Step 7148 | loss: 0.18867484312065522 | accuracy: 0.9333438552188552 \n",
      "Epoch 18 | Step 7149 | loss: 0.18869961238147429 | accuracy: 0.9333578020134228 \n",
      "Epoch 18 | Step 7150 | loss: 0.18845035434765958 | accuracy: 0.9334239130434783 \n",
      "Epoch 18 | Step 7151 | loss: 0.18808263018727303 | accuracy: 0.9335416666666667 \n",
      "Epoch 18 | Step 7152 | loss: 0.1883032675894392 | accuracy: 0.9334509966777409 \n",
      "Epoch 18 | Step 7153 | loss: 0.18815206242910285 | accuracy: 0.933516142384106 \n",
      "Epoch 18 | Step 7154 | loss: 0.18799438054608827 | accuracy: 0.9335808580858086 \n",
      "Epoch 18 | Step 7155 | loss: 0.18797414382233432 | accuracy: 0.9336451480263158 \n",
      "Epoch 18 | Step 7156 | loss: 0.18792268834153159 | accuracy: 0.9336065573770492 \n",
      "Epoch 18 | Step 7157 | loss: 0.1881085951733433 | accuracy: 0.9334660947712419 \n",
      "Epoch 18 | Step 7158 | loss: 0.18885877456649505 | accuracy: 0.9333265472312704 \n",
      "Epoch 18 | Step 7159 | loss: 0.188777905344576 | accuracy: 0.933390827922078 \n",
      "Epoch 18 | Step 7160 | loss: 0.18857671117898328 | accuracy: 0.9333535598705501 \n",
      "Epoch 18 | Step 7161 | loss: 0.18879515158553276 | accuracy: 0.9333165322580645 \n",
      "Epoch 18 | Step 7162 | loss: 0.18890421629143678 | accuracy: 0.9332797427652733 \n",
      "Epoch 18 | Step 7163 | loss: 0.18877611189889598 | accuracy: 0.9332932692307693 \n",
      "Epoch 18 | Step 7164 | loss: 0.1885982206739937 | accuracy: 0.9333566293929713 \n",
      "Epoch 18 | Step 7165 | loss: 0.18881348093414 | accuracy: 0.9332703025477707 \n",
      "Epoch 18 | Step 7166 | loss: 0.18938438442964398 | accuracy: 0.9331349206349207 \n",
      "Epoch 18 | Step 7167 | loss: 0.1892911198584339 | accuracy: 0.9331487341772152 \n",
      "Epoch 18 | Step 7168 | loss: 0.18911761778762284 | accuracy: 0.9332117507886435 \n",
      "Epoch 18 | Step 7169 | loss: 0.18924095186422452 | accuracy: 0.933126965408805 \n",
      "Epoch 18 | Step 7170 | loss: 0.1892941514246142 | accuracy: 0.9331406739811913 \n",
      "Epoch 18 | Step 7171 | loss: 0.18916721167042846 | accuracy: 0.933154296875 \n",
      "Epoch 18 | Step 7172 | loss: 0.18910837503051456 | accuracy: 0.9331191588785047 \n",
      "Epoch 18 | Step 7173 | loss: 0.1895374418323084 | accuracy: 0.9330842391304348 \n",
      "Epoch 18 | Step 7174 | loss: 0.1893541935150837 | accuracy: 0.9330979102167183 \n",
      "Epoch 18 | Step 7175 | loss: 0.18907684835110913 | accuracy: 0.9332561728395061 \n",
      "Epoch 18 | Step 7176 | loss: 0.18938228554450545 | accuracy: 0.933125 \n",
      "Epoch 18 | Step 7177 | loss: 0.18918435796638203 | accuracy: 0.933282208588957 \n",
      "Epoch 18 | Step 7178 | loss: 0.18937490502264154 | accuracy: 0.9331995412844036 \n",
      "Epoch 18 | Step 7179 | loss: 0.18929639881158744 | accuracy: 0.9332602896341463 \n",
      "Epoch 18 | Step 7180 | loss: 0.18971859299122015 | accuracy: 0.9329882218844985 \n",
      "Epoch 18 | Step 7181 | loss: 0.18960348579919695 | accuracy: 0.9330492424242425 \n",
      "Epoch 18 | Step 7182 | loss: 0.1895738230100931 | accuracy: 0.9330154833836858 \n",
      "Epoch 18 | Step 7183 | loss: 0.18952887388597048 | accuracy: 0.9329819277108434 \n",
      "Epoch 18 | Step 7184 | loss: 0.18950464672691467 | accuracy: 0.9330424174174174 \n",
      "Epoch 18 | Step 7185 | loss: 0.18966677923223926 | accuracy: 0.9328686377245509 \n",
      "Epoch 18 | Step 7186 | loss: 0.1893265247122565 | accuracy: 0.9330223880597015 \n",
      "Epoch 18 | Step 7187 | loss: 0.18911221474852588 | accuracy: 0.9331752232142857 \n",
      "Epoch 18 | Step 7188 | loss: 0.1890778222096426 | accuracy: 0.9331880563798219 \n",
      "Epoch 18 | Step 7189 | loss: 0.18920224766142266 | accuracy: 0.9331545857988166 \n",
      "Epoch 18 | Step 7190 | loss: 0.18911195933203426 | accuracy: 0.9331674041297935 \n",
      "Epoch 18 | Step 7191 | loss: 0.18886337365735975 | accuracy: 0.9332720588235294 \n",
      "Epoch 18 | Step 7192 | loss: 0.1888029715401336 | accuracy: 0.9332844574780058 \n",
      "Epoch 18 | Step 7193 | loss: 0.1886400320071574 | accuracy: 0.933296783625731 \n",
      "Epoch 18 | Step 7194 | loss: 0.1884445331925553 | accuracy: 0.9333545918367347 \n",
      "Epoch 18 | Step 7195 | loss: 0.18825891011849388 | accuracy: 0.9333212209302325 \n",
      "Epoch 18 | Step 7196 | loss: 0.18830952881902885 | accuracy: 0.9332427536231884 \n",
      "Epoch 18 | Step 7197 | loss: 0.1883262294220786 | accuracy: 0.9333453757225434 \n",
      "Epoch 18 | Step 7198 | loss: 0.18814208770777371 | accuracy: 0.9334023775216138 \n",
      "Epoch 18 | Step 7199 | loss: 0.18866125436435482 | accuracy: 0.9333692528735632 \n",
      "Epoch 18 | Step 7200 | loss: 0.18860503563652062 | accuracy: 0.9333810888252149 \n",
      "Epoch 18 | Step 7201 | loss: 0.18844551637768742 | accuracy: 0.9335267857142857 \n",
      "Epoch 18 | Step 7202 | loss: 0.1882883673082729 | accuracy: 0.9336271367521367 \n",
      "Epoch 18 | Step 7203 | loss: 0.18855915406972842 | accuracy: 0.9335493607954546 \n",
      "Epoch 18 | Step 7204 | loss: 0.1883815880073366 | accuracy: 0.933560552407932 \n",
      "Epoch 18 | Step 7205 | loss: 0.18808355752778588 | accuracy: 0.9337040960451978 \n",
      "Epoch 18 | Step 7206 | loss: 0.1877947485992606 | accuracy: 0.9338028169014084 \n",
      "Epoch 18 | Step 7207 | loss: 0.18766697385254197 | accuracy: 0.9338570926966292 \n",
      "Epoch 18 | Step 7208 | loss: 0.18773406946442037 | accuracy: 0.9339110644257703 \n",
      "Epoch 18 | Step 7209 | loss: 0.18768205237704944 | accuracy: 0.9339210893854749 \n",
      "Epoch 18 | Step 7210 | loss: 0.18745409423345308 | accuracy: 0.9340616295264624 \n",
      "Epoch 18 | Step 7211 | loss: 0.18719793407039506 | accuracy: 0.9341579861111111 \n",
      "Epoch 18 | Step 7212 | loss: 0.18724688117771593 | accuracy: 0.9340373961218836 \n",
      "Epoch 18 | Step 7213 | loss: 0.1871047182348222 | accuracy: 0.9341332872928176 \n",
      "Epoch 18 | Step 7214 | loss: 0.18694096013452063 | accuracy: 0.9341856060606061 \n",
      "Epoch 18 | Step 7215 | loss: 0.1867488765945801 | accuracy: 0.9342805631868132 \n",
      "Epoch 18 | Step 7216 | loss: 0.18645839031836753 | accuracy: 0.9344178082191781 \n",
      "Epoch 18 | Step 7217 | loss: 0.18643970679634253 | accuracy: 0.9344262295081968 \n",
      "Epoch 18 | Step 7218 | loss: 0.1862017325143398 | accuracy: 0.9344771798365122 \n",
      "Epoch 18 | Step 7219 | loss: 0.18602305231615898 | accuracy: 0.9345703125 \n",
      "Epoch 18 | Step 7220 | loss: 0.18619334703780768 | accuracy: 0.9345359078590786 \n",
      "Epoch 18 | Step 7221 | loss: 0.18632121619743267 | accuracy: 0.9344594594594594 \n",
      "Epoch 18 | Step 7222 | loss: 0.18629146668547886 | accuracy: 0.9345097708894878 \n",
      "Epoch 18 | Step 7223 | loss: 0.18679061149477313 | accuracy: 0.9343077956989247 \n",
      "Epoch 18 | Step 7224 | loss: 0.18673861867700758 | accuracy: 0.9342325737265416 \n",
      "Epoch 18 | Step 7225 | loss: 0.18664444064631816 | accuracy: 0.9342830882352942 \n",
      "Epoch 18 | Step 7226 | loss: 0.18645013537009553 | accuracy: 0.9344166666666667 \n",
      "Epoch 18 | Step 7227 | loss: 0.1862635644985006 | accuracy: 0.9345079787234043 \n",
      "Epoch 18 | Step 7228 | loss: 0.18613667141853651 | accuracy: 0.9345159151193634 \n",
      "Epoch 18 | Step 7229 | loss: 0.1863603966419028 | accuracy: 0.9343998015873016 \n",
      "Epoch 18 | Step 7230 | loss: 0.18619016687678155 | accuracy: 0.9344492084432717 \n",
      "Epoch 18 | Step 7231 | loss: 0.18597754479238857 | accuracy: 0.9345394736842105 \n",
      "Epoch 18 | Step 7232 | loss: 0.1858871436807427 | accuracy: 0.9345472440944882 \n",
      "Epoch 18 | Step 7233 | loss: 0.1856931861080424 | accuracy: 0.9345549738219895 \n",
      "Epoch 18 | Step 7234 | loss: 0.1855384761919863 | accuracy: 0.9346034595300261 \n",
      "Epoch 18 | Step 7235 | loss: 0.18561481773698077 | accuracy: 0.9345703125 \n",
      "Epoch 18 | Step 7236 | loss: 0.18598047638094267 | accuracy: 0.9344561688311688 \n",
      "Epoch 18 | Step 7237 | loss: 0.18610169723089492 | accuracy: 0.934464054404145 \n",
      "Epoch 18 | Step 7238 | loss: 0.18626930628174032 | accuracy: 0.9344315245478036 \n",
      "Epoch 18 | Step 7239 | loss: 0.18601363910765373 | accuracy: 0.9345199742268041 \n",
      "Epoch 18 | Step 7240 | loss: 0.18618085059148176 | accuracy: 0.9344874678663239 \n",
      "Epoch 18 | Step 7241 | loss: 0.1861657664370842 | accuracy: 0.9344951923076923 \n",
      "Epoch 18 | Step 7242 | loss: 0.18625157966714379 | accuracy: 0.9344229539641944 \n",
      "Epoch 18 | Step 7243 | loss: 0.18606734739578495 | accuracy: 0.9345503826530612 \n",
      "Epoch 18 | Step 7244 | loss: 0.18591135920383242 | accuracy: 0.9345976463104325 \n",
      "Epoch 18 | Step 7245 | loss: 0.18589718297577748 | accuracy: 0.9345256979695431 \n",
      "Epoch 18 | Step 7246 | loss: 0.18574451089282576 | accuracy: 0.9346123417721519 \n",
      "Epoch 18 | Step 7247 | loss: 0.1856072517770408 | accuracy: 0.9346196338383839 \n",
      "Epoch 18 | Step 7248 | loss: 0.18561829136736144 | accuracy: 0.9346268891687658 \n",
      "Epoch 18 | Step 7249 | loss: 0.18572559112205575 | accuracy: 0.9345948492462312 \n",
      "Epoch 18 | Step 7250 | loss: 0.18557586367790557 | accuracy: 0.9346804511278195 \n",
      "Epoch 18 | Step 7251 | loss: 0.18576275398954745 | accuracy: 0.934609375 \n",
      "Epoch 18 | Step 7252 | loss: 0.18571541540120304 | accuracy: 0.9346555486284289 \n",
      "Epoch 18 | Step 7253 | loss: 0.18600609477850333 | accuracy: 0.9345071517412935 \n",
      "Epoch 18 | Step 7254 | loss: 0.185632119357364 | accuracy: 0.934669665012407 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.601504385471344 | accuracy: 0.78125 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.628044068813324 | accuracy: 0.7890625 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.5590441425641378 | accuracy: 0.8020833333333334 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.5325685366988182 | accuracy: 0.8125 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.5429704010486602 | accuracy: 0.809375 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.5333969543377558 | accuracy: 0.8098958333333334 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.5187771320343018 | accuracy: 0.8147321428571429 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.5065547674894333 | accuracy: 0.818359375 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.5025175842973921 | accuracy: 0.8211805555555556 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.5002467066049576 | accuracy: 0.821875 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.505465255542235 | accuracy: 0.8210227272727273 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4980338215827942 | accuracy: 0.8255208333333334 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.5068214077215928 | accuracy: 0.8197115384615384 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.5153795267854417 | accuracy: 0.8180803571428571 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.5018592158953348 | accuracy: 0.8208333333333333 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.5022709928452967 | accuracy: 0.8212890625 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.5152332326945136 | accuracy: 0.8180147058823529 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.5094799068238999 | accuracy: 0.8194444444444444 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.5052984356880187 | accuracy: 0.8199013157894737 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.5002065077424048 | accuracy: 0.82265625 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.499141589516685 | accuracy: 0.8244047619047619 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.49252875555645326 | accuracy: 0.8238636363636364 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4935458302497863 | accuracy: 0.8226902173913043 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4913073206941286 | accuracy: 0.8235677083333334 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4961379146575927 | accuracy: 0.821875 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4871236659013307 | accuracy: 0.8251201923076923 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.48716293992819604 | accuracy: 0.8252314814814815 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.48044051123516895 | accuracy: 0.8275669642857143 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4839109624254292 | accuracy: 0.8270474137931034 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4869450579086939 | accuracy: 0.8260416666666667 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.48054137056873686 | accuracy: 0.8286290322580645 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4748969385400414 | accuracy: 0.8310546875 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.47235263206742023 | accuracy: 0.8328598484848485 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4827057990957709 | accuracy: 0.8304227941176471 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4813315527779715 | accuracy: 0.8294642857142858 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.47455155642496216 | accuracy: 0.8311631944444444 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4757219355654072 | accuracy: 0.831081081081081 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.47482885930098984 | accuracy: 0.8301809210526315 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4723525738868958 | accuracy: 0.8317307692307693 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4766619447618723 | accuracy: 0.8296875 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.48063078340960713 | accuracy: 0.8277439024390244 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4785718594988187 | accuracy: 0.8288690476190477 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.47720478960247925 | accuracy: 0.8288517441860465 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4813102737746455 | accuracy: 0.8277698863636364 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.48521443439854517 | accuracy: 0.826766304175059 \n",
      "Epoch 19 | Step 7255 | loss: 0.10831254720687866 | accuracy: 0.96875 \n",
      "Epoch 19 | Step 7256 | loss: 0.20797887444496155 | accuracy: 0.9375 \n",
      "Epoch 19 | Step 7257 | loss: 0.1809894541899363 | accuracy: 0.9375 \n",
      "Epoch 19 | Step 7258 | loss: 0.1877462975680828 | accuracy: 0.93359375 \n",
      "Epoch 19 | Step 7259 | loss: 0.17319534420967103 | accuracy: 0.9375 \n",
      "Epoch 19 | Step 7260 | loss: 0.19490294655164084 | accuracy: 0.9244791666666666 \n",
      "Epoch 19 | Step 7261 | loss: 0.20488765835762024 | accuracy: 0.9263392857142857 \n",
      "Epoch 19 | Step 7262 | loss: 0.21678703278303146 | accuracy: 0.92578125 \n",
      "Epoch 19 | Step 7263 | loss: 0.2132946898539861 | accuracy: 0.9270833333333334 \n",
      "Epoch 19 | Step 7264 | loss: 0.21765947788953782 | accuracy: 0.9203125 \n",
      "Epoch 19 | Step 7265 | loss: 0.21788613227280704 | accuracy: 0.9190340909090909 \n",
      "Epoch 19 | Step 7266 | loss: 0.21836849922935167 | accuracy: 0.921875 \n",
      "Epoch 19 | Step 7267 | loss: 0.21387542669589704 | accuracy: 0.9254807692307693 \n",
      "Epoch 19 | Step 7268 | loss: 0.21534753165074758 | accuracy: 0.9241071428571429 \n",
      "Epoch 19 | Step 7269 | loss: 0.2098363439242045 | accuracy: 0.928125 \n",
      "Epoch 19 | Step 7270 | loss: 0.20117652462795377 | accuracy: 0.931640625 \n",
      "Epoch 19 | Step 7271 | loss: 0.195326088105931 | accuracy: 0.9338235294117647 \n",
      "Epoch 19 | Step 7272 | loss: 0.19280237621731228 | accuracy: 0.9357638888888888 \n",
      "Epoch 19 | Step 7273 | loss: 0.19095668039823832 | accuracy: 0.9366776315789473 \n",
      "Epoch 19 | Step 7274 | loss: 0.19538433700799943 | accuracy: 0.9359375 \n",
      "Epoch 19 | Step 7275 | loss: 0.19504643976688385 | accuracy: 0.9360119047619048 \n",
      "Epoch 19 | Step 7276 | loss: 0.19438454576513983 | accuracy: 0.9367897727272727 \n",
      "Epoch 19 | Step 7277 | loss: 0.19313593273577484 | accuracy: 0.936141304347826 \n",
      "Epoch 19 | Step 7278 | loss: 0.1883486776302258 | accuracy: 0.9388020833333334 \n",
      "Epoch 19 | Step 7279 | loss: 0.18499457150697707 | accuracy: 0.939375 \n",
      "Epoch 19 | Step 7280 | loss: 0.18516234623698088 | accuracy: 0.9381009615384616 \n",
      "Epoch 19 | Step 7281 | loss: 0.18453964177105162 | accuracy: 0.9386574074074074 \n",
      "Epoch 19 | Step 7282 | loss: 0.18007216389690126 | accuracy: 0.9402901785714286 \n",
      "Epoch 19 | Step 7283 | loss: 0.17800032835582208 | accuracy: 0.9407327586206896 \n",
      "Epoch 19 | Step 7284 | loss: 0.18038238038619359 | accuracy: 0.9390625 \n",
      "Epoch 19 | Step 7285 | loss: 0.18094306559331955 | accuracy: 0.9400201612903226 \n",
      "Epoch 19 | Step 7286 | loss: 0.18089616671204567 | accuracy: 0.93994140625 \n",
      "Epoch 19 | Step 7287 | loss: 0.1825868044838761 | accuracy: 0.9393939393939394 \n",
      "Epoch 19 | Step 7288 | loss: 0.1830481882481014 | accuracy: 0.9388786764705882 \n",
      "Epoch 19 | Step 7289 | loss: 0.1816133256469454 | accuracy: 0.9388392857142858 \n",
      "Epoch 19 | Step 7290 | loss: 0.18352612232168516 | accuracy: 0.9375 \n",
      "Epoch 19 | Step 7291 | loss: 0.180935403583823 | accuracy: 0.9387668918918919 \n",
      "Epoch 19 | Step 7292 | loss: 0.18034612210957626 | accuracy: 0.9391447368421053 \n",
      "Epoch 19 | Step 7293 | loss: 0.1790590364581499 | accuracy: 0.9395032051282052 \n",
      "Epoch 19 | Step 7294 | loss: 0.1792159417644143 | accuracy: 0.9390625 \n",
      "Epoch 19 | Step 7295 | loss: 0.17838114590906515 | accuracy: 0.9394054878048781 \n",
      "Epoch 19 | Step 7296 | loss: 0.17827774885864484 | accuracy: 0.9397321428571429 \n",
      "Epoch 19 | Step 7297 | loss: 0.17669451288705645 | accuracy: 0.940406976744186 \n",
      "Epoch 19 | Step 7298 | loss: 0.17475519126111808 | accuracy: 0.94140625 \n",
      "Epoch 19 | Step 7299 | loss: 0.17520753211445275 | accuracy: 0.940625 \n",
      "Epoch 19 | Step 7300 | loss: 0.1758638435731763 | accuracy: 0.9408967391304348 \n",
      "Epoch 19 | Step 7301 | loss: 0.17511955347466973 | accuracy: 0.9408244680851063 \n",
      "Epoch 19 | Step 7302 | loss: 0.17632042989134786 | accuracy: 0.9401041666666666 \n",
      "Epoch 19 | Step 7303 | loss: 0.17438858808303362 | accuracy: 0.9410076530612245 \n",
      "Epoch 19 | Step 7304 | loss: 0.1754176756739616 | accuracy: 0.940625 \n",
      "Epoch 19 | Step 7305 | loss: 0.17934838550932264 | accuracy: 0.9393382352941176 \n",
      "Epoch 19 | Step 7306 | loss: 0.1809963724361016 | accuracy: 0.9387019230769231 \n",
      "Epoch 19 | Step 7307 | loss: 0.18024593169959083 | accuracy: 0.9386792452830188 \n",
      "Epoch 19 | Step 7308 | loss: 0.1795963440780286 | accuracy: 0.9389467592592593 \n",
      "Epoch 19 | Step 7309 | loss: 0.18057918575677 | accuracy: 0.9383522727272727 \n",
      "Epoch 19 | Step 7310 | loss: 0.18263997377029484 | accuracy: 0.9377790178571429 \n",
      "Epoch 19 | Step 7311 | loss: 0.18223845305150013 | accuracy: 0.9383223684210527 \n",
      "Epoch 19 | Step 7312 | loss: 0.18311178427318045 | accuracy: 0.9385775862068966 \n",
      "Epoch 19 | Step 7313 | loss: 0.18441755387742637 | accuracy: 0.9385593220338984 \n",
      "Epoch 19 | Step 7314 | loss: 0.18559323449929552 | accuracy: 0.9380208333333333 \n",
      "Epoch 19 | Step 7315 | loss: 0.18464826584839428 | accuracy: 0.9382684426229508 \n",
      "Epoch 19 | Step 7316 | loss: 0.18415498565281588 | accuracy: 0.938508064516129 \n",
      "Epoch 19 | Step 7317 | loss: 0.18386818634139165 | accuracy: 0.9384920634920635 \n",
      "Epoch 19 | Step 7318 | loss: 0.18277154373936352 | accuracy: 0.938720703125 \n",
      "Epoch 19 | Step 7319 | loss: 0.18352536192307103 | accuracy: 0.9382211538461539 \n",
      "Epoch 19 | Step 7320 | loss: 0.18221522100044016 | accuracy: 0.9382102272727273 \n",
      "Epoch 19 | Step 7321 | loss: 0.1811046439097888 | accuracy: 0.9386660447761194 \n",
      "Epoch 19 | Step 7322 | loss: 0.18069563006215233 | accuracy: 0.9386488970588235 \n",
      "Epoch 19 | Step 7323 | loss: 0.18194422762894974 | accuracy: 0.9384057971014492 \n",
      "Epoch 19 | Step 7324 | loss: 0.18286307720201353 | accuracy: 0.9381696428571429 \n",
      "Epoch 19 | Step 7325 | loss: 0.18399519578252038 | accuracy: 0.9377200704225352 \n",
      "Epoch 19 | Step 7326 | loss: 0.18297317044602499 | accuracy: 0.9379340277777778 \n",
      "Epoch 19 | Step 7327 | loss: 0.1833011146685848 | accuracy: 0.9381421232876712 \n",
      "Epoch 19 | Step 7328 | loss: 0.1835125592109319 | accuracy: 0.9381334459459459 \n",
      "Epoch 19 | Step 7329 | loss: 0.18437248786290483 | accuracy: 0.9379166666666666 \n",
      "Epoch 19 | Step 7330 | loss: 0.18310080723542912 | accuracy: 0.9383223684210527 \n",
      "Epoch 19 | Step 7331 | loss: 0.18503593605060079 | accuracy: 0.937702922077922 \n",
      "Epoch 19 | Step 7332 | loss: 0.18461889066757298 | accuracy: 0.9377003205128205 \n",
      "Epoch 19 | Step 7333 | loss: 0.18383824768700174 | accuracy: 0.9376977848101266 \n",
      "Epoch 19 | Step 7334 | loss: 0.18400065358728168 | accuracy: 0.9375 \n",
      "Epoch 19 | Step 7335 | loss: 0.1845598581396503 | accuracy: 0.9375 \n",
      "Epoch 19 | Step 7336 | loss: 0.18358764434006156 | accuracy: 0.9378810975609756 \n",
      "Epoch 19 | Step 7337 | loss: 0.1841802272092865 | accuracy: 0.9376882530120482 \n",
      "Epoch 19 | Step 7338 | loss: 0.1841330806769076 | accuracy: 0.9378720238095238 \n",
      "Epoch 19 | Step 7339 | loss: 0.18479704067987554 | accuracy: 0.9376838235294118 \n",
      "Epoch 19 | Step 7340 | loss: 0.18356372753894606 | accuracy: 0.9382267441860465 \n",
      "Epoch 19 | Step 7341 | loss: 0.18351591121533822 | accuracy: 0.9382183908045977 \n",
      "Epoch 19 | Step 7342 | loss: 0.18403825934299015 | accuracy: 0.9380326704545454 \n",
      "Epoch 19 | Step 7343 | loss: 0.1835788805665595 | accuracy: 0.9380266853932584 \n",
      "Epoch 19 | Step 7344 | loss: 0.18449459829264217 | accuracy: 0.9375 \n",
      "Epoch 19 | Step 7345 | loss: 0.1847023599586644 | accuracy: 0.9373282967032966 \n",
      "Epoch 19 | Step 7346 | loss: 0.18676014949122202 | accuracy: 0.9368206521739131 \n",
      "Epoch 19 | Step 7347 | loss: 0.18913031545698003 | accuracy: 0.9359879032258065 \n",
      "Epoch 19 | Step 7348 | loss: 0.18828551859614698 | accuracy: 0.9365026595744681 \n",
      "Epoch 19 | Step 7349 | loss: 0.18719472681221208 | accuracy: 0.9370065789473684 \n",
      "Epoch 19 | Step 7350 | loss: 0.18665475646654764 | accuracy: 0.9368489583333334 \n",
      "Epoch 19 | Step 7351 | loss: 0.1863168911221101 | accuracy: 0.9368556701030928 \n",
      "Epoch 19 | Step 7352 | loss: 0.18764107202997013 | accuracy: 0.9362244897959183 \n",
      "Epoch 19 | Step 7353 | loss: 0.18703862919349862 | accuracy: 0.936395202020202 \n",
      "Epoch 19 | Step 7354 | loss: 0.18760885834693908 | accuracy: 0.93625 \n",
      "Epoch 19 | Step 7355 | loss: 0.18794972515932404 | accuracy: 0.9362623762376238 \n",
      "Epoch 19 | Step 7356 | loss: 0.18818433845744414 | accuracy: 0.9361213235294118 \n",
      "Epoch 19 | Step 7357 | loss: 0.1877572504640783 | accuracy: 0.9364381067961165 \n",
      "Epoch 19 | Step 7358 | loss: 0.18816650644517863 | accuracy: 0.9364483173076923 \n",
      "Epoch 19 | Step 7359 | loss: 0.18874556833789463 | accuracy: 0.9360119047619048 \n",
      "Epoch 19 | Step 7360 | loss: 0.18811008840237023 | accuracy: 0.9361733490566038 \n",
      "Epoch 19 | Step 7361 | loss: 0.18844154936687968 | accuracy: 0.9360397196261683 \n",
      "Epoch 19 | Step 7362 | loss: 0.18910659835846336 | accuracy: 0.9357638888888888 \n",
      "Epoch 19 | Step 7363 | loss: 0.1881873031411696 | accuracy: 0.9360665137614679 \n",
      "Epoch 19 | Step 7364 | loss: 0.18776351369240069 | accuracy: 0.936221590909091 \n",
      "Epoch 19 | Step 7365 | loss: 0.18861172724146028 | accuracy: 0.9358108108108109 \n",
      "Epoch 19 | Step 7366 | loss: 0.18920403366376246 | accuracy: 0.935546875 \n",
      "Epoch 19 | Step 7367 | loss: 0.18893588413443185 | accuracy: 0.9357024336283186 \n",
      "Epoch 19 | Step 7368 | loss: 0.188650004108224 | accuracy: 0.9357182017543859 \n",
      "Epoch 19 | Step 7369 | loss: 0.1879284397415493 | accuracy: 0.9360054347826087 \n",
      "Epoch 19 | Step 7370 | loss: 0.18766544232594556 | accuracy: 0.9360183189655172 \n",
      "Epoch 19 | Step 7371 | loss: 0.18703096678369066 | accuracy: 0.9364316239316239 \n",
      "Epoch 19 | Step 7372 | loss: 0.18685264007772429 | accuracy: 0.936573093220339 \n",
      "Epoch 19 | Step 7373 | loss: 0.18701007605350317 | accuracy: 0.936186974789916 \n",
      "Epoch 19 | Step 7374 | loss: 0.18711897240330774 | accuracy: 0.9359375 \n",
      "Epoch 19 | Step 7375 | loss: 0.18655106843995653 | accuracy: 0.9360795454545454 \n",
      "Epoch 19 | Step 7376 | loss: 0.18689517237123895 | accuracy: 0.9358350409836066 \n",
      "Epoch 19 | Step 7377 | loss: 0.18653365279116282 | accuracy: 0.9357215447154471 \n",
      "Epoch 19 | Step 7378 | loss: 0.1874823742095501 | accuracy: 0.9352318548387096 \n",
      "Epoch 19 | Step 7379 | loss: 0.18768534111976623 | accuracy: 0.93475 \n",
      "Epoch 19 | Step 7380 | loss: 0.1870885311019799 | accuracy: 0.9348958333333334 \n",
      "Epoch 19 | Step 7381 | loss: 0.18706526478209834 | accuracy: 0.9347933070866141 \n",
      "Epoch 19 | Step 7382 | loss: 0.18671143538085744 | accuracy: 0.934814453125 \n",
      "Epoch 19 | Step 7383 | loss: 0.186229417663674 | accuracy: 0.9348352713178295 \n",
      "Epoch 19 | Step 7384 | loss: 0.18670187254364673 | accuracy: 0.9346153846153846 \n",
      "Epoch 19 | Step 7385 | loss: 0.1870304706101199 | accuracy: 0.9345181297709924 \n",
      "Epoch 19 | Step 7386 | loss: 0.18678254605920025 | accuracy: 0.9347774621212122 \n",
      "Epoch 19 | Step 7387 | loss: 0.18632499576735317 | accuracy: 0.9350328947368421 \n",
      "Epoch 19 | Step 7388 | loss: 0.18557567900018906 | accuracy: 0.9352845149253731 \n",
      "Epoch 19 | Step 7389 | loss: 0.18578279388171656 | accuracy: 0.9350694444444444 \n",
      "Epoch 19 | Step 7390 | loss: 0.18665270107414791 | accuracy: 0.9349724264705882 \n",
      "Epoch 19 | Step 7391 | loss: 0.18707536144630751 | accuracy: 0.9348768248175182 \n",
      "Epoch 19 | Step 7392 | loss: 0.18704352965173515 | accuracy: 0.9347826086956522 \n",
      "Epoch 19 | Step 7393 | loss: 0.18791803540728932 | accuracy: 0.9345773381294964 \n",
      "Epoch 19 | Step 7394 | loss: 0.18752193828778607 | accuracy: 0.9345982142857143 \n",
      "Epoch 19 | Step 7395 | loss: 0.18728532240534504 | accuracy: 0.934729609929078 \n",
      "Epoch 19 | Step 7396 | loss: 0.18706398619942263 | accuracy: 0.9348591549295775 \n",
      "Epoch 19 | Step 7397 | loss: 0.18646316975355148 | accuracy: 0.9350961538461539 \n",
      "Epoch 19 | Step 7398 | loss: 0.1862498700308303 | accuracy: 0.9351128472222222 \n",
      "Epoch 19 | Step 7399 | loss: 0.18613315085912574 | accuracy: 0.9349137931034482 \n",
      "Epoch 19 | Step 7400 | loss: 0.18636226148842133 | accuracy: 0.934931506849315 \n",
      "Epoch 19 | Step 7401 | loss: 0.18647970466994915 | accuracy: 0.9349489795918368 \n",
      "Epoch 19 | Step 7402 | loss: 0.18638509637802034 | accuracy: 0.9348606418918919 \n",
      "Epoch 19 | Step 7403 | loss: 0.18638949831260132 | accuracy: 0.9346686241610739 \n",
      "Epoch 19 | Step 7404 | loss: 0.18558185294270518 | accuracy: 0.935 \n",
      "Epoch 19 | Step 7405 | loss: 0.1858741039570594 | accuracy: 0.9349130794701986 \n",
      "Epoch 19 | Step 7406 | loss: 0.18591474609351474 | accuracy: 0.9350328947368421 \n",
      "Epoch 19 | Step 7407 | loss: 0.1867463374936503 | accuracy: 0.9348447712418301 \n",
      "Epoch 19 | Step 7408 | loss: 0.1861485504581557 | accuracy: 0.934963474025974 \n",
      "Epoch 19 | Step 7409 | loss: 0.18548720248283884 | accuracy: 0.9351814516129032 \n",
      "Epoch 19 | Step 7410 | loss: 0.18453270158706575 | accuracy: 0.9355969551282052 \n",
      "Epoch 19 | Step 7411 | loss: 0.18445417674104125 | accuracy: 0.9355095541401274 \n",
      "Epoch 19 | Step 7412 | loss: 0.18413705576824244 | accuracy: 0.9354232594936709 \n",
      "Epoch 19 | Step 7413 | loss: 0.18430232907990995 | accuracy: 0.9352397798742138 \n",
      "Epoch 19 | Step 7414 | loss: 0.18423363072797663 | accuracy: 0.93515625 \n",
      "Epoch 19 | Step 7415 | loss: 0.1839254819643424 | accuracy: 0.9352678571428571 \n",
      "Epoch 19 | Step 7416 | loss: 0.1839831255284357 | accuracy: 0.9353780864197531 \n",
      "Epoch 19 | Step 7417 | loss: 0.18321751478625228 | accuracy: 0.9356786809815951 \n",
      "Epoch 19 | Step 7418 | loss: 0.18281428002547934 | accuracy: 0.9357850609756098 \n",
      "Epoch 19 | Step 7419 | loss: 0.18275553137063988 | accuracy: 0.9356060606060606 \n",
      "Epoch 19 | Step 7420 | loss: 0.18380997487040895 | accuracy: 0.9353350903614458 \n",
      "Epoch 19 | Step 7421 | loss: 0.18321915336711686 | accuracy: 0.9355351796407185 \n",
      "Epoch 19 | Step 7422 | loss: 0.1828526962282403 | accuracy: 0.935546875 \n",
      "Epoch 19 | Step 7423 | loss: 0.1841765712263317 | accuracy: 0.9352810650887574 \n",
      "Epoch 19 | Step 7424 | loss: 0.1843368816463387 | accuracy: 0.9352022058823529 \n",
      "Epoch 19 | Step 7425 | loss: 0.18472751230001458 | accuracy: 0.935124269005848 \n",
      "Epoch 19 | Step 7426 | loss: 0.18500593594860207 | accuracy: 0.935047238372093 \n",
      "Epoch 19 | Step 7427 | loss: 0.1841633761075536 | accuracy: 0.9354226878612717 \n",
      "Epoch 19 | Step 7428 | loss: 0.18415253697198705 | accuracy: 0.9353448275862069 \n",
      "Epoch 19 | Step 7429 | loss: 0.18386006093450963 | accuracy: 0.9355357142857142 \n",
      "Epoch 19 | Step 7430 | loss: 0.18379457847384575 | accuracy: 0.9356356534090909 \n",
      "Epoch 19 | Step 7431 | loss: 0.18397224574523466 | accuracy: 0.9355579096045198 \n",
      "Epoch 19 | Step 7432 | loss: 0.18384703234089234 | accuracy: 0.9356566011235955 \n",
      "Epoch 19 | Step 7433 | loss: 0.1841150906207509 | accuracy: 0.9356668994413407 \n",
      "Epoch 19 | Step 7434 | loss: 0.1841557248805961 | accuracy: 0.9356770833333333 \n",
      "Epoch 19 | Step 7435 | loss: 0.18385305335920168 | accuracy: 0.9358598066298343 \n",
      "Epoch 19 | Step 7436 | loss: 0.18326654516487995 | accuracy: 0.9361263736263736 \n",
      "Epoch 19 | Step 7437 | loss: 0.18309354930708976 | accuracy: 0.936219262295082 \n",
      "Epoch 19 | Step 7438 | loss: 0.18323953305978496 | accuracy: 0.9362262228260869 \n",
      "Epoch 19 | Step 7439 | loss: 0.18319041577948114 | accuracy: 0.9363175675675676 \n",
      "Epoch 19 | Step 7440 | loss: 0.18321905655646203 | accuracy: 0.9362399193548387 \n",
      "Epoch 19 | Step 7441 | loss: 0.18323667867378124 | accuracy: 0.9362466577540107 \n",
      "Epoch 19 | Step 7442 | loss: 0.18341358610369432 | accuracy: 0.9363364361702128 \n",
      "Epoch 19 | Step 7443 | loss: 0.18293371767042182 | accuracy: 0.9364252645502645 \n",
      "Epoch 19 | Step 7444 | loss: 0.18303876136870767 | accuracy: 0.9364309210526316 \n",
      "Epoch 19 | Step 7445 | loss: 0.18329089421642394 | accuracy: 0.9363547120418848 \n",
      "Epoch 19 | Step 7446 | loss: 0.1835533882064435 | accuracy: 0.9363606770833334 \n",
      "Epoch 19 | Step 7447 | loss: 0.1840105625207252 | accuracy: 0.9362046632124352 \n",
      "Epoch 19 | Step 7448 | loss: 0.183648277669377 | accuracy: 0.9363724226804123 \n",
      "Epoch 19 | Step 7449 | loss: 0.18399772951618226 | accuracy: 0.9361378205128205 \n",
      "Epoch 19 | Step 7450 | loss: 0.18430408715669605 | accuracy: 0.9359853316326531 \n",
      "Epoch 19 | Step 7451 | loss: 0.18441986373914082 | accuracy: 0.9359137055837563 \n",
      "Epoch 19 | Step 7452 | loss: 0.18464013988697778 | accuracy: 0.9357638888888888 \n",
      "Epoch 19 | Step 7453 | loss: 0.18512106520222066 | accuracy: 0.9356155778894473 \n",
      "Epoch 19 | Step 7454 | loss: 0.18510930838063366 | accuracy: 0.935546875 \n",
      "Epoch 19 | Step 7455 | loss: 0.185653716492564 | accuracy: 0.9352456467661692 \n",
      "Epoch 19 | Step 7456 | loss: 0.18574763120769872 | accuracy: 0.9351794554455446 \n",
      "Epoch 19 | Step 7457 | loss: 0.1854366606716159 | accuracy: 0.9353448275862069 \n",
      "Epoch 19 | Step 7458 | loss: 0.1852733539052162 | accuracy: 0.9353553921568627 \n",
      "Epoch 19 | Step 7459 | loss: 0.18532282762774613 | accuracy: 0.9352134146341463 \n",
      "Epoch 19 | Step 7460 | loss: 0.18540818983851712 | accuracy: 0.9351486650485437 \n",
      "Epoch 19 | Step 7461 | loss: 0.18509737231233275 | accuracy: 0.9353109903381642 \n",
      "Epoch 19 | Step 7462 | loss: 0.18477866592673736 | accuracy: 0.9353215144230769 \n",
      "Epoch 19 | Step 7463 | loss: 0.18470568906818857 | accuracy: 0.9354066985645934 \n",
      "Epoch 19 | Step 7464 | loss: 0.184277534360687 | accuracy: 0.9355654761904761 \n",
      "Epoch 19 | Step 7465 | loss: 0.18405878157200414 | accuracy: 0.9357968009478673 \n",
      "Epoch 19 | Step 7466 | loss: 0.1844191917587283 | accuracy: 0.9357311320754716 \n",
      "Epoch 19 | Step 7467 | loss: 0.1838815893470682 | accuracy: 0.9360328638497653 \n",
      "Epoch 19 | Step 7468 | loss: 0.1838320467064036 | accuracy: 0.9361857476635514 \n",
      "Epoch 19 | Step 7469 | loss: 0.18413720219287769 | accuracy: 0.9361191860465117 \n",
      "Epoch 19 | Step 7470 | loss: 0.18457394043259606 | accuracy: 0.9361255787037037 \n",
      "Epoch 19 | Step 7471 | loss: 0.18488192563438752 | accuracy: 0.9361319124423964 \n",
      "Epoch 19 | Step 7472 | loss: 0.18462683094682503 | accuracy: 0.9362098623853211 \n",
      "Epoch 19 | Step 7473 | loss: 0.184381110942391 | accuracy: 0.9362157534246576 \n",
      "Epoch 19 | Step 7474 | loss: 0.18440929696979855 | accuracy: 0.9360795454545454 \n",
      "Epoch 19 | Step 7475 | loss: 0.18404756383591114 | accuracy: 0.9361566742081447 \n",
      "Epoch 19 | Step 7476 | loss: 0.18368246216696132 | accuracy: 0.9363738738738738 \n",
      "Epoch 19 | Step 7477 | loss: 0.18365117170818723 | accuracy: 0.9364489910313901 \n",
      "Epoch 19 | Step 7478 | loss: 0.18346844013181654 | accuracy: 0.9365234375 \n",
      "Epoch 19 | Step 7479 | loss: 0.1837055641909441 | accuracy: 0.9363888888888889 \n",
      "Epoch 19 | Step 7480 | loss: 0.1837872594957595 | accuracy: 0.9363938053097345 \n",
      "Epoch 19 | Step 7481 | loss: 0.18368771191407413 | accuracy: 0.936398678414097 \n",
      "Epoch 19 | Step 7482 | loss: 0.18371001956167457 | accuracy: 0.9363349780701754 \n",
      "Epoch 19 | Step 7483 | loss: 0.18366965487208955 | accuracy: 0.9364082969432315 \n",
      "Epoch 19 | Step 7484 | loss: 0.1836097116541604 | accuracy: 0.9364809782608695 \n",
      "Epoch 19 | Step 7485 | loss: 0.1837589698662232 | accuracy: 0.9363501082251082 \n",
      "Epoch 19 | Step 7486 | loss: 0.18356266796010842 | accuracy: 0.9362203663793104 \n",
      "Epoch 19 | Step 7487 | loss: 0.18337934823954571 | accuracy: 0.9361587982832618 \n",
      "Epoch 19 | Step 7488 | loss: 0.18349592984677895 | accuracy: 0.9361645299145299 \n",
      "Epoch 19 | Step 7489 | loss: 0.18338803260567346 | accuracy: 0.9363031914893617 \n",
      "Epoch 19 | Step 7490 | loss: 0.183505493752911 | accuracy: 0.9363082627118644 \n",
      "Epoch 19 | Step 7491 | loss: 0.18365194744387262 | accuracy: 0.9363132911392406 \n",
      "Epoch 19 | Step 7492 | loss: 0.18410448233808294 | accuracy: 0.9360556722689075 \n",
      "Epoch 19 | Step 7493 | loss: 0.18370807661858068 | accuracy: 0.9361270920502092 \n",
      "Epoch 19 | Step 7494 | loss: 0.18330367264958725 | accuracy: 0.9362630208333333 \n",
      "Epoch 19 | Step 7495 | loss: 0.18336965231789104 | accuracy: 0.9362033195020747 \n",
      "Epoch 19 | Step 7496 | loss: 0.18353980984384863 | accuracy: 0.9361441115702479 \n",
      "Epoch 19 | Step 7497 | loss: 0.18342308738410723 | accuracy: 0.9362139917695473 \n",
      "Epoch 19 | Step 7498 | loss: 0.18284770437195658 | accuracy: 0.9364754098360656 \n",
      "Epoch 19 | Step 7499 | loss: 0.1824070745889022 | accuracy: 0.936670918367347 \n",
      "Epoch 19 | Step 7500 | loss: 0.18230232387417705 | accuracy: 0.9368013211382114 \n",
      "Epoch 19 | Step 7501 | loss: 0.18193647144777095 | accuracy: 0.9369306680161943 \n",
      "Epoch 19 | Step 7502 | loss: 0.18217674919193796 | accuracy: 0.9367439516129032 \n",
      "Epoch 19 | Step 7503 | loss: 0.1821633777225832 | accuracy: 0.9368097389558233 \n",
      "Epoch 19 | Step 7504 | loss: 0.18205012500286108 | accuracy: 0.936875 \n",
      "Epoch 19 | Step 7505 | loss: 0.18203646633254586 | accuracy: 0.9368152390438247 \n",
      "Epoch 19 | Step 7506 | loss: 0.1819754297298099 | accuracy: 0.9368179563492064 \n",
      "Epoch 19 | Step 7507 | loss: 0.18167839685212017 | accuracy: 0.9368824110671937 \n",
      "Epoch 19 | Step 7508 | loss: 0.18155784447362108 | accuracy: 0.9368848425196851 \n",
      "Epoch 19 | Step 7509 | loss: 0.18121691208844096 | accuracy: 0.9370098039215686 \n",
      "Epoch 19 | Step 7510 | loss: 0.18123874472803442 | accuracy: 0.93701171875 \n",
      "Epoch 19 | Step 7511 | loss: 0.18118002196114355 | accuracy: 0.9370744163424124 \n",
      "Epoch 19 | Step 7512 | loss: 0.1814016063026218 | accuracy: 0.9368943798449613 \n",
      "Epoch 19 | Step 7513 | loss: 0.18101971274292153 | accuracy: 0.9370173745173745 \n",
      "Epoch 19 | Step 7514 | loss: 0.18086932934820657 | accuracy: 0.9370793269230769 \n",
      "Epoch 19 | Step 7515 | loss: 0.18077465672031678 | accuracy: 0.937080938697318 \n",
      "Epoch 19 | Step 7516 | loss: 0.18114152729852515 | accuracy: 0.9368439885496184 \n",
      "Epoch 19 | Step 7517 | loss: 0.1811615627244852 | accuracy: 0.9369058935361216 \n",
      "Epoch 19 | Step 7518 | loss: 0.18113194882982614 | accuracy: 0.9369081439393939 \n",
      "Epoch 19 | Step 7519 | loss: 0.18102978285191199 | accuracy: 0.9369103773584906 \n",
      "Epoch 19 | Step 7520 | loss: 0.18093581489266314 | accuracy: 0.9369713345864662 \n",
      "Epoch 19 | Step 7521 | loss: 0.18058983281198965 | accuracy: 0.9370903558052435 \n",
      "Epoch 19 | Step 7522 | loss: 0.18084389446720264 | accuracy: 0.9369752798507462 \n",
      "Epoch 19 | Step 7523 | loss: 0.18081564605790004 | accuracy: 0.9369772304832714 \n",
      "Epoch 19 | Step 7524 | loss: 0.18116795583455655 | accuracy: 0.9367476851851851 \n",
      "Epoch 19 | Step 7525 | loss: 0.18107032030820852 | accuracy: 0.936865774907749 \n",
      "Epoch 19 | Step 7526 | loss: 0.18100067871787098 | accuracy: 0.9369255514705882 \n",
      "Epoch 19 | Step 7527 | loss: 0.18100105239685643 | accuracy: 0.9369848901098901 \n",
      "Epoch 19 | Step 7528 | loss: 0.18120300163426545 | accuracy: 0.9369867700729927 \n",
      "Epoch 19 | Step 7529 | loss: 0.18100963400168857 | accuracy: 0.9370454545454545 \n",
      "Epoch 19 | Step 7530 | loss: 0.1810869369655848 | accuracy: 0.9370471014492754 \n",
      "Epoch 19 | Step 7531 | loss: 0.18089724773211605 | accuracy: 0.9371615523465704 \n",
      "Epoch 19 | Step 7532 | loss: 0.18084692812973652 | accuracy: 0.9372751798561151 \n",
      "Epoch 19 | Step 7533 | loss: 0.1807298575090679 | accuracy: 0.9372759856630825 \n",
      "Epoch 19 | Step 7534 | loss: 0.18081919952694864 | accuracy: 0.9371651785714286 \n",
      "Epoch 19 | Step 7535 | loss: 0.18071255774578596 | accuracy: 0.9372775800711743 \n",
      "Epoch 19 | Step 7536 | loss: 0.18040290197476433 | accuracy: 0.9373337765957447 \n",
      "Epoch 19 | Step 7537 | loss: 0.18024557936844476 | accuracy: 0.9373343639575972 \n",
      "Epoch 19 | Step 7538 | loss: 0.1800034009444882 | accuracy: 0.9373899647887324 \n",
      "Epoch 19 | Step 7539 | loss: 0.1798447180735438 | accuracy: 0.937390350877193 \n",
      "Epoch 19 | Step 7540 | loss: 0.17942460427073753 | accuracy: 0.9375 \n",
      "Epoch 19 | Step 7541 | loss: 0.17941067592347962 | accuracy: 0.9375 \n",
      "Epoch 19 | Step 7542 | loss: 0.17894578597042715 | accuracy: 0.9377170138888888 \n",
      "Epoch 19 | Step 7543 | loss: 0.17985842762366716 | accuracy: 0.9375540657439446 \n",
      "Epoch 19 | Step 7544 | loss: 0.17986174535391664 | accuracy: 0.9375538793103448 \n",
      "Epoch 19 | Step 7545 | loss: 0.18005681566612422 | accuracy: 0.9374463058419243 \n",
      "Epoch 19 | Step 7546 | loss: 0.1799985639980599 | accuracy: 0.9375 \n",
      "Epoch 19 | Step 7547 | loss: 0.17992091276794167 | accuracy: 0.9375 \n",
      "Epoch 19 | Step 7548 | loss: 0.1799907652014981 | accuracy: 0.9375 \n",
      "Epoch 19 | Step 7549 | loss: 0.17984360280936051 | accuracy: 0.9375 \n",
      "Epoch 19 | Step 7550 | loss: 0.17999168340670504 | accuracy: 0.9372888513513513 \n",
      "Epoch 19 | Step 7551 | loss: 0.179913130435177 | accuracy: 0.9373421717171717 \n",
      "Epoch 19 | Step 7552 | loss: 0.17996028441960785 | accuracy: 0.9373427013422819 \n",
      "Epoch 19 | Step 7553 | loss: 0.17974201635921683 | accuracy: 0.9373954849498328 \n",
      "Epoch 19 | Step 7554 | loss: 0.17938505134234828 | accuracy: 0.9375 \n",
      "Epoch 19 | Step 7555 | loss: 0.17951903535529626 | accuracy: 0.9373961794019934 \n",
      "Epoch 19 | Step 7556 | loss: 0.1793689365245846 | accuracy: 0.937448261589404 \n",
      "Epoch 19 | Step 7557 | loss: 0.17921994332679034 | accuracy: 0.9375 \n",
      "Epoch 19 | Step 7558 | loss: 0.17922087289441965 | accuracy: 0.9375 \n",
      "Epoch 19 | Step 7559 | loss: 0.17921939478790175 | accuracy: 0.9374487704918033 \n",
      "Epoch 19 | Step 7560 | loss: 0.17933660556921383 | accuracy: 0.9374489379084967 \n",
      "Epoch 19 | Step 7561 | loss: 0.18015393921771733 | accuracy: 0.9373473127035831 \n",
      "Epoch 19 | Step 7562 | loss: 0.18010647634842566 | accuracy: 0.9374492694805194 \n",
      "Epoch 19 | Step 7563 | loss: 0.17991391884036434 | accuracy: 0.9373988673139159 \n",
      "Epoch 19 | Step 7564 | loss: 0.18015810576898436 | accuracy: 0.9373991935483871 \n",
      "Epoch 19 | Step 7565 | loss: 0.18027280202776289 | accuracy: 0.9373995176848875 \n",
      "Epoch 19 | Step 7566 | loss: 0.18022949849135983 | accuracy: 0.9373998397435898 \n",
      "Epoch 19 | Step 7567 | loss: 0.1800760321033458 | accuracy: 0.9374500798722045 \n",
      "Epoch 19 | Step 7568 | loss: 0.1803062217321935 | accuracy: 0.9374004777070064 \n",
      "Epoch 19 | Step 7569 | loss: 0.18091735848122173 | accuracy: 0.9372519841269841 \n",
      "Epoch 19 | Step 7570 | loss: 0.18087854197461017 | accuracy: 0.9372527689873418 \n",
      "Epoch 19 | Step 7571 | loss: 0.1807483749035217 | accuracy: 0.9372535488958991 \n",
      "Epoch 19 | Step 7572 | loss: 0.18082755934095604 | accuracy: 0.9372051886792453 \n",
      "Epoch 19 | Step 7573 | loss: 0.1808415244342204 | accuracy: 0.9372061128526645 \n",
      "Epoch 19 | Step 7574 | loss: 0.18067365445895117 | accuracy: 0.93720703125 \n",
      "Epoch 19 | Step 7575 | loss: 0.18056597083667725 | accuracy: 0.9372079439252337 \n",
      "Epoch 19 | Step 7576 | loss: 0.1810124293779549 | accuracy: 0.937111801242236 \n",
      "Epoch 19 | Step 7577 | loss: 0.18080566169538362 | accuracy: 0.9371613777089783 \n",
      "Epoch 19 | Step 7578 | loss: 0.1805284625655155 | accuracy: 0.9373070987654321 \n",
      "Epoch 19 | Step 7579 | loss: 0.18081230547565677 | accuracy: 0.9372596153846153 \n",
      "Epoch 19 | Step 7580 | loss: 0.18061308150231103 | accuracy: 0.9374041411042945 \n",
      "Epoch 19 | Step 7581 | loss: 0.18081706984464177 | accuracy: 0.9372610856269113 \n",
      "Epoch 19 | Step 7582 | loss: 0.1807436248764577 | accuracy: 0.9373094512195121 \n",
      "Epoch 19 | Step 7583 | loss: 0.18107611899997322 | accuracy: 0.9370250759878419 \n",
      "Epoch 19 | Step 7584 | loss: 0.18099907075591154 | accuracy: 0.9370738636363637 \n",
      "Epoch 19 | Step 7585 | loss: 0.18092829726208726 | accuracy: 0.9370751510574018 \n",
      "Epoch 19 | Step 7586 | loss: 0.1808507293799375 | accuracy: 0.9371234939759037 \n",
      "Epoch 19 | Step 7587 | loss: 0.18083373677578407 | accuracy: 0.9371715465465466 \n",
      "Epoch 19 | Step 7588 | loss: 0.18100081436603718 | accuracy: 0.9370321856287425 \n",
      "Epoch 19 | Step 7589 | loss: 0.18070058054221202 | accuracy: 0.9371268656716418 \n",
      "Epoch 19 | Step 7590 | loss: 0.18050098489038638 | accuracy: 0.9372209821428571 \n",
      "Epoch 19 | Step 7591 | loss: 0.1804509107520919 | accuracy: 0.937268175074184 \n",
      "Epoch 19 | Step 7592 | loss: 0.1805276143634636 | accuracy: 0.9372226331360947 \n",
      "Epoch 19 | Step 7593 | loss: 0.18036787843765753 | accuracy: 0.9372695427728613 \n",
      "Epoch 19 | Step 7594 | loss: 0.18012185617185683 | accuracy: 0.9373621323529412 \n",
      "Epoch 19 | Step 7595 | loss: 0.1800446094633721 | accuracy: 0.9373625366568915 \n",
      "Epoch 19 | Step 7596 | loss: 0.17989225532009928 | accuracy: 0.9374543128654971 \n",
      "Epoch 19 | Step 7597 | loss: 0.17966408583365437 | accuracy: 0.93754555393586 \n",
      "Epoch 19 | Step 7598 | loss: 0.179451439128972 | accuracy: 0.9375454215116279 \n",
      "Epoch 19 | Step 7599 | loss: 0.17954278893876757 | accuracy: 0.9374547101449275 \n",
      "Epoch 19 | Step 7600 | loss: 0.17956540030508017 | accuracy: 0.9375451589595376 \n",
      "Epoch 19 | Step 7601 | loss: 0.17940120853118652 | accuracy: 0.9375900576368876 \n",
      "Epoch 19 | Step 7602 | loss: 0.17989265699282106 | accuracy: 0.9375 \n",
      "Epoch 19 | Step 7603 | loss: 0.17976974726876066 | accuracy: 0.937544770773639 \n",
      "Epoch 19 | Step 7604 | loss: 0.17968305986906788 | accuracy: 0.9376785714285715 \n",
      "Epoch 19 | Step 7605 | loss: 0.1794692799130565 | accuracy: 0.937767094017094 \n",
      "Epoch 19 | Step 7606 | loss: 0.1797398350688374 | accuracy: 0.9376775568181818 \n",
      "Epoch 19 | Step 7607 | loss: 0.1795036948415273 | accuracy: 0.9378098441926346 \n",
      "Epoch 19 | Step 7608 | loss: 0.17919421599030824 | accuracy: 0.93798552259887 \n",
      "Epoch 19 | Step 7609 | loss: 0.1789403769646731 | accuracy: 0.9381161971830986 \n",
      "Epoch 19 | Step 7610 | loss: 0.17881141744261034 | accuracy: 0.9381144662921348 \n",
      "Epoch 19 | Step 7611 | loss: 0.17889731749892226 | accuracy: 0.9381565126050421 \n",
      "Epoch 19 | Step 7612 | loss: 0.17886648663220783 | accuracy: 0.9381546787709497 \n",
      "Epoch 19 | Step 7613 | loss: 0.1786663666222254 | accuracy: 0.9382399025069638 \n",
      "Epoch 19 | Step 7614 | loss: 0.17845767211789879 | accuracy: 0.93828125 \n",
      "Epoch 19 | Step 7615 | loss: 0.1784543130557127 | accuracy: 0.9382358033240997 \n",
      "Epoch 19 | Step 7616 | loss: 0.1783052810997758 | accuracy: 0.9383200966850829 \n",
      "Epoch 19 | Step 7617 | loss: 0.17815237842274426 | accuracy: 0.9383608815426997 \n",
      "Epoch 19 | Step 7618 | loss: 0.17795657862878428 | accuracy: 0.9384872939560439 \n",
      "Epoch 19 | Step 7619 | loss: 0.1776978999070108 | accuracy: 0.9386130136986301 \n",
      "Epoch 19 | Step 7620 | loss: 0.17769512176880087 | accuracy: 0.9385672814207651 \n",
      "Epoch 19 | Step 7621 | loss: 0.17744126104894378 | accuracy: 0.9386495231607629 \n",
      "Epoch 19 | Step 7622 | loss: 0.1772162345460737 | accuracy: 0.9387737771739131 \n",
      "Epoch 19 | Step 7623 | loss: 0.17742240361283781 | accuracy: 0.9388126693766937 \n",
      "Epoch 19 | Step 7624 | loss: 0.17755243038204868 | accuracy: 0.9386824324324324 \n",
      "Epoch 19 | Step 7625 | loss: 0.17756842583859697 | accuracy: 0.938637129380054 \n",
      "Epoch 19 | Step 7626 | loss: 0.17803935270996818 | accuracy: 0.938466061827957 \n",
      "Epoch 19 | Step 7627 | loss: 0.17799309648113973 | accuracy: 0.938421581769437 \n",
      "Epoch 19 | Step 7628 | loss: 0.17795557442076376 | accuracy: 0.9383773395721925 \n",
      "Epoch 19 | Step 7629 | loss: 0.1778318122327327 | accuracy: 0.9385 \n",
      "Epoch 19 | Step 7630 | loss: 0.17764426673703046 | accuracy: 0.9385804521276596 \n",
      "Epoch 19 | Step 7631 | loss: 0.177523831048837 | accuracy: 0.9385361405835544 \n",
      "Epoch 19 | Step 7632 | loss: 0.17764394577572892 | accuracy: 0.9384920634920635 \n",
      "Epoch 19 | Step 7633 | loss: 0.17742497500494153 | accuracy: 0.9385718997361477 \n",
      "Epoch 19 | Step 7634 | loss: 0.1771937388044438 | accuracy: 0.9386513157894737 \n",
      "Epoch 19 | Step 7635 | loss: 0.17710249017425403 | accuracy: 0.9386482939632546 \n",
      "Epoch 19 | Step 7636 | loss: 0.17690975664680844 | accuracy: 0.9386452879581152 \n",
      "Epoch 19 | Step 7637 | loss: 0.17672187470230352 | accuracy: 0.9387238903394256 \n",
      "Epoch 19 | Step 7638 | loss: 0.17684974566994538 | accuracy: 0.9386393229166666 \n",
      "Epoch 19 | Step 7639 | loss: 0.17712265174690772 | accuracy: 0.9385957792207792 \n",
      "Epoch 19 | Step 7640 | loss: 0.17727459603293255 | accuracy: 0.9385929404145078 \n",
      "Epoch 19 | Step 7641 | loss: 0.17741345580503606 | accuracy: 0.9385497416020672 \n",
      "Epoch 19 | Step 7642 | loss: 0.17716050521499402 | accuracy: 0.9386275773195877 \n",
      "Epoch 19 | Step 7643 | loss: 0.17720354554317597 | accuracy: 0.9386246786632391 \n",
      "Epoch 19 | Step 7644 | loss: 0.1771413813512294 | accuracy: 0.9386618589743589 \n",
      "Epoch 19 | Step 7645 | loss: 0.17730980159719575 | accuracy: 0.9385390025575447 \n",
      "Epoch 19 | Step 7646 | loss: 0.17710807566930134 | accuracy: 0.9386559311224489 \n",
      "Epoch 19 | Step 7647 | loss: 0.17693292212129846 | accuracy: 0.9386927480916031 \n",
      "Epoch 19 | Step 7648 | loss: 0.1768879172330731 | accuracy: 0.9386104060913706 \n",
      "Epoch 19 | Step 7649 | loss: 0.17675675728087176 | accuracy: 0.9386471518987342 \n",
      "Epoch 19 | Step 7650 | loss: 0.17657992161923278 | accuracy: 0.9386442550505051 \n",
      "Epoch 19 | Step 7651 | loss: 0.17658485942320792 | accuracy: 0.9386413727959698 \n",
      "Epoch 19 | Step 7652 | loss: 0.17671094633563972 | accuracy: 0.9385992462311558 \n",
      "Epoch 19 | Step 7653 | loss: 0.17657236813714622 | accuracy: 0.9386748120300752 \n",
      "Epoch 19 | Step 7654 | loss: 0.17673939771018915 | accuracy: 0.93859375 \n",
      "Epoch 19 | Step 7655 | loss: 0.17666342708646798 | accuracy: 0.9386689526184538 \n",
      "Epoch 19 | Step 7656 | loss: 0.17691545450679988 | accuracy: 0.9385494402985075 \n",
      "Epoch 19 | Step 7657 | loss: 0.17655987711276658 | accuracy: 0.9387019230769231 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.6261739134788513 | accuracy: 0.828125 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.6550653874874115 | accuracy: 0.796875 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5882885555426279 | accuracy: 0.8020833333333334 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5560774803161621 | accuracy: 0.80859375 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.56495281457901 | accuracy: 0.803125 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5560713410377502 | accuracy: 0.8072916666666666 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5395717663424355 | accuracy: 0.8147321428571429 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5272817015647888 | accuracy: 0.818359375 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5251149071587456 | accuracy: 0.8211805555555556 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5221171081066132 | accuracy: 0.821875 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5258003690026023 | accuracy: 0.8210227272727273 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5175482382376989 | accuracy: 0.8255208333333334 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.528001606464386 | accuracy: 0.8185096153846154 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5352674552372524 | accuracy: 0.8180803571428571 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5210928161938985 | accuracy: 0.8208333333333333 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5221239738166332 | accuracy: 0.8212890625 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5354523132829105 | accuracy: 0.8170955882352942 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5297482295168771 | accuracy: 0.8185763888888888 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5254375087587457 | accuracy: 0.8174342105263158 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5207255646586418 | accuracy: 0.8203125 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5190161523364839 | accuracy: 0.8221726190476191 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5117483978921716 | accuracy: 0.8231534090909091 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5135130027066106 | accuracy: 0.8220108695652174 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5110315233469009 | accuracy: 0.8229166666666666 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5160212230682373 | accuracy: 0.821875 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5068428138127694 | accuracy: 0.8251201923076923 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5071499226269899 | accuracy: 0.8252314814814815 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5002719536423683 | accuracy: 0.8275669642857143 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5042657862449514 | accuracy: 0.8270474137931034 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5072985380887985 | accuracy: 0.8260416666666667 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5005773132847201 | accuracy: 0.829133064516129 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.49494881648570294 | accuracy: 0.83154296875 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.4921543038252628 | accuracy: 0.8333333333333334 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5034376803566428 | accuracy: 0.8304227941176471 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5022335520812443 | accuracy: 0.8290178571428571 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.49483612759245765 | accuracy: 0.8311631944444444 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.49583294504397624 | accuracy: 0.831081081081081 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.4944343206129576 | accuracy: 0.8301809210526315 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.49208168647228145 | accuracy: 0.8321314102564102 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.49701094180345534 | accuracy: 0.830078125 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5013567296470084 | accuracy: 0.8285060975609756 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.49889729491301943 | accuracy: 0.8296130952380952 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.4973083069158155 | accuracy: 0.829578488372093 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5017050911079753 | accuracy: 0.8288352272727273 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5054310705926683 | accuracy: 0.8278079708417256 \n",
      "Epoch 20 | Step 7658 | loss: 0.10025200992822647 | accuracy: 0.96875 \n",
      "Epoch 20 | Step 7659 | loss: 0.19627583399415016 | accuracy: 0.9453125 \n",
      "Epoch 20 | Step 7660 | loss: 0.16770080228646597 | accuracy: 0.9427083333333334 \n",
      "Epoch 20 | Step 7661 | loss: 0.17679797857999802 | accuracy: 0.9375 \n",
      "Epoch 20 | Step 7662 | loss: 0.16326142996549606 | accuracy: 0.940625 \n",
      "Epoch 20 | Step 7663 | loss: 0.1814606674015522 | accuracy: 0.9296875 \n",
      "Epoch 20 | Step 7664 | loss: 0.18723623986755097 | accuracy: 0.9308035714285714 \n",
      "Epoch 20 | Step 7665 | loss: 0.2030502324923873 | accuracy: 0.927734375 \n",
      "Epoch 20 | Step 7666 | loss: 0.20088563942246968 | accuracy: 0.9288194444444444 \n",
      "Epoch 20 | Step 7667 | loss: 0.2023664616048336 | accuracy: 0.925 \n",
      "Epoch 20 | Step 7668 | loss: 0.20273296196352353 | accuracy: 0.9232954545454546 \n",
      "Epoch 20 | Step 7669 | loss: 0.20284722559154034 | accuracy: 0.92578125 \n",
      "Epoch 20 | Step 7670 | loss: 0.1978025545294468 | accuracy: 0.9302884615384616 \n",
      "Epoch 20 | Step 7671 | loss: 0.19986932671495847 | accuracy: 0.9285714285714286 \n",
      "Epoch 20 | Step 7672 | loss: 0.19592026521762212 | accuracy: 0.9322916666666666 \n",
      "Epoch 20 | Step 7673 | loss: 0.18750953115522861 | accuracy: 0.935546875 \n",
      "Epoch 20 | Step 7674 | loss: 0.18194004148244858 | accuracy: 0.9384191176470589 \n",
      "Epoch 20 | Step 7675 | loss: 0.1798157836827967 | accuracy: 0.9401041666666666 \n",
      "Epoch 20 | Step 7676 | loss: 0.17868558395850032 | accuracy: 0.9407894736842105 \n",
      "Epoch 20 | Step 7677 | loss: 0.18369345553219318 | accuracy: 0.93984375 \n",
      "Epoch 20 | Step 7678 | loss: 0.18317596507923944 | accuracy: 0.9397321428571429 \n",
      "Epoch 20 | Step 7679 | loss: 0.18320615488019856 | accuracy: 0.9403409090909091 \n",
      "Epoch 20 | Step 7680 | loss: 0.1822780062970908 | accuracy: 0.9395380434782609 \n",
      "Epoch 20 | Step 7681 | loss: 0.17725772488241395 | accuracy: 0.9420572916666666 \n",
      "Epoch 20 | Step 7682 | loss: 0.17432288095355034 | accuracy: 0.9425 \n",
      "Epoch 20 | Step 7683 | loss: 0.17442603681523067 | accuracy: 0.9417067307692307 \n",
      "Epoch 20 | Step 7684 | loss: 0.17386622547551436 | accuracy: 0.9421296296296297 \n",
      "Epoch 20 | Step 7685 | loss: 0.16975381637790374 | accuracy: 0.9436383928571429 \n",
      "Epoch 20 | Step 7686 | loss: 0.16775286750032983 | accuracy: 0.9439655172413793 \n",
      "Epoch 20 | Step 7687 | loss: 0.1694622450818618 | accuracy: 0.9427083333333334 \n",
      "Epoch 20 | Step 7688 | loss: 0.1702484309432968 | accuracy: 0.9435483870967742 \n",
      "Epoch 20 | Step 7689 | loss: 0.170190658303909 | accuracy: 0.943359375 \n",
      "Epoch 20 | Step 7690 | loss: 0.17192643237384883 | accuracy: 0.9431818181818182 \n",
      "Epoch 20 | Step 7691 | loss: 0.17225071820704377 | accuracy: 0.9420955882352942 \n",
      "Epoch 20 | Step 7692 | loss: 0.1708548974777971 | accuracy: 0.9424107142857143 \n",
      "Epoch 20 | Step 7693 | loss: 0.17214529205941495 | accuracy: 0.9418402777777778 \n",
      "Epoch 20 | Step 7694 | loss: 0.16951807779637545 | accuracy: 0.9434121621621622 \n",
      "Epoch 20 | Step 7695 | loss: 0.16923063179772155 | accuracy: 0.944078947368421 \n",
      "Epoch 20 | Step 7696 | loss: 0.16794110385653305 | accuracy: 0.9443108974358975 \n",
      "Epoch 20 | Step 7697 | loss: 0.16803141692653303 | accuracy: 0.94375 \n",
      "Epoch 20 | Step 7698 | loss: 0.16745735932050687 | accuracy: 0.9439786585365854 \n",
      "Epoch 20 | Step 7699 | loss: 0.16736510511310332 | accuracy: 0.9445684523809523 \n",
      "Epoch 20 | Step 7700 | loss: 0.16579388056037042 | accuracy: 0.9451308139534884 \n",
      "Epoch 20 | Step 7701 | loss: 0.16412831546569417 | accuracy: 0.9456676136363636 \n",
      "Epoch 20 | Step 7702 | loss: 0.16455158632662564 | accuracy: 0.9451388888888889 \n",
      "Epoch 20 | Step 7703 | loss: 0.16484708930163283 | accuracy: 0.9453125 \n",
      "Epoch 20 | Step 7704 | loss: 0.1639214287254405 | accuracy: 0.945811170212766 \n",
      "Epoch 20 | Step 7705 | loss: 0.16492106323130432 | accuracy: 0.9453125 \n",
      "Epoch 20 | Step 7706 | loss: 0.1631507891021213 | accuracy: 0.9461096938775511 \n",
      "Epoch 20 | Step 7707 | loss: 0.16388589434325695 | accuracy: 0.9459375 \n",
      "Epoch 20 | Step 7708 | loss: 0.16769659687198846 | accuracy: 0.944546568627451 \n",
      "Epoch 20 | Step 7709 | loss: 0.1696631873313051 | accuracy: 0.9441105769230769 \n",
      "Epoch 20 | Step 7710 | loss: 0.16914643677619268 | accuracy: 0.9442806603773585 \n",
      "Epoch 20 | Step 7711 | loss: 0.16853145723817525 | accuracy: 0.9444444444444444 \n",
      "Epoch 20 | Step 7712 | loss: 0.16912637427449226 | accuracy: 0.944034090909091 \n",
      "Epoch 20 | Step 7713 | loss: 0.17183356432776367 | accuracy: 0.943359375 \n",
      "Epoch 20 | Step 7714 | loss: 0.17149140509335617 | accuracy: 0.9432565789473685 \n",
      "Epoch 20 | Step 7715 | loss: 0.17217597872789564 | accuracy: 0.943426724137931 \n",
      "Epoch 20 | Step 7716 | loss: 0.17330327825778621 | accuracy: 0.9430614406779662 \n",
      "Epoch 20 | Step 7717 | loss: 0.17452022824436425 | accuracy: 0.9424479166666667 \n",
      "Epoch 20 | Step 7718 | loss: 0.17350565831436485 | accuracy: 0.9428790983606558 \n",
      "Epoch 20 | Step 7719 | loss: 0.17310459437149187 | accuracy: 0.9430443548387096 \n",
      "Epoch 20 | Step 7720 | loss: 0.17298925212687916 | accuracy: 0.9429563492063492 \n",
      "Epoch 20 | Step 7721 | loss: 0.1720762440818362 | accuracy: 0.943603515625 \n",
      "Epoch 20 | Step 7722 | loss: 0.1728829722564954 | accuracy: 0.9430288461538462 \n",
      "Epoch 20 | Step 7723 | loss: 0.17149568309612345 | accuracy: 0.9431818181818182 \n",
      "Epoch 20 | Step 7724 | loss: 0.1702422735962405 | accuracy: 0.9435634328358209 \n",
      "Epoch 20 | Step 7725 | loss: 0.16971406236510067 | accuracy: 0.9437040441176471 \n",
      "Epoch 20 | Step 7726 | loss: 0.17097001474188722 | accuracy: 0.9436141304347826 \n",
      "Epoch 20 | Step 7727 | loss: 0.17179206870496272 | accuracy: 0.9430803571428571 \n",
      "Epoch 20 | Step 7728 | loss: 0.17303746146425394 | accuracy: 0.9425616197183099 \n",
      "Epoch 20 | Step 7729 | loss: 0.171892658341676 | accuracy: 0.9429253472222222 \n",
      "Epoch 20 | Step 7730 | loss: 0.172362544203866 | accuracy: 0.9430650684931506 \n",
      "Epoch 20 | Step 7731 | loss: 0.17247687083845203 | accuracy: 0.9429898648648649 \n",
      "Epoch 20 | Step 7732 | loss: 0.17306243682901065 | accuracy: 0.9427083333333334 \n",
      "Epoch 20 | Step 7733 | loss: 0.17172148671785467 | accuracy: 0.9432565789473685 \n",
      "Epoch 20 | Step 7734 | loss: 0.17382144855407924 | accuracy: 0.9423701298701299 \n",
      "Epoch 20 | Step 7735 | loss: 0.1733463785300652 | accuracy: 0.9425080128205128 \n",
      "Epoch 20 | Step 7736 | loss: 0.17239191218078892 | accuracy: 0.9428401898734177 \n",
      "Epoch 20 | Step 7737 | loss: 0.17255970663391054 | accuracy: 0.942578125 \n",
      "Epoch 20 | Step 7738 | loss: 0.17326722758603685 | accuracy: 0.9423225308641975 \n",
      "Epoch 20 | Step 7739 | loss: 0.17240331817145754 | accuracy: 0.9426448170731707 \n",
      "Epoch 20 | Step 7740 | loss: 0.17307613112301712 | accuracy: 0.942394578313253 \n",
      "Epoch 20 | Step 7741 | loss: 0.17336921930490506 | accuracy: 0.9421502976190477 \n",
      "Epoch 20 | Step 7742 | loss: 0.17353250721798225 | accuracy: 0.9420955882352942 \n",
      "Epoch 20 | Step 7743 | loss: 0.1724291134972212 | accuracy: 0.9425872093023255 \n",
      "Epoch 20 | Step 7744 | loss: 0.17245440711749013 | accuracy: 0.9427083333333334 \n",
      "Epoch 20 | Step 7745 | loss: 0.1727461255663498 | accuracy: 0.9424715909090909 \n",
      "Epoch 20 | Step 7746 | loss: 0.1723754368722439 | accuracy: 0.9424157303370787 \n",
      "Epoch 20 | Step 7747 | loss: 0.17331876154575085 | accuracy: 0.9420138888888889 \n",
      "Epoch 20 | Step 7748 | loss: 0.17342197481583765 | accuracy: 0.9417925824175825 \n",
      "Epoch 20 | Step 7749 | loss: 0.17538881411209054 | accuracy: 0.9412364130434783 \n",
      "Epoch 20 | Step 7750 | loss: 0.17798756123069795 | accuracy: 0.9403561827956989 \n",
      "Epoch 20 | Step 7751 | loss: 0.17709771294067514 | accuracy: 0.9408244680851063 \n",
      "Epoch 20 | Step 7752 | loss: 0.17603101593099144 | accuracy: 0.9412828947368421 \n",
      "Epoch 20 | Step 7753 | loss: 0.17558049181631455 | accuracy: 0.94140625 \n",
      "Epoch 20 | Step 7754 | loss: 0.17545024808688262 | accuracy: 0.9412048969072165 \n",
      "Epoch 20 | Step 7755 | loss: 0.17717297242156096 | accuracy: 0.9403698979591837 \n",
      "Epoch 20 | Step 7756 | loss: 0.17643013382048317 | accuracy: 0.9408143939393939 \n",
      "Epoch 20 | Step 7757 | loss: 0.1768094202503562 | accuracy: 0.94078125 \n",
      "Epoch 20 | Step 7758 | loss: 0.1771355262118401 | accuracy: 0.9407487623762376 \n",
      "Epoch 20 | Step 7759 | loss: 0.17751755269573016 | accuracy: 0.9408700980392157 \n",
      "Epoch 20 | Step 7760 | loss: 0.1771848554388412 | accuracy: 0.9409890776699029 \n",
      "Epoch 20 | Step 7761 | loss: 0.1775676951600382 | accuracy: 0.9409555288461539 \n",
      "Epoch 20 | Step 7762 | loss: 0.17824609233509928 | accuracy: 0.940625 \n",
      "Epoch 20 | Step 7763 | loss: 0.17759105531533934 | accuracy: 0.9408903301886793 \n",
      "Epoch 20 | Step 7764 | loss: 0.1780102316673114 | accuracy: 0.9405665887850467 \n",
      "Epoch 20 | Step 7765 | loss: 0.1785699942804597 | accuracy: 0.9402488425925926 \n",
      "Epoch 20 | Step 7766 | loss: 0.17775195245759204 | accuracy: 0.9405103211009175 \n",
      "Epoch 20 | Step 7767 | loss: 0.1773866337470033 | accuracy: 0.9404829545454545 \n",
      "Epoch 20 | Step 7768 | loss: 0.1782459233728078 | accuracy: 0.9400337837837838 \n",
      "Epoch 20 | Step 7769 | loss: 0.17882818459267064 | accuracy: 0.9397321428571429 \n",
      "Epoch 20 | Step 7770 | loss: 0.1786385485490339 | accuracy: 0.9398506637168141 \n",
      "Epoch 20 | Step 7771 | loss: 0.17838399370380661 | accuracy: 0.9399671052631579 \n",
      "Epoch 20 | Step 7772 | loss: 0.17757796564179917 | accuracy: 0.9402173913043478 \n",
      "Epoch 20 | Step 7773 | loss: 0.17733236476136693 | accuracy: 0.9403286637931034 \n",
      "Epoch 20 | Step 7774 | loss: 0.17661246488619053 | accuracy: 0.9407051282051282 \n",
      "Epoch 20 | Step 7775 | loss: 0.17649134725205978 | accuracy: 0.9409427966101694 \n",
      "Epoch 20 | Step 7776 | loss: 0.17651006188087104 | accuracy: 0.9409138655462185 \n",
      "Epoch 20 | Step 7777 | loss: 0.17646599880730113 | accuracy: 0.9407552083333334 \n",
      "Epoch 20 | Step 7778 | loss: 0.1758155610627872 | accuracy: 0.9411157024793388 \n",
      "Epoch 20 | Step 7779 | loss: 0.1762875420820029 | accuracy: 0.9408299180327869 \n",
      "Epoch 20 | Step 7780 | loss: 0.17592085894893825 | accuracy: 0.9408028455284553 \n",
      "Epoch 20 | Step 7781 | loss: 0.176792026377253 | accuracy: 0.9406502016129032 \n",
      "Epoch 20 | Step 7782 | loss: 0.17719574269652366 | accuracy: 0.94025 \n",
      "Epoch 20 | Step 7783 | loss: 0.17655661338496775 | accuracy: 0.9404761904761905 \n",
      "Epoch 20 | Step 7784 | loss: 0.17655034377936304 | accuracy: 0.9404527559055118 \n",
      "Epoch 20 | Step 7785 | loss: 0.17630163245485164 | accuracy: 0.9404296875 \n",
      "Epoch 20 | Step 7786 | loss: 0.17578348410568495 | accuracy: 0.9406492248062015 \n",
      "Epoch 20 | Step 7787 | loss: 0.17625971617033848 | accuracy: 0.9405048076923077 \n",
      "Epoch 20 | Step 7788 | loss: 0.17681341860016794 | accuracy: 0.9403625954198473 \n",
      "Epoch 20 | Step 7789 | loss: 0.17656586395407264 | accuracy: 0.9405776515151515 \n",
      "Epoch 20 | Step 7790 | loss: 0.17613277161367855 | accuracy: 0.9407894736842105 \n",
      "Epoch 20 | Step 7791 | loss: 0.1754583622704246 | accuracy: 0.9409981343283582 \n",
      "Epoch 20 | Step 7792 | loss: 0.175649870738939 | accuracy: 0.9408564814814815 \n",
      "Epoch 20 | Step 7793 | loss: 0.17642638062619986 | accuracy: 0.9407169117647058 \n",
      "Epoch 20 | Step 7794 | loss: 0.1767737677008131 | accuracy: 0.9405793795620438 \n",
      "Epoch 20 | Step 7795 | loss: 0.1768612013724835 | accuracy: 0.9405570652173914 \n",
      "Epoch 20 | Step 7796 | loss: 0.17762788151987166 | accuracy: 0.9401978417266187 \n",
      "Epoch 20 | Step 7797 | loss: 0.17711996454745532 | accuracy: 0.9402901785714286 \n",
      "Epoch 20 | Step 7798 | loss: 0.17694458098593333 | accuracy: 0.9403812056737588 \n",
      "Epoch 20 | Step 7799 | loss: 0.17659545865591983 | accuracy: 0.9404709507042254 \n",
      "Epoch 20 | Step 7800 | loss: 0.17598944451738072 | accuracy: 0.940777972027972 \n",
      "Epoch 20 | Step 7801 | loss: 0.17571755113183624 | accuracy: 0.9408637152777778 \n",
      "Epoch 20 | Step 7802 | loss: 0.1754847088507537 | accuracy: 0.9407327586206896 \n",
      "Epoch 20 | Step 7803 | loss: 0.17584196843002756 | accuracy: 0.9408176369863014 \n",
      "Epoch 20 | Step 7804 | loss: 0.17585679024559298 | accuracy: 0.9409013605442177 \n",
      "Epoch 20 | Step 7805 | loss: 0.17598482641718674 | accuracy: 0.9407728040540541 \n",
      "Epoch 20 | Step 7806 | loss: 0.17591586216484137 | accuracy: 0.9406459731543624 \n",
      "Epoch 20 | Step 7807 | loss: 0.17515010741849737 | accuracy: 0.9409375 \n",
      "Epoch 20 | Step 7808 | loss: 0.17564182711259416 | accuracy: 0.9408112582781457 \n",
      "Epoch 20 | Step 7809 | loss: 0.1756805421441401 | accuracy: 0.9407894736842105 \n",
      "Epoch 20 | Step 7810 | loss: 0.17648958797061362 | accuracy: 0.9406658496732027 \n",
      "Epoch 20 | Step 7811 | loss: 0.1758523079530372 | accuracy: 0.9408482142857143 \n",
      "Epoch 20 | Step 7812 | loss: 0.17521942726546713 | accuracy: 0.9410282258064516 \n",
      "Epoch 20 | Step 7813 | loss: 0.17427520582882253 | accuracy: 0.94140625 \n",
      "Epoch 20 | Step 7814 | loss: 0.17432908357898136 | accuracy: 0.9411823248407644 \n",
      "Epoch 20 | Step 7815 | loss: 0.17410878615477413 | accuracy: 0.9412579113924051 \n",
      "Epoch 20 | Step 7816 | loss: 0.17428794676590262 | accuracy: 0.9412342767295597 \n",
      "Epoch 20 | Step 7817 | loss: 0.1742088584695011 | accuracy: 0.94111328125 \n",
      "Epoch 20 | Step 7818 | loss: 0.1737961537256744 | accuracy: 0.9412849378881988 \n",
      "Epoch 20 | Step 7819 | loss: 0.17373221730928357 | accuracy: 0.941358024691358 \n",
      "Epoch 20 | Step 7820 | loss: 0.1730380234954181 | accuracy: 0.9416219325153374 \n",
      "Epoch 20 | Step 7821 | loss: 0.17270276702304435 | accuracy: 0.9415967987804879 \n",
      "Epoch 20 | Step 7822 | loss: 0.17265704461570938 | accuracy: 0.9414772727272728 \n",
      "Epoch 20 | Step 7823 | loss: 0.17355447044842928 | accuracy: 0.9411709337349398 \n",
      "Epoch 20 | Step 7824 | loss: 0.17293010475838966 | accuracy: 0.9413360778443114 \n",
      "Epoch 20 | Step 7825 | loss: 0.17264379390204942 | accuracy: 0.9413132440476191 \n",
      "Epoch 20 | Step 7826 | loss: 0.17397290016331612 | accuracy: 0.9410133136094675 \n",
      "Epoch 20 | Step 7827 | loss: 0.17400465456440165 | accuracy: 0.9410845588235294 \n",
      "Epoch 20 | Step 7828 | loss: 0.1743803572192875 | accuracy: 0.9410635964912281 \n",
      "Epoch 20 | Step 7829 | loss: 0.17473784320836147 | accuracy: 0.9408611918604651 \n",
      "Epoch 20 | Step 7830 | loss: 0.17392874941918887 | accuracy: 0.9412030346820809 \n",
      "Epoch 20 | Step 7831 | loss: 0.17401352822352412 | accuracy: 0.9411817528735632 \n",
      "Epoch 20 | Step 7832 | loss: 0.1737144521091665 | accuracy: 0.9414285714285714 \n",
      "Epoch 20 | Step 7833 | loss: 0.1734857928134839 | accuracy: 0.9415838068181818 \n",
      "Epoch 20 | Step 7834 | loss: 0.1736088658414654 | accuracy: 0.9414724576271186 \n",
      "Epoch 20 | Step 7835 | loss: 0.17344220775817878 | accuracy: 0.9415379213483146 \n",
      "Epoch 20 | Step 7836 | loss: 0.1737658257216381 | accuracy: 0.9413407821229051 \n",
      "Epoch 20 | Step 7837 | loss: 0.17366214243488173 | accuracy: 0.9414930555555555 \n",
      "Epoch 20 | Step 7838 | loss: 0.17328465176303737 | accuracy: 0.9416436464088398 \n",
      "Epoch 20 | Step 7839 | loss: 0.1726446042840297 | accuracy: 0.9419642857142857 \n",
      "Epoch 20 | Step 7840 | loss: 0.1724985506528062 | accuracy: 0.9420252732240437 \n",
      "Epoch 20 | Step 7841 | loss: 0.17261252009674258 | accuracy: 0.9420855978260869 \n",
      "Epoch 20 | Step 7842 | loss: 0.17263648211956023 | accuracy: 0.9421452702702703 \n",
      "Epoch 20 | Step 7843 | loss: 0.17260882282449352 | accuracy: 0.9421202956989247 \n",
      "Epoch 20 | Step 7844 | loss: 0.17280118334739603 | accuracy: 0.9420955882352942 \n",
      "Epoch 20 | Step 7845 | loss: 0.17307098907359103 | accuracy: 0.942154255319149 \n",
      "Epoch 20 | Step 7846 | loss: 0.17257192265735102 | accuracy: 0.9422949735449735 \n",
      "Epoch 20 | Step 7847 | loss: 0.1726049758886036 | accuracy: 0.9422697368421052 \n",
      "Epoch 20 | Step 7848 | loss: 0.1727484175984148 | accuracy: 0.9422447643979057 \n",
      "Epoch 20 | Step 7849 | loss: 0.17300094035454094 | accuracy: 0.9422200520833334 \n",
      "Epoch 20 | Step 7850 | loss: 0.1733469831819979 | accuracy: 0.9421955958549223 \n",
      "Epoch 20 | Step 7851 | loss: 0.1729269871469011 | accuracy: 0.9424130154639175 \n",
      "Epoch 20 | Step 7852 | loss: 0.17325242792184536 | accuracy: 0.9422275641025641 \n",
      "Epoch 20 | Step 7853 | loss: 0.1736553141429108 | accuracy: 0.9420440051020408 \n",
      "Epoch 20 | Step 7854 | loss: 0.1738186414698659 | accuracy: 0.9419416243654822 \n",
      "Epoch 20 | Step 7855 | loss: 0.17393218872673583 | accuracy: 0.9418402777777778 \n",
      "Epoch 20 | Step 7856 | loss: 0.17428171982867036 | accuracy: 0.9417399497487438 \n",
      "Epoch 20 | Step 7857 | loss: 0.17420112151652575 | accuracy: 0.94171875 \n",
      "Epoch 20 | Step 7858 | loss: 0.17458219081163406 | accuracy: 0.9415422885572139 \n",
      "Epoch 20 | Step 7859 | loss: 0.1747019050071145 | accuracy: 0.9414449257425742 \n",
      "Epoch 20 | Step 7860 | loss: 0.17442424287056102 | accuracy: 0.9415024630541872 \n",
      "Epoch 20 | Step 7861 | loss: 0.1742763179628288 | accuracy: 0.9414828431372549 \n",
      "Epoch 20 | Step 7862 | loss: 0.17432084454268945 | accuracy: 0.9413109756097561 \n",
      "Epoch 20 | Step 7863 | loss: 0.17432318794206508 | accuracy: 0.9412924757281553 \n",
      "Epoch 20 | Step 7864 | loss: 0.17408927216909933 | accuracy: 0.9413496376811594 \n",
      "Epoch 20 | Step 7865 | loss: 0.1737523479745365 | accuracy: 0.9413311298076923 \n",
      "Epoch 20 | Step 7866 | loss: 0.17368986550272936 | accuracy: 0.9413875598086124 \n",
      "Epoch 20 | Step 7867 | loss: 0.17320802424635207 | accuracy: 0.9415922619047619 \n",
      "Epoch 20 | Step 7868 | loss: 0.17292293369487563 | accuracy: 0.9417950236966824 \n",
      "Epoch 20 | Step 7869 | loss: 0.17335785939446036 | accuracy: 0.9417010613207547 \n",
      "Epoch 20 | Step 7870 | loss: 0.17279331142983526 | accuracy: 0.941974765258216 \n",
      "Epoch 20 | Step 7871 | loss: 0.1727104604279048 | accuracy: 0.9420998831775701 \n",
      "Epoch 20 | Step 7872 | loss: 0.17297321372600488 | accuracy: 0.9420784883720931 \n",
      "Epoch 20 | Step 7873 | loss: 0.17342269042920735 | accuracy: 0.9419849537037037 \n",
      "Epoch 20 | Step 7874 | loss: 0.17371936810250108 | accuracy: 0.9419642857142857 \n",
      "Epoch 20 | Step 7875 | loss: 0.17340271432943846 | accuracy: 0.9420871559633027 \n",
      "Epoch 20 | Step 7876 | loss: 0.17313880393426168 | accuracy: 0.9420662100456622 \n",
      "Epoch 20 | Step 7877 | loss: 0.17313271346078676 | accuracy: 0.9419744318181819 \n",
      "Epoch 20 | Step 7878 | loss: 0.17279196488439227 | accuracy: 0.942024886877828 \n",
      "Epoch 20 | Step 7879 | loss: 0.1724722725548991 | accuracy: 0.9422156531531531 \n",
      "Epoch 20 | Step 7880 | loss: 0.1724273539545023 | accuracy: 0.9423346412556054 \n",
      "Epoch 20 | Step 7881 | loss: 0.1723304940221299 | accuracy: 0.9423828125 \n",
      "Epoch 20 | Step 7882 | loss: 0.17263671283920606 | accuracy: 0.9422222222222222 \n",
      "Epoch 20 | Step 7883 | loss: 0.172648865943857 | accuracy: 0.9422013274336283 \n",
      "Epoch 20 | Step 7884 | loss: 0.17261857790503207 | accuracy: 0.9422494493392071 \n",
      "Epoch 20 | Step 7885 | loss: 0.17267918434778326 | accuracy: 0.9422286184210527 \n",
      "Epoch 20 | Step 7886 | loss: 0.17255551369624889 | accuracy: 0.9422762008733624 \n",
      "Epoch 20 | Step 7887 | loss: 0.1725124670597522 | accuracy: 0.9423233695652173 \n",
      "Epoch 20 | Step 7888 | loss: 0.172532734658682 | accuracy: 0.9421672077922078 \n",
      "Epoch 20 | Step 7889 | loss: 0.17234308373761073 | accuracy: 0.9420797413793104 \n",
      "Epoch 20 | Step 7890 | loss: 0.17211557855997475 | accuracy: 0.9421271459227468 \n",
      "Epoch 20 | Step 7891 | loss: 0.1722544056132563 | accuracy: 0.9421073717948718 \n",
      "Epoch 20 | Step 7892 | loss: 0.17222508206329448 | accuracy: 0.942220744680851 \n",
      "Epoch 20 | Step 7893 | loss: 0.17238701224895353 | accuracy: 0.9422007415254238 \n",
      "Epoch 20 | Step 7894 | loss: 0.17259663439312564 | accuracy: 0.9421809071729957 \n",
      "Epoch 20 | Step 7895 | loss: 0.17283242003319144 | accuracy: 0.9419642857142857 \n",
      "Epoch 20 | Step 7896 | loss: 0.1724745333038863 | accuracy: 0.9420109832635983 \n",
      "Epoch 20 | Step 7897 | loss: 0.17210420694512626 | accuracy: 0.9421223958333333 \n",
      "Epoch 20 | Step 7898 | loss: 0.17220518600458426 | accuracy: 0.9420383817427386 \n",
      "Epoch 20 | Step 7899 | loss: 0.17218712700361555 | accuracy: 0.9419550619834711 \n",
      "Epoch 20 | Step 7900 | loss: 0.17205449762474362 | accuracy: 0.9421296296296297 \n",
      "Epoch 20 | Step 7901 | loss: 0.17149103568775242 | accuracy: 0.9423668032786885 \n",
      "Epoch 20 | Step 7902 | loss: 0.1710653428064317 | accuracy: 0.9425382653061225 \n",
      "Epoch 20 | Step 7903 | loss: 0.1710892352540561 | accuracy: 0.9425813008130082 \n",
      "Epoch 20 | Step 7904 | loss: 0.17071333679894687 | accuracy: 0.9427505060728745 \n",
      "Epoch 20 | Step 7905 | loss: 0.1708717590288049 | accuracy: 0.9426033266129032 \n",
      "Epoch 20 | Step 7906 | loss: 0.1709206705262144 | accuracy: 0.9426455823293173 \n",
      "Epoch 20 | Step 7907 | loss: 0.17080010177195074 | accuracy: 0.9426875 \n",
      "Epoch 20 | Step 7908 | loss: 0.17075519211798076 | accuracy: 0.9426045816733067 \n",
      "Epoch 20 | Step 7909 | loss: 0.1707413270034724 | accuracy: 0.9425223214285714 \n",
      "Epoch 20 | Step 7910 | loss: 0.17050293165998967 | accuracy: 0.9425642292490118 \n",
      "Epoch 20 | Step 7911 | loss: 0.17031655658593797 | accuracy: 0.9425442913385826 \n",
      "Epoch 20 | Step 7912 | loss: 0.1699580914395697 | accuracy: 0.9426470588235294 \n",
      "Epoch 20 | Step 7913 | loss: 0.1699976970703574 | accuracy: 0.942626953125 \n",
      "Epoch 20 | Step 7914 | loss: 0.16991404378750444 | accuracy: 0.9426070038910506 \n",
      "Epoch 20 | Step 7915 | loss: 0.17005521383916222 | accuracy: 0.9424660852713178 \n",
      "Epoch 20 | Step 7916 | loss: 0.1696839595652225 | accuracy: 0.9425072393822393 \n",
      "Epoch 20 | Step 7917 | loss: 0.16949599472662577 | accuracy: 0.942548076923077 \n",
      "Epoch 20 | Step 7918 | loss: 0.1692542254610765 | accuracy: 0.9426484674329502 \n",
      "Epoch 20 | Step 7919 | loss: 0.1695645044465329 | accuracy: 0.9424499045801527 \n",
      "Epoch 20 | Step 7920 | loss: 0.16963226681029842 | accuracy: 0.9424310836501901 \n",
      "Epoch 20 | Step 7921 | loss: 0.1695554994300685 | accuracy: 0.9424715909090909 \n",
      "Epoch 20 | Step 7922 | loss: 0.16953064120321903 | accuracy: 0.9424528301886792 \n",
      "Epoch 20 | Step 7923 | loss: 0.16938721664473974 | accuracy: 0.9424929511278195 \n",
      "Epoch 20 | Step 7924 | loss: 0.16908329642946354 | accuracy: 0.9425912921348315 \n",
      "Epoch 20 | Step 7925 | loss: 0.16934961632394524 | accuracy: 0.9424556902985075 \n",
      "Epoch 20 | Step 7926 | loss: 0.1693854720425207 | accuracy: 0.9423791821561338 \n",
      "Epoch 20 | Step 7927 | loss: 0.16963795629088527 | accuracy: 0.9422453703703704 \n",
      "Epoch 20 | Step 7928 | loss: 0.16955652224016807 | accuracy: 0.942285516605166 \n",
      "Epoch 20 | Step 7929 | loss: 0.1694907128728707 | accuracy: 0.9423828125 \n",
      "Epoch 20 | Step 7930 | loss: 0.16954018875629037 | accuracy: 0.9423649267399268 \n",
      "Epoch 20 | Step 7931 | loss: 0.16986937011952383 | accuracy: 0.9423471715328468 \n",
      "Epoch 20 | Step 7932 | loss: 0.16971050263805823 | accuracy: 0.9423863636363636 \n",
      "Epoch 20 | Step 7933 | loss: 0.16977387425098298 | accuracy: 0.9423686594202898 \n",
      "Epoch 20 | Step 7934 | loss: 0.16956543184090608 | accuracy: 0.9424638989169675 \n",
      "Epoch 20 | Step 7935 | loss: 0.1694820504903579 | accuracy: 0.94255845323741 \n",
      "Epoch 20 | Step 7936 | loss: 0.16932026599951114 | accuracy: 0.9425963261648745 \n",
      "Epoch 20 | Step 7937 | loss: 0.16933325583647402 | accuracy: 0.9425223214285714 \n",
      "Epoch 20 | Step 7938 | loss: 0.16920833094741525 | accuracy: 0.9426156583629893 \n",
      "Epoch 20 | Step 7939 | loss: 0.16885922002401332 | accuracy: 0.9427083333333334 \n",
      "Epoch 20 | Step 7940 | loss: 0.16869371743747705 | accuracy: 0.9427451413427562 \n",
      "Epoch 20 | Step 7941 | loss: 0.16843046710996978 | accuracy: 0.9428367077464789 \n",
      "Epoch 20 | Step 7942 | loss: 0.16830402812675424 | accuracy: 0.9428179824561403 \n",
      "Epoch 20 | Step 7943 | loss: 0.16786914158586436 | accuracy: 0.9430179195804196 \n",
      "Epoch 20 | Step 7944 | loss: 0.16781835181424423 | accuracy: 0.9430531358885017 \n",
      "Epoch 20 | Step 7945 | loss: 0.1673713111085817 | accuracy: 0.9432508680555556 \n",
      "Epoch 20 | Step 7946 | loss: 0.1681882368729395 | accuracy: 0.9431228373702422 \n",
      "Epoch 20 | Step 7947 | loss: 0.16817834237269283 | accuracy: 0.9431573275862069 \n",
      "Epoch 20 | Step 7948 | loss: 0.16839851079271828 | accuracy: 0.9430841924398625 \n",
      "Epoch 20 | Step 7949 | loss: 0.16830105894589667 | accuracy: 0.9431720890410958 \n",
      "Epoch 20 | Step 7950 | loss: 0.1681685130725338 | accuracy: 0.943259385665529 \n",
      "Epoch 20 | Step 7951 | loss: 0.1682587986064403 | accuracy: 0.9431335034013606 \n",
      "Epoch 20 | Step 7952 | loss: 0.16808678544426367 | accuracy: 0.9431673728813559 \n",
      "Epoch 20 | Step 7953 | loss: 0.16823270877923915 | accuracy: 0.9429898648648649 \n",
      "Epoch 20 | Step 7954 | loss: 0.16827539062309343 | accuracy: 0.94302398989899 \n",
      "Epoch 20 | Step 7955 | loss: 0.1683019708792035 | accuracy: 0.9430054530201343 \n",
      "Epoch 20 | Step 7956 | loss: 0.16810738493417418 | accuracy: 0.9430392976588629 \n",
      "Epoch 20 | Step 7957 | loss: 0.16775705385953188 | accuracy: 0.9431770833333334 \n",
      "Epoch 20 | Step 7958 | loss: 0.167853736290801 | accuracy: 0.9431582225913622 \n",
      "Epoch 20 | Step 7959 | loss: 0.1677167612861916 | accuracy: 0.9431912251655629 \n",
      "Epoch 20 | Step 7960 | loss: 0.16760775740734815 | accuracy: 0.9432240099009901 \n",
      "Epoch 20 | Step 7961 | loss: 0.16754016028962246 | accuracy: 0.9432051809210527 \n",
      "Epoch 20 | Step 7962 | loss: 0.16745485193172438 | accuracy: 0.9431352459016393 \n",
      "Epoch 20 | Step 7963 | loss: 0.16768624505722052 | accuracy: 0.9431168300653595 \n",
      "Epoch 20 | Step 7964 | loss: 0.1684842857529169 | accuracy: 0.9429967426710097 \n",
      "Epoch 20 | Step 7965 | loss: 0.1684550194360025 | accuracy: 0.9430296266233766 \n",
      "Epoch 20 | Step 7966 | loss: 0.16824705273057647 | accuracy: 0.9430622977346278 \n",
      "Epoch 20 | Step 7967 | loss: 0.1684077458636414 | accuracy: 0.9430443548387096 \n",
      "Epoch 20 | Step 7968 | loss: 0.16857442342439644 | accuracy: 0.9430265273311897 \n",
      "Epoch 20 | Step 7969 | loss: 0.16850411090761036 | accuracy: 0.9430088141025641 \n",
      "Epoch 20 | Step 7970 | loss: 0.16831014675501813 | accuracy: 0.9431409744408946 \n",
      "Epoch 20 | Step 7971 | loss: 0.16863715573908034 | accuracy: 0.9429737261146497 \n",
      "Epoch 20 | Step 7972 | loss: 0.1692346256048906 | accuracy: 0.9428075396825397 \n",
      "Epoch 20 | Step 7973 | loss: 0.16928981311760746 | accuracy: 0.9427412974683544 \n",
      "Epoch 20 | Step 7974 | loss: 0.16916833753324456 | accuracy: 0.9427247634069401 \n",
      "Epoch 20 | Step 7975 | loss: 0.16919837579271702 | accuracy: 0.9426591981132075 \n",
      "Epoch 20 | Step 7976 | loss: 0.16920122958509523 | accuracy: 0.94264302507837 \n",
      "Epoch 20 | Step 7977 | loss: 0.1690814614878036 | accuracy: 0.94267578125 \n",
      "Epoch 20 | Step 7978 | loss: 0.1690779443586541 | accuracy: 0.9426596573208723 \n",
      "Epoch 20 | Step 7979 | loss: 0.16940203041810054 | accuracy: 0.9426921583850931 \n",
      "Epoch 20 | Step 7980 | loss: 0.16922758721484116 | accuracy: 0.9427244582043344 \n",
      "Epoch 20 | Step 7981 | loss: 0.16901598147542016 | accuracy: 0.9428530092592593 \n",
      "Epoch 20 | Step 7982 | loss: 0.1693664903251024 | accuracy: 0.9427884615384615 \n",
      "Epoch 20 | Step 7983 | loss: 0.16922788569943667 | accuracy: 0.9429160276073619 \n",
      "Epoch 20 | Step 7984 | loss: 0.1693483313676596 | accuracy: 0.9428038990825688 \n",
      "Epoch 20 | Step 7985 | loss: 0.16931510004555667 | accuracy: 0.9428353658536586 \n",
      "Epoch 20 | Step 7986 | loss: 0.16959377349917645 | accuracy: 0.9425816869300911 \n",
      "Epoch 20 | Step 7987 | loss: 0.16951221012030582 | accuracy: 0.9426609848484848 \n",
      "Epoch 20 | Step 7988 | loss: 0.16951682426463077 | accuracy: 0.9426453927492447 \n",
      "Epoch 20 | Step 7989 | loss: 0.16948127563683738 | accuracy: 0.9426298945783133 \n",
      "Epoch 20 | Step 7990 | loss: 0.16947834481213897 | accuracy: 0.9426614114114115 \n",
      "Epoch 20 | Step 7991 | loss: 0.16963762612623007 | accuracy: 0.9425991766467066 \n",
      "Epoch 20 | Step 7992 | loss: 0.16938150826452378 | accuracy: 0.9426772388059701 \n",
      "Epoch 20 | Step 7993 | loss: 0.16917018362853137 | accuracy: 0.9427548363095238 \n",
      "Epoch 20 | Step 7994 | loss: 0.16907257466226014 | accuracy: 0.9428319732937686 \n",
      "Epoch 20 | Step 7995 | loss: 0.1691652489330112 | accuracy: 0.9428161982248521 \n",
      "Epoch 20 | Step 7996 | loss: 0.16907759658047225 | accuracy: 0.9428466076696165 \n",
      "Epoch 20 | Step 7997 | loss: 0.16884999863584246 | accuracy: 0.94296875 \n",
      "Epoch 20 | Step 7998 | loss: 0.16879432092357935 | accuracy: 0.9429527126099707 \n",
      "Epoch 20 | Step 7999 | loss: 0.16863392457932402 | accuracy: 0.9430281432748538 \n",
      "Epoch 20 | Step 8000 | loss: 0.16836721331706542 | accuracy: 0.9430575801749271 \n",
      "Epoch 20 | Step 8001 | loss: 0.16824148791344007 | accuracy: 0.9429505813953488 \n",
      "Epoch 20 | Step 8002 | loss: 0.16832783370130297 | accuracy: 0.9429347826086957 \n",
      "Epoch 20 | Step 8003 | loss: 0.1683870235813318 | accuracy: 0.9430093930635838 \n",
      "Epoch 20 | Step 8004 | loss: 0.16821421625935373 | accuracy: 0.9430835734870316 \n",
      "Epoch 20 | Step 8005 | loss: 0.16870117229248938 | accuracy: 0.9430226293103449 \n",
      "Epoch 20 | Step 8006 | loss: 0.16856296402122017 | accuracy: 0.9430963467048711 \n",
      "Epoch 20 | Step 8007 | loss: 0.16845948810023914 | accuracy: 0.9432142857142857 \n",
      "Epoch 20 | Step 8008 | loss: 0.1682814617463496 | accuracy: 0.9432870370370371 \n",
      "Epoch 20 | Step 8009 | loss: 0.16855978649321263 | accuracy: 0.9432262073863636 \n",
      "Epoch 20 | Step 8010 | loss: 0.16831039876885517 | accuracy: 0.9432985127478754 \n",
      "Epoch 20 | Step 8011 | loss: 0.16800805132857147 | accuracy: 0.9434145480225988 \n",
      "Epoch 20 | Step 8012 | loss: 0.16774403192627593 | accuracy: 0.9435299295774648 \n",
      "Epoch 20 | Step 8013 | loss: 0.16761029980490713 | accuracy: 0.9435568820224719 \n",
      "Epoch 20 | Step 8014 | loss: 0.16780700098399684 | accuracy: 0.9435836834733894 \n",
      "Epoch 20 | Step 8015 | loss: 0.16781602054834363 | accuracy: 0.9435666899441341 \n",
      "Epoch 20 | Step 8016 | loss: 0.16763017031890767 | accuracy: 0.9436368384401114 \n",
      "Epoch 20 | Step 8017 | loss: 0.16745397572716078 | accuracy: 0.9436631944444445 \n",
      "Epoch 20 | Step 8018 | loss: 0.16750721158743564 | accuracy: 0.9436461218836565 \n",
      "Epoch 20 | Step 8019 | loss: 0.16737705864300384 | accuracy: 0.9437154696132597 \n",
      "Epoch 20 | Step 8020 | loss: 0.16724632085190658 | accuracy: 0.943741391184573 \n",
      "Epoch 20 | Step 8021 | loss: 0.16703671812601795 | accuracy: 0.943853021978022 \n",
      "Epoch 20 | Step 8022 | loss: 0.16676783447396262 | accuracy: 0.9439640410958904 \n",
      "Epoch 20 | Step 8023 | loss: 0.16673732194744167 | accuracy: 0.9439890710382514 \n",
      "Epoch 20 | Step 8024 | loss: 0.16651136856475376 | accuracy: 0.9440565395095368 \n",
      "Epoch 20 | Step 8025 | loss: 0.16638116360358565 | accuracy: 0.9440387228260869 \n",
      "Epoch 20 | Step 8026 | loss: 0.16663441247733302 | accuracy: 0.9440633468834688 \n",
      "Epoch 20 | Step 8027 | loss: 0.16672213637345543 | accuracy: 0.9440033783783783 \n",
      "Epoch 20 | Step 8028 | loss: 0.16673794183930293 | accuracy: 0.9439858490566038 \n",
      "Epoch 20 | Step 8029 | loss: 0.16727550171556008 | accuracy: 0.9438424059139785 \n",
      "Epoch 20 | Step 8030 | loss: 0.16719574926685707 | accuracy: 0.94390918230563 \n",
      "Epoch 20 | Step 8031 | loss: 0.16710285587425533 | accuracy: 0.9439338235294118 \n",
      "Epoch 20 | Step 8032 | loss: 0.16695914771159484 | accuracy: 0.9440416666666667 \n",
      "Epoch 20 | Step 8033 | loss: 0.16677629931810048 | accuracy: 0.944107380319149 \n",
      "Epoch 20 | Step 8034 | loss: 0.16664833213827648 | accuracy: 0.944131299734748 \n",
      "Epoch 20 | Step 8035 | loss: 0.16673863379570536 | accuracy: 0.9440310846560847 \n",
      "Epoch 20 | Step 8036 | loss: 0.166533017201757 | accuracy: 0.9440963060686016 \n",
      "Epoch 20 | Step 8037 | loss: 0.16633398995587695 | accuracy: 0.9441611842105263 \n",
      "Epoch 20 | Step 8038 | loss: 0.1661802169688417 | accuracy: 0.9441437007874016 \n",
      "Epoch 20 | Step 8039 | loss: 0.16595613478600038 | accuracy: 0.9442081151832461 \n",
      "Epoch 20 | Step 8040 | loss: 0.16574729661950863 | accuracy: 0.9443129895561357 \n",
      "Epoch 20 | Step 8041 | loss: 0.16585952053234598 | accuracy: 0.9442952473958334 \n",
      "Epoch 20 | Step 8042 | loss: 0.1661746783109454 | accuracy: 0.9442775974025974 \n",
      "Epoch 20 | Step 8043 | loss: 0.16635559547518816 | accuracy: 0.9442600388601037 \n",
      "Epoch 20 | Step 8044 | loss: 0.16642033173979404 | accuracy: 0.944202196382429 \n",
      "Epoch 20 | Step 8045 | loss: 0.16614918013285726 | accuracy: 0.9442654639175257 \n",
      "Epoch 20 | Step 8046 | loss: 0.16623810441221243 | accuracy: 0.9442480719794345 \n",
      "Epoch 20 | Step 8047 | loss: 0.16617517175200655 | accuracy: 0.9443108974358975 \n",
      "Epoch 20 | Step 8048 | loss: 0.1662548356082128 | accuracy: 0.9441735933503836 \n",
      "Epoch 20 | Step 8049 | loss: 0.16608197333253155 | accuracy: 0.9442362882653061 \n",
      "Epoch 20 | Step 8050 | loss: 0.16594651438125213 | accuracy: 0.9442589058524173 \n",
      "Epoch 20 | Step 8051 | loss: 0.16581042895689224 | accuracy: 0.9443210659898477 \n",
      "Epoch 20 | Step 8052 | loss: 0.16565872725052166 | accuracy: 0.944382911392405 \n",
      "Epoch 20 | Step 8053 | loss: 0.1655421008101918 | accuracy: 0.9443655303030303 \n",
      "Epoch 20 | Step 8054 | loss: 0.16552166856581374 | accuracy: 0.9443482367758187 \n",
      "Epoch 20 | Step 8055 | loss: 0.16560796043606257 | accuracy: 0.9443310301507538 \n",
      "Epoch 20 | Step 8056 | loss: 0.1654606484306187 | accuracy: 0.9443922305764411 \n",
      "Epoch 20 | Step 8057 | loss: 0.16564820606261488 | accuracy: 0.9443359375 \n",
      "Epoch 20 | Step 8058 | loss: 0.1656044843116603 | accuracy: 0.944357855361596 \n",
      "Epoch 20 | Step 8059 | loss: 0.16583654777475848 | accuracy: 0.9442241915422885 \n",
      "Epoch 20 | Step 8060 | loss: 0.16552241961876155 | accuracy: 0.9443625930521092 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.6344354152679443 | accuracy: 0.796875 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.6579102873802185 | accuracy: 0.796875 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5880291362603506 | accuracy: 0.8072916666666666 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5538737326860428 | accuracy: 0.8125 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.559770667552948 | accuracy: 0.80625 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5530164440472921 | accuracy: 0.8098958333333334 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5354656023638589 | accuracy: 0.8169642857142857 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5209576152265072 | accuracy: 0.822265625 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5196211238702139 | accuracy: 0.8246527777777778 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5155128508806228 | accuracy: 0.825 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5204752060500059 | accuracy: 0.8224431818181818 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5131250148018202 | accuracy: 0.8268229166666666 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5220636610801404 | accuracy: 0.8245192307692307 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5312379236732211 | accuracy: 0.8236607142857143 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5185886959234874 | accuracy: 0.8270833333333333 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5210944321006538 | accuracy: 0.8271484375 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5337339552009808 | accuracy: 0.8235294117647058 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5274119062556162 | accuracy: 0.8255208333333334 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5228783723555114 | accuracy: 0.8240131578947368 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5178188353776932 | accuracy: 0.82578125 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5158562929857345 | accuracy: 0.828125 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5090426951646806 | accuracy: 0.8288352272727273 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5103393935638926 | accuracy: 0.8274456521739131 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5076529383659364 | accuracy: 0.828125 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5129718399047853 | accuracy: 0.82625 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5044329750996371 | accuracy: 0.828125 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5055931067025222 | accuracy: 0.8275462962962963 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.498986248459135 | accuracy: 0.8297991071428571 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.502781337705152 | accuracy: 0.8292025862068966 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5066771507263186 | accuracy: 0.8276041666666667 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.4998240278613185 | accuracy: 0.8306451612903226 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.4944258900359275 | accuracy: 0.8330078125 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.49181928869449754 | accuracy: 0.8347537878787878 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5018492980914959 | accuracy: 0.8322610294117647 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5007415149893082 | accuracy: 0.83125 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.4929902768797347 | accuracy: 0.8333333333333334 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.4942946289036727 | accuracy: 0.8336148648648649 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.49266158044338243 | accuracy: 0.8326480263157895 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.4898698612665521 | accuracy: 0.8345352564102564 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.4945519097149374 | accuracy: 0.832421875 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.49919837640553005 | accuracy: 0.8304115853658537 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.49697689570131776 | accuracy: 0.8311011904761905 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.495236726694329 | accuracy: 0.831031976744186 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.4996811977841639 | accuracy: 0.8302556818181818 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5036158548461068 | accuracy: 0.8291968597306145 \n"
     ]
    }
   ],
   "source": [
    "logger = SimpleLogger()\n",
    "train(20, model, train_iter, valid_iter, optimizer, criterion, task.train_step, task.eval_step, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nano-seq-r7R1Yrai-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
