{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from nano_seq.task.classification import ClassificationTask, ClassificationConfig\n",
    "from nano_seq.logger import PrintLogger\n",
    "from nano_seq.trainer import Trainer\n",
    "from nano_seq.data import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = ClassificationTask(\n",
    "    ClassificationConfig(\n",
    "        embed_dims=8,\n",
    "        batch_size=64,\n",
    "        num_heads=2,\n",
    "        encoder_layers=1,\n",
    "        encoder_dropout=0.3,\n",
    "        spm_dict_path=\"model.vocab\",\n",
    "        left_pad_src=False,\n",
    "        train_path=\"data/train\",\n",
    "        valid_path=\"data/valid\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dictionary: 10000it [00:00, 1254765.31it/s]\n",
      "Loading dataset: 25757it [00:00, 177759.60it/s]\n",
      "Loading dataset: 2862it [00:00, 198090.70it/s]\n"
     ]
    }
   ],
   "source": [
    "train_iter, valid_iter, model = task.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = PrintLogger()\n",
    "trainer = Trainer(train_iter, valid_iter, optimizer, criterion, task, model, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Step 1 | loss: 1.030600905418396 | accuracy: 0.484375 \n",
      "Epoch 1 | Step 2 | loss: 1.1478890180587769 | accuracy: 0.421875 \n",
      "Epoch 1 | Step 3 | loss: 1.1476312081019084 | accuracy: 0.421875 \n",
      "Epoch 1 | Step 4 | loss: 1.1625103950500488 | accuracy: 0.42578125 \n",
      "Epoch 1 | Step 5 | loss: 1.174710202217102 | accuracy: 0.4125 \n",
      "Epoch 1 | Step 6 | loss: 1.1589542428652446 | accuracy: 0.4140625 \n",
      "Epoch 1 | Step 7 | loss: 1.1263840368815832 | accuracy: 0.4174107142857143 \n",
      "Epoch 1 | Step 8 | loss: 1.1116086542606354 | accuracy: 0.416015625 \n",
      "Epoch 1 | Step 9 | loss: 1.0968861911031935 | accuracy: 0.4184027777777778 \n",
      "Epoch 1 | Step 10 | loss: 1.0783442199230193 | accuracy: 0.4203125 \n",
      "Epoch 1 | Step 11 | loss: 1.057119141925465 | accuracy: 0.4161931818181818 \n",
      "Epoch 1 | Step 12 | loss: 1.037397732337316 | accuracy: 0.421875 \n",
      "Epoch 1 | Step 13 | loss: 1.015440794137808 | accuracy: 0.4338942307692308 \n",
      "Epoch 1 | Step 14 | loss: 0.9958519637584687 | accuracy: 0.43973214285714285 \n",
      "Epoch 1 | Step 15 | loss: 0.9810517072677614 | accuracy: 0.4427083333333333 \n",
      "Epoch 1 | Step 16 | loss: 0.9728963971138002 | accuracy: 0.443359375 \n",
      "Epoch 1 | Step 17 | loss: 0.9656441001331105 | accuracy: 0.44577205882352944 \n",
      "Epoch 1 | Step 18 | loss: 0.9571487936708662 | accuracy: 0.4427083333333333 \n",
      "Epoch 1 | Step 19 | loss: 0.9475521664870413 | accuracy: 0.4432565789473684 \n",
      "Epoch 1 | Step 20 | loss: 0.9372537523508072 | accuracy: 0.44375 \n",
      "Epoch 1 | Step 21 | loss: 0.9286759836333138 | accuracy: 0.44642857142857145 \n",
      "Epoch 1 | Step 22 | loss: 0.9187886416912079 | accuracy: 0.4481534090909091 \n",
      "Epoch 1 | Step 23 | loss: 0.9103845668875653 | accuracy: 0.452445652173913 \n",
      "Epoch 1 | Step 24 | loss: 0.9050476973255476 | accuracy: 0.4518229166666667 \n",
      "Epoch 1 | Step 25 | loss: 0.8985435056686402 | accuracy: 0.45875 \n",
      "Epoch 1 | Step 26 | loss: 0.8919814916757437 | accuracy: 0.46274038461538464 \n",
      "Epoch 1 | Step 27 | loss: 0.8866531782680087 | accuracy: 0.46296296296296297 \n",
      "Epoch 1 | Step 28 | loss: 0.8827922620943615 | accuracy: 0.46205357142857145 \n",
      "Epoch 1 | Step 29 | loss: 0.8766449525438506 | accuracy: 0.4639008620689655 \n",
      "Epoch 1 | Step 30 | loss: 0.8698955039183299 | accuracy: 0.46875 \n",
      "Epoch 1 | Step 31 | loss: 0.8630347348028614 | accuracy: 0.4737903225806452 \n",
      "Epoch 1 | Step 32 | loss: 0.860512001439929 | accuracy: 0.47314453125 \n",
      "Epoch 1 | Step 33 | loss: 0.8595292857199004 | accuracy: 0.47017045454545453 \n",
      "Epoch 1 | Step 34 | loss: 0.8535179355565239 | accuracy: 0.4742647058823529 \n",
      "Epoch 1 | Step 35 | loss: 0.8472186548369272 | accuracy: 0.48035714285714287 \n",
      "Epoch 1 | Step 36 | loss: 0.8446897798114352 | accuracy: 0.4809027777777778 \n",
      "Epoch 1 | Step 37 | loss: 0.8413718117249979 | accuracy: 0.4814189189189189 \n",
      "Epoch 1 | Step 38 | loss: 0.8386834922589754 | accuracy: 0.4819078947368421 \n",
      "Epoch 1 | Step 39 | loss: 0.8373961632068341 | accuracy: 0.47996794871794873 \n",
      "Epoch 1 | Step 40 | loss: 0.8356888592243195 | accuracy: 0.48046875 \n",
      "Epoch 1 | Step 41 | loss: 0.8328740800299296 | accuracy: 0.4817073170731707 \n",
      "Epoch 1 | Step 42 | loss: 0.83209770492145 | accuracy: 0.4802827380952381 \n",
      "Epoch 1 | Step 43 | loss: 0.8287461760432221 | accuracy: 0.48183139534883723 \n",
      "Epoch 1 | Step 44 | loss: 0.8252963423728943 | accuracy: 0.4836647727272727 \n",
      "Epoch 1 | Step 45 | loss: 0.8224565201335483 | accuracy: 0.4857638888888889 \n",
      "Epoch 1 | Step 46 | loss: 0.8204639204170393 | accuracy: 0.485054347826087 \n",
      "Epoch 1 | Step 47 | loss: 0.8184515085626156 | accuracy: 0.4853723404255319 \n",
      "Epoch 1 | Step 48 | loss: 0.8170584614078203 | accuracy: 0.4856770833333333 \n",
      "Epoch 1 | Step 49 | loss: 0.8147274851799011 | accuracy: 0.4888392857142857 \n",
      "Epoch 1 | Step 50 | loss: 0.8133620524406433 | accuracy: 0.489375 \n",
      "Epoch 1 | Step 51 | loss: 0.8109115607598248 | accuracy: 0.4895833333333333 \n",
      "Epoch 1 | Step 52 | loss: 0.8085240939488778 | accuracy: 0.49158653846153844 \n",
      "Epoch 1 | Step 53 | loss: 0.8065136536112372 | accuracy: 0.49262971698113206 \n",
      "Epoch 1 | Step 54 | loss: 0.806486885856699 | accuracy: 0.4913194444444444 \n",
      "Epoch 1 | Step 55 | loss: 0.8050820990042253 | accuracy: 0.49176136363636364 \n",
      "Epoch 1 | Step 56 | loss: 0.8050331664936883 | accuracy: 0.48939732142857145 \n",
      "Epoch 1 | Step 57 | loss: 0.8033221343107391 | accuracy: 0.4909539473684211 \n",
      "Epoch 1 | Step 58 | loss: 0.803078084156431 | accuracy: 0.48976293103448276 \n",
      "Epoch 1 | Step 59 | loss: 0.8011807304317669 | accuracy: 0.4902012711864407 \n",
      "Epoch 1 | Step 60 | loss: 0.8006586064894994 | accuracy: 0.4895833333333333 \n",
      "Epoch 1 | Step 61 | loss: 0.7991260720081017 | accuracy: 0.49026639344262296 \n",
      "Epoch 1 | Step 62 | loss: 0.7980575523068828 | accuracy: 0.49117943548387094 \n",
      "Epoch 1 | Step 63 | loss: 0.7960228636151269 | accuracy: 0.49206349206349204 \n",
      "Epoch 1 | Step 64 | loss: 0.7942086914554238 | accuracy: 0.493408203125 \n",
      "Epoch 1 | Step 65 | loss: 0.7933990616064805 | accuracy: 0.49423076923076925 \n",
      "Epoch 1 | Step 66 | loss: 0.7919322956692089 | accuracy: 0.4952651515151515 \n",
      "Epoch 1 | Step 67 | loss: 0.791019779532703 | accuracy: 0.49463619402985076 \n",
      "Epoch 1 | Step 68 | loss: 0.7898876728380427 | accuracy: 0.4963235294117647 \n",
      "Epoch 1 | Step 69 | loss: 0.7893078871395277 | accuracy: 0.49569746376811596 \n",
      "Epoch 1 | Step 70 | loss: 0.7884946405887604 | accuracy: 0.4953125 \n",
      "Epoch 1 | Step 71 | loss: 0.7874817101048751 | accuracy: 0.4964788732394366 \n",
      "Epoch 1 | Step 72 | loss: 0.7862572173277536 | accuracy: 0.4969618055555556 \n",
      "Epoch 1 | Step 73 | loss: 0.7848447520438937 | accuracy: 0.4987157534246575 \n",
      "Epoch 1 | Step 74 | loss: 0.7839249316099526 | accuracy: 0.4985219594594595 \n",
      "Epoch 1 | Step 75 | loss: 0.7835749928156533 | accuracy: 0.49833333333333335 \n",
      "Epoch 1 | Step 76 | loss: 0.7830375205529363 | accuracy: 0.4987664473684211 \n",
      "Epoch 1 | Step 77 | loss: 0.7813650245790357 | accuracy: 0.5 \n",
      "Epoch 1 | Step 78 | loss: 0.7808500062196682 | accuracy: 0.499599358974359 \n",
      "Epoch 1 | Step 79 | loss: 0.7789511212819739 | accuracy: 0.5009889240506329 \n",
      "Epoch 1 | Step 80 | loss: 0.7783482059836386 | accuracy: 0.5009765625 \n",
      "Epoch 1 | Step 81 | loss: 0.7777053934556465 | accuracy: 0.5005787037037037 \n",
      "Epoch 1 | Step 82 | loss: 0.777071557393888 | accuracy: 0.5015243902439024 \n",
      "Epoch 1 | Step 83 | loss: 0.7762212437319467 | accuracy: 0.5016942771084336 \n",
      "Epoch 1 | Step 84 | loss: 0.7754609584808347 | accuracy: 0.501860119047619 \n",
      "Epoch 1 | Step 85 | loss: 0.7746553070404949 | accuracy: 0.5022058823529411 \n",
      "Epoch 1 | Step 86 | loss: 0.7746135932068491 | accuracy: 0.5018168604651162 \n",
      "Epoch 1 | Step 87 | loss: 0.7745051240098886 | accuracy: 0.5007183908045976 \n",
      "Epoch 1 | Step 88 | loss: 0.7734872414307159 | accuracy: 0.5014204545454544 \n",
      "Epoch 1 | Step 89 | loss: 0.7726742417624826 | accuracy: 0.5029845505617976 \n",
      "Epoch 1 | Step 90 | loss: 0.7722867468992868 | accuracy: 0.5027777777777777 \n",
      "Epoch 1 | Step 91 | loss: 0.7715191723226189 | accuracy: 0.5034340659340658 \n",
      "Epoch 1 | Step 92 | loss: 0.7705089773820792 | accuracy: 0.5044157608695651 \n",
      "Epoch 1 | Step 93 | loss: 0.7701138693799253 | accuracy: 0.5043682795698923 \n",
      "Epoch 1 | Step 94 | loss: 0.7695375560445987 | accuracy: 0.5049867021276594 \n",
      "Epoch 1 | Step 95 | loss: 0.768344411724492 | accuracy: 0.5067434210526315 \n",
      "Epoch 1 | Step 96 | loss: 0.768251976619164 | accuracy: 0.5060221354166666 \n",
      "Epoch 1 | Step 97 | loss: 0.7678421403943876 | accuracy: 0.5056378865979382 \n",
      "Epoch 1 | Step 98 | loss: 0.7672416938810931 | accuracy: 0.5060586734693877 \n",
      "Epoch 1 | Step 99 | loss: 0.7672996719678241 | accuracy: 0.5056818181818181 \n",
      "Epoch 1 | Step 100 | loss: 0.7667008155584334 | accuracy: 0.5056249999999999 \n",
      "Epoch 1 | Step 101 | loss: 0.7656754190378848 | accuracy: 0.5061881188118811 \n",
      "Epoch 1 | Step 102 | loss: 0.7651494817406522 | accuracy: 0.5065870098039215 \n",
      "Epoch 1 | Step 103 | loss: 0.7641518868288946 | accuracy: 0.5069781553398057 \n",
      "Epoch 1 | Step 104 | loss: 0.7632428940672139 | accuracy: 0.507061298076923 \n",
      "Epoch 1 | Step 105 | loss: 0.763060160477956 | accuracy: 0.5069940476190475 \n",
      "Epoch 1 | Step 106 | loss: 0.7629187337632448 | accuracy: 0.506191037735849 \n",
      "Epoch 1 | Step 107 | loss: 0.7619742639710969 | accuracy: 0.5073014018691587 \n",
      "Epoch 1 | Step 108 | loss: 0.761996707982487 | accuracy: 0.507667824074074 \n",
      "Epoch 1 | Step 109 | loss: 0.7613062825771646 | accuracy: 0.5074541284403669 \n",
      "Epoch 1 | Step 110 | loss: 0.7611786094578828 | accuracy: 0.5076704545454545 \n",
      "Epoch 1 | Step 111 | loss: 0.7601834906114113 | accuracy: 0.5083051801801801 \n",
      "Epoch 1 | Step 112 | loss: 0.7599114796945026 | accuracy: 0.5085100446428571 \n",
      "Epoch 1 | Step 113 | loss: 0.7595379653230176 | accuracy: 0.508987831858407 \n",
      "Epoch 1 | Step 114 | loss: 0.7594689517690423 | accuracy: 0.5084978070175438 \n",
      "Epoch 1 | Step 115 | loss: 0.7590121611304904 | accuracy: 0.5089673913043478 \n",
      "Epoch 1 | Step 116 | loss: 0.7589678851694895 | accuracy: 0.5082165948275862 \n",
      "Epoch 1 | Step 117 | loss: 0.7585361798604329 | accuracy: 0.5084134615384616 \n",
      "Epoch 1 | Step 118 | loss: 0.7582721594026532 | accuracy: 0.5080773305084746 \n",
      "Epoch 1 | Step 119 | loss: 0.7575593911299183 | accuracy: 0.5090598739495799 \n",
      "Epoch 1 | Step 120 | loss: 0.7568417410055795 | accuracy: 0.5095052083333333 \n",
      "Epoch 1 | Step 121 | loss: 0.756377039862073 | accuracy: 0.5096849173553719 \n",
      "Epoch 1 | Step 122 | loss: 0.7558985723823797 | accuracy: 0.5103739754098361 \n",
      "Epoch 1 | Step 123 | loss: 0.7560182887364209 | accuracy: 0.5097815040650406 \n",
      "Epoch 1 | Step 124 | loss: 0.7562151671417296 | accuracy: 0.508820564516129 \n",
      "Epoch 1 | Step 125 | loss: 0.7560799932479857 | accuracy: 0.509375 \n",
      "Epoch 1 | Step 126 | loss: 0.7558270319113655 | accuracy: 0.5094246031746031 \n",
      "Epoch 1 | Step 127 | loss: 0.7556198398897966 | accuracy: 0.5097194881889764 \n",
      "Epoch 1 | Step 128 | loss: 0.7553049908019601 | accuracy: 0.509765625 \n",
      "Epoch 1 | Step 129 | loss: 0.7545890350674472 | accuracy: 0.5104166666666666 \n",
      "Epoch 1 | Step 130 | loss: 0.7541352790135603 | accuracy: 0.5106971153846154 \n",
      "Epoch 1 | Step 131 | loss: 0.7542151981637677 | accuracy: 0.5103769083969466 \n",
      "Epoch 1 | Step 132 | loss: 0.7538597859216458 | accuracy: 0.5104166666666666 \n",
      "Epoch 1 | Step 133 | loss: 0.7532913761031358 | accuracy: 0.5111607142857143 \n",
      "Epoch 1 | Step 134 | loss: 0.7526972769801296 | accuracy: 0.5114272388059702 \n",
      "Epoch 1 | Step 135 | loss: 0.7523522937739335 | accuracy: 0.5113425925925926 \n",
      "Epoch 1 | Step 136 | loss: 0.7520295267595962 | accuracy: 0.5119485294117647 \n",
      "Epoch 1 | Step 137 | loss: 0.7515591883311304 | accuracy: 0.5125456204379562 \n",
      "Epoch 1 | Step 138 | loss: 0.7509007544621176 | accuracy: 0.5133605072463767 \n",
      "Epoch 1 | Step 139 | loss: 0.7509772044291597 | accuracy: 0.5128147482014388 \n",
      "Epoch 1 | Step 140 | loss: 0.7505407039608272 | accuracy: 0.5133928571428571 \n",
      "Epoch 1 | Step 141 | loss: 0.7505873116195623 | accuracy: 0.5134086879432624 \n",
      "Epoch 1 | Step 142 | loss: 0.7503632575693263 | accuracy: 0.5136443661971831 \n",
      "Epoch 1 | Step 143 | loss: 0.7499578861923483 | accuracy: 0.5142045454545454 \n",
      "Epoch 1 | Step 144 | loss: 0.7493934010465938 | accuracy: 0.5147569444444444 \n",
      "Epoch 1 | Step 145 | loss: 0.749107503068858 | accuracy: 0.514978448275862 \n",
      "Epoch 1 | Step 146 | loss: 0.7488224404315424 | accuracy: 0.5147688356164384 \n",
      "Epoch 1 | Step 147 | loss: 0.7483580554423687 | accuracy: 0.515093537414966 \n",
      "Epoch 1 | Step 148 | loss: 0.7481865907037578 | accuracy: 0.514674831081081 \n",
      "Epoch 1 | Step 149 | loss: 0.7477666331617622 | accuracy: 0.5149958053691274 \n",
      "Epoch 1 | Step 150 | loss: 0.7471394888559975 | accuracy: 0.5156249999999998 \n",
      "Epoch 1 | Step 151 | loss: 0.7468166884207564 | accuracy: 0.5163493377483441 \n",
      "Epoch 1 | Step 152 | loss: 0.7465748061474998 | accuracy: 0.516550164473684 \n",
      "Epoch 1 | Step 153 | loss: 0.7460224047984949 | accuracy: 0.5168504901960782 \n",
      "Epoch 1 | Step 154 | loss: 0.7454994533743174 | accuracy: 0.5174512987012985 \n",
      "Epoch 1 | Step 155 | loss: 0.7452276714386475 | accuracy: 0.5175403225806449 \n",
      "Epoch 1 | Step 156 | loss: 0.7450528087524264 | accuracy: 0.5175280448717946 \n",
      "Epoch 1 | Step 157 | loss: 0.745000116005065 | accuracy: 0.5174164012738851 \n",
      "Epoch 1 | Step 158 | loss: 0.7454152080831645 | accuracy: 0.5168117088607592 \n",
      "Epoch 1 | Step 159 | loss: 0.7450622852493378 | accuracy: 0.5169025157232702 \n",
      "Epoch 1 | Step 160 | loss: 0.7451073296368118 | accuracy: 0.5164062499999997 \n",
      "Epoch 1 | Step 161 | loss: 0.7447938848726494 | accuracy: 0.5165954968944096 \n",
      "Epoch 1 | Step 162 | loss: 0.7446304773106983 | accuracy: 0.5166859567901232 \n",
      "Epoch 1 | Step 163 | loss: 0.7444194705208382 | accuracy: 0.5168711656441716 \n",
      "Epoch 1 | Step 164 | loss: 0.7443177140340568 | accuracy: 0.5167682926829267 \n",
      "Epoch 1 | Step 165 | loss: 0.7438946492744211 | accuracy: 0.5172348484848484 \n",
      "Epoch 1 | Step 166 | loss: 0.743563996740134 | accuracy: 0.5175075301204818 \n",
      "Epoch 1 | Step 167 | loss: 0.7435309994006581 | accuracy: 0.5175898203592812 \n",
      "Epoch 1 | Step 168 | loss: 0.7433061188175561 | accuracy: 0.5180431547619045 \n",
      "Epoch 1 | Step 169 | loss: 0.7430089715669843 | accuracy: 0.5184911242603548 \n",
      "Epoch 1 | Step 170 | loss: 0.7427814956973577 | accuracy: 0.5189338235294115 \n",
      "Epoch 1 | Step 171 | loss: 0.7421097790288643 | accuracy: 0.5193713450292395 \n",
      "Epoch 1 | Step 172 | loss: 0.7419866694267403 | accuracy: 0.5191678779069765 \n",
      "Epoch 1 | Step 173 | loss: 0.7416013503350272 | accuracy: 0.5192377167630056 \n",
      "Epoch 1 | Step 174 | loss: 0.7413021908409291 | accuracy: 0.5196659482758619 \n",
      "Epoch 1 | Step 175 | loss: 0.7410414314270016 | accuracy: 0.5195535714285713 \n",
      "Epoch 1 | Step 176 | loss: 0.7406812973997806 | accuracy: 0.5199751420454544 \n",
      "Epoch 1 | Step 177 | loss: 0.7405058330735241 | accuracy: 0.5201271186440677 \n",
      "Epoch 1 | Step 178 | loss: 0.7402338757273853 | accuracy: 0.5200140449438202 \n",
      "Epoch 1 | Step 179 | loss: 0.7398497672054352 | accuracy: 0.5206005586592178 \n",
      "Epoch 1 | Step 180 | loss: 0.7394768218199409 | accuracy: 0.5207465277777777 \n",
      "Epoch 1 | Step 181 | loss: 0.739173102115399 | accuracy: 0.5213225138121547 \n",
      "Epoch 1 | Step 182 | loss: 0.7389795826031609 | accuracy: 0.5218063186813187 \n",
      "Epoch 1 | Step 183 | loss: 0.7385028265213052 | accuracy: 0.5227117486338798 \n",
      "Epoch 1 | Step 184 | loss: 0.7381062591853346 | accuracy: 0.5229279891304348 \n",
      "Epoch 1 | Step 185 | loss: 0.7377043579075785 | accuracy: 0.5235641891891892 \n",
      "Epoch 1 | Step 186 | loss: 0.737172464529673 | accuracy: 0.5241095430107527 \n",
      "Epoch 1 | Step 187 | loss: 0.7370905072931296 | accuracy: 0.5237299465240642 \n",
      "Epoch 1 | Step 188 | loss: 0.737338693218028 | accuracy: 0.5230219414893618 \n",
      "Epoch 1 | Step 189 | loss: 0.7366277143438024 | accuracy: 0.5238095238095238 \n",
      "Epoch 1 | Step 190 | loss: 0.7363969153479523 | accuracy: 0.523766447368421 \n",
      "Epoch 1 | Step 191 | loss: 0.7360848366278001 | accuracy: 0.5242964659685864 \n",
      "Epoch 1 | Step 192 | loss: 0.7358867159734167 | accuracy: 0.5244140625 \n",
      "Epoch 1 | Step 193 | loss: 0.7353069667989105 | accuracy: 0.5252590673575129 \n",
      "Epoch 1 | Step 194 | loss: 0.7351265777017649 | accuracy: 0.5253704896907216 \n",
      "Epoch 1 | Step 195 | loss: 0.7348848437651607 | accuracy: 0.5255608974358974 \n",
      "Epoch 1 | Step 196 | loss: 0.734592328874432 | accuracy: 0.5254304846938775 \n",
      "Epoch 1 | Step 197 | loss: 0.7344414824761712 | accuracy: 0.5255393401015228 \n",
      "Epoch 1 | Step 198 | loss: 0.7339583623288854 | accuracy: 0.5259627525252525 \n",
      "Epoch 1 | Step 199 | loss: 0.7338657942249545 | accuracy: 0.5256752512562813 \n",
      "Epoch 1 | Step 200 | loss: 0.7334935399889944 | accuracy: 0.5260156249999999 \n",
      "Epoch 1 | Step 201 | loss: 0.7336998848772758 | accuracy: 0.5257307213930347 \n",
      "Epoch 1 | Step 202 | loss: 0.7334183587296171 | accuracy: 0.5261448019801979 \n",
      "Epoch 1 | Step 203 | loss: 0.733326098895425 | accuracy: 0.5256311576354679 \n",
      "Epoch 1 | Step 204 | loss: 0.7333618452151613 | accuracy: 0.5253523284313724 \n",
      "Epoch 1 | Step 205 | loss: 0.733007595887998 | accuracy: 0.5259908536585364 \n",
      "Epoch 1 | Step 206 | loss: 0.733034132175075 | accuracy: 0.5258646844660192 \n",
      "Epoch 1 | Step 207 | loss: 0.7330981176256555 | accuracy: 0.5253623188405795 \n",
      "Epoch 1 | Step 208 | loss: 0.7330548445192664 | accuracy: 0.5251652644230768 \n",
      "Epoch 1 | Step 209 | loss: 0.7328495246371581 | accuracy: 0.5255681818181817 \n",
      "Epoch 1 | Step 210 | loss: 0.732599203927176 | accuracy: 0.5261904761904761 \n",
      "Epoch 1 | Step 211 | loss: 0.7324628211310686 | accuracy: 0.525992298578199 \n",
      "Epoch 1 | Step 212 | loss: 0.7323923889758449 | accuracy: 0.5259433962264151 \n",
      "Epoch 1 | Step 213 | loss: 0.7320747719684114 | accuracy: 0.5261883802816901 \n",
      "Epoch 1 | Step 214 | loss: 0.7318285193955785 | accuracy: 0.525919976635514 \n",
      "Epoch 1 | Step 215 | loss: 0.7316587808520292 | accuracy: 0.5260174418604651 \n",
      "Epoch 1 | Step 216 | loss: 0.7316252051128279 | accuracy: 0.5258969907407407 \n",
      "Epoch 1 | Step 217 | loss: 0.7310844750448303 | accuracy: 0.5265697004608294 \n",
      "Epoch 1 | Step 218 | loss: 0.7309351746642259 | accuracy: 0.5265911697247706 \n",
      "Epoch 1 | Step 219 | loss: 0.7309200545968528 | accuracy: 0.5264697488584474 \n",
      "Epoch 1 | Step 220 | loss: 0.7308237005363809 | accuracy: 0.5267045454545454 \n",
      "Epoch 1 | Step 221 | loss: 0.7305927244246813 | accuracy: 0.5267251131221719 \n",
      "Epoch 1 | Step 222 | loss: 0.7305475355268596 | accuracy: 0.5267454954954954 \n",
      "Epoch 1 | Step 223 | loss: 0.730328605046721 | accuracy: 0.5266255605381165 \n",
      "Epoch 1 | Step 224 | loss: 0.7299504641975673 | accuracy: 0.5272739955357142 \n",
      "Epoch 1 | Step 225 | loss: 0.7297933231459721 | accuracy: 0.5276388888888888 \n",
      "Epoch 1 | Step 226 | loss: 0.7296248355270485 | accuracy: 0.5278622787610618 \n",
      "Epoch 1 | Step 227 | loss: 0.7297016878485152 | accuracy: 0.527395374449339 \n",
      "Epoch 1 | Step 228 | loss: 0.7294017808479173 | accuracy: 0.5278919956140349 \n",
      "Epoch 1 | Step 229 | loss: 0.7293858366762184 | accuracy: 0.5273608078602618 \n",
      "Epoch 1 | Step 230 | loss: 0.7292028069496153 | accuracy: 0.5273777173913041 \n",
      "Epoch 1 | Step 231 | loss: 0.7289047463115673 | accuracy: 0.5279356060606059 \n",
      "Epoch 1 | Step 232 | loss: 0.728608249847231 | accuracy: 0.5282192887931033 \n",
      "Epoch 1 | Step 233 | loss: 0.7283740399221491 | accuracy: 0.5285675965665235 \n",
      "Epoch 1 | Step 234 | loss: 0.7282210728551585 | accuracy: 0.5287126068376068 \n",
      "Epoch 1 | Step 235 | loss: 0.7278991577473091 | accuracy: 0.5290558510638297 \n",
      "Epoch 1 | Step 236 | loss: 0.7274876792552105 | accuracy: 0.5293299788135593 \n",
      "Epoch 1 | Step 237 | loss: 0.7272588907414849 | accuracy: 0.529206223628692 \n",
      "Epoch 1 | Step 238 | loss: 0.7270707518112757 | accuracy: 0.5292804621848739 \n",
      "Epoch 1 | Step 239 | loss: 0.7268812741195804 | accuracy: 0.5295502092050208 \n",
      "Epoch 1 | Step 240 | loss: 0.7267840581635632 | accuracy: 0.5296874999999999 \n",
      "Epoch 1 | Step 241 | loss: 0.726299965035371 | accuracy: 0.5302774896265559 \n",
      "Epoch 1 | Step 242 | loss: 0.7258556076317777 | accuracy: 0.5309271694214873 \n",
      "Epoch 1 | Step 243 | loss: 0.7255895741191909 | accuracy: 0.5311856995884772 \n",
      "Epoch 1 | Step 244 | loss: 0.7256022574471643 | accuracy: 0.5309938524590162 \n",
      "Epoch 1 | Step 245 | loss: 0.725332120486668 | accuracy: 0.5315688775510202 \n",
      "Epoch 1 | Step 246 | loss: 0.7250568086538856 | accuracy: 0.5315040650406502 \n",
      "Epoch 1 | Step 247 | loss: 0.7246769007883571 | accuracy: 0.5319458502024289 \n",
      "Epoch 1 | Step 248 | loss: 0.7243852992692299 | accuracy: 0.5325730846774192 \n",
      "Epoch 1 | Step 249 | loss: 0.7243058116560478 | accuracy: 0.5325677710843372 \n",
      "Epoch 1 | Step 250 | loss: 0.7240055484771726 | accuracy: 0.5327499999999997 \n",
      "Epoch 1 | Step 251 | loss: 0.7239623668184316 | accuracy: 0.5327440239043822 \n",
      "Epoch 1 | Step 252 | loss: 0.7239255836558718 | accuracy: 0.5324900793650792 \n",
      "Epoch 1 | Step 253 | loss: 0.7236977264343983 | accuracy: 0.5329174901185768 \n",
      "Epoch 1 | Step 254 | loss: 0.7234405872859352 | accuracy: 0.5334645669291337 \n",
      "Epoch 1 | Step 255 | loss: 0.723254060745239 | accuracy: 0.5338235294117645 \n",
      "Epoch 1 | Step 256 | loss: 0.723098832182586 | accuracy: 0.5340576171874998 \n",
      "Epoch 1 | Step 257 | loss: 0.7229508757591245 | accuracy: 0.5342290856031127 \n",
      "Epoch 1 | Step 258 | loss: 0.7227492905402366 | accuracy: 0.5347020348837207 \n",
      "Epoch 1 | Step 259 | loss: 0.7225516571961773 | accuracy: 0.5350506756756754 \n",
      "Epoch 1 | Step 260 | loss: 0.7222572296857832 | accuracy: 0.535637019230769 \n",
      "Epoch 1 | Step 261 | loss: 0.7222015382686335 | accuracy: 0.5355004789272029 \n",
      "Epoch 1 | Step 262 | loss: 0.7220076813952612 | accuracy: 0.5358420801526715 \n",
      "Epoch 1 | Step 263 | loss: 0.7218308847666691 | accuracy: 0.5361216730038021 \n",
      "Epoch 1 | Step 264 | loss: 0.7218698369282662 | accuracy: 0.5358072916666664 \n",
      "Epoch 1 | Step 265 | loss: 0.7215678233020708 | accuracy: 0.536202830188679 \n",
      "Epoch 1 | Step 266 | loss: 0.7214295527988804 | accuracy: 0.5361842105263156 \n",
      "Epoch 1 | Step 267 | loss: 0.7210587892639501 | accuracy: 0.5367509363295878 \n",
      "Epoch 1 | Step 268 | loss: 0.7209586358782069 | accuracy: 0.5366721082089551 \n",
      "Epoch 1 | Step 269 | loss: 0.7207578890385679 | accuracy: 0.5370585501858733 \n",
      "Epoch 1 | Step 270 | loss: 0.7207316506791995 | accuracy: 0.5371527777777775 \n",
      "Epoch 1 | Step 271 | loss: 0.7205599022967347 | accuracy: 0.5372463099630993 \n",
      "Epoch 1 | Step 272 | loss: 0.7203793096191741 | accuracy: 0.5373391544117644 \n",
      "Epoch 1 | Step 273 | loss: 0.7203086317677199 | accuracy: 0.5372596153846151 \n",
      "Epoch 1 | Step 274 | loss: 0.720092594188495 | accuracy: 0.5376938868613136 \n",
      "Epoch 1 | Step 275 | loss: 0.720149334777485 | accuracy: 0.5375568181818179 \n",
      "Epoch 1 | Step 276 | loss: 0.7201990020879798 | accuracy: 0.5370810688405794 \n",
      "Epoch 1 | Step 277 | loss: 0.7200806020399291 | accuracy: 0.5371164259927794 \n",
      "Epoch 1 | Step 278 | loss: 0.7201106089482201 | accuracy: 0.5370953237410068 \n",
      "Epoch 1 | Step 279 | loss: 0.719959270355949 | accuracy: 0.5374103942652325 \n",
      "Epoch 1 | Step 280 | loss: 0.7197390128459246 | accuracy: 0.5375558035714281 \n",
      "Epoch 1 | Step 281 | loss: 0.7195670053203755 | accuracy: 0.5378113879003553 \n",
      "Epoch 1 | Step 282 | loss: 0.7196299697913172 | accuracy: 0.5376773049645385 \n",
      "Epoch 1 | Step 283 | loss: 0.719544565930383 | accuracy: 0.5374889575971726 \n",
      "Epoch 1 | Step 284 | loss: 0.7193312540020738 | accuracy: 0.5380171654929572 \n",
      "Epoch 1 | Step 285 | loss: 0.7191868604275214 | accuracy: 0.538103070175438 \n",
      "Epoch 1 | Step 286 | loss: 0.7190100621510215 | accuracy: 0.5384615384615379 \n",
      "Epoch 1 | Step 287 | loss: 0.7189364910956455 | accuracy: 0.5385452961672468 \n",
      "Epoch 1 | Step 288 | loss: 0.7187423960616187 | accuracy: 0.5387912326388883 \n",
      "Epoch 1 | Step 289 | loss: 0.7187190748828501 | accuracy: 0.5385488754325254 \n",
      "Epoch 1 | Step 290 | loss: 0.718723795126224 | accuracy: 0.538577586206896 \n",
      "Epoch 1 | Step 291 | loss: 0.718532528049757 | accuracy: 0.538713487972508 \n",
      "Epoch 1 | Step 292 | loss: 0.7183647629332865 | accuracy: 0.5390089897260267 \n",
      "Epoch 1 | Step 293 | loss: 0.7181129553212237 | accuracy: 0.5394624573378832 \n",
      "Epoch 1 | Step 294 | loss: 0.7178791789781476 | accuracy: 0.5397534013605434 \n",
      "Epoch 1 | Step 295 | loss: 0.7177919181726743 | accuracy: 0.5399894067796601 \n",
      "Epoch 1 | Step 296 | loss: 0.7177957244016024 | accuracy: 0.5396431587837829 \n",
      "Epoch 1 | Step 297 | loss: 0.7175552397464658 | accuracy: 0.5400357744107736 \n",
      "Epoch 1 | Step 298 | loss: 0.7174137204685463 | accuracy: 0.5401111577181199 \n",
      "Epoch 1 | Step 299 | loss: 0.717419001370369 | accuracy: 0.5400815217391296 \n",
      "Epoch 1 | Step 300 | loss: 0.7170599255959188 | accuracy: 0.5406249999999991 \n",
      "Epoch 1 | Step 301 | loss: 0.7170383850997464 | accuracy: 0.5405419435215938 \n",
      "Epoch 1 | Step 302 | loss: 0.7167979068313998 | accuracy: 0.5408733443708601 \n",
      "Epoch 1 | Step 303 | loss: 0.7165969559068329 | accuracy: 0.541150990099009 \n",
      "Epoch 1 | Step 304 | loss: 0.7163930768637276 | accuracy: 0.5414782072368413 \n",
      "Epoch 1 | Step 305 | loss: 0.7164518614284322 | accuracy: 0.5414446721311467 \n",
      "Epoch 1 | Step 306 | loss: 0.7162890412838625 | accuracy: 0.5415134803921561 \n",
      "Epoch 1 | Step 307 | loss: 0.7159690806454084 | accuracy: 0.541785423452768 \n",
      "Epoch 1 | Step 308 | loss: 0.7158197423854425 | accuracy: 0.5420048701298694 \n",
      "Epoch 1 | Step 309 | loss: 0.7156952604120983 | accuracy: 0.5422734627831708 \n",
      "Epoch 1 | Step 310 | loss: 0.7155266048446772 | accuracy: 0.5425907258064508 \n",
      "Epoch 1 | Step 311 | loss: 0.7153163395127293 | accuracy: 0.5428557073954977 \n",
      "Epoch 1 | Step 312 | loss: 0.7151522009800636 | accuracy: 0.5431189903846148 \n",
      "Epoch 1 | Step 313 | loss: 0.7150351685076088 | accuracy: 0.5431809105431303 \n",
      "Epoch 1 | Step 314 | loss: 0.714972552410356 | accuracy: 0.5432424363057319 \n",
      "Epoch 1 | Step 315 | loss: 0.7145840974081124 | accuracy: 0.5438492063492057 \n",
      "Epoch 1 | Step 316 | loss: 0.7144805415521688 | accuracy: 0.5439576740506323 \n",
      "Epoch 1 | Step 317 | loss: 0.7143429474499693 | accuracy: 0.5441640378548891 \n",
      "Epoch 1 | Step 318 | loss: 0.7141388369806152 | accuracy: 0.5443199685534585 \n",
      "Epoch 1 | Step 319 | loss: 0.7140103498222681 | accuracy: 0.5444259404388709 \n",
      "Epoch 1 | Step 320 | loss: 0.7138885535299773 | accuracy: 0.5445312499999995 \n",
      "Epoch 1 | Step 321 | loss: 0.713836363357175 | accuracy: 0.5444898753894075 \n",
      "Epoch 1 | Step 322 | loss: 0.7137758839204439 | accuracy: 0.5445458074534155 \n",
      "Epoch 1 | Step 323 | loss: 0.7137414037996764 | accuracy: 0.5445046439628477 \n",
      "Epoch 1 | Step 324 | loss: 0.7135083923737202 | accuracy: 0.5448013117283944 \n",
      "Epoch 1 | Step 325 | loss: 0.7132187124399032 | accuracy: 0.545240384615384 \n",
      "Epoch 1 | Step 326 | loss: 0.713246400370919 | accuracy: 0.5450536809815945 \n",
      "Epoch 1 | Step 327 | loss: 0.7131713820159976 | accuracy: 0.5452025993883786 \n",
      "Epoch 1 | Step 328 | loss: 0.7129486535743963 | accuracy: 0.5454935213414628 \n",
      "Epoch 1 | Step 329 | loss: 0.7127776944890929 | accuracy: 0.5457351823708201 \n",
      "Epoch 1 | Step 330 | loss: 0.7126638555165488 | accuracy: 0.5456439393939387 \n",
      "Epoch 1 | Step 331 | loss: 0.7126684624622951 | accuracy: 0.5456948640483377 \n",
      "Epoch 1 | Step 332 | loss: 0.7125175649143122 | accuracy: 0.5459337349397584 \n",
      "Epoch 1 | Step 333 | loss: 0.7122771220880223 | accuracy: 0.5460773273273266 \n",
      "Epoch 1 | Step 334 | loss: 0.7121343625162885 | accuracy: 0.5460797155688616 \n",
      "Epoch 1 | Step 335 | loss: 0.712073080219439 | accuracy: 0.5459888059701485 \n",
      "Epoch 1 | Step 336 | loss: 0.7119923393641193 | accuracy: 0.5460844494047612 \n",
      "Epoch 1 | Step 337 | loss: 0.7119684785339169 | accuracy: 0.545901335311572 \n",
      "Epoch 1 | Step 338 | loss: 0.7118695059118886 | accuracy: 0.5459504437869815 \n",
      "Epoch 1 | Step 339 | loss: 0.7116858013259972 | accuracy: 0.5462297197640111 \n",
      "Epoch 1 | Step 340 | loss: 0.7116477130090484 | accuracy: 0.546323529411764 \n",
      "Epoch 1 | Step 341 | loss: 0.7114658095270303 | accuracy: 0.5465084310850432 \n",
      "Epoch 1 | Step 342 | loss: 0.7114671838213821 | accuracy: 0.54641812865497 \n",
      "Epoch 1 | Step 343 | loss: 0.71136925536759 | accuracy: 0.5463283527696785 \n",
      "Epoch 1 | Step 344 | loss: 0.7113571284815318 | accuracy: 0.5463299418604642 \n",
      "Epoch 1 | Step 345 | loss: 0.7111521230227701 | accuracy: 0.5466938405797093 \n",
      "Epoch 1 | Step 346 | loss: 0.7110553068577206 | accuracy: 0.5469201589595367 \n",
      "Epoch 1 | Step 347 | loss: 0.7108459531058492 | accuracy: 0.5472802593659934 \n",
      "Epoch 1 | Step 348 | loss: 0.7106480833100173 | accuracy: 0.5475484913793095 \n",
      "Epoch 1 | Step 349 | loss: 0.7104499457900364 | accuracy: 0.5477256446991395 \n",
      "Epoch 1 | Step 350 | loss: 0.7105361773286544 | accuracy: 0.5474107142857134 \n",
      "Epoch 1 | Step 351 | loss: 0.7102900468386133 | accuracy: 0.5475872507122498 \n",
      "Epoch 1 | Step 352 | loss: 0.7101772637529803 | accuracy: 0.5478071732954537 \n",
      "Epoch 1 | Step 353 | loss: 0.7100170629558072 | accuracy: 0.5480258498583561 \n",
      "Epoch 1 | Step 354 | loss: 0.7099326035733946 | accuracy: 0.5482432909604512 \n",
      "Epoch 1 | Step 355 | loss: 0.7097860032403969 | accuracy: 0.5483714788732387 \n",
      "Epoch 1 | Step 356 | loss: 0.7096115112974398 | accuracy: 0.5484111657303363 \n",
      "Epoch 1 | Step 357 | loss: 0.7095091488181038 | accuracy: 0.5484068627450973 \n",
      "Epoch 1 | Step 358 | loss: 0.7093760579324964 | accuracy: 0.5486208100558652 \n",
      "Epoch 1 | Step 359 | loss: 0.7092245159707026 | accuracy: 0.5489206128133697 \n",
      "Epoch 1 | Step 360 | loss: 0.7091139614582058 | accuracy: 0.5490017361111104 \n",
      "Epoch 1 | Step 361 | loss: 0.7091769125322883 | accuracy: 0.5488659972299161 \n",
      "Epoch 1 | Step 362 | loss: 0.7090496583867465 | accuracy: 0.5488604972375682 \n",
      "Epoch 1 | Step 363 | loss: 0.7091836196988736 | accuracy: 0.5487258953168036 \n",
      "Epoch 1 | Step 364 | loss: 0.708897864261826 | accuracy: 0.5492788461538454 \n",
      "Epoch 1 | Step 365 | loss: 0.7086127882134421 | accuracy: 0.5495291095890403 \n",
      "Epoch 1 | Step 366 | loss: 0.7084782273391553 | accuracy: 0.5496926229508189 \n",
      "Epoch 1 | Step 367 | loss: 0.7083858857362728 | accuracy: 0.5497700953678466 \n",
      "Epoch 1 | Step 368 | loss: 0.7082406154469301 | accuracy: 0.549974524456521 \n",
      "Epoch 1 | Step 369 | loss: 0.7081432229458152 | accuracy: 0.550093157181571 \n",
      "Epoch 1 | Step 370 | loss: 0.7080529399820273 | accuracy: 0.5502111486486478 \n",
      "Epoch 1 | Step 371 | loss: 0.7079643031978862 | accuracy: 0.550202156334231 \n",
      "Epoch 1 | Step 372 | loss: 0.7078953261977879 | accuracy: 0.5501092069892465 \n",
      "Epoch 1 | Step 373 | loss: 0.7078316210102457 | accuracy: 0.5501843163538865 \n",
      "Epoch 1 | Step 374 | loss: 0.7075781493900929 | accuracy: 0.5505514705882345 \n",
      "Epoch 1 | Step 375 | loss: 0.7074861923853554 | accuracy: 0.5505416666666659 \n",
      "Epoch 1 | Step 376 | loss: 0.7074932685874875 | accuracy: 0.5505734707446801 \n",
      "Epoch 1 | Step 377 | loss: 0.707524095985554 | accuracy: 0.5506879973474793 \n",
      "Epoch 1 | Step 378 | loss: 0.7074885552837732 | accuracy: 0.5505125661375653 \n",
      "Epoch 1 | Step 379 | loss: 0.7073299480616886 | accuracy: 0.5506266490765164 \n",
      "Epoch 1 | Step 380 | loss: 0.7074052559702017 | accuracy: 0.5505756578947361 \n",
      "Epoch 1 | Step 381 | loss: 0.7072560904532903 | accuracy: 0.5507299868766397 \n",
      "Epoch 1 | Step 382 | loss: 0.7071155276910169 | accuracy: 0.5510880235602087 \n",
      "Epoch 1 | Step 383 | loss: 0.7070160192235639 | accuracy: 0.5514441906005214 \n",
      "Epoch 1 | Step 384 | loss: 0.7070127890134849 | accuracy: 0.5513102213541659 \n",
      "Epoch 1 | Step 385 | loss: 0.7069523611626065 | accuracy: 0.5513798701298693 \n",
      "Epoch 1 | Step 386 | loss: 0.7068371266281046 | accuracy: 0.5516515544041443 \n",
      "Epoch 1 | Step 387 | loss: 0.7068517562338853 | accuracy: 0.5515988372093015 \n",
      "Epoch 1 | Step 388 | loss: 0.7066558448924228 | accuracy: 0.5518685567010301 \n",
      "Epoch 1 | Step 389 | loss: 0.7065750605649381 | accuracy: 0.5518155526992279 \n",
      "Epoch 1 | Step 390 | loss: 0.706504104687617 | accuracy: 0.5520032051282042 \n",
      "Epoch 1 | Step 391 | loss: 0.7064780199619203 | accuracy: 0.551950127877237 \n",
      "Epoch 1 | Step 392 | loss: 0.7063520905010552 | accuracy: 0.5520567602040808 \n",
      "Epoch 1 | Step 393 | loss: 0.7061284371004757 | accuracy: 0.5525604325699737 \n",
      "Epoch 1 | Step 394 | loss: 0.7061026267291323 | accuracy: 0.5525460025380702 \n",
      "Epoch 1 | Step 395 | loss: 0.7059557825704161 | accuracy: 0.5526503164556953 \n",
      "Epoch 1 | Step 396 | loss: 0.7058251783101243 | accuracy: 0.5528330176767667 \n",
      "Epoch 1 | Step 397 | loss: 0.7056633965194372 | accuracy: 0.5529754408060444 \n",
      "Epoch 1 | Step 398 | loss: 0.7055715049930551 | accuracy: 0.5529993718592956 \n",
      "Epoch 1 | Step 399 | loss: 0.705531939677427 | accuracy: 0.5529840225563901 \n",
      "Epoch 1 | Step 400 | loss: 0.705501624047756 | accuracy: 0.5530859374999991 \n",
      "Epoch 1 | Step 401 | loss: 0.7054981537293314 | accuracy: 0.5528756234413956 \n",
      "Epoch 1 | Step 402 | loss: 0.7052763836893866 | accuracy: 0.5533659825870638 \n",
      "Epoch 1 | Step 403 | loss: 0.7053174096952298 | accuracy: 0.5531907781921596 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.7177601456642151 | accuracy: 0.5 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6946043372154236 | accuracy: 0.5390625 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6786286433537801 | accuracy: 0.5677083333333334 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.682356521487236 | accuracy: 0.57421875 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6750442624092102 | accuracy: 0.584375 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6759551962216696 | accuracy: 0.5703125 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6768837060247149 | accuracy: 0.5736607142857143 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6776196658611298 | accuracy: 0.576171875 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6764745182461209 | accuracy: 0.5729166666666666 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6763993918895721 | accuracy: 0.5734375 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6733322956345298 | accuracy: 0.5809659090909091 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6683656672636668 | accuracy: 0.59375 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6633610221055838 | accuracy: 0.5997596153846154 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6619818764073508 | accuracy: 0.6037946428571429 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6608666896820068 | accuracy: 0.60625 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6617418229579926 | accuracy: 0.60546875 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6667029542081496 | accuracy: 0.5983455882352942 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6671087013350593 | accuracy: 0.5972222222222222 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6666687193669771 | accuracy: 0.5970394736842105 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6632873594760895 | accuracy: 0.60078125 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6627711199578785 | accuracy: 0.6026785714285714 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6629831655458971 | accuracy: 0.6029829545454546 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6630143030830051 | accuracy: 0.6046195652173914 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6628737126787504 | accuracy: 0.6041666666666667 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6638542842864991 | accuracy: 0.6012500000000001 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6633739127562597 | accuracy: 0.600360576923077 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6635865811948423 | accuracy: 0.5983796296296297 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6629163686718259 | accuracy: 0.5982142857142857 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6623161065167394 | accuracy: 0.5975215517241379 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6627042114734649 | accuracy: 0.5989583333333334 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6603315741785111 | accuracy: 0.6023185483870968 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6604249347001314 | accuracy: 0.60400390625 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6610490390748689 | accuracy: 0.6013257575757576 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6620522158987382 | accuracy: 0.5978860294117647 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6630802784647261 | accuracy: 0.5964285714285714 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6632939974466959 | accuracy: 0.5967881944444444 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6628296665243201 | accuracy: 0.5988175675675675 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6638647490426114 | accuracy: 0.5974506578947368 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6640249337905493 | accuracy: 0.5985576923076923 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6633906051516533 | accuracy: 0.599609375 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6634570229344252 | accuracy: 0.5994664634146342 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6626231599421728 | accuracy: 0.5997023809523809 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6619915906773057 | accuracy: 0.6017441860465116 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6618324193087491 | accuracy: 0.6036931818181818 \n",
      "Validation | Epoch 1 | Step 403 | loss: 0.6618020786179437 | accuracy: 0.6042874402470058 \n",
      "Epoch 2 | Step 404 | loss: 0.6417719721794128 | accuracy: 0.65625 \n",
      "Epoch 2 | Step 405 | loss: 0.6256987154483795 | accuracy: 0.65625 \n",
      "Epoch 2 | Step 406 | loss: 0.6350833773612976 | accuracy: 0.6458333333333334 \n",
      "Epoch 2 | Step 407 | loss: 0.6426508277654648 | accuracy: 0.6328125 \n",
      "Epoch 2 | Step 408 | loss: 0.6515061497688294 | accuracy: 0.621875 \n",
      "Epoch 2 | Step 409 | loss: 0.6536785264809927 | accuracy: 0.6197916666666666 \n",
      "Epoch 2 | Step 410 | loss: 0.6454386370522636 | accuracy: 0.6316964285714286 \n",
      "Epoch 2 | Step 411 | loss: 0.6437122672796249 | accuracy: 0.6328125 \n",
      "Epoch 2 | Step 412 | loss: 0.6455198923746744 | accuracy: 0.6302083333333334 \n",
      "Epoch 2 | Step 413 | loss: 0.6451643466949463 | accuracy: 0.6265625 \n",
      "Epoch 2 | Step 414 | loss: 0.6418809294700623 | accuracy: 0.6321022727272727 \n",
      "Epoch 2 | Step 415 | loss: 0.647206316391627 | accuracy: 0.6236979166666666 \n",
      "Epoch 2 | Step 416 | loss: 0.653418229176448 | accuracy: 0.6141826923076923 \n",
      "Epoch 2 | Step 417 | loss: 0.6488794769559588 | accuracy: 0.6194196428571429 \n",
      "Epoch 2 | Step 418 | loss: 0.649844209353129 | accuracy: 0.61875 \n",
      "Epoch 2 | Step 419 | loss: 0.6465761959552765 | accuracy: 0.6259765625 \n",
      "Epoch 2 | Step 420 | loss: 0.6467532550587374 | accuracy: 0.6185661764705882 \n",
      "Epoch 2 | Step 421 | loss: 0.6463438835408952 | accuracy: 0.6180555555555556 \n",
      "Epoch 2 | Step 422 | loss: 0.6443873016457808 | accuracy: 0.6200657894736842 \n",
      "Epoch 2 | Step 423 | loss: 0.6439033389091492 | accuracy: 0.62578125 \n",
      "Epoch 2 | Step 424 | loss: 0.6465913653373718 | accuracy: 0.6227678571428571 \n",
      "Epoch 2 | Step 425 | loss: 0.6467476974834095 | accuracy: 0.6193181818181818 \n",
      "Epoch 2 | Step 426 | loss: 0.6453691461811895 | accuracy: 0.6209239130434782 \n",
      "Epoch 2 | Step 427 | loss: 0.6480969289938608 | accuracy: 0.6191406249999999 \n",
      "Epoch 2 | Step 428 | loss: 0.650504183769226 | accuracy: 0.6137499999999999 \n",
      "Epoch 2 | Step 429 | loss: 0.6508018305668464 | accuracy: 0.6135817307692307 \n",
      "Epoch 2 | Step 430 | loss: 0.6534450517760383 | accuracy: 0.6099537037037037 \n",
      "Epoch 2 | Step 431 | loss: 0.6540273811135974 | accuracy: 0.6088169642857143 \n",
      "Epoch 2 | Step 432 | loss: 0.6543577498403089 | accuracy: 0.6082974137931034 \n",
      "Epoch 2 | Step 433 | loss: 0.6542019963264465 | accuracy: 0.6083333333333333 \n",
      "Epoch 2 | Step 434 | loss: 0.6525424757311421 | accuracy: 0.6098790322580645 \n",
      "Epoch 2 | Step 435 | loss: 0.6541172824800014 | accuracy: 0.60693359375 \n",
      "Epoch 2 | Step 436 | loss: 0.6554367777073022 | accuracy: 0.6051136363636364 \n",
      "Epoch 2 | Step 437 | loss: 0.6534346727763906 | accuracy: 0.6084558823529411 \n",
      "Epoch 2 | Step 438 | loss: 0.6511807884488787 | accuracy: 0.6133928571428572 \n",
      "Epoch 2 | Step 439 | loss: 0.6512590083811018 | accuracy: 0.61328125 \n",
      "Epoch 2 | Step 440 | loss: 0.6508198638220091 | accuracy: 0.6152871621621622 \n",
      "Epoch 2 | Step 441 | loss: 0.6515045213071924 | accuracy: 0.6143092105263158 \n",
      "Epoch 2 | Step 442 | loss: 0.6518271932235131 | accuracy: 0.6145833333333334 \n",
      "Epoch 2 | Step 443 | loss: 0.6515564069151878 | accuracy: 0.616015625 \n",
      "Epoch 2 | Step 444 | loss: 0.6526679280327587 | accuracy: 0.6131859756097561 \n",
      "Epoch 2 | Step 445 | loss: 0.6535187122367677 | accuracy: 0.6119791666666666 \n",
      "Epoch 2 | Step 446 | loss: 0.6524908625802328 | accuracy: 0.6137354651162791 \n",
      "Epoch 2 | Step 447 | loss: 0.6519386050376025 | accuracy: 0.6136363636363636 \n",
      "Epoch 2 | Step 448 | loss: 0.6513764593336318 | accuracy: 0.6145833333333334 \n",
      "Epoch 2 | Step 449 | loss: 0.6520471067532249 | accuracy: 0.6137907608695652 \n",
      "Epoch 2 | Step 450 | loss: 0.6533615982278864 | accuracy: 0.6117021276595744 \n",
      "Epoch 2 | Step 451 | loss: 0.6532484578589598 | accuracy: 0.6126302083333334 \n",
      "Epoch 2 | Step 452 | loss: 0.6531474359181463 | accuracy: 0.6119260204081632 \n",
      "Epoch 2 | Step 453 | loss: 0.6539946699142456 | accuracy: 0.610625 \n",
      "Epoch 2 | Step 454 | loss: 0.6535447976168465 | accuracy: 0.6118259803921569 \n",
      "Epoch 2 | Step 455 | loss: 0.6531055443561994 | accuracy: 0.6123798076923077 \n",
      "Epoch 2 | Step 456 | loss: 0.6523945803912181 | accuracy: 0.6137971698113207 \n",
      "Epoch 2 | Step 457 | loss: 0.6534068860389568 | accuracy: 0.6114004629629629 \n",
      "Epoch 2 | Step 458 | loss: 0.6534261866049333 | accuracy: 0.6113636363636363 \n",
      "Epoch 2 | Step 459 | loss: 0.653996969972338 | accuracy: 0.6116071428571429 \n",
      "Epoch 2 | Step 460 | loss: 0.6538326081476713 | accuracy: 0.6118421052631579 \n",
      "Epoch 2 | Step 461 | loss: 0.6546277537428099 | accuracy: 0.6115301724137931 \n",
      "Epoch 2 | Step 462 | loss: 0.6544647944175591 | accuracy: 0.6109639830508474 \n",
      "Epoch 2 | Step 463 | loss: 0.6551511337359747 | accuracy: 0.6104166666666667 \n",
      "Epoch 2 | Step 464 | loss: 0.6546425145180499 | accuracy: 0.6103995901639344 \n",
      "Epoch 2 | Step 465 | loss: 0.6543696647690188 | accuracy: 0.6108870967741935 \n",
      "Epoch 2 | Step 466 | loss: 0.654219889451587 | accuracy: 0.6118551587301587 \n",
      "Epoch 2 | Step 467 | loss: 0.6539268596097827 | accuracy: 0.611083984375 \n",
      "Epoch 2 | Step 468 | loss: 0.653745998786046 | accuracy: 0.6115384615384616 \n",
      "Epoch 2 | Step 469 | loss: 0.6539841763900988 | accuracy: 0.6112689393939394 \n",
      "Epoch 2 | Step 470 | loss: 0.6538348464823481 | accuracy: 0.6121735074626866 \n",
      "Epoch 2 | Step 471 | loss: 0.653806209564209 | accuracy: 0.6114430147058824 \n",
      "Epoch 2 | Step 472 | loss: 0.6547124014384504 | accuracy: 0.6098278985507246 \n",
      "Epoch 2 | Step 473 | loss: 0.6544384096349989 | accuracy: 0.6095982142857143 \n",
      "Epoch 2 | Step 474 | loss: 0.6544071427533324 | accuracy: 0.6095950704225352 \n",
      "Epoch 2 | Step 475 | loss: 0.6541506888137923 | accuracy: 0.6095920138888888 \n",
      "Epoch 2 | Step 476 | loss: 0.6542172276810424 | accuracy: 0.6095890410958904 \n",
      "Epoch 2 | Step 477 | loss: 0.6543826573603863 | accuracy: 0.6102195945945946 \n",
      "Epoch 2 | Step 478 | loss: 0.6547224919001262 | accuracy: 0.6091666666666666 \n",
      "Epoch 2 | Step 479 | loss: 0.6546866729071267 | accuracy: 0.609375 \n",
      "Epoch 2 | Step 480 | loss: 0.6541468841688974 | accuracy: 0.609577922077922 \n",
      "Epoch 2 | Step 481 | loss: 0.6548201388273485 | accuracy: 0.6079727564102564 \n",
      "Epoch 2 | Step 482 | loss: 0.654551109935664 | accuracy: 0.6079905063291139 \n",
      "Epoch 2 | Step 483 | loss: 0.655201541632414 | accuracy: 0.60703125 \n",
      "Epoch 2 | Step 484 | loss: 0.6547897973178346 | accuracy: 0.6080246913580247 \n",
      "Epoch 2 | Step 485 | loss: 0.6546719772059744 | accuracy: 0.6078506097560976 \n",
      "Epoch 2 | Step 486 | loss: 0.6542632314096015 | accuracy: 0.6086219879518073 \n",
      "Epoch 2 | Step 487 | loss: 0.6543056219816209 | accuracy: 0.6084449404761906 \n",
      "Epoch 2 | Step 488 | loss: 0.6543284605531132 | accuracy: 0.6088235294117648 \n",
      "Epoch 2 | Step 489 | loss: 0.6543652075667715 | accuracy: 0.6093750000000001 \n",
      "Epoch 2 | Step 490 | loss: 0.6548293054788964 | accuracy: 0.6090158045977012 \n",
      "Epoch 2 | Step 491 | loss: 0.6543631804260343 | accuracy: 0.6102627840909092 \n",
      "Epoch 2 | Step 492 | loss: 0.6540704751282597 | accuracy: 0.6109550561797754 \n",
      "Epoch 2 | Step 493 | loss: 0.6538981629742517 | accuracy: 0.6112847222222224 \n",
      "Epoch 2 | Step 494 | loss: 0.6534272262028287 | accuracy: 0.6121222527472528 \n",
      "Epoch 2 | Step 495 | loss: 0.653565507868062 | accuracy: 0.6119225543478262 \n",
      "Epoch 2 | Step 496 | loss: 0.6537107222823687 | accuracy: 0.6115591397849464 \n",
      "Epoch 2 | Step 497 | loss: 0.654082088394368 | accuracy: 0.610372340425532 \n",
      "Epoch 2 | Step 498 | loss: 0.6538821069817795 | accuracy: 0.6108552631578948 \n",
      "Epoch 2 | Step 499 | loss: 0.6543179421375196 | accuracy: 0.6095377604166667 \n",
      "Epoch 2 | Step 500 | loss: 0.6549408736917162 | accuracy: 0.6090528350515465 \n",
      "Epoch 2 | Step 501 | loss: 0.6547061618493528 | accuracy: 0.6095344387755104 \n",
      "Epoch 2 | Step 502 | loss: 0.6549061061155916 | accuracy: 0.6100063131313134 \n",
      "Epoch 2 | Step 503 | loss: 0.6544341123104096 | accuracy: 0.6101562500000002 \n",
      "Epoch 2 | Step 504 | loss: 0.6540459235115806 | accuracy: 0.6106126237623763 \n",
      "Epoch 2 | Step 505 | loss: 0.6540279902663886 | accuracy: 0.6106004901960785 \n",
      "Epoch 2 | Step 506 | loss: 0.6537850719053768 | accuracy: 0.6114987864077671 \n",
      "Epoch 2 | Step 507 | loss: 0.6538781752953162 | accuracy: 0.6114783653846155 \n",
      "Epoch 2 | Step 508 | loss: 0.6537023646490915 | accuracy: 0.6114583333333334 \n",
      "Epoch 2 | Step 509 | loss: 0.6539599586207911 | accuracy: 0.6107016509433963 \n",
      "Epoch 2 | Step 510 | loss: 0.6539798289815956 | accuracy: 0.6106892523364488 \n",
      "Epoch 2 | Step 511 | loss: 0.6542310510520581 | accuracy: 0.6103877314814816 \n",
      "Epoch 2 | Step 512 | loss: 0.6541007702503729 | accuracy: 0.6108084862385322 \n",
      "Epoch 2 | Step 513 | loss: 0.6547085014256564 | accuracy: 0.6102272727272728 \n",
      "Epoch 2 | Step 514 | loss: 0.6545487089200063 | accuracy: 0.610641891891892 \n",
      "Epoch 2 | Step 515 | loss: 0.6542339303663799 | accuracy: 0.611607142857143 \n",
      "Epoch 2 | Step 516 | loss: 0.6543611826094906 | accuracy: 0.6110342920353984 \n",
      "Epoch 2 | Step 517 | loss: 0.6550946366368678 | accuracy: 0.6096491228070177 \n",
      "Epoch 2 | Step 518 | loss: 0.6556370963221011 | accuracy: 0.6093750000000001 \n",
      "Epoch 2 | Step 519 | loss: 0.6555818822877161 | accuracy: 0.6095096982758622 \n",
      "Epoch 2 | Step 520 | loss: 0.6557246426231841 | accuracy: 0.6095085470085472 \n",
      "Epoch 2 | Step 521 | loss: 0.655740784386457 | accuracy: 0.6100370762711865 \n",
      "Epoch 2 | Step 522 | loss: 0.6553042681277299 | accuracy: 0.6106880252100841 \n",
      "Epoch 2 | Step 523 | loss: 0.6555012846986453 | accuracy: 0.6106770833333335 \n",
      "Epoch 2 | Step 524 | loss: 0.6555124260177297 | accuracy: 0.6109245867768596 \n",
      "Epoch 2 | Step 525 | loss: 0.6558845678313834 | accuracy: 0.6100153688524591 \n",
      "Epoch 2 | Step 526 | loss: 0.6564590393043146 | accuracy: 0.6093750000000001 \n",
      "Epoch 2 | Step 527 | loss: 0.6570069217874158 | accuracy: 0.6086189516129034 \n",
      "Epoch 2 | Step 528 | loss: 0.6569819707870483 | accuracy: 0.6083750000000001 \n",
      "Epoch 2 | Step 529 | loss: 0.6568627783230373 | accuracy: 0.6083829365079366 \n",
      "Epoch 2 | Step 530 | loss: 0.656876234557685 | accuracy: 0.6081446850393701 \n",
      "Epoch 2 | Step 531 | loss: 0.6565695586614311 | accuracy: 0.6087646484375001 \n",
      "Epoch 2 | Step 532 | loss: 0.6565643913986147 | accuracy: 0.6091327519379846 \n",
      "Epoch 2 | Step 533 | loss: 0.6564054755064157 | accuracy: 0.6097355769230769 \n",
      "Epoch 2 | Step 534 | loss: 0.6569916041752765 | accuracy: 0.6088979007633588 \n",
      "Epoch 2 | Step 535 | loss: 0.6569805145263672 | accuracy: 0.6090198863636364 \n",
      "Epoch 2 | Step 536 | loss: 0.6569969192483371 | accuracy: 0.6090225563909775 \n",
      "Epoch 2 | Step 537 | loss: 0.6569014872187999 | accuracy: 0.609258395522388 \n",
      "Epoch 2 | Step 538 | loss: 0.6566936152952688 | accuracy: 0.609837962962963 \n",
      "Epoch 2 | Step 539 | loss: 0.6566883053849724 | accuracy: 0.6104090073529411 \n",
      "Epoch 2 | Step 540 | loss: 0.6565048803378194 | accuracy: 0.6108576642335767 \n",
      "Epoch 2 | Step 541 | loss: 0.6563227133474486 | accuracy: 0.6108469202898551 \n",
      "Epoch 2 | Step 542 | loss: 0.6565158783103062 | accuracy: 0.6108363309352518 \n",
      "Epoch 2 | Step 543 | loss: 0.6562562691313878 | accuracy: 0.6111607142857143 \n",
      "Epoch 2 | Step 544 | loss: 0.6564736269044535 | accuracy: 0.61114804964539 \n",
      "Epoch 2 | Step 545 | loss: 0.6564313492304841 | accuracy: 0.6111355633802817 \n",
      "Epoch 2 | Step 546 | loss: 0.6565065929939695 | accuracy: 0.6112325174825176 \n",
      "Epoch 2 | Step 547 | loss: 0.6563535138136809 | accuracy: 0.6111111111111112 \n",
      "Epoch 2 | Step 548 | loss: 0.65620088988337 | accuracy: 0.6114224137931035 \n",
      "Epoch 2 | Step 549 | loss: 0.6561925954198182 | accuracy: 0.6113013698630136 \n",
      "Epoch 2 | Step 550 | loss: 0.6558653947447431 | accuracy: 0.6117134353741496 \n",
      "Epoch 2 | Step 551 | loss: 0.6559677679796475 | accuracy: 0.6112753378378377 \n",
      "Epoch 2 | Step 552 | loss: 0.6559555762566174 | accuracy: 0.6112625838926173 \n",
      "Epoch 2 | Step 553 | loss: 0.6558461789290109 | accuracy: 0.6113541666666665 \n",
      "Epoch 2 | Step 554 | loss: 0.6556361511053627 | accuracy: 0.6119619205298013 \n",
      "Epoch 2 | Step 555 | loss: 0.6558137249789738 | accuracy: 0.6118421052631579 \n",
      "Epoch 2 | Step 556 | loss: 0.6556540626326416 | accuracy: 0.6119281045751634 \n",
      "Epoch 2 | Step 557 | loss: 0.6553412029495486 | accuracy: 0.612114448051948 \n",
      "Epoch 2 | Step 558 | loss: 0.6552034797207 | accuracy: 0.6122983870967742 \n",
      "Epoch 2 | Step 559 | loss: 0.6554051576516565 | accuracy: 0.612479967948718 \n",
      "Epoch 2 | Step 560 | loss: 0.6556102952380087 | accuracy: 0.6122611464968153 \n",
      "Epoch 2 | Step 561 | loss: 0.6563170491894588 | accuracy: 0.6108583860759493 \n",
      "Epoch 2 | Step 562 | loss: 0.656373988907292 | accuracy: 0.6111438679245284 \n",
      "Epoch 2 | Step 563 | loss: 0.6564645260572431 | accuracy: 0.6108398437500001 \n",
      "Epoch 2 | Step 564 | loss: 0.6564922417913163 | accuracy: 0.61034549689441 \n",
      "Epoch 2 | Step 565 | loss: 0.6565331323647203 | accuracy: 0.6100501543209876 \n",
      "Epoch 2 | Step 566 | loss: 0.656207325999722 | accuracy: 0.6108128834355828 \n",
      "Epoch 2 | Step 567 | loss: 0.6561175773783426 | accuracy: 0.6109946646341463 \n",
      "Epoch 2 | Step 568 | loss: 0.6558810346054307 | accuracy: 0.6115530303030303 \n",
      "Epoch 2 | Step 569 | loss: 0.6556184970470794 | accuracy: 0.6120105421686747 \n",
      "Epoch 2 | Step 570 | loss: 0.6554767960559821 | accuracy: 0.6121818862275449 \n",
      "Epoch 2 | Step 571 | loss: 0.6558663110647881 | accuracy: 0.6117931547619048 \n",
      "Epoch 2 | Step 572 | loss: 0.6556139263881027 | accuracy: 0.6119637573964497 \n",
      "Epoch 2 | Step 573 | loss: 0.6553843396551468 | accuracy: 0.6122242647058823 \n",
      "Epoch 2 | Step 574 | loss: 0.6549307920082269 | accuracy: 0.6128472222222222 \n",
      "Epoch 2 | Step 575 | loss: 0.6547999052807341 | accuracy: 0.6133720930232558 \n",
      "Epoch 2 | Step 576 | loss: 0.6544427489269674 | accuracy: 0.6138908959537572 \n",
      "Epoch 2 | Step 577 | loss: 0.6544561701259393 | accuracy: 0.6134159482758621 \n",
      "Epoch 2 | Step 578 | loss: 0.6544424891471862 | accuracy: 0.6133928571428572 \n",
      "Epoch 2 | Step 579 | loss: 0.6542317003689028 | accuracy: 0.6138139204545455 \n",
      "Epoch 2 | Step 580 | loss: 0.6544824791493388 | accuracy: 0.6135240112994351 \n",
      "Epoch 2 | Step 581 | loss: 0.6546088724993587 | accuracy: 0.6131495786516855 \n",
      "Epoch 2 | Step 582 | loss: 0.6544366372364192 | accuracy: 0.6130412011173185 \n",
      "Epoch 2 | Step 583 | loss: 0.6543450858857895 | accuracy: 0.6129340277777778 \n",
      "Epoch 2 | Step 584 | loss: 0.6543322511799426 | accuracy: 0.6132596685082874 \n",
      "Epoch 2 | Step 585 | loss: 0.6544258398014109 | accuracy: 0.613066620879121 \n",
      "Epoch 2 | Step 586 | loss: 0.6538638876435534 | accuracy: 0.6143271857923499 \n",
      "Epoch 2 | Step 587 | loss: 0.6536959510134613 | accuracy: 0.6143002717391306 \n",
      "Epoch 2 | Step 588 | loss: 0.653557408500362 | accuracy: 0.6145270270270272 \n",
      "Epoch 2 | Step 589 | loss: 0.6532730001916167 | accuracy: 0.6147513440860216 \n",
      "Epoch 2 | Step 590 | loss: 0.6532308554904346 | accuracy: 0.6144719251336899 \n",
      "Epoch 2 | Step 591 | loss: 0.6533460880213595 | accuracy: 0.6141954787234043 \n",
      "Epoch 2 | Step 592 | loss: 0.6529233815178038 | accuracy: 0.6149966931216932 \n",
      "Epoch 2 | Step 593 | loss: 0.6528827309608459 | accuracy: 0.6148848684210528 \n",
      "Epoch 2 | Step 594 | loss: 0.6526588856861854 | accuracy: 0.6148560209424087 \n",
      "Epoch 2 | Step 595 | loss: 0.6526085097963611 | accuracy: 0.614908854166667 \n",
      "Epoch 2 | Step 596 | loss: 0.6520699556009757 | accuracy: 0.6156897668393785 \n",
      "Epoch 2 | Step 597 | loss: 0.6520703290541148 | accuracy: 0.6159793814432992 \n",
      "Epoch 2 | Step 598 | loss: 0.6519990746791546 | accuracy: 0.6161858974358977 \n",
      "Epoch 2 | Step 599 | loss: 0.6517294867306339 | accuracy: 0.6166294642857145 \n",
      "Epoch 2 | Step 600 | loss: 0.6515801028551789 | accuracy: 0.616671954314721 \n",
      "Epoch 2 | Step 601 | loss: 0.6512181063493093 | accuracy: 0.6169507575757578 \n",
      "Epoch 2 | Step 602 | loss: 0.6510494656898268 | accuracy: 0.6174623115577892 \n",
      "Epoch 2 | Step 603 | loss: 0.6506995579600334 | accuracy: 0.6178125000000002 \n",
      "Epoch 2 | Step 604 | loss: 0.6510729033555558 | accuracy: 0.617537313432836 \n",
      "Epoch 2 | Step 605 | loss: 0.6508775598341876 | accuracy: 0.6178063118811883 \n",
      "Epoch 2 | Step 606 | loss: 0.6511814773376352 | accuracy: 0.6175338669950741 \n",
      "Epoch 2 | Step 607 | loss: 0.6511959325449139 | accuracy: 0.6178002450980393 \n",
      "Epoch 2 | Step 608 | loss: 0.6509747415054136 | accuracy: 0.6182164634146343 \n",
      "Epoch 2 | Step 609 | loss: 0.6510803415937331 | accuracy: 0.617794296116505 \n",
      "Epoch 2 | Step 610 | loss: 0.6515433033883283 | accuracy: 0.6173762077294688 \n",
      "Epoch 2 | Step 611 | loss: 0.651703785531796 | accuracy: 0.6169621394230772 \n",
      "Epoch 2 | Step 612 | loss: 0.6517192612994801 | accuracy: 0.6171501196172251 \n",
      "Epoch 2 | Step 613 | loss: 0.6517310761270069 | accuracy: 0.617261904761905 \n",
      "Epoch 2 | Step 614 | loss: 0.6517233727102596 | accuracy: 0.617224526066351 \n",
      "Epoch 2 | Step 615 | loss: 0.6517037077332443 | accuracy: 0.6172612028301889 \n",
      "Epoch 2 | Step 616 | loss: 0.6514224494007271 | accuracy: 0.6176643192488266 \n",
      "Epoch 2 | Step 617 | loss: 0.6513886485144357 | accuracy: 0.6179176401869162 \n",
      "Epoch 2 | Step 618 | loss: 0.6514674361362014 | accuracy: 0.6177325581395351 \n",
      "Epoch 2 | Step 619 | loss: 0.6515249803110406 | accuracy: 0.617693865740741 \n",
      "Epoch 2 | Step 620 | loss: 0.650996528737556 | accuracy: 0.6184475806451616 \n",
      "Epoch 2 | Step 621 | loss: 0.6510477979248817 | accuracy: 0.6184059633027525 \n",
      "Epoch 2 | Step 622 | loss: 0.6510121190928977 | accuracy: 0.6185074200913244 \n",
      "Epoch 2 | Step 623 | loss: 0.6509236920963634 | accuracy: 0.6186789772727276 \n",
      "Epoch 2 | Step 624 | loss: 0.6508742309263928 | accuracy: 0.6187075791855207 \n",
      "Epoch 2 | Step 625 | loss: 0.6508978589161022 | accuracy: 0.6187359234234237 \n",
      "Epoch 2 | Step 626 | loss: 0.6506621760103201 | accuracy: 0.618834080717489 \n",
      "Epoch 2 | Step 627 | loss: 0.6503192529614482 | accuracy: 0.6195591517857145 \n",
      "Epoch 2 | Step 628 | loss: 0.6504468782742818 | accuracy: 0.6195138888888891 \n",
      "Epoch 2 | Step 629 | loss: 0.6503380246921978 | accuracy: 0.6198838495575224 \n",
      "Epoch 2 | Step 630 | loss: 0.6502134631908938 | accuracy: 0.6198375550660795 \n",
      "Epoch 2 | Step 631 | loss: 0.6500190101694643 | accuracy: 0.6202028508771932 \n",
      "Epoch 2 | Step 632 | loss: 0.6500642057589568 | accuracy: 0.6204284934497819 \n",
      "Epoch 2 | Step 633 | loss: 0.6501334636107735 | accuracy: 0.6207201086956524 \n",
      "Epoch 2 | Step 634 | loss: 0.6496791798315007 | accuracy: 0.6212797619047622 \n",
      "Epoch 2 | Step 635 | loss: 0.6495438120488463 | accuracy: 0.6215651939655175 \n",
      "Epoch 2 | Step 636 | loss: 0.6492872322577775 | accuracy: 0.6220493562231763 \n",
      "Epoch 2 | Step 637 | loss: 0.6493174107665689 | accuracy: 0.6222622863247865 \n",
      "Epoch 2 | Step 638 | loss: 0.6491849135845266 | accuracy: 0.6224069148936172 \n",
      "Epoch 2 | Step 639 | loss: 0.6487651204658766 | accuracy: 0.6230799788135596 \n",
      "Epoch 2 | Step 640 | loss: 0.6486467248779811 | accuracy: 0.6232858649789031 \n",
      "Epoch 2 | Step 641 | loss: 0.6485690071302301 | accuracy: 0.6234900210084036 \n",
      "Epoch 2 | Step 642 | loss: 0.6483456195647747 | accuracy: 0.6235617154811718 \n",
      "Epoch 2 | Step 643 | loss: 0.6481310456991196 | accuracy: 0.6238932291666669 \n",
      "Epoch 2 | Step 644 | loss: 0.6478494005084532 | accuracy: 0.6241571576763488 \n",
      "Epoch 2 | Step 645 | loss: 0.6475414052482479 | accuracy: 0.6245480371900829 \n",
      "Epoch 2 | Step 646 | loss: 0.6474348834022082 | accuracy: 0.6248070987654323 \n",
      "Epoch 2 | Step 647 | loss: 0.6475305476638137 | accuracy: 0.6245517418032789 \n",
      "Epoch 2 | Step 648 | loss: 0.6473231858136702 | accuracy: 0.6250000000000002 \n",
      "Epoch 2 | Step 649 | loss: 0.6472073081063061 | accuracy: 0.6248094512195125 \n",
      "Epoch 2 | Step 650 | loss: 0.6468264489521381 | accuracy: 0.6251897773279355 \n",
      "Epoch 2 | Step 651 | loss: 0.6468283493191965 | accuracy: 0.6251890120967745 \n",
      "Epoch 2 | Step 652 | loss: 0.6467301613355736 | accuracy: 0.6254392570281126 \n",
      "Epoch 2 | Step 653 | loss: 0.646519711971283 | accuracy: 0.6256875000000002 \n",
      "Epoch 2 | Step 654 | loss: 0.6464194826395863 | accuracy: 0.6258715139442234 \n",
      "Epoch 2 | Step 655 | loss: 0.646454896245684 | accuracy: 0.6257440476190479 \n",
      "Epoch 2 | Step 656 | loss: 0.6463000941653496 | accuracy: 0.626049901185771 \n",
      "Epoch 2 | Step 657 | loss: 0.6461778165787224 | accuracy: 0.6262303149606302 \n",
      "Epoch 2 | Step 658 | loss: 0.6462366508502586 | accuracy: 0.6261029411764708 \n",
      "Epoch 2 | Step 659 | loss: 0.6460474876221269 | accuracy: 0.6264038085937502 \n",
      "Epoch 2 | Step 660 | loss: 0.6459191647948922 | accuracy: 0.6264591439688718 \n",
      "Epoch 2 | Step 661 | loss: 0.6457822052545326 | accuracy: 0.6266957364341087 \n",
      "Epoch 2 | Step 662 | loss: 0.6455863670492724 | accuracy: 0.6269908301158303 \n",
      "Epoch 2 | Step 663 | loss: 0.6452768078217139 | accuracy: 0.6274639423076925 \n",
      "Epoch 2 | Step 664 | loss: 0.6453471284259782 | accuracy: 0.6271551724137934 \n",
      "Epoch 2 | Step 665 | loss: 0.6451770053565047 | accuracy: 0.627266221374046 \n",
      "Epoch 2 | Step 666 | loss: 0.6450420529670136 | accuracy: 0.6274952471482892 \n",
      "Epoch 2 | Step 667 | loss: 0.6450914602839586 | accuracy: 0.6275449810606063 \n",
      "Epoch 2 | Step 668 | loss: 0.6450262251889931 | accuracy: 0.6274764150943398 \n",
      "Epoch 2 | Step 669 | loss: 0.6446608143641537 | accuracy: 0.6281132518796995 \n",
      "Epoch 2 | Step 670 | loss: 0.6443472009026603 | accuracy: 0.6285697565543074 \n",
      "Epoch 2 | Step 671 | loss: 0.6444292702336809 | accuracy: 0.6284981343283584 \n",
      "Epoch 2 | Step 672 | loss: 0.6443180929329315 | accuracy: 0.6287174721189593 \n",
      "Epoch 2 | Step 673 | loss: 0.6443823143287941 | accuracy: 0.6286458333333336 \n",
      "Epoch 2 | Step 674 | loss: 0.644214375432567 | accuracy: 0.629093634686347 \n",
      "Epoch 2 | Step 675 | loss: 0.6439540121046936 | accuracy: 0.6294232536764708 \n",
      "Epoch 2 | Step 676 | loss: 0.6437150028162387 | accuracy: 0.6295215201465204 \n",
      "Epoch 2 | Step 677 | loss: 0.643454807083102 | accuracy: 0.6297901459854017 \n",
      "Epoch 2 | Step 678 | loss: 0.6433284971930764 | accuracy: 0.6300568181818185 \n",
      "Epoch 2 | Step 679 | loss: 0.6431846864845442 | accuracy: 0.6303781702898554 \n",
      "Epoch 2 | Step 680 | loss: 0.6430672080077849 | accuracy: 0.6304715703971123 \n",
      "Epoch 2 | Step 681 | loss: 0.6430244745968057 | accuracy: 0.6302832733812954 \n",
      "Epoch 2 | Step 682 | loss: 0.6430848401079896 | accuracy: 0.6303203405017925 \n",
      "Epoch 2 | Step 683 | loss: 0.6430481927735465 | accuracy: 0.630133928571429 \n",
      "Epoch 2 | Step 684 | loss: 0.6428549145464371 | accuracy: 0.6303936832740218 \n",
      "Epoch 2 | Step 685 | loss: 0.6428466219428584 | accuracy: 0.6304853723404259 \n",
      "Epoch 2 | Step 686 | loss: 0.6427766328986879 | accuracy: 0.6305212014134279 \n",
      "Epoch 2 | Step 687 | loss: 0.6424664261055665 | accuracy: 0.6308868838028173 \n",
      "Epoch 2 | Step 688 | loss: 0.642353726060767 | accuracy: 0.6311403508771933 \n",
      "Epoch 2 | Step 689 | loss: 0.6423321647660717 | accuracy: 0.6313374125874129 \n",
      "Epoch 2 | Step 690 | loss: 0.6419524895189532 | accuracy: 0.6316964285714289 \n",
      "Epoch 2 | Step 691 | loss: 0.6418669033381675 | accuracy: 0.6315646701388893 \n",
      "Epoch 2 | Step 692 | loss: 0.6419184418285595 | accuracy: 0.6315419550173015 \n",
      "Epoch 2 | Step 693 | loss: 0.6420366108417512 | accuracy: 0.6315732758620695 \n",
      "Epoch 2 | Step 694 | loss: 0.6417164255663292 | accuracy: 0.6319802405498287 \n",
      "Epoch 2 | Step 695 | loss: 0.6415820862740688 | accuracy: 0.6321168664383566 \n",
      "Epoch 2 | Step 696 | loss: 0.641357402549262 | accuracy: 0.6324125426621166 \n",
      "Epoch 2 | Step 697 | loss: 0.6410977720808821 | accuracy: 0.632759353741497 \n",
      "Epoch 2 | Step 698 | loss: 0.641440620664823 | accuracy: 0.6325741525423734 \n",
      "Epoch 2 | Step 699 | loss: 0.6414480473141413 | accuracy: 0.6326013513513519 \n",
      "Epoch 2 | Step 700 | loss: 0.6412950673890033 | accuracy: 0.6326809764309769 \n",
      "Epoch 2 | Step 701 | loss: 0.6411284056285884 | accuracy: 0.6327076342281884 \n",
      "Epoch 2 | Step 702 | loss: 0.6411535556499774 | accuracy: 0.6327863712374586 \n",
      "Epoch 2 | Step 703 | loss: 0.6407834378878275 | accuracy: 0.6330729166666671 \n",
      "Epoch 2 | Step 704 | loss: 0.6408596163572267 | accuracy: 0.6329941860465121 \n",
      "Epoch 2 | Step 705 | loss: 0.640749900546295 | accuracy: 0.6329677152317885 \n",
      "Epoch 2 | Step 706 | loss: 0.6406978892021054 | accuracy: 0.632889851485149 \n",
      "Epoch 2 | Step 707 | loss: 0.6405886976342452 | accuracy: 0.6329152960526321 \n",
      "Epoch 2 | Step 708 | loss: 0.6406525129177532 | accuracy: 0.6325819672131152 \n",
      "Epoch 2 | Step 709 | loss: 0.6404442294360766 | accuracy: 0.6326593137254907 \n",
      "Epoch 2 | Step 710 | loss: 0.6399212471825293 | accuracy: 0.6332451140065152 \n",
      "Epoch 2 | Step 711 | loss: 0.6398210136534332 | accuracy: 0.6334212662337668 \n",
      "Epoch 2 | Step 712 | loss: 0.6396430647874728 | accuracy: 0.633798543689321 \n",
      "Epoch 2 | Step 713 | loss: 0.6395355489946182 | accuracy: 0.6339213709677425 \n",
      "Epoch 2 | Step 714 | loss: 0.6392493008417333 | accuracy: 0.6342443729903543 \n",
      "Epoch 2 | Step 715 | loss: 0.639168908007634 | accuracy: 0.6343149038461545 \n",
      "Epoch 2 | Step 716 | loss: 0.6389961766358764 | accuracy: 0.6345347444089463 \n",
      "Epoch 2 | Step 717 | loss: 0.6389011681839161 | accuracy: 0.6346536624203828 \n",
      "Epoch 2 | Step 718 | loss: 0.6384094401011392 | accuracy: 0.6350694444444451 \n",
      "Epoch 2 | Step 719 | loss: 0.6383136376927171 | accuracy: 0.6350375791139248 \n",
      "Epoch 2 | Step 720 | loss: 0.6382948560669595 | accuracy: 0.6350552050473194 \n",
      "Epoch 2 | Step 721 | loss: 0.6381120432472828 | accuracy: 0.6351709905660385 \n",
      "Epoch 2 | Step 722 | loss: 0.6380416670563078 | accuracy: 0.6353350313479632 \n",
      "Epoch 2 | Step 723 | loss: 0.6379699187353253 | accuracy: 0.6355468750000008 \n",
      "Epoch 2 | Step 724 | loss: 0.6378734809958674 | accuracy: 0.6356113707165117 \n",
      "Epoch 2 | Step 725 | loss: 0.6379633020169986 | accuracy: 0.6356754658385102 \n",
      "Epoch 2 | Step 726 | loss: 0.6379857461887984 | accuracy: 0.635642414860682 \n",
      "Epoch 2 | Step 727 | loss: 0.6378537399901283 | accuracy: 0.6357542438271614 \n",
      "Epoch 2 | Step 728 | loss: 0.637742383480072 | accuracy: 0.6359134615384624 \n",
      "Epoch 2 | Step 729 | loss: 0.6378150267835043 | accuracy: 0.6358799846625776 \n",
      "Epoch 2 | Step 730 | loss: 0.638060811280475 | accuracy: 0.6357511467889917 \n",
      "Epoch 2 | Step 731 | loss: 0.6378946146223602 | accuracy: 0.6360518292682935 \n",
      "Epoch 2 | Step 732 | loss: 0.637688369917652 | accuracy: 0.6363031914893625 \n",
      "Epoch 2 | Step 733 | loss: 0.6375434519666612 | accuracy: 0.6364109848484857 \n",
      "Epoch 2 | Step 734 | loss: 0.6374772639433061 | accuracy: 0.6365653323262849 \n",
      "Epoch 2 | Step 735 | loss: 0.6372999114444455 | accuracy: 0.6369540662650611 \n",
      "Epoch 2 | Step 736 | loss: 0.6371246114507451 | accuracy: 0.6371527777777787 \n",
      "Epoch 2 | Step 737 | loss: 0.6370510382209709 | accuracy: 0.63744386227545 \n",
      "Epoch 2 | Step 738 | loss: 0.6370546412112107 | accuracy: 0.6374067164179114 \n",
      "Epoch 2 | Step 739 | loss: 0.6370692444699151 | accuracy: 0.6375558035714295 \n",
      "Epoch 2 | Step 740 | loss: 0.6369809089145604 | accuracy: 0.6376112759643926 \n",
      "Epoch 2 | Step 741 | loss: 0.636900396918404 | accuracy: 0.6378051035502967 \n",
      "Epoch 2 | Step 742 | loss: 0.6367826853881543 | accuracy: 0.6379056047197649 \n",
      "Epoch 2 | Step 743 | loss: 0.6367173713796279 | accuracy: 0.6380514705882361 \n",
      "Epoch 2 | Step 744 | loss: 0.6364307316167613 | accuracy: 0.6383797653958951 \n",
      "Epoch 2 | Step 745 | loss: 0.6364649971674757 | accuracy: 0.6381122076023399 \n",
      "Epoch 2 | Step 746 | loss: 0.6363485750929607 | accuracy: 0.6383928571428578 \n",
      "Epoch 2 | Step 747 | loss: 0.6363450125899426 | accuracy: 0.6382630813953494 \n",
      "Epoch 2 | Step 748 | loss: 0.6360664099886797 | accuracy: 0.6385416666666671 \n",
      "Epoch 2 | Step 749 | loss: 0.635969542699053 | accuracy: 0.6386380057803472 \n",
      "Epoch 2 | Step 750 | loss: 0.6357688410824932 | accuracy: 0.6389589337175796 \n",
      "Epoch 2 | Step 751 | loss: 0.6356700300827793 | accuracy: 0.6391433189655176 \n",
      "Epoch 2 | Step 752 | loss: 0.6353726802036209 | accuracy: 0.6393714183381092 \n",
      "Epoch 2 | Step 753 | loss: 0.6354413545131683 | accuracy: 0.6392410714285718 \n",
      "Epoch 2 | Step 754 | loss: 0.6351730916914438 | accuracy: 0.63960113960114 \n",
      "Epoch 2 | Step 755 | loss: 0.6351322428407994 | accuracy: 0.6396928267045457 \n",
      "Epoch 2 | Step 756 | loss: 0.6349826914392855 | accuracy: 0.6397397308781873 \n",
      "Epoch 2 | Step 757 | loss: 0.6349821663172233 | accuracy: 0.6397863700564975 \n",
      "Epoch 2 | Step 758 | loss: 0.6347832085381092 | accuracy: 0.6399647887323947 \n",
      "Epoch 2 | Step 759 | loss: 0.6343607019340055 | accuracy: 0.6404933286516857 \n",
      "Epoch 2 | Step 760 | loss: 0.6343114019608966 | accuracy: 0.6404936974789919 \n",
      "Epoch 2 | Step 761 | loss: 0.6342834491470009 | accuracy: 0.6404940642458103 \n",
      "Epoch 2 | Step 762 | loss: 0.6341924203305525 | accuracy: 0.6404509052924794 \n",
      "Epoch 2 | Step 763 | loss: 0.6341549955308439 | accuracy: 0.6404079861111114 \n",
      "Epoch 2 | Step 764 | loss: 0.6342786490256768 | accuracy: 0.640408587257618 \n",
      "Epoch 2 | Step 765 | loss: 0.6341362688587516 | accuracy: 0.6405818370165748 \n",
      "Epoch 2 | Step 766 | loss: 0.6342864666267533 | accuracy: 0.6404097796143253 \n",
      "Epoch 2 | Step 767 | loss: 0.6338738758157899 | accuracy: 0.6407967032967036 \n",
      "Epoch 2 | Step 768 | loss: 0.6337419225745007 | accuracy: 0.6408390410958907 \n",
      "Epoch 2 | Step 769 | loss: 0.6335813087192391 | accuracy: 0.6409665300546451 \n",
      "Epoch 2 | Step 770 | loss: 0.6335584550527528 | accuracy: 0.6410933242506816 \n",
      "Epoch 2 | Step 771 | loss: 0.6332902493684189 | accuracy: 0.6414317255434786 \n",
      "Epoch 2 | Step 772 | loss: 0.6332747269129044 | accuracy: 0.6415989159891602 \n",
      "Epoch 2 | Step 773 | loss: 0.6331983376193693 | accuracy: 0.6415962837837841 \n",
      "Epoch 2 | Step 774 | loss: 0.6330642512223793 | accuracy: 0.6418042452830192 \n",
      "Epoch 2 | Step 775 | loss: 0.6330498051579282 | accuracy: 0.6417170698924735 \n",
      "Epoch 2 | Step 776 | loss: 0.6328404900535504 | accuracy: 0.6420492627345847 \n",
      "Epoch 2 | Step 777 | loss: 0.632637988437306 | accuracy: 0.6422961229946527 \n",
      "Epoch 2 | Step 778 | loss: 0.6326481548945111 | accuracy: 0.6422916666666669 \n",
      "Epoch 2 | Step 779 | loss: 0.6327512763599134 | accuracy: 0.6422041223404258 \n",
      "Epoch 2 | Step 780 | loss: 0.6327431918139168 | accuracy: 0.6421584880636607 \n",
      "Epoch 2 | Step 781 | loss: 0.6327578631973773 | accuracy: 0.6421130952380955 \n",
      "Epoch 2 | Step 782 | loss: 0.6325573067237332 | accuracy: 0.6422328496042219 \n",
      "Epoch 2 | Step 783 | loss: 0.6325564011147149 | accuracy: 0.6422697368421055 \n",
      "Epoch 2 | Step 784 | loss: 0.6324155064705477 | accuracy: 0.6423474409448822 \n",
      "Epoch 2 | Step 785 | loss: 0.6323283271015627 | accuracy: 0.6424656413612568 \n",
      "Epoch 2 | Step 786 | loss: 0.6322971443905844 | accuracy: 0.6426648172323762 \n",
      "Epoch 2 | Step 787 | loss: 0.6323682035629948 | accuracy: 0.6426188151041669 \n",
      "Epoch 2 | Step 788 | loss: 0.6323040959122893 | accuracy: 0.6428165584415586 \n",
      "Epoch 2 | Step 789 | loss: 0.6324244836451476 | accuracy: 0.6427299222797929 \n",
      "Epoch 2 | Step 790 | loss: 0.6324091940271146 | accuracy: 0.6427244832041346 \n",
      "Epoch 2 | Step 791 | loss: 0.6323511571306544 | accuracy: 0.6427190721649487 \n",
      "Epoch 2 | Step 792 | loss: 0.6323681790908383 | accuracy: 0.6426735218509 \n",
      "Epoch 2 | Step 793 | loss: 0.6322841454774907 | accuracy: 0.6427483974358976 \n",
      "Epoch 2 | Step 794 | loss: 0.6321524752070533 | accuracy: 0.6429028132992329 \n",
      "Epoch 2 | Step 795 | loss: 0.632178062230957 | accuracy: 0.6428970025510207 \n",
      "Epoch 2 | Step 796 | loss: 0.6319295921701816 | accuracy: 0.6431695292620868 \n",
      "Epoch 2 | Step 797 | loss: 0.6320908443274234 | accuracy: 0.6428854695431475 \n",
      "Epoch 2 | Step 798 | loss: 0.6319595895236053 | accuracy: 0.6429984177215192 \n",
      "Epoch 2 | Step 799 | loss: 0.6318479884754529 | accuracy: 0.6430713383838386 \n",
      "Epoch 2 | Step 800 | loss: 0.631626873532831 | accuracy: 0.6432226070528969 \n",
      "Epoch 2 | Step 801 | loss: 0.6315552975664187 | accuracy: 0.6433731155778898 \n",
      "Epoch 2 | Step 802 | loss: 0.63145503334533 | accuracy: 0.6436011904761908 \n",
      "Epoch 2 | Step 803 | loss: 0.6314158409833908 | accuracy: 0.6437500000000003 \n",
      "Epoch 2 | Step 804 | loss: 0.6314088247363406 | accuracy: 0.6438980673316711 \n",
      "Epoch 2 | Step 805 | loss: 0.6312016672755948 | accuracy: 0.6442008706467665 \n",
      "Epoch 2 | Step 806 | loss: 0.6313110056053616 | accuracy: 0.6439713998408829 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6755146980285645 | accuracy: 0.640625 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6331721842288971 | accuracy: 0.6640625 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6438021858533224 | accuracy: 0.6614583333333334 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6362334042787552 | accuracy: 0.6640625 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6252438426017761 | accuracy: 0.684375 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6267896691958109 | accuracy: 0.6770833333333334 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6283574019159589 | accuracy: 0.6741071428571429 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6260345578193665 | accuracy: 0.66796875 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6250492533047994 | accuracy: 0.6666666666666666 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6217591226100921 | accuracy: 0.671875 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.618772728876634 | accuracy: 0.671875 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6155492415030798 | accuracy: 0.67578125 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6090056666961083 | accuracy: 0.6802884615384616 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6044460833072662 | accuracy: 0.6841517857142857 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6036491314570109 | accuracy: 0.6822916666666666 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6066785901784897 | accuracy: 0.677734375 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6137210060568417 | accuracy: 0.6727941176470589 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6149808069070181 | accuracy: 0.6701388888888888 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6102778033206337 | accuracy: 0.6751644736842105 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6071791619062423 | accuracy: 0.67734375 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6051126917203268 | accuracy: 0.6785714285714286 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.603771299123764 | accuracy: 0.6789772727272727 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6042714144872583 | accuracy: 0.6779891304347826 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6058709472417833 | accuracy: 0.67578125 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6072036981582642 | accuracy: 0.671875 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.606099131015631 | accuracy: 0.6736778846153846 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6034496603188692 | accuracy: 0.6753472222222222 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.6015783101320267 | accuracy: 0.6780133928571429 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5992050376431696 | accuracy: 0.681573275862069 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5979154090086619 | accuracy: 0.6833333333333333 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5936225777672183 | accuracy: 0.688508064516129 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5938347773626447 | accuracy: 0.68994140625 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5945375444311084 | accuracy: 0.6884469696969697 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5964483872932547 | accuracy: 0.6838235294117647 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5981521052973611 | accuracy: 0.6830357142857143 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5981733062201076 | accuracy: 0.6831597222222222 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5984606686476115 | accuracy: 0.6824324324324325 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5993422905081197 | accuracy: 0.6817434210526315 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5989890778676058 | accuracy: 0.6810897435897435 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5971742980182172 | accuracy: 0.6820312499999999 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5975070762925032 | accuracy: 0.6810213414634144 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5964438922348476 | accuracy: 0.6811755952380951 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5959625167902126 | accuracy: 0.6816860465116278 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5974726588888601 | accuracy: 0.6800426136363635 \n",
      "Validation | Epoch 2 | Step 806 | loss: 0.5985314190387726 | accuracy: 0.6794233096970451 \n",
      "Epoch 3 | Step 807 | loss: 0.5915085673332214 | accuracy: 0.703125 \n",
      "Epoch 3 | Step 808 | loss: 0.5645251870155334 | accuracy: 0.7421875 \n",
      "Epoch 3 | Step 809 | loss: 0.578703244527181 | accuracy: 0.7135416666666666 \n",
      "Epoch 3 | Step 810 | loss: 0.5858290791511536 | accuracy: 0.703125 \n",
      "Epoch 3 | Step 811 | loss: 0.5870128989219665 | accuracy: 0.70625 \n",
      "Epoch 3 | Step 812 | loss: 0.5888847609361013 | accuracy: 0.6979166666666666 \n",
      "Epoch 3 | Step 813 | loss: 0.5804337433406285 | accuracy: 0.7008928571428571 \n",
      "Epoch 3 | Step 814 | loss: 0.579103410243988 | accuracy: 0.701171875 \n",
      "Epoch 3 | Step 815 | loss: 0.5826889276504517 | accuracy: 0.6944444444444444 \n",
      "Epoch 3 | Step 816 | loss: 0.5841221511363983 | accuracy: 0.6890625 \n",
      "Epoch 3 | Step 817 | loss: 0.5788968422196128 | accuracy: 0.6946022727272727 \n",
      "Epoch 3 | Step 818 | loss: 0.58258023361365 | accuracy: 0.6888020833333334 \n",
      "Epoch 3 | Step 819 | loss: 0.587615810907804 | accuracy: 0.6850961538461539 \n",
      "Epoch 3 | Step 820 | loss: 0.5811510043484824 | accuracy: 0.6919642857142857 \n",
      "Epoch 3 | Step 821 | loss: 0.5837916533152262 | accuracy: 0.6885416666666667 \n",
      "Epoch 3 | Step 822 | loss: 0.5795941427350044 | accuracy: 0.6923828125 \n",
      "Epoch 3 | Step 823 | loss: 0.5767663822454565 | accuracy: 0.6939338235294118 \n",
      "Epoch 3 | Step 824 | loss: 0.5776102079285516 | accuracy: 0.6953125 \n",
      "Epoch 3 | Step 825 | loss: 0.5753157891725239 | accuracy: 0.696546052631579 \n",
      "Epoch 3 | Step 826 | loss: 0.5770326524972915 | accuracy: 0.69765625 \n",
      "Epoch 3 | Step 827 | loss: 0.581318545909155 | accuracy: 0.6949404761904762 \n",
      "Epoch 3 | Step 828 | loss: 0.5840304737741296 | accuracy: 0.6924715909090909 \n",
      "Epoch 3 | Step 829 | loss: 0.5829195095145183 | accuracy: 0.6922554347826086 \n",
      "Epoch 3 | Step 830 | loss: 0.5833434537053107 | accuracy: 0.69140625 \n",
      "Epoch 3 | Step 831 | loss: 0.5860437941551208 | accuracy: 0.69 \n",
      "Epoch 3 | Step 832 | loss: 0.5846597781548133 | accuracy: 0.6917067307692307 \n",
      "Epoch 3 | Step 833 | loss: 0.5850628989714163 | accuracy: 0.6898148148148148 \n",
      "Epoch 3 | Step 834 | loss: 0.584980213216373 | accuracy: 0.6902901785714286 \n",
      "Epoch 3 | Step 835 | loss: 0.5844023638758166 | accuracy: 0.6891163793103449 \n",
      "Epoch 3 | Step 836 | loss: 0.5855452279249828 | accuracy: 0.6880208333333333 \n",
      "Epoch 3 | Step 837 | loss: 0.5840165057489949 | accuracy: 0.6905241935483871 \n",
      "Epoch 3 | Step 838 | loss: 0.5846593119204044 | accuracy: 0.6884765625 \n",
      "Epoch 3 | Step 839 | loss: 0.5872794064608488 | accuracy: 0.6860795454545454 \n",
      "Epoch 3 | Step 840 | loss: 0.5870481343830333 | accuracy: 0.6842830882352942 \n",
      "Epoch 3 | Step 841 | loss: 0.5852459686143058 | accuracy: 0.6857142857142857 \n",
      "Epoch 3 | Step 842 | loss: 0.5845878223578135 | accuracy: 0.6879340277777778 \n",
      "Epoch 3 | Step 843 | loss: 0.5840998726922113 | accuracy: 0.6891891891891891 \n",
      "Epoch 3 | Step 844 | loss: 0.5849752112438805 | accuracy: 0.6883223684210527 \n",
      "Epoch 3 | Step 845 | loss: 0.5849568324211317 | accuracy: 0.6895032051282052 \n",
      "Epoch 3 | Step 846 | loss: 0.5835062861442567 | accuracy: 0.6910156250000001 \n",
      "Epoch 3 | Step 847 | loss: 0.5842674607183876 | accuracy: 0.6901676829268294 \n",
      "Epoch 3 | Step 848 | loss: 0.583738494487036 | accuracy: 0.691592261904762 \n",
      "Epoch 3 | Step 849 | loss: 0.5816522330738778 | accuracy: 0.6922238372093024 \n",
      "Epoch 3 | Step 850 | loss: 0.5805389332500371 | accuracy: 0.6931818181818182 \n",
      "Epoch 3 | Step 851 | loss: 0.5794963604874082 | accuracy: 0.6965277777777779 \n",
      "Epoch 3 | Step 852 | loss: 0.5787222443715386 | accuracy: 0.6959918478260869 \n",
      "Epoch 3 | Step 853 | loss: 0.5809312215510836 | accuracy: 0.6944813829787234 \n",
      "Epoch 3 | Step 854 | loss: 0.5823901401211818 | accuracy: 0.6927083333333334 \n",
      "Epoch 3 | Step 855 | loss: 0.5840748128842335 | accuracy: 0.6913265306122449 \n",
      "Epoch 3 | Step 856 | loss: 0.5842316895723343 | accuracy: 0.690625 \n",
      "Epoch 3 | Step 857 | loss: 0.5836213155120027 | accuracy: 0.6914828431372549 \n",
      "Epoch 3 | Step 858 | loss: 0.5825907479111965 | accuracy: 0.6929086538461539 \n",
      "Epoch 3 | Step 859 | loss: 0.5819998951453083 | accuracy: 0.6931014150943396 \n",
      "Epoch 3 | Step 860 | loss: 0.5828580033999902 | accuracy: 0.6927083333333334 \n",
      "Epoch 3 | Step 861 | loss: 0.58233781023459 | accuracy: 0.694034090909091 \n",
      "Epoch 3 | Step 862 | loss: 0.5821820598627839 | accuracy: 0.693359375 \n",
      "Epoch 3 | Step 863 | loss: 0.5810095443014514 | accuracy: 0.6946271929824561 \n",
      "Epoch 3 | Step 864 | loss: 0.5812172082991436 | accuracy: 0.6947737068965517 \n",
      "Epoch 3 | Step 865 | loss: 0.5814881612688808 | accuracy: 0.694385593220339 \n",
      "Epoch 3 | Step 866 | loss: 0.5813676153620084 | accuracy: 0.6955729166666667 \n",
      "Epoch 3 | Step 867 | loss: 0.5809639277028256 | accuracy: 0.6969774590163934 \n",
      "Epoch 3 | Step 868 | loss: 0.5801292489613256 | accuracy: 0.6975806451612904 \n",
      "Epoch 3 | Step 869 | loss: 0.5801442714910658 | accuracy: 0.6969246031746031 \n",
      "Epoch 3 | Step 870 | loss: 0.5797773380763829 | accuracy: 0.6962890625 \n",
      "Epoch 3 | Step 871 | loss: 0.5798853897131406 | accuracy: 0.6971153846153846 \n",
      "Epoch 3 | Step 872 | loss: 0.5797943558656808 | accuracy: 0.6974431818181818 \n",
      "Epoch 3 | Step 873 | loss: 0.5791988226015177 | accuracy: 0.6984608208955224 \n",
      "Epoch 3 | Step 874 | loss: 0.5791411106200779 | accuracy: 0.6982996323529411 \n",
      "Epoch 3 | Step 875 | loss: 0.5804091860418734 | accuracy: 0.6976902173913043 \n",
      "Epoch 3 | Step 876 | loss: 0.579343187383243 | accuracy: 0.6982142857142857 \n",
      "Epoch 3 | Step 877 | loss: 0.5797849729867048 | accuracy: 0.6976232394366197 \n",
      "Epoch 3 | Step 878 | loss: 0.5796130552060075 | accuracy: 0.6979166666666666 \n",
      "Epoch 3 | Step 879 | loss: 0.5803898095268093 | accuracy: 0.6977739726027398 \n",
      "Epoch 3 | Step 880 | loss: 0.5796663531580487 | accuracy: 0.698268581081081 \n",
      "Epoch 3 | Step 881 | loss: 0.5806926786899567 | accuracy: 0.6970833333333333 \n",
      "Epoch 3 | Step 882 | loss: 0.5802334284311846 | accuracy: 0.6977796052631579 \n",
      "Epoch 3 | Step 883 | loss: 0.5799436557602573 | accuracy: 0.698051948051948 \n",
      "Epoch 3 | Step 884 | loss: 0.5804219219164971 | accuracy: 0.6981169871794872 \n",
      "Epoch 3 | Step 885 | loss: 0.5807243219659299 | accuracy: 0.6971914556962026 \n",
      "Epoch 3 | Step 886 | loss: 0.5814543444663287 | accuracy: 0.6962890625 \n",
      "Epoch 3 | Step 887 | loss: 0.5808303933820608 | accuracy: 0.6967592592592593 \n",
      "Epoch 3 | Step 888 | loss: 0.5807270462193141 | accuracy: 0.6964557926829268 \n",
      "Epoch 3 | Step 889 | loss: 0.5807186677513354 | accuracy: 0.6963478915662651 \n",
      "Epoch 3 | Step 890 | loss: 0.5806108354812578 | accuracy: 0.6960565476190477 \n",
      "Epoch 3 | Step 891 | loss: 0.5797396915800432 | accuracy: 0.6968750000000001 \n",
      "Epoch 3 | Step 892 | loss: 0.5797395834396053 | accuracy: 0.6965843023255816 \n",
      "Epoch 3 | Step 893 | loss: 0.5803640289553281 | accuracy: 0.6957614942528737 \n",
      "Epoch 3 | Step 894 | loss: 0.5795173885470087 | accuracy: 0.6965553977272729 \n",
      "Epoch 3 | Step 895 | loss: 0.5785625700870257 | accuracy: 0.6969803370786518 \n",
      "Epoch 3 | Step 896 | loss: 0.5788764407237371 | accuracy: 0.6970486111111113 \n",
      "Epoch 3 | Step 897 | loss: 0.5780195472659645 | accuracy: 0.6979739010989012 \n",
      "Epoch 3 | Step 898 | loss: 0.5773189330230588 | accuracy: 0.6987092391304349 \n",
      "Epoch 3 | Step 899 | loss: 0.5771250529314882 | accuracy: 0.6985887096774195 \n",
      "Epoch 3 | Step 900 | loss: 0.5774029420411333 | accuracy: 0.6974734042553193 \n",
      "Epoch 3 | Step 901 | loss: 0.5777221300100025 | accuracy: 0.6970394736842107 \n",
      "Epoch 3 | Step 902 | loss: 0.5791098857298492 | accuracy: 0.6961263020833335 \n",
      "Epoch 3 | Step 903 | loss: 0.5794741582010209 | accuracy: 0.6957152061855671 \n",
      "Epoch 3 | Step 904 | loss: 0.5797551794319735 | accuracy: 0.6956313775510206 \n",
      "Epoch 3 | Step 905 | loss: 0.5798928168686952 | accuracy: 0.695233585858586 \n",
      "Epoch 3 | Step 906 | loss: 0.5796585556864737 | accuracy: 0.6956250000000002 \n",
      "Epoch 3 | Step 907 | loss: 0.5784960973380815 | accuracy: 0.6969368811881189 \n",
      "Epoch 3 | Step 908 | loss: 0.5784957706928252 | accuracy: 0.6968443627450982 \n",
      "Epoch 3 | Step 909 | loss: 0.5781709760138131 | accuracy: 0.6978155339805827 \n",
      "Epoch 3 | Step 910 | loss: 0.5782443319375697 | accuracy: 0.6974158653846155 \n",
      "Epoch 3 | Step 911 | loss: 0.5776981881686619 | accuracy: 0.6976190476190478 \n",
      "Epoch 3 | Step 912 | loss: 0.5777102292708631 | accuracy: 0.6975235849056605 \n",
      "Epoch 3 | Step 913 | loss: 0.5777584002396772 | accuracy: 0.6981600467289721 \n",
      "Epoch 3 | Step 914 | loss: 0.5782461834174617 | accuracy: 0.697627314814815 \n",
      "Epoch 3 | Step 915 | loss: 0.5780821650400075 | accuracy: 0.6973910550458717 \n",
      "Epoch 3 | Step 916 | loss: 0.5781231202862481 | accuracy: 0.6978693181818183 \n",
      "Epoch 3 | Step 917 | loss: 0.5776346717868842 | accuracy: 0.6987612612612614 \n",
      "Epoch 3 | Step 918 | loss: 0.5771866392876424 | accuracy: 0.6992187500000001 \n",
      "Epoch 3 | Step 919 | loss: 0.5774721645675932 | accuracy: 0.6991150442477877 \n",
      "Epoch 3 | Step 920 | loss: 0.5784661796009334 | accuracy: 0.6986019736842106 \n",
      "Epoch 3 | Step 921 | loss: 0.5789041933806048 | accuracy: 0.6980978260869567 \n",
      "Epoch 3 | Step 922 | loss: 0.5792126424353701 | accuracy: 0.6981411637931035 \n",
      "Epoch 3 | Step 923 | loss: 0.5793826187777725 | accuracy: 0.6981837606837608 \n",
      "Epoch 3 | Step 924 | loss: 0.579744903212887 | accuracy: 0.6979608050847459 \n",
      "Epoch 3 | Step 925 | loss: 0.5790658938784562 | accuracy: 0.6982668067226891 \n",
      "Epoch 3 | Step 926 | loss: 0.5790417234102887 | accuracy: 0.6983072916666668 \n",
      "Epoch 3 | Step 927 | loss: 0.5787179327208151 | accuracy: 0.6986053719008266 \n",
      "Epoch 3 | Step 928 | loss: 0.5790604343179799 | accuracy: 0.6982581967213116 \n",
      "Epoch 3 | Step 929 | loss: 0.5797345076150043 | accuracy: 0.6972815040650407 \n",
      "Epoch 3 | Step 930 | loss: 0.5799782540529007 | accuracy: 0.6975806451612905 \n",
      "Epoch 3 | Step 931 | loss: 0.5802978959083559 | accuracy: 0.6973750000000001 \n",
      "Epoch 3 | Step 932 | loss: 0.5802162582912145 | accuracy: 0.6970486111111113 \n",
      "Epoch 3 | Step 933 | loss: 0.5802802457584173 | accuracy: 0.6969734251968505 \n",
      "Epoch 3 | Step 934 | loss: 0.5798419364728036 | accuracy: 0.6976318359375001 \n",
      "Epoch 3 | Step 935 | loss: 0.5800077254457994 | accuracy: 0.6974321705426357 \n",
      "Epoch 3 | Step 936 | loss: 0.5800726276177629 | accuracy: 0.6973557692307694 \n",
      "Epoch 3 | Step 937 | loss: 0.5808240643894401 | accuracy: 0.6968034351145039 \n",
      "Epoch 3 | Step 938 | loss: 0.580970418724147 | accuracy: 0.6968513257575759 \n",
      "Epoch 3 | Step 939 | loss: 0.5812406181392815 | accuracy: 0.6964285714285715 \n",
      "Epoch 3 | Step 940 | loss: 0.5812181536831075 | accuracy: 0.6965951492537314 \n",
      "Epoch 3 | Step 941 | loss: 0.5809893859757319 | accuracy: 0.6968750000000001 \n",
      "Epoch 3 | Step 942 | loss: 0.5808840025873747 | accuracy: 0.696920955882353 \n",
      "Epoch 3 | Step 943 | loss: 0.5801698345772544 | accuracy: 0.6978786496350367 \n",
      "Epoch 3 | Step 944 | loss: 0.579724279218826 | accuracy: 0.6982563405797103 \n",
      "Epoch 3 | Step 945 | loss: 0.5799155404670635 | accuracy: 0.6980665467625902 \n",
      "Epoch 3 | Step 946 | loss: 0.5799908682703974 | accuracy: 0.6977678571428574 \n",
      "Epoch 3 | Step 947 | loss: 0.5802104107454316 | accuracy: 0.6973625886524825 \n",
      "Epoch 3 | Step 948 | loss: 0.5805147304921086 | accuracy: 0.6967429577464791 \n",
      "Epoch 3 | Step 949 | loss: 0.5806456939740616 | accuracy: 0.6966783216783219 \n",
      "Epoch 3 | Step 950 | loss: 0.5804922073665595 | accuracy: 0.6966145833333335 \n",
      "Epoch 3 | Step 951 | loss: 0.5802041549107126 | accuracy: 0.6968750000000002 \n",
      "Epoch 3 | Step 952 | loss: 0.5802608501829515 | accuracy: 0.6969178082191783 \n",
      "Epoch 3 | Step 953 | loss: 0.5798734505565801 | accuracy: 0.6973852040816328 \n",
      "Epoch 3 | Step 954 | loss: 0.5802706896856027 | accuracy: 0.6966849662162165 \n",
      "Epoch 3 | Step 955 | loss: 0.5800607810484486 | accuracy: 0.6965184563758391 \n",
      "Epoch 3 | Step 956 | loss: 0.5800510944922768 | accuracy: 0.6965625000000002 \n",
      "Epoch 3 | Step 957 | loss: 0.5797019930470072 | accuracy: 0.6972268211920531 \n",
      "Epoch 3 | Step 958 | loss: 0.579703050028337 | accuracy: 0.6968544407894739 \n",
      "Epoch 3 | Step 959 | loss: 0.5794928293991715 | accuracy: 0.697201797385621 \n",
      "Epoch 3 | Step 960 | loss: 0.5788917868555369 | accuracy: 0.6977475649350651 \n",
      "Epoch 3 | Step 961 | loss: 0.5786776748395738 | accuracy: 0.6976814516129033 \n",
      "Epoch 3 | Step 962 | loss: 0.5780706294836145 | accuracy: 0.6981169871794872 \n",
      "Epoch 3 | Step 963 | loss: 0.578613029923409 | accuracy: 0.6979498407643312 \n",
      "Epoch 3 | Step 964 | loss: 0.5792530461957187 | accuracy: 0.6973892405063291 \n",
      "Epoch 3 | Step 965 | loss: 0.5793644800875926 | accuracy: 0.6975235849056604 \n",
      "Epoch 3 | Step 966 | loss: 0.5795391112565997 | accuracy: 0.69736328125 \n",
      "Epoch 3 | Step 967 | loss: 0.5798033494386617 | accuracy: 0.6971079192546584 \n",
      "Epoch 3 | Step 968 | loss: 0.5798538577409441 | accuracy: 0.6971450617283951 \n",
      "Epoch 3 | Step 969 | loss: 0.5796634554862978 | accuracy: 0.6969900306748467 \n",
      "Epoch 3 | Step 970 | loss: 0.579621287380777 | accuracy: 0.6972179878048781 \n",
      "Epoch 3 | Step 971 | loss: 0.5792048284501743 | accuracy: 0.6978219696969697 \n",
      "Epoch 3 | Step 972 | loss: 0.5789957319397526 | accuracy: 0.6978539156626506 \n",
      "Epoch 3 | Step 973 | loss: 0.5786243405884613 | accuracy: 0.6984468562874252 \n",
      "Epoch 3 | Step 974 | loss: 0.5788442052546003 | accuracy: 0.6983816964285715 \n",
      "Epoch 3 | Step 975 | loss: 0.5785390709984234 | accuracy: 0.6986871301775148 \n",
      "Epoch 3 | Step 976 | loss: 0.5780472134842594 | accuracy: 0.6992647058823529 \n",
      "Epoch 3 | Step 977 | loss: 0.5773875952115535 | accuracy: 0.6997441520467836 \n",
      "Epoch 3 | Step 978 | loss: 0.5773724308887195 | accuracy: 0.6997638081395349 \n",
      "Epoch 3 | Step 979 | loss: 0.5768129658492316 | accuracy: 0.7004154624277457 \n",
      "Epoch 3 | Step 980 | loss: 0.5767470113504893 | accuracy: 0.7004310344827587 \n",
      "Epoch 3 | Step 981 | loss: 0.5766674734864917 | accuracy: 0.7003571428571429 \n",
      "Epoch 3 | Step 982 | loss: 0.5766334877434103 | accuracy: 0.7002840909090909 \n",
      "Epoch 3 | Step 983 | loss: 0.5770183938034511 | accuracy: 0.700388418079096 \n",
      "Epoch 3 | Step 984 | loss: 0.5771063675036592 | accuracy: 0.7002282303370787 \n",
      "Epoch 3 | Step 985 | loss: 0.5768629926875983 | accuracy: 0.700157122905028 \n",
      "Epoch 3 | Step 986 | loss: 0.5769166921575865 | accuracy: 0.7001736111111111 \n",
      "Epoch 3 | Step 987 | loss: 0.5767765382706131 | accuracy: 0.7003625690607734 \n",
      "Epoch 3 | Step 988 | loss: 0.5764933272704974 | accuracy: 0.7007211538461537 \n",
      "Epoch 3 | Step 989 | loss: 0.5755460934886516 | accuracy: 0.7015881147540983 \n",
      "Epoch 3 | Step 990 | loss: 0.5751407368351584 | accuracy: 0.701766304347826 \n",
      "Epoch 3 | Step 991 | loss: 0.5749415305820671 | accuracy: 0.7019425675675676 \n",
      "Epoch 3 | Step 992 | loss: 0.574626452980503 | accuracy: 0.7023689516129032 \n",
      "Epoch 3 | Step 993 | loss: 0.5747405521691165 | accuracy: 0.7022058823529411 \n",
      "Epoch 3 | Step 994 | loss: 0.5748556511516266 | accuracy: 0.7017952127659575 \n",
      "Epoch 3 | Step 995 | loss: 0.5745267232574482 | accuracy: 0.7019675925925926 \n",
      "Epoch 3 | Step 996 | loss: 0.5747759340625059 | accuracy: 0.7017269736842106 \n",
      "Epoch 3 | Step 997 | loss: 0.5744219667312361 | accuracy: 0.7021433246073299 \n",
      "Epoch 3 | Step 998 | loss: 0.5741138674008349 | accuracy: 0.7022298177083334 \n",
      "Epoch 3 | Step 999 | loss: 0.5735419809509436 | accuracy: 0.7027202072538861 \n",
      "Epoch 3 | Step 1000 | loss: 0.5736624678385627 | accuracy: 0.7024806701030928 \n",
      "Epoch 3 | Step 1001 | loss: 0.5735615406280908 | accuracy: 0.7026442307692308 \n",
      "Epoch 3 | Step 1002 | loss: 0.5735303622727491 | accuracy: 0.7026466836734694 \n",
      "Epoch 3 | Step 1003 | loss: 0.5732264216176144 | accuracy: 0.7028870558375635 \n",
      "Epoch 3 | Step 1004 | loss: 0.5729038164471134 | accuracy: 0.703125 \n",
      "Epoch 3 | Step 1005 | loss: 0.572417969829473 | accuracy: 0.7036746231155779 \n",
      "Epoch 3 | Step 1006 | loss: 0.5720835994184017 | accuracy: 0.7040625 \n",
      "Epoch 3 | Step 1007 | loss: 0.5725058419490928 | accuracy: 0.7038246268656716 \n",
      "Epoch 3 | Step 1008 | loss: 0.5720520892945846 | accuracy: 0.7042079207920792 \n",
      "Epoch 3 | Step 1009 | loss: 0.5720476836993775 | accuracy: 0.7044334975369458 \n",
      "Epoch 3 | Step 1010 | loss: 0.572064430690279 | accuracy: 0.7045036764705882 \n",
      "Epoch 3 | Step 1011 | loss: 0.5720043528370738 | accuracy: 0.7044969512195122 \n",
      "Epoch 3 | Step 1012 | loss: 0.5722717900299329 | accuracy: 0.7042627427184466 \n",
      "Epoch 3 | Step 1013 | loss: 0.5727654364373946 | accuracy: 0.7040307971014492 \n",
      "Epoch 3 | Step 1014 | loss: 0.5730774365365503 | accuracy: 0.7038010817307693 \n",
      "Epoch 3 | Step 1015 | loss: 0.5731436005619722 | accuracy: 0.7036483253588517 \n",
      "Epoch 3 | Step 1016 | loss: 0.5732498591854457 | accuracy: 0.7034970238095238 \n",
      "Epoch 3 | Step 1017 | loss: 0.5732953833742728 | accuracy: 0.7031990521327014 \n",
      "Epoch 3 | Step 1018 | loss: 0.5729606770119575 | accuracy: 0.7035672169811321 \n",
      "Epoch 3 | Step 1019 | loss: 0.572608731022463 | accuracy: 0.7038585680751174 \n",
      "Epoch 3 | Step 1020 | loss: 0.5725383489766966 | accuracy: 0.7038551401869159 \n",
      "Epoch 3 | Step 1021 | loss: 0.5725884383501008 | accuracy: 0.7039970930232559 \n",
      "Epoch 3 | Step 1022 | loss: 0.572450477078005 | accuracy: 0.7039930555555556 \n",
      "Epoch 3 | Step 1023 | loss: 0.571904366466856 | accuracy: 0.7044210829493087 \n",
      "Epoch 3 | Step 1024 | loss: 0.571934717784234 | accuracy: 0.7044868119266054 \n",
      "Epoch 3 | Step 1025 | loss: 0.5720443145869528 | accuracy: 0.7044092465753424 \n",
      "Epoch 3 | Step 1026 | loss: 0.5719537569717926 | accuracy: 0.7043323863636364 \n",
      "Epoch 3 | Step 1027 | loss: 0.5720048107173107 | accuracy: 0.7043976244343891 \n",
      "Epoch 3 | Step 1028 | loss: 0.5719369674051129 | accuracy: 0.7045326576576577 \n",
      "Epoch 3 | Step 1029 | loss: 0.5715689550868063 | accuracy: 0.7047365470852018 \n",
      "Epoch 3 | Step 1030 | loss: 0.5711991719103284 | accuracy: 0.7048688616071429 \n",
      "Epoch 3 | Step 1031 | loss: 0.5712784747282663 | accuracy: 0.7046527777777778 \n",
      "Epoch 3 | Step 1032 | loss: 0.5712809716969464 | accuracy: 0.7047151548672567 \n",
      "Epoch 3 | Step 1033 | loss: 0.5713884301385164 | accuracy: 0.7047769823788547 \n",
      "Epoch 3 | Step 1034 | loss: 0.5711273803261288 | accuracy: 0.7049753289473685 \n",
      "Epoch 3 | Step 1035 | loss: 0.5712184748535072 | accuracy: 0.704967248908297 \n",
      "Epoch 3 | Step 1036 | loss: 0.571287843066713 | accuracy: 0.7049592391304348 \n",
      "Epoch 3 | Step 1037 | loss: 0.5705769273625823 | accuracy: 0.7054924242424242 \n",
      "Epoch 3 | Step 1038 | loss: 0.5703939333044248 | accuracy: 0.7054822198275862 \n",
      "Epoch 3 | Step 1039 | loss: 0.5703376242531214 | accuracy: 0.7054721030042919 \n",
      "Epoch 3 | Step 1040 | loss: 0.5701993507707219 | accuracy: 0.7057291666666666 \n",
      "Epoch 3 | Step 1041 | loss: 0.5699084218512189 | accuracy: 0.7060505319148936 \n",
      "Epoch 3 | Step 1042 | loss: 0.569418122455225 | accuracy: 0.7063691737288136 \n",
      "Epoch 3 | Step 1043 | loss: 0.5690803629688068 | accuracy: 0.7066851265822784 \n",
      "Epoch 3 | Step 1044 | loss: 0.5690516197130459 | accuracy: 0.7066701680672269 \n",
      "Epoch 3 | Step 1045 | loss: 0.5690355825873098 | accuracy: 0.7066553347280334 \n",
      "Epoch 3 | Step 1046 | loss: 0.5686339349796373 | accuracy: 0.7069661458333333 \n",
      "Epoch 3 | Step 1047 | loss: 0.5681005896869041 | accuracy: 0.7074688796680498 \n",
      "Epoch 3 | Step 1048 | loss: 0.5675032374041138 | accuracy: 0.707709194214876 \n",
      "Epoch 3 | Step 1049 | loss: 0.5673643788437783 | accuracy: 0.7080761316872428 \n",
      "Epoch 3 | Step 1050 | loss: 0.5673718192293995 | accuracy: 0.7079918032786885 \n",
      "Epoch 3 | Step 1051 | loss: 0.5673435823041565 | accuracy: 0.7080994897959184 \n",
      "Epoch 3 | Step 1052 | loss: 0.5672174477722586 | accuracy: 0.7080157520325203 \n",
      "Epoch 3 | Step 1053 | loss: 0.5669071725022936 | accuracy: 0.7083755060728745 \n",
      "Epoch 3 | Step 1054 | loss: 0.566960954377728 | accuracy: 0.7081653225806451 \n",
      "Epoch 3 | Step 1055 | loss: 0.5669031535765252 | accuracy: 0.7083333333333334 \n",
      "Epoch 3 | Step 1056 | loss: 0.5667857918739317 | accuracy: 0.708375 \n",
      "Epoch 3 | Step 1057 | loss: 0.5666260132751616 | accuracy: 0.7083540836653387 \n",
      "Epoch 3 | Step 1058 | loss: 0.5666012962659199 | accuracy: 0.7083953373015873 \n",
      "Epoch 3 | Step 1059 | loss: 0.5662911334056627 | accuracy: 0.7087450592885376 \n",
      "Epoch 3 | Step 1060 | loss: 0.5663026949082771 | accuracy: 0.7086614173228346 \n",
      "Epoch 3 | Step 1061 | loss: 0.5660561316153582 | accuracy: 0.7088235294117647 \n",
      "Epoch 3 | Step 1062 | loss: 0.5658184036146848 | accuracy: 0.70892333984375 \n",
      "Epoch 3 | Step 1063 | loss: 0.5656675953809388 | accuracy: 0.7088399805447471 \n",
      "Epoch 3 | Step 1064 | loss: 0.5653381427360135 | accuracy: 0.7090600775193798 \n",
      "Epoch 3 | Step 1065 | loss: 0.5652655262974697 | accuracy: 0.7090974903474904 \n",
      "Epoch 3 | Step 1066 | loss: 0.564771031989501 | accuracy: 0.7095552884615385 \n",
      "Epoch 3 | Step 1067 | loss: 0.5651361228634113 | accuracy: 0.709051724137931 \n",
      "Epoch 3 | Step 1068 | loss: 0.5651477799388287 | accuracy: 0.7088501908396947 \n",
      "Epoch 3 | Step 1069 | loss: 0.5650031560954031 | accuracy: 0.7089472433460076 \n",
      "Epoch 3 | Step 1070 | loss: 0.5649846705297628 | accuracy: 0.7089251893939394 \n",
      "Epoch 3 | Step 1071 | loss: 0.5647199152775529 | accuracy: 0.7090212264150944 \n",
      "Epoch 3 | Step 1072 | loss: 0.564333597072085 | accuracy: 0.7094102443609023 \n",
      "Epoch 3 | Step 1073 | loss: 0.5640330024426349 | accuracy: 0.7097378277153558 \n",
      "Epoch 3 | Step 1074 | loss: 0.5641928875624243 | accuracy: 0.7097714552238806 \n",
      "Epoch 3 | Step 1075 | loss: 0.5641210819265655 | accuracy: 0.7098629182156134 \n",
      "Epoch 3 | Step 1076 | loss: 0.5639650618588482 | accuracy: 0.7100694444444444 \n",
      "Epoch 3 | Step 1077 | loss: 0.5639347517622352 | accuracy: 0.7101591328413284 \n",
      "Epoch 3 | Step 1078 | loss: 0.5637893437900963 | accuracy: 0.7104204963235294 \n",
      "Epoch 3 | Step 1079 | loss: 0.5636193206458737 | accuracy: 0.7105082417582418 \n",
      "Epoch 3 | Step 1080 | loss: 0.5633353006883258 | accuracy: 0.7108234489051095 \n",
      "Epoch 3 | Step 1081 | loss: 0.5631089146570725 | accuracy: 0.7110795454545454 \n",
      "Epoch 3 | Step 1082 | loss: 0.5630714227107987 | accuracy: 0.7112205615942029 \n",
      "Epoch 3 | Step 1083 | loss: 0.5627725678445629 | accuracy: 0.7114733754512635 \n",
      "Epoch 3 | Step 1084 | loss: 0.5627014775284759 | accuracy: 0.7113871402877698 \n",
      "Epoch 3 | Step 1085 | loss: 0.5628576858710216 | accuracy: 0.7113015232974912 \n",
      "Epoch 3 | Step 1086 | loss: 0.5625548140278883 | accuracy: 0.711607142857143 \n",
      "Epoch 3 | Step 1087 | loss: 0.5624521657877545 | accuracy: 0.7119105871886122 \n",
      "Epoch 3 | Step 1088 | loss: 0.5623048479464037 | accuracy: 0.711934840425532 \n",
      "Epoch 3 | Step 1089 | loss: 0.5624706611405834 | accuracy: 0.7117932862190813 \n",
      "Epoch 3 | Step 1090 | loss: 0.5621916447097147 | accuracy: 0.7119278169014086 \n",
      "Epoch 3 | Step 1091 | loss: 0.5621858152381161 | accuracy: 0.7119517543859651 \n",
      "Epoch 3 | Step 1092 | loss: 0.5622636795669169 | accuracy: 0.7120301573426575 \n",
      "Epoch 3 | Step 1093 | loss: 0.5618681053043658 | accuracy: 0.7122713414634149 \n",
      "Epoch 3 | Step 1094 | loss: 0.5615790362159411 | accuracy: 0.7124023437500002 \n",
      "Epoch 3 | Step 1095 | loss: 0.561462066784037 | accuracy: 0.712532439446367 \n",
      "Epoch 3 | Step 1096 | loss: 0.5615417363314793 | accuracy: 0.7126616379310347 \n",
      "Epoch 3 | Step 1097 | loss: 0.5611790295728704 | accuracy: 0.7130047250859108 \n",
      "Epoch 3 | Step 1098 | loss: 0.5608822021582355 | accuracy: 0.7132384417808221 \n",
      "Epoch 3 | Step 1099 | loss: 0.5605209176857724 | accuracy: 0.7134172354948808 \n",
      "Epoch 3 | Step 1100 | loss: 0.5600539649627647 | accuracy: 0.7137542517006805 \n",
      "Epoch 3 | Step 1101 | loss: 0.5604538985228136 | accuracy: 0.7135063559322037 \n",
      "Epoch 3 | Step 1102 | loss: 0.5603159250238459 | accuracy: 0.7136296452702705 \n",
      "Epoch 3 | Step 1103 | loss: 0.5602818975344251 | accuracy: 0.7135942760942763 \n",
      "Epoch 3 | Step 1104 | loss: 0.5600349295059307 | accuracy: 0.7138213087248324 \n",
      "Epoch 3 | Step 1105 | loss: 0.5598210514987194 | accuracy: 0.7138900501672243 \n",
      "Epoch 3 | Step 1106 | loss: 0.5593446691830954 | accuracy: 0.7142708333333335 \n",
      "Epoch 3 | Step 1107 | loss: 0.5592578522786747 | accuracy: 0.7142857142857145 \n",
      "Epoch 3 | Step 1108 | loss: 0.5592660238805988 | accuracy: 0.71445571192053 \n",
      "Epoch 3 | Step 1109 | loss: 0.5590892522641929 | accuracy: 0.714624587458746 \n",
      "Epoch 3 | Step 1110 | loss: 0.5589405149221421 | accuracy: 0.7147409539473686 \n",
      "Epoch 3 | Step 1111 | loss: 0.5592102902834534 | accuracy: 0.7144467213114756 \n",
      "Epoch 3 | Step 1112 | loss: 0.558841633738256 | accuracy: 0.7148182189542486 \n",
      "Epoch 3 | Step 1113 | loss: 0.5583998048344343 | accuracy: 0.7152381921824106 \n",
      "Epoch 3 | Step 1114 | loss: 0.5582697726302334 | accuracy: 0.7153510551948054 \n",
      "Epoch 3 | Step 1115 | loss: 0.5578907063670916 | accuracy: 0.7156148867313917 \n",
      "Epoch 3 | Step 1116 | loss: 0.5575136965320958 | accuracy: 0.7157258064516131 \n",
      "Epoch 3 | Step 1117 | loss: 0.5573864006152875 | accuracy: 0.7158862540192927 \n",
      "Epoch 3 | Step 1118 | loss: 0.5573770014139324 | accuracy: 0.7156951121794872 \n",
      "Epoch 3 | Step 1119 | loss: 0.5572135812177447 | accuracy: 0.7158047124600639 \n",
      "Epoch 3 | Step 1120 | loss: 0.5570587726535313 | accuracy: 0.7158638535031847 \n",
      "Epoch 3 | Step 1121 | loss: 0.5565018646300787 | accuracy: 0.7163194444444444 \n",
      "Epoch 3 | Step 1122 | loss: 0.5564550727228577 | accuracy: 0.7163765822784809 \n",
      "Epoch 3 | Step 1123 | loss: 0.556473868126373 | accuracy: 0.716433359621451 \n",
      "Epoch 3 | Step 1124 | loss: 0.5562708296303481 | accuracy: 0.7166371855345911 \n",
      "Epoch 3 | Step 1125 | loss: 0.5562018140169522 | accuracy: 0.7167417711598745 \n",
      "Epoch 3 | Step 1126 | loss: 0.5560673371888699 | accuracy: 0.7167968749999998 \n",
      "Epoch 3 | Step 1127 | loss: 0.5559728904119535 | accuracy: 0.7168516355140185 \n",
      "Epoch 3 | Step 1128 | loss: 0.5559870755265219 | accuracy: 0.716906055900621 \n",
      "Epoch 3 | Step 1129 | loss: 0.5560082524738077 | accuracy: 0.716815015479876 \n",
      "Epoch 3 | Step 1130 | loss: 0.5557316354947327 | accuracy: 0.7169656635802467 \n",
      "Epoch 3 | Step 1131 | loss: 0.5554690946065465 | accuracy: 0.7171153846153845 \n",
      "Epoch 3 | Step 1132 | loss: 0.555576782102234 | accuracy: 0.7170724693251533 \n",
      "Epoch 3 | Step 1133 | loss: 0.5557646498038502 | accuracy: 0.7170775993883792 \n",
      "Epoch 3 | Step 1134 | loss: 0.5555138315369447 | accuracy: 0.7173208841463414 \n",
      "Epoch 3 | Step 1135 | loss: 0.5552685124895859 | accuracy: 0.7174677051671733 \n",
      "Epoch 3 | Step 1136 | loss: 0.5552525811123129 | accuracy: 0.7176609848484848 \n",
      "Epoch 3 | Step 1137 | loss: 0.5550446299627831 | accuracy: 0.7178530966767371 \n",
      "Epoch 3 | Step 1138 | loss: 0.5549190825367551 | accuracy: 0.7179028614457831 \n",
      "Epoch 3 | Step 1139 | loss: 0.5547618436383774 | accuracy: 0.7179992492492492 \n",
      "Epoch 3 | Step 1140 | loss: 0.5545615441427976 | accuracy: 0.7180482784431137 \n",
      "Epoch 3 | Step 1141 | loss: 0.5545321848855093 | accuracy: 0.7179570895522387 \n",
      "Epoch 3 | Step 1142 | loss: 0.554480910123814 | accuracy: 0.7180989583333333 \n",
      "Epoch 3 | Step 1143 | loss: 0.5544164562791323 | accuracy: 0.7181008902077151 \n",
      "Epoch 3 | Step 1144 | loss: 0.5542718977970487 | accuracy: 0.718287721893491 \n",
      "Epoch 3 | Step 1145 | loss: 0.5541702375299462 | accuracy: 0.7181508112094394 \n",
      "Epoch 3 | Step 1146 | loss: 0.5542081994168901 | accuracy: 0.7183363970588234 \n",
      "Epoch 3 | Step 1147 | loss: 0.5539010133037122 | accuracy: 0.7185667155425218 \n",
      "Epoch 3 | Step 1148 | loss: 0.5538277238258844 | accuracy: 0.7187956871345027 \n",
      "Epoch 3 | Step 1149 | loss: 0.5535816095834574 | accuracy: 0.7190233236151601 \n",
      "Epoch 3 | Step 1150 | loss: 0.5536744167465113 | accuracy: 0.7189316860465114 \n",
      "Epoch 3 | Step 1151 | loss: 0.5532877325147825 | accuracy: 0.7192481884057969 \n",
      "Epoch 3 | Step 1152 | loss: 0.5532047370437945 | accuracy: 0.7193370664739882 \n",
      "Epoch 3 | Step 1153 | loss: 0.5530288915125715 | accuracy: 0.7194254322766568 \n",
      "Epoch 3 | Step 1154 | loss: 0.5528338063379817 | accuracy: 0.7195581896551722 \n",
      "Epoch 3 | Step 1155 | loss: 0.552597086118764 | accuracy: 0.7197349570200571 \n",
      "Epoch 3 | Step 1156 | loss: 0.5528453580822267 | accuracy: 0.7196428571428569 \n",
      "Epoch 3 | Step 1157 | loss: 0.5524619586786996 | accuracy: 0.7198628917378915 \n",
      "Epoch 3 | Step 1158 | loss: 0.5524097989228642 | accuracy: 0.7199485085227271 \n",
      "Epoch 3 | Step 1159 | loss: 0.552152211115651 | accuracy: 0.7202992209631727 \n",
      "Epoch 3 | Step 1160 | loss: 0.5522068775137943 | accuracy: 0.7204272598870055 \n",
      "Epoch 3 | Step 1161 | loss: 0.5519473482185691 | accuracy: 0.7205545774647886 \n",
      "Epoch 3 | Step 1162 | loss: 0.5514265456226439 | accuracy: 0.7209006320224718 \n",
      "Epoch 3 | Step 1163 | loss: 0.5514168569019867 | accuracy: 0.7208946078431371 \n",
      "Epoch 3 | Step 1164 | loss: 0.5514403140411701 | accuracy: 0.7207576815642457 \n",
      "Epoch 3 | Step 1165 | loss: 0.5511627740182589 | accuracy: 0.7210132311977714 \n",
      "Epoch 3 | Step 1166 | loss: 0.5513543912106094 | accuracy: 0.7208333333333332 \n",
      "Epoch 3 | Step 1167 | loss: 0.5513232581503177 | accuracy: 0.7207842797783932 \n",
      "Epoch 3 | Step 1168 | loss: 0.5512560841457623 | accuracy: 0.7207354972375689 \n",
      "Epoch 3 | Step 1169 | loss: 0.5513615233839054 | accuracy: 0.7206869834710742 \n",
      "Epoch 3 | Step 1170 | loss: 0.5509748375350305 | accuracy: 0.7209821428571427 \n",
      "Epoch 3 | Step 1171 | loss: 0.5507667654997686 | accuracy: 0.7212756849315067 \n",
      "Epoch 3 | Step 1172 | loss: 0.550760191402149 | accuracy: 0.7213114754098359 \n",
      "Epoch 3 | Step 1173 | loss: 0.550870582826781 | accuracy: 0.7212193460490461 \n",
      "Epoch 3 | Step 1174 | loss: 0.5505095004387527 | accuracy: 0.7215523097826085 \n",
      "Epoch 3 | Step 1175 | loss: 0.5505249424355466 | accuracy: 0.7215870596205961 \n",
      "Epoch 3 | Step 1176 | loss: 0.5504440354334345 | accuracy: 0.721537162162162 \n",
      "Epoch 3 | Step 1177 | loss: 0.5505022877310167 | accuracy: 0.7214875336927222 \n",
      "Epoch 3 | Step 1178 | loss: 0.5503268487030463 | accuracy: 0.7216061827956988 \n",
      "Epoch 3 | Step 1179 | loss: 0.549978167617609 | accuracy: 0.7219755361930293 \n",
      "Epoch 3 | Step 1180 | loss: 0.5496914158849159 | accuracy: 0.7222593582887699 \n",
      "Epoch 3 | Step 1181 | loss: 0.5498402204513554 | accuracy: 0.7220833333333332 \n",
      "Epoch 3 | Step 1182 | loss: 0.5500253621251029 | accuracy: 0.7219082446808509 \n",
      "Epoch 3 | Step 1183 | loss: 0.55010952509999 | accuracy: 0.721858421750663 \n",
      "Epoch 3 | Step 1184 | loss: 0.5501435544124991 | accuracy: 0.7216435185185184 \n",
      "Epoch 3 | Step 1185 | loss: 0.5499765390141976 | accuracy: 0.7216358839050131 \n",
      "Epoch 3 | Step 1186 | loss: 0.5498830778034114 | accuracy: 0.721751644736842 \n",
      "Epoch 3 | Step 1187 | loss: 0.549581322144336 | accuracy: 0.7219488188976376 \n",
      "Epoch 3 | Step 1188 | loss: 0.5496541381818465 | accuracy: 0.7218995418848166 \n",
      "Epoch 3 | Step 1189 | loss: 0.5495353860892456 | accuracy: 0.7220137075718014 \n",
      "Epoch 3 | Step 1190 | loss: 0.5497150006704036 | accuracy: 0.7218017578124999 \n",
      "Epoch 3 | Step 1191 | loss: 0.5497016583170212 | accuracy: 0.7217126623376622 \n",
      "Epoch 3 | Step 1192 | loss: 0.5497326163739124 | accuracy: 0.7217454663212434 \n",
      "Epoch 3 | Step 1193 | loss: 0.5498283987513504 | accuracy: 0.7216569767441859 \n",
      "Epoch 3 | Step 1194 | loss: 0.5497472100343904 | accuracy: 0.7217300257731958 \n",
      "Epoch 3 | Step 1195 | loss: 0.5497711829477231 | accuracy: 0.7216821979434446 \n",
      "Epoch 3 | Step 1196 | loss: 0.5498430213867094 | accuracy: 0.7214743589743589 \n",
      "Epoch 3 | Step 1197 | loss: 0.5496635345546795 | accuracy: 0.7215872762148337 \n",
      "Epoch 3 | Step 1198 | loss: 0.5496072577578686 | accuracy: 0.7215800382653059 \n",
      "Epoch 3 | Step 1199 | loss: 0.549403946666621 | accuracy: 0.7218511450381678 \n",
      "Epoch 3 | Step 1200 | loss: 0.5495029625856337 | accuracy: 0.7217243020304567 \n",
      "Epoch 3 | Step 1201 | loss: 0.549373852301248 | accuracy: 0.721756329113924 \n",
      "Epoch 3 | Step 1202 | loss: 0.5492412465238817 | accuracy: 0.7217487373737372 \n",
      "Epoch 3 | Step 1203 | loss: 0.5490646838991713 | accuracy: 0.7219379722921913 \n",
      "Epoch 3 | Step 1204 | loss: 0.5489944906240737 | accuracy: 0.7220084798994973 \n",
      "Epoch 3 | Step 1205 | loss: 0.5489221232427397 | accuracy: 0.7220003132832079 \n",
      "Epoch 3 | Step 1206 | loss: 0.5488096211105591 | accuracy: 0.7221484374999999 \n",
      "Epoch 3 | Step 1207 | loss: 0.5488782097722532 | accuracy: 0.7221399625935161 \n",
      "Epoch 3 | Step 1208 | loss: 0.5485925664800916 | accuracy: 0.722403606965174 \n",
      "Epoch 3 | Step 1209 | loss: 0.5486235026242425 | accuracy: 0.722236780167809 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.6323853731155396 | accuracy: 0.734375 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5697963237762451 | accuracy: 0.7578125 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5806081891059875 | accuracy: 0.7291666666666666 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5762423425912857 | accuracy: 0.72265625 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5512024223804474 | accuracy: 0.74375 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5637384901444117 | accuracy: 0.7265625 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5569254287651607 | accuracy: 0.7276785714285714 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5542263202369213 | accuracy: 0.7265625 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5594860878255632 | accuracy: 0.7170138888888888 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5534591466188431 | accuracy: 0.7265625 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5505595992911946 | accuracy: 0.7272727272727273 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.549939714372158 | accuracy: 0.7317708333333334 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5434099458731138 | accuracy: 0.734375 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5406676552125386 | accuracy: 0.7354910714285714 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5379485090573629 | accuracy: 0.7375 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5415566265583038 | accuracy: 0.734375 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.550273530623492 | accuracy: 0.7288602941176471 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5536206761995951 | accuracy: 0.7248263888888888 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5464393104377546 | accuracy: 0.7302631578947368 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5454897835850716 | accuracy: 0.728125 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5431865993000212 | accuracy: 0.7299107142857143 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5401871786876158 | accuracy: 0.7286931818181818 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5421717879564866 | accuracy: 0.7262228260869565 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.546937191238006 | accuracy: 0.72265625 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5490964734554291 | accuracy: 0.7225 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5472774081505262 | accuracy: 0.7253605769230769 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.544631466821388 | accuracy: 0.7268518518518519 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.540245991732393 | accuracy: 0.73046875 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5370571952441643 | accuracy: 0.734375 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5361611256996791 | accuracy: 0.7354166666666667 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5305315015777465 | accuracy: 0.7404233870967742 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5323682120069861 | accuracy: 0.73974609375 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5338113262797847 | accuracy: 0.7381628787878788 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.538615469546879 | accuracy: 0.7339154411764706 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5394557910306114 | accuracy: 0.7321428571428571 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.53868056088686 | accuracy: 0.7330729166666666 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5400306252208917 | accuracy: 0.7309966216216216 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.540784789543403 | accuracy: 0.7310855263157895 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5399483663913534 | accuracy: 0.7319711538461539 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5383092097938064 | accuracy: 0.731640625 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5371990327428029 | accuracy: 0.7320884146341463 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5352404763301215 | accuracy: 0.7328869047619048 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5362914641236152 | accuracy: 0.7318313953488372 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5377643223513258 | accuracy: 0.7301136363636364 \n",
      "Validation | Epoch 3 | Step 1209 | loss: 0.5378790636857352 | accuracy: 0.727898551358117 \n",
      "Epoch 4 | Step 1210 | loss: 0.5177693367004395 | accuracy: 0.78125 \n",
      "Epoch 4 | Step 1211 | loss: 0.490397185087204 | accuracy: 0.7890625 \n",
      "Epoch 4 | Step 1212 | loss: 0.4975441098213196 | accuracy: 0.7760416666666666 \n",
      "Epoch 4 | Step 1213 | loss: 0.5111927092075348 | accuracy: 0.78515625 \n",
      "Epoch 4 | Step 1214 | loss: 0.49672265648841857 | accuracy: 0.790625 \n",
      "Epoch 4 | Step 1215 | loss: 0.4947039733330409 | accuracy: 0.7890625 \n",
      "Epoch 4 | Step 1216 | loss: 0.49050896082605633 | accuracy: 0.7991071428571429 \n",
      "Epoch 4 | Step 1217 | loss: 0.49353765323758125 | accuracy: 0.79296875 \n",
      "Epoch 4 | Step 1218 | loss: 0.5011559691694047 | accuracy: 0.7829861111111112 \n",
      "Epoch 4 | Step 1219 | loss: 0.5104260593652725 | accuracy: 0.775 \n",
      "Epoch 4 | Step 1220 | loss: 0.5012370402162726 | accuracy: 0.7798295454545454 \n",
      "Epoch 4 | Step 1221 | loss: 0.5036768565575283 | accuracy: 0.7760416666666666 \n",
      "Epoch 4 | Step 1222 | loss: 0.5100752848845262 | accuracy: 0.7716346153846154 \n",
      "Epoch 4 | Step 1223 | loss: 0.5045138725212642 | accuracy: 0.7745535714285714 \n",
      "Epoch 4 | Step 1224 | loss: 0.5054046670595805 | accuracy: 0.7760416666666666 \n",
      "Epoch 4 | Step 1225 | loss: 0.4995204154402018 | accuracy: 0.7783203125 \n",
      "Epoch 4 | Step 1226 | loss: 0.4988950911690207 | accuracy: 0.7720588235294118 \n",
      "Epoch 4 | Step 1227 | loss: 0.4969032473034329 | accuracy: 0.7725694444444444 \n",
      "Epoch 4 | Step 1228 | loss: 0.49380532377644587 | accuracy: 0.7738486842105263 \n",
      "Epoch 4 | Step 1229 | loss: 0.4966288089752197 | accuracy: 0.77109375 \n",
      "Epoch 4 | Step 1230 | loss: 0.49977649109704153 | accuracy: 0.7686011904761905 \n",
      "Epoch 4 | Step 1231 | loss: 0.5009830404411663 | accuracy: 0.7642045454545454 \n",
      "Epoch 4 | Step 1232 | loss: 0.5001693082892377 | accuracy: 0.7635869565217391 \n",
      "Epoch 4 | Step 1233 | loss: 0.5016302863756815 | accuracy: 0.7623697916666666 \n",
      "Epoch 4 | Step 1234 | loss: 0.5069897651672364 | accuracy: 0.75625 \n",
      "Epoch 4 | Step 1235 | loss: 0.5063659972869433 | accuracy: 0.7560096153846154 \n",
      "Epoch 4 | Step 1236 | loss: 0.5068795714113448 | accuracy: 0.7540509259259259 \n",
      "Epoch 4 | Step 1237 | loss: 0.5061280567731176 | accuracy: 0.7566964285714286 \n",
      "Epoch 4 | Step 1238 | loss: 0.5066594985024682 | accuracy: 0.7564655172413793 \n",
      "Epoch 4 | Step 1239 | loss: 0.5080649187167485 | accuracy: 0.75625 \n",
      "Epoch 4 | Step 1240 | loss: 0.50530378568557 | accuracy: 0.7575604838709677 \n",
      "Epoch 4 | Step 1241 | loss: 0.5052691688761115 | accuracy: 0.7578125 \n",
      "Epoch 4 | Step 1242 | loss: 0.5065128378795855 | accuracy: 0.7575757575757576 \n",
      "Epoch 4 | Step 1243 | loss: 0.5041097279857186 | accuracy: 0.7587316176470589 \n",
      "Epoch 4 | Step 1244 | loss: 0.5021282528127943 | accuracy: 0.7602678571428572 \n",
      "Epoch 4 | Step 1245 | loss: 0.5017844976650344 | accuracy: 0.7599826388888888 \n",
      "Epoch 4 | Step 1246 | loss: 0.501788280300192 | accuracy: 0.7597128378378378 \n",
      "Epoch 4 | Step 1247 | loss: 0.503714601460256 | accuracy: 0.7598684210526315 \n",
      "Epoch 4 | Step 1248 | loss: 0.5031374448384994 | accuracy: 0.7612179487179487 \n",
      "Epoch 4 | Step 1249 | loss: 0.5014715842902661 | accuracy: 0.76171875 \n",
      "Epoch 4 | Step 1250 | loss: 0.5028096473798519 | accuracy: 0.7614329268292683 \n",
      "Epoch 4 | Step 1251 | loss: 0.5036942596946444 | accuracy: 0.7611607142857143 \n",
      "Epoch 4 | Step 1252 | loss: 0.5018582018308863 | accuracy: 0.7609011627906976 \n",
      "Epoch 4 | Step 1253 | loss: 0.49961072341962304 | accuracy: 0.7620738636363636 \n",
      "Epoch 4 | Step 1254 | loss: 0.49995735618803244 | accuracy: 0.7628472222222222 \n",
      "Epoch 4 | Step 1255 | loss: 0.4999613010365031 | accuracy: 0.7608695652173914 \n",
      "Epoch 4 | Step 1256 | loss: 0.5015655172632096 | accuracy: 0.7589760638297872 \n",
      "Epoch 4 | Step 1257 | loss: 0.5032039918005468 | accuracy: 0.7578125 \n",
      "Epoch 4 | Step 1258 | loss: 0.5057891242358151 | accuracy: 0.7547831632653061 \n",
      "Epoch 4 | Step 1259 | loss: 0.505882194042206 | accuracy: 0.75375 \n",
      "Epoch 4 | Step 1260 | loss: 0.5051365278515163 | accuracy: 0.7545955882352942 \n",
      "Epoch 4 | Step 1261 | loss: 0.5040060980961875 | accuracy: 0.7548076923076923 \n",
      "Epoch 4 | Step 1262 | loss: 0.5040262453960924 | accuracy: 0.7544221698113207 \n",
      "Epoch 4 | Step 1263 | loss: 0.5043733131002498 | accuracy: 0.7546296296296297 \n",
      "Epoch 4 | Step 1264 | loss: 0.5039111354134301 | accuracy: 0.7553977272727272 \n",
      "Epoch 4 | Step 1265 | loss: 0.5038628705910276 | accuracy: 0.7561383928571429 \n",
      "Epoch 4 | Step 1266 | loss: 0.5029460291067762 | accuracy: 0.7568530701754386 \n",
      "Epoch 4 | Step 1267 | loss: 0.5030982437832605 | accuracy: 0.7572737068965517 \n",
      "Epoch 4 | Step 1268 | loss: 0.5046164964215233 | accuracy: 0.7555614406779662 \n",
      "Epoch 4 | Step 1269 | loss: 0.5043860485156381 | accuracy: 0.7557291666666667 \n",
      "Epoch 4 | Step 1270 | loss: 0.5041242344457598 | accuracy: 0.7558913934426229 \n",
      "Epoch 4 | Step 1271 | loss: 0.5024642910688157 | accuracy: 0.7575604838709677 \n",
      "Epoch 4 | Step 1272 | loss: 0.5029642775891322 | accuracy: 0.7579365079365079 \n",
      "Epoch 4 | Step 1273 | loss: 0.5018134894780817 | accuracy: 0.7587890625 \n",
      "Epoch 4 | Step 1274 | loss: 0.5011054451649007 | accuracy: 0.7596153846153846 \n",
      "Epoch 4 | Step 1275 | loss: 0.5011732840176787 | accuracy: 0.7597064393939394 \n",
      "Epoch 4 | Step 1276 | loss: 0.49960715957541985 | accuracy: 0.7602611940298507 \n",
      "Epoch 4 | Step 1277 | loss: 0.49985713949974864 | accuracy: 0.7598805147058824 \n",
      "Epoch 4 | Step 1278 | loss: 0.501459865898326 | accuracy: 0.7590579710144928 \n",
      "Epoch 4 | Step 1279 | loss: 0.5006070903369361 | accuracy: 0.7600446428571429 \n",
      "Epoch 4 | Step 1280 | loss: 0.5010676686192904 | accuracy: 0.7588028169014085 \n",
      "Epoch 4 | Step 1281 | loss: 0.5005410098367269 | accuracy: 0.7595486111111112 \n",
      "Epoch 4 | Step 1282 | loss: 0.5004573052060116 | accuracy: 0.7602739726027398 \n",
      "Epoch 4 | Step 1283 | loss: 0.499395400285721 | accuracy: 0.7611908783783784 \n",
      "Epoch 4 | Step 1284 | loss: 0.5001712346076967 | accuracy: 0.7602083333333334 \n",
      "Epoch 4 | Step 1285 | loss: 0.49969284158003974 | accuracy: 0.7611019736842105 \n",
      "Epoch 4 | Step 1286 | loss: 0.4992740723219787 | accuracy: 0.760551948051948 \n",
      "Epoch 4 | Step 1287 | loss: 0.49981038119548427 | accuracy: 0.7606169871794872 \n",
      "Epoch 4 | Step 1288 | loss: 0.5008449588395374 | accuracy: 0.759493670886076 \n",
      "Epoch 4 | Step 1289 | loss: 0.5012281920760872 | accuracy: 0.758984375 \n",
      "Epoch 4 | Step 1290 | loss: 0.5004892341884568 | accuracy: 0.7584876543209876 \n",
      "Epoch 4 | Step 1291 | loss: 0.499994457494922 | accuracy: 0.7585746951219512 \n",
      "Epoch 4 | Step 1292 | loss: 0.500297692884882 | accuracy: 0.7584713855421686 \n",
      "Epoch 4 | Step 1293 | loss: 0.4998687615706809 | accuracy: 0.7587425595238095 \n",
      "Epoch 4 | Step 1294 | loss: 0.49905375522725737 | accuracy: 0.759375 \n",
      "Epoch 4 | Step 1295 | loss: 0.49879067651061143 | accuracy: 0.7594476744186046 \n",
      "Epoch 4 | Step 1296 | loss: 0.5002393030572213 | accuracy: 0.7586206896551724 \n",
      "Epoch 4 | Step 1297 | loss: 0.49961006878451886 | accuracy: 0.7595880681818182 \n",
      "Epoch 4 | Step 1298 | loss: 0.49858663155791483 | accuracy: 0.7601825842696629 \n",
      "Epoch 4 | Step 1299 | loss: 0.4992623074187174 | accuracy: 0.7597222222222222 \n",
      "Epoch 4 | Step 1300 | loss: 0.4987029128677244 | accuracy: 0.7606456043956044 \n",
      "Epoch 4 | Step 1301 | loss: 0.49777452453323046 | accuracy: 0.7615489130434783 \n",
      "Epoch 4 | Step 1302 | loss: 0.4973324178367534 | accuracy: 0.7620967741935484 \n",
      "Epoch 4 | Step 1303 | loss: 0.49762081782868584 | accuracy: 0.7616356382978723 \n",
      "Epoch 4 | Step 1304 | loss: 0.49784076276578415 | accuracy: 0.7610197368421052 \n",
      "Epoch 4 | Step 1305 | loss: 0.49942289665341394 | accuracy: 0.7600911458333334 \n",
      "Epoch 4 | Step 1306 | loss: 0.49966030575565473 | accuracy: 0.7595038659793815 \n",
      "Epoch 4 | Step 1307 | loss: 0.5005562281122015 | accuracy: 0.7590880102040817 \n",
      "Epoch 4 | Step 1308 | loss: 0.500417547394531 | accuracy: 0.7591540404040404 \n",
      "Epoch 4 | Step 1309 | loss: 0.49965681940317164 | accuracy: 0.7590625 \n",
      "Epoch 4 | Step 1310 | loss: 0.49834313487062365 | accuracy: 0.7597462871287128 \n",
      "Epoch 4 | Step 1311 | loss: 0.49793288316212453 | accuracy: 0.7596507352941176 \n",
      "Epoch 4 | Step 1312 | loss: 0.4971567820576789 | accuracy: 0.7603155339805825 \n",
      "Epoch 4 | Step 1313 | loss: 0.4978924296223201 | accuracy: 0.7602163461538461 \n",
      "Epoch 4 | Step 1314 | loss: 0.4977854569753012 | accuracy: 0.7604166666666666 \n",
      "Epoch 4 | Step 1315 | loss: 0.4973203477994452 | accuracy: 0.7613502358490566 \n",
      "Epoch 4 | Step 1316 | loss: 0.4978196420402171 | accuracy: 0.7612441588785047 \n",
      "Epoch 4 | Step 1317 | loss: 0.49827037254969286 | accuracy: 0.7608506944444444 \n",
      "Epoch 4 | Step 1318 | loss: 0.49785132008955024 | accuracy: 0.7603211009174312 \n",
      "Epoch 4 | Step 1319 | loss: 0.4982472644610839 | accuracy: 0.7605113636363636 \n",
      "Epoch 4 | Step 1320 | loss: 0.49822740243361885 | accuracy: 0.7602759009009009 \n",
      "Epoch 4 | Step 1321 | loss: 0.4978456478565932 | accuracy: 0.7608816964285714 \n",
      "Epoch 4 | Step 1322 | loss: 0.4986046571119697 | accuracy: 0.760370575221239 \n",
      "Epoch 4 | Step 1323 | loss: 0.4994607058010604 | accuracy: 0.7595942982456141 \n",
      "Epoch 4 | Step 1324 | loss: 0.49981688649758055 | accuracy: 0.7588315217391305 \n",
      "Epoch 4 | Step 1325 | loss: 0.5000483375684969 | accuracy: 0.7588900862068966 \n",
      "Epoch 4 | Step 1326 | loss: 0.5002576696057606 | accuracy: 0.7586805555555556 \n",
      "Epoch 4 | Step 1327 | loss: 0.500949511336068 | accuracy: 0.7580773305084746 \n",
      "Epoch 4 | Step 1328 | loss: 0.5004742133016347 | accuracy: 0.758140756302521 \n",
      "Epoch 4 | Step 1329 | loss: 0.5001261008282503 | accuracy: 0.758203125 \n",
      "Epoch 4 | Step 1330 | loss: 0.4995953640169349 | accuracy: 0.7586518595041323 \n",
      "Epoch 4 | Step 1331 | loss: 0.4997977890440675 | accuracy: 0.7585809426229508 \n",
      "Epoch 4 | Step 1332 | loss: 0.5001333978602557 | accuracy: 0.7580030487804879 \n",
      "Epoch 4 | Step 1333 | loss: 0.5000910888756475 | accuracy: 0.7581905241935484 \n",
      "Epoch 4 | Step 1334 | loss: 0.5003073282241821 | accuracy: 0.75775 \n",
      "Epoch 4 | Step 1335 | loss: 0.5003130081154051 | accuracy: 0.7573164682539683 \n",
      "Epoch 4 | Step 1336 | loss: 0.5007305342381395 | accuracy: 0.7568897637795275 \n",
      "Epoch 4 | Step 1337 | loss: 0.49996534036472445 | accuracy: 0.7574462890625 \n",
      "Epoch 4 | Step 1338 | loss: 0.4998728870883469 | accuracy: 0.7576308139534884 \n",
      "Epoch 4 | Step 1339 | loss: 0.4997343652523481 | accuracy: 0.7575721153846153 \n",
      "Epoch 4 | Step 1340 | loss: 0.5003709672516539 | accuracy: 0.7571564885496184 \n",
      "Epoch 4 | Step 1341 | loss: 0.5004460497787504 | accuracy: 0.7573390151515151 \n",
      "Epoch 4 | Step 1342 | loss: 0.5009870791345611 | accuracy: 0.7569313909774437 \n",
      "Epoch 4 | Step 1343 | loss: 0.5013050016627383 | accuracy: 0.7565298507462688 \n",
      "Epoch 4 | Step 1344 | loss: 0.5012955318998408 | accuracy: 0.7563657407407408 \n",
      "Epoch 4 | Step 1345 | loss: 0.5012587898356073 | accuracy: 0.7563189338235295 \n",
      "Epoch 4 | Step 1346 | loss: 0.500534322575061 | accuracy: 0.7568430656934307 \n",
      "Epoch 4 | Step 1347 | loss: 0.5000992976668952 | accuracy: 0.7569067028985508 \n",
      "Epoch 4 | Step 1348 | loss: 0.5004289053755698 | accuracy: 0.7564073741007195 \n",
      "Epoch 4 | Step 1349 | loss: 0.5005587060536657 | accuracy: 0.7563616071428572 \n",
      "Epoch 4 | Step 1350 | loss: 0.5014014343420664 | accuracy: 0.755540780141844 \n",
      "Epoch 4 | Step 1351 | loss: 0.5015418267166111 | accuracy: 0.7552816901408451 \n",
      "Epoch 4 | Step 1352 | loss: 0.5018163017042867 | accuracy: 0.7551354895104895 \n",
      "Epoch 4 | Step 1353 | loss: 0.5023251827806234 | accuracy: 0.7544487847222222 \n",
      "Epoch 4 | Step 1354 | loss: 0.5022860549647232 | accuracy: 0.7542025862068965 \n",
      "Epoch 4 | Step 1355 | loss: 0.5022925952934238 | accuracy: 0.7540667808219178 \n",
      "Epoch 4 | Step 1356 | loss: 0.5018879073817712 | accuracy: 0.7544642857142857 \n",
      "Epoch 4 | Step 1357 | loss: 0.502159255984667 | accuracy: 0.7541173986486487 \n",
      "Epoch 4 | Step 1358 | loss: 0.5021813551851565 | accuracy: 0.7540897651006712 \n",
      "Epoch 4 | Step 1359 | loss: 0.5022307181358335 | accuracy: 0.7542708333333333 \n",
      "Epoch 4 | Step 1360 | loss: 0.5019215213147218 | accuracy: 0.7547599337748344 \n",
      "Epoch 4 | Step 1361 | loss: 0.5021043978631493 | accuracy: 0.7547286184210527 \n",
      "Epoch 4 | Step 1362 | loss: 0.5020833732255919 | accuracy: 0.7549019607843137 \n",
      "Epoch 4 | Step 1363 | loss: 0.5019178698202229 | accuracy: 0.755073051948052 \n",
      "Epoch 4 | Step 1364 | loss: 0.5015133236685104 | accuracy: 0.7554435483870968 \n",
      "Epoch 4 | Step 1365 | loss: 0.5008911339518348 | accuracy: 0.7558092948717948 \n",
      "Epoch 4 | Step 1366 | loss: 0.501594626409992 | accuracy: 0.7556727707006369 \n",
      "Epoch 4 | Step 1367 | loss: 0.5023881715687012 | accuracy: 0.7550435126582278 \n",
      "Epoch 4 | Step 1368 | loss: 0.5026276878215978 | accuracy: 0.754815251572327 \n",
      "Epoch 4 | Step 1369 | loss: 0.503133510239422 | accuracy: 0.7545898437499999 \n",
      "Epoch 4 | Step 1370 | loss: 0.5035397327094341 | accuracy: 0.7539790372670807 \n",
      "Epoch 4 | Step 1371 | loss: 0.5038383281157337 | accuracy: 0.7537615740740741 \n",
      "Epoch 4 | Step 1372 | loss: 0.503935367234645 | accuracy: 0.7535467791411042 \n",
      "Epoch 4 | Step 1373 | loss: 0.503758719236385 | accuracy: 0.7535251524390243 \n",
      "Epoch 4 | Step 1374 | loss: 0.5033208370208735 | accuracy: 0.7540719696969697 \n",
      "Epoch 4 | Step 1375 | loss: 0.5030960501676577 | accuracy: 0.7543298192771084 \n",
      "Epoch 4 | Step 1376 | loss: 0.5026364615577418 | accuracy: 0.7546781437125748 \n",
      "Epoch 4 | Step 1377 | loss: 0.502983537103448 | accuracy: 0.7549293154761904 \n",
      "Epoch 4 | Step 1378 | loss: 0.5026516168427885 | accuracy: 0.7552699704142011 \n",
      "Epoch 4 | Step 1379 | loss: 0.5020728370722597 | accuracy: 0.7558823529411764 \n",
      "Epoch 4 | Step 1380 | loss: 0.5016265406943198 | accuracy: 0.7562134502923976 \n",
      "Epoch 4 | Step 1381 | loss: 0.5015225249320955 | accuracy: 0.7559956395348837 \n",
      "Epoch 4 | Step 1382 | loss: 0.5008475804604541 | accuracy: 0.7566835260115607 \n",
      "Epoch 4 | Step 1383 | loss: 0.5007651300950976 | accuracy: 0.7566451149425287 \n",
      "Epoch 4 | Step 1384 | loss: 0.5006016658033637 | accuracy: 0.756875 \n",
      "Epoch 4 | Step 1385 | loss: 0.50075036202642 | accuracy: 0.7567471590909091 \n",
      "Epoch 4 | Step 1386 | loss: 0.5012555390091261 | accuracy: 0.7562676553672316 \n",
      "Epoch 4 | Step 1387 | loss: 0.5013487997014866 | accuracy: 0.7561446629213483 \n",
      "Epoch 4 | Step 1388 | loss: 0.5013194005915568 | accuracy: 0.756197625698324 \n",
      "Epoch 4 | Step 1389 | loss: 0.5010330405500195 | accuracy: 0.7565104166666666 \n",
      "Epoch 4 | Step 1390 | loss: 0.5012273159474953 | accuracy: 0.7563881215469613 \n",
      "Epoch 4 | Step 1391 | loss: 0.5007927530741948 | accuracy: 0.7566964285714286 \n",
      "Epoch 4 | Step 1392 | loss: 0.49993126656188286 | accuracy: 0.7570867486338798 \n",
      "Epoch 4 | Step 1393 | loss: 0.49946155755416155 | accuracy: 0.7573029891304348 \n",
      "Epoch 4 | Step 1394 | loss: 0.49918513249706525 | accuracy: 0.7577702702702702 \n",
      "Epoch 4 | Step 1395 | loss: 0.49920575961630775 | accuracy: 0.7578965053763441 \n",
      "Epoch 4 | Step 1396 | loss: 0.4992980748255617 | accuracy: 0.7576871657754011 \n",
      "Epoch 4 | Step 1397 | loss: 0.4996977256650615 | accuracy: 0.7569813829787234 \n",
      "Epoch 4 | Step 1398 | loss: 0.49947159835901156 | accuracy: 0.7571097883597884 \n",
      "Epoch 4 | Step 1399 | loss: 0.49997899548003494 | accuracy: 0.7567434210526316 \n",
      "Epoch 4 | Step 1400 | loss: 0.4994827833475238 | accuracy: 0.7571989528795812 \n",
      "Epoch 4 | Step 1401 | loss: 0.4990181829780335 | accuracy: 0.757568359375 \n",
      "Epoch 4 | Step 1402 | loss: 0.498475637306203 | accuracy: 0.7582577720207254 \n",
      "Epoch 4 | Step 1403 | loss: 0.4984959356256362 | accuracy: 0.7581346649484536 \n",
      "Epoch 4 | Step 1404 | loss: 0.49842140689874254 | accuracy: 0.7582532051282052 \n",
      "Epoch 4 | Step 1405 | loss: 0.4983965605497355 | accuracy: 0.7582110969387755 \n",
      "Epoch 4 | Step 1406 | loss: 0.4982812516580373 | accuracy: 0.7584866751269036 \n",
      "Epoch 4 | Step 1407 | loss: 0.49790868930744353 | accuracy: 0.7586016414141414 \n",
      "Epoch 4 | Step 1408 | loss: 0.4975925875668545 | accuracy: 0.7590295226130653 \n",
      "Epoch 4 | Step 1409 | loss: 0.4972412183880801 | accuracy: 0.759296875 \n",
      "Epoch 4 | Step 1410 | loss: 0.49769620990278657 | accuracy: 0.7591728855721394 \n",
      "Epoch 4 | Step 1411 | loss: 0.49737065366589145 | accuracy: 0.7593595297029703 \n",
      "Epoch 4 | Step 1412 | loss: 0.4970869332405142 | accuracy: 0.7598522167487685 \n",
      "Epoch 4 | Step 1413 | loss: 0.4971104221893287 | accuracy: 0.7598805147058824 \n",
      "Epoch 4 | Step 1414 | loss: 0.49741151231091146 | accuracy: 0.7595274390243902 \n",
      "Epoch 4 | Step 1415 | loss: 0.49797143042087505 | accuracy: 0.7590260922330098 \n",
      "Epoch 4 | Step 1416 | loss: 0.49857017657031133 | accuracy: 0.7586050724637681 \n",
      "Epoch 4 | Step 1417 | loss: 0.49894534409619246 | accuracy: 0.7583383413461539 \n",
      "Epoch 4 | Step 1418 | loss: 0.4990975561609674 | accuracy: 0.7582236842105263 \n",
      "Epoch 4 | Step 1419 | loss: 0.499390093343598 | accuracy: 0.7579613095238096 \n",
      "Epoch 4 | Step 1420 | loss: 0.4993745690273443 | accuracy: 0.7579976303317536 \n",
      "Epoch 4 | Step 1421 | loss: 0.4990050119330294 | accuracy: 0.7583284198113207 \n",
      "Epoch 4 | Step 1422 | loss: 0.49856230448669064 | accuracy: 0.7585093896713615 \n",
      "Epoch 4 | Step 1423 | loss: 0.4986307371721085 | accuracy: 0.7583235981308412 \n",
      "Epoch 4 | Step 1424 | loss: 0.49866934695909143 | accuracy: 0.7582848837209303 \n",
      "Epoch 4 | Step 1425 | loss: 0.49869305819824844 | accuracy: 0.7582465277777778 \n",
      "Epoch 4 | Step 1426 | loss: 0.4982108079618019 | accuracy: 0.7584965437788018 \n",
      "Epoch 4 | Step 1427 | loss: 0.4984385142905992 | accuracy: 0.7583858944954128 \n",
      "Epoch 4 | Step 1428 | loss: 0.49846000309404126 | accuracy: 0.7584189497716894 \n",
      "Epoch 4 | Step 1429 | loss: 0.4984881478277115 | accuracy: 0.7583806818181819 \n",
      "Epoch 4 | Step 1430 | loss: 0.49865422273113674 | accuracy: 0.7583427601809954 \n",
      "Epoch 4 | Step 1431 | loss: 0.49847431601704734 | accuracy: 0.7585163288288288 \n",
      "Epoch 4 | Step 1432 | loss: 0.4982550223044746 | accuracy: 0.7586182735426009 \n",
      "Epoch 4 | Step 1433 | loss: 0.4978443011641498 | accuracy: 0.7587890625 \n",
      "Epoch 4 | Step 1434 | loss: 0.4976899649037251 | accuracy: 0.7588194444444445 \n",
      "Epoch 4 | Step 1435 | loss: 0.49775330959695585 | accuracy: 0.7587112831858407 \n",
      "Epoch 4 | Step 1436 | loss: 0.49804295487865957 | accuracy: 0.7584664096916299 \n",
      "Epoch 4 | Step 1437 | loss: 0.4978039161416518 | accuracy: 0.758703399122807 \n",
      "Epoch 4 | Step 1438 | loss: 0.49780012959996645 | accuracy: 0.7585971615720524 \n",
      "Epoch 4 | Step 1439 | loss: 0.4978659384924428 | accuracy: 0.7587635869565217 \n",
      "Epoch 4 | Step 1440 | loss: 0.4972109835901297 | accuracy: 0.7591314935064936 \n",
      "Epoch 4 | Step 1441 | loss: 0.49696565663506204 | accuracy: 0.7594288793103449 \n",
      "Epoch 4 | Step 1442 | loss: 0.49692519130624885 | accuracy: 0.7593884120171673 \n",
      "Epoch 4 | Step 1443 | loss: 0.49678561740960786 | accuracy: 0.7595486111111112 \n",
      "Epoch 4 | Step 1444 | loss: 0.49640616444831154 | accuracy: 0.7599734042553191 \n",
      "Epoch 4 | Step 1445 | loss: 0.4959845689393702 | accuracy: 0.7601297669491526 \n",
      "Epoch 4 | Step 1446 | loss: 0.4957656716998615 | accuracy: 0.7602188818565401 \n",
      "Epoch 4 | Step 1447 | loss: 0.4956759799177903 | accuracy: 0.7601102941176471 \n",
      "Epoch 4 | Step 1448 | loss: 0.4958718689665132 | accuracy: 0.7599372384937239 \n",
      "Epoch 4 | Step 1449 | loss: 0.4956839945167299 | accuracy: 0.7599609375 \n",
      "Epoch 4 | Step 1450 | loss: 0.4951885826112814 | accuracy: 0.7602437759336099 \n",
      "Epoch 4 | Step 1451 | loss: 0.49464527080374276 | accuracy: 0.7605242768595041 \n",
      "Epoch 4 | Step 1452 | loss: 0.4945416379367369 | accuracy: 0.7608667695473251 \n",
      "Epoch 4 | Step 1453 | loss: 0.49474640654735835 | accuracy: 0.7606941598360656 \n",
      "Epoch 4 | Step 1454 | loss: 0.49482509068080316 | accuracy: 0.7608418367346939 \n",
      "Epoch 4 | Step 1455 | loss: 0.49463323861118214 | accuracy: 0.760670731707317 \n",
      "Epoch 4 | Step 1456 | loss: 0.49433340946672377 | accuracy: 0.7609438259109311 \n",
      "Epoch 4 | Step 1457 | loss: 0.4944700698458375 | accuracy: 0.7608366935483871 \n",
      "Epoch 4 | Step 1458 | loss: 0.4943292642453584 | accuracy: 0.7609814257028112 \n",
      "Epoch 4 | Step 1459 | loss: 0.49436161577701526 | accuracy: 0.7610625 \n",
      "Epoch 4 | Step 1460 | loss: 0.4942727777587461 | accuracy: 0.7610806772908366 \n",
      "Epoch 4 | Step 1461 | loss: 0.49414858872455225 | accuracy: 0.7610367063492064 \n",
      "Epoch 4 | Step 1462 | loss: 0.4939049962952199 | accuracy: 0.7611166007905138 \n",
      "Epoch 4 | Step 1463 | loss: 0.4938325389163697 | accuracy: 0.7613188976377953 \n",
      "Epoch 4 | Step 1464 | loss: 0.49363915756636934 | accuracy: 0.7613357843137255 \n",
      "Epoch 4 | Step 1465 | loss: 0.49358981265686414 | accuracy: 0.76123046875 \n",
      "Epoch 4 | Step 1466 | loss: 0.49334636748068955 | accuracy: 0.7615515564202334 \n",
      "Epoch 4 | Step 1467 | loss: 0.4929239518882689 | accuracy: 0.7618095930232558 \n",
      "Epoch 4 | Step 1468 | loss: 0.4931395787990228 | accuracy: 0.761703667953668 \n",
      "Epoch 4 | Step 1469 | loss: 0.49267628777485595 | accuracy: 0.7620793269230769 \n",
      "Epoch 4 | Step 1470 | loss: 0.49308855905843385 | accuracy: 0.7613745210727969 \n",
      "Epoch 4 | Step 1471 | loss: 0.4932836377211196 | accuracy: 0.7610925572519084 \n",
      "Epoch 4 | Step 1472 | loss: 0.49313150827875574 | accuracy: 0.760990969581749 \n",
      "Epoch 4 | Step 1473 | loss: 0.49326519995476226 | accuracy: 0.7609493371212122 \n",
      "Epoch 4 | Step 1474 | loss: 0.49306137471828787 | accuracy: 0.7609669811320755 \n",
      "Epoch 4 | Step 1475 | loss: 0.49251380630005537 | accuracy: 0.761454417293233 \n",
      "Epoch 4 | Step 1476 | loss: 0.4922734077057139 | accuracy: 0.7617626404494382 \n",
      "Epoch 4 | Step 1477 | loss: 0.4925643717175096 | accuracy: 0.761660447761194 \n",
      "Epoch 4 | Step 1478 | loss: 0.49240370864761773 | accuracy: 0.7619075278810409 \n",
      "Epoch 4 | Step 1479 | loss: 0.4922727667623093 | accuracy: 0.7620949074074074 \n",
      "Epoch 4 | Step 1480 | loss: 0.492341176940066 | accuracy: 0.7623962177121771 \n",
      "Epoch 4 | Step 1481 | loss: 0.4922777449383452 | accuracy: 0.7624080882352942 \n",
      "Epoch 4 | Step 1482 | loss: 0.4921833610796663 | accuracy: 0.7622481684981685 \n",
      "Epoch 4 | Step 1483 | loss: 0.4918893403815524 | accuracy: 0.7623175182481752 \n",
      "Epoch 4 | Step 1484 | loss: 0.4918117202411995 | accuracy: 0.7623863636363636 \n",
      "Epoch 4 | Step 1485 | loss: 0.4917553461332249 | accuracy: 0.7624547101449274 \n",
      "Epoch 4 | Step 1486 | loss: 0.491569326134795 | accuracy: 0.7625225631768952 \n",
      "Epoch 4 | Step 1487 | loss: 0.4914806872177464 | accuracy: 0.7624213129496401 \n",
      "Epoch 4 | Step 1488 | loss: 0.49172624219275685 | accuracy: 0.7621527777777776 \n",
      "Epoch 4 | Step 1489 | loss: 0.4913615976061137 | accuracy: 0.7624441964285712 \n",
      "Epoch 4 | Step 1490 | loss: 0.49124663357632836 | accuracy: 0.762511120996441 \n",
      "Epoch 4 | Step 1491 | loss: 0.4911116286583823 | accuracy: 0.7625775709219855 \n",
      "Epoch 4 | Step 1492 | loss: 0.4912492577052366 | accuracy: 0.7625883392226145 \n",
      "Epoch 4 | Step 1493 | loss: 0.49094694139252215 | accuracy: 0.7627640845070418 \n",
      "Epoch 4 | Step 1494 | loss: 0.49102812336202223 | accuracy: 0.7627741228070172 \n",
      "Epoch 4 | Step 1495 | loss: 0.49127389688591827 | accuracy: 0.7626748251748248 \n",
      "Epoch 4 | Step 1496 | loss: 0.49092878531080475 | accuracy: 0.7628484320557487 \n",
      "Epoch 4 | Step 1497 | loss: 0.4906338044545714 | accuracy: 0.7630208333333329 \n",
      "Epoch 4 | Step 1498 | loss: 0.4905346555693336 | accuracy: 0.763192041522491 \n",
      "Epoch 4 | Step 1499 | loss: 0.490801393985748 | accuracy: 0.7630387931034479 \n",
      "Epoch 4 | Step 1500 | loss: 0.4904987827404255 | accuracy: 0.7632624570446731 \n",
      "Epoch 4 | Step 1501 | loss: 0.4902467563340106 | accuracy: 0.7635380993150681 \n",
      "Epoch 4 | Step 1502 | loss: 0.48998566119337217 | accuracy: 0.7637052047781566 \n",
      "Epoch 4 | Step 1503 | loss: 0.48950745449179667 | accuracy: 0.7641369047619043 \n",
      "Epoch 4 | Step 1504 | loss: 0.49003681580899094 | accuracy: 0.7638771186440673 \n",
      "Epoch 4 | Step 1505 | loss: 0.48986736362850314 | accuracy: 0.7640413851351345 \n",
      "Epoch 4 | Step 1506 | loss: 0.48995968107422566 | accuracy: 0.7637836700336694 \n",
      "Epoch 4 | Step 1507 | loss: 0.4897937066603024 | accuracy: 0.7641568791946303 \n",
      "Epoch 4 | Step 1508 | loss: 0.489635894131102 | accuracy: 0.7642140468227419 \n",
      "Epoch 4 | Step 1509 | loss: 0.489247438907623 | accuracy: 0.764479166666666 \n",
      "Epoch 4 | Step 1510 | loss: 0.4891919928333685 | accuracy: 0.7645867940199329 \n",
      "Epoch 4 | Step 1511 | loss: 0.48917157661835853 | accuracy: 0.7645902317880788 \n",
      "Epoch 4 | Step 1512 | loss: 0.4890643891328236 | accuracy: 0.7646452145214515 \n",
      "Epoch 4 | Step 1513 | loss: 0.4887921792504032 | accuracy: 0.7649054276315783 \n",
      "Epoch 4 | Step 1514 | loss: 0.48902787693211264 | accuracy: 0.7645491803278682 \n",
      "Epoch 4 | Step 1515 | loss: 0.4886109498785989 | accuracy: 0.7649101307189536 \n",
      "Epoch 4 | Step 1516 | loss: 0.4881885153657059 | accuracy: 0.7652687296416931 \n",
      "Epoch 4 | Step 1517 | loss: 0.48813583401890515 | accuracy: 0.7653206168831163 \n",
      "Epoch 4 | Step 1518 | loss: 0.4876494908217085 | accuracy: 0.7657261326860835 \n",
      "Epoch 4 | Step 1519 | loss: 0.48743270174149517 | accuracy: 0.7658770161290316 \n",
      "Epoch 4 | Step 1520 | loss: 0.48728271858868466 | accuracy: 0.7659766881028932 \n",
      "Epoch 4 | Step 1521 | loss: 0.48729351487679334 | accuracy: 0.7659755608974352 \n",
      "Epoch 4 | Step 1522 | loss: 0.4872383073495978 | accuracy: 0.7660243610223636 \n",
      "Epoch 4 | Step 1523 | loss: 0.48711197571769616 | accuracy: 0.7661226114649675 \n",
      "Epoch 4 | Step 1524 | loss: 0.4866475029597204 | accuracy: 0.7662698412698407 \n",
      "Epoch 4 | Step 1525 | loss: 0.48665961783520756 | accuracy: 0.7661194620253158 \n",
      "Epoch 4 | Step 1526 | loss: 0.48669700780501474 | accuracy: 0.7662657728706618 \n",
      "Epoch 4 | Step 1527 | loss: 0.48665411929664343 | accuracy: 0.7663128930817603 \n",
      "Epoch 4 | Step 1528 | loss: 0.4865685332344615 | accuracy: 0.7662127742946702 \n",
      "Epoch 4 | Step 1529 | loss: 0.4864271492697296 | accuracy: 0.7662109374999992 \n",
      "Epoch 4 | Step 1530 | loss: 0.4864659900791546 | accuracy: 0.7660630841121489 \n",
      "Epoch 4 | Step 1531 | loss: 0.4863991415278509 | accuracy: 0.7661587732919247 \n",
      "Epoch 4 | Step 1532 | loss: 0.4864516704813243 | accuracy: 0.7662054953560364 \n",
      "Epoch 4 | Step 1533 | loss: 0.4862264609999124 | accuracy: 0.766300154320987 \n",
      "Epoch 4 | Step 1534 | loss: 0.4860087292010965 | accuracy: 0.7663461538461531 \n",
      "Epoch 4 | Step 1535 | loss: 0.48610571246205636 | accuracy: 0.7662001533742324 \n",
      "Epoch 4 | Step 1536 | loss: 0.4863068424962709 | accuracy: 0.7661506116207945 \n",
      "Epoch 4 | Step 1537 | loss: 0.4860919140642733 | accuracy: 0.7663395579268286 \n",
      "Epoch 4 | Step 1538 | loss: 0.4857966873602299 | accuracy: 0.7665748480243154 \n",
      "Epoch 4 | Step 1539 | loss: 0.48591751736221866 | accuracy: 0.7665246212121205 \n",
      "Epoch 4 | Step 1540 | loss: 0.4858213789153313 | accuracy: 0.7667579305135945 \n",
      "Epoch 4 | Step 1541 | loss: 0.4857747890504007 | accuracy: 0.7667545180722886 \n",
      "Epoch 4 | Step 1542 | loss: 0.4856511349076621 | accuracy: 0.7667042042042036 \n",
      "Epoch 4 | Step 1543 | loss: 0.48546136148318536 | accuracy: 0.7668880988023945 \n",
      "Epoch 4 | Step 1544 | loss: 0.48554870717561044 | accuracy: 0.766744402985074 \n",
      "Epoch 4 | Step 1545 | loss: 0.4854528505709907 | accuracy: 0.7667875744047612 \n",
      "Epoch 4 | Step 1546 | loss: 0.485343081218906 | accuracy: 0.7668304896142426 \n",
      "Epoch 4 | Step 1547 | loss: 0.4851788881086031 | accuracy: 0.7668731508875732 \n",
      "Epoch 4 | Step 1548 | loss: 0.48503673410696946 | accuracy: 0.7670077433628312 \n",
      "Epoch 4 | Step 1549 | loss: 0.4850940767456501 | accuracy: 0.7671415441176463 \n",
      "Epoch 4 | Step 1550 | loss: 0.4848588724290169 | accuracy: 0.7672287390029319 \n",
      "Epoch 4 | Step 1551 | loss: 0.48465499029173464 | accuracy: 0.7673611111111105 \n",
      "Epoch 4 | Step 1552 | loss: 0.4844757789425528 | accuracy: 0.7674927113702618 \n",
      "Epoch 4 | Step 1553 | loss: 0.48468252912510246 | accuracy: 0.7673055959302318 \n",
      "Epoch 4 | Step 1554 | loss: 0.4843118388583692 | accuracy: 0.7674818840579704 \n",
      "Epoch 4 | Step 1555 | loss: 0.484291308015757 | accuracy: 0.7676119942196525 \n",
      "Epoch 4 | Step 1556 | loss: 0.4841039868699712 | accuracy: 0.7676963256484143 \n",
      "Epoch 4 | Step 1557 | loss: 0.48391899158214674 | accuracy: 0.7678699712643672 \n",
      "Epoch 4 | Step 1558 | loss: 0.4838261207229426 | accuracy: 0.7678187679083088 \n",
      "Epoch 4 | Step 1559 | loss: 0.48416297188826946 | accuracy: 0.7677232142857137 \n",
      "Epoch 4 | Step 1560 | loss: 0.48377659679138396 | accuracy: 0.7681178774928769 \n",
      "Epoch 4 | Step 1561 | loss: 0.4836732133884319 | accuracy: 0.7681551846590903 \n",
      "Epoch 4 | Step 1562 | loss: 0.4835372331628716 | accuracy: 0.7681037535410759 \n",
      "Epoch 4 | Step 1563 | loss: 0.4836121204040816 | accuracy: 0.7681408898305079 \n",
      "Epoch 4 | Step 1564 | loss: 0.48336332834942214 | accuracy: 0.7683098591549289 \n",
      "Epoch 4 | Step 1565 | loss: 0.4828440422254999 | accuracy: 0.7684339887640443 \n",
      "Epoch 4 | Step 1566 | loss: 0.4829048693847921 | accuracy: 0.7684261204481786 \n",
      "Epoch 4 | Step 1567 | loss: 0.4830388395979415 | accuracy: 0.7682873603351948 \n",
      "Epoch 4 | Step 1568 | loss: 0.48272625433701305 | accuracy: 0.7684540389972139 \n",
      "Epoch 4 | Step 1569 | loss: 0.4830319393012256 | accuracy: 0.7682291666666661 \n",
      "Epoch 4 | Step 1570 | loss: 0.4829673927246366 | accuracy: 0.7681353878116337 \n",
      "Epoch 4 | Step 1571 | loss: 0.482931935490824 | accuracy: 0.7681716160220988 \n",
      "Epoch 4 | Step 1572 | loss: 0.48311598701582115 | accuracy: 0.7681646005509636 \n",
      "Epoch 4 | Step 1573 | loss: 0.4827403047910101 | accuracy: 0.7684151785714279 \n",
      "Epoch 4 | Step 1574 | loss: 0.48259336785094353 | accuracy: 0.7685787671232871 \n",
      "Epoch 4 | Step 1575 | loss: 0.48257262475503576 | accuracy: 0.768656079234972 \n",
      "Epoch 4 | Step 1576 | loss: 0.4827887919358399 | accuracy: 0.7685626702997269 \n",
      "Epoch 4 | Step 1577 | loss: 0.4824935592225062 | accuracy: 0.768809442934782 \n",
      "Epoch 4 | Step 1578 | loss: 0.48247699992766524 | accuracy: 0.7687584688346877 \n",
      "Epoch 4 | Step 1579 | loss: 0.48245001250022146 | accuracy: 0.7687077702702697 \n",
      "Epoch 4 | Step 1580 | loss: 0.4826348622372206 | accuracy: 0.7684888814016166 \n",
      "Epoch 4 | Step 1581 | loss: 0.482554770685652 | accuracy: 0.7685231854838703 \n",
      "Epoch 4 | Step 1582 | loss: 0.48222045652348594 | accuracy: 0.7688505361930289 \n",
      "Epoch 4 | Step 1583 | loss: 0.4820107713262025 | accuracy: 0.7690090240641705 \n",
      "Epoch 4 | Step 1584 | loss: 0.4821763643423714 | accuracy: 0.768916666666666 \n",
      "Epoch 4 | Step 1585 | loss: 0.4823357761698832 | accuracy: 0.7687416888297867 \n",
      "Epoch 4 | Step 1586 | loss: 0.4823651278999185 | accuracy: 0.7687748673740047 \n",
      "Epoch 4 | Step 1587 | loss: 0.482404241486201 | accuracy: 0.7686838624338619 \n",
      "Epoch 4 | Step 1588 | loss: 0.48224424104891833 | accuracy: 0.7687582453825852 \n",
      "Epoch 4 | Step 1589 | loss: 0.482149778306484 | accuracy: 0.7687911184210521 \n",
      "Epoch 4 | Step 1590 | loss: 0.48183614031223465 | accuracy: 0.7690288713910756 \n",
      "Epoch 4 | Step 1591 | loss: 0.48189116288854167 | accuracy: 0.7691017670157062 \n",
      "Epoch 4 | Step 1592 | loss: 0.48189526625152646 | accuracy: 0.7691334856396861 \n",
      "Epoch 4 | Step 1593 | loss: 0.48203022017454084 | accuracy: 0.7689615885416661 \n",
      "Epoch 4 | Step 1594 | loss: 0.48198185307638963 | accuracy: 0.768912337662337 \n",
      "Epoch 4 | Step 1595 | loss: 0.4819975240551744 | accuracy: 0.7688228626942999 \n",
      "Epoch 4 | Step 1596 | loss: 0.482101592444634 | accuracy: 0.768774224806201 \n",
      "Epoch 4 | Step 1597 | loss: 0.4820843336662064 | accuracy: 0.7688063788659788 \n",
      "Epoch 4 | Step 1598 | loss: 0.482198528504923 | accuracy: 0.7687982005141383 \n",
      "Epoch 4 | Step 1599 | loss: 0.4822741090487209 | accuracy: 0.7688301282051276 \n",
      "Epoch 4 | Step 1600 | loss: 0.4822024745709449 | accuracy: 0.7687420076726337 \n",
      "Epoch 4 | Step 1601 | loss: 0.482247607820496 | accuracy: 0.7688137755102035 \n",
      "Epoch 4 | Step 1602 | loss: 0.48203033891342956 | accuracy: 0.7690044529262081 \n",
      "Epoch 4 | Step 1603 | loss: 0.4822617158066801 | accuracy: 0.7687579314720806 \n",
      "Epoch 4 | Step 1604 | loss: 0.482088233021241 | accuracy: 0.7689082278481006 \n",
      "Epoch 4 | Step 1605 | loss: 0.48188161526364487 | accuracy: 0.7689788510101004 \n",
      "Epoch 4 | Step 1606 | loss: 0.4817438464921425 | accuracy: 0.7691278337531481 \n",
      "Epoch 4 | Step 1607 | loss: 0.48169502780665086 | accuracy: 0.7691975502512557 \n",
      "Epoch 4 | Step 1608 | loss: 0.48163589387011685 | accuracy: 0.769149436090225 \n",
      "Epoch 4 | Step 1609 | loss: 0.48156205199658847 | accuracy: 0.7692578124999995 \n",
      "Epoch 4 | Step 1610 | loss: 0.4817190923149744 | accuracy: 0.7692877182044882 \n",
      "Epoch 4 | Step 1611 | loss: 0.48152018230945887 | accuracy: 0.7694729477611935 \n",
      "Epoch 4 | Step 1612 | loss: 0.4815831657674707 | accuracy: 0.7693604538517608 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5601344108581543 | accuracy: 0.75 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.49814510345458984 | accuracy: 0.796875 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5204624931017557 | accuracy: 0.78125 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5248248428106308 | accuracy: 0.765625 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5003984451293946 | accuracy: 0.78125 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5206072231133779 | accuracy: 0.7578125 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5172909625938961 | accuracy: 0.7522321428571429 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5168526358902454 | accuracy: 0.75 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5186015731758542 | accuracy: 0.7482638888888888 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5115997582674027 | accuracy: 0.75625 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.509775310754776 | accuracy: 0.7556818181818182 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5057596092422804 | accuracy: 0.76171875 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5007328207676227 | accuracy: 0.7596153846153846 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.49948874754565104 | accuracy: 0.7611607142857143 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.4993633290131887 | accuracy: 0.7635416666666667 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5006638634949923 | accuracy: 0.76171875 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5089535835911246 | accuracy: 0.7536764705882353 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5137443360355165 | accuracy: 0.7508680555555556 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.506927772572166 | accuracy: 0.7557565789473685 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5055561780929565 | accuracy: 0.7539062500000001 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5023987548691886 | accuracy: 0.7537202380952381 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.49871874532916327 | accuracy: 0.7528409090909091 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5030367128227068 | accuracy: 0.748641304347826 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5090749897062778 | accuracy: 0.744140625 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5137541377544403 | accuracy: 0.743125 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5110419598909525 | accuracy: 0.7457932692307693 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5084631487175271 | accuracy: 0.7459490740740741 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5054716042109898 | accuracy: 0.7477678571428571 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5018529881691111 | accuracy: 0.7505387931034483 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5002619832754135 | accuracy: 0.7526041666666666 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.49444623916379865 | accuracy: 0.7565524193548387 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.49584713391959667 | accuracy: 0.75634765625 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.49628454266172467 | accuracy: 0.7552083333333334 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.49988561167436485 | accuracy: 0.7522977941176471 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5009411283901759 | accuracy: 0.7517857142857143 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.4994623520308071 | accuracy: 0.7517361111111112 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5002076021722845 | accuracy: 0.7512668918918919 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.5010028034448624 | accuracy: 0.7516447368421053 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.49989249232487803 | accuracy: 0.7524038461538461 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.49805653765797614 | accuracy: 0.75390625 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.4968085405303211 | accuracy: 0.7541920731707317 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.49478384994325186 | accuracy: 0.7552083333333334 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.4954840942870739 | accuracy: 0.7536337209302325 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.49792655354196375 | accuracy: 0.7517755681818182 \n",
      "Validation | Epoch 4 | Step 1612 | loss: 0.4978245728545719 | accuracy: 0.7514945652749804 \n",
      "Epoch 5 | Step 1613 | loss: 0.516775369644165 | accuracy: 0.8125 \n",
      "Epoch 5 | Step 1614 | loss: 0.4500531554222107 | accuracy: 0.8203125 \n",
      "Epoch 5 | Step 1615 | loss: 0.45592402418454486 | accuracy: 0.8020833333333334 \n",
      "Epoch 5 | Step 1616 | loss: 0.47213228791952133 | accuracy: 0.80078125 \n",
      "Epoch 5 | Step 1617 | loss: 0.4530739843845367 | accuracy: 0.80625 \n",
      "Epoch 5 | Step 1618 | loss: 0.44758901993433636 | accuracy: 0.796875 \n",
      "Epoch 5 | Step 1619 | loss: 0.4465391933917999 | accuracy: 0.7991071428571429 \n",
      "Epoch 5 | Step 1620 | loss: 0.44332683086395264 | accuracy: 0.80078125 \n",
      "Epoch 5 | Step 1621 | loss: 0.4514955480893453 | accuracy: 0.7951388888888888 \n",
      "Epoch 5 | Step 1622 | loss: 0.461590176820755 | accuracy: 0.7875 \n",
      "Epoch 5 | Step 1623 | loss: 0.4479631212624637 | accuracy: 0.8011363636363636 \n",
      "Epoch 5 | Step 1624 | loss: 0.4470130205154419 | accuracy: 0.80078125 \n",
      "Epoch 5 | Step 1625 | loss: 0.45542558339925915 | accuracy: 0.7932692307692307 \n",
      "Epoch 5 | Step 1626 | loss: 0.45372286438941956 | accuracy: 0.7946428571428571 \n",
      "Epoch 5 | Step 1627 | loss: 0.4545234739780426 | accuracy: 0.7927083333333333 \n",
      "Epoch 5 | Step 1628 | loss: 0.4484412670135498 | accuracy: 0.7958984375 \n",
      "Epoch 5 | Step 1629 | loss: 0.4506094771272996 | accuracy: 0.7931985294117647 \n",
      "Epoch 5 | Step 1630 | loss: 0.4480973399347729 | accuracy: 0.7951388888888888 \n",
      "Epoch 5 | Step 1631 | loss: 0.4458288738602086 | accuracy: 0.7952302631578947 \n",
      "Epoch 5 | Step 1632 | loss: 0.4496362149715424 | accuracy: 0.79453125 \n",
      "Epoch 5 | Step 1633 | loss: 0.4516549692267463 | accuracy: 0.7938988095238095 \n",
      "Epoch 5 | Step 1634 | loss: 0.45314261452718213 | accuracy: 0.7904829545454546 \n",
      "Epoch 5 | Step 1635 | loss: 0.45099509151085565 | accuracy: 0.7921195652173914 \n",
      "Epoch 5 | Step 1636 | loss: 0.45229842886328697 | accuracy: 0.791015625 \n",
      "Epoch 5 | Step 1637 | loss: 0.4575102698802948 | accuracy: 0.786875 \n",
      "Epoch 5 | Step 1638 | loss: 0.45732413920072407 | accuracy: 0.7878605769230769 \n",
      "Epoch 5 | Step 1639 | loss: 0.45798060297966003 | accuracy: 0.7864583333333334 \n",
      "Epoch 5 | Step 1640 | loss: 0.4573702450309481 | accuracy: 0.7879464285714286 \n",
      "Epoch 5 | Step 1641 | loss: 0.45875346660614014 | accuracy: 0.7860991379310345 \n",
      "Epoch 5 | Step 1642 | loss: 0.4591111679871877 | accuracy: 0.7859375 \n",
      "Epoch 5 | Step 1643 | loss: 0.4567237082988985 | accuracy: 0.7872983870967742 \n",
      "Epoch 5 | Step 1644 | loss: 0.4563803495839238 | accuracy: 0.7880859375 \n",
      "Epoch 5 | Step 1645 | loss: 0.45786318905425794 | accuracy: 0.7878787878787878 \n",
      "Epoch 5 | Step 1646 | loss: 0.45544590318904205 | accuracy: 0.7886029411764706 \n",
      "Epoch 5 | Step 1647 | loss: 0.45349075283323015 | accuracy: 0.7901785714285714 \n",
      "Epoch 5 | Step 1648 | loss: 0.45458241883251405 | accuracy: 0.7886284722222222 \n",
      "Epoch 5 | Step 1649 | loss: 0.45494756827483307 | accuracy: 0.7884290540540541 \n",
      "Epoch 5 | Step 1650 | loss: 0.4570487988622565 | accuracy: 0.7865953947368421 \n",
      "Epoch 5 | Step 1651 | loss: 0.4564288487801185 | accuracy: 0.7888621794871795 \n",
      "Epoch 5 | Step 1652 | loss: 0.4542696483433247 | accuracy: 0.790625 \n",
      "Epoch 5 | Step 1653 | loss: 0.4554116747728208 | accuracy: 0.7907774390243902 \n",
      "Epoch 5 | Step 1654 | loss: 0.45581562959012534 | accuracy: 0.7898065476190477 \n",
      "Epoch 5 | Step 1655 | loss: 0.4539517372153526 | accuracy: 0.7896075581395349 \n",
      "Epoch 5 | Step 1656 | loss: 0.45149109038439666 | accuracy: 0.7908380681818182 \n",
      "Epoch 5 | Step 1657 | loss: 0.4516942984528012 | accuracy: 0.7920138888888889 \n",
      "Epoch 5 | Step 1658 | loss: 0.4512229140685952 | accuracy: 0.7914402173913043 \n",
      "Epoch 5 | Step 1659 | loss: 0.4542754007146714 | accuracy: 0.7902260638297872 \n",
      "Epoch 5 | Step 1660 | loss: 0.45596434610585374 | accuracy: 0.7887369791666666 \n",
      "Epoch 5 | Step 1661 | loss: 0.45870369247027803 | accuracy: 0.7863520408163265 \n",
      "Epoch 5 | Step 1662 | loss: 0.4593689984083176 | accuracy: 0.785625 \n",
      "Epoch 5 | Step 1663 | loss: 0.45785795590456796 | accuracy: 0.7861519607843137 \n",
      "Epoch 5 | Step 1664 | loss: 0.45713502971025616 | accuracy: 0.78515625 \n",
      "Epoch 5 | Step 1665 | loss: 0.45712837464404554 | accuracy: 0.7847877358490566 \n",
      "Epoch 5 | Step 1666 | loss: 0.4569285103568324 | accuracy: 0.7853009259259259 \n",
      "Epoch 5 | Step 1667 | loss: 0.45707201090725985 | accuracy: 0.7857954545454545 \n",
      "Epoch 5 | Step 1668 | loss: 0.4563895490552698 | accuracy: 0.7862723214285714 \n",
      "Epoch 5 | Step 1669 | loss: 0.4552888472874959 | accuracy: 0.7872807017543859 \n",
      "Epoch 5 | Step 1670 | loss: 0.4554257937546434 | accuracy: 0.7882543103448276 \n",
      "Epoch 5 | Step 1671 | loss: 0.45729931835400855 | accuracy: 0.7876059322033898 \n",
      "Epoch 5 | Step 1672 | loss: 0.4566780164837837 | accuracy: 0.7872395833333333 \n",
      "Epoch 5 | Step 1673 | loss: 0.45576646093462336 | accuracy: 0.7879098360655737 \n",
      "Epoch 5 | Step 1674 | loss: 0.45428141711219666 | accuracy: 0.7888104838709677 \n",
      "Epoch 5 | Step 1675 | loss: 0.45547116512344 | accuracy: 0.7889384920634921 \n",
      "Epoch 5 | Step 1676 | loss: 0.45432881312444806 | accuracy: 0.789306640625 \n",
      "Epoch 5 | Step 1677 | loss: 0.45386738456212555 | accuracy: 0.7901442307692308 \n",
      "Epoch 5 | Step 1678 | loss: 0.4534504476821784 | accuracy: 0.7897727272727273 \n",
      "Epoch 5 | Step 1679 | loss: 0.4514688787175648 | accuracy: 0.7901119402985075 \n",
      "Epoch 5 | Step 1680 | loss: 0.4518590337213348 | accuracy: 0.7897518382352942 \n",
      "Epoch 5 | Step 1681 | loss: 0.4531088320241458 | accuracy: 0.7894021739130435 \n",
      "Epoch 5 | Step 1682 | loss: 0.45185054200036184 | accuracy: 0.790625 \n",
      "Epoch 5 | Step 1683 | loss: 0.45222637351130096 | accuracy: 0.7900528169014085 \n",
      "Epoch 5 | Step 1684 | loss: 0.45134585723280907 | accuracy: 0.7905815972222222 \n",
      "Epoch 5 | Step 1685 | loss: 0.45156607317597897 | accuracy: 0.7898116438356164 \n",
      "Epoch 5 | Step 1686 | loss: 0.4506825103953078 | accuracy: 0.7905405405405406 \n",
      "Epoch 5 | Step 1687 | loss: 0.4517751987775167 | accuracy: 0.7891666666666667 \n",
      "Epoch 5 | Step 1688 | loss: 0.4516082982483663 | accuracy: 0.7896792763157895 \n",
      "Epoch 5 | Step 1689 | loss: 0.45131803836141315 | accuracy: 0.7899756493506493 \n",
      "Epoch 5 | Step 1690 | loss: 0.4520619240326759 | accuracy: 0.7890625 \n",
      "Epoch 5 | Step 1691 | loss: 0.4532322947737537 | accuracy: 0.7877768987341772 \n",
      "Epoch 5 | Step 1692 | loss: 0.45375240333378314 | accuracy: 0.787890625 \n",
      "Epoch 5 | Step 1693 | loss: 0.45307938662576086 | accuracy: 0.7878086419753086 \n",
      "Epoch 5 | Step 1694 | loss: 0.4530695436931238 | accuracy: 0.7871570121951219 \n",
      "Epoch 5 | Step 1695 | loss: 0.4533016879156411 | accuracy: 0.7872740963855421 \n",
      "Epoch 5 | Step 1696 | loss: 0.452884146854991 | accuracy: 0.7877604166666666 \n",
      "Epoch 5 | Step 1697 | loss: 0.4519362326930551 | accuracy: 0.7886029411764706 \n",
      "Epoch 5 | Step 1698 | loss: 0.451793736496637 | accuracy: 0.7886991279069767 \n",
      "Epoch 5 | Step 1699 | loss: 0.4539192332618538 | accuracy: 0.7877155172413793 \n",
      "Epoch 5 | Step 1700 | loss: 0.4531794126060876 | accuracy: 0.7885298295454546 \n",
      "Epoch 5 | Step 1701 | loss: 0.4522718596324492 | accuracy: 0.7891502808988764 \n",
      "Epoch 5 | Step 1702 | loss: 0.45324446194701723 | accuracy: 0.7883680555555556 \n",
      "Epoch 5 | Step 1703 | loss: 0.45251672182764324 | accuracy: 0.7891483516483516 \n",
      "Epoch 5 | Step 1704 | loss: 0.4515164504232614 | accuracy: 0.7897418478260869 \n",
      "Epoch 5 | Step 1705 | loss: 0.451119860013326 | accuracy: 0.7898185483870968 \n",
      "Epoch 5 | Step 1706 | loss: 0.4515459527994724 | accuracy: 0.7897273936170213 \n",
      "Epoch 5 | Step 1707 | loss: 0.4517453284640061 | accuracy: 0.7894736842105263 \n",
      "Epoch 5 | Step 1708 | loss: 0.4536998951807618 | accuracy: 0.7882486979166666 \n",
      "Epoch 5 | Step 1709 | loss: 0.4545437069897799 | accuracy: 0.787854381443299 \n",
      "Epoch 5 | Step 1710 | loss: 0.45525906736753424 | accuracy: 0.7877869897959183 \n",
      "Epoch 5 | Step 1711 | loss: 0.45507709245489103 | accuracy: 0.7877209595959596 \n",
      "Epoch 5 | Step 1712 | loss: 0.45468078017234803 | accuracy: 0.7878125 \n",
      "Epoch 5 | Step 1713 | loss: 0.4532880113266482 | accuracy: 0.7886757425742574 \n",
      "Epoch 5 | Step 1714 | loss: 0.4529414007476732 | accuracy: 0.7887561274509803 \n",
      "Epoch 5 | Step 1715 | loss: 0.4519607731439535 | accuracy: 0.7895934466019418 \n",
      "Epoch 5 | Step 1716 | loss: 0.4525703466855563 | accuracy: 0.7898137019230769 \n",
      "Epoch 5 | Step 1717 | loss: 0.4525424628030686 | accuracy: 0.7900297619047619 \n",
      "Epoch 5 | Step 1718 | loss: 0.45204136619028057 | accuracy: 0.7900943396226415 \n",
      "Epoch 5 | Step 1719 | loss: 0.45296513588629034 | accuracy: 0.7898656542056075 \n",
      "Epoch 5 | Step 1720 | loss: 0.45355780864203415 | accuracy: 0.7892071759259259 \n",
      "Epoch 5 | Step 1721 | loss: 0.453411375163892 | accuracy: 0.7891341743119266 \n",
      "Epoch 5 | Step 1722 | loss: 0.45364676768129525 | accuracy: 0.7894886363636363 \n",
      "Epoch 5 | Step 1723 | loss: 0.4532352108676154 | accuracy: 0.7898367117117117 \n",
      "Epoch 5 | Step 1724 | loss: 0.45287649386695455 | accuracy: 0.7900390625 \n",
      "Epoch 5 | Step 1725 | loss: 0.4535533711973545 | accuracy: 0.7896847345132744 \n",
      "Epoch 5 | Step 1726 | loss: 0.45452497768820377 | accuracy: 0.7893366228070176 \n",
      "Epoch 5 | Step 1727 | loss: 0.4545286124167235 | accuracy: 0.7889945652173913 \n",
      "Epoch 5 | Step 1728 | loss: 0.45460942901414014 | accuracy: 0.7887931034482759 \n",
      "Epoch 5 | Step 1729 | loss: 0.45507535567650426 | accuracy: 0.7881944444444444 \n",
      "Epoch 5 | Step 1730 | loss: 0.4556877799963547 | accuracy: 0.7878707627118644 \n",
      "Epoch 5 | Step 1731 | loss: 0.4552034184712322 | accuracy: 0.7878151260504201 \n",
      "Epoch 5 | Step 1732 | loss: 0.45484234566489856 | accuracy: 0.7881510416666667 \n",
      "Epoch 5 | Step 1733 | loss: 0.4544290168718858 | accuracy: 0.7884814049586777 \n",
      "Epoch 5 | Step 1734 | loss: 0.45442391663301185 | accuracy: 0.788422131147541 \n",
      "Epoch 5 | Step 1735 | loss: 0.45451439275005 | accuracy: 0.788109756097561 \n",
      "Epoch 5 | Step 1736 | loss: 0.45470035004038967 | accuracy: 0.7879284274193549 \n",
      "Epoch 5 | Step 1737 | loss: 0.4552406761646271 | accuracy: 0.78775 \n",
      "Epoch 5 | Step 1738 | loss: 0.4551759222670207 | accuracy: 0.7878224206349206 \n",
      "Epoch 5 | Step 1739 | loss: 0.4554148827950785 | accuracy: 0.7875246062992126 \n",
      "Epoch 5 | Step 1740 | loss: 0.454769441857934 | accuracy: 0.787841796875 \n",
      "Epoch 5 | Step 1741 | loss: 0.4546521668748338 | accuracy: 0.7879118217054264 \n",
      "Epoch 5 | Step 1742 | loss: 0.4544690950558736 | accuracy: 0.7877403846153846 \n",
      "Epoch 5 | Step 1743 | loss: 0.4547710523350548 | accuracy: 0.7875715648854962 \n",
      "Epoch 5 | Step 1744 | loss: 0.4550786366065343 | accuracy: 0.787405303030303 \n",
      "Epoch 5 | Step 1745 | loss: 0.45575220602795596 | accuracy: 0.7868890977443609 \n",
      "Epoch 5 | Step 1746 | loss: 0.4559036419907613 | accuracy: 0.7862639925373134 \n",
      "Epoch 5 | Step 1747 | loss: 0.4559240294827355 | accuracy: 0.7861111111111111 \n",
      "Epoch 5 | Step 1748 | loss: 0.4559086344259627 | accuracy: 0.7860753676470589 \n",
      "Epoch 5 | Step 1749 | loss: 0.45525263021462153 | accuracy: 0.7867244525547445 \n",
      "Epoch 5 | Step 1750 | loss: 0.45476989340091095 | accuracy: 0.7867980072463768 \n",
      "Epoch 5 | Step 1751 | loss: 0.45525668036165856 | accuracy: 0.7867580935251799 \n",
      "Epoch 5 | Step 1752 | loss: 0.4553068863494056 | accuracy: 0.7868303571428571 \n",
      "Epoch 5 | Step 1753 | loss: 0.45615670359726496 | accuracy: 0.7862367021276596 \n",
      "Epoch 5 | Step 1754 | loss: 0.45620096863155635 | accuracy: 0.785981514084507 \n",
      "Epoch 5 | Step 1755 | loss: 0.4564231980097044 | accuracy: 0.7857298951048951 \n",
      "Epoch 5 | Step 1756 | loss: 0.4568580372465981 | accuracy: 0.78515625 \n",
      "Epoch 5 | Step 1757 | loss: 0.45685143306337556 | accuracy: 0.7853448275862069 \n",
      "Epoch 5 | Step 1758 | loss: 0.45668857983530387 | accuracy: 0.7855308219178082 \n",
      "Epoch 5 | Step 1759 | loss: 0.45616307165346986 | accuracy: 0.7862457482993197 \n",
      "Epoch 5 | Step 1760 | loss: 0.4567514680124618 | accuracy: 0.785472972972973 \n",
      "Epoch 5 | Step 1761 | loss: 0.45663462189219944 | accuracy: 0.7854446308724833 \n",
      "Epoch 5 | Step 1762 | loss: 0.4569565316041311 | accuracy: 0.7856250000000001 \n",
      "Epoch 5 | Step 1763 | loss: 0.45663650876638906 | accuracy: 0.7862168874172186 \n",
      "Epoch 5 | Step 1764 | loss: 0.4569231167827782 | accuracy: 0.7863898026315791 \n",
      "Epoch 5 | Step 1765 | loss: 0.45696885309188195 | accuracy: 0.7866625816993466 \n",
      "Epoch 5 | Step 1766 | loss: 0.4567005659465666 | accuracy: 0.7867288961038963 \n",
      "Epoch 5 | Step 1767 | loss: 0.4563801359745764 | accuracy: 0.7868951612903228 \n",
      "Epoch 5 | Step 1768 | loss: 0.4556898262638312 | accuracy: 0.7872596153846155 \n",
      "Epoch 5 | Step 1769 | loss: 0.4561605751514435 | accuracy: 0.7871218152866244 \n",
      "Epoch 5 | Step 1770 | loss: 0.45694886072527 | accuracy: 0.7863924050632913 \n",
      "Epoch 5 | Step 1771 | loss: 0.4572788726233836 | accuracy: 0.7860652515723272 \n",
      "Epoch 5 | Step 1772 | loss: 0.45765352752059696 | accuracy: 0.7859375000000002 \n",
      "Epoch 5 | Step 1773 | loss: 0.4577381566444539 | accuracy: 0.7854231366459629 \n",
      "Epoch 5 | Step 1774 | loss: 0.4580276310443878 | accuracy: 0.785204475308642 \n",
      "Epoch 5 | Step 1775 | loss: 0.4583932808571798 | accuracy: 0.7846050613496932 \n",
      "Epoch 5 | Step 1776 | loss: 0.45821879985855846 | accuracy: 0.7846798780487805 \n",
      "Epoch 5 | Step 1777 | loss: 0.45781044508471636 | accuracy: 0.7852272727272728 \n",
      "Epoch 5 | Step 1778 | loss: 0.45765866626457996 | accuracy: 0.7855798192771084 \n",
      "Epoch 5 | Step 1779 | loss: 0.45748700567348277 | accuracy: 0.7857410179640718 \n",
      "Epoch 5 | Step 1780 | loss: 0.4578461678964751 | accuracy: 0.7859002976190477 \n",
      "Epoch 5 | Step 1781 | loss: 0.457523314028802 | accuracy: 0.7862426035502958 \n",
      "Epoch 5 | Step 1782 | loss: 0.4568885315867031 | accuracy: 0.7868566176470588 \n",
      "Epoch 5 | Step 1783 | loss: 0.45660489117890074 | accuracy: 0.7870979532163743 \n",
      "Epoch 5 | Step 1784 | loss: 0.4566286188918491 | accuracy: 0.7868822674418605 \n",
      "Epoch 5 | Step 1785 | loss: 0.4560455380147592 | accuracy: 0.7873013005780347 \n",
      "Epoch 5 | Step 1786 | loss: 0.4559720833411162 | accuracy: 0.7872665229885057 \n",
      "Epoch 5 | Step 1787 | loss: 0.4557762123857226 | accuracy: 0.7871428571428571 \n",
      "Epoch 5 | Step 1788 | loss: 0.45611616816710343 | accuracy: 0.7871981534090909 \n",
      "Epoch 5 | Step 1789 | loss: 0.45676703894205684 | accuracy: 0.7869879943502824 \n",
      "Epoch 5 | Step 1790 | loss: 0.4570423694473974 | accuracy: 0.7868679775280899 \n",
      "Epoch 5 | Step 1791 | loss: 0.45707898383034007 | accuracy: 0.7870111731843575 \n",
      "Epoch 5 | Step 1792 | loss: 0.4567621192998356 | accuracy: 0.7871527777777778 \n",
      "Epoch 5 | Step 1793 | loss: 0.45703101141676716 | accuracy: 0.7866885359116023 \n",
      "Epoch 5 | Step 1794 | loss: 0.4568358119372483 | accuracy: 0.7866586538461539 \n",
      "Epoch 5 | Step 1795 | loss: 0.4558688431489663 | accuracy: 0.7873121584699454 \n",
      "Epoch 5 | Step 1796 | loss: 0.45539195025744644 | accuracy: 0.7876188858695652 \n",
      "Epoch 5 | Step 1797 | loss: 0.4550515265078158 | accuracy: 0.7878378378378378 \n",
      "Epoch 5 | Step 1798 | loss: 0.4550904275909547 | accuracy: 0.7878864247311828 \n",
      "Epoch 5 | Step 1799 | loss: 0.45551119194948736 | accuracy: 0.7876002673796791 \n",
      "Epoch 5 | Step 1800 | loss: 0.4557704056831116 | accuracy: 0.7870678191489362 \n",
      "Epoch 5 | Step 1801 | loss: 0.45558584067556596 | accuracy: 0.7872023809523809 \n",
      "Epoch 5 | Step 1802 | loss: 0.4562545508146286 | accuracy: 0.7865131578947369 \n",
      "Epoch 5 | Step 1803 | loss: 0.4555676674655595 | accuracy: 0.7871400523560209 \n",
      "Epoch 5 | Step 1804 | loss: 0.4551046670724948 | accuracy: 0.787353515625 \n",
      "Epoch 5 | Step 1805 | loss: 0.45451524668406945 | accuracy: 0.7878886010362695 \n",
      "Epoch 5 | Step 1806 | loss: 0.45436044974425405 | accuracy: 0.7882570876288659 \n",
      "Epoch 5 | Step 1807 | loss: 0.4543580617660131 | accuracy: 0.7883814102564103 \n",
      "Epoch 5 | Step 1808 | loss: 0.45442052124714366 | accuracy: 0.7882653061224489 \n",
      "Epoch 5 | Step 1809 | loss: 0.4541193758170617 | accuracy: 0.7885469543147208 \n",
      "Epoch 5 | Step 1810 | loss: 0.4539064525654822 | accuracy: 0.7886679292929293 \n",
      "Epoch 5 | Step 1811 | loss: 0.4534632210156426 | accuracy: 0.7891802763819096 \n",
      "Epoch 5 | Step 1812 | loss: 0.453100309073925 | accuracy: 0.78953125 \n",
      "Epoch 5 | Step 1813 | loss: 0.4535821516122391 | accuracy: 0.7893345771144279 \n",
      "Epoch 5 | Step 1814 | loss: 0.453163676775328 | accuracy: 0.7896813118811881 \n",
      "Epoch 5 | Step 1815 | loss: 0.45297263951724387 | accuracy: 0.7901016009852216 \n",
      "Epoch 5 | Step 1816 | loss: 0.45286962302292094 | accuracy: 0.7900582107843137 \n",
      "Epoch 5 | Step 1817 | loss: 0.4530478801669144 | accuracy: 0.7897103658536585 \n",
      "Epoch 5 | Step 1818 | loss: 0.4538405084783591 | accuracy: 0.7891383495145631 \n",
      "Epoch 5 | Step 1819 | loss: 0.45432671040728473 | accuracy: 0.7890247584541062 \n",
      "Epoch 5 | Step 1820 | loss: 0.4545483198016882 | accuracy: 0.7886868990384616 \n",
      "Epoch 5 | Step 1821 | loss: 0.45466030299948734 | accuracy: 0.788427033492823 \n",
      "Epoch 5 | Step 1822 | loss: 0.4549434917313712 | accuracy: 0.7881696428571429 \n",
      "Epoch 5 | Step 1823 | loss: 0.4549762698428891 | accuracy: 0.7881368483412322 \n",
      "Epoch 5 | Step 1824 | loss: 0.45436792595768877 | accuracy: 0.7886202830188679 \n",
      "Epoch 5 | Step 1825 | loss: 0.45396309041641125 | accuracy: 0.7887323943661971 \n",
      "Epoch 5 | Step 1826 | loss: 0.454105404771377 | accuracy: 0.7884053738317757 \n",
      "Epoch 5 | Step 1827 | loss: 0.454000054403793 | accuracy: 0.7883720930232558 \n",
      "Epoch 5 | Step 1828 | loss: 0.45396630176239544 | accuracy: 0.7883391203703703 \n",
      "Epoch 5 | Step 1829 | loss: 0.45360404541415555 | accuracy: 0.788522465437788 \n",
      "Epoch 5 | Step 1830 | loss: 0.4537923069448646 | accuracy: 0.7884174311926605 \n",
      "Epoch 5 | Step 1831 | loss: 0.45385482907295227 | accuracy: 0.7884560502283106 \n",
      "Epoch 5 | Step 1832 | loss: 0.45385012260892177 | accuracy: 0.7884232954545455 \n",
      "Epoch 5 | Step 1833 | loss: 0.45401740249465494 | accuracy: 0.7881787330316742 \n",
      "Epoch 5 | Step 1834 | loss: 0.45382122440381095 | accuracy: 0.7882179054054054 \n",
      "Epoch 5 | Step 1835 | loss: 0.45360607977939826 | accuracy: 0.7882567264573991 \n",
      "Epoch 5 | Step 1836 | loss: 0.4531468709132501 | accuracy: 0.7886439732142857 \n",
      "Epoch 5 | Step 1837 | loss: 0.4531335563129849 | accuracy: 0.7885416666666667 \n",
      "Epoch 5 | Step 1838 | loss: 0.4532315678301111 | accuracy: 0.7887168141592921 \n",
      "Epoch 5 | Step 1839 | loss: 0.4536006954798089 | accuracy: 0.7884085903083701 \n",
      "Epoch 5 | Step 1840 | loss: 0.4534155816624039 | accuracy: 0.7886513157894737 \n",
      "Epoch 5 | Step 1841 | loss: 0.45341423114834917 | accuracy: 0.7884143013100436 \n",
      "Epoch 5 | Step 1842 | loss: 0.4534646439811458 | accuracy: 0.7883831521739131 \n",
      "Epoch 5 | Step 1843 | loss: 0.45289065711426013 | accuracy: 0.7886904761904762 \n",
      "Epoch 5 | Step 1844 | loss: 0.45257467275549623 | accuracy: 0.7889278017241379 \n",
      "Epoch 5 | Step 1845 | loss: 0.45267824758275893 | accuracy: 0.7888277896995708 \n",
      "Epoch 5 | Step 1846 | loss: 0.45250727401839363 | accuracy: 0.7889289529914529 \n",
      "Epoch 5 | Step 1847 | loss: 0.4521286036105866 | accuracy: 0.7891622340425531 \n",
      "Epoch 5 | Step 1848 | loss: 0.4517524808140124 | accuracy: 0.7895921610169492 \n",
      "Epoch 5 | Step 1849 | loss: 0.4515026527366558 | accuracy: 0.7898206751054853 \n",
      "Epoch 5 | Step 1850 | loss: 0.4515775112795229 | accuracy: 0.7896533613445378 \n",
      "Epoch 5 | Step 1851 | loss: 0.4517941673181047 | accuracy: 0.7896182008368201 \n",
      "Epoch 5 | Step 1852 | loss: 0.4515142080684503 | accuracy: 0.7897135416666666 \n",
      "Epoch 5 | Step 1853 | loss: 0.45091203374486744 | accuracy: 0.7901970954356846 \n",
      "Epoch 5 | Step 1854 | loss: 0.45026521261565944 | accuracy: 0.7906120867768595 \n",
      "Epoch 5 | Step 1855 | loss: 0.4502185583114624 | accuracy: 0.7908307613168725 \n",
      "Epoch 5 | Step 1856 | loss: 0.4503434433555994 | accuracy: 0.7907274590163934 \n",
      "Epoch 5 | Step 1857 | loss: 0.4504975852917652 | accuracy: 0.7908801020408164 \n",
      "Epoch 5 | Step 1858 | loss: 0.45029716423856536 | accuracy: 0.7908409552845529 \n",
      "Epoch 5 | Step 1859 | loss: 0.4500457874917791 | accuracy: 0.7910551619433198 \n",
      "Epoch 5 | Step 1860 | loss: 0.4503871215687644 | accuracy: 0.7908896169354839 \n",
      "Epoch 5 | Step 1861 | loss: 0.4503818847328784 | accuracy: 0.7909136546184738 \n",
      "Epoch 5 | Step 1862 | loss: 0.4503350796699524 | accuracy: 0.790875 \n",
      "Epoch 5 | Step 1863 | loss: 0.4502151397119955 | accuracy: 0.7907121513944223 \n",
      "Epoch 5 | Step 1864 | loss: 0.4501897030406528 | accuracy: 0.7905505952380952 \n",
      "Epoch 5 | Step 1865 | loss: 0.4499444766006922 | accuracy: 0.790822628458498 \n",
      "Epoch 5 | Step 1866 | loss: 0.4498248954457561 | accuracy: 0.7909079724409449 \n",
      "Epoch 5 | Step 1867 | loss: 0.44967885379697764 | accuracy: 0.7909313725490196 \n",
      "Epoch 5 | Step 1868 | loss: 0.44962355855386704 | accuracy: 0.7906494140625 \n",
      "Epoch 5 | Step 1869 | loss: 0.4494331817682615 | accuracy: 0.7907344357976653 \n",
      "Epoch 5 | Step 1870 | loss: 0.44904786706432814 | accuracy: 0.7908793604651163 \n",
      "Epoch 5 | Step 1871 | loss: 0.4491362402567992 | accuracy: 0.7908421814671814 \n",
      "Epoch 5 | Step 1872 | loss: 0.4486997134410418 | accuracy: 0.7910456730769231 \n",
      "Epoch 5 | Step 1873 | loss: 0.44927140305325447 | accuracy: 0.790529214559387 \n",
      "Epoch 5 | Step 1874 | loss: 0.44941614556858556 | accuracy: 0.7903148854961832 \n",
      "Epoch 5 | Step 1875 | loss: 0.4493273720995102 | accuracy: 0.7902210076045627 \n",
      "Epoch 5 | Step 1876 | loss: 0.4494878846136006 | accuracy: 0.7903053977272727 \n",
      "Epoch 5 | Step 1877 | loss: 0.44935725218844863 | accuracy: 0.7903301886792453 \n",
      "Epoch 5 | Step 1878 | loss: 0.44888411675180706 | accuracy: 0.7905897556390977 \n",
      "Epoch 5 | Step 1879 | loss: 0.4487910910268848 | accuracy: 0.7905547752808989 \n",
      "Epoch 5 | Step 1880 | loss: 0.449105597142853 | accuracy: 0.7902868470149254 \n",
      "Epoch 5 | Step 1881 | loss: 0.44899239759462917 | accuracy: 0.7904275092936803 \n",
      "Epoch 5 | Step 1882 | loss: 0.4487799793481827 | accuracy: 0.790625 \n",
      "Epoch 5 | Step 1883 | loss: 0.4488516740253491 | accuracy: 0.790590405904059 \n",
      "Epoch 5 | Step 1884 | loss: 0.4487411268055439 | accuracy: 0.7905560661764706 \n",
      "Epoch 5 | Step 1885 | loss: 0.4487127163907984 | accuracy: 0.7904075091575091 \n",
      "Epoch 5 | Step 1886 | loss: 0.4484877692956994 | accuracy: 0.7903740875912408 \n",
      "Epoch 5 | Step 1887 | loss: 0.4483430337905884 | accuracy: 0.7905113636363637 \n",
      "Epoch 5 | Step 1888 | loss: 0.4483452771884808 | accuracy: 0.7904778079710145 \n",
      "Epoch 5 | Step 1889 | loss: 0.4481311988098957 | accuracy: 0.7905573104693141 \n",
      "Epoch 5 | Step 1890 | loss: 0.4481692116895168 | accuracy: 0.7905800359712231 \n",
      "Epoch 5 | Step 1891 | loss: 0.44832280513206263 | accuracy: 0.7903785842293907 \n",
      "Epoch 5 | Step 1892 | loss: 0.44792025440505573 | accuracy: 0.7905691964285714 \n",
      "Epoch 5 | Step 1893 | loss: 0.4479294174294455 | accuracy: 0.7903692170818505 \n",
      "Epoch 5 | Step 1894 | loss: 0.4477773463049679 | accuracy: 0.7903922872340425 \n",
      "Epoch 5 | Step 1895 | loss: 0.4479462679199111 | accuracy: 0.7903047703180212 \n",
      "Epoch 5 | Step 1896 | loss: 0.4477558024752308 | accuracy: 0.7904929577464789 \n",
      "Epoch 5 | Step 1897 | loss: 0.44775361439637973 | accuracy: 0.790405701754386 \n",
      "Epoch 5 | Step 1898 | loss: 0.4478856259501064 | accuracy: 0.7904283216783217 \n",
      "Epoch 5 | Step 1899 | loss: 0.4475096885750933 | accuracy: 0.7906141114982579 \n",
      "Epoch 5 | Step 1900 | loss: 0.44718801354368526 | accuracy: 0.7909071180555556 \n",
      "Epoch 5 | Step 1901 | loss: 0.44701595609575817 | accuracy: 0.79092776816609 \n",
      "Epoch 5 | Step 1902 | loss: 0.44729498820058233 | accuracy: 0.7908405172413793 \n",
      "Epoch 5 | Step 1903 | loss: 0.44700602884964435 | accuracy: 0.7910760309278351 \n",
      "Epoch 5 | Step 1904 | loss: 0.4467113336471662 | accuracy: 0.7913099315068494 \n",
      "Epoch 5 | Step 1905 | loss: 0.44647791015410176 | accuracy: 0.7914889078498294 \n",
      "Epoch 5 | Step 1906 | loss: 0.4460109982158051 | accuracy: 0.7917729591836735 \n",
      "Epoch 5 | Step 1907 | loss: 0.4466410108542038 | accuracy: 0.7914724576271187 \n",
      "Epoch 5 | Step 1908 | loss: 0.44654543848859296 | accuracy: 0.791649070945946 \n",
      "Epoch 5 | Step 1909 | loss: 0.44658616847462124 | accuracy: 0.7915614478114479 \n",
      "Epoch 5 | Step 1910 | loss: 0.4463543500876267 | accuracy: 0.7918414429530203 \n",
      "Epoch 5 | Step 1911 | loss: 0.4460995573064555 | accuracy: 0.7919627926421406 \n",
      "Epoch 5 | Step 1912 | loss: 0.44570802092552186 | accuracy: 0.7921875000000002 \n",
      "Epoch 5 | Step 1913 | loss: 0.44566913399585456 | accuracy: 0.7921511627906979 \n",
      "Epoch 5 | Step 1914 | loss: 0.4457862798543955 | accuracy: 0.7921668046357617 \n",
      "Epoch 5 | Step 1915 | loss: 0.4455193837877154 | accuracy: 0.7921823432343236 \n",
      "Epoch 5 | Step 1916 | loss: 0.4453447569945925 | accuracy: 0.7923519736842106 \n",
      "Epoch 5 | Step 1917 | loss: 0.44575156803990973 | accuracy: 0.792110655737705 \n",
      "Epoch 5 | Step 1918 | loss: 0.44542710356463017 | accuracy: 0.7923304738562092 \n",
      "Epoch 5 | Step 1919 | loss: 0.44504338745573835 | accuracy: 0.7926506514657982 \n",
      "Epoch 5 | Step 1920 | loss: 0.4450131146745248 | accuracy: 0.7926136363636365 \n",
      "Epoch 5 | Step 1921 | loss: 0.44454824654415587 | accuracy: 0.7929813915857606 \n",
      "Epoch 5 | Step 1922 | loss: 0.4442849213077176 | accuracy: 0.7931451612903226 \n",
      "Epoch 5 | Step 1923 | loss: 0.44411435263333215 | accuracy: 0.7932576366559486 \n",
      "Epoch 5 | Step 1924 | loss: 0.44414142614755875 | accuracy: 0.7931189903846155 \n",
      "Epoch 5 | Step 1925 | loss: 0.4440628263516167 | accuracy: 0.7931309904153356 \n",
      "Epoch 5 | Step 1926 | loss: 0.44397220290770195 | accuracy: 0.7931926751592359 \n",
      "Epoch 5 | Step 1927 | loss: 0.44346938568448263 | accuracy: 0.7936011904761907 \n",
      "Epoch 5 | Step 1928 | loss: 0.443490111469468 | accuracy: 0.7936115506329117 \n",
      "Epoch 5 | Step 1929 | loss: 0.44348667914559037 | accuracy: 0.7937204258675081 \n",
      "Epoch 5 | Step 1930 | loss: 0.443479319507221 | accuracy: 0.7936812106918242 \n",
      "Epoch 5 | Step 1931 | loss: 0.4433187935793288 | accuracy: 0.7937891849529783 \n",
      "Epoch 5 | Step 1932 | loss: 0.44318277221173047 | accuracy: 0.7938476562500003 \n",
      "Epoch 5 | Step 1933 | loss: 0.4432288685877375 | accuracy: 0.7937110591900315 \n",
      "Epoch 5 | Step 1934 | loss: 0.44310909019123695 | accuracy: 0.7938179347826091 \n",
      "Epoch 5 | Step 1935 | loss: 0.4432306642133754 | accuracy: 0.793682275541796 \n",
      "Epoch 5 | Step 1936 | loss: 0.4430491440458062 | accuracy: 0.79369212962963 \n",
      "Epoch 5 | Step 1937 | loss: 0.4429465098564441 | accuracy: 0.7937500000000004 \n",
      "Epoch 5 | Step 1938 | loss: 0.4431020890825365 | accuracy: 0.7934720092024543 \n",
      "Epoch 5 | Step 1939 | loss: 0.4432073273789992 | accuracy: 0.7933390672782878 \n",
      "Epoch 5 | Step 1940 | loss: 0.44300448194873043 | accuracy: 0.7936356707317077 \n",
      "Epoch 5 | Step 1941 | loss: 0.44283234520523745 | accuracy: 0.793787993920973 \n",
      "Epoch 5 | Step 1942 | loss: 0.44289181494351587 | accuracy: 0.7937026515151518 \n",
      "Epoch 5 | Step 1943 | loss: 0.44277674770067105 | accuracy: 0.7938066465256801 \n",
      "Epoch 5 | Step 1944 | loss: 0.4427835309361837 | accuracy: 0.793627635542169 \n",
      "Epoch 5 | Step 1945 | loss: 0.4426189691454799 | accuracy: 0.7936373873873878 \n",
      "Epoch 5 | Step 1946 | loss: 0.44236641569051915 | accuracy: 0.7937874251497009 \n",
      "Epoch 5 | Step 1947 | loss: 0.4424333728071469 | accuracy: 0.7936567164179108 \n",
      "Epoch 5 | Step 1948 | loss: 0.44225449416609036 | accuracy: 0.7938058035714289 \n",
      "Epoch 5 | Step 1949 | loss: 0.44218258864801785 | accuracy: 0.7937221810089025 \n",
      "Epoch 5 | Step 1950 | loss: 0.4419668912005848 | accuracy: 0.7939164201183435 \n",
      "Epoch 5 | Step 1951 | loss: 0.441936732305538 | accuracy: 0.793879056047198 \n",
      "Epoch 5 | Step 1952 | loss: 0.4419868946951978 | accuracy: 0.7939338235294121 \n",
      "Epoch 5 | Step 1953 | loss: 0.4418244395962209 | accuracy: 0.7939882697947217 \n",
      "Epoch 5 | Step 1954 | loss: 0.4417236686972847 | accuracy: 0.794088084795322 \n",
      "Epoch 5 | Step 1955 | loss: 0.4415014984830128 | accuracy: 0.7941873177842569 \n",
      "Epoch 5 | Step 1956 | loss: 0.44170078678533087 | accuracy: 0.7939226017441864 \n",
      "Epoch 5 | Step 1957 | loss: 0.4413262055403944 | accuracy: 0.794202898550725 \n",
      "Epoch 5 | Step 1958 | loss: 0.44128066301345825 | accuracy: 0.7944364161849714 \n",
      "Epoch 5 | Step 1959 | loss: 0.44119139749996944 | accuracy: 0.7944884726224787 \n",
      "Epoch 5 | Step 1960 | loss: 0.4410804748192601 | accuracy: 0.7944953304597704 \n",
      "Epoch 5 | Step 1961 | loss: 0.4409644468807559 | accuracy: 0.794502148997135 \n",
      "Epoch 5 | Step 1962 | loss: 0.4412396240234375 | accuracy: 0.7942857142857146 \n",
      "Epoch 5 | Step 1963 | loss: 0.4408896320905441 | accuracy: 0.7946047008547011 \n",
      "Epoch 5 | Step 1964 | loss: 0.44086443734439934 | accuracy: 0.7946111505681821 \n",
      "Epoch 5 | Step 1965 | loss: 0.4407673670617447 | accuracy: 0.7946175637393771 \n",
      "Epoch 5 | Step 1966 | loss: 0.44094745924243817 | accuracy: 0.7945798022598873 \n",
      "Epoch 5 | Step 1967 | loss: 0.44075194202678303 | accuracy: 0.7946742957746482 \n",
      "Epoch 5 | Step 1968 | loss: 0.4403760763868857 | accuracy: 0.7947682584269666 \n",
      "Epoch 5 | Step 1969 | loss: 0.44057202965271575 | accuracy: 0.7946428571428574 \n",
      "Epoch 5 | Step 1970 | loss: 0.44081406644935717 | accuracy: 0.7946054469273747 \n",
      "Epoch 5 | Step 1971 | loss: 0.44063034786487354 | accuracy: 0.7946988161559891 \n",
      "Epoch 5 | Step 1972 | loss: 0.4408618217541112 | accuracy: 0.7946614583333337 \n",
      "Epoch 5 | Step 1973 | loss: 0.44073053649587973 | accuracy: 0.7947108725761776 \n",
      "Epoch 5 | Step 1974 | loss: 0.4406205845471904 | accuracy: 0.7947168508287296 \n",
      "Epoch 5 | Step 1975 | loss: 0.4407226059062422 | accuracy: 0.794808884297521 \n",
      "Epoch 5 | Step 1976 | loss: 0.4402426749795348 | accuracy: 0.7950721153846158 \n",
      "Epoch 5 | Step 1977 | loss: 0.4400569058444402 | accuracy: 0.7952054794520551 \n",
      "Epoch 5 | Step 1978 | loss: 0.43999883027676023 | accuracy: 0.7952527322404375 \n",
      "Epoch 5 | Step 1979 | loss: 0.4402506031522309 | accuracy: 0.7950868528610358 \n",
      "Epoch 5 | Step 1980 | loss: 0.4400421084593172 | accuracy: 0.7953040081521742 \n",
      "Epoch 5 | Step 1981 | loss: 0.4400000342831702 | accuracy: 0.7954352981029813 \n",
      "Epoch 5 | Step 1982 | loss: 0.43999977611206675 | accuracy: 0.7953547297297301 \n",
      "Epoch 5 | Step 1983 | loss: 0.440172325408041 | accuracy: 0.795148247978437 \n",
      "Epoch 5 | Step 1984 | loss: 0.4400322517400147 | accuracy: 0.7951948924731186 \n",
      "Epoch 5 | Step 1985 | loss: 0.43970015948643315 | accuracy: 0.795366957104558 \n",
      "Epoch 5 | Step 1986 | loss: 0.4395000257275321 | accuracy: 0.7955381016042784 \n",
      "Epoch 5 | Step 1987 | loss: 0.43960364000002544 | accuracy: 0.7955416666666669 \n",
      "Epoch 5 | Step 1988 | loss: 0.43985459882211175 | accuracy: 0.795254321808511 \n",
      "Epoch 5 | Step 1989 | loss: 0.43997447963418634 | accuracy: 0.7950928381962867 \n",
      "Epoch 5 | Step 1990 | loss: 0.4399598215622877 | accuracy: 0.7950148809523813 \n",
      "Epoch 5 | Step 1991 | loss: 0.4398342006911074 | accuracy: 0.7949785620052774 \n",
      "Epoch 5 | Step 1992 | loss: 0.4397300958633423 | accuracy: 0.7950657894736846 \n",
      "Epoch 5 | Step 1993 | loss: 0.43944261776493604 | accuracy: 0.7952345800524937 \n",
      "Epoch 5 | Step 1994 | loss: 0.43956760328789657 | accuracy: 0.7951979712041888 \n",
      "Epoch 5 | Step 1995 | loss: 0.4396552011643004 | accuracy: 0.7952431462140995 \n",
      "Epoch 5 | Step 1996 | loss: 0.4398030140437186 | accuracy: 0.7951253255208336 \n",
      "Epoch 5 | Step 1997 | loss: 0.43977470289577136 | accuracy: 0.7952516233766237 \n",
      "Epoch 5 | Step 1998 | loss: 0.43985754012135025 | accuracy: 0.7951748704663215 \n",
      "Epoch 5 | Step 1999 | loss: 0.4399463697613364 | accuracy: 0.7950985142118866 \n",
      "Epoch 5 | Step 2000 | loss: 0.43995512622533384 | accuracy: 0.7951433634020622 \n",
      "Epoch 5 | Step 2001 | loss: 0.44006069360784517 | accuracy: 0.7949871465295633 \n",
      "Epoch 5 | Step 2002 | loss: 0.44005887355559914 | accuracy: 0.7950320512820516 \n",
      "Epoch 5 | Step 2003 | loss: 0.4399780826952756 | accuracy: 0.794996803069054 \n",
      "Epoch 5 | Step 2004 | loss: 0.43999163274254116 | accuracy: 0.7950015943877554 \n",
      "Epoch 5 | Step 2005 | loss: 0.4398228577681777 | accuracy: 0.7952449109414761 \n",
      "Epoch 5 | Step 2006 | loss: 0.4400859045498262 | accuracy: 0.7950904187817261 \n",
      "Epoch 5 | Step 2007 | loss: 0.43989294873008244 | accuracy: 0.7952531645569623 \n",
      "Epoch 5 | Step 2008 | loss: 0.4397026037778517 | accuracy: 0.7953361742424245 \n",
      "Epoch 5 | Step 2009 | loss: 0.43954418745989765 | accuracy: 0.795458123425693 \n",
      "Epoch 5 | Step 2010 | loss: 0.4395590027672562 | accuracy: 0.7953046482412063 \n",
      "Epoch 5 | Step 2011 | loss: 0.4394951548642084 | accuracy: 0.7953085839599 \n",
      "Epoch 5 | Step 2012 | loss: 0.4393738031387329 | accuracy: 0.7953515625000003 \n",
      "Epoch 5 | Step 2013 | loss: 0.4395195710242835 | accuracy: 0.7953553615960103 \n",
      "Epoch 5 | Step 2014 | loss: 0.4393889506657918 | accuracy: 0.795592350746269 \n",
      "Epoch 5 | Step 2015 | loss: 0.4393862629350894 | accuracy: 0.7955861748300181 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.5473200082778931 | accuracy: 0.765625 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4818301647901535 | accuracy: 0.8125 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.5058246950308481 | accuracy: 0.7916666666666666 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.5166021659970284 | accuracy: 0.765625 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.47975923418998717 | accuracy: 0.796875 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.5037130862474442 | accuracy: 0.7682291666666666 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.5005245677062443 | accuracy: 0.7678571428571429 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.49328209832310677 | accuracy: 0.771484375 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.5019490420818329 | accuracy: 0.7690972222222222 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.49293971359729766 | accuracy: 0.775 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.48843496766957367 | accuracy: 0.7769886363636364 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.48248524963855743 | accuracy: 0.78125 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.47456408922488874 | accuracy: 0.7836538461538461 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.47176665706293924 | accuracy: 0.7857142857142857 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.47186901768048606 | accuracy: 0.7854166666666667 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.47376887686550617 | accuracy: 0.78515625 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4823554912034203 | accuracy: 0.7803308823529411 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.484486644466718 | accuracy: 0.7786458333333334 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4804039660253023 | accuracy: 0.78125 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4788132220506668 | accuracy: 0.77890625 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4757919524397169 | accuracy: 0.7790178571428571 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.47212137281894684 | accuracy: 0.7805397727272727 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4760934490224589 | accuracy: 0.7771739130434783 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.48468775177995366 | accuracy: 0.7721354166666666 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4892563998699188 | accuracy: 0.769375 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4859597854889356 | accuracy: 0.7704326923076923 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4814576937092675 | accuracy: 0.7719907407407407 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4785439914890698 | accuracy: 0.7734375 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4753843001250563 | accuracy: 0.7758620689655172 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4743593881527583 | accuracy: 0.7776041666666667 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4695885508291183 | accuracy: 0.780241935483871 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.47210955433547497 | accuracy: 0.779296875 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4722054853583827 | accuracy: 0.7784090909090909 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.47582806559169993 | accuracy: 0.7752757352941176 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4772234984806606 | accuracy: 0.775 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4753536292248302 | accuracy: 0.7751736111111112 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4756605319074682 | accuracy: 0.7749155405405406 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4759619447745775 | accuracy: 0.7754934210526315 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.47488951683044434 | accuracy: 0.7760416666666666 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.47303963229060175 | accuracy: 0.778125 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4716131563593702 | accuracy: 0.7785823170731707 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.46935492966856274 | accuracy: 0.7786458333333334 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4711228713046673 | accuracy: 0.7768895348837209 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.47403122146021237 | accuracy: 0.7752130681818182 \n",
      "Validation | Epoch 5 | Step 2015 | loss: 0.4736817081769307 | accuracy: 0.7748943236139085 \n",
      "Epoch 6 | Step 2016 | loss: 0.4809724688529968 | accuracy: 0.8125 \n",
      "Epoch 6 | Step 2017 | loss: 0.40623190999031067 | accuracy: 0.828125 \n",
      "Epoch 6 | Step 2018 | loss: 0.4120941758155823 | accuracy: 0.828125 \n",
      "Epoch 6 | Step 2019 | loss: 0.4290194436907768 | accuracy: 0.82421875 \n",
      "Epoch 6 | Step 2020 | loss: 0.4091158270835876 | accuracy: 0.834375 \n",
      "Epoch 6 | Step 2021 | loss: 0.4090057760477066 | accuracy: 0.8151041666666666 \n",
      "Epoch 6 | Step 2022 | loss: 0.4113453073160989 | accuracy: 0.8147321428571429 \n",
      "Epoch 6 | Step 2023 | loss: 0.40813978388905525 | accuracy: 0.818359375 \n",
      "Epoch 6 | Step 2024 | loss: 0.41823649737570023 | accuracy: 0.8072916666666666 \n",
      "Epoch 6 | Step 2025 | loss: 0.4272638946771622 | accuracy: 0.8 \n",
      "Epoch 6 | Step 2026 | loss: 0.41352526437152515 | accuracy: 0.8125 \n",
      "Epoch 6 | Step 2027 | loss: 0.41034011791149777 | accuracy: 0.81640625 \n",
      "Epoch 6 | Step 2028 | loss: 0.42063209414482117 | accuracy: 0.8100961538461539 \n",
      "Epoch 6 | Step 2029 | loss: 0.41761755517550875 | accuracy: 0.8136160714285714 \n",
      "Epoch 6 | Step 2030 | loss: 0.41683432857195535 | accuracy: 0.8145833333333333 \n",
      "Epoch 6 | Step 2031 | loss: 0.4096050076186657 | accuracy: 0.81640625 \n",
      "Epoch 6 | Step 2032 | loss: 0.41197973139145794 | accuracy: 0.8097426470588235 \n",
      "Epoch 6 | Step 2033 | loss: 0.4096059799194336 | accuracy: 0.8116319444444444 \n",
      "Epoch 6 | Step 2034 | loss: 0.40852045542315435 | accuracy: 0.8133223684210527 \n",
      "Epoch 6 | Step 2035 | loss: 0.4092936530709267 | accuracy: 0.81484375 \n",
      "Epoch 6 | Step 2036 | loss: 0.410996322120939 | accuracy: 0.8132440476190477 \n",
      "Epoch 6 | Step 2037 | loss: 0.41355988112362946 | accuracy: 0.8089488636363636 \n",
      "Epoch 6 | Step 2038 | loss: 0.4124082819275234 | accuracy: 0.8084239130434783 \n",
      "Epoch 6 | Step 2039 | loss: 0.4145737290382385 | accuracy: 0.8072916666666666 \n",
      "Epoch 6 | Step 2040 | loss: 0.4185393214225769 | accuracy: 0.80375 \n",
      "Epoch 6 | Step 2041 | loss: 0.41831917143785036 | accuracy: 0.8028846153846154 \n",
      "Epoch 6 | Step 2042 | loss: 0.4191031003439868 | accuracy: 0.8020833333333334 \n",
      "Epoch 6 | Step 2043 | loss: 0.4188073788370405 | accuracy: 0.8035714285714286 \n",
      "Epoch 6 | Step 2044 | loss: 0.4207432907203148 | accuracy: 0.8038793103448276 \n",
      "Epoch 6 | Step 2045 | loss: 0.42227830986181897 | accuracy: 0.803125 \n",
      "Epoch 6 | Step 2046 | loss: 0.41921992936441976 | accuracy: 0.8044354838709677 \n",
      "Epoch 6 | Step 2047 | loss: 0.41973887849599123 | accuracy: 0.8037109375 \n",
      "Epoch 6 | Step 2048 | loss: 0.42070143873041327 | accuracy: 0.8035037878787878 \n",
      "Epoch 6 | Step 2049 | loss: 0.4185197353363037 | accuracy: 0.8046875 \n",
      "Epoch 6 | Step 2050 | loss: 0.4160002452986581 | accuracy: 0.80625 \n",
      "Epoch 6 | Step 2051 | loss: 0.4160412334733539 | accuracy: 0.8059895833333334 \n",
      "Epoch 6 | Step 2052 | loss: 0.4158941636214385 | accuracy: 0.8061655405405406 \n",
      "Epoch 6 | Step 2053 | loss: 0.41844895952626276 | accuracy: 0.8042763157894737 \n",
      "Epoch 6 | Step 2054 | loss: 0.4170778691768646 | accuracy: 0.8064903846153846 \n",
      "Epoch 6 | Step 2055 | loss: 0.41554815545678137 | accuracy: 0.8078125 \n",
      "Epoch 6 | Step 2056 | loss: 0.4165106030499063 | accuracy: 0.8079268292682927 \n",
      "Epoch 6 | Step 2057 | loss: 0.4167337871733166 | accuracy: 0.8072916666666666 \n",
      "Epoch 6 | Step 2058 | loss: 0.41519265881804535 | accuracy: 0.8066860465116279 \n",
      "Epoch 6 | Step 2059 | loss: 0.4127891713922674 | accuracy: 0.8078835227272727 \n",
      "Epoch 6 | Step 2060 | loss: 0.4132386207580566 | accuracy: 0.8090277777777778 \n",
      "Epoch 6 | Step 2061 | loss: 0.4132277064997217 | accuracy: 0.8080842391304348 \n",
      "Epoch 6 | Step 2062 | loss: 0.4152759611606598 | accuracy: 0.8065159574468085 \n",
      "Epoch 6 | Step 2063 | loss: 0.415877440944314 | accuracy: 0.8059895833333334 \n",
      "Epoch 6 | Step 2064 | loss: 0.4192725961305657 | accuracy: 0.8035714285714286 \n",
      "Epoch 6 | Step 2065 | loss: 0.42003888309001924 | accuracy: 0.803125 \n",
      "Epoch 6 | Step 2066 | loss: 0.41894732211150376 | accuracy: 0.8045343137254902 \n",
      "Epoch 6 | Step 2067 | loss: 0.41753426652688247 | accuracy: 0.8055889423076923 \n",
      "Epoch 6 | Step 2068 | loss: 0.4176375387974505 | accuracy: 0.8039504716981132 \n",
      "Epoch 6 | Step 2069 | loss: 0.41747104680096664 | accuracy: 0.8041087962962963 \n",
      "Epoch 6 | Step 2070 | loss: 0.4169160680337386 | accuracy: 0.8042613636363637 \n",
      "Epoch 6 | Step 2071 | loss: 0.4164453936474664 | accuracy: 0.8046875 \n",
      "Epoch 6 | Step 2072 | loss: 0.4163933898273267 | accuracy: 0.8048245614035088 \n",
      "Epoch 6 | Step 2073 | loss: 0.41627724571474667 | accuracy: 0.8054956896551724 \n",
      "Epoch 6 | Step 2074 | loss: 0.4179835506414963 | accuracy: 0.8050847457627118 \n",
      "Epoch 6 | Step 2075 | loss: 0.41758188406626384 | accuracy: 0.80546875 \n",
      "Epoch 6 | Step 2076 | loss: 0.4171804038227582 | accuracy: 0.8055840163934426 \n",
      "Epoch 6 | Step 2077 | loss: 0.4158991330092953 | accuracy: 0.8069556451612904 \n",
      "Epoch 6 | Step 2078 | loss: 0.4171497277797215 | accuracy: 0.8070436507936508 \n",
      "Epoch 6 | Step 2079 | loss: 0.4158723442815244 | accuracy: 0.807861328125 \n",
      "Epoch 6 | Step 2080 | loss: 0.41470384230980506 | accuracy: 0.8088942307692307 \n",
      "Epoch 6 | Step 2081 | loss: 0.4140371070666747 | accuracy: 0.8089488636363636 \n",
      "Epoch 6 | Step 2082 | loss: 0.4122090824504397 | accuracy: 0.8106343283582089 \n",
      "Epoch 6 | Step 2083 | loss: 0.4126219232292736 | accuracy: 0.8097426470588235 \n",
      "Epoch 6 | Step 2084 | loss: 0.41361910795819934 | accuracy: 0.8091032608695652 \n",
      "Epoch 6 | Step 2085 | loss: 0.4125081441232136 | accuracy: 0.8098214285714286 \n",
      "Epoch 6 | Step 2086 | loss: 0.4123190809303606 | accuracy: 0.8096390845070423 \n",
      "Epoch 6 | Step 2087 | loss: 0.41154833303557503 | accuracy: 0.8098958333333334 \n",
      "Epoch 6 | Step 2088 | loss: 0.4115538466466616 | accuracy: 0.8101455479452054 \n",
      "Epoch 6 | Step 2089 | loss: 0.4107695991123045 | accuracy: 0.8103885135135135 \n",
      "Epoch 6 | Step 2090 | loss: 0.4110235818227132 | accuracy: 0.8095833333333333 \n",
      "Epoch 6 | Step 2091 | loss: 0.4107366623847108 | accuracy: 0.8104440789473685 \n",
      "Epoch 6 | Step 2092 | loss: 0.4099984676032871 | accuracy: 0.8106737012987014 \n",
      "Epoch 6 | Step 2093 | loss: 0.4107027390064337 | accuracy: 0.810096153846154 \n",
      "Epoch 6 | Step 2094 | loss: 0.41234577154811425 | accuracy: 0.8091376582278482 \n",
      "Epoch 6 | Step 2095 | loss: 0.4127840016037226 | accuracy: 0.8091796875 \n",
      "Epoch 6 | Step 2096 | loss: 0.41211255023508897 | accuracy: 0.8094135802469136 \n",
      "Epoch 6 | Step 2097 | loss: 0.41199646126933215 | accuracy: 0.8090701219512195 \n",
      "Epoch 6 | Step 2098 | loss: 0.412493740937796 | accuracy: 0.8094879518072289 \n",
      "Epoch 6 | Step 2099 | loss: 0.41202321364766076 | accuracy: 0.8100818452380952 \n",
      "Epoch 6 | Step 2100 | loss: 0.4109033426817726 | accuracy: 0.8106617647058824 \n",
      "Epoch 6 | Step 2101 | loss: 0.41086292717345924 | accuracy: 0.8108648255813954 \n",
      "Epoch 6 | Step 2102 | loss: 0.41280737313730964 | accuracy: 0.8098060344827587 \n",
      "Epoch 6 | Step 2103 | loss: 0.4122880192642862 | accuracy: 0.8100142045454546 \n",
      "Epoch 6 | Step 2104 | loss: 0.4114046957385674 | accuracy: 0.8103932584269663 \n",
      "Epoch 6 | Step 2105 | loss: 0.412625225716167 | accuracy: 0.8102430555555555 \n",
      "Epoch 6 | Step 2106 | loss: 0.4121489213718163 | accuracy: 0.8106112637362637 \n",
      "Epoch 6 | Step 2107 | loss: 0.4112988192102183 | accuracy: 0.811141304347826 \n",
      "Epoch 6 | Step 2108 | loss: 0.41061235980321004 | accuracy: 0.8113239247311828 \n",
      "Epoch 6 | Step 2109 | loss: 0.41056763206390623 | accuracy: 0.8113364361702128 \n",
      "Epoch 6 | Step 2110 | loss: 0.4111410263337587 | accuracy: 0.8113486842105263 \n",
      "Epoch 6 | Step 2111 | loss: 0.41287346339474124 | accuracy: 0.81103515625 \n",
      "Epoch 6 | Step 2112 | loss: 0.4137581082963452 | accuracy: 0.8105670103092784 \n",
      "Epoch 6 | Step 2113 | loss: 0.4143475412714238 | accuracy: 0.8105867346938775 \n",
      "Epoch 6 | Step 2114 | loss: 0.41392856625595476 | accuracy: 0.8104482323232324 \n",
      "Epoch 6 | Step 2115 | loss: 0.41331839621067046 | accuracy: 0.810625 \n",
      "Epoch 6 | Step 2116 | loss: 0.41196858174730056 | accuracy: 0.8114170792079208 \n",
      "Epoch 6 | Step 2117 | loss: 0.4116005193369061 | accuracy: 0.8114276960784313 \n",
      "Epoch 6 | Step 2118 | loss: 0.41078135834156887 | accuracy: 0.8121966019417476 \n",
      "Epoch 6 | Step 2119 | loss: 0.4115103457409602 | accuracy: 0.8123497596153846 \n",
      "Epoch 6 | Step 2120 | loss: 0.4119235410576775 | accuracy: 0.812202380952381 \n",
      "Epoch 6 | Step 2121 | loss: 0.41142690968963336 | accuracy: 0.8122051886792453 \n",
      "Epoch 6 | Step 2122 | loss: 0.4125991485943304 | accuracy: 0.8123539719626168 \n",
      "Epoch 6 | Step 2123 | loss: 0.4133544213793896 | accuracy: 0.8116319444444444 \n",
      "Epoch 6 | Step 2124 | loss: 0.4135217084250319 | accuracy: 0.8112098623853211 \n",
      "Epoch 6 | Step 2125 | loss: 0.414254875887524 | accuracy: 0.8107954545454545 \n",
      "Epoch 6 | Step 2126 | loss: 0.41388240134393844 | accuracy: 0.8110923423423423 \n",
      "Epoch 6 | Step 2127 | loss: 0.41363283672503065 | accuracy: 0.8116629464285714 \n",
      "Epoch 6 | Step 2128 | loss: 0.4143968675516348 | accuracy: 0.8112555309734514 \n",
      "Epoch 6 | Step 2129 | loss: 0.4154036011089358 | accuracy: 0.8105811403508771 \n",
      "Epoch 6 | Step 2130 | loss: 0.4154337667900583 | accuracy: 0.810054347826087 \n",
      "Epoch 6 | Step 2131 | loss: 0.41566482468925675 | accuracy: 0.8099407327586207 \n",
      "Epoch 6 | Step 2132 | loss: 0.41606442311890107 | accuracy: 0.8098290598290598 \n",
      "Epoch 6 | Step 2133 | loss: 0.41659087801383715 | accuracy: 0.809322033898305 \n",
      "Epoch 6 | Step 2134 | loss: 0.4165039370540811 | accuracy: 0.8092174369747899 \n",
      "Epoch 6 | Step 2135 | loss: 0.4163333187500636 | accuracy: 0.8096354166666667 \n",
      "Epoch 6 | Step 2136 | loss: 0.4158123928653307 | accuracy: 0.8096590909090909 \n",
      "Epoch 6 | Step 2137 | loss: 0.4157591376636849 | accuracy: 0.8094262295081968 \n",
      "Epoch 6 | Step 2138 | loss: 0.4159596368549316 | accuracy: 0.8091971544715447 \n",
      "Epoch 6 | Step 2139 | loss: 0.41620335151110927 | accuracy: 0.8092237903225806 \n",
      "Epoch 6 | Step 2140 | loss: 0.41684272527694705 | accuracy: 0.809 \n",
      "Epoch 6 | Step 2141 | loss: 0.416660490253615 | accuracy: 0.8089037698412699 \n",
      "Epoch 6 | Step 2142 | loss: 0.41685283864576983 | accuracy: 0.8086860236220472 \n",
      "Epoch 6 | Step 2143 | loss: 0.416341649601236 | accuracy: 0.8089599609375 \n",
      "Epoch 6 | Step 2144 | loss: 0.41629701344541803 | accuracy: 0.8086240310077519 \n",
      "Epoch 6 | Step 2145 | loss: 0.4161383874141253 | accuracy: 0.8085336538461538 \n",
      "Epoch 6 | Step 2146 | loss: 0.4164089612833416 | accuracy: 0.8085639312977099 \n",
      "Epoch 6 | Step 2147 | loss: 0.4169760172565778 | accuracy: 0.8083570075757576 \n",
      "Epoch 6 | Step 2148 | loss: 0.4177657076738831 | accuracy: 0.8079182330827067 \n",
      "Epoch 6 | Step 2149 | loss: 0.4181812988288367 | accuracy: 0.8074860074626866 \n",
      "Epoch 6 | Step 2150 | loss: 0.4182431516823945 | accuracy: 0.8076388888888889 \n",
      "Epoch 6 | Step 2151 | loss: 0.4181283583097598 | accuracy: 0.8077895220588235 \n",
      "Epoch 6 | Step 2152 | loss: 0.4176613699345693 | accuracy: 0.8080520072992701 \n",
      "Epoch 6 | Step 2153 | loss: 0.41735747607721796 | accuracy: 0.8080842391304348 \n",
      "Epoch 6 | Step 2154 | loss: 0.4178667222853187 | accuracy: 0.8078911870503597 \n",
      "Epoch 6 | Step 2155 | loss: 0.41786257880074634 | accuracy: 0.8079241071428571 \n",
      "Epoch 6 | Step 2156 | loss: 0.4188979699256572 | accuracy: 0.8071808510638298 \n",
      "Epoch 6 | Step 2157 | loss: 0.4190356794377447 | accuracy: 0.8067781690140845 \n",
      "Epoch 6 | Step 2158 | loss: 0.4192798331484094 | accuracy: 0.806708916083916 \n",
      "Epoch 6 | Step 2159 | loss: 0.4195239401112 | accuracy: 0.8063151041666666 \n",
      "Epoch 6 | Step 2160 | loss: 0.41939425879511333 | accuracy: 0.8060344827586207 \n",
      "Epoch 6 | Step 2161 | loss: 0.41951765630343185 | accuracy: 0.805757705479452 \n",
      "Epoch 6 | Step 2162 | loss: 0.4187362376524477 | accuracy: 0.8063350340136054 \n",
      "Epoch 6 | Step 2163 | loss: 0.41937833178687733 | accuracy: 0.805637668918919 \n",
      "Epoch 6 | Step 2164 | loss: 0.4193790757016047 | accuracy: 0.8053691275167786 \n",
      "Epoch 6 | Step 2165 | loss: 0.41953897555669145 | accuracy: 0.8054166666666668 \n",
      "Epoch 6 | Step 2166 | loss: 0.4193044529845383 | accuracy: 0.8056705298013246 \n",
      "Epoch 6 | Step 2167 | loss: 0.41963829374627065 | accuracy: 0.8056126644736843 \n",
      "Epoch 6 | Step 2168 | loss: 0.4197564845770792 | accuracy: 0.8059640522875818 \n",
      "Epoch 6 | Step 2169 | loss: 0.41943502039104313 | accuracy: 0.8064123376623378 \n",
      "Epoch 6 | Step 2170 | loss: 0.41906204550496995 | accuracy: 0.8065524193548388 \n",
      "Epoch 6 | Step 2171 | loss: 0.4182157239470726 | accuracy: 0.8070913461538463 \n",
      "Epoch 6 | Step 2172 | loss: 0.4187046179346218 | accuracy: 0.8069267515923568 \n",
      "Epoch 6 | Step 2173 | loss: 0.418979209435137 | accuracy: 0.806665348101266 \n",
      "Epoch 6 | Step 2174 | loss: 0.41900838939648755 | accuracy: 0.8065055031446543 \n",
      "Epoch 6 | Step 2175 | loss: 0.4196952262893319 | accuracy: 0.8061523437500002 \n",
      "Epoch 6 | Step 2176 | loss: 0.42011267131900193 | accuracy: 0.8059006211180126 \n",
      "Epoch 6 | Step 2177 | loss: 0.42031050593028835 | accuracy: 0.8058449074074076 \n",
      "Epoch 6 | Step 2178 | loss: 0.42062609455336825 | accuracy: 0.8054064417177916 \n",
      "Epoch 6 | Step 2179 | loss: 0.4201808502761329 | accuracy: 0.8055449695121953 \n",
      "Epoch 6 | Step 2180 | loss: 0.419905711665298 | accuracy: 0.8059659090909093 \n",
      "Epoch 6 | Step 2181 | loss: 0.4199353596532201 | accuracy: 0.8060993975903616 \n",
      "Epoch 6 | Step 2182 | loss: 0.41963025231561263 | accuracy: 0.8064184131736528 \n",
      "Epoch 6 | Step 2183 | loss: 0.4203089259210087 | accuracy: 0.8064546130952382 \n",
      "Epoch 6 | Step 2184 | loss: 0.42001906672173 | accuracy: 0.8066752958579884 \n",
      "Epoch 6 | Step 2185 | loss: 0.4192559422815547 | accuracy: 0.8073529411764707 \n",
      "Epoch 6 | Step 2186 | loss: 0.4189933073102382 | accuracy: 0.8073830409356727 \n",
      "Epoch 6 | Step 2187 | loss: 0.41885296255350113 | accuracy: 0.8074127906976746 \n",
      "Epoch 6 | Step 2188 | loss: 0.4182518165924646 | accuracy: 0.8077131502890175 \n",
      "Epoch 6 | Step 2189 | loss: 0.418222911570264 | accuracy: 0.8079202586206898 \n",
      "Epoch 6 | Step 2190 | loss: 0.41817873869623456 | accuracy: 0.8077678571428573 \n",
      "Epoch 6 | Step 2191 | loss: 0.41842734221030364 | accuracy: 0.8078835227272729 \n",
      "Epoch 6 | Step 2192 | loss: 0.4191065152822915 | accuracy: 0.8075564971751414 \n",
      "Epoch 6 | Step 2193 | loss: 0.41928510786442275 | accuracy: 0.8074964887640451 \n",
      "Epoch 6 | Step 2194 | loss: 0.41934727373735864 | accuracy: 0.807437150837989 \n",
      "Epoch 6 | Step 2195 | loss: 0.41919557369417615 | accuracy: 0.8075520833333335 \n",
      "Epoch 6 | Step 2196 | loss: 0.41936539418130947 | accuracy: 0.8072341160220996 \n",
      "Epoch 6 | Step 2197 | loss: 0.41912560361427265 | accuracy: 0.8073489010989012 \n",
      "Epoch 6 | Step 2198 | loss: 0.4181568853842105 | accuracy: 0.8078893442622952 \n",
      "Epoch 6 | Step 2199 | loss: 0.4176518967294175 | accuracy: 0.8082540760869567 \n",
      "Epoch 6 | Step 2200 | loss: 0.4174094171137423 | accuracy: 0.8083614864864866 \n",
      "Epoch 6 | Step 2201 | loss: 0.41754595086138735 | accuracy: 0.8080477150537636 \n",
      "Epoch 6 | Step 2202 | loss: 0.4180639631607953 | accuracy: 0.8075701871657756 \n",
      "Epoch 6 | Step 2203 | loss: 0.4182271664129927 | accuracy: 0.8070146276595747 \n",
      "Epoch 6 | Step 2204 | loss: 0.417925324074175 | accuracy: 0.8073743386243388 \n",
      "Epoch 6 | Step 2205 | loss: 0.4186862813799005 | accuracy: 0.8069901315789475 \n",
      "Epoch 6 | Step 2206 | loss: 0.41807786691251225 | accuracy: 0.8072643979057593 \n",
      "Epoch 6 | Step 2207 | loss: 0.41776351785908145 | accuracy: 0.8072916666666669 \n",
      "Epoch 6 | Step 2208 | loss: 0.4172511361732384 | accuracy: 0.8078044041450778 \n",
      "Epoch 6 | Step 2209 | loss: 0.4172179615989174 | accuracy: 0.8078286082474229 \n",
      "Epoch 6 | Step 2210 | loss: 0.41716700868728834 | accuracy: 0.8079326923076925 \n",
      "Epoch 6 | Step 2211 | loss: 0.41718074329653565 | accuracy: 0.8081951530612246 \n",
      "Epoch 6 | Step 2212 | loss: 0.4169729846685671 | accuracy: 0.8084549492385789 \n",
      "Epoch 6 | Step 2213 | loss: 0.41686207040993856 | accuracy: 0.8084753787878789 \n",
      "Epoch 6 | Step 2214 | loss: 0.4165291907499783 | accuracy: 0.8088096733668343 \n",
      "Epoch 6 | Step 2215 | loss: 0.4160297532379627 | accuracy: 0.8091406250000002 \n",
      "Epoch 6 | Step 2216 | loss: 0.4165298379772338 | accuracy: 0.8087686567164181 \n",
      "Epoch 6 | Step 2217 | loss: 0.4161835578408572 | accuracy: 0.8090965346534655 \n",
      "Epoch 6 | Step 2218 | loss: 0.41596525628578485 | accuracy: 0.8093442118226603 \n",
      "Epoch 6 | Step 2219 | loss: 0.41592784006805983 | accuracy: 0.8093596813725492 \n",
      "Epoch 6 | Step 2220 | loss: 0.4160185406847698 | accuracy: 0.8090701219512196 \n",
      "Epoch 6 | Step 2221 | loss: 0.41673599226960856 | accuracy: 0.8086316747572817 \n",
      "Epoch 6 | Step 2222 | loss: 0.4171436141078599 | accuracy: 0.8085748792270533 \n",
      "Epoch 6 | Step 2223 | loss: 0.41718849554084814 | accuracy: 0.8085186298076924 \n",
      "Epoch 6 | Step 2224 | loss: 0.4171475144949826 | accuracy: 0.8086124401913877 \n",
      "Epoch 6 | Step 2225 | loss: 0.4175731762534096 | accuracy: 0.8083333333333335 \n",
      "Epoch 6 | Step 2226 | loss: 0.4177287178581925 | accuracy: 0.8082049763033177 \n",
      "Epoch 6 | Step 2227 | loss: 0.41713726253442046 | accuracy: 0.8085937500000001 \n",
      "Epoch 6 | Step 2228 | loss: 0.4167520118431306 | accuracy: 0.8086854460093899 \n",
      "Epoch 6 | Step 2229 | loss: 0.41682496625129306 | accuracy: 0.8087032710280375 \n",
      "Epoch 6 | Step 2230 | loss: 0.41665334216384 | accuracy: 0.808575581395349 \n",
      "Epoch 6 | Step 2231 | loss: 0.41671375806132954 | accuracy: 0.8084490740740742 \n",
      "Epoch 6 | Step 2232 | loss: 0.4164442376057673 | accuracy: 0.808467741935484 \n",
      "Epoch 6 | Step 2233 | loss: 0.4165417922472735 | accuracy: 0.808342889908257 \n",
      "Epoch 6 | Step 2234 | loss: 0.41675505668060964 | accuracy: 0.8080764840182649 \n",
      "Epoch 6 | Step 2235 | loss: 0.4166663645343347 | accuracy: 0.808096590909091 \n",
      "Epoch 6 | Step 2236 | loss: 0.41672958103240343 | accuracy: 0.8080458144796382 \n",
      "Epoch 6 | Step 2237 | loss: 0.41656635527138236 | accuracy: 0.8081362612612614 \n",
      "Epoch 6 | Step 2238 | loss: 0.4165051250714358 | accuracy: 0.8079456278026907 \n",
      "Epoch 6 | Step 2239 | loss: 0.41597002784588505 | accuracy: 0.8082449776785715 \n",
      "Epoch 6 | Step 2240 | loss: 0.41595621373918323 | accuracy: 0.8083333333333335 \n",
      "Epoch 6 | Step 2241 | loss: 0.4161341916934579 | accuracy: 0.8084209070796461 \n",
      "Epoch 6 | Step 2242 | loss: 0.41634615914412004 | accuracy: 0.8080947136563877 \n",
      "Epoch 6 | Step 2243 | loss: 0.41615529306102217 | accuracy: 0.808388157894737 \n",
      "Epoch 6 | Step 2244 | loss: 0.4161762548325884 | accuracy: 0.8082014192139739 \n",
      "Epoch 6 | Step 2245 | loss: 0.416209535235944 | accuracy: 0.808288043478261 \n",
      "Epoch 6 | Step 2246 | loss: 0.41555293052743525 | accuracy: 0.808779761904762 \n",
      "Epoch 6 | Step 2247 | loss: 0.4152800932783505 | accuracy: 0.8089978448275863 \n",
      "Epoch 6 | Step 2248 | loss: 0.4153142845170181 | accuracy: 0.808878755364807 \n",
      "Epoch 6 | Step 2249 | loss: 0.4152206489418307 | accuracy: 0.8090277777777779 \n",
      "Epoch 6 | Step 2250 | loss: 0.41482424824795827 | accuracy: 0.809308510638298 \n",
      "Epoch 6 | Step 2251 | loss: 0.41435707638324315 | accuracy: 0.8097192796610171 \n",
      "Epoch 6 | Step 2252 | loss: 0.41411651526322346 | accuracy: 0.8098628691983124 \n",
      "Epoch 6 | Step 2253 | loss: 0.41416884770914286 | accuracy: 0.8096113445378152 \n",
      "Epoch 6 | Step 2254 | loss: 0.4142164780006249 | accuracy: 0.8095580543933055 \n",
      "Epoch 6 | Step 2255 | loss: 0.4140211630612612 | accuracy: 0.8094401041666668 \n",
      "Epoch 6 | Step 2256 | loss: 0.41341070490753995 | accuracy: 0.8097121369294606 \n",
      "Epoch 6 | Step 2257 | loss: 0.41281406766126966 | accuracy: 0.8100464876033059 \n",
      "Epoch 6 | Step 2258 | loss: 0.41293016480810846 | accuracy: 0.810249485596708 \n",
      "Epoch 6 | Step 2259 | loss: 0.4131541569701961 | accuracy: 0.8100665983606559 \n",
      "Epoch 6 | Step 2260 | loss: 0.4131424002501429 | accuracy: 0.8102678571428572 \n",
      "Epoch 6 | Step 2261 | loss: 0.4128256184541113 | accuracy: 0.8104674796747968 \n",
      "Epoch 6 | Step 2262 | loss: 0.412590005740463 | accuracy: 0.8106654858299597 \n",
      "Epoch 6 | Step 2263 | loss: 0.4130867434845817 | accuracy: 0.8104838709677421 \n",
      "Epoch 6 | Step 2264 | loss: 0.4129046139468151 | accuracy: 0.8106174698795182 \n",
      "Epoch 6 | Step 2265 | loss: 0.41285499489307403 | accuracy: 0.8105625000000001 \n",
      "Epoch 6 | Step 2266 | loss: 0.41269382157648704 | accuracy: 0.8105079681274902 \n",
      "Epoch 6 | Step 2267 | loss: 0.4125146891862627 | accuracy: 0.810639880952381 \n",
      "Epoch 6 | Step 2268 | loss: 0.4123272800398438 | accuracy: 0.8108942687747037 \n",
      "Epoch 6 | Step 2269 | loss: 0.41222800607756366 | accuracy: 0.8110236220472442 \n",
      "Epoch 6 | Step 2270 | loss: 0.4119954236582214 | accuracy: 0.811029411764706 \n",
      "Epoch 6 | Step 2271 | loss: 0.41209268500097096 | accuracy: 0.8107910156250001 \n",
      "Epoch 6 | Step 2272 | loss: 0.41190670018993925 | accuracy: 0.8108584630350195 \n",
      "Epoch 6 | Step 2273 | loss: 0.41154862674631815 | accuracy: 0.8109253875968994 \n",
      "Epoch 6 | Step 2274 | loss: 0.4116098511403132 | accuracy: 0.810871138996139 \n",
      "Epoch 6 | Step 2275 | loss: 0.41129093479651674 | accuracy: 0.8111177884615386 \n",
      "Epoch 6 | Step 2276 | loss: 0.41195798753778595 | accuracy: 0.810763888888889 \n",
      "Epoch 6 | Step 2277 | loss: 0.41219005898664923 | accuracy: 0.8105319656488551 \n",
      "Epoch 6 | Step 2278 | loss: 0.4120091880908937 | accuracy: 0.8106582699619773 \n",
      "Epoch 6 | Step 2279 | loss: 0.4122786027464 | accuracy: 0.8106652462121213 \n",
      "Epoch 6 | Step 2280 | loss: 0.4121097780623526 | accuracy: 0.8107311320754718 \n",
      "Epoch 6 | Step 2281 | loss: 0.4116464576550892 | accuracy: 0.8109140037593986 \n",
      "Epoch 6 | Step 2282 | loss: 0.41144586993513926 | accuracy: 0.8110369850187267 \n",
      "Epoch 6 | Step 2283 | loss: 0.41157280264505697 | accuracy: 0.810867537313433 \n",
      "Epoch 6 | Step 2284 | loss: 0.4115281255714955 | accuracy: 0.810989776951673 \n",
      "Epoch 6 | Step 2285 | loss: 0.41147537982022314 | accuracy: 0.8111111111111112 \n",
      "Epoch 6 | Step 2286 | loss: 0.41161741134865254 | accuracy: 0.8110585793357935 \n",
      "Epoch 6 | Step 2287 | loss: 0.4115711461533518 | accuracy: 0.8111213235294119 \n",
      "Epoch 6 | Step 2288 | loss: 0.41162544150492203 | accuracy: 0.810897435897436 \n",
      "Epoch 6 | Step 2289 | loss: 0.4114475746224396 | accuracy: 0.8110743613138687 \n",
      "Epoch 6 | Step 2290 | loss: 0.4113180739229375 | accuracy: 0.8112500000000001 \n",
      "Epoch 6 | Step 2291 | loss: 0.411432523874269 | accuracy: 0.8111413043478262 \n",
      "Epoch 6 | Step 2292 | loss: 0.4113280726899308 | accuracy: 0.8111462093862817 \n",
      "Epoch 6 | Step 2293 | loss: 0.4110852166903104 | accuracy: 0.811207284172662 \n",
      "Epoch 6 | Step 2294 | loss: 0.41130382837360474 | accuracy: 0.8109879032258066 \n",
      "Epoch 6 | Step 2295 | loss: 0.410951269524438 | accuracy: 0.8112165178571431 \n",
      "Epoch 6 | Step 2296 | loss: 0.4110744060994891 | accuracy: 0.81110987544484 \n",
      "Epoch 6 | Step 2297 | loss: 0.41100628547211904 | accuracy: 0.8110593971631208 \n",
      "Epoch 6 | Step 2298 | loss: 0.4112117391593043 | accuracy: 0.811064487632509 \n",
      "Epoch 6 | Step 2299 | loss: 0.41100535342391104 | accuracy: 0.8110695422535213 \n",
      "Epoch 6 | Step 2300 | loss: 0.41097411251904664 | accuracy: 0.811184210526316 \n",
      "Epoch 6 | Step 2301 | loss: 0.41108294529514705 | accuracy: 0.8110249125874128 \n",
      "Epoch 6 | Step 2302 | loss: 0.41086602304455283 | accuracy: 0.8110844947735194 \n",
      "Epoch 6 | Step 2303 | loss: 0.41074642073363055 | accuracy: 0.8111436631944446 \n",
      "Epoch 6 | Step 2304 | loss: 0.41059284010147956 | accuracy: 0.8111483564013843 \n",
      "Epoch 6 | Step 2305 | loss: 0.41097524114723855 | accuracy: 0.8111530172413796 \n",
      "Epoch 6 | Step 2306 | loss: 0.4107106715133509 | accuracy: 0.8111576460481102 \n",
      "Epoch 6 | Step 2307 | loss: 0.4104984293449414 | accuracy: 0.8114297945205482 \n",
      "Epoch 6 | Step 2308 | loss: 0.4102566284938069 | accuracy: 0.81159343003413 \n",
      "Epoch 6 | Step 2309 | loss: 0.4097589258434009 | accuracy: 0.8119153911564628 \n",
      "Epoch 6 | Step 2310 | loss: 0.4103061465893761 | accuracy: 0.8115995762711867 \n",
      "Epoch 6 | Step 2311 | loss: 0.41009780724306355 | accuracy: 0.8117081925675679 \n",
      "Epoch 6 | Step 2312 | loss: 0.41021989020032906 | accuracy: 0.8116582491582495 \n",
      "Epoch 6 | Step 2313 | loss: 0.4100810792422134 | accuracy: 0.8118708053691278 \n",
      "Epoch 6 | Step 2314 | loss: 0.40977951924139033 | accuracy: 0.8119251672240806 \n",
      "Epoch 6 | Step 2315 | loss: 0.40948371867338806 | accuracy: 0.8120833333333336 \n",
      "Epoch 6 | Step 2316 | loss: 0.40943028691203087 | accuracy: 0.8122404485049837 \n",
      "Epoch 6 | Step 2317 | loss: 0.40948259741659976 | accuracy: 0.8123447847682123 \n",
      "Epoch 6 | Step 2318 | loss: 0.40922606424136515 | accuracy: 0.8122937293729376 \n",
      "Epoch 6 | Step 2319 | loss: 0.4090935796695319 | accuracy: 0.8123972039473688 \n",
      "Epoch 6 | Step 2320 | loss: 0.4094976052886149 | accuracy: 0.8119877049180332 \n",
      "Epoch 6 | Step 2321 | loss: 0.4091408484511904 | accuracy: 0.8122446895424841 \n",
      "Epoch 6 | Step 2322 | loss: 0.4088538554087523 | accuracy: 0.8124491042345281 \n",
      "Epoch 6 | Step 2323 | loss: 0.40873505252522296 | accuracy: 0.8124492694805199 \n",
      "Epoch 6 | Step 2324 | loss: 0.40825346305146565 | accuracy: 0.8128539644012949 \n",
      "Epoch 6 | Step 2325 | loss: 0.4079781125630101 | accuracy: 0.8131048387096778 \n",
      "Epoch 6 | Step 2326 | loss: 0.40776996616381916 | accuracy: 0.8132033762057882 \n",
      "Epoch 6 | Step 2327 | loss: 0.4077536801879222 | accuracy: 0.8129507211538466 \n",
      "Epoch 6 | Step 2328 | loss: 0.40772529846182254 | accuracy: 0.8128993610223647 \n",
      "Epoch 6 | Step 2329 | loss: 0.40756863479021993 | accuracy: 0.8130473726114654 \n",
      "Epoch 6 | Step 2330 | loss: 0.4070818806451463 | accuracy: 0.8133928571428575 \n",
      "Epoch 6 | Step 2331 | loss: 0.4071984525911414 | accuracy: 0.81339003164557 \n",
      "Epoch 6 | Step 2332 | loss: 0.4073739600858476 | accuracy: 0.8133872239747638 \n",
      "Epoch 6 | Step 2333 | loss: 0.40735015423042953 | accuracy: 0.8134827044025161 \n",
      "Epoch 6 | Step 2334 | loss: 0.4071947385711728 | accuracy: 0.8136265673981194 \n",
      "Epoch 6 | Step 2335 | loss: 0.4069976569153367 | accuracy: 0.8138183593750004 \n",
      "Epoch 6 | Step 2336 | loss: 0.4069903959923442 | accuracy: 0.8137655763239879 \n",
      "Epoch 6 | Step 2337 | loss: 0.4068103721423177 | accuracy: 0.8140042701863358 \n",
      "Epoch 6 | Step 2338 | loss: 0.406904489909163 | accuracy: 0.8138544891640871 \n",
      "Epoch 6 | Step 2339 | loss: 0.40677082391432756 | accuracy: 0.8138985339506176 \n",
      "Epoch 6 | Step 2340 | loss: 0.406766469478607 | accuracy: 0.8138942307692311 \n",
      "Epoch 6 | Step 2341 | loss: 0.40685718940810905 | accuracy: 0.8136023773006138 \n",
      "Epoch 6 | Step 2342 | loss: 0.4070274006882937 | accuracy: 0.8133600917431196 \n",
      "Epoch 6 | Step 2343 | loss: 0.40691486528006976 | accuracy: 0.8134527439024394 \n",
      "Epoch 6 | Step 2344 | loss: 0.40663409378028553 | accuracy: 0.813544832826748 \n",
      "Epoch 6 | Step 2345 | loss: 0.40673236801768775 | accuracy: 0.813541666666667 \n",
      "Epoch 6 | Step 2346 | loss: 0.406620757997576 | accuracy: 0.813680135951662 \n",
      "Epoch 6 | Step 2347 | loss: 0.4065650030970572 | accuracy: 0.8135824548192775 \n",
      "Epoch 6 | Step 2348 | loss: 0.406437613853105 | accuracy: 0.8136261261261265 \n",
      "Epoch 6 | Step 2349 | loss: 0.40625735144772196 | accuracy: 0.8139502245508985 \n",
      "Epoch 6 | Step 2350 | loss: 0.40646224982702894 | accuracy: 0.8136660447761197 \n",
      "Epoch 6 | Step 2351 | loss: 0.40629686761115263 | accuracy: 0.8138020833333337 \n",
      "Epoch 6 | Step 2352 | loss: 0.4063057436964277 | accuracy: 0.8137518545994069 \n",
      "Epoch 6 | Step 2353 | loss: 0.40607116596233195 | accuracy: 0.8139330621301778 \n",
      "Epoch 6 | Step 2354 | loss: 0.40595574901167253 | accuracy: 0.8140210176991154 \n",
      "Epoch 6 | Step 2355 | loss: 0.4059469233540926 | accuracy: 0.8140625000000004 \n",
      "Epoch 6 | Step 2356 | loss: 0.4059154294278263 | accuracy: 0.8140579178885634 \n",
      "Epoch 6 | Step 2357 | loss: 0.4058535268083649 | accuracy: 0.8141904239766086 \n",
      "Epoch 6 | Step 2358 | loss: 0.4055843488815573 | accuracy: 0.8142310495626826 \n",
      "Epoch 6 | Step 2359 | loss: 0.4057098116812316 | accuracy: 0.8141805959302328 \n",
      "Epoch 6 | Step 2360 | loss: 0.40533475487128534 | accuracy: 0.8144021739130438 \n",
      "Epoch 6 | Step 2361 | loss: 0.40519644785134074 | accuracy: 0.8146224710982662 \n",
      "Epoch 6 | Step 2362 | loss: 0.4050379539772824 | accuracy: 0.8146613832853029 \n",
      "Epoch 6 | Step 2363 | loss: 0.40493648396483767 | accuracy: 0.8147449712643682 \n",
      "Epoch 6 | Step 2364 | loss: 0.4047813645235787 | accuracy: 0.8146937679083098 \n",
      "Epoch 6 | Step 2365 | loss: 0.4051491816554749 | accuracy: 0.8145089285714289 \n",
      "Epoch 6 | Step 2366 | loss: 0.40479915510555264 | accuracy: 0.8147257834757838 \n",
      "Epoch 6 | Step 2367 | loss: 0.40466723049228825 | accuracy: 0.8147638494318185 \n",
      "Epoch 6 | Step 2368 | loss: 0.4046576293264501 | accuracy: 0.8146689093484423 \n",
      "Epoch 6 | Step 2369 | loss: 0.4048691521593405 | accuracy: 0.8144862288135597 \n",
      "Epoch 6 | Step 2370 | loss: 0.4046519459133415 | accuracy: 0.8145246478873243 \n",
      "Epoch 6 | Step 2371 | loss: 0.4042669734760615 | accuracy: 0.8146506320224722 \n",
      "Epoch 6 | Step 2372 | loss: 0.4044060837320919 | accuracy: 0.8145570728291319 \n",
      "Epoch 6 | Step 2373 | loss: 0.40461637803962097 | accuracy: 0.8145076815642461 \n",
      "Epoch 6 | Step 2374 | loss: 0.4043578746259045 | accuracy: 0.814589136490251 \n",
      "Epoch 6 | Step 2375 | loss: 0.4046041304038629 | accuracy: 0.8145399305555558 \n",
      "Epoch 6 | Step 2376 | loss: 0.4044456042741473 | accuracy: 0.8144909972299172 \n",
      "Epoch 6 | Step 2377 | loss: 0.40425720185206065 | accuracy: 0.8145718232044202 \n",
      "Epoch 6 | Step 2378 | loss: 0.4043036117205605 | accuracy: 0.8145661157024796 \n",
      "Epoch 6 | Step 2379 | loss: 0.4038741097345455 | accuracy: 0.814775068681319 \n",
      "Epoch 6 | Step 2380 | loss: 0.40370661836780897 | accuracy: 0.8148972602739729 \n",
      "Epoch 6 | Step 2381 | loss: 0.40370662477824193 | accuracy: 0.8149760928961751 \n",
      "Epoch 6 | Step 2382 | loss: 0.40393882340241505 | accuracy: 0.8148416212534063 \n",
      "Epoch 6 | Step 2383 | loss: 0.40371551745287737 | accuracy: 0.8149201766304351 \n",
      "Epoch 6 | Step 2384 | loss: 0.40378789736972576 | accuracy: 0.8149983062330627 \n",
      "Epoch 6 | Step 2385 | loss: 0.40375737797569566 | accuracy: 0.8149915540540543 \n",
      "Epoch 6 | Step 2386 | loss: 0.4039573729680875 | accuracy: 0.8147321428571431 \n",
      "Epoch 6 | Step 2387 | loss: 0.4038325714808637 | accuracy: 0.8147681451612906 \n",
      "Epoch 6 | Step 2388 | loss: 0.4034114093707009 | accuracy: 0.8150552949061666 \n",
      "Epoch 6 | Step 2389 | loss: 0.40321405506867125 | accuracy: 0.8151320187165778 \n",
      "Epoch 6 | Step 2390 | loss: 0.40339611605803155 | accuracy: 0.8150833333333336 \n",
      "Epoch 6 | Step 2391 | loss: 0.40350050380096775 | accuracy: 0.8149517952127663 \n",
      "Epoch 6 | Step 2392 | loss: 0.40347756461218104 | accuracy: 0.8149038461538465 \n",
      "Epoch 6 | Step 2393 | loss: 0.4035219557622752 | accuracy: 0.8146908068783072 \n",
      "Epoch 6 | Step 2394 | loss: 0.4033280018530293 | accuracy: 0.8146850263852246 \n",
      "Epoch 6 | Step 2395 | loss: 0.40323025666569395 | accuracy: 0.8146792763157897 \n",
      "Epoch 6 | Step 2396 | loss: 0.4029172961245683 | accuracy: 0.8148786089238849 \n",
      "Epoch 6 | Step 2397 | loss: 0.40309151745747507 | accuracy: 0.8148314790575919 \n",
      "Epoch 6 | Step 2398 | loss: 0.40316529953293 | accuracy: 0.8148253916449089 \n",
      "Epoch 6 | Step 2399 | loss: 0.40338574602113403 | accuracy: 0.8147786458333336 \n",
      "Epoch 6 | Step 2400 | loss: 0.4033677136356179 | accuracy: 0.8149756493506497 \n",
      "Epoch 6 | Step 2401 | loss: 0.40334433012212484 | accuracy: 0.8149287564766843 \n",
      "Epoch 6 | Step 2402 | loss: 0.40345846155047094 | accuracy: 0.8148821059431528 \n",
      "Epoch 6 | Step 2403 | loss: 0.4034765671900251 | accuracy: 0.8148759664948456 \n",
      "Epoch 6 | Step 2404 | loss: 0.4035406869986981 | accuracy: 0.8148296915167098 \n",
      "Epoch 6 | Step 2405 | loss: 0.4035872244299985 | accuracy: 0.8149038461538465 \n",
      "Epoch 6 | Step 2406 | loss: 0.4034330731691301 | accuracy: 0.8150575447570335 \n",
      "Epoch 6 | Step 2407 | loss: 0.4033810919416801 | accuracy: 0.8150908801020411 \n",
      "Epoch 6 | Step 2408 | loss: 0.4032279849431592 | accuracy: 0.8152035623409672 \n",
      "Epoch 6 | Step 2409 | loss: 0.4035196934027719 | accuracy: 0.8149190989847719 \n",
      "Epoch 6 | Step 2410 | loss: 0.40332181789452504 | accuracy: 0.8150316455696205 \n",
      "Epoch 6 | Step 2411 | loss: 0.403114383682759 | accuracy: 0.8152225378787882 \n",
      "Epoch 6 | Step 2412 | loss: 0.4029869969080316 | accuracy: 0.8152943954659952 \n",
      "Epoch 6 | Step 2413 | loss: 0.40303016468957426 | accuracy: 0.81516959798995 \n",
      "Epoch 6 | Step 2414 | loss: 0.40285110014273695 | accuracy: 0.8152020676691732 \n",
      "Epoch 6 | Step 2415 | loss: 0.4026977543905376 | accuracy: 0.8151953125000003 \n",
      "Epoch 6 | Step 2416 | loss: 0.40285636402870934 | accuracy: 0.8151496259351624 \n",
      "Epoch 6 | Step 2417 | loss: 0.4028035487182696 | accuracy: 0.8152207711442789 \n",
      "Epoch 6 | Step 2418 | loss: 0.402780043021325 | accuracy: 0.8150803242664482 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.532963216304779 | accuracy: 0.765625 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4551806151866913 | accuracy: 0.8125 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.48029961188634235 | accuracy: 0.8125 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.47870851308107376 | accuracy: 0.80078125 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.44460076093673706 | accuracy: 0.825 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4609307845433553 | accuracy: 0.8046875 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.45589608805520193 | accuracy: 0.8013392857142857 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4522809125483036 | accuracy: 0.80859375 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4647001988357968 | accuracy: 0.8055555555555556 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.45625098049640656 | accuracy: 0.8125 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4542334188114513 | accuracy: 0.8110795454545454 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4471210390329361 | accuracy: 0.8138020833333334 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4446543042476361 | accuracy: 0.8112980769230769 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4407716819218227 | accuracy: 0.8113839285714286 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.44208779533704123 | accuracy: 0.8145833333333333 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4436612222343683 | accuracy: 0.8134765625 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.45284075070829954 | accuracy: 0.8088235294117647 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.45492851899729836 | accuracy: 0.8064236111111112 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4507405475566262 | accuracy: 0.8083881578947368 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4506515145301819 | accuracy: 0.80546875 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.44610544613429476 | accuracy: 0.8065476190476191 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.44207758524201135 | accuracy: 0.8068181818181818 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.44752629684365314 | accuracy: 0.8002717391304348 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4567457338174184 | accuracy: 0.7955729166666666 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4622011971473694 | accuracy: 0.7925 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4604383088075198 | accuracy: 0.7938701923076923 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4567691507162871 | accuracy: 0.7945601851851852 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.45346255068268093 | accuracy: 0.7952008928571429 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4502725477876334 | accuracy: 0.796875 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4480452318986257 | accuracy: 0.7984375 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4427358815746923 | accuracy: 0.8009072580645161 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4455893151462078 | accuracy: 0.798828125 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.44649244528828247 | accuracy: 0.7982954545454546 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.45062803082606373 | accuracy: 0.7936580882352942 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4518778783934457 | accuracy: 0.79375 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4502198812034395 | accuracy: 0.7942708333333334 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.45104745674777674 | accuracy: 0.793918918918919 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.45223039937646764 | accuracy: 0.7939967105263159 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4519040202483153 | accuracy: 0.794070512820513 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4501497492194176 | accuracy: 0.7960937500000002 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.448697385264606 | accuracy: 0.7964939024390245 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4468404239132291 | accuracy: 0.7965029761904764 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.44778970230457393 | accuracy: 0.7957848837209304 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.45091169666160236 | accuracy: 0.7929687500000001 \n",
      "Validation | Epoch 6 | Step 2418 | loss: 0.4500792033142514 | accuracy: 0.7932216180695429 \n",
      "Epoch 7 | Step 2419 | loss: 0.47523316740989685 | accuracy: 0.84375 \n",
      "Epoch 7 | Step 2420 | loss: 0.3834976255893707 | accuracy: 0.859375 \n",
      "Epoch 7 | Step 2421 | loss: 0.3865940173467 | accuracy: 0.8489583333333334 \n",
      "Epoch 7 | Step 2422 | loss: 0.39891931414604187 | accuracy: 0.85546875 \n",
      "Epoch 7 | Step 2423 | loss: 0.37973164916038515 | accuracy: 0.859375 \n",
      "Epoch 7 | Step 2424 | loss: 0.38105180859565735 | accuracy: 0.8489583333333334 \n",
      "Epoch 7 | Step 2425 | loss: 0.3828914889267513 | accuracy: 0.8459821428571429 \n",
      "Epoch 7 | Step 2426 | loss: 0.38227206841111183 | accuracy: 0.845703125 \n",
      "Epoch 7 | Step 2427 | loss: 0.3887319796615177 | accuracy: 0.8385416666666666 \n",
      "Epoch 7 | Step 2428 | loss: 0.40278702080249784 | accuracy: 0.828125 \n",
      "Epoch 7 | Step 2429 | loss: 0.39074506001038983 | accuracy: 0.8380681818181818 \n",
      "Epoch 7 | Step 2430 | loss: 0.38508322338263196 | accuracy: 0.83984375 \n",
      "Epoch 7 | Step 2431 | loss: 0.39687734842300415 | accuracy: 0.8317307692307693 \n",
      "Epoch 7 | Step 2432 | loss: 0.3925021844250815 | accuracy: 0.8348214285714286 \n",
      "Epoch 7 | Step 2433 | loss: 0.39244621992111206 | accuracy: 0.834375 \n",
      "Epoch 7 | Step 2434 | loss: 0.38629781641066074 | accuracy: 0.8349609375 \n",
      "Epoch 7 | Step 2435 | loss: 0.3876113523455227 | accuracy: 0.8299632352941176 \n",
      "Epoch 7 | Step 2436 | loss: 0.3855432586537467 | accuracy: 0.8315972222222222 \n",
      "Epoch 7 | Step 2437 | loss: 0.3826717420628196 | accuracy: 0.8322368421052632 \n",
      "Epoch 7 | Step 2438 | loss: 0.38610407412052156 | accuracy: 0.83203125 \n",
      "Epoch 7 | Step 2439 | loss: 0.38701696197191876 | accuracy: 0.8318452380952381 \n",
      "Epoch 7 | Step 2440 | loss: 0.38939129493453284 | accuracy: 0.8302556818181818 \n",
      "Epoch 7 | Step 2441 | loss: 0.38825508045113605 | accuracy: 0.8315217391304348 \n",
      "Epoch 7 | Step 2442 | loss: 0.3891939123471578 | accuracy: 0.830078125 \n",
      "Epoch 7 | Step 2443 | loss: 0.3936355185508728 | accuracy: 0.82625 \n",
      "Epoch 7 | Step 2444 | loss: 0.3941765370277258 | accuracy: 0.8245192307692307 \n",
      "Epoch 7 | Step 2445 | loss: 0.39586767995799027 | accuracy: 0.8223379629629629 \n",
      "Epoch 7 | Step 2446 | loss: 0.39457396950040546 | accuracy: 0.82421875 \n",
      "Epoch 7 | Step 2447 | loss: 0.39718082444421177 | accuracy: 0.8232758620689655 \n",
      "Epoch 7 | Step 2448 | loss: 0.39848397970199584 | accuracy: 0.8223958333333333 \n",
      "Epoch 7 | Step 2449 | loss: 0.3951174347631393 | accuracy: 0.8245967741935484 \n",
      "Epoch 7 | Step 2450 | loss: 0.39538616966456175 | accuracy: 0.82421875 \n",
      "Epoch 7 | Step 2451 | loss: 0.3959286691564502 | accuracy: 0.8243371212121212 \n",
      "Epoch 7 | Step 2452 | loss: 0.39264680532848134 | accuracy: 0.8267463235294118 \n",
      "Epoch 7 | Step 2453 | loss: 0.3897174315793174 | accuracy: 0.828125 \n",
      "Epoch 7 | Step 2454 | loss: 0.38868320484956104 | accuracy: 0.8263888888888888 \n",
      "Epoch 7 | Step 2455 | loss: 0.38883928189406525 | accuracy: 0.8264358108108109 \n",
      "Epoch 7 | Step 2456 | loss: 0.39053778271926076 | accuracy: 0.8252467105263158 \n",
      "Epoch 7 | Step 2457 | loss: 0.38866380697641617 | accuracy: 0.8269230769230769 \n",
      "Epoch 7 | Step 2458 | loss: 0.38633926287293435 | accuracy: 0.827734375 \n",
      "Epoch 7 | Step 2459 | loss: 0.387006311881833 | accuracy: 0.828125 \n",
      "Epoch 7 | Step 2460 | loss: 0.3880739084311894 | accuracy: 0.8270089285714286 \n",
      "Epoch 7 | Step 2461 | loss: 0.3863846042821574 | accuracy: 0.8270348837209303 \n",
      "Epoch 7 | Step 2462 | loss: 0.3842943480068987 | accuracy: 0.828125 \n",
      "Epoch 7 | Step 2463 | loss: 0.3844575040870243 | accuracy: 0.8295138888888889 \n",
      "Epoch 7 | Step 2464 | loss: 0.38394210908723914 | accuracy: 0.8288043478260869 \n",
      "Epoch 7 | Step 2465 | loss: 0.38630763393767337 | accuracy: 0.8271276595744681 \n",
      "Epoch 7 | Step 2466 | loss: 0.3871116532633702 | accuracy: 0.8264973958333334 \n",
      "Epoch 7 | Step 2467 | loss: 0.38979303289432915 | accuracy: 0.8246173469387755 \n",
      "Epoch 7 | Step 2468 | loss: 0.3900380104780197 | accuracy: 0.8240625 \n",
      "Epoch 7 | Step 2469 | loss: 0.38893910482818006 | accuracy: 0.8253676470588235 \n",
      "Epoch 7 | Step 2470 | loss: 0.3877820974359146 | accuracy: 0.8257211538461539 \n",
      "Epoch 7 | Step 2471 | loss: 0.38830663460605547 | accuracy: 0.8248820754716981 \n",
      "Epoch 7 | Step 2472 | loss: 0.3874018137101774 | accuracy: 0.8255208333333334 \n",
      "Epoch 7 | Step 2473 | loss: 0.38738861138170416 | accuracy: 0.8255681818181818 \n",
      "Epoch 7 | Step 2474 | loss: 0.38702893470014843 | accuracy: 0.8264508928571429 \n",
      "Epoch 7 | Step 2475 | loss: 0.38739202210777685 | accuracy: 0.8259320175438597 \n",
      "Epoch 7 | Step 2476 | loss: 0.38740473369072226 | accuracy: 0.826239224137931 \n",
      "Epoch 7 | Step 2477 | loss: 0.389013334856195 | accuracy: 0.8257415254237288 \n",
      "Epoch 7 | Step 2478 | loss: 0.38869004795948664 | accuracy: 0.8255208333333334 \n",
      "Epoch 7 | Step 2479 | loss: 0.38806783175859294 | accuracy: 0.8260758196721312 \n",
      "Epoch 7 | Step 2480 | loss: 0.38675509008669084 | accuracy: 0.827116935483871 \n",
      "Epoch 7 | Step 2481 | loss: 0.38801544857403586 | accuracy: 0.8271329365079365 \n",
      "Epoch 7 | Step 2482 | loss: 0.3863877225667238 | accuracy: 0.82763671875 \n",
      "Epoch 7 | Step 2483 | loss: 0.38557629676965566 | accuracy: 0.828125 \n",
      "Epoch 7 | Step 2484 | loss: 0.3842664261658986 | accuracy: 0.8290719696969697 \n",
      "Epoch 7 | Step 2485 | loss: 0.38340564405740196 | accuracy: 0.8292910447761194 \n",
      "Epoch 7 | Step 2486 | loss: 0.38364701411303354 | accuracy: 0.8288143382352942 \n",
      "Epoch 7 | Step 2487 | loss: 0.38478798753973364 | accuracy: 0.8283514492753623 \n",
      "Epoch 7 | Step 2488 | loss: 0.3837690953697477 | accuracy: 0.8287946428571429 \n",
      "Epoch 7 | Step 2489 | loss: 0.38315870266565133 | accuracy: 0.829225352112676 \n",
      "Epoch 7 | Step 2490 | loss: 0.3823719521363576 | accuracy: 0.8296440972222222 \n",
      "Epoch 7 | Step 2491 | loss: 0.3820004573423568 | accuracy: 0.8294092465753424 \n",
      "Epoch 7 | Step 2492 | loss: 0.3811036114757125 | accuracy: 0.8296030405405406 \n",
      "Epoch 7 | Step 2493 | loss: 0.3816852056980133 | accuracy: 0.829375 \n",
      "Epoch 7 | Step 2494 | loss: 0.3814160172876559 | accuracy: 0.8295641447368421 \n",
      "Epoch 7 | Step 2495 | loss: 0.38105701974460054 | accuracy: 0.8299512987012987 \n",
      "Epoch 7 | Step 2496 | loss: 0.3817830609205441 | accuracy: 0.8301282051282052 \n",
      "Epoch 7 | Step 2497 | loss: 0.3833870031411134 | accuracy: 0.8293117088607594 \n",
      "Epoch 7 | Step 2498 | loss: 0.38401368111371986 | accuracy: 0.829296875 \n",
      "Epoch 7 | Step 2499 | loss: 0.38353087467911795 | accuracy: 0.8292824074074074 \n",
      "Epoch 7 | Step 2500 | loss: 0.38317330108910064 | accuracy: 0.8292682926829268 \n",
      "Epoch 7 | Step 2501 | loss: 0.3834601446806665 | accuracy: 0.8292545180722891 \n",
      "Epoch 7 | Step 2502 | loss: 0.3828606261383918 | accuracy: 0.8297991071428571 \n",
      "Epoch 7 | Step 2503 | loss: 0.38202569169156675 | accuracy: 0.830514705882353 \n",
      "Epoch 7 | Step 2504 | loss: 0.3825460987728694 | accuracy: 0.8301235465116279 \n",
      "Epoch 7 | Step 2505 | loss: 0.38406519882980417 | accuracy: 0.829382183908046 \n",
      "Epoch 7 | Step 2506 | loss: 0.38390934568914487 | accuracy: 0.8299005681818182 \n",
      "Epoch 7 | Step 2507 | loss: 0.38293250156252556 | accuracy: 0.8304073033707865 \n",
      "Epoch 7 | Step 2508 | loss: 0.38404910630649974 | accuracy: 0.8298611111111112 \n",
      "Epoch 7 | Step 2509 | loss: 0.38350203633308394 | accuracy: 0.8301854395604396 \n",
      "Epoch 7 | Step 2510 | loss: 0.38273550472829637 | accuracy: 0.8308423913043478 \n",
      "Epoch 7 | Step 2511 | loss: 0.3825766809525027 | accuracy: 0.8306451612903226 \n",
      "Epoch 7 | Step 2512 | loss: 0.38264455313378176 | accuracy: 0.8299534574468085 \n",
      "Epoch 7 | Step 2513 | loss: 0.38293025148542287 | accuracy: 0.8302631578947368 \n",
      "Epoch 7 | Step 2514 | loss: 0.3848388136054077 | accuracy: 0.8299153645833334 \n",
      "Epoch 7 | Step 2515 | loss: 0.3855526994184119 | accuracy: 0.8294136597938144 \n",
      "Epoch 7 | Step 2516 | loss: 0.3865382574042494 | accuracy: 0.8289221938775511 \n",
      "Epoch 7 | Step 2517 | loss: 0.3861464897189476 | accuracy: 0.829229797979798 \n",
      "Epoch 7 | Step 2518 | loss: 0.3853758630156516 | accuracy: 0.82953125 \n",
      "Epoch 7 | Step 2519 | loss: 0.3840086333232349 | accuracy: 0.8299814356435643 \n",
      "Epoch 7 | Step 2520 | loss: 0.38368797097720336 | accuracy: 0.8301164215686274 \n",
      "Epoch 7 | Step 2521 | loss: 0.3827418786229438 | accuracy: 0.8307038834951457 \n",
      "Epoch 7 | Step 2522 | loss: 0.3837341236380429 | accuracy: 0.8303786057692307 \n",
      "Epoch 7 | Step 2523 | loss: 0.38436351560410986 | accuracy: 0.8300595238095239 \n",
      "Epoch 7 | Step 2524 | loss: 0.3839220230309467 | accuracy: 0.8298938679245284 \n",
      "Epoch 7 | Step 2525 | loss: 0.38503342142728986 | accuracy: 0.8300233644859814 \n",
      "Epoch 7 | Step 2526 | loss: 0.385903750028875 | accuracy: 0.8291377314814815 \n",
      "Epoch 7 | Step 2527 | loss: 0.38589423566783226 | accuracy: 0.8288417431192661 \n",
      "Epoch 7 | Step 2528 | loss: 0.38612180081280784 | accuracy: 0.8286931818181819 \n",
      "Epoch 7 | Step 2529 | loss: 0.38602884878983357 | accuracy: 0.8288288288288288 \n",
      "Epoch 7 | Step 2530 | loss: 0.3857750988432338 | accuracy: 0.8292410714285714 \n",
      "Epoch 7 | Step 2531 | loss: 0.3866059242096621 | accuracy: 0.8292311946902655 \n",
      "Epoch 7 | Step 2532 | loss: 0.3878335022089773 | accuracy: 0.8288103070175439 \n",
      "Epoch 7 | Step 2533 | loss: 0.38767620998880126 | accuracy: 0.8290760869565217 \n",
      "Epoch 7 | Step 2534 | loss: 0.3879178860064209 | accuracy: 0.8289331896551724 \n",
      "Epoch 7 | Step 2535 | loss: 0.38857076336175955 | accuracy: 0.8282585470085471 \n",
      "Epoch 7 | Step 2536 | loss: 0.3890385837373086 | accuracy: 0.8279925847457628 \n",
      "Epoch 7 | Step 2537 | loss: 0.3887542320900603 | accuracy: 0.8282563025210085 \n",
      "Epoch 7 | Step 2538 | loss: 0.3880705083409944 | accuracy: 0.82890625 \n",
      "Epoch 7 | Step 2539 | loss: 0.3876719923058816 | accuracy: 0.8287706611570248 \n",
      "Epoch 7 | Step 2540 | loss: 0.38760186487533993 | accuracy: 0.8285092213114754 \n",
      "Epoch 7 | Step 2541 | loss: 0.38774881299918246 | accuracy: 0.828125 \n",
      "Epoch 7 | Step 2542 | loss: 0.38820103724156646 | accuracy: 0.828125 \n",
      "Epoch 7 | Step 2543 | loss: 0.38868840503692614 | accuracy: 0.827625 \n",
      "Epoch 7 | Step 2544 | loss: 0.38853631298693386 | accuracy: 0.8276289682539683 \n",
      "Epoch 7 | Step 2545 | loss: 0.38875860726739464 | accuracy: 0.827386811023622 \n",
      "Epoch 7 | Step 2546 | loss: 0.3880630414932965 | accuracy: 0.8277587890625 \n",
      "Epoch 7 | Step 2547 | loss: 0.3878631748894387 | accuracy: 0.8275193798449613 \n",
      "Epoch 7 | Step 2548 | loss: 0.387591254711151 | accuracy: 0.8276442307692308 \n",
      "Epoch 7 | Step 2549 | loss: 0.3880787951345661 | accuracy: 0.8274093511450382 \n",
      "Epoch 7 | Step 2550 | loss: 0.3887212524811426 | accuracy: 0.8270596590909091 \n",
      "Epoch 7 | Step 2551 | loss: 0.38967949510516964 | accuracy: 0.8264802631578947 \n",
      "Epoch 7 | Step 2552 | loss: 0.390076969319315 | accuracy: 0.8261427238805971 \n",
      "Epoch 7 | Step 2553 | loss: 0.39000690976778657 | accuracy: 0.8263888888888888 \n",
      "Epoch 7 | Step 2554 | loss: 0.38984983633546255 | accuracy: 0.8264016544117647 \n",
      "Epoch 7 | Step 2555 | loss: 0.3892599009249331 | accuracy: 0.8264142335766423 \n",
      "Epoch 7 | Step 2556 | loss: 0.38878548037314753 | accuracy: 0.8265398550724637 \n",
      "Epoch 7 | Step 2557 | loss: 0.3896467644962475 | accuracy: 0.8259892086330936 \n",
      "Epoch 7 | Step 2558 | loss: 0.3896512787256922 | accuracy: 0.8260044642857143 \n",
      "Epoch 7 | Step 2559 | loss: 0.39051226330987104 | accuracy: 0.825354609929078 \n",
      "Epoch 7 | Step 2560 | loss: 0.39063851094581714 | accuracy: 0.8252640845070423 \n",
      "Epoch 7 | Step 2561 | loss: 0.3910301579878881 | accuracy: 0.824847027972028 \n",
      "Epoch 7 | Step 2562 | loss: 0.39134905839131945 | accuracy: 0.824435763888889 \n",
      "Epoch 7 | Step 2563 | loss: 0.3912715247992812 | accuracy: 0.8243534482758622 \n",
      "Epoch 7 | Step 2564 | loss: 0.3912053867562177 | accuracy: 0.8242722602739727 \n",
      "Epoch 7 | Step 2565 | loss: 0.39059984379885154 | accuracy: 0.8248299319727892 \n",
      "Epoch 7 | Step 2566 | loss: 0.39066593208023026 | accuracy: 0.824535472972973 \n",
      "Epoch 7 | Step 2567 | loss: 0.3905735355895638 | accuracy: 0.8243498322147652 \n",
      "Epoch 7 | Step 2568 | loss: 0.3908788897593817 | accuracy: 0.8243750000000001 \n",
      "Epoch 7 | Step 2569 | loss: 0.39080251388202447 | accuracy: 0.8246067880794703 \n",
      "Epoch 7 | Step 2570 | loss: 0.39117173458400534 | accuracy: 0.8245271381578948 \n",
      "Epoch 7 | Step 2571 | loss: 0.3911366449072471 | accuracy: 0.8247549019607844 \n",
      "Epoch 7 | Step 2572 | loss: 0.39088383800797655 | accuracy: 0.8249797077922079 \n",
      "Epoch 7 | Step 2573 | loss: 0.39054571082515105 | accuracy: 0.8253024193548388 \n",
      "Epoch 7 | Step 2574 | loss: 0.3896506235767634 | accuracy: 0.8260216346153846 \n",
      "Epoch 7 | Step 2575 | loss: 0.3902212985002312 | accuracy: 0.8258359872611465 \n",
      "Epoch 7 | Step 2576 | loss: 0.3910643948784358 | accuracy: 0.8255537974683544 \n",
      "Epoch 7 | Step 2577 | loss: 0.39138357613071717 | accuracy: 0.825373427672956 \n",
      "Epoch 7 | Step 2578 | loss: 0.39182783346623196 | accuracy: 0.825 \n",
      "Epoch 7 | Step 2579 | loss: 0.39206958168782075 | accuracy: 0.8245341614906833 \n",
      "Epoch 7 | Step 2580 | loss: 0.3922813341573434 | accuracy: 0.8243634259259259 \n",
      "Epoch 7 | Step 2581 | loss: 0.3925407243652579 | accuracy: 0.8238113496932515 \n",
      "Epoch 7 | Step 2582 | loss: 0.3921903820662965 | accuracy: 0.8237423780487805 \n",
      "Epoch 7 | Step 2583 | loss: 0.3920565048853557 | accuracy: 0.8243371212121212 \n",
      "Epoch 7 | Step 2584 | loss: 0.3919637860303903 | accuracy: 0.8243599397590361 \n",
      "Epoch 7 | Step 2585 | loss: 0.3915866918549567 | accuracy: 0.8246631736526946 \n",
      "Epoch 7 | Step 2586 | loss: 0.39237048743026604 | accuracy: 0.8244977678571429 \n",
      "Epoch 7 | Step 2587 | loss: 0.39201849293426655 | accuracy: 0.8247965976331361 \n",
      "Epoch 7 | Step 2588 | loss: 0.39126785169629497 | accuracy: 0.8253676470588235 \n",
      "Epoch 7 | Step 2589 | loss: 0.3909994076218522 | accuracy: 0.8254751461988304 \n",
      "Epoch 7 | Step 2590 | loss: 0.3907083259072415 | accuracy: 0.8254905523255814 \n",
      "Epoch 7 | Step 2591 | loss: 0.3901314444280085 | accuracy: 0.8256864161849711 \n",
      "Epoch 7 | Step 2592 | loss: 0.38999780704235215 | accuracy: 0.8256106321839081 \n",
      "Epoch 7 | Step 2593 | loss: 0.38996911832264497 | accuracy: 0.8254464285714286 \n",
      "Epoch 7 | Step 2594 | loss: 0.39037747799672873 | accuracy: 0.8253728693181818 \n",
      "Epoch 7 | Step 2595 | loss: 0.3913282810968195 | accuracy: 0.8250353107344632 \n",
      "Epoch 7 | Step 2596 | loss: 0.39163057539570206 | accuracy: 0.8247893258426966 \n",
      "Epoch 7 | Step 2597 | loss: 0.3918811432476151 | accuracy: 0.8247206703910615 \n",
      "Epoch 7 | Step 2598 | loss: 0.39155578778849714 | accuracy: 0.8247395833333333 \n",
      "Epoch 7 | Step 2599 | loss: 0.39176081310319644 | accuracy: 0.8243266574585635 \n",
      "Epoch 7 | Step 2600 | loss: 0.3913613579102926 | accuracy: 0.8246050824175825 \n",
      "Epoch 7 | Step 2601 | loss: 0.390331353971867 | accuracy: 0.825136612021858 \n",
      "Epoch 7 | Step 2602 | loss: 0.3897058116677016 | accuracy: 0.825577445652174 \n",
      "Epoch 7 | Step 2603 | loss: 0.3893961200842987 | accuracy: 0.8256756756756757 \n",
      "Epoch 7 | Step 2604 | loss: 0.38960498090713264 | accuracy: 0.8256048387096774 \n",
      "Epoch 7 | Step 2605 | loss: 0.39007906623702643 | accuracy: 0.8251169786096256 \n",
      "Epoch 7 | Step 2606 | loss: 0.390346701950469 | accuracy: 0.824717420212766 \n",
      "Epoch 7 | Step 2607 | loss: 0.38996547492092887 | accuracy: 0.8250661375661376 \n",
      "Epoch 7 | Step 2608 | loss: 0.3906626453525142 | accuracy: 0.8248355263157895 \n",
      "Epoch 7 | Step 2609 | loss: 0.38991726942711485 | accuracy: 0.8252617801047121 \n",
      "Epoch 7 | Step 2610 | loss: 0.38970105784634756 | accuracy: 0.825439453125 \n",
      "Epoch 7 | Step 2611 | loss: 0.38941124282352674 | accuracy: 0.8258581606217616 \n",
      "Epoch 7 | Step 2612 | loss: 0.3894557413673893 | accuracy: 0.8259503865979382 \n",
      "Epoch 7 | Step 2613 | loss: 0.38940147940929126 | accuracy: 0.825801282051282 \n",
      "Epoch 7 | Step 2614 | loss: 0.38952903023787916 | accuracy: 0.8257334183673469 \n",
      "Epoch 7 | Step 2615 | loss: 0.3894270734133455 | accuracy: 0.8258248730964467 \n",
      "Epoch 7 | Step 2616 | loss: 0.38918512036101993 | accuracy: 0.8259154040404041 \n",
      "Epoch 7 | Step 2617 | loss: 0.3888230412150149 | accuracy: 0.8264761306532663 \n",
      "Epoch 7 | Step 2618 | loss: 0.3881970492005349 | accuracy: 0.826796875 \n",
      "Epoch 7 | Step 2619 | loss: 0.388964997298682 | accuracy: 0.8264925373134329 \n",
      "Epoch 7 | Step 2620 | loss: 0.3884705827377811 | accuracy: 0.8268873762376238 \n",
      "Epoch 7 | Step 2621 | loss: 0.38822995574016295 | accuracy: 0.8271243842364532 \n",
      "Epoch 7 | Step 2622 | loss: 0.3881725505286573 | accuracy: 0.8272824754901961 \n",
      "Epoch 7 | Step 2623 | loss: 0.38836608238336523 | accuracy: 0.8269817073170732 \n",
      "Epoch 7 | Step 2624 | loss: 0.389025842825186 | accuracy: 0.8266080097087378 \n",
      "Epoch 7 | Step 2625 | loss: 0.3895074435766193 | accuracy: 0.8265398550724637 \n",
      "Epoch 7 | Step 2626 | loss: 0.3896866460832266 | accuracy: 0.8262469951923077 \n",
      "Epoch 7 | Step 2627 | loss: 0.3896500137434052 | accuracy: 0.826255980861244 \n",
      "Epoch 7 | Step 2628 | loss: 0.3899139008351735 | accuracy: 0.8260416666666667 \n",
      "Epoch 7 | Step 2629 | loss: 0.3901862146165134 | accuracy: 0.8259034360189573 \n",
      "Epoch 7 | Step 2630 | loss: 0.3895422914680446 | accuracy: 0.8262824292452831 \n",
      "Epoch 7 | Step 2631 | loss: 0.38908181363987815 | accuracy: 0.8265111502347418 \n",
      "Epoch 7 | Step 2632 | loss: 0.3892007004991871 | accuracy: 0.8263726635514018 \n",
      "Epoch 7 | Step 2633 | loss: 0.38906822897667115 | accuracy: 0.8263081395348837 \n",
      "Epoch 7 | Step 2634 | loss: 0.38915681452662865 | accuracy: 0.8260271990740741 \n",
      "Epoch 7 | Step 2635 | loss: 0.3888413065589519 | accuracy: 0.8262528801843319 \n",
      "Epoch 7 | Step 2636 | loss: 0.3889143849731586 | accuracy: 0.8261897935779816 \n",
      "Epoch 7 | Step 2637 | loss: 0.38873218959324984 | accuracy: 0.8262699771689498 \n",
      "Epoch 7 | Step 2638 | loss: 0.3885751201347872 | accuracy: 0.8262073863636363 \n",
      "Epoch 7 | Step 2639 | loss: 0.38868147283118243 | accuracy: 0.8261453619909502 \n",
      "Epoch 7 | Step 2640 | loss: 0.38851885846606254 | accuracy: 0.8261542792792793 \n",
      "Epoch 7 | Step 2641 | loss: 0.3883956652051131 | accuracy: 0.8261631165919282 \n",
      "Epoch 7 | Step 2642 | loss: 0.3878027424216271 | accuracy: 0.8265206473214286 \n",
      "Epoch 7 | Step 2643 | loss: 0.3877547766102685 | accuracy: 0.8265277777777778 \n",
      "Epoch 7 | Step 2644 | loss: 0.3879688123686124 | accuracy: 0.8265348451327433 \n",
      "Epoch 7 | Step 2645 | loss: 0.38803350846672907 | accuracy: 0.8262665198237885 \n",
      "Epoch 7 | Step 2646 | loss: 0.3881081721761771 | accuracy: 0.8264117324561403 \n",
      "Epoch 7 | Step 2647 | loss: 0.38814654803171955 | accuracy: 0.826146288209607 \n",
      "Epoch 7 | Step 2648 | loss: 0.3881659961265067 | accuracy: 0.8261548913043478 \n",
      "Epoch 7 | Step 2649 | loss: 0.3876680285383613 | accuracy: 0.8264339826839827 \n",
      "Epoch 7 | Step 2650 | loss: 0.3874119801511025 | accuracy: 0.8266433189655172 \n",
      "Epoch 7 | Step 2651 | loss: 0.3874238124476994 | accuracy: 0.8265155579399142 \n",
      "Epoch 7 | Step 2652 | loss: 0.387415331016239 | accuracy: 0.8265224358974359 \n",
      "Epoch 7 | Step 2653 | loss: 0.38702026288560104 | accuracy: 0.8268617021276595 \n",
      "Epoch 7 | Step 2654 | loss: 0.3864968975974342 | accuracy: 0.8272643008474576 \n",
      "Epoch 7 | Step 2655 | loss: 0.38620755780598287 | accuracy: 0.8274657172995781 \n",
      "Epoch 7 | Step 2656 | loss: 0.38626134984132626 | accuracy: 0.8272715336134454 \n",
      "Epoch 7 | Step 2657 | loss: 0.386474169572527 | accuracy: 0.8270789748953975 \n",
      "Epoch 7 | Step 2658 | loss: 0.38623195774853236 | accuracy: 0.8270833333333333 \n",
      "Epoch 7 | Step 2659 | loss: 0.38561571868623445 | accuracy: 0.827411825726141 \n",
      "Epoch 7 | Step 2660 | loss: 0.38500802428269193 | accuracy: 0.8277376033057852 \n",
      "Epoch 7 | Step 2661 | loss: 0.38509535691375113 | accuracy: 0.8279320987654321 \n",
      "Epoch 7 | Step 2662 | loss: 0.38535274662932417 | accuracy: 0.8277407786885246 \n",
      "Epoch 7 | Step 2663 | loss: 0.3853622698054022 | accuracy: 0.8278061224489796 \n",
      "Epoch 7 | Step 2664 | loss: 0.3852087895317776 | accuracy: 0.827807418699187 \n",
      "Epoch 7 | Step 2665 | loss: 0.38490367128781466 | accuracy: 0.828125 \n",
      "Epoch 7 | Step 2666 | loss: 0.38536525361480256 | accuracy: 0.8279989919354839 \n",
      "Epoch 7 | Step 2667 | loss: 0.3852583464369717 | accuracy: 0.8281877510040161 \n",
      "Epoch 7 | Step 2668 | loss: 0.38531860029697423 | accuracy: 0.8280625 \n",
      "Epoch 7 | Step 2669 | loss: 0.38513149873193997 | accuracy: 0.828125 \n",
      "Epoch 7 | Step 2670 | loss: 0.3849539178467933 | accuracy: 0.828062996031746 \n",
      "Epoch 7 | Step 2671 | loss: 0.38481952079199994 | accuracy: 0.8283102766798419 \n",
      "Epoch 7 | Step 2672 | loss: 0.3848022947630545 | accuracy: 0.828371062992126 \n",
      "Epoch 7 | Step 2673 | loss: 0.38468752631954123 | accuracy: 0.8285539215686275 \n",
      "Epoch 7 | Step 2674 | loss: 0.3846897943876684 | accuracy: 0.8284912109375 \n",
      "Epoch 7 | Step 2675 | loss: 0.38450340967234015 | accuracy: 0.8285505836575876 \n",
      "Epoch 7 | Step 2676 | loss: 0.3841666504163151 | accuracy: 0.8286700581395349 \n",
      "Epoch 7 | Step 2677 | loss: 0.3842318391707874 | accuracy: 0.8287282818532818 \n",
      "Epoch 7 | Step 2678 | loss: 0.3839759909189665 | accuracy: 0.8287860576923077 \n",
      "Epoch 7 | Step 2679 | loss: 0.38443653405397793 | accuracy: 0.8283644636015326 \n",
      "Epoch 7 | Step 2680 | loss: 0.38464943916743044 | accuracy: 0.828125 \n",
      "Epoch 7 | Step 2681 | loss: 0.38442774111327116 | accuracy: 0.8283032319391636 \n",
      "Epoch 7 | Step 2682 | loss: 0.3847983027949478 | accuracy: 0.8283025568181819 \n",
      "Epoch 7 | Step 2683 | loss: 0.38471693891399317 | accuracy: 0.8284787735849057 \n",
      "Epoch 7 | Step 2684 | loss: 0.3843248688188711 | accuracy: 0.8285949248120302 \n",
      "Epoch 7 | Step 2685 | loss: 0.3841274276878057 | accuracy: 0.8285931647940076 \n",
      "Epoch 7 | Step 2686 | loss: 0.3842121161409279 | accuracy: 0.8285331156716419 \n",
      "Epoch 7 | Step 2687 | loss: 0.384225164204282 | accuracy: 0.8286477695167287 \n",
      "Epoch 7 | Step 2688 | loss: 0.38421338829729296 | accuracy: 0.8287037037037038 \n",
      "Epoch 7 | Step 2689 | loss: 0.3843662802583618 | accuracy: 0.8287015682656828 \n",
      "Epoch 7 | Step 2690 | loss: 0.38433682819937964 | accuracy: 0.8286994485294119 \n",
      "Epoch 7 | Step 2691 | loss: 0.3843052906867786 | accuracy: 0.8286973443223444 \n",
      "Epoch 7 | Step 2692 | loss: 0.38417028934851183 | accuracy: 0.8286952554744527 \n",
      "Epoch 7 | Step 2693 | loss: 0.38401012995026335 | accuracy: 0.8287500000000001 \n",
      "Epoch 7 | Step 2694 | loss: 0.38406971669283474 | accuracy: 0.8286345108695653 \n",
      "Epoch 7 | Step 2695 | loss: 0.3838732114552592 | accuracy: 0.8286890794223828 \n",
      "Epoch 7 | Step 2696 | loss: 0.38366259613054277 | accuracy: 0.8289118705035973 \n",
      "Epoch 7 | Step 2697 | loss: 0.38387867359704886 | accuracy: 0.8288530465949822 \n",
      "Epoch 7 | Step 2698 | loss: 0.383619992967163 | accuracy: 0.8289620535714287 \n",
      "Epoch 7 | Step 2699 | loss: 0.38385972476090413 | accuracy: 0.828792259786477 \n",
      "Epoch 7 | Step 2700 | loss: 0.38370665337177046 | accuracy: 0.8287898936170214 \n",
      "Epoch 7 | Step 2701 | loss: 0.3838048357213766 | accuracy: 0.8287323321554771 \n",
      "Epoch 7 | Step 2702 | loss: 0.3837014558449598 | accuracy: 0.8287852112676057 \n",
      "Epoch 7 | Step 2703 | loss: 0.3836118401142589 | accuracy: 0.8288377192982457 \n",
      "Epoch 7 | Step 2704 | loss: 0.38371441831121916 | accuracy: 0.8288352272727274 \n",
      "Epoch 7 | Step 2705 | loss: 0.3834072812509039 | accuracy: 0.8288327526132405 \n",
      "Epoch 7 | Step 2706 | loss: 0.38325252570211893 | accuracy: 0.8288845486111112 \n",
      "Epoch 7 | Step 2707 | loss: 0.38305242808219886 | accuracy: 0.8289359861591695 \n",
      "Epoch 7 | Step 2708 | loss: 0.38336589603588506 | accuracy: 0.8288793103448275 \n",
      "Epoch 7 | Step 2709 | loss: 0.38313850074289596 | accuracy: 0.8289841065292095 \n",
      "Epoch 7 | Step 2710 | loss: 0.3829007995863484 | accuracy: 0.8291416952054793 \n",
      "Epoch 7 | Step 2711 | loss: 0.38264309190239115 | accuracy: 0.8294048634812285 \n",
      "Epoch 7 | Step 2712 | loss: 0.38221684726728067 | accuracy: 0.8296662414965985 \n",
      "Epoch 7 | Step 2713 | loss: 0.3827936208854288 | accuracy: 0.8294491525423728 \n",
      "Epoch 7 | Step 2714 | loss: 0.38259622585531833 | accuracy: 0.8295502533783784 \n",
      "Epoch 7 | Step 2715 | loss: 0.38280123391938137 | accuracy: 0.8294402356902357 \n",
      "Epoch 7 | Step 2716 | loss: 0.38264918007306614 | accuracy: 0.8296455536912751 \n",
      "Epoch 7 | Step 2717 | loss: 0.3824597727694241 | accuracy: 0.8297449832775919 \n",
      "Epoch 7 | Step 2718 | loss: 0.3822170940041543 | accuracy: 0.82984375 \n",
      "Epoch 7 | Step 2719 | loss: 0.38204586802923013 | accuracy: 0.8300456810631229 \n",
      "Epoch 7 | Step 2720 | loss: 0.3820871049599932 | accuracy: 0.8300910596026491 \n",
      "Epoch 7 | Step 2721 | loss: 0.3818028522009897 | accuracy: 0.8301361386138615 \n",
      "Epoch 7 | Step 2722 | loss: 0.3816504929410784 | accuracy: 0.8302323190789475 \n",
      "Epoch 7 | Step 2723 | loss: 0.3821142499564124 | accuracy: 0.829969262295082 \n",
      "Epoch 7 | Step 2724 | loss: 0.3817805153092528 | accuracy: 0.8302185457516341 \n",
      "Epoch 7 | Step 2725 | loss: 0.38160377090451 | accuracy: 0.8304153094462542 \n",
      "Epoch 7 | Step 2726 | loss: 0.38134892584828595 | accuracy: 0.8305600649350651 \n",
      "Epoch 7 | Step 2727 | loss: 0.3808254882645068 | accuracy: 0.830906148867314 \n",
      "Epoch 7 | Step 2728 | loss: 0.38057845393496187 | accuracy: 0.8310987903225806 \n",
      "Epoch 7 | Step 2729 | loss: 0.38050610943430885 | accuracy: 0.8311897106109325 \n",
      "Epoch 7 | Step 2730 | loss: 0.3804965819208287 | accuracy: 0.8309795673076923 \n",
      "Epoch 7 | Step 2731 | loss: 0.38042436521083794 | accuracy: 0.8309205271565495 \n",
      "Epoch 7 | Step 2732 | loss: 0.38026763047951817 | accuracy: 0.8310609076433121 \n",
      "Epoch 7 | Step 2733 | loss: 0.3797983406555086 | accuracy: 0.8313492063492064 \n",
      "Epoch 7 | Step 2734 | loss: 0.37992302172734776 | accuracy: 0.831190664556962 \n",
      "Epoch 7 | Step 2735 | loss: 0.37999309082324584 | accuracy: 0.8311809936908517 \n",
      "Epoch 7 | Step 2736 | loss: 0.37999230403007966 | accuracy: 0.8312696540880503 \n",
      "Epoch 7 | Step 2737 | loss: 0.3798771630914235 | accuracy: 0.8312597962382445 \n",
      "Epoch 7 | Step 2738 | loss: 0.37968861921690417 | accuracy: 0.83154296875 \n",
      "Epoch 7 | Step 2739 | loss: 0.3796349094942724 | accuracy: 0.8316296728971962 \n",
      "Epoch 7 | Step 2740 | loss: 0.37947465465490876 | accuracy: 0.8318614130434783 \n",
      "Epoch 7 | Step 2741 | loss: 0.3794722392370828 | accuracy: 0.8318498452012384 \n",
      "Epoch 7 | Step 2742 | loss: 0.3793158550045374 | accuracy: 0.8317418981481481 \n",
      "Epoch 7 | Step 2743 | loss: 0.3792408360426244 | accuracy: 0.8316346153846154 \n",
      "Epoch 7 | Step 2744 | loss: 0.37949907235755526 | accuracy: 0.831336273006135 \n",
      "Epoch 7 | Step 2745 | loss: 0.37964718818482285 | accuracy: 0.8311353211009175 \n",
      "Epoch 7 | Step 2746 | loss: 0.37950190115810906 | accuracy: 0.8313643292682927 \n",
      "Epoch 7 | Step 2747 | loss: 0.3793867520738881 | accuracy: 0.831544452887538 \n",
      "Epoch 7 | Step 2748 | loss: 0.379445182870735 | accuracy: 0.8314867424242425 \n",
      "Epoch 7 | Step 2749 | loss: 0.3793002431396273 | accuracy: 0.8316182024169184 \n",
      "Epoch 7 | Step 2750 | loss: 0.3792951453970859 | accuracy: 0.8315135542168675 \n",
      "Epoch 7 | Step 2751 | loss: 0.37921141204354303 | accuracy: 0.8315033783783784 \n",
      "Epoch 7 | Step 2752 | loss: 0.3790604685862623 | accuracy: 0.8316336077844312 \n",
      "Epoch 7 | Step 2753 | loss: 0.3792139898930025 | accuracy: 0.8314365671641791 \n",
      "Epoch 7 | Step 2754 | loss: 0.3791441038871807 | accuracy: 0.8314267113095238 \n",
      "Epoch 7 | Step 2755 | loss: 0.3791622945303735 | accuracy: 0.8313241839762612 \n",
      "Epoch 7 | Step 2756 | loss: 0.37890628213889516 | accuracy: 0.8315920857988166 \n",
      "Epoch 7 | Step 2757 | loss: 0.3787813790164516 | accuracy: 0.8317201327433629 \n",
      "Epoch 7 | Step 2758 | loss: 0.3788441431434717 | accuracy: 0.8317095588235294 \n",
      "Epoch 7 | Step 2759 | loss: 0.3788333079419879 | accuracy: 0.8316990469208211 \n",
      "Epoch 7 | Step 2760 | loss: 0.37877990492777536 | accuracy: 0.831734283625731 \n",
      "Epoch 7 | Step 2761 | loss: 0.3784492247393112 | accuracy: 0.8317693148688047 \n",
      "Epoch 7 | Step 2762 | loss: 0.3785944872557426 | accuracy: 0.8317132994186046 \n",
      "Epoch 7 | Step 2763 | loss: 0.378272866814033 | accuracy: 0.8318840579710145 \n",
      "Epoch 7 | Step 2764 | loss: 0.3781210069969901 | accuracy: 0.8320538294797688 \n",
      "Epoch 7 | Step 2765 | loss: 0.3779885662821598 | accuracy: 0.8322226224783862 \n",
      "Epoch 7 | Step 2766 | loss: 0.3778871494377483 | accuracy: 0.8322557471264368 \n",
      "Epoch 7 | Step 2767 | loss: 0.37776601361511103 | accuracy: 0.8321991404011462 \n",
      "Epoch 7 | Step 2768 | loss: 0.3780534932868823 | accuracy: 0.8319642857142857 \n",
      "Epoch 7 | Step 2769 | loss: 0.3776894865127712 | accuracy: 0.8321759259259259 \n",
      "Epoch 7 | Step 2770 | loss: 0.3776093712499875 | accuracy: 0.8321200284090909 \n",
      "Epoch 7 | Step 2771 | loss: 0.37756726394800577 | accuracy: 0.8321087110481586 \n",
      "Epoch 7 | Step 2772 | loss: 0.3777640908535593 | accuracy: 0.8319650423728814 \n",
      "Epoch 7 | Step 2773 | loss: 0.37756131807683235 | accuracy: 0.8320862676056338 \n",
      "Epoch 7 | Step 2774 | loss: 0.3772009571365428 | accuracy: 0.8322068117977528 \n",
      "Epoch 7 | Step 2775 | loss: 0.37741402471933727 | accuracy: 0.8320640756302521 \n",
      "Epoch 7 | Step 2776 | loss: 0.3777454318530734 | accuracy: 0.8318784916201117 \n",
      "Epoch 7 | Step 2777 | loss: 0.377492966799683 | accuracy: 0.8320856545961003 \n",
      "Epoch 7 | Step 2778 | loss: 0.3778457648638224 | accuracy: 0.8319444444444445 \n",
      "Epoch 7 | Step 2779 | loss: 0.37779926556134175 | accuracy: 0.831847299168975 \n",
      "Epoch 7 | Step 2780 | loss: 0.37761442663755224 | accuracy: 0.8319665055248618 \n",
      "Epoch 7 | Step 2781 | loss: 0.3776842255155575 | accuracy: 0.8319128787878788 \n",
      "Epoch 7 | Step 2782 | loss: 0.3772108407056595 | accuracy: 0.8322458791208791 \n",
      "Epoch 7 | Step 2783 | loss: 0.37697645642169547 | accuracy: 0.8323630136986301 \n",
      "Epoch 7 | Step 2784 | loss: 0.37697794149970765 | accuracy: 0.8324368169398907 \n",
      "Epoch 7 | Step 2785 | loss: 0.3771924850320298 | accuracy: 0.8322973433242506 \n",
      "Epoch 7 | Step 2786 | loss: 0.37694881358386395 | accuracy: 0.832413383152174 \n",
      "Epoch 7 | Step 2787 | loss: 0.3769795823953341 | accuracy: 0.8324441056910569 \n",
      "Epoch 7 | Step 2788 | loss: 0.37695432623495945 | accuracy: 0.8324324324324325 \n",
      "Epoch 7 | Step 2789 | loss: 0.37707588980300744 | accuracy: 0.832252358490566 \n",
      "Epoch 7 | Step 2790 | loss: 0.3769812037146862 | accuracy: 0.8323252688172043 \n",
      "Epoch 7 | Step 2791 | loss: 0.3765332018482143 | accuracy: 0.832691018766756 \n",
      "Epoch 7 | Step 2792 | loss: 0.3763587652122912 | accuracy: 0.8326788101604278 \n",
      "Epoch 7 | Step 2793 | loss: 0.3764888462622962 | accuracy: 0.8325416666666666 \n",
      "Epoch 7 | Step 2794 | loss: 0.37654666971177514 | accuracy: 0.832529920212766 \n",
      "Epoch 7 | Step 2795 | loss: 0.376543502157816 | accuracy: 0.8324767904509284 \n",
      "Epoch 7 | Step 2796 | loss: 0.3766219986888468 | accuracy: 0.8322999338624338 \n",
      "Epoch 7 | Step 2797 | loss: 0.37639418287610643 | accuracy: 0.8323713720316622 \n",
      "Epoch 7 | Step 2798 | loss: 0.37626374932496187 | accuracy: 0.832360197368421 \n",
      "Epoch 7 | Step 2799 | loss: 0.37595880497002554 | accuracy: 0.832636154855643 \n",
      "Epoch 7 | Step 2800 | loss: 0.3761303930772538 | accuracy: 0.8326243455497382 \n",
      "Epoch 7 | Step 2801 | loss: 0.3762295961613445 | accuracy: 0.8326533942558747 \n",
      "Epoch 7 | Step 2802 | loss: 0.37641819865287607 | accuracy: 0.8325602213541666 \n",
      "Epoch 7 | Step 2803 | loss: 0.3764267642389646 | accuracy: 0.8326298701298701 \n",
      "Epoch 7 | Step 2804 | loss: 0.3764200529054658 | accuracy: 0.8326181994818653 \n",
      "Epoch 7 | Step 2805 | loss: 0.37646463524925633 | accuracy: 0.8326469638242894 \n",
      "Epoch 7 | Step 2806 | loss: 0.3764996840858584 | accuracy: 0.8327158505154639 \n",
      "Epoch 7 | Step 2807 | loss: 0.3765907705519685 | accuracy: 0.8325835475578406 \n",
      "Epoch 7 | Step 2808 | loss: 0.37658001998296164 | accuracy: 0.8326522435897435 \n",
      "Epoch 7 | Step 2809 | loss: 0.37651325533609575 | accuracy: 0.8326806265984654 \n",
      "Epoch 7 | Step 2810 | loss: 0.37646131753465367 | accuracy: 0.8326690051020408 \n",
      "Epoch 7 | Step 2811 | loss: 0.37623372419948203 | accuracy: 0.832816475826972 \n",
      "Epoch 7 | Step 2812 | loss: 0.37650099710613355 | accuracy: 0.8326459390862944 \n",
      "Epoch 7 | Step 2813 | loss: 0.37627221500571784 | accuracy: 0.832753164556962 \n",
      "Epoch 7 | Step 2814 | loss: 0.37609744956246544 | accuracy: 0.8328993055555556 \n",
      "Epoch 7 | Step 2815 | loss: 0.3759987365163545 | accuracy: 0.8330053526448362 \n",
      "Epoch 7 | Step 2816 | loss: 0.3760656404060935 | accuracy: 0.8329145728643216 \n",
      "Epoch 7 | Step 2817 | loss: 0.37591510760903674 | accuracy: 0.8329417293233082 \n",
      "Epoch 7 | Step 2818 | loss: 0.3758219104632737 | accuracy: 0.8329296875 \n",
      "Epoch 7 | Step 2819 | loss: 0.375973140992726 | accuracy: 0.8329566708229427 \n",
      "Epoch 7 | Step 2820 | loss: 0.37596366717595975 | accuracy: 0.8330223880597015 \n",
      "Epoch 7 | Step 2821 | loss: 0.3758170065232011 | accuracy: 0.8330944638985854 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.5057186484336853 | accuracy: 0.75 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4427361637353897 | accuracy: 0.8125 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4733323355515798 | accuracy: 0.8125 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4682556465268135 | accuracy: 0.79296875 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4352410316467285 | accuracy: 0.815625 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4547987182935079 | accuracy: 0.7994791666666666 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4500556801046644 | accuracy: 0.796875 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.44337835907936096 | accuracy: 0.802734375 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4569043583340115 | accuracy: 0.8020833333333334 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.44551033079624175 | accuracy: 0.8078125 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4429304003715515 | accuracy: 0.8082386363636364 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4353044430414836 | accuracy: 0.8111979166666666 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.43416006289995634 | accuracy: 0.8100961538461539 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4291556009224483 | accuracy: 0.8113839285714286 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.43053592840830485 | accuracy: 0.8125 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4315446149557829 | accuracy: 0.8125 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4403584757271935 | accuracy: 0.8079044117647058 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.44156576858626473 | accuracy: 0.8072916666666666 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.43807417624875117 | accuracy: 0.8092105263157895 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4355290964245796 | accuracy: 0.80703125 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.43040130393845694 | accuracy: 0.8080357142857143 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.42591079527681525 | accuracy: 0.8117897727272727 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4307161440020022 | accuracy: 0.8070652173913043 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.44285953293244046 | accuracy: 0.8014322916666666 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4470502352714539 | accuracy: 0.799375 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.44403533981396603 | accuracy: 0.8004807692307693 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.43967104068508855 | accuracy: 0.8026620370370371 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4379188322595188 | accuracy: 0.8035714285714286 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.43457114182669543 | accuracy: 0.8060344827586207 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4325972020626068 | accuracy: 0.8078125 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.42768078177205976 | accuracy: 0.8109879032258065 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4315467355772853 | accuracy: 0.8076171875 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4329832241390691 | accuracy: 0.806344696969697 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4372880695497288 | accuracy: 0.8023897058823529 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4385238638945988 | accuracy: 0.8022321428571428 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4364438677827517 | accuracy: 0.8033854166666666 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4379301562502578 | accuracy: 0.8032094594594594 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.43874727973812505 | accuracy: 0.803453947368421 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.43838130510770357 | accuracy: 0.8036858974358975 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4361149035394192 | accuracy: 0.80546875 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.43439390165049857 | accuracy: 0.805640243902439 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.43223864762555986 | accuracy: 0.8058035714285714 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.43328397980956146 | accuracy: 0.8052325581395349 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.43617762151089584 | accuracy: 0.8032670454545454 \n",
      "Validation | Epoch 7 | Step 2821 | loss: 0.4354075226518843 | accuracy: 0.8032910625139872 \n",
      "Epoch 8 | Step 2822 | loss: 0.4601762890815735 | accuracy: 0.796875 \n",
      "Epoch 8 | Step 2823 | loss: 0.35301097482442856 | accuracy: 0.859375 \n",
      "Epoch 8 | Step 2824 | loss: 0.3568122237920761 | accuracy: 0.8541666666666666 \n",
      "Epoch 8 | Step 2825 | loss: 0.36333344504237175 | accuracy: 0.859375 \n",
      "Epoch 8 | Step 2826 | loss: 0.3438595324754715 | accuracy: 0.86875 \n",
      "Epoch 8 | Step 2827 | loss: 0.34106189757585526 | accuracy: 0.8697916666666666 \n",
      "Epoch 8 | Step 2828 | loss: 0.34213609993457794 | accuracy: 0.8638392857142857 \n",
      "Epoch 8 | Step 2829 | loss: 0.3429920841008425 | accuracy: 0.86328125 \n",
      "Epoch 8 | Step 2830 | loss: 0.3491056975391176 | accuracy: 0.8576388888888888 \n",
      "Epoch 8 | Step 2831 | loss: 0.35979143530130386 | accuracy: 0.853125 \n",
      "Epoch 8 | Step 2832 | loss: 0.3492736125534231 | accuracy: 0.8607954545454546 \n",
      "Epoch 8 | Step 2833 | loss: 0.3464994641641776 | accuracy: 0.8619791666666666 \n",
      "Epoch 8 | Step 2834 | loss: 0.358758895443036 | accuracy: 0.8533653846153846 \n",
      "Epoch 8 | Step 2835 | loss: 0.3547076465828078 | accuracy: 0.8560267857142857 \n",
      "Epoch 8 | Step 2836 | loss: 0.354906897743543 | accuracy: 0.8541666666666666 \n",
      "Epoch 8 | Step 2837 | loss: 0.3486320832744241 | accuracy: 0.85546875 \n",
      "Epoch 8 | Step 2838 | loss: 0.3515264488318387 | accuracy: 0.8483455882352942 \n",
      "Epoch 8 | Step 2839 | loss: 0.3507901190055741 | accuracy: 0.8489583333333334 \n",
      "Epoch 8 | Step 2840 | loss: 0.3507991299817437 | accuracy: 0.8478618421052632 \n",
      "Epoch 8 | Step 2841 | loss: 0.3531646139919758 | accuracy: 0.8484375 \n",
      "Epoch 8 | Step 2842 | loss: 0.3558472870361237 | accuracy: 0.8459821428571429 \n",
      "Epoch 8 | Step 2843 | loss: 0.35816244984214957 | accuracy: 0.84375 \n",
      "Epoch 8 | Step 2844 | loss: 0.3569256060797235 | accuracy: 0.845108695652174 \n",
      "Epoch 8 | Step 2845 | loss: 0.3587850822756688 | accuracy: 0.8430989583333334 \n",
      "Epoch 8 | Step 2846 | loss: 0.36284317791461945 | accuracy: 0.84125 \n",
      "Epoch 8 | Step 2847 | loss: 0.36492157498231304 | accuracy: 0.8413461538461539 \n",
      "Epoch 8 | Step 2848 | loss: 0.3669438455943708 | accuracy: 0.8402777777777778 \n",
      "Epoch 8 | Step 2849 | loss: 0.36564880343420164 | accuracy: 0.8415178571428571 \n",
      "Epoch 8 | Step 2850 | loss: 0.36724953661704884 | accuracy: 0.8426724137931034 \n",
      "Epoch 8 | Step 2851 | loss: 0.36833554953336717 | accuracy: 0.8411458333333334 \n",
      "Epoch 8 | Step 2852 | loss: 0.36726212934140234 | accuracy: 0.8412298387096774 \n",
      "Epoch 8 | Step 2853 | loss: 0.36699825758114457 | accuracy: 0.84130859375 \n",
      "Epoch 8 | Step 2854 | loss: 0.36732201368519757 | accuracy: 0.8413825757575758 \n",
      "Epoch 8 | Step 2855 | loss: 0.36406494808547635 | accuracy: 0.8428308823529411 \n",
      "Epoch 8 | Step 2856 | loss: 0.36081372797489164 | accuracy: 0.8446428571428571 \n",
      "Epoch 8 | Step 2857 | loss: 0.36005719792511726 | accuracy: 0.84375 \n",
      "Epoch 8 | Step 2858 | loss: 0.36050672829151154 | accuracy: 0.8441722972972973 \n",
      "Epoch 8 | Step 2859 | loss: 0.36231502616091776 | accuracy: 0.8421052631578947 \n",
      "Epoch 8 | Step 2860 | loss: 0.3609370577793855 | accuracy: 0.84375 \n",
      "Epoch 8 | Step 2861 | loss: 0.35890529565513135 | accuracy: 0.84375 \n",
      "Epoch 8 | Step 2862 | loss: 0.35963750285346335 | accuracy: 0.8433689024390244 \n",
      "Epoch 8 | Step 2863 | loss: 0.36051492144664127 | accuracy: 0.8422619047619048 \n",
      "Epoch 8 | Step 2864 | loss: 0.3592371195554733 | accuracy: 0.842296511627907 \n",
      "Epoch 8 | Step 2865 | loss: 0.357211999933828 | accuracy: 0.84375 \n",
      "Epoch 8 | Step 2866 | loss: 0.35715848439269593 | accuracy: 0.8454861111111112 \n",
      "Epoch 8 | Step 2867 | loss: 0.35733821437410684 | accuracy: 0.8454483695652174 \n",
      "Epoch 8 | Step 2868 | loss: 0.3586647310789595 | accuracy: 0.8440824468085106 \n",
      "Epoch 8 | Step 2869 | loss: 0.35951520781964064 | accuracy: 0.8424479166666666 \n",
      "Epoch 8 | Step 2870 | loss: 0.3625037806982897 | accuracy: 0.8415178571428571 \n",
      "Epoch 8 | Step 2871 | loss: 0.36384168356657026 | accuracy: 0.8403125 \n",
      "Epoch 8 | Step 2872 | loss: 0.36292245545808005 | accuracy: 0.8409926470588235 \n",
      "Epoch 8 | Step 2873 | loss: 0.3617833935870574 | accuracy: 0.8416466346153846 \n",
      "Epoch 8 | Step 2874 | loss: 0.36265973184468614 | accuracy: 0.8399174528301887 \n",
      "Epoch 8 | Step 2875 | loss: 0.3623671374387211 | accuracy: 0.8405671296296297 \n",
      "Epoch 8 | Step 2876 | loss: 0.3624735330993479 | accuracy: 0.8403409090909091 \n",
      "Epoch 8 | Step 2877 | loss: 0.3619462829083204 | accuracy: 0.8409598214285714 \n",
      "Epoch 8 | Step 2878 | loss: 0.36274840408249903 | accuracy: 0.840734649122807 \n",
      "Epoch 8 | Step 2879 | loss: 0.3627141423780343 | accuracy: 0.8407866379310345 \n",
      "Epoch 8 | Step 2880 | loss: 0.36477748089927736 | accuracy: 0.840572033898305 \n",
      "Epoch 8 | Step 2881 | loss: 0.3644242284198602 | accuracy: 0.840625 \n",
      "Epoch 8 | Step 2882 | loss: 0.3635833842343971 | accuracy: 0.8419569672131147 \n",
      "Epoch 8 | Step 2883 | loss: 0.362439225998617 | accuracy: 0.842741935483871 \n",
      "Epoch 8 | Step 2884 | loss: 0.363856379238386 | accuracy: 0.8425099206349206 \n",
      "Epoch 8 | Step 2885 | loss: 0.3623289775568992 | accuracy: 0.84326171875 \n",
      "Epoch 8 | Step 2886 | loss: 0.3613661827949377 | accuracy: 0.84375 \n",
      "Epoch 8 | Step 2887 | loss: 0.3600845357233828 | accuracy: 0.8442234848484849 \n",
      "Epoch 8 | Step 2888 | loss: 0.3586119375566938 | accuracy: 0.8449160447761194 \n",
      "Epoch 8 | Step 2889 | loss: 0.35899153461351113 | accuracy: 0.8448988970588235 \n",
      "Epoch 8 | Step 2890 | loss: 0.36029132487981214 | accuracy: 0.8442028985507246 \n",
      "Epoch 8 | Step 2891 | loss: 0.3592130927102906 | accuracy: 0.8446428571428571 \n",
      "Epoch 8 | Step 2892 | loss: 0.3582052237970728 | accuracy: 0.8452904929577465 \n",
      "Epoch 8 | Step 2893 | loss: 0.357494421924154 | accuracy: 0.8454861111111112 \n",
      "Epoch 8 | Step 2894 | loss: 0.3570904705214174 | accuracy: 0.8458904109589042 \n",
      "Epoch 8 | Step 2895 | loss: 0.3565677394335334 | accuracy: 0.8458614864864866 \n",
      "Epoch 8 | Step 2896 | loss: 0.3567311495542526 | accuracy: 0.8447916666666667 \n",
      "Epoch 8 | Step 2897 | loss: 0.356194675949059 | accuracy: 0.844983552631579 \n",
      "Epoch 8 | Step 2898 | loss: 0.3554890196431767 | accuracy: 0.8449675324675324 \n",
      "Epoch 8 | Step 2899 | loss: 0.35613328008315503 | accuracy: 0.8449519230769231 \n",
      "Epoch 8 | Step 2900 | loss: 0.3576985957879054 | accuracy: 0.84375 \n",
      "Epoch 8 | Step 2901 | loss: 0.35788611788302654 | accuracy: 0.84375 \n",
      "Epoch 8 | Step 2902 | loss: 0.35704836046990046 | accuracy: 0.8439429012345679 \n",
      "Epoch 8 | Step 2903 | loss: 0.3568502186638552 | accuracy: 0.8433689024390244 \n",
      "Epoch 8 | Step 2904 | loss: 0.3571144516568585 | accuracy: 0.8435617469879518 \n",
      "Epoch 8 | Step 2905 | loss: 0.3568100342083544 | accuracy: 0.84375 \n",
      "Epoch 8 | Step 2906 | loss: 0.3561087462831945 | accuracy: 0.8439338235294118 \n",
      "Epoch 8 | Step 2907 | loss: 0.3562003899105759 | accuracy: 0.8435683139534884 \n",
      "Epoch 8 | Step 2908 | loss: 0.3583643571741279 | accuracy: 0.8423132183908046 \n",
      "Epoch 8 | Step 2909 | loss: 0.3581424309787425 | accuracy: 0.8426846590909091 \n",
      "Epoch 8 | Step 2910 | loss: 0.35743031290809757 | accuracy: 0.8432233146067416 \n",
      "Epoch 8 | Step 2911 | loss: 0.35837346331940756 | accuracy: 0.8432291666666667 \n",
      "Epoch 8 | Step 2912 | loss: 0.3573673365862815 | accuracy: 0.8439217032967034 \n",
      "Epoch 8 | Step 2913 | loss: 0.3563465195829454 | accuracy: 0.8444293478260869 \n",
      "Epoch 8 | Step 2914 | loss: 0.356149618824323 | accuracy: 0.8445900537634409 \n",
      "Epoch 8 | Step 2915 | loss: 0.3558150198548398 | accuracy: 0.8444148936170213 \n",
      "Epoch 8 | Step 2916 | loss: 0.3563592084144291 | accuracy: 0.8445723684210527 \n",
      "Epoch 8 | Step 2917 | loss: 0.3581548371973137 | accuracy: 0.8439127604166666 \n",
      "Epoch 8 | Step 2918 | loss: 0.35857580202756467 | accuracy: 0.84375 \n",
      "Epoch 8 | Step 2919 | loss: 0.3593323691462984 | accuracy: 0.8434311224489796 \n",
      "Epoch 8 | Step 2920 | loss: 0.35894235501987765 | accuracy: 0.84375 \n",
      "Epoch 8 | Step 2921 | loss: 0.35805893912911413 | accuracy: 0.84421875 \n",
      "Epoch 8 | Step 2922 | loss: 0.3565153066474612 | accuracy: 0.8448329207920792 \n",
      "Epoch 8 | Step 2923 | loss: 0.3565397423272039 | accuracy: 0.8448223039215687 \n",
      "Epoch 8 | Step 2924 | loss: 0.3558818145284375 | accuracy: 0.8454186893203883 \n",
      "Epoch 8 | Step 2925 | loss: 0.35667803425055283 | accuracy: 0.8452524038461539 \n",
      "Epoch 8 | Step 2926 | loss: 0.3576207634948549 | accuracy: 0.8444940476190477 \n",
      "Epoch 8 | Step 2927 | loss: 0.3572542279396417 | accuracy: 0.8443396226415094 \n",
      "Epoch 8 | Step 2928 | loss: 0.35807512909452494 | accuracy: 0.8441880841121495 \n",
      "Epoch 8 | Step 2929 | loss: 0.3593325874319783 | accuracy: 0.8433159722222222 \n",
      "Epoch 8 | Step 2930 | loss: 0.35951349521995685 | accuracy: 0.8431766055045872 \n",
      "Epoch 8 | Step 2931 | loss: 0.3597750371152704 | accuracy: 0.8430397727272727 \n",
      "Epoch 8 | Step 2932 | loss: 0.3591585658692025 | accuracy: 0.8431869369369369 \n",
      "Epoch 8 | Step 2933 | loss: 0.35887481245611397 | accuracy: 0.8436104910714286 \n",
      "Epoch 8 | Step 2934 | loss: 0.35991409130856 | accuracy: 0.8433351769911505 \n",
      "Epoch 8 | Step 2935 | loss: 0.36099520351803094 | accuracy: 0.8432017543859649 \n",
      "Epoch 8 | Step 2936 | loss: 0.36101196019545845 | accuracy: 0.8429347826086957 \n",
      "Epoch 8 | Step 2937 | loss: 0.3608776356639533 | accuracy: 0.8430765086206896 \n",
      "Epoch 8 | Step 2938 | loss: 0.3615923641074417 | accuracy: 0.8428151709401709 \n",
      "Epoch 8 | Step 2939 | loss: 0.3619448767375138 | accuracy: 0.8426906779661016 \n",
      "Epoch 8 | Step 2940 | loss: 0.36184011637663643 | accuracy: 0.8429621848739496 \n",
      "Epoch 8 | Step 2941 | loss: 0.36139481887221336 | accuracy: 0.8434895833333333 \n",
      "Epoch 8 | Step 2942 | loss: 0.3611442922068036 | accuracy: 0.8433626033057852 \n",
      "Epoch 8 | Step 2943 | loss: 0.36117700792726926 | accuracy: 0.843109631147541 \n",
      "Epoch 8 | Step 2944 | loss: 0.3611730308067508 | accuracy: 0.8428607723577236 \n",
      "Epoch 8 | Step 2945 | loss: 0.36132726553947697 | accuracy: 0.8428679435483871 \n",
      "Epoch 8 | Step 2946 | loss: 0.36158349442481996 | accuracy: 0.84275 \n",
      "Epoch 8 | Step 2947 | loss: 0.36130054176799836 | accuracy: 0.8428819444444444 \n",
      "Epoch 8 | Step 2948 | loss: 0.3613474303343165 | accuracy: 0.843011811023622 \n",
      "Epoch 8 | Step 2949 | loss: 0.36078830785118043 | accuracy: 0.843017578125 \n",
      "Epoch 8 | Step 2950 | loss: 0.3605463012706402 | accuracy: 0.8430232558139535 \n",
      "Epoch 8 | Step 2951 | loss: 0.35998976138921884 | accuracy: 0.8433894230769231 \n",
      "Epoch 8 | Step 2952 | loss: 0.36065237189977223 | accuracy: 0.8430343511450382 \n",
      "Epoch 8 | Step 2953 | loss: 0.3614123045946612 | accuracy: 0.8426846590909091 \n",
      "Epoch 8 | Step 2954 | loss: 0.362350026467689 | accuracy: 0.8419877819548872 \n",
      "Epoch 8 | Step 2955 | loss: 0.36286891529809184 | accuracy: 0.8413013059701493 \n",
      "Epoch 8 | Step 2956 | loss: 0.36295646053773384 | accuracy: 0.841550925925926 \n",
      "Epoch 8 | Step 2957 | loss: 0.3625987246632576 | accuracy: 0.8419117647058824 \n",
      "Epoch 8 | Step 2958 | loss: 0.3620371135481953 | accuracy: 0.8421532846715328 \n",
      "Epoch 8 | Step 2959 | loss: 0.36169635688049206 | accuracy: 0.8420516304347826 \n",
      "Epoch 8 | Step 2960 | loss: 0.3623072983120843 | accuracy: 0.8416142086330936 \n",
      "Epoch 8 | Step 2961 | loss: 0.3624762971486364 | accuracy: 0.8416294642857143 \n",
      "Epoch 8 | Step 2962 | loss: 0.3634074757285152 | accuracy: 0.8410904255319149 \n",
      "Epoch 8 | Step 2963 | loss: 0.3635134890045918 | accuracy: 0.8408890845070423 \n",
      "Epoch 8 | Step 2964 | loss: 0.3639353615837497 | accuracy: 0.8405812937062938 \n",
      "Epoch 8 | Step 2965 | loss: 0.3641966233650843 | accuracy: 0.8401692708333334 \n",
      "Epoch 8 | Step 2966 | loss: 0.3640371115043245 | accuracy: 0.840301724137931 \n",
      "Epoch 8 | Step 2967 | loss: 0.364051559812402 | accuracy: 0.8403253424657534 \n",
      "Epoch 8 | Step 2968 | loss: 0.3632938961187998 | accuracy: 0.8409863945578231 \n",
      "Epoch 8 | Step 2969 | loss: 0.363620662004561 | accuracy: 0.8405827702702703 \n",
      "Epoch 8 | Step 2970 | loss: 0.3635355598174485 | accuracy: 0.8407088926174496 \n",
      "Epoch 8 | Step 2971 | loss: 0.363822941382726 | accuracy: 0.8409375 \n",
      "Epoch 8 | Step 2972 | loss: 0.3638625439034392 | accuracy: 0.8407491721854304 \n",
      "Epoch 8 | Step 2973 | loss: 0.3644291501688329 | accuracy: 0.8404605263157895 \n",
      "Epoch 8 | Step 2974 | loss: 0.36458386217846583 | accuracy: 0.8405841503267973 \n",
      "Epoch 8 | Step 2975 | loss: 0.36424928980988336 | accuracy: 0.841010551948052 \n",
      "Epoch 8 | Step 2976 | loss: 0.3640229855814287 | accuracy: 0.8411290322580646 \n",
      "Epoch 8 | Step 2977 | loss: 0.3631570528333003 | accuracy: 0.8416466346153846 \n",
      "Epoch 8 | Step 2978 | loss: 0.3637739818566923 | accuracy: 0.8416600318471338 \n",
      "Epoch 8 | Step 2979 | loss: 0.3641968537357788 | accuracy: 0.8416732594936709 \n",
      "Epoch 8 | Step 2980 | loss: 0.3645027109287069 | accuracy: 0.8413915094339622 \n",
      "Epoch 8 | Step 2981 | loss: 0.36498975772410625 | accuracy: 0.84111328125 \n",
      "Epoch 8 | Step 2982 | loss: 0.3651514643837946 | accuracy: 0.8409355590062112 \n",
      "Epoch 8 | Step 2983 | loss: 0.36534169978565634 | accuracy: 0.8410493827160493 \n",
      "Epoch 8 | Step 2984 | loss: 0.36578165424382025 | accuracy: 0.8403949386503068 \n",
      "Epoch 8 | Step 2985 | loss: 0.36541489002908145 | accuracy: 0.8404153963414634 \n",
      "Epoch 8 | Step 2986 | loss: 0.36501727248683113 | accuracy: 0.8409090909090909 \n",
      "Epoch 8 | Step 2987 | loss: 0.3650620779000132 | accuracy: 0.840832078313253 \n",
      "Epoch 8 | Step 2988 | loss: 0.3647336567233422 | accuracy: 0.8411302395209581 \n",
      "Epoch 8 | Step 2989 | loss: 0.3655257235680307 | accuracy: 0.8408668154761905 \n",
      "Epoch 8 | Step 2990 | loss: 0.36527337107432656 | accuracy: 0.840883875739645 \n",
      "Epoch 8 | Step 2991 | loss: 0.3644867173012564 | accuracy: 0.8415441176470588 \n",
      "Epoch 8 | Step 2992 | loss: 0.36424286707102893 | accuracy: 0.8416483918128655 \n",
      "Epoch 8 | Step 2993 | loss: 0.36406192807264093 | accuracy: 0.8417514534883721 \n",
      "Epoch 8 | Step 2994 | loss: 0.3635847535781087 | accuracy: 0.8422145953757225 \n",
      "Epoch 8 | Step 2995 | loss: 0.36344733320433503 | accuracy: 0.842492816091954 \n",
      "Epoch 8 | Step 2996 | loss: 0.3633180301530019 | accuracy: 0.8425 \n",
      "Epoch 8 | Step 2997 | loss: 0.36363209208304215 | accuracy: 0.8423295454545454 \n",
      "Epoch 8 | Step 2998 | loss: 0.36449283698184326 | accuracy: 0.841896186440678 \n",
      "Epoch 8 | Step 2999 | loss: 0.3648547091510857 | accuracy: 0.8415554775280899 \n",
      "Epoch 8 | Step 3000 | loss: 0.3651058973546799 | accuracy: 0.8413058659217877 \n",
      "Epoch 8 | Step 3001 | loss: 0.3645962867471905 | accuracy: 0.8416666666666667 \n",
      "Epoch 8 | Step 3002 | loss: 0.3649173839974797 | accuracy: 0.8411602209944752 \n",
      "Epoch 8 | Step 3003 | loss: 0.36467013139646115 | accuracy: 0.8413461538461539 \n",
      "Epoch 8 | Step 3004 | loss: 0.3639021919724718 | accuracy: 0.8417008196721312 \n",
      "Epoch 8 | Step 3005 | loss: 0.36345788285784086 | accuracy: 0.8420516304347826 \n",
      "Epoch 8 | Step 3006 | loss: 0.36312162537832504 | accuracy: 0.8423986486486487 \n",
      "Epoch 8 | Step 3007 | loss: 0.3634675218853898 | accuracy: 0.8420698924731183 \n",
      "Epoch 8 | Step 3008 | loss: 0.363890277032546 | accuracy: 0.8417446524064172 \n",
      "Epoch 8 | Step 3009 | loss: 0.3640734361524276 | accuracy: 0.8414228723404256 \n",
      "Epoch 8 | Step 3010 | loss: 0.3636596532410413 | accuracy: 0.841765873015873 \n",
      "Epoch 8 | Step 3011 | loss: 0.36423518077323297 | accuracy: 0.8415296052631579 \n",
      "Epoch 8 | Step 3012 | loss: 0.3635364071860986 | accuracy: 0.8419502617801047 \n",
      "Epoch 8 | Step 3013 | loss: 0.36307472797731544 | accuracy: 0.8423665364583334 \n",
      "Epoch 8 | Step 3014 | loss: 0.36255224612710374 | accuracy: 0.8426975388601037 \n",
      "Epoch 8 | Step 3015 | loss: 0.36249104910290103 | accuracy: 0.8427835051546392 \n",
      "Epoch 8 | Step 3016 | loss: 0.362419029076894 | accuracy: 0.8427884615384615 \n",
      "Epoch 8 | Step 3017 | loss: 0.3625765070319174 | accuracy: 0.8427933673469388 \n",
      "Epoch 8 | Step 3018 | loss: 0.362558684221984 | accuracy: 0.8427982233502538 \n",
      "Epoch 8 | Step 3019 | loss: 0.36249613731798486 | accuracy: 0.8429608585858586 \n",
      "Epoch 8 | Step 3020 | loss: 0.3622907504963514 | accuracy: 0.8433574120603015 \n",
      "Epoch 8 | Step 3021 | loss: 0.36186255827546104 | accuracy: 0.843515625 \n",
      "Epoch 8 | Step 3022 | loss: 0.36251490077569104 | accuracy: 0.8431281094527363 \n",
      "Epoch 8 | Step 3023 | loss: 0.3623251079922854 | accuracy: 0.8433632425742574 \n",
      "Epoch 8 | Step 3024 | loss: 0.3622613102931693 | accuracy: 0.843442118226601 \n",
      "Epoch 8 | Step 3025 | loss: 0.36222634595983155 | accuracy: 0.8435202205882353 \n",
      "Epoch 8 | Step 3026 | loss: 0.3624130233031946 | accuracy: 0.8432926829268292 \n",
      "Epoch 8 | Step 3027 | loss: 0.36284571090369533 | accuracy: 0.8431432038834952 \n",
      "Epoch 8 | Step 3028 | loss: 0.3635939176819749 | accuracy: 0.8429951690821256 \n",
      "Epoch 8 | Step 3029 | loss: 0.36358699102241243 | accuracy: 0.8429236778846154 \n",
      "Epoch 8 | Step 3030 | loss: 0.36347535552020266 | accuracy: 0.8427781100478469 \n",
      "Epoch 8 | Step 3031 | loss: 0.3637208688826787 | accuracy: 0.8426339285714286 \n",
      "Epoch 8 | Step 3032 | loss: 0.36399125106526764 | accuracy: 0.8425651658767772 \n",
      "Epoch 8 | Step 3033 | loss: 0.36341520223133955 | accuracy: 0.8428655660377359 \n",
      "Epoch 8 | Step 3034 | loss: 0.363049879530226 | accuracy: 0.8428697183098591 \n",
      "Epoch 8 | Step 3035 | loss: 0.36302973392689325 | accuracy: 0.8428008177570093 \n",
      "Epoch 8 | Step 3036 | loss: 0.3628768236831176 | accuracy: 0.8428052325581395 \n",
      "Epoch 8 | Step 3037 | loss: 0.36295361865173875 | accuracy: 0.8428096064814815 \n",
      "Epoch 8 | Step 3038 | loss: 0.36264730825127534 | accuracy: 0.8430299539170507 \n",
      "Epoch 8 | Step 3039 | loss: 0.3626939671438767 | accuracy: 0.8429615825688074 \n",
      "Epoch 8 | Step 3040 | loss: 0.362708572587466 | accuracy: 0.8431078767123288 \n",
      "Epoch 8 | Step 3041 | loss: 0.362639149007472 | accuracy: 0.8431818181818181 \n",
      "Epoch 8 | Step 3042 | loss: 0.3627964829292771 | accuracy: 0.8431843891402715 \n",
      "Epoch 8 | Step 3043 | loss: 0.3626343170936042 | accuracy: 0.8432573198198198 \n",
      "Epoch 8 | Step 3044 | loss: 0.36255719262120956 | accuracy: 0.8432595291479821 \n",
      "Epoch 8 | Step 3045 | loss: 0.3619279835506208 | accuracy: 0.8438197544642857 \n",
      "Epoch 8 | Step 3046 | loss: 0.3618360423379473 | accuracy: 0.8438194444444445 \n",
      "Epoch 8 | Step 3047 | loss: 0.3619514013418053 | accuracy: 0.8438882743362832 \n",
      "Epoch 8 | Step 3048 | loss: 0.36218750430886426 | accuracy: 0.8435435022026432 \n",
      "Epoch 8 | Step 3049 | loss: 0.36206583907468265 | accuracy: 0.84375 \n",
      "Epoch 8 | Step 3050 | loss: 0.36197807779738983 | accuracy: 0.8436135371179039 \n",
      "Epoch 8 | Step 3051 | loss: 0.362060030452583 | accuracy: 0.84375 \n",
      "Epoch 8 | Step 3052 | loss: 0.361520826235994 | accuracy: 0.8440882034632035 \n",
      "Epoch 8 | Step 3053 | loss: 0.3612112290514953 | accuracy: 0.8443561422413793 \n",
      "Epoch 8 | Step 3054 | loss: 0.3613299401916658 | accuracy: 0.8440853004291845 \n",
      "Epoch 8 | Step 3055 | loss: 0.36121504244386626 | accuracy: 0.8441506410256411 \n",
      "Epoch 8 | Step 3056 | loss: 0.36086776453129776 | accuracy: 0.8444148936170213 \n",
      "Epoch 8 | Step 3057 | loss: 0.36033270975290704 | accuracy: 0.8448093220338984 \n",
      "Epoch 8 | Step 3058 | loss: 0.3601608877443562 | accuracy: 0.8450026371308017 \n",
      "Epoch 8 | Step 3059 | loss: 0.36027017962030994 | accuracy: 0.8448660714285714 \n",
      "Epoch 8 | Step 3060 | loss: 0.36028234030911105 | accuracy: 0.8448614016736402 \n",
      "Epoch 8 | Step 3061 | loss: 0.3600118715316056 | accuracy: 0.8447265625 \n",
      "Epoch 8 | Step 3062 | loss: 0.3593680005350547 | accuracy: 0.8451115145228216 \n",
      "Epoch 8 | Step 3063 | loss: 0.3588529583836389 | accuracy: 0.8452995867768595 \n",
      "Epoch 8 | Step 3064 | loss: 0.35906927060688465 | accuracy: 0.8453575102880658 \n",
      "Epoch 8 | Step 3065 | loss: 0.3595074935526143 | accuracy: 0.8449667008196722 \n",
      "Epoch 8 | Step 3066 | loss: 0.3595899133049711 | accuracy: 0.8450892857142858 \n",
      "Epoch 8 | Step 3067 | loss: 0.3593816911059665 | accuracy: 0.8452108739837398 \n",
      "Epoch 8 | Step 3068 | loss: 0.3591976929531405 | accuracy: 0.8455212550607287 \n",
      "Epoch 8 | Step 3069 | loss: 0.35967777164713016 | accuracy: 0.8454511088709677 \n",
      "Epoch 8 | Step 3070 | loss: 0.3594180557383111 | accuracy: 0.8456325301204819 \n",
      "Epoch 8 | Step 3071 | loss: 0.3593400775194167 | accuracy: 0.845625 \n",
      "Epoch 8 | Step 3072 | loss: 0.35905552789034584 | accuracy: 0.8456175298804781 \n",
      "Epoch 8 | Step 3073 | loss: 0.35881946448768876 | accuracy: 0.8456101190476191 \n",
      "Epoch 8 | Step 3074 | loss: 0.35868188727043354 | accuracy: 0.8458498023715415 \n",
      "Epoch 8 | Step 3075 | loss: 0.35860200284972893 | accuracy: 0.8459030511811023 \n",
      "Epoch 8 | Step 3076 | loss: 0.358425424262589 | accuracy: 0.8460171568627451 \n",
      "Epoch 8 | Step 3077 | loss: 0.35842104582115997 | accuracy: 0.8458251953125 \n",
      "Epoch 8 | Step 3078 | loss: 0.3581752544015297 | accuracy: 0.8458171206225681 \n",
      "Epoch 8 | Step 3079 | loss: 0.3578217670668002 | accuracy: 0.8458091085271318 \n",
      "Epoch 8 | Step 3080 | loss: 0.35805020288611 | accuracy: 0.8456201737451737 \n",
      "Epoch 8 | Step 3081 | loss: 0.3576753483368799 | accuracy: 0.8456730769230769 \n",
      "Epoch 8 | Step 3082 | loss: 0.35840713703769367 | accuracy: 0.8452466475095786 \n",
      "Epoch 8 | Step 3083 | loss: 0.35858831162216087 | accuracy: 0.8451216603053435 \n",
      "Epoch 8 | Step 3084 | loss: 0.3583348212133341 | accuracy: 0.845175855513308 \n",
      "Epoch 8 | Step 3085 | loss: 0.3587515838444232 | accuracy: 0.8450520833333334 \n",
      "Epoch 8 | Step 3086 | loss: 0.3586260938419485 | accuracy: 0.8451650943396226 \n",
      "Epoch 8 | Step 3087 | loss: 0.35840475828127744 | accuracy: 0.8452772556390977 \n",
      "Epoch 8 | Step 3088 | loss: 0.35826251703255174 | accuracy: 0.8452130149812734 \n",
      "Epoch 8 | Step 3089 | loss: 0.3584085459362214 | accuracy: 0.8450909514925373 \n",
      "Epoch 8 | Step 3090 | loss: 0.35832448076581414 | accuracy: 0.8451440520446096 \n",
      "Epoch 8 | Step 3091 | loss: 0.3581056158851693 | accuracy: 0.8451967592592593 \n",
      "Epoch 8 | Step 3092 | loss: 0.3582775230997162 | accuracy: 0.8451337638376384 \n",
      "Epoch 8 | Step 3093 | loss: 0.3581797128871959 | accuracy: 0.8451861213235294 \n",
      "Epoch 8 | Step 3094 | loss: 0.3581578008857838 | accuracy: 0.845066391941392 \n",
      "Epoch 8 | Step 3095 | loss: 0.3580267791547914 | accuracy: 0.8450615875912408 \n",
      "Epoch 8 | Step 3096 | loss: 0.35785835092717944 | accuracy: 0.8451136363636363 \n",
      "Epoch 8 | Step 3097 | loss: 0.3580620599829632 | accuracy: 0.8448822463768116 \n",
      "Epoch 8 | Step 3098 | loss: 0.3579007934792377 | accuracy: 0.8449345667870036 \n",
      "Epoch 8 | Step 3099 | loss: 0.35769072796801005 | accuracy: 0.8450989208633094 \n",
      "Epoch 8 | Step 3100 | loss: 0.3579000144876459 | accuracy: 0.8449260752688172 \n",
      "Epoch 8 | Step 3101 | loss: 0.3576251557895115 | accuracy: 0.8450334821428571 \n",
      "Epoch 8 | Step 3102 | loss: 0.3580514202126404 | accuracy: 0.8447508896797153 \n",
      "Epoch 8 | Step 3103 | loss: 0.35785413422483076 | accuracy: 0.8448581560283688 \n",
      "Epoch 8 | Step 3104 | loss: 0.3579929692163905 | accuracy: 0.8448542402826855 \n",
      "Epoch 8 | Step 3105 | loss: 0.357820124168631 | accuracy: 0.8449603873239436 \n",
      "Epoch 8 | Step 3106 | loss: 0.35776747444219753 | accuracy: 0.8450657894736842 \n",
      "Epoch 8 | Step 3107 | loss: 0.35778930991679636 | accuracy: 0.8451158216783216 \n",
      "Epoch 8 | Step 3108 | loss: 0.3575441925575509 | accuracy: 0.8450566202090591 \n",
      "Epoch 8 | Step 3109 | loss: 0.35738109579930705 | accuracy: 0.8451063368055555 \n",
      "Epoch 8 | Step 3110 | loss: 0.3572892356908858 | accuracy: 0.8449935121107266 \n",
      "Epoch 8 | Step 3111 | loss: 0.35759197894869177 | accuracy: 0.8448275862068966 \n",
      "Epoch 8 | Step 3112 | loss: 0.3572893378251196 | accuracy: 0.8448775773195877 \n",
      "Epoch 8 | Step 3113 | loss: 0.3571222264268626 | accuracy: 0.8449807363013699 \n",
      "Epoch 8 | Step 3114 | loss: 0.35696475009462525 | accuracy: 0.8450298634812288 \n",
      "Epoch 8 | Step 3115 | loss: 0.3565334798831517 | accuracy: 0.8452380952380953 \n",
      "Epoch 8 | Step 3116 | loss: 0.3571055062241473 | accuracy: 0.8451271186440679 \n",
      "Epoch 8 | Step 3117 | loss: 0.3569012926136319 | accuracy: 0.8452808277027029 \n",
      "Epoch 8 | Step 3118 | loss: 0.3570577752610248 | accuracy: 0.8451704545454547 \n",
      "Epoch 8 | Step 3119 | loss: 0.3569276427362589 | accuracy: 0.8452705536912754 \n",
      "Epoch 8 | Step 3120 | loss: 0.35671225264917644 | accuracy: 0.845265468227425 \n",
      "Epoch 8 | Step 3121 | loss: 0.35651612952351563 | accuracy: 0.845260416666667 \n",
      "Epoch 8 | Step 3122 | loss: 0.3563220884613816 | accuracy: 0.8454111295681066 \n",
      "Epoch 8 | Step 3123 | loss: 0.35633941641114397 | accuracy: 0.8453538907284771 \n",
      "Epoch 8 | Step 3124 | loss: 0.3560484134816493 | accuracy: 0.8454517326732677 \n",
      "Epoch 8 | Step 3125 | loss: 0.35588964226802705 | accuracy: 0.845548930921053 \n",
      "Epoch 8 | Step 3126 | loss: 0.3563170870308015 | accuracy: 0.8451844262295086 \n",
      "Epoch 8 | Step 3127 | loss: 0.35599920129269547 | accuracy: 0.8453329248366017 \n",
      "Epoch 8 | Step 3128 | loss: 0.3558213914159066 | accuracy: 0.8455822475570036 \n",
      "Epoch 8 | Step 3129 | loss: 0.35562525452537963 | accuracy: 0.8457284902597406 \n",
      "Epoch 8 | Step 3130 | loss: 0.3551607826863291 | accuracy: 0.8460254854368936 \n",
      "Epoch 8 | Step 3131 | loss: 0.3549522806079156 | accuracy: 0.8461189516129036 \n",
      "Epoch 8 | Step 3132 | loss: 0.354783966754027 | accuracy: 0.8463122990353701 \n",
      "Epoch 8 | Step 3133 | loss: 0.35480624929261506 | accuracy: 0.8461538461538465 \n",
      "Epoch 8 | Step 3134 | loss: 0.3547175595649895 | accuracy: 0.8460463258785946 \n",
      "Epoch 8 | Step 3135 | loss: 0.3545911911471633 | accuracy: 0.8461882961783443 \n",
      "Epoch 8 | Step 3136 | loss: 0.3540738799742289 | accuracy: 0.8465277777777781 \n",
      "Epoch 8 | Step 3137 | loss: 0.3542205059924457 | accuracy: 0.8465189873417726 \n",
      "Epoch 8 | Step 3138 | loss: 0.35430105246768007 | accuracy: 0.8465595425867511 \n",
      "Epoch 8 | Step 3139 | loss: 0.3542937566555521 | accuracy: 0.8465998427672959 \n",
      "Epoch 8 | Step 3140 | loss: 0.3541957580464013 | accuracy: 0.8465909090909094 \n",
      "Epoch 8 | Step 3141 | loss: 0.354110507806763 | accuracy: 0.8467285156250004 \n",
      "Epoch 8 | Step 3142 | loss: 0.3541326276331304 | accuracy: 0.846719236760125 \n",
      "Epoch 8 | Step 3143 | loss: 0.353991970743822 | accuracy: 0.8468070652173917 \n",
      "Epoch 8 | Step 3144 | loss: 0.3540770051187775 | accuracy: 0.8467008513931892 \n",
      "Epoch 8 | Step 3145 | loss: 0.3539931507850135 | accuracy: 0.8465952932098769 \n",
      "Epoch 8 | Step 3146 | loss: 0.3539960285791984 | accuracy: 0.846442307692308 \n",
      "Epoch 8 | Step 3147 | loss: 0.35406750984535623 | accuracy: 0.8462423312883439 \n",
      "Epoch 8 | Step 3148 | loss: 0.354213461279869 | accuracy: 0.846186926605505 \n",
      "Epoch 8 | Step 3149 | loss: 0.3541120693723603 | accuracy: 0.8463224085365857 \n",
      "Epoch 8 | Step 3150 | loss: 0.3539395805640786 | accuracy: 0.8464570668693012 \n",
      "Epoch 8 | Step 3151 | loss: 0.3540219857385664 | accuracy: 0.8463068181818185 \n",
      "Epoch 8 | Step 3152 | loss: 0.3538567788921454 | accuracy: 0.8463935045317224 \n",
      "Epoch 8 | Step 3153 | loss: 0.35387966032308266 | accuracy: 0.8463384789156629 \n",
      "Epoch 8 | Step 3154 | loss: 0.3538481092399305 | accuracy: 0.8463776276276279 \n",
      "Epoch 8 | Step 3155 | loss: 0.35364176408794823 | accuracy: 0.8466504491017968 \n",
      "Epoch 8 | Step 3156 | loss: 0.353656200997865 | accuracy: 0.846548507462687 \n",
      "Epoch 8 | Step 3157 | loss: 0.3535517393389628 | accuracy: 0.8465866815476194 \n",
      "Epoch 8 | Step 3158 | loss: 0.3534981765361497 | accuracy: 0.8465782640949558 \n",
      "Epoch 8 | Step 3159 | loss: 0.35332245062265166 | accuracy: 0.8466623520710063 \n",
      "Epoch 8 | Step 3160 | loss: 0.3532286052067371 | accuracy: 0.8467920353982304 \n",
      "Epoch 8 | Step 3161 | loss: 0.353151113627588 | accuracy: 0.8468290441176474 \n",
      "Epoch 8 | Step 3162 | loss: 0.35316160308126127 | accuracy: 0.8467283724340179 \n",
      "Epoch 8 | Step 3163 | loss: 0.35314012353706076 | accuracy: 0.8467653508771933 \n",
      "Epoch 8 | Step 3164 | loss: 0.3527818734027206 | accuracy: 0.8469387755102045 \n",
      "Epoch 8 | Step 3165 | loss: 0.3528603094435015 | accuracy: 0.846838662790698 \n",
      "Epoch 8 | Step 3166 | loss: 0.35252770492132157 | accuracy: 0.8470561594202902 \n",
      "Epoch 8 | Step 3167 | loss: 0.3524190961367133 | accuracy: 0.8472272398843934 \n",
      "Epoch 8 | Step 3168 | loss: 0.352256754160958 | accuracy: 0.8473973342939485 \n",
      "Epoch 8 | Step 3169 | loss: 0.3520909063518047 | accuracy: 0.8475215517241382 \n",
      "Epoch 8 | Step 3170 | loss: 0.35199251980187213 | accuracy: 0.8474659742120347 \n",
      "Epoch 8 | Step 3171 | loss: 0.3523191739405904 | accuracy: 0.847276785714286 \n",
      "Epoch 8 | Step 3172 | loss: 0.35194743048940963 | accuracy: 0.8475338319088322 \n",
      "Epoch 8 | Step 3173 | loss: 0.3518812837163833 | accuracy: 0.8474786931818185 \n",
      "Epoch 8 | Step 3174 | loss: 0.35187319702028214 | accuracy: 0.8473796033994337 \n",
      "Epoch 8 | Step 3175 | loss: 0.3519996813377418 | accuracy: 0.8471927966101698 \n",
      "Epoch 8 | Step 3176 | loss: 0.3518589316539361 | accuracy: 0.8472271126760567 \n",
      "Epoch 8 | Step 3177 | loss: 0.3514935459230053 | accuracy: 0.8473929073033711 \n",
      "Epoch 8 | Step 3178 | loss: 0.351766920598949 | accuracy: 0.8472951680672272 \n",
      "Epoch 8 | Step 3179 | loss: 0.3520339072666354 | accuracy: 0.8472416201117322 \n",
      "Epoch 8 | Step 3180 | loss: 0.3518098018710659 | accuracy: 0.8472754178272983 \n",
      "Epoch 8 | Step 3181 | loss: 0.35193891016145545 | accuracy: 0.8472222222222225 \n",
      "Epoch 8 | Step 3182 | loss: 0.35186396902452877 | accuracy: 0.8471693213296402 \n",
      "Epoch 8 | Step 3183 | loss: 0.35173694497149294 | accuracy: 0.8472030386740335 \n",
      "Epoch 8 | Step 3184 | loss: 0.3517720449315615 | accuracy: 0.8471935261707992 \n",
      "Epoch 8 | Step 3185 | loss: 0.3512583277546443 | accuracy: 0.8475703983516487 \n",
      "Epoch 8 | Step 3186 | loss: 0.35103893753600446 | accuracy: 0.8476455479452057 \n",
      "Epoch 8 | Step 3187 | loss: 0.35107406957553383 | accuracy: 0.8476775956284156 \n",
      "Epoch 8 | Step 3188 | loss: 0.35125875221286224 | accuracy: 0.8474540190735698 \n",
      "Epoch 8 | Step 3189 | loss: 0.35103981974332227 | accuracy: 0.8475713315217395 \n",
      "Epoch 8 | Step 3190 | loss: 0.3510914194551587 | accuracy: 0.8476880081300816 \n",
      "Epoch 8 | Step 3191 | loss: 0.35109281612409127 | accuracy: 0.8476351351351354 \n",
      "Epoch 8 | Step 3192 | loss: 0.35127002603281543 | accuracy: 0.8474983153638818 \n",
      "Epoch 8 | Step 3193 | loss: 0.35120812218676334 | accuracy: 0.8476142473118282 \n",
      "Epoch 8 | Step 3194 | loss: 0.3508517895163544 | accuracy: 0.8478133378016088 \n",
      "Epoch 8 | Step 3195 | loss: 0.35059277852748166 | accuracy: 0.8479695855614976 \n",
      "Epoch 8 | Step 3196 | loss: 0.35082441771030426 | accuracy: 0.847916666666667 \n",
      "Epoch 8 | Step 3197 | loss: 0.35077801009917514 | accuracy: 0.8479471409574472 \n",
      "Epoch 8 | Step 3198 | loss: 0.35076703518550023 | accuracy: 0.8478531167108756 \n",
      "Epoch 8 | Step 3199 | loss: 0.3508119980099971 | accuracy: 0.8476769179894182 \n",
      "Epoch 8 | Step 3200 | loss: 0.35060230538366965 | accuracy: 0.8477077836411613 \n",
      "Epoch 8 | Step 3201 | loss: 0.35050645380427964 | accuracy: 0.8476973684210529 \n",
      "Epoch 8 | Step 3202 | loss: 0.3501057563804266 | accuracy: 0.8480150918635173 \n",
      "Epoch 8 | Step 3203 | loss: 0.35021512834501517 | accuracy: 0.848003926701571 \n",
      "Epoch 8 | Step 3204 | loss: 0.35029248430274484 | accuracy: 0.8479520234986948 \n",
      "Epoch 8 | Step 3205 | loss: 0.3505119630911698 | accuracy: 0.8478597005208336 \n",
      "Epoch 8 | Step 3206 | loss: 0.3504956618531958 | accuracy: 0.8478896103896106 \n",
      "Epoch 8 | Step 3207 | loss: 0.35048108119421056 | accuracy: 0.8478384067357516 \n",
      "Epoch 8 | Step 3208 | loss: 0.3506431976184056 | accuracy: 0.8477874677002587 \n",
      "Epoch 8 | Step 3209 | loss: 0.350712579319772 | accuracy: 0.8478173324742271 \n",
      "Epoch 8 | Step 3210 | loss: 0.35075701531836795 | accuracy: 0.8478470437017998 \n",
      "Epoch 8 | Step 3211 | loss: 0.3508125462593176 | accuracy: 0.8478766025641029 \n",
      "Epoch 8 | Step 3212 | loss: 0.3508067849804373 | accuracy: 0.8479859335038366 \n",
      "Epoch 8 | Step 3213 | loss: 0.3507322780027681 | accuracy: 0.848134566326531 \n",
      "Epoch 8 | Step 3214 | loss: 0.3505241691914527 | accuracy: 0.8482426844783718 \n",
      "Epoch 8 | Step 3215 | loss: 0.3508551360538163 | accuracy: 0.847953680203046 \n",
      "Epoch 8 | Step 3216 | loss: 0.35067409390135656 | accuracy: 0.8480617088607598 \n",
      "Epoch 8 | Step 3217 | loss: 0.3504515059217058 | accuracy: 0.8482086489898992 \n",
      "Epoch 8 | Step 3218 | loss: 0.3504150352940451 | accuracy: 0.848354848866499 \n",
      "Epoch 8 | Step 3219 | loss: 0.3505011251074585 | accuracy: 0.8482647613065329 \n",
      "Epoch 8 | Step 3220 | loss: 0.3504193701540916 | accuracy: 0.848214285714286 \n",
      "Epoch 8 | Step 3221 | loss: 0.3502983498573303 | accuracy: 0.8482031250000003 \n",
      "Epoch 8 | Step 3222 | loss: 0.35041545647338146 | accuracy: 0.8480361596009978 \n",
      "Epoch 8 | Step 3223 | loss: 0.3504639857295734 | accuracy: 0.8480643656716421 \n",
      "Epoch 8 | Step 3224 | loss: 0.35030487438585267 | accuracy: 0.8480135514481786 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4783332049846649 | accuracy: 0.78125 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.42622675001621246 | accuracy: 0.8125 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.44492097695668537 | accuracy: 0.8125 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4430293142795563 | accuracy: 0.80078125 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4172016799449921 | accuracy: 0.81875 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.43577814598878223 | accuracy: 0.7994791666666666 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4300643929413387 | accuracy: 0.7991071428571429 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4252709709107876 | accuracy: 0.8046875 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.44272450937165153 | accuracy: 0.7986111111111112 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.43498718440532685 | accuracy: 0.8015625 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4348302971233021 | accuracy: 0.7997159090909091 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.42417216300964355 | accuracy: 0.8059895833333334 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.42526610768758333 | accuracy: 0.8040865384615384 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.42090780820165363 | accuracy: 0.8069196428571429 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4235250294208527 | accuracy: 0.809375 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4267469011247158 | accuracy: 0.80859375 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4359068204374874 | accuracy: 0.8060661764705882 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.43583228521876866 | accuracy: 0.8064236111111112 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.43195060993495743 | accuracy: 0.8100328947368421 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4308395624160767 | accuracy: 0.809375 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4259570226782844 | accuracy: 0.8117559523809523 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4223561639135534 | accuracy: 0.8132102272727273 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.42869993914728577 | accuracy: 0.8084239130434783 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4409116705258687 | accuracy: 0.8033854166666666 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4447283625602722 | accuracy: 0.800625 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4417434208668195 | accuracy: 0.8022836538461539 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.43705207882104097 | accuracy: 0.8055555555555556 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.43665030705077307 | accuracy: 0.8058035714285714 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.43415180054204217 | accuracy: 0.8060344827586207 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.43076764841874443 | accuracy: 0.8088541666666667 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.425173774842293 | accuracy: 0.811491935483871 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.42815820313990116 | accuracy: 0.8095703125 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.42884028228846466 | accuracy: 0.8087121212121212 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4324124376563465 | accuracy: 0.8056066176470589 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.433042768069676 | accuracy: 0.8058035714285714 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4303509559896257 | accuracy: 0.8072916666666666 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4299415913788048 | accuracy: 0.808277027027027 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4318940514012387 | accuracy: 0.8083881578947367 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.43026373860163564 | accuracy: 0.8100961538461537 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4281922660768032 | accuracy: 0.81171875 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4264872139546929 | accuracy: 0.8117378048780488 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4242575346004395 | accuracy: 0.8128720238095238 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4244585792685664 | accuracy: 0.8132267441860465 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.4281810163096948 | accuracy: 0.8110795454545454 \n",
      "Validation | Epoch 8 | Step 3224 | loss: 0.42619693875312803 | accuracy: 0.8114130430751376 \n",
      "Epoch 9 | Step 3225 | loss: 0.5082210302352905 | accuracy: 0.78125 \n",
      "Epoch 9 | Step 3226 | loss: 0.3789414092898369 | accuracy: 0.8359375 \n",
      "Epoch 9 | Step 3227 | loss: 0.36830467482407886 | accuracy: 0.8385416666666666 \n",
      "Epoch 9 | Step 3228 | loss: 0.3749731369316578 | accuracy: 0.83984375 \n",
      "Epoch 9 | Step 3229 | loss: 0.3480925887823105 | accuracy: 0.85625 \n",
      "Epoch 9 | Step 3230 | loss: 0.3414176180958748 | accuracy: 0.8541666666666666 \n",
      "Epoch 9 | Step 3231 | loss: 0.34010873309203554 | accuracy: 0.8571428571428571 \n",
      "Epoch 9 | Step 3232 | loss: 0.33496961556375027 | accuracy: 0.859375 \n",
      "Epoch 9 | Step 3233 | loss: 0.3417716042862998 | accuracy: 0.8559027777777778 \n",
      "Epoch 9 | Step 3234 | loss: 0.3523450419306755 | accuracy: 0.8515625 \n",
      "Epoch 9 | Step 3235 | loss: 0.33982121402567084 | accuracy: 0.859375 \n",
      "Epoch 9 | Step 3236 | loss: 0.33442597339550656 | accuracy: 0.8619791666666666 \n",
      "Epoch 9 | Step 3237 | loss: 0.3466588006569789 | accuracy: 0.8533653846153846 \n",
      "Epoch 9 | Step 3238 | loss: 0.3431484081915447 | accuracy: 0.8571428571428571 \n",
      "Epoch 9 | Step 3239 | loss: 0.34386189381281534 | accuracy: 0.8583333333333333 \n",
      "Epoch 9 | Step 3240 | loss: 0.3356222491711378 | accuracy: 0.8623046875 \n",
      "Epoch 9 | Step 3241 | loss: 0.3379822320797864 | accuracy: 0.8566176470588235 \n",
      "Epoch 9 | Step 3242 | loss: 0.33548371328247917 | accuracy: 0.8576388888888888 \n",
      "Epoch 9 | Step 3243 | loss: 0.332977189829475 | accuracy: 0.859375 \n",
      "Epoch 9 | Step 3244 | loss: 0.3367676630616188 | accuracy: 0.859375 \n",
      "Epoch 9 | Step 3245 | loss: 0.3358618602866218 | accuracy: 0.8586309523809523 \n",
      "Epoch 9 | Step 3246 | loss: 0.3368563191457228 | accuracy: 0.8572443181818182 \n",
      "Epoch 9 | Step 3247 | loss: 0.3368117537187493 | accuracy: 0.8566576086956522 \n",
      "Epoch 9 | Step 3248 | loss: 0.33733084052801127 | accuracy: 0.85546875 \n",
      "Epoch 9 | Step 3249 | loss: 0.3418786478042602 | accuracy: 0.85375 \n",
      "Epoch 9 | Step 3250 | loss: 0.34219276217313904 | accuracy: 0.8533653846153846 \n",
      "Epoch 9 | Step 3251 | loss: 0.3440931207603878 | accuracy: 0.8524305555555556 \n",
      "Epoch 9 | Step 3252 | loss: 0.34170787142855774 | accuracy: 0.8543526785714286 \n",
      "Epoch 9 | Step 3253 | loss: 0.3431842172967976 | accuracy: 0.853448275862069 \n",
      "Epoch 9 | Step 3254 | loss: 0.3434160947799682 | accuracy: 0.853125 \n",
      "Epoch 9 | Step 3255 | loss: 0.34103433451344883 | accuracy: 0.8538306451612904 \n",
      "Epoch 9 | Step 3256 | loss: 0.340422092936933 | accuracy: 0.853515625 \n",
      "Epoch 9 | Step 3257 | loss: 0.34033377513741 | accuracy: 0.8536931818181818 \n",
      "Epoch 9 | Step 3258 | loss: 0.33707501783090477 | accuracy: 0.8552389705882353 \n",
      "Epoch 9 | Step 3259 | loss: 0.33371269404888154 | accuracy: 0.8571428571428571 \n",
      "Epoch 9 | Step 3260 | loss: 0.3325544219050143 | accuracy: 0.8576388888888888 \n",
      "Epoch 9 | Step 3261 | loss: 0.3327702545636409 | accuracy: 0.8576858108108109 \n",
      "Epoch 9 | Step 3262 | loss: 0.3345618644043019 | accuracy: 0.8552631578947368 \n",
      "Epoch 9 | Step 3263 | loss: 0.3337258157821802 | accuracy: 0.8565705128205128 \n",
      "Epoch 9 | Step 3264 | loss: 0.33193933628499506 | accuracy: 0.85703125 \n",
      "Epoch 9 | Step 3265 | loss: 0.3331714603232174 | accuracy: 0.8567073170731707 \n",
      "Epoch 9 | Step 3266 | loss: 0.33380214621623355 | accuracy: 0.8556547619047619 \n",
      "Epoch 9 | Step 3267 | loss: 0.33185493772806124 | accuracy: 0.8561046511627907 \n",
      "Epoch 9 | Step 3268 | loss: 0.33002653751860966 | accuracy: 0.8575994318181818 \n",
      "Epoch 9 | Step 3269 | loss: 0.3302736391623815 | accuracy: 0.8586805555555556 \n",
      "Epoch 9 | Step 3270 | loss: 0.3306947723031044 | accuracy: 0.8583559782608695 \n",
      "Epoch 9 | Step 3271 | loss: 0.3314785751256537 | accuracy: 0.8577127659574468 \n",
      "Epoch 9 | Step 3272 | loss: 0.33258532887945574 | accuracy: 0.8561197916666666 \n",
      "Epoch 9 | Step 3273 | loss: 0.33569920397534664 | accuracy: 0.8552295918367347 \n",
      "Epoch 9 | Step 3274 | loss: 0.33670066624879835 | accuracy: 0.855 \n",
      "Epoch 9 | Step 3275 | loss: 0.33537447423327205 | accuracy: 0.8556985294117647 \n",
      "Epoch 9 | Step 3276 | loss: 0.3342245997717747 | accuracy: 0.8557692307692307 \n",
      "Epoch 9 | Step 3277 | loss: 0.3355199686198864 | accuracy: 0.8549528301886793 \n",
      "Epoch 9 | Step 3278 | loss: 0.33462350429208193 | accuracy: 0.8556134259259259 \n",
      "Epoch 9 | Step 3279 | loss: 0.33486936444585974 | accuracy: 0.8553977272727272 \n",
      "Epoch 9 | Step 3280 | loss: 0.33466399274766445 | accuracy: 0.85546875 \n",
      "Epoch 9 | Step 3281 | loss: 0.3357802454316825 | accuracy: 0.8541666666666666 \n",
      "Epoch 9 | Step 3282 | loss: 0.33554029695946597 | accuracy: 0.8542564655172413 \n",
      "Epoch 9 | Step 3283 | loss: 0.33712650633464425 | accuracy: 0.854343220338983 \n",
      "Epoch 9 | Step 3284 | loss: 0.3366844785710176 | accuracy: 0.8546875 \n",
      "Epoch 9 | Step 3285 | loss: 0.33606147106553685 | accuracy: 0.8555327868852459 \n",
      "Epoch 9 | Step 3286 | loss: 0.33506859911064946 | accuracy: 0.8563508064516129 \n",
      "Epoch 9 | Step 3287 | loss: 0.33679002878211795 | accuracy: 0.8561507936507936 \n",
      "Epoch 9 | Step 3288 | loss: 0.3355090662371367 | accuracy: 0.85693359375 \n",
      "Epoch 9 | Step 3289 | loss: 0.3342831077483984 | accuracy: 0.8574519230769231 \n",
      "Epoch 9 | Step 3290 | loss: 0.3335320658304475 | accuracy: 0.8572443181818182 \n",
      "Epoch 9 | Step 3291 | loss: 0.33245945577301195 | accuracy: 0.8575093283582089 \n",
      "Epoch 9 | Step 3292 | loss: 0.3323574690696071 | accuracy: 0.8570772058823529 \n",
      "Epoch 9 | Step 3293 | loss: 0.3331740310658579 | accuracy: 0.8568840579710145 \n",
      "Epoch 9 | Step 3294 | loss: 0.33226339540311267 | accuracy: 0.8571428571428571 \n",
      "Epoch 9 | Step 3295 | loss: 0.331579037745234 | accuracy: 0.8569542253521126 \n",
      "Epoch 9 | Step 3296 | loss: 0.33076070559521514 | accuracy: 0.8569878472222222 \n",
      "Epoch 9 | Step 3297 | loss: 0.33079056115183114 | accuracy: 0.8570205479452054 \n",
      "Epoch 9 | Step 3298 | loss: 0.33011251426226385 | accuracy: 0.8572635135135135 \n",
      "Epoch 9 | Step 3299 | loss: 0.33021359582742055 | accuracy: 0.8572916666666667 \n",
      "Epoch 9 | Step 3300 | loss: 0.32940202186766426 | accuracy: 0.8579358552631579 \n",
      "Epoch 9 | Step 3301 | loss: 0.3286213152981424 | accuracy: 0.8583603896103896 \n",
      "Epoch 9 | Step 3302 | loss: 0.3291745042571655 | accuracy: 0.8579727564102564 \n",
      "Epoch 9 | Step 3303 | loss: 0.33087273507933074 | accuracy: 0.8566060126582279 \n",
      "Epoch 9 | Step 3304 | loss: 0.33135692980140447 | accuracy: 0.85625 \n",
      "Epoch 9 | Step 3305 | loss: 0.3307904220289654 | accuracy: 0.8562885802469136 \n",
      "Epoch 9 | Step 3306 | loss: 0.330565205616195 | accuracy: 0.856516768292683 \n",
      "Epoch 9 | Step 3307 | loss: 0.33071781084480056 | accuracy: 0.8569277108433735 \n",
      "Epoch 9 | Step 3308 | loss: 0.33029932546473684 | accuracy: 0.8573288690476191 \n",
      "Epoch 9 | Step 3309 | loss: 0.32972592658856337 | accuracy: 0.8575367647058824 \n",
      "Epoch 9 | Step 3310 | loss: 0.32998293863479483 | accuracy: 0.8573764534883721 \n",
      "Epoch 9 | Step 3311 | loss: 0.3328382429377786 | accuracy: 0.8565014367816092 \n",
      "Epoch 9 | Step 3312 | loss: 0.3330182411115277 | accuracy: 0.8567116477272727 \n",
      "Epoch 9 | Step 3313 | loss: 0.3319668280944395 | accuracy: 0.8572682584269663 \n",
      "Epoch 9 | Step 3314 | loss: 0.3328590104977289 | accuracy: 0.8569444444444444 \n",
      "Epoch 9 | Step 3315 | loss: 0.33187233582957754 | accuracy: 0.8574862637362637 \n",
      "Epoch 9 | Step 3316 | loss: 0.33101152401903394 | accuracy: 0.8578464673913043 \n",
      "Epoch 9 | Step 3317 | loss: 0.3308106657638344 | accuracy: 0.8573588709677419 \n",
      "Epoch 9 | Step 3318 | loss: 0.330392873667656 | accuracy: 0.8572140957446809 \n",
      "Epoch 9 | Step 3319 | loss: 0.3312307869133196 | accuracy: 0.8569078947368421 \n",
      "Epoch 9 | Step 3320 | loss: 0.3329528371493021 | accuracy: 0.8562825520833334 \n",
      "Epoch 9 | Step 3321 | loss: 0.3335478032372661 | accuracy: 0.8563144329896907 \n",
      "Epoch 9 | Step 3322 | loss: 0.33497804281662924 | accuracy: 0.8558673469387755 \n",
      "Epoch 9 | Step 3323 | loss: 0.3345713016360697 | accuracy: 0.8562184343434344 \n",
      "Epoch 9 | Step 3324 | loss: 0.33387141972780227 | accuracy: 0.8565625 \n",
      "Epoch 9 | Step 3325 | loss: 0.3325243949299992 | accuracy: 0.8568997524752475 \n",
      "Epoch 9 | Step 3326 | loss: 0.33234309682659074 | accuracy: 0.8569240196078431 \n",
      "Epoch 9 | Step 3327 | loss: 0.33137369633299635 | accuracy: 0.8574029126213593 \n",
      "Epoch 9 | Step 3328 | loss: 0.33212696918501305 | accuracy: 0.8572716346153846 \n",
      "Epoch 9 | Step 3329 | loss: 0.3330729630731401 | accuracy: 0.856845238095238 \n",
      "Epoch 9 | Step 3330 | loss: 0.33247502921324856 | accuracy: 0.8567216981132075 \n",
      "Epoch 9 | Step 3331 | loss: 0.33365410914487925 | accuracy: 0.8566004672897196 \n",
      "Epoch 9 | Step 3332 | loss: 0.3346201191069903 | accuracy: 0.8560474537037037 \n",
      "Epoch 9 | Step 3333 | loss: 0.33475245207274723 | accuracy: 0.8560779816513762 \n",
      "Epoch 9 | Step 3334 | loss: 0.3352749755436724 | accuracy: 0.8558238636363636 \n",
      "Epoch 9 | Step 3335 | loss: 0.33483685741016456 | accuracy: 0.8557150900900901 \n",
      "Epoch 9 | Step 3336 | loss: 0.33449931456042187 | accuracy: 0.8560267857142857 \n",
      "Epoch 9 | Step 3337 | loss: 0.3354694836698802 | accuracy: 0.8557798672566371 \n",
      "Epoch 9 | Step 3338 | loss: 0.33671518389070243 | accuracy: 0.8552631578947368 \n",
      "Epoch 9 | Step 3339 | loss: 0.3365968757349512 | accuracy: 0.8551630434782609 \n",
      "Epoch 9 | Step 3340 | loss: 0.3367710826468879 | accuracy: 0.8550646551724138 \n",
      "Epoch 9 | Step 3341 | loss: 0.33770430661164796 | accuracy: 0.8545673076923077 \n",
      "Epoch 9 | Step 3342 | loss: 0.338213236023814 | accuracy: 0.8542108050847458 \n",
      "Epoch 9 | Step 3343 | loss: 0.3381808576714091 | accuracy: 0.8542542016806722 \n",
      "Epoch 9 | Step 3344 | loss: 0.33772543954352535 | accuracy: 0.8545572916666667 \n",
      "Epoch 9 | Step 3345 | loss: 0.337468201833323 | accuracy: 0.8547262396694215 \n",
      "Epoch 9 | Step 3346 | loss: 0.3375389616264672 | accuracy: 0.8542520491803278 \n",
      "Epoch 9 | Step 3347 | loss: 0.3375350611238945 | accuracy: 0.8539126016260162 \n",
      "Epoch 9 | Step 3348 | loss: 0.33792093143828456 | accuracy: 0.8539566532258065 \n",
      "Epoch 9 | Step 3349 | loss: 0.33849132001399995 | accuracy: 0.853625 \n",
      "Epoch 9 | Step 3350 | loss: 0.3382574214585244 | accuracy: 0.8537946428571429 \n",
      "Epoch 9 | Step 3351 | loss: 0.3388900870647956 | accuracy: 0.8537155511811023 \n",
      "Epoch 9 | Step 3352 | loss: 0.3383657360682264 | accuracy: 0.8536376953125 \n",
      "Epoch 9 | Step 3353 | loss: 0.33815645328325816 | accuracy: 0.8534399224806202 \n",
      "Epoch 9 | Step 3354 | loss: 0.33751425983814093 | accuracy: 0.8537259615384616 \n",
      "Epoch 9 | Step 3355 | loss: 0.3379593624640967 | accuracy: 0.8537690839694656 \n",
      "Epoch 9 | Step 3356 | loss: 0.33912131337053847 | accuracy: 0.8533380681818182 \n",
      "Epoch 9 | Step 3357 | loss: 0.33997047496469396 | accuracy: 0.8525610902255639 \n",
      "Epoch 9 | Step 3358 | loss: 0.34056822121588154 | accuracy: 0.8519123134328358 \n",
      "Epoch 9 | Step 3359 | loss: 0.34069312402495633 | accuracy: 0.8518518518518519 \n",
      "Epoch 9 | Step 3360 | loss: 0.34046940078191895 | accuracy: 0.8522518382352942 \n",
      "Epoch 9 | Step 3361 | loss: 0.3400077923153439 | accuracy: 0.8524178832116789 \n",
      "Epoch 9 | Step 3362 | loss: 0.3396288349792577 | accuracy: 0.8521286231884058 \n",
      "Epoch 9 | Step 3363 | loss: 0.3401191683767511 | accuracy: 0.8519559352517986 \n",
      "Epoch 9 | Step 3364 | loss: 0.3400331481226853 | accuracy: 0.8521205357142857 \n",
      "Epoch 9 | Step 3365 | loss: 0.34096645939011944 | accuracy: 0.8513962765957447 \n",
      "Epoch 9 | Step 3366 | loss: 0.3409501319410096 | accuracy: 0.8514524647887324 \n",
      "Epoch 9 | Step 3367 | loss: 0.34138650504442364 | accuracy: 0.8513986013986014 \n",
      "Epoch 9 | Step 3368 | loss: 0.3415559057353271 | accuracy: 0.8510199652777778 \n",
      "Epoch 9 | Step 3369 | loss: 0.3413612749042182 | accuracy: 0.8511853448275862 \n",
      "Epoch 9 | Step 3370 | loss: 0.3415827178587652 | accuracy: 0.8511344178082192 \n",
      "Epoch 9 | Step 3371 | loss: 0.3409094608762637 | accuracy: 0.8515093537414966 \n",
      "Epoch 9 | Step 3372 | loss: 0.34098091751739784 | accuracy: 0.8511402027027027 \n",
      "Epoch 9 | Step 3373 | loss: 0.3408918315732239 | accuracy: 0.8513003355704698 \n",
      "Epoch 9 | Step 3374 | loss: 0.3413965887824694 | accuracy: 0.8513541666666666 \n",
      "Epoch 9 | Step 3375 | loss: 0.3412071037174061 | accuracy: 0.851510761589404 \n",
      "Epoch 9 | Step 3376 | loss: 0.34179458365236465 | accuracy: 0.8515625 \n",
      "Epoch 9 | Step 3377 | loss: 0.34201538689385835 | accuracy: 0.8516135620915033 \n",
      "Epoch 9 | Step 3378 | loss: 0.34171418990794716 | accuracy: 0.851765422077922 \n",
      "Epoch 9 | Step 3379 | loss: 0.34130799203149736 | accuracy: 0.8520161290322581 \n",
      "Epoch 9 | Step 3380 | loss: 0.34045013107168376 | accuracy: 0.8526642628205128 \n",
      "Epoch 9 | Step 3381 | loss: 0.34092730464069715 | accuracy: 0.8524084394904459 \n",
      "Epoch 9 | Step 3382 | loss: 0.34129592257587227 | accuracy: 0.8523536392405063 \n",
      "Epoch 9 | Step 3383 | loss: 0.3416165635458329 | accuracy: 0.8520047169811321 \n",
      "Epoch 9 | Step 3384 | loss: 0.3421649000607432 | accuracy: 0.8517578125 \n",
      "Epoch 9 | Step 3385 | loss: 0.3425118548344382 | accuracy: 0.8514169254658385 \n",
      "Epoch 9 | Step 3386 | loss: 0.3427308471298513 | accuracy: 0.8512731481481481 \n",
      "Epoch 9 | Step 3387 | loss: 0.3433543932767003 | accuracy: 0.8507476993865031 \n",
      "Epoch 9 | Step 3388 | loss: 0.3430378318014669 | accuracy: 0.8508955792682927 \n",
      "Epoch 9 | Step 3389 | loss: 0.34297772654981334 | accuracy: 0.8511363636363637 \n",
      "Epoch 9 | Step 3390 | loss: 0.3430548980832101 | accuracy: 0.8510918674698795 \n",
      "Epoch 9 | Step 3391 | loss: 0.34280074526092974 | accuracy: 0.8515157185628742 \n",
      "Epoch 9 | Step 3392 | loss: 0.3435503915839253 | accuracy: 0.8512834821428571 \n",
      "Epoch 9 | Step 3393 | loss: 0.343331735955893 | accuracy: 0.8513313609467456 \n",
      "Epoch 9 | Step 3394 | loss: 0.3424940302091487 | accuracy: 0.8520220588235294 \n",
      "Epoch 9 | Step 3395 | loss: 0.34218806307218236 | accuracy: 0.852156432748538 \n",
      "Epoch 9 | Step 3396 | loss: 0.3420442720485289 | accuracy: 0.8521075581395349 \n",
      "Epoch 9 | Step 3397 | loss: 0.3416128747725074 | accuracy: 0.852510838150289 \n",
      "Epoch 9 | Step 3398 | loss: 0.3417246096778191 | accuracy: 0.8527298850574713 \n",
      "Epoch 9 | Step 3399 | loss: 0.3416475585528783 | accuracy: 0.8525892857142857 \n",
      "Epoch 9 | Step 3400 | loss: 0.3420304061675614 | accuracy: 0.8524502840909091 \n",
      "Epoch 9 | Step 3401 | loss: 0.3426771930045328 | accuracy: 0.8522245762711864 \n",
      "Epoch 9 | Step 3402 | loss: 0.3430385440587998 | accuracy: 0.852001404494382 \n",
      "Epoch 9 | Step 3403 | loss: 0.3434671451592579 | accuracy: 0.8518680167597765 \n",
      "Epoch 9 | Step 3404 | loss: 0.34316258033116664 | accuracy: 0.8519965277777778 \n",
      "Epoch 9 | Step 3405 | loss: 0.3434463713050548 | accuracy: 0.8516056629834254 \n",
      "Epoch 9 | Step 3406 | loss: 0.34334591194823555 | accuracy: 0.8515625 \n",
      "Epoch 9 | Step 3407 | loss: 0.34248029127147034 | accuracy: 0.8519467213114754 \n",
      "Epoch 9 | Step 3408 | loss: 0.3421733107255853 | accuracy: 0.8520720108695652 \n",
      "Epoch 9 | Step 3409 | loss: 0.3420013748310708 | accuracy: 0.8523648648648648 \n",
      "Epoch 9 | Step 3410 | loss: 0.34226420954350506 | accuracy: 0.8523185483870968 \n",
      "Epoch 9 | Step 3411 | loss: 0.3427770164879886 | accuracy: 0.8520220588235294 \n",
      "Epoch 9 | Step 3412 | loss: 0.34297090499325 | accuracy: 0.8517287234042553 \n",
      "Epoch 9 | Step 3413 | loss: 0.3426692556767237 | accuracy: 0.8520171957671958 \n",
      "Epoch 9 | Step 3414 | loss: 0.34348700485731426 | accuracy: 0.8518092105263158 \n",
      "Epoch 9 | Step 3415 | loss: 0.3427965298529071 | accuracy: 0.8521760471204188 \n",
      "Epoch 9 | Step 3416 | loss: 0.342388584666575 | accuracy: 0.8525390625 \n",
      "Epoch 9 | Step 3417 | loss: 0.3419554648158464 | accuracy: 0.8528983160621761 \n",
      "Epoch 9 | Step 3418 | loss: 0.34186667626358797 | accuracy: 0.853173324742268 \n",
      "Epoch 9 | Step 3419 | loss: 0.34169231324623794 | accuracy: 0.8532852564102564 \n",
      "Epoch 9 | Step 3420 | loss: 0.34178692627013946 | accuracy: 0.8533960459183674 \n",
      "Epoch 9 | Step 3421 | loss: 0.3416158244543269 | accuracy: 0.8535057106598984 \n",
      "Epoch 9 | Step 3422 | loss: 0.34162117819292376 | accuracy: 0.8536142676767676 \n",
      "Epoch 9 | Step 3423 | loss: 0.34125057484336835 | accuracy: 0.8540358040201005 \n",
      "Epoch 9 | Step 3424 | loss: 0.3408537480980158 | accuracy: 0.85421875 \n",
      "Epoch 9 | Step 3425 | loss: 0.34158835148633415 | accuracy: 0.8540111940298507 \n",
      "Epoch 9 | Step 3426 | loss: 0.3412784020056819 | accuracy: 0.854269801980198 \n",
      "Epoch 9 | Step 3427 | loss: 0.34105423393801515 | accuracy: 0.854371921182266 \n",
      "Epoch 9 | Step 3428 | loss: 0.3408857386047934 | accuracy: 0.8546262254901961 \n",
      "Epoch 9 | Step 3429 | loss: 0.3410638607856704 | accuracy: 0.854344512195122 \n",
      "Epoch 9 | Step 3430 | loss: 0.34182716479289876 | accuracy: 0.8539896844660194 \n",
      "Epoch 9 | Step 3431 | loss: 0.3422745341696025 | accuracy: 0.8539402173913043 \n",
      "Epoch 9 | Step 3432 | loss: 0.3422451803747278 | accuracy: 0.8536658653846154 \n",
      "Epoch 9 | Step 3433 | loss: 0.34215322529014786 | accuracy: 0.8534688995215312 \n",
      "Epoch 9 | Step 3434 | loss: 0.34250736967438744 | accuracy: 0.8533482142857143 \n",
      "Epoch 9 | Step 3435 | loss: 0.34269638458416923 | accuracy: 0.853228672985782 \n",
      "Epoch 9 | Step 3436 | loss: 0.34199745622727107 | accuracy: 0.8536998820754716 \n",
      "Epoch 9 | Step 3437 | loss: 0.3414905977920747 | accuracy: 0.853799882629108 \n",
      "Epoch 9 | Step 3438 | loss: 0.3415794667796554 | accuracy: 0.8539719626168224 \n",
      "Epoch 9 | Step 3439 | loss: 0.34129767099092173 | accuracy: 0.8538517441860465 \n",
      "Epoch 9 | Step 3440 | loss: 0.34140220160285634 | accuracy: 0.8537326388888888 \n",
      "Epoch 9 | Step 3441 | loss: 0.3410152842372244 | accuracy: 0.8539026497695853 \n",
      "Epoch 9 | Step 3442 | loss: 0.34100531547441393 | accuracy: 0.8539994266055045 \n",
      "Epoch 9 | Step 3443 | loss: 0.3408771727455261 | accuracy: 0.8540239726027398 \n",
      "Epoch 9 | Step 3444 | loss: 0.3408274926922538 | accuracy: 0.854190340909091 \n",
      "Epoch 9 | Step 3445 | loss: 0.34095570027019106 | accuracy: 0.8541430995475113 \n",
      "Epoch 9 | Step 3446 | loss: 0.3408183487685951 | accuracy: 0.8543074324324325 \n",
      "Epoch 9 | Step 3447 | loss: 0.3406776088235624 | accuracy: 0.8543301569506726 \n",
      "Epoch 9 | Step 3448 | loss: 0.3400589246302843 | accuracy: 0.8547712053571429 \n",
      "Epoch 9 | Step 3449 | loss: 0.3400045283635457 | accuracy: 0.8547916666666666 \n",
      "Epoch 9 | Step 3450 | loss: 0.3401033114806741 | accuracy: 0.8548810840707964 \n",
      "Epoch 9 | Step 3451 | loss: 0.34023023505042826 | accuracy: 0.8547632158590308 \n",
      "Epoch 9 | Step 3452 | loss: 0.34011640308196084 | accuracy: 0.8548519736842105 \n",
      "Epoch 9 | Step 3453 | loss: 0.34002552087129984 | accuracy: 0.8546670305676856 \n",
      "Epoch 9 | Step 3454 | loss: 0.34007008386694865 | accuracy: 0.8547554347826087 \n",
      "Epoch 9 | Step 3455 | loss: 0.3396752285105841 | accuracy: 0.854978354978355 \n",
      "Epoch 9 | Step 3456 | loss: 0.3392992390255476 | accuracy: 0.855401400862069 \n",
      "Epoch 9 | Step 3457 | loss: 0.3393984982512028 | accuracy: 0.8554184549356223 \n",
      "Epoch 9 | Step 3458 | loss: 0.3393453733406515 | accuracy: 0.8554353632478633 \n",
      "Epoch 9 | Step 3459 | loss: 0.3389131482611311 | accuracy: 0.855718085106383 \n",
      "Epoch 9 | Step 3460 | loss: 0.33860083934614216 | accuracy: 0.8559322033898306 \n",
      "Epoch 9 | Step 3461 | loss: 0.33839303858672515 | accuracy: 0.8560785864978903 \n",
      "Epoch 9 | Step 3462 | loss: 0.3384579760687692 | accuracy: 0.8559611344537815 \n",
      "Epoch 9 | Step 3463 | loss: 0.338548697936485 | accuracy: 0.8559100418410042 \n",
      "Epoch 9 | Step 3464 | loss: 0.33826798386871815 | accuracy: 0.8559244791666667 \n",
      "Epoch 9 | Step 3465 | loss: 0.33757664071573756 | accuracy: 0.8563278008298755 \n",
      "Epoch 9 | Step 3466 | loss: 0.3370932565370867 | accuracy: 0.8565986570247934 \n",
      "Epoch 9 | Step 3467 | loss: 0.3372523239487974 | accuracy: 0.8567386831275721 \n",
      "Epoch 9 | Step 3468 | loss: 0.3375922812179464 | accuracy: 0.856749487704918 \n",
      "Epoch 9 | Step 3469 | loss: 0.3376987192703753 | accuracy: 0.8568239795918368 \n",
      "Epoch 9 | Step 3470 | loss: 0.33756160075829283 | accuracy: 0.8568978658536586 \n",
      "Epoch 9 | Step 3471 | loss: 0.33730580359094053 | accuracy: 0.8570344129554656 \n",
      "Epoch 9 | Step 3472 | loss: 0.3377215884505741 | accuracy: 0.8569808467741935 \n",
      "Epoch 9 | Step 3473 | loss: 0.33756324499247065 | accuracy: 0.8571787148594378 \n",
      "Epoch 9 | Step 3474 | loss: 0.33750988632440565 | accuracy: 0.85725 \n",
      "Epoch 9 | Step 3475 | loss: 0.3372431146314894 | accuracy: 0.8573207171314741 \n",
      "Epoch 9 | Step 3476 | loss: 0.3370029130980136 | accuracy: 0.857390873015873 \n",
      "Epoch 9 | Step 3477 | loss: 0.336892238659821 | accuracy: 0.857522233201581 \n",
      "Epoch 9 | Step 3478 | loss: 0.336819918430227 | accuracy: 0.8575910433070866 \n",
      "Epoch 9 | Step 3479 | loss: 0.33667864968963696 | accuracy: 0.8576593137254902 \n",
      "Epoch 9 | Step 3480 | loss: 0.33679190854309127 | accuracy: 0.8575439453125 \n",
      "Epoch 9 | Step 3481 | loss: 0.336558601793612 | accuracy: 0.8577334630350194 \n",
      "Epoch 9 | Step 3482 | loss: 0.33628006435410923 | accuracy: 0.8576792635658915 \n",
      "Epoch 9 | Step 3483 | loss: 0.3364394795595449 | accuracy: 0.8576858108108109 \n",
      "Epoch 9 | Step 3484 | loss: 0.33605199353053017 | accuracy: 0.8578125 \n",
      "Epoch 9 | Step 3485 | loss: 0.3366011258971189 | accuracy: 0.857698754789272 \n",
      "Epoch 9 | Step 3486 | loss: 0.33681557299071596 | accuracy: 0.8573473282442748 \n",
      "Epoch 9 | Step 3487 | loss: 0.3363646736843051 | accuracy: 0.8575332699619772 \n",
      "Epoch 9 | Step 3488 | loss: 0.3367609595033256 | accuracy: 0.8574810606060606 \n",
      "Epoch 9 | Step 3489 | loss: 0.33655919815009494 | accuracy: 0.8575471698113207 \n",
      "Epoch 9 | Step 3490 | loss: 0.336366582857935 | accuracy: 0.8575540413533834 \n",
      "Epoch 9 | Step 3491 | loss: 0.3360878634318877 | accuracy: 0.8577364232209738 \n",
      "Epoch 9 | Step 3492 | loss: 0.33608717449120623 | accuracy: 0.8577425373134329 \n",
      "Epoch 9 | Step 3493 | loss: 0.33603101514529116 | accuracy: 0.8578066914498141 \n",
      "Epoch 9 | Step 3494 | loss: 0.335804455699744 | accuracy: 0.8579282407407407 \n",
      "Epoch 9 | Step 3495 | loss: 0.33581482275385693 | accuracy: 0.8579335793357934 \n",
      "Epoch 9 | Step 3496 | loss: 0.33570888375534724 | accuracy: 0.8578239889705882 \n",
      "Epoch 9 | Step 3497 | loss: 0.3358482074388217 | accuracy: 0.857657967032967 \n",
      "Epoch 9 | Step 3498 | loss: 0.33581437964509 | accuracy: 0.8576072080291971 \n",
      "Epoch 9 | Step 3499 | loss: 0.33562229514122005 | accuracy: 0.8577272727272728 \n",
      "Epoch 9 | Step 3500 | loss: 0.3359107999266057 | accuracy: 0.857506793478261 \n",
      "Epoch 9 | Step 3501 | loss: 0.3357858873016137 | accuracy: 0.8574007220216607 \n",
      "Epoch 9 | Step 3502 | loss: 0.33550561610743296 | accuracy: 0.857576438848921 \n",
      "Epoch 9 | Step 3503 | loss: 0.3356214475460805 | accuracy: 0.8575268817204302 \n",
      "Epoch 9 | Step 3504 | loss: 0.33533573299646385 | accuracy: 0.8577008928571429 \n",
      "Epoch 9 | Step 3505 | loss: 0.33585644680410104 | accuracy: 0.857317615658363 \n",
      "Epoch 9 | Step 3506 | loss: 0.3356143134705565 | accuracy: 0.8573803191489362 \n",
      "Epoch 9 | Step 3507 | loss: 0.3357493899525687 | accuracy: 0.8574425795053003 \n",
      "Epoch 9 | Step 3508 | loss: 0.3355604182456582 | accuracy: 0.8575044014084507 \n",
      "Epoch 9 | Step 3509 | loss: 0.33542191197997656 | accuracy: 0.8575109649122807 \n",
      "Epoch 9 | Step 3510 | loss: 0.3354992331949982 | accuracy: 0.8574628496503497 \n",
      "Epoch 9 | Step 3511 | loss: 0.33522617951918154 | accuracy: 0.8574695121951219 \n",
      "Epoch 9 | Step 3512 | loss: 0.3349302910889189 | accuracy: 0.8576388888888888 \n",
      "Epoch 9 | Step 3513 | loss: 0.3347867187950439 | accuracy: 0.8576448961937716 \n",
      "Epoch 9 | Step 3514 | loss: 0.3352092882682538 | accuracy: 0.857489224137931 \n",
      "Epoch 9 | Step 3515 | loss: 0.3349696783880189 | accuracy: 0.8574957044673539 \n",
      "Epoch 9 | Step 3516 | loss: 0.33493365235116396 | accuracy: 0.8576091609589042 \n",
      "Epoch 9 | Step 3517 | loss: 0.33486014848683077 | accuracy: 0.8576151877133107 \n",
      "Epoch 9 | Step 3518 | loss: 0.33437881760654004 | accuracy: 0.8578869047619049 \n",
      "Epoch 9 | Step 3519 | loss: 0.3349729056580593 | accuracy: 0.8575211864406781 \n",
      "Epoch 9 | Step 3520 | loss: 0.33485864973752894 | accuracy: 0.8575274493243245 \n",
      "Epoch 9 | Step 3521 | loss: 0.3350567214115702 | accuracy: 0.8573758417508418 \n",
      "Epoch 9 | Step 3522 | loss: 0.3348701179727612 | accuracy: 0.8574349832214766 \n",
      "Epoch 9 | Step 3523 | loss: 0.3346279393570081 | accuracy: 0.8575982441471572 \n",
      "Epoch 9 | Step 3524 | loss: 0.3344371367990971 | accuracy: 0.8577083333333333 \n",
      "Epoch 9 | Step 3525 | loss: 0.3343398328932417 | accuracy: 0.857765780730897 \n",
      "Epoch 9 | Step 3526 | loss: 0.33430576023479175 | accuracy: 0.8577711092715232 \n",
      "Epoch 9 | Step 3527 | loss: 0.3339798354571409 | accuracy: 0.8579311056105611 \n",
      "Epoch 9 | Step 3528 | loss: 0.33392136656728233 | accuracy: 0.8579358552631579 \n",
      "Epoch 9 | Step 3529 | loss: 0.33436337548201206 | accuracy: 0.8576844262295082 \n",
      "Epoch 9 | Step 3530 | loss: 0.33403573185205465 | accuracy: 0.8578431372549019 \n",
      "Epoch 9 | Step 3531 | loss: 0.3339388168110522 | accuracy: 0.8579499185667753 \n",
      "Epoch 9 | Step 3532 | loss: 0.33369527152412903 | accuracy: 0.8579545454545454 \n",
      "Epoch 9 | Step 3533 | loss: 0.3331923258632518 | accuracy: 0.8583131067961165 \n",
      "Epoch 9 | Step 3534 | loss: 0.33302547475022654 | accuracy: 0.8584677419354839 \n",
      "Epoch 9 | Step 3535 | loss: 0.33292984804348164 | accuracy: 0.858621382636656 \n",
      "Epoch 9 | Step 3536 | loss: 0.3329462284365526 | accuracy: 0.858573717948718 \n",
      "Epoch 9 | Step 3537 | loss: 0.3328503008943777 | accuracy: 0.858526357827476 \n",
      "Epoch 9 | Step 3538 | loss: 0.33274713457579824 | accuracy: 0.8586285828025477 \n",
      "Epoch 9 | Step 3539 | loss: 0.33223361259415035 | accuracy: 0.8589285714285714 \n",
      "Epoch 9 | Step 3540 | loss: 0.332298226937463 | accuracy: 0.8588805379746836 \n",
      "Epoch 9 | Step 3541 | loss: 0.3323243134405335 | accuracy: 0.8589313880126183 \n",
      "Epoch 9 | Step 3542 | loss: 0.3323014222975797 | accuracy: 0.8588836477987422 \n",
      "Epoch 9 | Step 3543 | loss: 0.3322882038485668 | accuracy: 0.858689263322884 \n",
      "Epoch 9 | Step 3544 | loss: 0.332109254039824 | accuracy: 0.858935546875 \n",
      "Epoch 9 | Step 3545 | loss: 0.3321101534589429 | accuracy: 0.8588882398753894 \n",
      "Epoch 9 | Step 3546 | loss: 0.33191421655764497 | accuracy: 0.859083850931677 \n",
      "Epoch 9 | Step 3547 | loss: 0.331851704847702 | accuracy: 0.8590363777089783 \n",
      "Epoch 9 | Step 3548 | loss: 0.3318650152212308 | accuracy: 0.8589409722222222 \n",
      "Epoch 9 | Step 3549 | loss: 0.33199084199391876 | accuracy: 0.858798076923077 \n",
      "Epoch 9 | Step 3550 | loss: 0.3322200695612679 | accuracy: 0.8584643404907976 \n",
      "Epoch 9 | Step 3551 | loss: 0.3323365303172248 | accuracy: 0.8584193425076453 \n",
      "Epoch 9 | Step 3552 | loss: 0.3322418781860572 | accuracy: 0.8586128048780488 \n",
      "Epoch 9 | Step 3553 | loss: 0.3320964691667933 | accuracy: 0.8586626139817629 \n",
      "Epoch 9 | Step 3554 | loss: 0.3320962545546618 | accuracy: 0.8586647727272727 \n",
      "Epoch 9 | Step 3555 | loss: 0.33199866903872643 | accuracy: 0.858666918429003 \n",
      "Epoch 9 | Step 3556 | loss: 0.3318926303322056 | accuracy: 0.8586690512048193 \n",
      "Epoch 9 | Step 3557 | loss: 0.331784631575908 | accuracy: 0.8586711711711712 \n",
      "Epoch 9 | Step 3558 | loss: 0.3316683278469268 | accuracy: 0.858813622754491 \n",
      "Epoch 9 | Step 3559 | loss: 0.3316544817454779 | accuracy: 0.8586753731343284 \n",
      "Epoch 9 | Step 3560 | loss: 0.3315702398263272 | accuracy: 0.8586774553571429 \n",
      "Epoch 9 | Step 3561 | loss: 0.33167005160088353 | accuracy: 0.8585404302670623 \n",
      "Epoch 9 | Step 3562 | loss: 0.3314927542174356 | accuracy: 0.858542899408284 \n",
      "Epoch 9 | Step 3563 | loss: 0.3313371924172461 | accuracy: 0.8587297197640118 \n",
      "Epoch 9 | Step 3564 | loss: 0.3313239776912858 | accuracy: 0.8586397058823529 \n",
      "Epoch 9 | Step 3565 | loss: 0.33134330472638535 | accuracy: 0.858641862170088 \n",
      "Epoch 9 | Step 3566 | loss: 0.3311442306690049 | accuracy: 0.858781067251462 \n",
      "Epoch 9 | Step 3567 | loss: 0.3308206607666377 | accuracy: 0.8589194606413995 \n",
      "Epoch 9 | Step 3568 | loss: 0.33092715378937326 | accuracy: 0.858875363372093 \n",
      "Epoch 9 | Step 3569 | loss: 0.33069462374500597 | accuracy: 0.8591032608695652 \n",
      "Epoch 9 | Step 3570 | loss: 0.33050492642759577 | accuracy: 0.8593298410404624 \n",
      "Epoch 9 | Step 3571 | loss: 0.33038154059768743 | accuracy: 0.8595551152737753 \n",
      "Epoch 9 | Step 3572 | loss: 0.3302314655277235 | accuracy: 0.8596443965517241 \n",
      "Epoch 9 | Step 3573 | loss: 0.3301157095285404 | accuracy: 0.8596883954154728 \n",
      "Epoch 9 | Step 3574 | loss: 0.3304506733162062 | accuracy: 0.8594642857142857 \n",
      "Epoch 9 | Step 3575 | loss: 0.330113757964213 | accuracy: 0.859642094017094 \n",
      "Epoch 9 | Step 3576 | loss: 0.3300133503296159 | accuracy: 0.8595525568181818 \n",
      "Epoch 9 | Step 3577 | loss: 0.3300141711579504 | accuracy: 0.8595520538243626 \n",
      "Epoch 9 | Step 3578 | loss: 0.33016445752927814 | accuracy: 0.859375 \n",
      "Epoch 9 | Step 3579 | loss: 0.33002834647474155 | accuracy: 0.8594630281690141 \n",
      "Epoch 9 | Step 3580 | loss: 0.3297919813920273 | accuracy: 0.8595505617977528 \n",
      "Epoch 9 | Step 3581 | loss: 0.3300318970483225 | accuracy: 0.8594187675070029 \n",
      "Epoch 9 | Step 3582 | loss: 0.33036669943086266 | accuracy: 0.8592877094972067 \n",
      "Epoch 9 | Step 3583 | loss: 0.330099142735051 | accuracy: 0.8593314763231198 \n",
      "Epoch 9 | Step 3584 | loss: 0.330368776826395 | accuracy: 0.8592013888888889 \n",
      "Epoch 9 | Step 3585 | loss: 0.3301866387643973 | accuracy: 0.8591585872576177 \n",
      "Epoch 9 | Step 3586 | loss: 0.33002343580373744 | accuracy: 0.8592455110497238 \n",
      "Epoch 9 | Step 3587 | loss: 0.330040801039412 | accuracy: 0.85928891184573 \n",
      "Epoch 9 | Step 3588 | loss: 0.3295998151240113 | accuracy: 0.8595037774725275 \n",
      "Epoch 9 | Step 3589 | loss: 0.32941802956470073 | accuracy: 0.8596318493150685 \n",
      "Epoch 9 | Step 3590 | loss: 0.32943862998257567 | accuracy: 0.8597165300546448 \n",
      "Epoch 9 | Step 3591 | loss: 0.3296191638350811 | accuracy: 0.8595878746594006 \n",
      "Epoch 9 | Step 3592 | loss: 0.3294250127333013 | accuracy: 0.8596722146739131 \n",
      "Epoch 9 | Step 3593 | loss: 0.32954084198810857 | accuracy: 0.8597137533875339 \n",
      "Epoch 9 | Step 3594 | loss: 0.32957629952076306 | accuracy: 0.8597128378378378 \n",
      "Epoch 9 | Step 3595 | loss: 0.3297449516237905 | accuracy: 0.8594592318059299 \n",
      "Epoch 9 | Step 3596 | loss: 0.3296246495378272 | accuracy: 0.8594590053763441 \n",
      "Epoch 9 | Step 3597 | loss: 0.3292456323595531 | accuracy: 0.8597101206434317 \n",
      "Epoch 9 | Step 3598 | loss: 0.32905102549070964 | accuracy: 0.8598345588235294 \n",
      "Epoch 9 | Step 3599 | loss: 0.32928919370969123 | accuracy: 0.85975 \n",
      "Epoch 9 | Step 3600 | loss: 0.32934328525307316 | accuracy: 0.8597490026595744 \n",
      "Epoch 9 | Step 3601 | loss: 0.3293908105604843 | accuracy: 0.8595822281167109 \n",
      "Epoch 9 | Step 3602 | loss: 0.3293830556844276 | accuracy: 0.859375 \n",
      "Epoch 9 | Step 3603 | loss: 0.3291011859213141 | accuracy: 0.8594574538258575 \n",
      "Epoch 9 | Step 3604 | loss: 0.32898914751253616 | accuracy: 0.8594572368421053 \n",
      "Epoch 9 | Step 3605 | loss: 0.32860948556051467 | accuracy: 0.859744094488189 \n",
      "Epoch 9 | Step 3606 | loss: 0.3287465394479441 | accuracy: 0.85970222513089 \n",
      "Epoch 9 | Step 3607 | loss: 0.32881594139975595 | accuracy: 0.8597013707571801 \n",
      "Epoch 9 | Step 3608 | loss: 0.32901789566191525 | accuracy: 0.8597005208333334 \n",
      "Epoch 9 | Step 3609 | loss: 0.32889981881364594 | accuracy: 0.8597808441558441 \n",
      "Epoch 9 | Step 3610 | loss: 0.32884218547628324 | accuracy: 0.8598202720207254 \n",
      "Epoch 9 | Step 3611 | loss: 0.32895481994601794 | accuracy: 0.8597787467700259 \n",
      "Epoch 9 | Step 3612 | loss: 0.3290468637937123 | accuracy: 0.859777706185567 \n",
      "Epoch 9 | Step 3613 | loss: 0.32906182887928037 | accuracy: 0.8597365038560412 \n",
      "Epoch 9 | Step 3614 | loss: 0.3290565635913458 | accuracy: 0.8598557692307692 \n",
      "Epoch 9 | Step 3615 | loss: 0.32910451643607197 | accuracy: 0.8598545396419437 \n",
      "Epoch 9 | Step 3616 | loss: 0.3290207519823191 | accuracy: 0.8599330357142857 \n",
      "Epoch 9 | Step 3617 | loss: 0.32894601015037556 | accuracy: 0.8600508905852418 \n",
      "Epoch 9 | Step 3618 | loss: 0.3293070783318602 | accuracy: 0.8597715736040609 \n",
      "Epoch 9 | Step 3619 | loss: 0.32910324131386187 | accuracy: 0.8599287974683544 \n",
      "Epoch 9 | Step 3620 | loss: 0.3288787259071162 | accuracy: 0.8600063131313131 \n",
      "Epoch 9 | Step 3621 | loss: 0.3287916045720391 | accuracy: 0.8600834382871536 \n",
      "Epoch 9 | Step 3622 | loss: 0.3288724079877887 | accuracy: 0.8600031407035176 \n",
      "Epoch 9 | Step 3623 | loss: 0.32866242849139643 | accuracy: 0.8600407268170426 \n",
      "Epoch 9 | Step 3624 | loss: 0.32859465293586254 | accuracy: 0.8600390625 \n",
      "Epoch 9 | Step 3625 | loss: 0.32866815646687647 | accuracy: 0.859959476309227 \n",
      "Epoch 9 | Step 3626 | loss: 0.3287191577070388 | accuracy: 0.8599968905472637 \n",
      "Epoch 9 | Step 3627 | loss: 0.3285476887048622 | accuracy: 0.8599164670809327 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4604211747646332 | accuracy: 0.75 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4041684865951538 | accuracy: 0.8203125 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4231603741645813 | accuracy: 0.8177083333333334 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4266396313905716 | accuracy: 0.80859375 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.396959125995636 | accuracy: 0.825 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.41980214913686115 | accuracy: 0.8020833333333334 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.42005867617470877 | accuracy: 0.8035714285714286 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4121832549571991 | accuracy: 0.80859375 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4343796372413635 | accuracy: 0.8055555555555556 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4261007457971573 | accuracy: 0.809375 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4243452847003937 | accuracy: 0.8110795454545454 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.41363004346688587 | accuracy: 0.8151041666666666 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4151750963467818 | accuracy: 0.8137019230769231 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.41007716740880695 | accuracy: 0.8158482142857143 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.412676606575648 | accuracy: 0.81875 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4136101622134447 | accuracy: 0.8193359375 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.42356229003737955 | accuracy: 0.8170955882352942 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4225491136312485 | accuracy: 0.8177083333333334 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.417764276266098 | accuracy: 0.8199013157894737 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.414845609664917 | accuracy: 0.81875 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4103215067159562 | accuracy: 0.8206845238095238 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4069397178563205 | accuracy: 0.8224431818181818 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4119442208953526 | accuracy: 0.8192934782608695 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4255841597914696 | accuracy: 0.8151041666666666 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4311204767227173 | accuracy: 0.8125 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.42864225460932803 | accuracy: 0.8137019230769231 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4241497825693201 | accuracy: 0.8165509259259259 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.42382848262786865 | accuracy: 0.8169642857142857 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4203481211744506 | accuracy: 0.8178879310344828 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4174217998981476 | accuracy: 0.8203125 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.41330661792908946 | accuracy: 0.8225806451612904 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4167382149025798 | accuracy: 0.8193359375 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4180128014448917 | accuracy: 0.8191287878787878 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.42248759374899025 | accuracy: 0.8152573529411765 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4231864971773965 | accuracy: 0.8160714285714286 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.42082468337482876 | accuracy: 0.8172743055555556 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.421061075217015 | accuracy: 0.8175675675675675 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.42183881135363327 | accuracy: 0.8182565789473685 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.42162392689631534 | accuracy: 0.8185096153846155 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4201549679040909 | accuracy: 0.8203125000000002 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4173712257931872 | accuracy: 0.820503048780488 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.41496211999938604 | accuracy: 0.8203125000000002 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4148781777814377 | accuracy: 0.8204941860465118 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.4183965223756703 | accuracy: 0.817471590909091 \n",
      "Validation | Epoch 9 | Step 3627 | loss: 0.41711757845348785 | accuracy: 0.8171799514028762 \n",
      "Epoch 10 | Step 3628 | loss: 0.4455045759677887 | accuracy: 0.8125 \n",
      "Epoch 10 | Step 3629 | loss: 0.3292948231101036 | accuracy: 0.8515625 \n",
      "Epoch 10 | Step 3630 | loss: 0.3162178049484889 | accuracy: 0.875 \n",
      "Epoch 10 | Step 3631 | loss: 0.33407482132315636 | accuracy: 0.8671875 \n",
      "Epoch 10 | Step 3632 | loss: 0.3117440491914749 | accuracy: 0.875 \n",
      "Epoch 10 | Step 3633 | loss: 0.3040743445356687 | accuracy: 0.8802083333333334 \n",
      "Epoch 10 | Step 3634 | loss: 0.312328855906214 | accuracy: 0.8772321428571429 \n",
      "Epoch 10 | Step 3635 | loss: 0.3086010981351137 | accuracy: 0.876953125 \n",
      "Epoch 10 | Step 3636 | loss: 0.3201200481918123 | accuracy: 0.8715277777777778 \n",
      "Epoch 10 | Step 3637 | loss: 0.3302585378289223 | accuracy: 0.8671875 \n",
      "Epoch 10 | Step 3638 | loss: 0.32166107269850647 | accuracy: 0.8735795454545454 \n",
      "Epoch 10 | Step 3639 | loss: 0.31546672806143766 | accuracy: 0.875 \n",
      "Epoch 10 | Step 3640 | loss: 0.3267033822261371 | accuracy: 0.8653846153846154 \n",
      "Epoch 10 | Step 3641 | loss: 0.3224431010229248 | accuracy: 0.8683035714285714 \n",
      "Epoch 10 | Step 3642 | loss: 0.3217266728480658 | accuracy: 0.8666666666666667 \n",
      "Epoch 10 | Step 3643 | loss: 0.3140751132741571 | accuracy: 0.87109375 \n",
      "Epoch 10 | Step 3644 | loss: 0.3170194284004324 | accuracy: 0.8648897058823529 \n",
      "Epoch 10 | Step 3645 | loss: 0.3146167273322742 | accuracy: 0.8663194444444444 \n",
      "Epoch 10 | Step 3646 | loss: 0.31281265694844107 | accuracy: 0.868421052631579 \n",
      "Epoch 10 | Step 3647 | loss: 0.3156384982168675 | accuracy: 0.86796875 \n",
      "Epoch 10 | Step 3648 | loss: 0.31691942399456396 | accuracy: 0.8683035714285714 \n",
      "Epoch 10 | Step 3649 | loss: 0.31920257007533864 | accuracy: 0.8686079545454546 \n",
      "Epoch 10 | Step 3650 | loss: 0.31810494026412145 | accuracy: 0.8688858695652174 \n",
      "Epoch 10 | Step 3651 | loss: 0.3178879575182995 | accuracy: 0.8678385416666666 \n",
      "Epoch 10 | Step 3652 | loss: 0.3224355560541154 | accuracy: 0.866875 \n",
      "Epoch 10 | Step 3653 | loss: 0.32401364640547686 | accuracy: 0.8653846153846154 \n",
      "Epoch 10 | Step 3654 | loss: 0.32661276227898073 | accuracy: 0.8640046296296297 \n",
      "Epoch 10 | Step 3655 | loss: 0.3246876038610936 | accuracy: 0.8666294642857143 \n",
      "Epoch 10 | Step 3656 | loss: 0.3276649153438108 | accuracy: 0.8663793103448276 \n",
      "Epoch 10 | Step 3657 | loss: 0.32725137720505404 | accuracy: 0.8661458333333333 \n",
      "Epoch 10 | Step 3658 | loss: 0.3252035413057574 | accuracy: 0.8674395161290323 \n",
      "Epoch 10 | Step 3659 | loss: 0.3246878008358181 | accuracy: 0.8671875 \n",
      "Epoch 10 | Step 3660 | loss: 0.3250210930903753 | accuracy: 0.8664772727272727 \n",
      "Epoch 10 | Step 3661 | loss: 0.32192003463997565 | accuracy: 0.8676470588235294 \n",
      "Epoch 10 | Step 3662 | loss: 0.3184184721537999 | accuracy: 0.86875 \n",
      "Epoch 10 | Step 3663 | loss: 0.31741360906097627 | accuracy: 0.8689236111111112 \n",
      "Epoch 10 | Step 3664 | loss: 0.317242247832788 | accuracy: 0.8690878378378378 \n",
      "Epoch 10 | Step 3665 | loss: 0.31914062092178747 | accuracy: 0.868421052631579 \n",
      "Epoch 10 | Step 3666 | loss: 0.31709877917399776 | accuracy: 0.8697916666666666 \n",
      "Epoch 10 | Step 3667 | loss: 0.31504898071289067 | accuracy: 0.8703125 \n",
      "Epoch 10 | Step 3668 | loss: 0.31674971740420277 | accuracy: 0.870045731707317 \n",
      "Epoch 10 | Step 3669 | loss: 0.31715739341009236 | accuracy: 0.8690476190476191 \n",
      "Epoch 10 | Step 3670 | loss: 0.31565700991209167 | accuracy: 0.8699127906976745 \n",
      "Epoch 10 | Step 3671 | loss: 0.314104419878938 | accuracy: 0.87109375 \n",
      "Epoch 10 | Step 3672 | loss: 0.31476264430416956 | accuracy: 0.8715277777777778 \n",
      "Epoch 10 | Step 3673 | loss: 0.3154062644942947 | accuracy: 0.8709239130434783 \n",
      "Epoch 10 | Step 3674 | loss: 0.31625948592703396 | accuracy: 0.8706781914893617 \n",
      "Epoch 10 | Step 3675 | loss: 0.31691919049868983 | accuracy: 0.8701171875 \n",
      "Epoch 10 | Step 3676 | loss: 0.31881407906814496 | accuracy: 0.8695790816326531 \n",
      "Epoch 10 | Step 3677 | loss: 0.3197969755530357 | accuracy: 0.8690625 \n",
      "Epoch 10 | Step 3678 | loss: 0.31887417009063795 | accuracy: 0.8697916666666666 \n",
      "Epoch 10 | Step 3679 | loss: 0.31731241282362205 | accuracy: 0.8701923076923077 \n",
      "Epoch 10 | Step 3680 | loss: 0.31848544641485754 | accuracy: 0.8693985849056604 \n",
      "Epoch 10 | Step 3681 | loss: 0.3174837377888185 | accuracy: 0.8697916666666666 \n",
      "Epoch 10 | Step 3682 | loss: 0.31743513372811405 | accuracy: 0.8698863636363636 \n",
      "Epoch 10 | Step 3683 | loss: 0.3175164878900562 | accuracy: 0.8702566964285714 \n",
      "Epoch 10 | Step 3684 | loss: 0.3183533562379971 | accuracy: 0.8695175438596491 \n",
      "Epoch 10 | Step 3685 | loss: 0.31837504614016104 | accuracy: 0.8696120689655172 \n",
      "Epoch 10 | Step 3686 | loss: 0.32012115772497857 | accuracy: 0.8697033898305084 \n",
      "Epoch 10 | Step 3687 | loss: 0.32000219598412516 | accuracy: 0.8697916666666666 \n",
      "Epoch 10 | Step 3688 | loss: 0.31881343561117764 | accuracy: 0.8706454918032787 \n",
      "Epoch 10 | Step 3689 | loss: 0.31820988198441846 | accuracy: 0.8712197580645161 \n",
      "Epoch 10 | Step 3690 | loss: 0.3195371809932921 | accuracy: 0.8707837301587301 \n",
      "Epoch 10 | Step 3691 | loss: 0.31773687642998993 | accuracy: 0.87158203125 \n",
      "Epoch 10 | Step 3692 | loss: 0.3165555933347115 | accuracy: 0.8721153846153846 \n",
      "Epoch 10 | Step 3693 | loss: 0.3155410271702391 | accuracy: 0.8723958333333334 \n",
      "Epoch 10 | Step 3694 | loss: 0.3144165662242405 | accuracy: 0.8726679104477612 \n",
      "Epoch 10 | Step 3695 | loss: 0.3142271385911633 | accuracy: 0.8717830882352942 \n",
      "Epoch 10 | Step 3696 | loss: 0.3145633104486742 | accuracy: 0.8716032608695652 \n",
      "Epoch 10 | Step 3697 | loss: 0.31336959451436996 | accuracy: 0.871875 \n",
      "Epoch 10 | Step 3698 | loss: 0.312161428827635 | accuracy: 0.8723591549295775 \n",
      "Epoch 10 | Step 3699 | loss: 0.3117227666079998 | accuracy: 0.8723958333333334 \n",
      "Epoch 10 | Step 3700 | loss: 0.31144600004366 | accuracy: 0.8722174657534246 \n",
      "Epoch 10 | Step 3701 | loss: 0.3112729103178592 | accuracy: 0.8722550675675675 \n",
      "Epoch 10 | Step 3702 | loss: 0.31105805993080143 | accuracy: 0.8716666666666667 \n",
      "Epoch 10 | Step 3703 | loss: 0.3107763281778286 | accuracy: 0.8721217105263158 \n",
      "Epoch 10 | Step 3704 | loss: 0.3100914196534591 | accuracy: 0.872362012987013 \n",
      "Epoch 10 | Step 3705 | loss: 0.3106815562798428 | accuracy: 0.8717948717948718 \n",
      "Epoch 10 | Step 3706 | loss: 0.31280340009097823 | accuracy: 0.8708465189873418 \n",
      "Epoch 10 | Step 3707 | loss: 0.3129447020590307 | accuracy: 0.8705078125 \n",
      "Epoch 10 | Step 3708 | loss: 0.3123683005939297 | accuracy: 0.8705632716049383 \n",
      "Epoch 10 | Step 3709 | loss: 0.3117239998608103 | accuracy: 0.8706173780487805 \n",
      "Epoch 10 | Step 3710 | loss: 0.31183474609650785 | accuracy: 0.8706701807228916 \n",
      "Epoch 10 | Step 3711 | loss: 0.31147948439632167 | accuracy: 0.8709077380952381 \n",
      "Epoch 10 | Step 3712 | loss: 0.31070549803621655 | accuracy: 0.8711397058823529 \n",
      "Epoch 10 | Step 3713 | loss: 0.3107721729334013 | accuracy: 0.8708212209302325 \n",
      "Epoch 10 | Step 3714 | loss: 0.312942369573418 | accuracy: 0.8697916666666666 \n",
      "Epoch 10 | Step 3715 | loss: 0.31323046677491906 | accuracy: 0.8700284090909091 \n",
      "Epoch 10 | Step 3716 | loss: 0.311749154764615 | accuracy: 0.8707865168539326 \n",
      "Epoch 10 | Step 3717 | loss: 0.31249184128310975 | accuracy: 0.8704861111111111 \n",
      "Epoch 10 | Step 3718 | loss: 0.3115281192483486 | accuracy: 0.8708791208791209 \n",
      "Epoch 10 | Step 3719 | loss: 0.31068693263375274 | accuracy: 0.8712635869565217 \n",
      "Epoch 10 | Step 3720 | loss: 0.3105101684729262 | accuracy: 0.871135752688172 \n",
      "Epoch 10 | Step 3721 | loss: 0.31033688561713474 | accuracy: 0.8715093085106383 \n",
      "Epoch 10 | Step 3722 | loss: 0.31093877428456385 | accuracy: 0.8713815789473685 \n",
      "Epoch 10 | Step 3723 | loss: 0.312900455358128 | accuracy: 0.8707682291666666 \n",
      "Epoch 10 | Step 3724 | loss: 0.31361556483298253 | accuracy: 0.8706507731958762 \n",
      "Epoch 10 | Step 3725 | loss: 0.3147636478652761 | accuracy: 0.8703762755102041 \n",
      "Epoch 10 | Step 3726 | loss: 0.31427452449846766 | accuracy: 0.8705808080808081 \n",
      "Epoch 10 | Step 3727 | loss: 0.3134391787648203 | accuracy: 0.870625 \n",
      "Epoch 10 | Step 3728 | loss: 0.31218336316028467 | accuracy: 0.8711324257425742 \n",
      "Epoch 10 | Step 3729 | loss: 0.3120541182510995 | accuracy: 0.8714767156862745 \n",
      "Epoch 10 | Step 3730 | loss: 0.31122847277562615 | accuracy: 0.8718143203883495 \n",
      "Epoch 10 | Step 3731 | loss: 0.3121426052485523 | accuracy: 0.8712439903846154 \n",
      "Epoch 10 | Step 3732 | loss: 0.3131241416647323 | accuracy: 0.8708333333333333 \n",
      "Epoch 10 | Step 3733 | loss: 0.3126392219707653 | accuracy: 0.870872641509434 \n",
      "Epoch 10 | Step 3734 | loss: 0.31377039320558053 | accuracy: 0.8704731308411215 \n",
      "Epoch 10 | Step 3735 | loss: 0.31476532212562053 | accuracy: 0.8696469907407407 \n",
      "Epoch 10 | Step 3736 | loss: 0.3149633922981562 | accuracy: 0.869552752293578 \n",
      "Epoch 10 | Step 3737 | loss: 0.3159020972522824 | accuracy: 0.8690340909090909 \n",
      "Epoch 10 | Step 3738 | loss: 0.3154893234237896 | accuracy: 0.8689470720720721 \n",
      "Epoch 10 | Step 3739 | loss: 0.3153181473857592 | accuracy: 0.8688616071428571 \n",
      "Epoch 10 | Step 3740 | loss: 0.31605452813405926 | accuracy: 0.8685011061946902 \n",
      "Epoch 10 | Step 3741 | loss: 0.3171951238784876 | accuracy: 0.8677357456140351 \n",
      "Epoch 10 | Step 3742 | loss: 0.31710555462733575 | accuracy: 0.8676630434782608 \n",
      "Epoch 10 | Step 3743 | loss: 0.31687541935464447 | accuracy: 0.8678609913793104 \n",
      "Epoch 10 | Step 3744 | loss: 0.3176207011326767 | accuracy: 0.8673878205128205 \n",
      "Epoch 10 | Step 3745 | loss: 0.3181874210299073 | accuracy: 0.8671875 \n",
      "Epoch 10 | Step 3746 | loss: 0.31800388375751126 | accuracy: 0.867515756302521 \n",
      "Epoch 10 | Step 3747 | loss: 0.3175002896537385 | accuracy: 0.8678385416666666 \n",
      "Epoch 10 | Step 3748 | loss: 0.3171589464441806 | accuracy: 0.8680268595041323 \n",
      "Epoch 10 | Step 3749 | loss: 0.31731602683907667 | accuracy: 0.867827868852459 \n",
      "Epoch 10 | Step 3750 | loss: 0.3173467944550322 | accuracy: 0.8677591463414634 \n",
      "Epoch 10 | Step 3751 | loss: 0.3175361369165684 | accuracy: 0.8678175403225806 \n",
      "Epoch 10 | Step 3752 | loss: 0.3180286937952043 | accuracy: 0.867375 \n",
      "Epoch 10 | Step 3753 | loss: 0.3177859044027709 | accuracy: 0.8675595238095238 \n",
      "Epoch 10 | Step 3754 | loss: 0.31801708488483144 | accuracy: 0.8673720472440944 \n",
      "Epoch 10 | Step 3755 | loss: 0.3173264386132361 | accuracy: 0.86767578125 \n",
      "Epoch 10 | Step 3756 | loss: 0.3172280488088151 | accuracy: 0.8673691860465116 \n",
      "Epoch 10 | Step 3757 | loss: 0.3168067001379455 | accuracy: 0.8676682692307692 \n",
      "Epoch 10 | Step 3758 | loss: 0.31762131206861904 | accuracy: 0.867604961832061 \n",
      "Epoch 10 | Step 3759 | loss: 0.31854253510634123 | accuracy: 0.8673058712121212 \n",
      "Epoch 10 | Step 3760 | loss: 0.3198311100328777 | accuracy: 0.8666588345864662 \n",
      "Epoch 10 | Step 3761 | loss: 0.32014357154049106 | accuracy: 0.8662546641791045 \n",
      "Epoch 10 | Step 3762 | loss: 0.32028965199435216 | accuracy: 0.8662037037037037 \n",
      "Epoch 10 | Step 3763 | loss: 0.3199573774986409 | accuracy: 0.8664981617647058 \n",
      "Epoch 10 | Step 3764 | loss: 0.3193520803521151 | accuracy: 0.8669023722627737 \n",
      "Epoch 10 | Step 3765 | loss: 0.3189976269352265 | accuracy: 0.8670742753623187 \n",
      "Epoch 10 | Step 3766 | loss: 0.31958119238880917 | accuracy: 0.8666816546762589 \n",
      "Epoch 10 | Step 3767 | loss: 0.31954063517706754 | accuracy: 0.8668526785714284 \n",
      "Epoch 10 | Step 3768 | loss: 0.320591375548789 | accuracy: 0.8664671985815602 \n",
      "Epoch 10 | Step 3769 | loss: 0.3206604643606806 | accuracy: 0.8664172535211266 \n",
      "Epoch 10 | Step 3770 | loss: 0.3212120503812405 | accuracy: 0.8660402097902097 \n",
      "Epoch 10 | Step 3771 | loss: 0.321544996980164 | accuracy: 0.8657769097222221 \n",
      "Epoch 10 | Step 3772 | loss: 0.3214359530087177 | accuracy: 0.8658405172413792 \n",
      "Epoch 10 | Step 3773 | loss: 0.32171672970464804 | accuracy: 0.8655821917808219 \n",
      "Epoch 10 | Step 3774 | loss: 0.3209519427852568 | accuracy: 0.8660714285714285 \n",
      "Epoch 10 | Step 3775 | loss: 0.321087337929655 | accuracy: 0.8658150337837838 \n",
      "Epoch 10 | Step 3776 | loss: 0.3210409984692634 | accuracy: 0.8655620805369127 \n",
      "Epoch 10 | Step 3777 | loss: 0.32125670442978566 | accuracy: 0.865625 \n",
      "Epoch 10 | Step 3778 | loss: 0.3213919656758279 | accuracy: 0.8656870860927153 \n",
      "Epoch 10 | Step 3779 | loss: 0.3220195722227036 | accuracy: 0.8654399671052632 \n",
      "Epoch 10 | Step 3780 | loss: 0.32203200118604075 | accuracy: 0.8654003267973857 \n",
      "Epoch 10 | Step 3781 | loss: 0.32168789256315755 | accuracy: 0.8656655844155844 \n",
      "Epoch 10 | Step 3782 | loss: 0.3214902538445691 | accuracy: 0.8657258064516129 \n",
      "Epoch 10 | Step 3783 | loss: 0.3206829822216281 | accuracy: 0.8662860576923077 \n",
      "Epoch 10 | Step 3784 | loss: 0.32083718564100355 | accuracy: 0.8664410828025477 \n",
      "Epoch 10 | Step 3785 | loss: 0.3210802791239343 | accuracy: 0.8662974683544303 \n",
      "Epoch 10 | Step 3786 | loss: 0.32150083780288724 | accuracy: 0.8658608490566038 \n",
      "Epoch 10 | Step 3787 | loss: 0.3218461340293291 | accuracy: 0.865625 \n",
      "Epoch 10 | Step 3788 | loss: 0.3219765302557385 | accuracy: 0.8654891304347826 \n",
      "Epoch 10 | Step 3789 | loss: 0.32225067122482987 | accuracy: 0.865258487654321 \n",
      "Epoch 10 | Step 3790 | loss: 0.32309313657825006 | accuracy: 0.8646472392638037 \n",
      "Epoch 10 | Step 3791 | loss: 0.3229466729411267 | accuracy: 0.8646150914634146 \n",
      "Epoch 10 | Step 3792 | loss: 0.32277042287768765 | accuracy: 0.8647727272727272 \n",
      "Epoch 10 | Step 3793 | loss: 0.3229396481470892 | accuracy: 0.8647402108433735 \n",
      "Epoch 10 | Step 3794 | loss: 0.32262578321074326 | accuracy: 0.8649887724550899 \n",
      "Epoch 10 | Step 3795 | loss: 0.32334356613102444 | accuracy: 0.8645833333333334 \n",
      "Epoch 10 | Step 3796 | loss: 0.3231586023900639 | accuracy: 0.864737426035503 \n",
      "Epoch 10 | Step 3797 | loss: 0.32230495591374037 | accuracy: 0.8652573529411764 \n",
      "Epoch 10 | Step 3798 | loss: 0.3221124821064768 | accuracy: 0.8653143274853801 \n",
      "Epoch 10 | Step 3799 | loss: 0.32216899088302353 | accuracy: 0.8650981104651163 \n",
      "Epoch 10 | Step 3800 | loss: 0.32199052536074163 | accuracy: 0.8651553468208093 \n",
      "Epoch 10 | Step 3801 | loss: 0.32196556091651174 | accuracy: 0.865301724137931 \n",
      "Epoch 10 | Step 3802 | loss: 0.32180161178112054 | accuracy: 0.8651785714285715 \n",
      "Epoch 10 | Step 3803 | loss: 0.3221648271957584 | accuracy: 0.865234375 \n",
      "Epoch 10 | Step 3804 | loss: 0.32302559019818844 | accuracy: 0.8650247175141242 \n",
      "Epoch 10 | Step 3805 | loss: 0.32349476059166254 | accuracy: 0.8646418539325843 \n",
      "Epoch 10 | Step 3806 | loss: 0.32383227256756275 | accuracy: 0.8645251396648045 \n",
      "Epoch 10 | Step 3807 | loss: 0.32344644988576593 | accuracy: 0.8645833333333334 \n",
      "Epoch 10 | Step 3808 | loss: 0.32369888001713326 | accuracy: 0.8641229281767956 \n",
      "Epoch 10 | Step 3809 | loss: 0.32336950981682494 | accuracy: 0.8640968406593407 \n",
      "Epoch 10 | Step 3810 | loss: 0.3225762913298739 | accuracy: 0.8644125683060109 \n",
      "Epoch 10 | Step 3811 | loss: 0.32202493488464684 | accuracy: 0.8645550271739131 \n",
      "Epoch 10 | Step 3812 | loss: 0.3218775421380999 | accuracy: 0.8646114864864864 \n",
      "Epoch 10 | Step 3813 | loss: 0.32220094298483243 | accuracy: 0.8645833333333334 \n",
      "Epoch 10 | Step 3814 | loss: 0.32269808195810284 | accuracy: 0.8643883689839572 \n",
      "Epoch 10 | Step 3815 | loss: 0.3228922168466641 | accuracy: 0.8641954787234043 \n",
      "Epoch 10 | Step 3816 | loss: 0.32270045815006154 | accuracy: 0.8642526455026455 \n",
      "Epoch 10 | Step 3817 | loss: 0.3233918938981861 | accuracy: 0.8640625 \n",
      "Epoch 10 | Step 3818 | loss: 0.3227883212229346 | accuracy: 0.8644469895287958 \n",
      "Epoch 10 | Step 3819 | loss: 0.3224357264116408 | accuracy: 0.8646647135416666 \n",
      "Epoch 10 | Step 3820 | loss: 0.3220664522190787 | accuracy: 0.8651230569948186 \n",
      "Epoch 10 | Step 3821 | loss: 0.3217993395537446 | accuracy: 0.8654961340206185 \n",
      "Epoch 10 | Step 3822 | loss: 0.32160615141575166 | accuracy: 0.865625 \n",
      "Epoch 10 | Step 3823 | loss: 0.3216920309529014 | accuracy: 0.865593112244898 \n",
      "Epoch 10 | Step 3824 | loss: 0.32167340081355306 | accuracy: 0.8654822335025381 \n",
      "Epoch 10 | Step 3825 | loss: 0.3216486339918292 | accuracy: 0.8656092171717171 \n",
      "Epoch 10 | Step 3826 | loss: 0.32133535763726173 | accuracy: 0.865891959798995 \n",
      "Epoch 10 | Step 3827 | loss: 0.3208959244191648 | accuracy: 0.866015625 \n",
      "Epoch 10 | Step 3828 | loss: 0.3216406130672096 | accuracy: 0.8656716417910447 \n",
      "Epoch 10 | Step 3829 | loss: 0.3213845339446966 | accuracy: 0.8657951732673267 \n",
      "Epoch 10 | Step 3830 | loss: 0.3213267160460281 | accuracy: 0.8657635467980296 \n",
      "Epoch 10 | Step 3831 | loss: 0.32118230809768056 | accuracy: 0.8660386029411765 \n",
      "Epoch 10 | Step 3832 | loss: 0.3213354263363816 | accuracy: 0.865625 \n",
      "Epoch 10 | Step 3833 | loss: 0.3221355720052443 | accuracy: 0.8654429611650486 \n",
      "Epoch 10 | Step 3834 | loss: 0.32268732152699287 | accuracy: 0.8653381642512077 \n",
      "Epoch 10 | Step 3835 | loss: 0.3225410698124997 | accuracy: 0.8653846153846154 \n",
      "Epoch 10 | Step 3836 | loss: 0.3222605845574558 | accuracy: 0.8655053827751196 \n",
      "Epoch 10 | Step 3837 | loss: 0.32236562059039175 | accuracy: 0.8657738095238096 \n",
      "Epoch 10 | Step 3838 | loss: 0.3224921749101432 | accuracy: 0.8656694312796208 \n",
      "Epoch 10 | Step 3839 | loss: 0.3218366466462613 | accuracy: 0.8659345518867925 \n",
      "Epoch 10 | Step 3840 | loss: 0.321407221012832 | accuracy: 0.8659771126760564 \n",
      "Epoch 10 | Step 3841 | loss: 0.32148363100034066 | accuracy: 0.8658732476635514 \n",
      "Epoch 10 | Step 3842 | loss: 0.3212542536646822 | accuracy: 0.865843023255814 \n",
      "Epoch 10 | Step 3843 | loss: 0.3212219613293808 | accuracy: 0.8659577546296297 \n",
      "Epoch 10 | Step 3844 | loss: 0.32092496725271386 | accuracy: 0.8659994239631337 \n",
      "Epoch 10 | Step 3845 | loss: 0.32091018502865376 | accuracy: 0.8659690366972477 \n",
      "Epoch 10 | Step 3846 | loss: 0.3208812449348573 | accuracy: 0.8659389269406392 \n",
      "Epoch 10 | Step 3847 | loss: 0.3208790566433561 | accuracy: 0.8659801136363636 \n",
      "Epoch 10 | Step 3848 | loss: 0.3208315856586216 | accuracy: 0.8661623303167421 \n",
      "Epoch 10 | Step 3849 | loss: 0.32073719638424963 | accuracy: 0.8662021396396397 \n",
      "Epoch 10 | Step 3850 | loss: 0.3207405601114437 | accuracy: 0.8660313901345291 \n",
      "Epoch 10 | Step 3851 | loss: 0.32017696575660803 | accuracy: 0.8664899553571429 \n",
      "Epoch 10 | Step 3852 | loss: 0.3200306950012844 | accuracy: 0.8665277777777778 \n",
      "Epoch 10 | Step 3853 | loss: 0.32008618175719705 | accuracy: 0.866496128318584 \n",
      "Epoch 10 | Step 3854 | loss: 0.3201747990258466 | accuracy: 0.8662582599118943 \n",
      "Epoch 10 | Step 3855 | loss: 0.3202491051664479 | accuracy: 0.866296600877193 \n",
      "Epoch 10 | Step 3856 | loss: 0.32029665030506516 | accuracy: 0.8661299126637555 \n",
      "Epoch 10 | Step 3857 | loss: 0.3202569208067398 | accuracy: 0.8661684782608695 \n",
      "Epoch 10 | Step 3858 | loss: 0.3198182765410577 | accuracy: 0.8664096320346321 \n",
      "Epoch 10 | Step 3859 | loss: 0.31939916897179765 | accuracy: 0.8668507543103449 \n",
      "Epoch 10 | Step 3860 | loss: 0.3193791875128072 | accuracy: 0.8669527896995708 \n",
      "Epoch 10 | Step 3861 | loss: 0.3193967894483836 | accuracy: 0.8670539529914529 \n",
      "Epoch 10 | Step 3862 | loss: 0.31907486230769067 | accuracy: 0.8672872340425531 \n",
      "Epoch 10 | Step 3863 | loss: 0.3186289784893142 | accuracy: 0.8676509533898306 \n",
      "Epoch 10 | Step 3864 | loss: 0.3184506746661312 | accuracy: 0.8678138185654009 \n",
      "Epoch 10 | Step 3865 | loss: 0.31842546647085873 | accuracy: 0.8676470588235294 \n",
      "Epoch 10 | Step 3866 | loss: 0.31835386437601637 | accuracy: 0.8677432008368201 \n",
      "Epoch 10 | Step 3867 | loss: 0.3182688511287174 | accuracy: 0.8677083333333333 \n",
      "Epoch 10 | Step 3868 | loss: 0.3176696808753668 | accuracy: 0.867933091286307 \n",
      "Epoch 10 | Step 3869 | loss: 0.3171282576874269 | accuracy: 0.8681559917355371 \n",
      "Epoch 10 | Step 3870 | loss: 0.3174010998427624 | accuracy: 0.8681198559670782 \n",
      "Epoch 10 | Step 3871 | loss: 0.31770912789907624 | accuracy: 0.8679559426229508 \n",
      "Epoch 10 | Step 3872 | loss: 0.3177260869619799 | accuracy: 0.8679846938775511 \n",
      "Epoch 10 | Step 3873 | loss: 0.3175217207612062 | accuracy: 0.8682037601626016 \n",
      "Epoch 10 | Step 3874 | loss: 0.3172418405169901 | accuracy: 0.8684843117408907 \n",
      "Epoch 10 | Step 3875 | loss: 0.31768790163820804 | accuracy: 0.8683215725806451 \n",
      "Epoch 10 | Step 3876 | loss: 0.3174518492805911 | accuracy: 0.8683483935742972 \n",
      "Epoch 10 | Step 3877 | loss: 0.31734869968891155 | accuracy: 0.868375 \n",
      "Epoch 10 | Step 3878 | loss: 0.3171686562171496 | accuracy: 0.8684636454183267 \n",
      "Epoch 10 | Step 3879 | loss: 0.3169751391997414 | accuracy: 0.8684275793650794 \n",
      "Epoch 10 | Step 3880 | loss: 0.31677570326526183 | accuracy: 0.8686388339920948 \n",
      "Epoch 10 | Step 3881 | loss: 0.3167737869061824 | accuracy: 0.8686023622047244 \n",
      "Epoch 10 | Step 3882 | loss: 0.31668622108066796 | accuracy: 0.868688725490196 \n",
      "Epoch 10 | Step 3883 | loss: 0.3167084068991245 | accuracy: 0.86865234375 \n",
      "Epoch 10 | Step 3884 | loss: 0.31657377859497826 | accuracy: 0.8686162451361867 \n",
      "Epoch 10 | Step 3885 | loss: 0.3161993474923364 | accuracy: 0.8687621124031008 \n",
      "Epoch 10 | Step 3886 | loss: 0.3163444514900562 | accuracy: 0.8686655405405406 \n",
      "Epoch 10 | Step 3887 | loss: 0.3159665974860009 | accuracy: 0.8688100961538462 \n",
      "Epoch 10 | Step 3888 | loss: 0.31659748025552537 | accuracy: 0.8684147509578544 \n",
      "Epoch 10 | Step 3889 | loss: 0.3167572565774882 | accuracy: 0.8682609732824428 \n",
      "Epoch 10 | Step 3890 | loss: 0.31643143857160005 | accuracy: 0.8684054182509505 \n",
      "Epoch 10 | Step 3891 | loss: 0.31678661224291194 | accuracy: 0.8683712121212122 \n",
      "Epoch 10 | Step 3892 | loss: 0.3166446054319167 | accuracy: 0.8683372641509434 \n",
      "Epoch 10 | Step 3893 | loss: 0.3164072181833419 | accuracy: 0.8683035714285714 \n",
      "Epoch 10 | Step 3894 | loss: 0.3163062510977078 | accuracy: 0.8682116104868914 \n",
      "Epoch 10 | Step 3895 | loss: 0.31637414283494464 | accuracy: 0.8682369402985075 \n",
      "Epoch 10 | Step 3896 | loss: 0.31644540388123266 | accuracy: 0.8682620817843866 \n",
      "Epoch 10 | Step 3897 | loss: 0.31625146330506726 | accuracy: 0.868287037037037 \n",
      "Epoch 10 | Step 3898 | loss: 0.3164010213419961 | accuracy: 0.8683118081180812 \n",
      "Epoch 10 | Step 3899 | loss: 0.3162786571089837 | accuracy: 0.8682789522058824 \n",
      "Epoch 10 | Step 3900 | loss: 0.3164652354005493 | accuracy: 0.8680173992673993 \n",
      "Epoch 10 | Step 3901 | loss: 0.31642369713878993 | accuracy: 0.867871806569343 \n",
      "Epoch 10 | Step 3902 | loss: 0.3163791602849962 | accuracy: 0.867840909090909 \n",
      "Epoch 10 | Step 3903 | loss: 0.3167039038802404 | accuracy: 0.8676403985507246 \n",
      "Epoch 10 | Step 3904 | loss: 0.31657217658168585 | accuracy: 0.8677233754512635 \n",
      "Epoch 10 | Step 3905 | loss: 0.3163161654052118 | accuracy: 0.8680867805755396 \n",
      "Epoch 10 | Step 3906 | loss: 0.31658445699240584 | accuracy: 0.8676635304659498 \n",
      "Epoch 10 | Step 3907 | loss: 0.3162703394357648 | accuracy: 0.8679129464285714 \n",
      "Epoch 10 | Step 3908 | loss: 0.31659937207172784 | accuracy: 0.8675489323843416 \n",
      "Epoch 10 | Step 3909 | loss: 0.3163692108388489 | accuracy: 0.8675199468085106 \n",
      "Epoch 10 | Step 3910 | loss: 0.31632840048929833 | accuracy: 0.8675463780918727 \n",
      "Epoch 10 | Step 3911 | loss: 0.3161216529847031 | accuracy: 0.8676826584507041 \n",
      "Epoch 10 | Step 3912 | loss: 0.3159664806043893 | accuracy: 0.8678179824561403 \n",
      "Epoch 10 | Step 3913 | loss: 0.31598902848008636 | accuracy: 0.8678430944055943 \n",
      "Epoch 10 | Step 3914 | loss: 0.3157846998773801 | accuracy: 0.8678680313588849 \n",
      "Epoch 10 | Step 3915 | loss: 0.31562652081872034 | accuracy: 0.8678927951388888 \n",
      "Epoch 10 | Step 3916 | loss: 0.3154338318274509 | accuracy: 0.8678092560553633 \n",
      "Epoch 10 | Step 3917 | loss: 0.3156382669148775 | accuracy: 0.8677262931034483 \n",
      "Epoch 10 | Step 3918 | loss: 0.31543896375448033 | accuracy: 0.8677512886597938 \n",
      "Epoch 10 | Step 3919 | loss: 0.31537785651545014 | accuracy: 0.8679366438356164 \n",
      "Epoch 10 | Step 3920 | loss: 0.3153887343793193 | accuracy: 0.8680140784982935 \n",
      "Epoch 10 | Step 3921 | loss: 0.3149121121383039 | accuracy: 0.8683035714285714 \n",
      "Epoch 10 | Step 3922 | loss: 0.3155311688023099 | accuracy: 0.8679025423728813 \n",
      "Epoch 10 | Step 3923 | loss: 0.3154068710534154 | accuracy: 0.8679793074324325 \n",
      "Epoch 10 | Step 3924 | loss: 0.3157919385918865 | accuracy: 0.8676872895622896 \n",
      "Epoch 10 | Step 3925 | loss: 0.3157572548761464 | accuracy: 0.8676593959731543 \n",
      "Epoch 10 | Step 3926 | loss: 0.3156170271411788 | accuracy: 0.8677362040133779 \n",
      "Epoch 10 | Step 3927 | loss: 0.3154017971456051 | accuracy: 0.8678125 \n",
      "Epoch 10 | Step 3928 | loss: 0.3152253842135997 | accuracy: 0.8680440199335548 \n",
      "Epoch 10 | Step 3929 | loss: 0.31530736697628015 | accuracy: 0.8680153145695364 \n",
      "Epoch 10 | Step 3930 | loss: 0.3150372984189012 | accuracy: 0.8680899339933993 \n",
      "Epoch 10 | Step 3931 | loss: 0.3149266320427782 | accuracy: 0.8680612664473685 \n",
      "Epoch 10 | Step 3932 | loss: 0.3153595974210833 | accuracy: 0.8676229508196721 \n",
      "Epoch 10 | Step 3933 | loss: 0.31506786178919227 | accuracy: 0.8676981209150327 \n",
      "Epoch 10 | Step 3934 | loss: 0.31493004176049744 | accuracy: 0.8678745928338762 \n",
      "Epoch 10 | Step 3935 | loss: 0.3145846353432575 | accuracy: 0.8679991883116883 \n",
      "Epoch 10 | Step 3936 | loss: 0.31409149826730337 | accuracy: 0.8682746763754046 \n",
      "Epoch 10 | Step 3937 | loss: 0.3140333977918471 | accuracy: 0.8682459677419355 \n",
      "Epoch 10 | Step 3938 | loss: 0.3139222580999423 | accuracy: 0.8684184083601286 \n",
      "Epoch 10 | Step 3939 | loss: 0.31400578827238995 | accuracy: 0.8680889423076923 \n",
      "Epoch 10 | Step 3940 | loss: 0.3139218098153702 | accuracy: 0.8680111821086262 \n",
      "Epoch 10 | Step 3941 | loss: 0.31388219664241096 | accuracy: 0.8680334394904459 \n",
      "Epoch 10 | Step 3942 | loss: 0.31339016296560795 | accuracy: 0.8683035714285714 \n",
      "Epoch 10 | Step 3943 | loss: 0.31348799239796926 | accuracy: 0.8682753164556962 \n",
      "Epoch 10 | Step 3944 | loss: 0.3134084334038786 | accuracy: 0.8682965299684543 \n",
      "Epoch 10 | Step 3945 | loss: 0.31340371011375634 | accuracy: 0.8682684748427673 \n",
      "Epoch 10 | Step 3946 | loss: 0.31328060639128796 | accuracy: 0.8682895768025078 \n",
      "Epoch 10 | Step 3947 | loss: 0.31311834747903056 | accuracy: 0.868505859375 \n",
      "Epoch 10 | Step 3948 | loss: 0.3130786580924305 | accuracy: 0.8685260903426791 \n",
      "Epoch 10 | Step 3949 | loss: 0.31294554430320404 | accuracy: 0.8686432453416149 \n",
      "Epoch 10 | Step 3950 | loss: 0.31298014055649204 | accuracy: 0.8686145510835913 \n",
      "Epoch 10 | Step 3951 | loss: 0.3129538931872375 | accuracy: 0.8685378086419753 \n",
      "Epoch 10 | Step 3952 | loss: 0.3129954780523595 | accuracy: 0.8684615384615385 \n",
      "Epoch 10 | Step 3953 | loss: 0.3131176582051934 | accuracy: 0.8682898773006135 \n",
      "Epoch 10 | Step 3954 | loss: 0.31330919543719815 | accuracy: 0.8681670489296636 \n",
      "Epoch 10 | Step 3955 | loss: 0.3132002060642331 | accuracy: 0.8682831554878049 \n",
      "Epoch 10 | Step 3956 | loss: 0.3129727028785869 | accuracy: 0.8684460486322189 \n",
      "Epoch 10 | Step 3957 | loss: 0.3129815889127328 | accuracy: 0.8683712121212122 \n",
      "Epoch 10 | Step 3958 | loss: 0.312899570810831 | accuracy: 0.8684384441087614 \n",
      "Epoch 10 | Step 3959 | loss: 0.31278495885521546 | accuracy: 0.8683640813253012 \n",
      "Epoch 10 | Step 3960 | loss: 0.31271483348654566 | accuracy: 0.8683370870870871 \n",
      "Epoch 10 | Step 3961 | loss: 0.31266105201786876 | accuracy: 0.8684505988023952 \n",
      "Epoch 10 | Step 3962 | loss: 0.3126999412899588 | accuracy: 0.868330223880597 \n",
      "Epoch 10 | Step 3963 | loss: 0.3125790591750827 | accuracy: 0.8683500744047619 \n",
      "Epoch 10 | Step 3964 | loss: 0.31249326591321913 | accuracy: 0.8682770771513353 \n",
      "Epoch 10 | Step 3965 | loss: 0.3123151399856489 | accuracy: 0.8683894230769231 \n",
      "Epoch 10 | Step 3966 | loss: 0.31227728381621106 | accuracy: 0.8684550147492626 \n",
      "Epoch 10 | Step 3967 | loss: 0.3121957753511037 | accuracy: 0.8686121323529412 \n",
      "Epoch 10 | Step 3968 | loss: 0.31222817791172497 | accuracy: 0.8685392228739003 \n",
      "Epoch 10 | Step 3969 | loss: 0.31214882633839447 | accuracy: 0.8686494883040936 \n",
      "Epoch 10 | Step 3970 | loss: 0.31185272961594285 | accuracy: 0.8687135568513119 \n",
      "Epoch 10 | Step 3971 | loss: 0.31188047876538244 | accuracy: 0.8686864098837209 \n",
      "Epoch 10 | Step 3972 | loss: 0.31170500620551744 | accuracy: 0.868840579710145 \n",
      "Epoch 10 | Step 3973 | loss: 0.3115127893713859 | accuracy: 0.8689938583815029 \n",
      "Epoch 10 | Step 3974 | loss: 0.3113185765076784 | accuracy: 0.8691012247838616 \n",
      "Epoch 10 | Step 3975 | loss: 0.31116984330717185 | accuracy: 0.8691181752873564 \n",
      "Epoch 10 | Step 3976 | loss: 0.3111175307230144 | accuracy: 0.8690902578796562 \n",
      "Epoch 10 | Step 3977 | loss: 0.31148768808160515 | accuracy: 0.8689285714285714 \n",
      "Epoch 10 | Step 3978 | loss: 0.31112996720180897 | accuracy: 0.8691239316239316 \n",
      "Epoch 10 | Step 3979 | loss: 0.31102208183570346 | accuracy: 0.8690962357954546 \n",
      "Epoch 10 | Step 3980 | loss: 0.31121098387342677 | accuracy: 0.8689801699716714 \n",
      "Epoch 10 | Step 3981 | loss: 0.31129735211531323 | accuracy: 0.8688647598870056 \n",
      "Epoch 10 | Step 3982 | loss: 0.311065818348401 | accuracy: 0.8689260563380282 \n",
      "Epoch 10 | Step 3983 | loss: 0.31086958643425716 | accuracy: 0.8690308988764045 \n",
      "Epoch 10 | Step 3984 | loss: 0.3111285323522338 | accuracy: 0.8689600840336135 \n",
      "Epoch 10 | Step 3985 | loss: 0.31148263545675653 | accuracy: 0.868802374301676 \n",
      "Epoch 10 | Step 3986 | loss: 0.3112629873257826 | accuracy: 0.8689066852367688 \n",
      "Epoch 10 | Step 3987 | loss: 0.31132905578447717 | accuracy: 0.8689236111111112 \n",
      "Epoch 10 | Step 3988 | loss: 0.3112965772274129 | accuracy: 0.8688538781163435 \n",
      "Epoch 10 | Step 3989 | loss: 0.31118455772077186 | accuracy: 0.8688708563535912 \n",
      "Epoch 10 | Step 3990 | loss: 0.31126220639251156 | accuracy: 0.868887741046832 \n",
      "Epoch 10 | Step 3991 | loss: 0.310809354369457 | accuracy: 0.8691620879120879 \n",
      "Epoch 10 | Step 3992 | loss: 0.31058236131929373 | accuracy: 0.8693493150684931 \n",
      "Epoch 10 | Step 3993 | loss: 0.31070580980816825 | accuracy: 0.8693647540983607 \n",
      "Epoch 10 | Step 3994 | loss: 0.31096112622552086 | accuracy: 0.869167234332425 \n",
      "Epoch 10 | Step 3995 | loss: 0.31086288700285164 | accuracy: 0.8692255434782609 \n",
      "Epoch 10 | Step 3996 | loss: 0.311014117991052 | accuracy: 0.8692835365853658 \n",
      "Epoch 10 | Step 3997 | loss: 0.3110039347732389 | accuracy: 0.8693412162162162 \n",
      "Epoch 10 | Step 3998 | loss: 0.3112223238315222 | accuracy: 0.8690616576819407 \n",
      "Epoch 10 | Step 3999 | loss: 0.3111905965914008 | accuracy: 0.869119623655914 \n",
      "Epoch 10 | Step 4000 | loss: 0.31079572670900785 | accuracy: 0.8693448391420912 \n",
      "Epoch 10 | Step 4001 | loss: 0.31060646303037903 | accuracy: 0.8694435160427807 \n",
      "Epoch 10 | Step 4002 | loss: 0.31081399754683176 | accuracy: 0.8693333333333333 \n",
      "Epoch 10 | Step 4003 | loss: 0.3107274271785579 | accuracy: 0.8693484042553191 \n",
      "Epoch 10 | Step 4004 | loss: 0.3106421289535669 | accuracy: 0.8692390583554377 \n",
      "Epoch 10 | Step 4005 | loss: 0.3106676316056302 | accuracy: 0.869171626984127 \n",
      "Epoch 10 | Step 4006 | loss: 0.3104305940441846 | accuracy: 0.8692282321899736 \n",
      "Epoch 10 | Step 4007 | loss: 0.3103508025407791 | accuracy: 0.8692434210526315 \n",
      "Epoch 10 | Step 4008 | loss: 0.30997329488826864 | accuracy: 0.869504593175853 \n",
      "Epoch 10 | Step 4009 | loss: 0.3100785074745797 | accuracy: 0.8694780759162304 \n",
      "Epoch 10 | Step 4010 | loss: 0.3101598439888916 | accuracy: 0.8694924934725848 \n",
      "Epoch 10 | Step 4011 | loss: 0.31034439631427324 | accuracy: 0.8694254557291666 \n",
      "Epoch 10 | Step 4012 | loss: 0.31024837958348256 | accuracy: 0.8694399350649351 \n",
      "Epoch 10 | Step 4013 | loss: 0.3101561426189896 | accuracy: 0.8694948186528497 \n",
      "Epoch 10 | Step 4014 | loss: 0.3102548317237725 | accuracy: 0.8693879198966409 \n",
      "Epoch 10 | Step 4015 | loss: 0.3103090198998598 | accuracy: 0.8694426546391752 \n",
      "Epoch 10 | Step 4016 | loss: 0.31027070124535444 | accuracy: 0.8693364395886889 \n",
      "Epoch 10 | Step 4017 | loss: 0.31018384320613657 | accuracy: 0.8694711538461538 \n",
      "Epoch 10 | Step 4018 | loss: 0.310124548271184 | accuracy: 0.8695652173913043 \n",
      "Epoch 10 | Step 4019 | loss: 0.3100375828846376 | accuracy: 0.8696588010204082 \n",
      "Epoch 10 | Step 4020 | loss: 0.30988749778301045 | accuracy: 0.8697519083969466 \n",
      "Epoch 10 | Step 4021 | loss: 0.3102042373213065 | accuracy: 0.8694479695431472 \n",
      "Epoch 10 | Step 4022 | loss: 0.31001513909689976 | accuracy: 0.8694620253164557 \n",
      "Epoch 10 | Step 4023 | loss: 0.30981595682525864 | accuracy: 0.8695549242424242 \n",
      "Epoch 10 | Step 4024 | loss: 0.30971227346049135 | accuracy: 0.8696473551637279 \n",
      "Epoch 10 | Step 4025 | loss: 0.30982070835541226 | accuracy: 0.8695430276381909 \n",
      "Epoch 10 | Step 4026 | loss: 0.30965103011083467 | accuracy: 0.8695958646616542 \n",
      "Epoch 10 | Step 4027 | loss: 0.30953462094068507 | accuracy: 0.86953125 \n",
      "Epoch 10 | Step 4028 | loss: 0.30956276589795517 | accuracy: 0.8695448877805486 \n",
      "Epoch 10 | Step 4029 | loss: 0.309671825882214 | accuracy: 0.8695584577114428 \n",
      "Epoch 10 | Step 4030 | loss: 0.30958660497854695 | accuracy: 0.8695398733278658 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4360257089138031 | accuracy: 0.765625 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.39536401629447937 | accuracy: 0.8125 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.42402971784273785 | accuracy: 0.8229166666666666 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.42941757291555405 | accuracy: 0.8125 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4010062634944916 | accuracy: 0.828125 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4301595439513524 | accuracy: 0.8046875 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4226726974759783 | accuracy: 0.8058035714285714 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.41717879846692085 | accuracy: 0.810546875 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4408082399103377 | accuracy: 0.8038194444444444 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4286740094423294 | accuracy: 0.809375 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.42583290013399994 | accuracy: 0.8082386363636364 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4153236250082652 | accuracy: 0.8125 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.41876118458234346 | accuracy: 0.8112980769230769 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.41307799092360903 | accuracy: 0.8113839285714286 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.41543691356976825 | accuracy: 0.815625 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4136833120137453 | accuracy: 0.81640625 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.42384840285076814 | accuracy: 0.8143382352941176 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.421573218372133 | accuracy: 0.8151041666666666 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.41518499506147283 | accuracy: 0.8174342105263158 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.41133095920085905 | accuracy: 0.81875 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4054394577230726 | accuracy: 0.8199404761904762 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4002462760968642 | accuracy: 0.8231534090909091 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4036016554936119 | accuracy: 0.8199728260869565 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4182356335222721 | accuracy: 0.8177083333333334 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4234296691417694 | accuracy: 0.816875 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4196295887231827 | accuracy: 0.8185096153846154 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4149727401910005 | accuracy: 0.8211805555555556 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.41593059045927866 | accuracy: 0.8197544642857143 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.41298394059312754 | accuracy: 0.8195043103448276 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4096362978219986 | accuracy: 0.8223958333333333 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4055083922801479 | accuracy: 0.8245967741935484 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4091134751215577 | accuracy: 0.8212890625 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.40971232905532373 | accuracy: 0.8210227272727273 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4140550459132475 | accuracy: 0.8170955882352942 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.41507303374154225 | accuracy: 0.8174107142857143 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4124853453702397 | accuracy: 0.8185763888888888 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.41314387965846705 | accuracy: 0.8188344594594594 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.4139130829196227 | accuracy: 0.8199013157894737 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.41423744345322633 | accuracy: 0.8201121794871795 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.41207794696092603 | accuracy: 0.822265625 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.40947255928341936 | accuracy: 0.8224085365853658 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.40698691705862683 | accuracy: 0.8236607142857143 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.40746805972831196 | accuracy: 0.8241279069767442 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.41007068482312287 | accuracy: 0.8220880681818182 \n",
      "Validation | Epoch 10 | Step 4030 | loss: 0.40848807361390854 | accuracy: 0.8221769319640265 \n",
      "Epoch 11 | Step 4031 | loss: 0.44704872369766235 | accuracy: 0.828125 \n",
      "Epoch 11 | Step 4032 | loss: 0.32523083686828613 | accuracy: 0.8671875 \n",
      "Epoch 11 | Step 4033 | loss: 0.29807726045449573 | accuracy: 0.8802083333333334 \n",
      "Epoch 11 | Step 4034 | loss: 0.315541360527277 | accuracy: 0.875 \n",
      "Epoch 11 | Step 4035 | loss: 0.2962887465953827 | accuracy: 0.8875 \n",
      "Epoch 11 | Step 4036 | loss: 0.29214080174763996 | accuracy: 0.8880208333333334 \n",
      "Epoch 11 | Step 4037 | loss: 0.297947313104357 | accuracy: 0.8883928571428571 \n",
      "Epoch 11 | Step 4038 | loss: 0.29308711364865303 | accuracy: 0.888671875 \n",
      "Epoch 11 | Step 4039 | loss: 0.30215604768859017 | accuracy: 0.8819444444444444 \n",
      "Epoch 11 | Step 4040 | loss: 0.31275940537452696 | accuracy: 0.878125 \n",
      "Epoch 11 | Step 4041 | loss: 0.30479100211100146 | accuracy: 0.8835227272727273 \n",
      "Epoch 11 | Step 4042 | loss: 0.3007875395317872 | accuracy: 0.8815104166666666 \n",
      "Epoch 11 | Step 4043 | loss: 0.31281408552940076 | accuracy: 0.8713942307692307 \n",
      "Epoch 11 | Step 4044 | loss: 0.3103900881750243 | accuracy: 0.8727678571428571 \n",
      "Epoch 11 | Step 4045 | loss: 0.31037837962309517 | accuracy: 0.8739583333333333 \n",
      "Epoch 11 | Step 4046 | loss: 0.30275822058320045 | accuracy: 0.8759765625 \n",
      "Epoch 11 | Step 4047 | loss: 0.3048453541362987 | accuracy: 0.8713235294117647 \n",
      "Epoch 11 | Step 4048 | loss: 0.30130414333608413 | accuracy: 0.875 \n",
      "Epoch 11 | Step 4049 | loss: 0.3005488954092327 | accuracy: 0.8758223684210527 \n",
      "Epoch 11 | Step 4050 | loss: 0.3037122428417206 | accuracy: 0.87421875 \n",
      "Epoch 11 | Step 4051 | loss: 0.3031864577815646 | accuracy: 0.8742559523809523 \n",
      "Epoch 11 | Step 4052 | loss: 0.3051819679411975 | accuracy: 0.8735795454545454 \n",
      "Epoch 11 | Step 4053 | loss: 0.303707497275394 | accuracy: 0.873641304347826 \n",
      "Epoch 11 | Step 4054 | loss: 0.3039753002425035 | accuracy: 0.873046875 \n",
      "Epoch 11 | Step 4055 | loss: 0.30825154662132265 | accuracy: 0.870625 \n",
      "Epoch 11 | Step 4056 | loss: 0.30822154077199787 | accuracy: 0.8701923076923077 \n",
      "Epoch 11 | Step 4057 | loss: 0.30884601562111463 | accuracy: 0.8692129629629629 \n",
      "Epoch 11 | Step 4058 | loss: 0.306542018694537 | accuracy: 0.87109375 \n",
      "Epoch 11 | Step 4059 | loss: 0.31012058566356526 | accuracy: 0.8706896551724138 \n",
      "Epoch 11 | Step 4060 | loss: 0.3103970527648926 | accuracy: 0.8697916666666666 \n",
      "Epoch 11 | Step 4061 | loss: 0.3084832747136393 | accuracy: 0.8704637096774194 \n",
      "Epoch 11 | Step 4062 | loss: 0.30774344597011805 | accuracy: 0.87109375 \n",
      "Epoch 11 | Step 4063 | loss: 0.30727409593986743 | accuracy: 0.8721590909090909 \n",
      "Epoch 11 | Step 4064 | loss: 0.3040308899739209 | accuracy: 0.8745404411764706 \n",
      "Epoch 11 | Step 4065 | loss: 0.3010760464838573 | accuracy: 0.875 \n",
      "Epoch 11 | Step 4066 | loss: 0.3001758013334539 | accuracy: 0.8754340277777778 \n",
      "Epoch 11 | Step 4067 | loss: 0.30008722036271485 | accuracy: 0.875 \n",
      "Epoch 11 | Step 4068 | loss: 0.3018305917319499 | accuracy: 0.8741776315789473 \n",
      "Epoch 11 | Step 4069 | loss: 0.3001844157011082 | accuracy: 0.8754006410256411 \n",
      "Epoch 11 | Step 4070 | loss: 0.29806973077356824 | accuracy: 0.87578125 \n",
      "Epoch 11 | Step 4071 | loss: 0.2984390742168195 | accuracy: 0.8757621951219512 \n",
      "Epoch 11 | Step 4072 | loss: 0.29882390193995984 | accuracy: 0.8746279761904762 \n",
      "Epoch 11 | Step 4073 | loss: 0.2971419387085494 | accuracy: 0.875 \n",
      "Epoch 11 | Step 4074 | loss: 0.29514775594527076 | accuracy: 0.8764204545454546 \n",
      "Epoch 11 | Step 4075 | loss: 0.2957893759012223 | accuracy: 0.8774305555555556 \n",
      "Epoch 11 | Step 4076 | loss: 0.2968558711202249 | accuracy: 0.8766983695652174 \n",
      "Epoch 11 | Step 4077 | loss: 0.29718879657856967 | accuracy: 0.8763297872340425 \n",
      "Epoch 11 | Step 4078 | loss: 0.29766933340579277 | accuracy: 0.876953125 \n",
      "Epoch 11 | Step 4079 | loss: 0.30035435271506417 | accuracy: 0.8759566326530612 \n",
      "Epoch 11 | Step 4080 | loss: 0.30182077080011377 | accuracy: 0.8753125 \n",
      "Epoch 11 | Step 4081 | loss: 0.30071134952937867 | accuracy: 0.8756127450980392 \n",
      "Epoch 11 | Step 4082 | loss: 0.29916399488082307 | accuracy: 0.8762019230769231 \n",
      "Epoch 11 | Step 4083 | loss: 0.29981710325996835 | accuracy: 0.8752948113207547 \n",
      "Epoch 11 | Step 4084 | loss: 0.2989236177117736 | accuracy: 0.8758680555555556 \n",
      "Epoch 11 | Step 4085 | loss: 0.2996863240545446 | accuracy: 0.8755681818181819 \n",
      "Epoch 11 | Step 4086 | loss: 0.29918485028403147 | accuracy: 0.8758370535714286 \n",
      "Epoch 11 | Step 4087 | loss: 0.30061209672375727 | accuracy: 0.8752741228070176 \n",
      "Epoch 11 | Step 4088 | loss: 0.30057530105113983 | accuracy: 0.8752693965517241 \n",
      "Epoch 11 | Step 4089 | loss: 0.3018126770601434 | accuracy: 0.875 \n",
      "Epoch 11 | Step 4090 | loss: 0.3018435716629028 | accuracy: 0.8747395833333333 \n",
      "Epoch 11 | Step 4091 | loss: 0.30089496002822624 | accuracy: 0.8755122950819673 \n",
      "Epoch 11 | Step 4092 | loss: 0.29999822017646605 | accuracy: 0.8757560483870968 \n",
      "Epoch 11 | Step 4093 | loss: 0.301294610377342 | accuracy: 0.8752480158730159 \n",
      "Epoch 11 | Step 4094 | loss: 0.2993720178492367 | accuracy: 0.87646484375 \n",
      "Epoch 11 | Step 4095 | loss: 0.2978851011166206 | accuracy: 0.8769230769230769 \n",
      "Epoch 11 | Step 4096 | loss: 0.29675697512698895 | accuracy: 0.8773674242424242 \n",
      "Epoch 11 | Step 4097 | loss: 0.2955534951900368 | accuracy: 0.8780317164179104 \n",
      "Epoch 11 | Step 4098 | loss: 0.29521815741763396 | accuracy: 0.8782169117647058 \n",
      "Epoch 11 | Step 4099 | loss: 0.2956476500932721 | accuracy: 0.8783967391304348 \n",
      "Epoch 11 | Step 4100 | loss: 0.29448365207229343 | accuracy: 0.8785714285714286 \n",
      "Epoch 11 | Step 4101 | loss: 0.2931159117691953 | accuracy: 0.8794014084507042 \n",
      "Epoch 11 | Step 4102 | loss: 0.2921619415283203 | accuracy: 0.8799913194444444 \n",
      "Epoch 11 | Step 4103 | loss: 0.2920445432401683 | accuracy: 0.879708904109589 \n",
      "Epoch 11 | Step 4104 | loss: 0.2919569704178217 | accuracy: 0.8796452702702703 \n",
      "Epoch 11 | Step 4105 | loss: 0.2919259603818257 | accuracy: 0.8791666666666667 \n",
      "Epoch 11 | Step 4106 | loss: 0.29143612714190226 | accuracy: 0.8797286184210527 \n",
      "Epoch 11 | Step 4107 | loss: 0.2908899205458628 | accuracy: 0.880073051948052 \n",
      "Epoch 11 | Step 4108 | loss: 0.29126519098495823 | accuracy: 0.8798076923076923 \n",
      "Epoch 11 | Step 4109 | loss: 0.2926851060194305 | accuracy: 0.8787579113924051 \n",
      "Epoch 11 | Step 4110 | loss: 0.29269998315721746 | accuracy: 0.878515625 \n",
      "Epoch 11 | Step 4111 | loss: 0.292083501079936 | accuracy: 0.8786651234567902 \n",
      "Epoch 11 | Step 4112 | loss: 0.29165276412556806 | accuracy: 0.8784298780487805 \n",
      "Epoch 11 | Step 4113 | loss: 0.29184970798262627 | accuracy: 0.8785768072289156 \n",
      "Epoch 11 | Step 4114 | loss: 0.2912419078250726 | accuracy: 0.8785342261904762 \n",
      "Epoch 11 | Step 4115 | loss: 0.29037190325119916 | accuracy: 0.8788602941176471 \n",
      "Epoch 11 | Step 4116 | loss: 0.2903886645339256 | accuracy: 0.8784520348837209 \n",
      "Epoch 11 | Step 4117 | loss: 0.29226534942100785 | accuracy: 0.8778735632183908 \n",
      "Epoch 11 | Step 4118 | loss: 0.29238046908920456 | accuracy: 0.8780184659090909 \n",
      "Epoch 11 | Step 4119 | loss: 0.2911668001266008 | accuracy: 0.8785112359550562 \n",
      "Epoch 11 | Step 4120 | loss: 0.29241204261779785 | accuracy: 0.878125 \n",
      "Epoch 11 | Step 4121 | loss: 0.291686800810007 | accuracy: 0.8786057692307693 \n",
      "Epoch 11 | Step 4122 | loss: 0.2908267668731835 | accuracy: 0.8787364130434783 \n",
      "Epoch 11 | Step 4123 | loss: 0.2909746562601418 | accuracy: 0.8781922043010753 \n",
      "Epoch 11 | Step 4124 | loss: 0.29075144754445303 | accuracy: 0.8779920212765957 \n",
      "Epoch 11 | Step 4125 | loss: 0.2915409974361721 | accuracy: 0.8777960526315789 \n",
      "Epoch 11 | Step 4126 | loss: 0.2932485830970109 | accuracy: 0.8776041666666666 \n",
      "Epoch 11 | Step 4127 | loss: 0.2937473822193048 | accuracy: 0.8774162371134021 \n",
      "Epoch 11 | Step 4128 | loss: 0.29521603106844185 | accuracy: 0.8767538265306123 \n",
      "Epoch 11 | Step 4129 | loss: 0.2952726418622817 | accuracy: 0.8765782828282829 \n",
      "Epoch 11 | Step 4130 | loss: 0.2947730615735054 | accuracy: 0.87671875 \n",
      "Epoch 11 | Step 4131 | loss: 0.293370712954219 | accuracy: 0.8774752475247525 \n",
      "Epoch 11 | Step 4132 | loss: 0.2932895061139967 | accuracy: 0.8779105392156863 \n",
      "Epoch 11 | Step 4133 | loss: 0.2925249782291431 | accuracy: 0.8781856796116505 \n",
      "Epoch 11 | Step 4134 | loss: 0.2932724395337013 | accuracy: 0.8777043269230769 \n",
      "Epoch 11 | Step 4135 | loss: 0.2943421808027086 | accuracy: 0.8769345238095239 \n",
      "Epoch 11 | Step 4136 | loss: 0.2937611259941785 | accuracy: 0.8767688679245284 \n",
      "Epoch 11 | Step 4137 | loss: 0.29496492905037425 | accuracy: 0.8768983644859814 \n",
      "Epoch 11 | Step 4138 | loss: 0.296194512810972 | accuracy: 0.8764467592592593 \n",
      "Epoch 11 | Step 4139 | loss: 0.2966634508119811 | accuracy: 0.8765768348623854 \n",
      "Epoch 11 | Step 4140 | loss: 0.2973919773643667 | accuracy: 0.876278409090909 \n",
      "Epoch 11 | Step 4141 | loss: 0.29671142981933046 | accuracy: 0.8765484234234234 \n",
      "Epoch 11 | Step 4142 | loss: 0.2965054977685213 | accuracy: 0.8768136160714286 \n",
      "Epoch 11 | Step 4143 | loss: 0.29748779403424896 | accuracy: 0.8763827433628318 \n",
      "Epoch 11 | Step 4144 | loss: 0.29864820367411565 | accuracy: 0.8755482456140351 \n",
      "Epoch 11 | Step 4145 | loss: 0.2984974539798239 | accuracy: 0.8755434782608695 \n",
      "Epoch 11 | Step 4146 | loss: 0.2984018713749688 | accuracy: 0.8756734913793104 \n",
      "Epoch 11 | Step 4147 | loss: 0.29936348576831 | accuracy: 0.875267094017094 \n",
      "Epoch 11 | Step 4148 | loss: 0.29945140092049616 | accuracy: 0.8751324152542372 \n",
      "Epoch 11 | Step 4149 | loss: 0.29956009558268953 | accuracy: 0.8752626050420168 \n",
      "Epoch 11 | Step 4150 | loss: 0.29910486601293085 | accuracy: 0.8756510416666666 \n",
      "Epoch 11 | Step 4151 | loss: 0.29877224108896966 | accuracy: 0.8757747933884298 \n",
      "Epoch 11 | Step 4152 | loss: 0.29850048498540627 | accuracy: 0.875640368852459 \n",
      "Epoch 11 | Step 4153 | loss: 0.29855844051372715 | accuracy: 0.8755081300813008 \n",
      "Epoch 11 | Step 4154 | loss: 0.2989422471052216 | accuracy: 0.8755040322580645 \n",
      "Epoch 11 | Step 4155 | loss: 0.2992743855714798 | accuracy: 0.875125 \n",
      "Epoch 11 | Step 4156 | loss: 0.2990528154704306 | accuracy: 0.8752480158730159 \n",
      "Epoch 11 | Step 4157 | loss: 0.29950476901268397 | accuracy: 0.875 \n",
      "Epoch 11 | Step 4158 | loss: 0.29886635148432106 | accuracy: 0.8748779296875 \n",
      "Epoch 11 | Step 4159 | loss: 0.2985566026249597 | accuracy: 0.8746366279069767 \n",
      "Epoch 11 | Step 4160 | loss: 0.2982142124038476 | accuracy: 0.8747596153846153 \n",
      "Epoch 11 | Step 4161 | loss: 0.29860512184277743 | accuracy: 0.8746421755725191 \n",
      "Epoch 11 | Step 4162 | loss: 0.2992754112364668 | accuracy: 0.8745265151515151 \n",
      "Epoch 11 | Step 4163 | loss: 0.3004435234724131 | accuracy: 0.8740601503759399 \n",
      "Epoch 11 | Step 4164 | loss: 0.3009228956565928 | accuracy: 0.8736007462686567 \n",
      "Epoch 11 | Step 4165 | loss: 0.30105884616021755 | accuracy: 0.8736111111111111 \n",
      "Epoch 11 | Step 4166 | loss: 0.30101029826875997 | accuracy: 0.8736213235294118 \n",
      "Epoch 11 | Step 4167 | loss: 0.30054254057633617 | accuracy: 0.8738594890510949 \n",
      "Epoch 11 | Step 4168 | loss: 0.3001550131517908 | accuracy: 0.8738677536231884 \n",
      "Epoch 11 | Step 4169 | loss: 0.3007372885728054 | accuracy: 0.8736510791366906 \n",
      "Epoch 11 | Step 4170 | loss: 0.30063503427164895 | accuracy: 0.8738839285714286 \n",
      "Epoch 11 | Step 4171 | loss: 0.3015359855712728 | accuracy: 0.8735593971631206 \n",
      "Epoch 11 | Step 4172 | loss: 0.3014382260366225 | accuracy: 0.8736795774647887 \n",
      "Epoch 11 | Step 4173 | loss: 0.30204199931838294 | accuracy: 0.8732517482517482 \n",
      "Epoch 11 | Step 4174 | loss: 0.3024312011483643 | accuracy: 0.8727213541666666 \n",
      "Epoch 11 | Step 4175 | loss: 0.30236252299670513 | accuracy: 0.8727370689655173 \n",
      "Epoch 11 | Step 4176 | loss: 0.3027548857339441 | accuracy: 0.8725385273972602 \n",
      "Epoch 11 | Step 4177 | loss: 0.3020245876847481 | accuracy: 0.8730867346938775 \n",
      "Epoch 11 | Step 4178 | loss: 0.3020096556157679 | accuracy: 0.8729940878378378 \n",
      "Epoch 11 | Step 4179 | loss: 0.3019303729470144 | accuracy: 0.8727978187919463 \n",
      "Epoch 11 | Step 4180 | loss: 0.3022966855764389 | accuracy: 0.8727083333333333 \n",
      "Epoch 11 | Step 4181 | loss: 0.3021717397187719 | accuracy: 0.8726200331125827 \n",
      "Epoch 11 | Step 4182 | loss: 0.30298095098451566 | accuracy: 0.8726356907894737 \n",
      "Epoch 11 | Step 4183 | loss: 0.30307721000870846 | accuracy: 0.8726511437908496 \n",
      "Epoch 11 | Step 4184 | loss: 0.3026816813009126 | accuracy: 0.8730722402597403 \n",
      "Epoch 11 | Step 4185 | loss: 0.30236041267072006 | accuracy: 0.8732862903225806 \n",
      "Epoch 11 | Step 4186 | loss: 0.3014691664049259 | accuracy: 0.8738982371794872 \n",
      "Epoch 11 | Step 4187 | loss: 0.30177015872897617 | accuracy: 0.8738057324840764 \n",
      "Epoch 11 | Step 4188 | loss: 0.3022195584600485 | accuracy: 0.8736155063291139 \n",
      "Epoch 11 | Step 4189 | loss: 0.3025689245957249 | accuracy: 0.8733294025157232 \n",
      "Epoch 11 | Step 4190 | loss: 0.30310637494549153 | accuracy: 0.87314453125 \n",
      "Epoch 11 | Step 4191 | loss: 0.30336006207865956 | accuracy: 0.8729619565217391 \n",
      "Epoch 11 | Step 4192 | loss: 0.3034561825571237 | accuracy: 0.8727816358024691 \n",
      "Epoch 11 | Step 4193 | loss: 0.3043714649289664 | accuracy: 0.8724118098159509 \n",
      "Epoch 11 | Step 4194 | loss: 0.30405989207509093 | accuracy: 0.8724275914634146 \n",
      "Epoch 11 | Step 4195 | loss: 0.30390573911594626 | accuracy: 0.8727272727272727 \n",
      "Epoch 11 | Step 4196 | loss: 0.3040087965418058 | accuracy: 0.8726468373493976 \n",
      "Epoch 11 | Step 4197 | loss: 0.30376491941020883 | accuracy: 0.8727544910179641 \n",
      "Epoch 11 | Step 4198 | loss: 0.3045958354182187 | accuracy: 0.8722098214285714 \n",
      "Epoch 11 | Step 4199 | loss: 0.3044167546301904 | accuracy: 0.872133875739645 \n",
      "Epoch 11 | Step 4200 | loss: 0.30369269944289157 | accuracy: 0.8727022058823529 \n",
      "Epoch 11 | Step 4201 | loss: 0.3035736654759848 | accuracy: 0.8728983918128655 \n",
      "Epoch 11 | Step 4202 | loss: 0.30355054737870085 | accuracy: 0.8729106104651163 \n",
      "Epoch 11 | Step 4203 | loss: 0.3031117506971249 | accuracy: 0.8731936416184971 \n",
      "Epoch 11 | Step 4204 | loss: 0.303178929820143 | accuracy: 0.8732938218390804 \n",
      "Epoch 11 | Step 4205 | loss: 0.3030944159201214 | accuracy: 0.8732142857142857 \n",
      "Epoch 11 | Step 4206 | loss: 0.3033554612404921 | accuracy: 0.873046875 \n",
      "Epoch 11 | Step 4207 | loss: 0.3041530765887708 | accuracy: 0.8728813559322034 \n",
      "Epoch 11 | Step 4208 | loss: 0.30475781933310325 | accuracy: 0.8724543539325843 \n",
      "Epoch 11 | Step 4209 | loss: 0.30519407379893615 | accuracy: 0.8721194134078212 \n",
      "Epoch 11 | Step 4210 | loss: 0.3048790475560559 | accuracy: 0.8722222222222222 \n",
      "Epoch 11 | Step 4211 | loss: 0.30524315615055964 | accuracy: 0.8717196132596685 \n",
      "Epoch 11 | Step 4212 | loss: 0.305002154966632 | accuracy: 0.8719093406593407 \n",
      "Epoch 11 | Step 4213 | loss: 0.3043186299787844 | accuracy: 0.8722677595628415 \n",
      "Epoch 11 | Step 4214 | loss: 0.30395471231768956 | accuracy: 0.8723675271739131 \n",
      "Epoch 11 | Step 4215 | loss: 0.3037605463652997 | accuracy: 0.8725506756756757 \n",
      "Epoch 11 | Step 4216 | loss: 0.3041186650754303 | accuracy: 0.8722278225806451 \n",
      "Epoch 11 | Step 4217 | loss: 0.3046551288608561 | accuracy: 0.8719084224598931 \n",
      "Epoch 11 | Step 4218 | loss: 0.3046669623160616 | accuracy: 0.871592420212766 \n",
      "Epoch 11 | Step 4219 | loss: 0.3042984559107079 | accuracy: 0.8717757936507936 \n",
      "Epoch 11 | Step 4220 | loss: 0.3051451832056046 | accuracy: 0.8715460526315789 \n",
      "Epoch 11 | Step 4221 | loss: 0.304434967056619 | accuracy: 0.8718913612565445 \n",
      "Epoch 11 | Step 4222 | loss: 0.3039897554554046 | accuracy: 0.8721516927083334 \n",
      "Epoch 11 | Step 4223 | loss: 0.30367579778241377 | accuracy: 0.8724902849740933 \n",
      "Epoch 11 | Step 4224 | loss: 0.3035240525130145 | accuracy: 0.8725837628865979 \n",
      "Epoch 11 | Step 4225 | loss: 0.3032894200239427 | accuracy: 0.872676282051282 \n",
      "Epoch 11 | Step 4226 | loss: 0.30312170985401904 | accuracy: 0.8728475765306123 \n",
      "Epoch 11 | Step 4227 | loss: 0.30320073838161343 | accuracy: 0.8728585025380711 \n",
      "Epoch 11 | Step 4228 | loss: 0.3031580877123458 | accuracy: 0.8730271464646465 \n",
      "Epoch 11 | Step 4229 | loss: 0.30289540773061063 | accuracy: 0.8733511306532663 \n",
      "Epoch 11 | Step 4230 | loss: 0.3024360088258983 | accuracy: 0.87359375 \n",
      "Epoch 11 | Step 4231 | loss: 0.3030908133704865 | accuracy: 0.8733675373134329 \n",
      "Epoch 11 | Step 4232 | loss: 0.3029624708365687 | accuracy: 0.8736076732673267 \n",
      "Epoch 11 | Step 4233 | loss: 0.3029101281770933 | accuracy: 0.8735375615763546 \n",
      "Epoch 11 | Step 4234 | loss: 0.30277686266630316 | accuracy: 0.8736213235294118 \n",
      "Epoch 11 | Step 4235 | loss: 0.3031818921246181 | accuracy: 0.8733231707317073 \n",
      "Epoch 11 | Step 4236 | loss: 0.30385229331486446 | accuracy: 0.8732554611650486 \n",
      "Epoch 11 | Step 4237 | loss: 0.3047173507691583 | accuracy: 0.873112922705314 \n",
      "Epoch 11 | Step 4238 | loss: 0.3046128511285554 | accuracy: 0.8731219951923077 \n",
      "Epoch 11 | Step 4239 | loss: 0.3044249403277084 | accuracy: 0.873130980861244 \n",
      "Epoch 11 | Step 4240 | loss: 0.30449974302734667 | accuracy: 0.8732142857142857 \n",
      "Epoch 11 | Step 4241 | loss: 0.3046962280550276 | accuracy: 0.873074644549763 \n",
      "Epoch 11 | Step 4242 | loss: 0.30404539160289873 | accuracy: 0.8733785377358491 \n",
      "Epoch 11 | Step 4243 | loss: 0.30354642917012964 | accuracy: 0.8736795774647887 \n",
      "Epoch 11 | Step 4244 | loss: 0.30353585463539484 | accuracy: 0.8739047897196262 \n",
      "Epoch 11 | Step 4245 | loss: 0.30326324029024276 | accuracy: 0.873764534883721 \n",
      "Epoch 11 | Step 4246 | loss: 0.3032549979096211 | accuracy: 0.8737702546296297 \n",
      "Epoch 11 | Step 4247 | loss: 0.3030466475107705 | accuracy: 0.8738479262672811 \n",
      "Epoch 11 | Step 4248 | loss: 0.30295258767287686 | accuracy: 0.8738532110091743 \n",
      "Epoch 11 | Step 4249 | loss: 0.3027991265330687 | accuracy: 0.873787100456621 \n",
      "Epoch 11 | Step 4250 | loss: 0.30274881293827854 | accuracy: 0.873721590909091 \n",
      "Epoch 11 | Step 4251 | loss: 0.3026719915246534 | accuracy: 0.873868778280543 \n",
      "Epoch 11 | Step 4252 | loss: 0.30251040135149504 | accuracy: 0.8740850225225225 \n",
      "Epoch 11 | Step 4253 | loss: 0.30255927773601826 | accuracy: 0.8738789237668162 \n",
      "Epoch 11 | Step 4254 | loss: 0.30196074210107343 | accuracy: 0.8743024553571429 \n",
      "Epoch 11 | Step 4255 | loss: 0.3019817354944019 | accuracy: 0.8742361111111111 \n",
      "Epoch 11 | Step 4256 | loss: 0.30219976419368694 | accuracy: 0.8741703539823009 \n",
      "Epoch 11 | Step 4257 | loss: 0.3022479439884557 | accuracy: 0.8740363436123348 \n",
      "Epoch 11 | Step 4258 | loss: 0.30222071341255274 | accuracy: 0.8742461622807017 \n",
      "Epoch 11 | Step 4259 | loss: 0.30217449646849837 | accuracy: 0.8740447598253275 \n",
      "Epoch 11 | Step 4260 | loss: 0.3022024729977485 | accuracy: 0.8741847826086957 \n",
      "Epoch 11 | Step 4261 | loss: 0.3017483865156836 | accuracy: 0.8743912337662337 \n",
      "Epoch 11 | Step 4262 | loss: 0.3015039239464137 | accuracy: 0.8745959051724138 \n",
      "Epoch 11 | Step 4263 | loss: 0.30165557301095647 | accuracy: 0.8743964592274678 \n",
      "Epoch 11 | Step 4264 | loss: 0.3016641570462123 | accuracy: 0.8743990384615384 \n",
      "Epoch 11 | Step 4265 | loss: 0.30130060346836757 | accuracy: 0.8746010638297872 \n",
      "Epoch 11 | Step 4266 | loss: 0.30093449234204794 | accuracy: 0.8747351694915254 \n",
      "Epoch 11 | Step 4267 | loss: 0.30077199725913617 | accuracy: 0.8747362869198312 \n",
      "Epoch 11 | Step 4268 | loss: 0.3009343768994349 | accuracy: 0.874671743697479 \n",
      "Epoch 11 | Step 4269 | loss: 0.300863547492227 | accuracy: 0.8747384937238494 \n",
      "Epoch 11 | Step 4270 | loss: 0.3007483518992863 | accuracy: 0.874609375 \n",
      "Epoch 11 | Step 4271 | loss: 0.3001222642625518 | accuracy: 0.8749351659751037 \n",
      "Epoch 11 | Step 4272 | loss: 0.29967779653870386 | accuracy: 0.87525826446281 \n",
      "Epoch 11 | Step 4273 | loss: 0.2998595445612332 | accuracy: 0.8752572016460906 \n",
      "Epoch 11 | Step 4274 | loss: 0.3001802406716544 | accuracy: 0.8751921106557377 \n",
      "Epoch 11 | Step 4275 | loss: 0.30010489158484416 | accuracy: 0.8752551020408164 \n",
      "Epoch 11 | Step 4276 | loss: 0.2999420186004989 | accuracy: 0.8753810975609756 \n",
      "Epoch 11 | Step 4277 | loss: 0.2997158585410371 | accuracy: 0.8756325910931174 \n",
      "Epoch 11 | Step 4278 | loss: 0.30003585696460755 | accuracy: 0.8755040322580645 \n",
      "Epoch 11 | Step 4279 | loss: 0.29995931445594787 | accuracy: 0.8756275100401606 \n",
      "Epoch 11 | Step 4280 | loss: 0.29990758770704284 | accuracy: 0.87575 \n",
      "Epoch 11 | Step 4281 | loss: 0.29960176319002646 | accuracy: 0.875996015936255 \n",
      "Epoch 11 | Step 4282 | loss: 0.29942019632647926 | accuracy: 0.8759920634920635 \n",
      "Epoch 11 | Step 4283 | loss: 0.29922075575519474 | accuracy: 0.8761116600790514 \n",
      "Epoch 11 | Step 4284 | loss: 0.29921118903347843 | accuracy: 0.8761072834645669 \n",
      "Epoch 11 | Step 4285 | loss: 0.2991383873948866 | accuracy: 0.8761642156862746 \n",
      "Epoch 11 | Step 4286 | loss: 0.2993259530048819 | accuracy: 0.87591552734375 \n",
      "Epoch 11 | Step 4287 | loss: 0.29924855784219545 | accuracy: 0.8760335603112841 \n",
      "Epoch 11 | Step 4288 | loss: 0.2989577654489253 | accuracy: 0.8760901162790697 \n",
      "Epoch 11 | Step 4289 | loss: 0.29916805120968926 | accuracy: 0.8760255791505791 \n",
      "Epoch 11 | Step 4290 | loss: 0.29881572763507197 | accuracy: 0.8760216346153846 \n",
      "Epoch 11 | Step 4291 | loss: 0.2994295826246 | accuracy: 0.8756585249042146 \n",
      "Epoch 11 | Step 4292 | loss: 0.29971107516352474 | accuracy: 0.875417461832061 \n",
      "Epoch 11 | Step 4293 | loss: 0.29953067650586496 | accuracy: 0.8755346958174905 \n",
      "Epoch 11 | Step 4294 | loss: 0.3000577614275797 | accuracy: 0.8752959280303031 \n",
      "Epoch 11 | Step 4295 | loss: 0.29981479656021565 | accuracy: 0.8755306603773586 \n",
      "Epoch 11 | Step 4296 | loss: 0.2996197938919069 | accuracy: 0.8755874060150377 \n",
      "Epoch 11 | Step 4297 | loss: 0.29943145660871884 | accuracy: 0.8757022471910113 \n",
      "Epoch 11 | Step 4298 | loss: 0.2993484399656753 | accuracy: 0.8758745335820897 \n",
      "Epoch 11 | Step 4299 | loss: 0.29930746522091595 | accuracy: 0.8759874535315986 \n",
      "Epoch 11 | Step 4300 | loss: 0.29918972882959594 | accuracy: 0.8759837962962964 \n",
      "Epoch 11 | Step 4301 | loss: 0.29924208035768196 | accuracy: 0.8759225092250924 \n",
      "Epoch 11 | Step 4302 | loss: 0.2991124626029942 | accuracy: 0.8758616727941178 \n",
      "Epoch 11 | Step 4303 | loss: 0.2992192085409341 | accuracy: 0.8756868131868133 \n",
      "Epoch 11 | Step 4304 | loss: 0.29922803551176186 | accuracy: 0.8756843065693432 \n",
      "Epoch 11 | Step 4305 | loss: 0.29913455768065034 | accuracy: 0.8757386363636365 \n",
      "Epoch 11 | Step 4306 | loss: 0.2993774860017543 | accuracy: 0.8754528985507247 \n",
      "Epoch 11 | Step 4307 | loss: 0.29920824275550445 | accuracy: 0.8755076714801445 \n",
      "Epoch 11 | Step 4308 | loss: 0.2989333629500953 | accuracy: 0.875730665467626 \n",
      "Epoch 11 | Step 4309 | loss: 0.2991622997761629 | accuracy: 0.8755040322580646 \n",
      "Epoch 11 | Step 4310 | loss: 0.2989741941115687 | accuracy: 0.8755022321428573 \n",
      "Epoch 11 | Step 4311 | loss: 0.29945321465938557 | accuracy: 0.8752224199288258 \n",
      "Epoch 11 | Step 4312 | loss: 0.29921914034701425 | accuracy: 0.8753878546099292 \n",
      "Epoch 11 | Step 4313 | loss: 0.29937466357706305 | accuracy: 0.8752760600706715 \n",
      "Epoch 11 | Step 4314 | loss: 0.2991721041395632 | accuracy: 0.8753851232394367 \n",
      "Epoch 11 | Step 4315 | loss: 0.2990482337642135 | accuracy: 0.8754934210526317 \n",
      "Epoch 11 | Step 4316 | loss: 0.29905180122468866 | accuracy: 0.8755463286713288 \n",
      "Epoch 11 | Step 4317 | loss: 0.298741633987593 | accuracy: 0.875598867595819 \n",
      "Epoch 11 | Step 4318 | loss: 0.29853201429877024 | accuracy: 0.875705295138889 \n",
      "Epoch 11 | Step 4319 | loss: 0.2983106495393602 | accuracy: 0.875756920415225 \n",
      "Epoch 11 | Step 4320 | loss: 0.2986194765773314 | accuracy: 0.8756465517241381 \n",
      "Epoch 11 | Step 4321 | loss: 0.2984411891076164 | accuracy: 0.8757517182130586 \n",
      "Epoch 11 | Step 4322 | loss: 0.2983608231050512 | accuracy: 0.8758026541095892 \n",
      "Epoch 11 | Step 4323 | loss: 0.29838005344005175 | accuracy: 0.8758532423208193 \n",
      "Epoch 11 | Step 4324 | loss: 0.2979894351898408 | accuracy: 0.8760629251700682 \n",
      "Epoch 11 | Step 4325 | loss: 0.29865516621177485 | accuracy: 0.875741525423729 \n",
      "Epoch 11 | Step 4326 | loss: 0.29860757376897984 | accuracy: 0.8757918074324327 \n",
      "Epoch 11 | Step 4327 | loss: 0.29891964156017564 | accuracy: 0.8755787037037039 \n",
      "Epoch 11 | Step 4328 | loss: 0.29883792621377336 | accuracy: 0.8755243288590606 \n",
      "Epoch 11 | Step 4329 | loss: 0.2986553943775171 | accuracy: 0.8755225752508363 \n",
      "Epoch 11 | Step 4330 | loss: 0.298481669574976 | accuracy: 0.8755208333333335 \n",
      "Epoch 11 | Step 4331 | loss: 0.29835461208788666 | accuracy: 0.8756748338870434 \n",
      "Epoch 11 | Step 4332 | loss: 0.2982867549093354 | accuracy: 0.8756725993377485 \n",
      "Epoch 11 | Step 4333 | loss: 0.2979365560186185 | accuracy: 0.8757735148514854 \n",
      "Epoch 11 | Step 4334 | loss: 0.2979037577874567 | accuracy: 0.8757195723684212 \n",
      "Epoch 11 | Step 4335 | loss: 0.29833776330361605 | accuracy: 0.875409836065574 \n",
      "Epoch 11 | Step 4336 | loss: 0.2980159348229957 | accuracy: 0.8755616830065361 \n",
      "Epoch 11 | Step 4337 | loss: 0.29788160532810015 | accuracy: 0.875610749185668 \n",
      "Epoch 11 | Step 4338 | loss: 0.29763079342710513 | accuracy: 0.875659496753247 \n",
      "Epoch 11 | Step 4339 | loss: 0.2971788649613032 | accuracy: 0.8759101941747575 \n",
      "Epoch 11 | Step 4340 | loss: 0.29707430831847653 | accuracy: 0.8759576612903227 \n",
      "Epoch 11 | Step 4341 | loss: 0.2969195841784646 | accuracy: 0.8761053054662381 \n",
      "Epoch 11 | Step 4342 | loss: 0.29689988321982896 | accuracy: 0.8759515224358976 \n",
      "Epoch 11 | Step 4343 | loss: 0.29682212963271826 | accuracy: 0.8758985623003197 \n",
      "Epoch 11 | Step 4344 | loss: 0.2966722334456292 | accuracy: 0.8759454617834397 \n",
      "Epoch 11 | Step 4345 | loss: 0.2962083157092806 | accuracy: 0.8762400793650795 \n",
      "Epoch 11 | Step 4346 | loss: 0.2962884444601928 | accuracy: 0.8761867088607597 \n",
      "Epoch 11 | Step 4347 | loss: 0.2963097628546814 | accuracy: 0.8762322555205049 \n",
      "Epoch 11 | Step 4348 | loss: 0.2963448921277088 | accuracy: 0.8762283805031449 \n",
      "Epoch 11 | Step 4349 | loss: 0.29626321727205596 | accuracy: 0.8762245297805644 \n",
      "Epoch 11 | Step 4350 | loss: 0.29610767471604055 | accuracy: 0.8764160156250002 \n",
      "Epoch 11 | Step 4351 | loss: 0.2960829836464374 | accuracy: 0.876460280373832 \n",
      "Epoch 11 | Step 4352 | loss: 0.295947671167969 | accuracy: 0.8765527950310561 \n",
      "Epoch 11 | Step 4353 | loss: 0.2959875809057579 | accuracy: 0.8764996130030962 \n",
      "Epoch 11 | Step 4354 | loss: 0.2960140049733498 | accuracy: 0.8763503086419755 \n",
      "Epoch 11 | Step 4355 | loss: 0.2961076978078256 | accuracy: 0.8762019230769232 \n",
      "Epoch 11 | Step 4356 | loss: 0.296204085593209 | accuracy: 0.8760544478527609 \n",
      "Epoch 11 | Step 4357 | loss: 0.2963202778443649 | accuracy: 0.8760034403669726 \n",
      "Epoch 11 | Step 4358 | loss: 0.2962737280148559 | accuracy: 0.8760956554878051 \n",
      "Epoch 11 | Step 4359 | loss: 0.2960078998449001 | accuracy: 0.8761873100303953 \n",
      "Epoch 11 | Step 4360 | loss: 0.29595586779442706 | accuracy: 0.8761837121212123 \n",
      "Epoch 11 | Step 4361 | loss: 0.29584456476019955 | accuracy: 0.8762745468277947 \n",
      "Epoch 11 | Step 4362 | loss: 0.29581568143274417 | accuracy: 0.8761295180722893 \n",
      "Epoch 11 | Step 4363 | loss: 0.29571760618113907 | accuracy: 0.8761261261261263 \n",
      "Epoch 11 | Step 4364 | loss: 0.2956619644147194 | accuracy: 0.8762163173652696 \n",
      "Epoch 11 | Step 4365 | loss: 0.29565477864955797 | accuracy: 0.8762593283582091 \n",
      "Epoch 11 | Step 4366 | loss: 0.29562677456332115 | accuracy: 0.876348586309524 \n",
      "Epoch 11 | Step 4367 | loss: 0.29551928214043477 | accuracy: 0.8763445845697331 \n",
      "Epoch 11 | Step 4368 | loss: 0.29535512626171123 | accuracy: 0.876294378698225 \n",
      "Epoch 11 | Step 4369 | loss: 0.2952132381960355 | accuracy: 0.8765210176991152 \n",
      "Epoch 11 | Step 4370 | loss: 0.2950906015932561 | accuracy: 0.876746323529412 \n",
      "Epoch 11 | Step 4371 | loss: 0.295168430181193 | accuracy: 0.8766953812316717 \n",
      "Epoch 11 | Step 4372 | loss: 0.29510965572986003 | accuracy: 0.8766447368421054 \n",
      "Epoch 11 | Step 4373 | loss: 0.29479662013992286 | accuracy: 0.8767310495626823 \n",
      "Epoch 11 | Step 4374 | loss: 0.29488846360770776 | accuracy: 0.8766351744186048 \n",
      "Epoch 11 | Step 4375 | loss: 0.2946652942377589 | accuracy: 0.8767210144927537 \n",
      "Epoch 11 | Step 4376 | loss: 0.29442750503217563 | accuracy: 0.8769418352601158 \n",
      "Epoch 11 | Step 4377 | loss: 0.2943368399521117 | accuracy: 0.8770262968299714 \n",
      "Epoch 11 | Step 4378 | loss: 0.29421631229677425 | accuracy: 0.8770653735632186 \n",
      "Epoch 11 | Step 4379 | loss: 0.29419283974478105 | accuracy: 0.8771042263610317 \n",
      "Epoch 11 | Step 4380 | loss: 0.29443092371736257 | accuracy: 0.8769642857142859 \n",
      "Epoch 11 | Step 4381 | loss: 0.29410716424300803 | accuracy: 0.8771812678062679 \n",
      "Epoch 11 | Step 4382 | loss: 0.2939695621925322 | accuracy: 0.877130681818182 \n",
      "Epoch 11 | Step 4383 | loss: 0.2940791913706588 | accuracy: 0.8770361189801701 \n",
      "Epoch 11 | Step 4384 | loss: 0.2942793803699946 | accuracy: 0.8768538135593222 \n",
      "Epoch 11 | Step 4385 | loss: 0.29414373480937855 | accuracy: 0.876892605633803 \n",
      "Epoch 11 | Step 4386 | loss: 0.29399126613240567 | accuracy: 0.8769750702247192 \n",
      "Epoch 11 | Step 4387 | loss: 0.2942344887333424 | accuracy: 0.8768382352941178 \n",
      "Epoch 11 | Step 4388 | loss: 0.2946056916310801 | accuracy: 0.8766585195530728 \n",
      "Epoch 11 | Step 4389 | loss: 0.29446386352887066 | accuracy: 0.8767409470752091 \n",
      "Epoch 11 | Step 4390 | loss: 0.2946065646906694 | accuracy: 0.8767361111111113 \n",
      "Epoch 11 | Step 4391 | loss: 0.29458459477015153 | accuracy: 0.876601454293629 \n",
      "Epoch 11 | Step 4392 | loss: 0.2945473887314454 | accuracy: 0.8765538674033151 \n",
      "Epoch 11 | Step 4393 | loss: 0.2945270068717726 | accuracy: 0.8765926308539946 \n",
      "Epoch 11 | Step 4394 | loss: 0.2941150721776617 | accuracy: 0.8768028846153848 \n",
      "Epoch 11 | Step 4395 | loss: 0.2939464959379745 | accuracy: 0.87701198630137 \n",
      "Epoch 11 | Step 4396 | loss: 0.29403955851747693 | accuracy: 0.8770064890710384 \n",
      "Epoch 11 | Step 4397 | loss: 0.29421702863734817 | accuracy: 0.8768307220708449 \n",
      "Epoch 11 | Step 4398 | loss: 0.29404396179091674 | accuracy: 0.8769106657608697 \n",
      "Epoch 11 | Step 4399 | loss: 0.2941966133954403 | accuracy: 0.8769478319783199 \n",
      "Epoch 11 | Step 4400 | loss: 0.29427796251870497 | accuracy: 0.8768158783783785 \n",
      "Epoch 11 | Step 4401 | loss: 0.2944808035606966 | accuracy: 0.8766846361185985 \n",
      "Epoch 11 | Step 4402 | loss: 0.2944162352992002 | accuracy: 0.8766381048387099 \n",
      "Epoch 11 | Step 4403 | loss: 0.29407871244899714 | accuracy: 0.8768012734584452 \n",
      "Epoch 11 | Step 4404 | loss: 0.2938927153454108 | accuracy: 0.8768800133689841 \n",
      "Epoch 11 | Step 4405 | loss: 0.29411059264341993 | accuracy: 0.8767916666666669 \n",
      "Epoch 11 | Step 4406 | loss: 0.294121870691789 | accuracy: 0.8767037898936172 \n",
      "Epoch 11 | Step 4407 | loss: 0.29405561299001515 | accuracy: 0.876616379310345 \n",
      "Epoch 11 | Step 4408 | loss: 0.29406427552618053 | accuracy: 0.8766121031746034 \n",
      "Epoch 11 | Step 4409 | loss: 0.29381592308311166 | accuracy: 0.8766903034300793 \n",
      "Epoch 11 | Step 4410 | loss: 0.2936537370477853 | accuracy: 0.8767680921052633 \n",
      "Epoch 11 | Step 4411 | loss: 0.2933482768654512 | accuracy: 0.876968503937008 \n",
      "Epoch 11 | Step 4412 | loss: 0.29349730885465747 | accuracy: 0.8769224476439792 \n",
      "Epoch 11 | Step 4413 | loss: 0.29356057611208997 | accuracy: 0.876795039164491 \n",
      "Epoch 11 | Step 4414 | loss: 0.2937774249197296 | accuracy: 0.8767903645833335 \n",
      "Epoch 11 | Step 4415 | loss: 0.2937623688926946 | accuracy: 0.8768262987012988 \n",
      "Epoch 11 | Step 4416 | loss: 0.29377088815437097 | accuracy: 0.8767810880829017 \n",
      "Epoch 11 | Step 4417 | loss: 0.2938430859136953 | accuracy: 0.8766957364341087 \n",
      "Epoch 11 | Step 4418 | loss: 0.29393861634829627 | accuracy: 0.8766913659793816 \n",
      "Epoch 11 | Step 4419 | loss: 0.29395146587514037 | accuracy: 0.8766870179948587 \n",
      "Epoch 11 | Step 4420 | loss: 0.2939082515545382 | accuracy: 0.8767628205128206 \n",
      "Epoch 11 | Step 4421 | loss: 0.2939244799906642 | accuracy: 0.8767982736572891 \n",
      "Epoch 11 | Step 4422 | loss: 0.29370441751516607 | accuracy: 0.8769531250000001 \n",
      "Epoch 11 | Step 4423 | loss: 0.2936301074410214 | accuracy: 0.8770276717557254 \n",
      "Epoch 11 | Step 4424 | loss: 0.29389771387964353 | accuracy: 0.8767449238578682 \n",
      "Epoch 11 | Step 4425 | loss: 0.2937075979347472 | accuracy: 0.87685917721519 \n",
      "Epoch 11 | Step 4426 | loss: 0.2934944675576809 | accuracy: 0.8768939393939396 \n",
      "Epoch 11 | Step 4427 | loss: 0.2934050559246872 | accuracy: 0.8769678841309825 \n",
      "Epoch 11 | Step 4428 | loss: 0.2935366655264669 | accuracy: 0.876884422110553 \n",
      "Epoch 11 | Step 4429 | loss: 0.2933500211564522 | accuracy: 0.876918859649123 \n",
      "Epoch 11 | Step 4430 | loss: 0.2932154003530742 | accuracy: 0.8769140625000001 \n",
      "Epoch 11 | Step 4431 | loss: 0.2932851918766327 | accuracy: 0.8768703241895264 \n",
      "Epoch 11 | Step 4432 | loss: 0.29342929018077574 | accuracy: 0.8768268034825872 \n",
      "Epoch 11 | Step 4433 | loss: 0.29326597333102317 | accuracy: 0.8768757487053317 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.45566707849502563 | accuracy: 0.75 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.40982942283153534 | accuracy: 0.8125 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4463416238625844 | accuracy: 0.8072916666666666 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4428457245230675 | accuracy: 0.8046875 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4122018277645111 | accuracy: 0.825 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.42509559293588 | accuracy: 0.8125 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4198349288531712 | accuracy: 0.8125 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4129857160151005 | accuracy: 0.81640625 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.43418259421984357 | accuracy: 0.8125 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.41978142857551576 | accuracy: 0.81875 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4193689796057614 | accuracy: 0.8196022727272727 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4091138343016307 | accuracy: 0.82421875 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.41594841617804307 | accuracy: 0.8209134615384616 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.40778397236551556 | accuracy: 0.8236607142857143 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4130264381567637 | accuracy: 0.8270833333333333 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4147696103900671 | accuracy: 0.826171875 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4214790691347683 | accuracy: 0.8235294117647058 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.420596655872133 | accuracy: 0.8246527777777778 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4159573159719768 | accuracy: 0.8273026315789473 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.41426446437835696 | accuracy: 0.82578125 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.40826742847760517 | accuracy: 0.8273809523809523 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.40315703641284595 | accuracy: 0.8302556818181818 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.40766835990159406 | accuracy: 0.828125 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4241182208061218 | accuracy: 0.8235677083333334 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.43262212991714477 | accuracy: 0.820625 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4298836485697673 | accuracy: 0.8209134615384616 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.42445350576330115 | accuracy: 0.8234953703703703 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.42675729947430746 | accuracy: 0.8214285714285714 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4232364358573124 | accuracy: 0.8227370689655172 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4205791642268499 | accuracy: 0.825 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.41531873326147756 | accuracy: 0.8276209677419355 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4184804856777191 | accuracy: 0.8251953125 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.41911084362954804 | accuracy: 0.8248106060606061 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.42401047839837913 | accuracy: 0.8230698529411765 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.42408811705453053 | accuracy: 0.8236607142857143 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4218866303563118 | accuracy: 0.8246527777777778 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.42276701894966334 | accuracy: 0.825168918918919 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4243350013306266 | accuracy: 0.8264802631578948 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.42247410386036605 | accuracy: 0.827323717948718 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4201867803931236 | accuracy: 0.828515625 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.41862993414809063 | accuracy: 0.828125 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.41587550867171513 | accuracy: 0.8292410714285714 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.4161259871582652 | accuracy: 0.829578488372093 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.41897907243533566 | accuracy: 0.8274147727272727 \n",
      "Validation | Epoch 11 | Step 4433 | loss: 0.41845332384109496 | accuracy: 0.8264190819528368 \n",
      "Epoch 12 | Step 4434 | loss: 0.4299601912498474 | accuracy: 0.8125 \n",
      "Epoch 12 | Step 4435 | loss: 0.2983529642224312 | accuracy: 0.8828125 \n",
      "Epoch 12 | Step 4436 | loss: 0.2839207500219345 | accuracy: 0.890625 \n",
      "Epoch 12 | Step 4437 | loss: 0.2993103228509426 | accuracy: 0.8828125 \n",
      "Epoch 12 | Step 4438 | loss: 0.27940185070037843 | accuracy: 0.896875 \n",
      "Epoch 12 | Step 4439 | loss: 0.27029664317766827 | accuracy: 0.9036458333333334 \n",
      "Epoch 12 | Step 4440 | loss: 0.2745509743690491 | accuracy: 0.8995535714285714 \n",
      "Epoch 12 | Step 4441 | loss: 0.2726495489478111 | accuracy: 0.8984375 \n",
      "Epoch 12 | Step 4442 | loss: 0.2783264418443044 | accuracy: 0.8923611111111112 \n",
      "Epoch 12 | Step 4443 | loss: 0.29140793681144717 | accuracy: 0.8890625 \n",
      "Epoch 12 | Step 4444 | loss: 0.2810673171823675 | accuracy: 0.8934659090909091 \n",
      "Epoch 12 | Step 4445 | loss: 0.2750336689253648 | accuracy: 0.8971354166666666 \n",
      "Epoch 12 | Step 4446 | loss: 0.28822010640914625 | accuracy: 0.8894230769230769 \n",
      "Epoch 12 | Step 4447 | loss: 0.28555930831602644 | accuracy: 0.890625 \n",
      "Epoch 12 | Step 4448 | loss: 0.28535143037637073 | accuracy: 0.8895833333333333 \n",
      "Epoch 12 | Step 4449 | loss: 0.2763245552778244 | accuracy: 0.8955078125 \n",
      "Epoch 12 | Step 4450 | loss: 0.27722786454593434 | accuracy: 0.8915441176470589 \n",
      "Epoch 12 | Step 4451 | loss: 0.274772225982613 | accuracy: 0.8949652777777778 \n",
      "Epoch 12 | Step 4452 | loss: 0.274020340097578 | accuracy: 0.8939144736842105 \n",
      "Epoch 12 | Step 4453 | loss: 0.2788062028586865 | accuracy: 0.8921875 \n",
      "Epoch 12 | Step 4454 | loss: 0.2786389113891693 | accuracy: 0.8928571428571429 \n",
      "Epoch 12 | Step 4455 | loss: 0.27995158122344455 | accuracy: 0.8934659090909091 \n",
      "Epoch 12 | Step 4456 | loss: 0.27827675770158355 | accuracy: 0.8947010869565217 \n",
      "Epoch 12 | Step 4457 | loss: 0.27885819288591546 | accuracy: 0.8932291666666666 \n",
      "Epoch 12 | Step 4458 | loss: 0.2838486796617508 | accuracy: 0.89 \n",
      "Epoch 12 | Step 4459 | loss: 0.28339911023011577 | accuracy: 0.8882211538461539 \n",
      "Epoch 12 | Step 4460 | loss: 0.2847230439936674 | accuracy: 0.8877314814814815 \n",
      "Epoch 12 | Step 4461 | loss: 0.2831973667655673 | accuracy: 0.8889508928571429 \n",
      "Epoch 12 | Step 4462 | loss: 0.28712405829594057 | accuracy: 0.8879310344827587 \n",
      "Epoch 12 | Step 4463 | loss: 0.28698951502641046 | accuracy: 0.8875 \n",
      "Epoch 12 | Step 4464 | loss: 0.28530918590484133 | accuracy: 0.8886088709677419 \n",
      "Epoch 12 | Step 4465 | loss: 0.28518175613135105 | accuracy: 0.88818359375 \n",
      "Epoch 12 | Step 4466 | loss: 0.28519558725935046 | accuracy: 0.8887310606060606 \n",
      "Epoch 12 | Step 4467 | loss: 0.2818148215027417 | accuracy: 0.890625 \n",
      "Epoch 12 | Step 4468 | loss: 0.27856119487966813 | accuracy: 0.8915178571428571 \n",
      "Epoch 12 | Step 4469 | loss: 0.2781265522870753 | accuracy: 0.8914930555555556 \n",
      "Epoch 12 | Step 4470 | loss: 0.27851669893071457 | accuracy: 0.8910472972972973 \n",
      "Epoch 12 | Step 4471 | loss: 0.27920377999544144 | accuracy: 0.8902138157894737 \n",
      "Epoch 12 | Step 4472 | loss: 0.2769120943087798 | accuracy: 0.8910256410256411 \n",
      "Epoch 12 | Step 4473 | loss: 0.2749726284295321 | accuracy: 0.8921875 \n",
      "Epoch 12 | Step 4474 | loss: 0.27505419058043784 | accuracy: 0.8921493902439024 \n",
      "Epoch 12 | Step 4475 | loss: 0.2751931423942248 | accuracy: 0.8909970238095238 \n",
      "Epoch 12 | Step 4476 | loss: 0.2738630303809809 | accuracy: 0.890625 \n",
      "Epoch 12 | Step 4477 | loss: 0.2725449478761716 | accuracy: 0.8909801136363636 \n",
      "Epoch 12 | Step 4478 | loss: 0.2732304549879498 | accuracy: 0.8920138888888889 \n",
      "Epoch 12 | Step 4479 | loss: 0.27461624501839926 | accuracy: 0.890625 \n",
      "Epoch 12 | Step 4480 | loss: 0.2756572406976781 | accuracy: 0.8899601063829787 \n",
      "Epoch 12 | Step 4481 | loss: 0.2754594649498661 | accuracy: 0.8902994791666666 \n",
      "Epoch 12 | Step 4482 | loss: 0.2777418880438318 | accuracy: 0.8896683673469388 \n",
      "Epoch 12 | Step 4483 | loss: 0.27927856355905534 | accuracy: 0.8890625 \n",
      "Epoch 12 | Step 4484 | loss: 0.2789072134331161 | accuracy: 0.8890931372549019 \n",
      "Epoch 12 | Step 4485 | loss: 0.27701484583891356 | accuracy: 0.8900240384615384 \n",
      "Epoch 12 | Step 4486 | loss: 0.27847358359480806 | accuracy: 0.8885613207547169 \n",
      "Epoch 12 | Step 4487 | loss: 0.27773244292647753 | accuracy: 0.8885995370370371 \n",
      "Epoch 12 | Step 4488 | loss: 0.27917366082018075 | accuracy: 0.8875 \n",
      "Epoch 12 | Step 4489 | loss: 0.2786408974123853 | accuracy: 0.8875558035714286 \n",
      "Epoch 12 | Step 4490 | loss: 0.2798217631745757 | accuracy: 0.8862390350877193 \n",
      "Epoch 12 | Step 4491 | loss: 0.27982817975611524 | accuracy: 0.8863146551724138 \n",
      "Epoch 12 | Step 4492 | loss: 0.2809580819586576 | accuracy: 0.8863877118644068 \n",
      "Epoch 12 | Step 4493 | loss: 0.28134779011209804 | accuracy: 0.8864583333333333 \n",
      "Epoch 12 | Step 4494 | loss: 0.2803202869950748 | accuracy: 0.8870389344262295 \n",
      "Epoch 12 | Step 4495 | loss: 0.2798368726526537 | accuracy: 0.8876008064516129 \n",
      "Epoch 12 | Step 4496 | loss: 0.28170232190972283 | accuracy: 0.8871527777777778 \n",
      "Epoch 12 | Step 4497 | loss: 0.27988190203905106 | accuracy: 0.88818359375 \n",
      "Epoch 12 | Step 4498 | loss: 0.27871603346787965 | accuracy: 0.8889423076923076 \n",
      "Epoch 12 | Step 4499 | loss: 0.2776786700794191 | accuracy: 0.888967803030303 \n",
      "Epoch 12 | Step 4500 | loss: 0.27681834017162893 | accuracy: 0.8894589552238806 \n",
      "Epoch 12 | Step 4501 | loss: 0.27725861900869536 | accuracy: 0.8892463235294118 \n",
      "Epoch 12 | Step 4502 | loss: 0.2778518348932266 | accuracy: 0.889266304347826 \n",
      "Epoch 12 | Step 4503 | loss: 0.2773848665612085 | accuracy: 0.8895089285714286 \n",
      "Epoch 12 | Step 4504 | loss: 0.2757987657063444 | accuracy: 0.8904049295774648 \n",
      "Epoch 12 | Step 4505 | loss: 0.2749729638712274 | accuracy: 0.8908420138888888 \n",
      "Epoch 12 | Step 4506 | loss: 0.2750220488603801 | accuracy: 0.8897688356164384 \n",
      "Epoch 12 | Step 4507 | loss: 0.2751582399816127 | accuracy: 0.8891469594594594 \n",
      "Epoch 12 | Step 4508 | loss: 0.27523850897947955 | accuracy: 0.88875 \n",
      "Epoch 12 | Step 4509 | loss: 0.27514193932476805 | accuracy: 0.8889802631578947 \n",
      "Epoch 12 | Step 4510 | loss: 0.27464312334339347 | accuracy: 0.8890016233766234 \n",
      "Epoch 12 | Step 4511 | loss: 0.275694268445174 | accuracy: 0.8882211538461539 \n",
      "Epoch 12 | Step 4512 | loss: 0.27755819562869743 | accuracy: 0.8874604430379747 \n",
      "Epoch 12 | Step 4513 | loss: 0.27768040429800755 | accuracy: 0.8873046875 \n",
      "Epoch 12 | Step 4514 | loss: 0.27735350952472226 | accuracy: 0.8875385802469136 \n",
      "Epoch 12 | Step 4515 | loss: 0.2766626469972658 | accuracy: 0.8875762195121951 \n",
      "Epoch 12 | Step 4516 | loss: 0.27667818012007755 | accuracy: 0.8874246987951807 \n",
      "Epoch 12 | Step 4517 | loss: 0.2764298209831829 | accuracy: 0.8874627976190477 \n",
      "Epoch 12 | Step 4518 | loss: 0.2756409382118899 | accuracy: 0.8880514705882353 \n",
      "Epoch 12 | Step 4519 | loss: 0.2755973477696264 | accuracy: 0.887718023255814 \n",
      "Epoch 12 | Step 4520 | loss: 0.27746839256122197 | accuracy: 0.8868534482758621 \n",
      "Epoch 12 | Step 4521 | loss: 0.2779258506541903 | accuracy: 0.8868963068181818 \n",
      "Epoch 12 | Step 4522 | loss: 0.2766640244909887 | accuracy: 0.8876404494382022 \n",
      "Epoch 12 | Step 4523 | loss: 0.27741183290878935 | accuracy: 0.8873263888888889 \n",
      "Epoch 12 | Step 4524 | loss: 0.2765432047647435 | accuracy: 0.8878777472527473 \n",
      "Epoch 12 | Step 4525 | loss: 0.27590423239314044 | accuracy: 0.888077445652174 \n",
      "Epoch 12 | Step 4526 | loss: 0.2757499471146574 | accuracy: 0.8879368279569892 \n",
      "Epoch 12 | Step 4527 | loss: 0.275288630039134 | accuracy: 0.8879654255319149 \n",
      "Epoch 12 | Step 4528 | loss: 0.2759752778630508 | accuracy: 0.8879934210526316 \n",
      "Epoch 12 | Step 4529 | loss: 0.27769588306546217 | accuracy: 0.8873697916666666 \n",
      "Epoch 12 | Step 4530 | loss: 0.2777233639943232 | accuracy: 0.8875644329896907 \n",
      "Epoch 12 | Step 4531 | loss: 0.27895655102875777 | accuracy: 0.8869579081632653 \n",
      "Epoch 12 | Step 4532 | loss: 0.278669826611124 | accuracy: 0.8871527777777778 \n",
      "Epoch 12 | Step 4533 | loss: 0.27795356303453456 | accuracy: 0.8875 \n",
      "Epoch 12 | Step 4534 | loss: 0.27662663692885114 | accuracy: 0.8884591584158416 \n",
      "Epoch 12 | Step 4535 | loss: 0.2763921704654601 | accuracy: 0.8886335784313726 \n",
      "Epoch 12 | Step 4536 | loss: 0.2755966336981765 | accuracy: 0.8889563106796117 \n",
      "Epoch 12 | Step 4537 | loss: 0.27650801207010567 | accuracy: 0.8885216346153846 \n",
      "Epoch 12 | Step 4538 | loss: 0.2777540601435162 | accuracy: 0.887797619047619 \n",
      "Epoch 12 | Step 4539 | loss: 0.27717201566358785 | accuracy: 0.8878242924528302 \n",
      "Epoch 12 | Step 4540 | loss: 0.2783610315244889 | accuracy: 0.8874123831775701 \n",
      "Epoch 12 | Step 4541 | loss: 0.2797370855179098 | accuracy: 0.88671875 \n",
      "Epoch 12 | Step 4542 | loss: 0.28010425012592877 | accuracy: 0.8868979357798165 \n",
      "Epoch 12 | Step 4543 | loss: 0.2809292932802981 | accuracy: 0.8866477272727272 \n",
      "Epoch 12 | Step 4544 | loss: 0.28063331061118363 | accuracy: 0.886402027027027 \n",
      "Epoch 12 | Step 4545 | loss: 0.2803216120228172 | accuracy: 0.8864397321428571 \n",
      "Epoch 12 | Step 4546 | loss: 0.281593624601322 | accuracy: 0.8860619469026548 \n",
      "Epoch 12 | Step 4547 | loss: 0.2823951909678024 | accuracy: 0.8859649122807017 \n",
      "Epoch 12 | Step 4548 | loss: 0.28214908928974813 | accuracy: 0.8857336956521739 \n",
      "Epoch 12 | Step 4549 | loss: 0.28196540718962404 | accuracy: 0.8857758620689655 \n",
      "Epoch 12 | Step 4550 | loss: 0.2826739163734974 | accuracy: 0.8854166666666666 \n",
      "Epoch 12 | Step 4551 | loss: 0.28287737589266343 | accuracy: 0.885593220338983 \n",
      "Epoch 12 | Step 4552 | loss: 0.2829641718573931 | accuracy: 0.885766806722689 \n",
      "Epoch 12 | Step 4553 | loss: 0.2824732158333063 | accuracy: 0.8859375 \n",
      "Epoch 12 | Step 4554 | loss: 0.28211421180855145 | accuracy: 0.8861053719008265 \n",
      "Epoch 12 | Step 4555 | loss: 0.28201681631998937 | accuracy: 0.8860143442622951 \n",
      "Epoch 12 | Step 4556 | loss: 0.28203728540641504 | accuracy: 0.8860518292682927 \n",
      "Epoch 12 | Step 4557 | loss: 0.28232667342789713 | accuracy: 0.8860887096774194 \n",
      "Epoch 12 | Step 4558 | loss: 0.2824201098680496 | accuracy: 0.885875 \n",
      "Epoch 12 | Step 4559 | loss: 0.28238336824708515 | accuracy: 0.8859126984126984 \n",
      "Epoch 12 | Step 4560 | loss: 0.2826944097993881 | accuracy: 0.8858267716535433 \n",
      "Epoch 12 | Step 4561 | loss: 0.28217034484259784 | accuracy: 0.8857421875 \n",
      "Epoch 12 | Step 4562 | loss: 0.28209628430447836 | accuracy: 0.8855377906976745 \n",
      "Epoch 12 | Step 4563 | loss: 0.28152141777368694 | accuracy: 0.8859375 \n",
      "Epoch 12 | Step 4564 | loss: 0.28233441596722786 | accuracy: 0.8856154580152672 \n",
      "Epoch 12 | Step 4565 | loss: 0.2832199883731929 | accuracy: 0.8854166666666666 \n",
      "Epoch 12 | Step 4566 | loss: 0.28431091003848197 | accuracy: 0.8848684210526315 \n",
      "Epoch 12 | Step 4567 | loss: 0.2845825499563075 | accuracy: 0.8844449626865671 \n",
      "Epoch 12 | Step 4568 | loss: 0.28462292662373295 | accuracy: 0.884375 \n",
      "Epoch 12 | Step 4569 | loss: 0.2842052036567646 | accuracy: 0.8845358455882353 \n",
      "Epoch 12 | Step 4570 | loss: 0.2837533751760956 | accuracy: 0.8846943430656934 \n",
      "Epoch 12 | Step 4571 | loss: 0.28335919036813406 | accuracy: 0.8848505434782609 \n",
      "Epoch 12 | Step 4572 | loss: 0.2839358574409279 | accuracy: 0.8844424460431655 \n",
      "Epoch 12 | Step 4573 | loss: 0.2839094616472721 | accuracy: 0.8845982142857143 \n",
      "Epoch 12 | Step 4574 | loss: 0.2850718486604961 | accuracy: 0.884197695035461 \n",
      "Epoch 12 | Step 4575 | loss: 0.28490181109854873 | accuracy: 0.8843529929577465 \n",
      "Epoch 12 | Step 4576 | loss: 0.2853411824761571 | accuracy: 0.8840690559440559 \n",
      "Epoch 12 | Step 4577 | loss: 0.28570299978471464 | accuracy: 0.8835720486111112 \n",
      "Epoch 12 | Step 4578 | loss: 0.285675968281154 | accuracy: 0.8835129310344828 \n",
      "Epoch 12 | Step 4579 | loss: 0.28586680401269704 | accuracy: 0.883347602739726 \n",
      "Epoch 12 | Step 4580 | loss: 0.28521283761579164 | accuracy: 0.8838222789115646 \n",
      "Epoch 12 | Step 4581 | loss: 0.28532621939037295 | accuracy: 0.8834459459459459 \n",
      "Epoch 12 | Step 4582 | loss: 0.28519565257050045 | accuracy: 0.8834941275167785 \n",
      "Epoch 12 | Step 4583 | loss: 0.28553204009930294 | accuracy: 0.8836458333333334 \n",
      "Epoch 12 | Step 4584 | loss: 0.28565682668164866 | accuracy: 0.8835885761589404 \n",
      "Epoch 12 | Step 4585 | loss: 0.2863594725924103 | accuracy: 0.8834292763157895 \n",
      "Epoch 12 | Step 4586 | loss: 0.2865941646247128 | accuracy: 0.8833741830065359 \n",
      "Epoch 12 | Step 4587 | loss: 0.28610228853566305 | accuracy: 0.8836241883116883 \n",
      "Epoch 12 | Step 4588 | loss: 0.28568317649825925 | accuracy: 0.8839717741935483 \n",
      "Epoch 12 | Step 4589 | loss: 0.28473504498983043 | accuracy: 0.8845152243589743 \n",
      "Epoch 12 | Step 4590 | loss: 0.2849309070474783 | accuracy: 0.8844546178343949 \n",
      "Epoch 12 | Step 4591 | loss: 0.28505913932112203 | accuracy: 0.8841969936708861 \n",
      "Epoch 12 | Step 4592 | loss: 0.28523739760026995 | accuracy: 0.8838443396226415 \n",
      "Epoch 12 | Step 4593 | loss: 0.2857295755296946 | accuracy: 0.88330078125 \n",
      "Epoch 12 | Step 4594 | loss: 0.2859009696830134 | accuracy: 0.8831521739130435 \n",
      "Epoch 12 | Step 4595 | loss: 0.2859295792417762 | accuracy: 0.8830054012345679 \n",
      "Epoch 12 | Step 4596 | loss: 0.28675227863656966 | accuracy: 0.8825728527607362 \n",
      "Epoch 12 | Step 4597 | loss: 0.28660517821951614 | accuracy: 0.8825266768292683 \n",
      "Epoch 12 | Step 4598 | loss: 0.28650581963134536 | accuracy: 0.8825757575757576 \n",
      "Epoch 12 | Step 4599 | loss: 0.28673993086958505 | accuracy: 0.8824359939759037 \n",
      "Epoch 12 | Step 4600 | loss: 0.2865342667359792 | accuracy: 0.8825785928143712 \n",
      "Epoch 12 | Step 4601 | loss: 0.2873674625796931 | accuracy: 0.8821614583333334 \n",
      "Epoch 12 | Step 4602 | loss: 0.28705820441246027 | accuracy: 0.8823039940828402 \n",
      "Epoch 12 | Step 4603 | loss: 0.2862343279754414 | accuracy: 0.8828125 \n",
      "Epoch 12 | Step 4604 | loss: 0.2861522012635281 | accuracy: 0.8829495614035088 \n",
      "Epoch 12 | Step 4605 | loss: 0.28635181833145223 | accuracy: 0.8828125 \n",
      "Epoch 12 | Step 4606 | loss: 0.2859791110705777 | accuracy: 0.8828576589595376 \n",
      "Epoch 12 | Step 4607 | loss: 0.28603734161661953 | accuracy: 0.8829920977011494 \n",
      "Epoch 12 | Step 4608 | loss: 0.2858725135666983 | accuracy: 0.8829464285714286 \n",
      "Epoch 12 | Step 4609 | loss: 0.28618878329342057 | accuracy: 0.8828125 \n",
      "Epoch 12 | Step 4610 | loss: 0.28700262981619534 | accuracy: 0.8826800847457628 \n",
      "Epoch 12 | Step 4611 | loss: 0.28758893639184113 | accuracy: 0.8822858146067416 \n",
      "Epoch 12 | Step 4612 | loss: 0.28800342752280844 | accuracy: 0.882070530726257 \n",
      "Epoch 12 | Step 4613 | loss: 0.2877321461836497 | accuracy: 0.8821180555555556 \n",
      "Epoch 12 | Step 4614 | loss: 0.28800269763772657 | accuracy: 0.8816470994475138 \n",
      "Epoch 12 | Step 4615 | loss: 0.2877740254113962 | accuracy: 0.8817822802197802 \n",
      "Epoch 12 | Step 4616 | loss: 0.28714461502481675 | accuracy: 0.8820867486338798 \n",
      "Epoch 12 | Step 4617 | loss: 0.286620686640558 | accuracy: 0.8823029891304348 \n",
      "Epoch 12 | Step 4618 | loss: 0.2864257537835353 | accuracy: 0.8825168918918919 \n",
      "Epoch 12 | Step 4619 | loss: 0.28681783273976336 | accuracy: 0.8822244623655914 \n",
      "Epoch 12 | Step 4620 | loss: 0.28725260854723617 | accuracy: 0.8821022727272727 \n",
      "Epoch 12 | Step 4621 | loss: 0.2872542192802784 | accuracy: 0.8818982712765957 \n",
      "Epoch 12 | Step 4622 | loss: 0.2870527438858829 | accuracy: 0.8819444444444444 \n",
      "Epoch 12 | Step 4623 | loss: 0.28778144474092276 | accuracy: 0.8818256578947369 \n",
      "Epoch 12 | Step 4624 | loss: 0.2872756828812404 | accuracy: 0.8819535340314136 \n",
      "Epoch 12 | Step 4625 | loss: 0.2869729249893377 | accuracy: 0.882080078125 \n",
      "Epoch 12 | Step 4626 | loss: 0.2865685880029757 | accuracy: 0.8823672279792746 \n",
      "Epoch 12 | Step 4627 | loss: 0.2864147046024037 | accuracy: 0.882409793814433 \n",
      "Epoch 12 | Step 4628 | loss: 0.2861186517354769 | accuracy: 0.8825320512820513 \n",
      "Epoch 12 | Step 4629 | loss: 0.2861864546275868 | accuracy: 0.8825733418367347 \n",
      "Epoch 12 | Step 4630 | loss: 0.2863193817701436 | accuracy: 0.8825348984771574 \n",
      "Epoch 12 | Step 4631 | loss: 0.28639705862962833 | accuracy: 0.8825757575757576 \n",
      "Epoch 12 | Step 4632 | loss: 0.28610394206178846 | accuracy: 0.8828517587939698 \n",
      "Epoch 12 | Step 4633 | loss: 0.2856587255001068 | accuracy: 0.882890625 \n",
      "Epoch 12 | Step 4634 | loss: 0.28632713150029154 | accuracy: 0.8826181592039801 \n",
      "Epoch 12 | Step 4635 | loss: 0.2860803925755 | accuracy: 0.8828125 \n",
      "Epoch 12 | Step 4636 | loss: 0.2861084757473668 | accuracy: 0.8826970443349754 \n",
      "Epoch 12 | Step 4637 | loss: 0.2859879632790883 | accuracy: 0.8827359068627451 \n",
      "Epoch 12 | Step 4638 | loss: 0.28604851743070087 | accuracy: 0.8826219512195121 \n",
      "Epoch 12 | Step 4639 | loss: 0.28690113575713144 | accuracy: 0.8823574029126213 \n",
      "Epoch 12 | Step 4640 | loss: 0.2873901177719595 | accuracy: 0.8823218599033816 \n",
      "Epoch 12 | Step 4641 | loss: 0.2872275328980042 | accuracy: 0.8823617788461539 \n",
      "Epoch 12 | Step 4642 | loss: 0.2869482776194668 | accuracy: 0.8825508373205742 \n",
      "Epoch 12 | Step 4643 | loss: 0.28711027162415637 | accuracy: 0.8825892857142857 \n",
      "Epoch 12 | Step 4644 | loss: 0.28740696870320215 | accuracy: 0.8823311611374408 \n",
      "Epoch 12 | Step 4645 | loss: 0.2868523194964202 | accuracy: 0.882591391509434 \n",
      "Epoch 12 | Step 4646 | loss: 0.2864676550940169 | accuracy: 0.8827758215962441 \n",
      "Epoch 12 | Step 4647 | loss: 0.286603027206158 | accuracy: 0.8828855140186916 \n",
      "Epoch 12 | Step 4648 | loss: 0.2863003062647443 | accuracy: 0.882921511627907 \n",
      "Epoch 12 | Step 4649 | loss: 0.2863323931340818 | accuracy: 0.8828848379629629 \n",
      "Epoch 12 | Step 4650 | loss: 0.28589251932735266 | accuracy: 0.8830645161290323 \n",
      "Epoch 12 | Step 4651 | loss: 0.2857991610781862 | accuracy: 0.8830275229357798 \n",
      "Epoch 12 | Step 4652 | loss: 0.28579941371532336 | accuracy: 0.8831335616438356 \n",
      "Epoch 12 | Step 4653 | loss: 0.2858516246757724 | accuracy: 0.8830255681818182 \n",
      "Epoch 12 | Step 4654 | loss: 0.2859763084358759 | accuracy: 0.8829892533936652 \n",
      "Epoch 12 | Step 4655 | loss: 0.28600820462714444 | accuracy: 0.8830236486486487 \n",
      "Epoch 12 | Step 4656 | loss: 0.28609015568756735 | accuracy: 0.882917600896861 \n",
      "Epoch 12 | Step 4657 | loss: 0.2854286172826375 | accuracy: 0.8834402901785714 \n",
      "Epoch 12 | Step 4658 | loss: 0.28548730068736605 | accuracy: 0.8834027777777778 \n",
      "Epoch 12 | Step 4659 | loss: 0.2856228606099576 | accuracy: 0.8833655973451328 \n",
      "Epoch 12 | Step 4660 | loss: 0.2857281517089726 | accuracy: 0.8831222466960352 \n",
      "Epoch 12 | Step 4661 | loss: 0.285678617525519 | accuracy: 0.8832236842105263 \n",
      "Epoch 12 | Step 4662 | loss: 0.28556689867286184 | accuracy: 0.8832560043668122 \n",
      "Epoch 12 | Step 4663 | loss: 0.28559696052385414 | accuracy: 0.8832880434782608 \n",
      "Epoch 12 | Step 4664 | loss: 0.28530431103396725 | accuracy: 0.8833874458874459 \n",
      "Epoch 12 | Step 4665 | loss: 0.28500448257244865 | accuracy: 0.8837553879310345 \n",
      "Epoch 12 | Step 4666 | loss: 0.2849608511372186 | accuracy: 0.8835836909871244 \n",
      "Epoch 12 | Step 4667 | loss: 0.28489583501449 | accuracy: 0.883613782051282 \n",
      "Epoch 12 | Step 4668 | loss: 0.2845675636479195 | accuracy: 0.883843085106383 \n",
      "Epoch 12 | Step 4669 | loss: 0.28428457614223834 | accuracy: 0.8840042372881356 \n",
      "Epoch 12 | Step 4670 | loss: 0.28403661679869463 | accuracy: 0.8840981012658228 \n",
      "Epoch 12 | Step 4671 | loss: 0.2840816092466106 | accuracy: 0.8839285714285714 \n",
      "Epoch 12 | Step 4672 | loss: 0.2840957910321248 | accuracy: 0.883956589958159 \n",
      "Epoch 12 | Step 4673 | loss: 0.28404755412290494 | accuracy: 0.8839192708333333 \n",
      "Epoch 12 | Step 4674 | loss: 0.28341060141062835 | accuracy: 0.8841415975103735 \n",
      "Epoch 12 | Step 4675 | loss: 0.28292967268258085 | accuracy: 0.884426652892562 \n",
      "Epoch 12 | Step 4676 | loss: 0.28328649779406107 | accuracy: 0.8843878600823045 \n",
      "Epoch 12 | Step 4677 | loss: 0.28389642387628555 | accuracy: 0.884093237704918 \n",
      "Epoch 12 | Step 4678 | loss: 0.2839220074974761 | accuracy: 0.8841198979591837 \n",
      "Epoch 12 | Step 4679 | loss: 0.283934023200981 | accuracy: 0.8840193089430894 \n",
      "Epoch 12 | Step 4680 | loss: 0.2837773894491466 | accuracy: 0.8842990890688259 \n",
      "Epoch 12 | Step 4681 | loss: 0.28410150567370074 | accuracy: 0.8841985887096774 \n",
      "Epoch 12 | Step 4682 | loss: 0.2839539007968213 | accuracy: 0.8842871485943775 \n",
      "Epoch 12 | Step 4683 | loss: 0.28403366219997406 | accuracy: 0.884375 \n",
      "Epoch 12 | Step 4684 | loss: 0.2837192282021283 | accuracy: 0.8846489043824701 \n",
      "Epoch 12 | Step 4685 | loss: 0.2835207934535685 | accuracy: 0.8846106150793651 \n",
      "Epoch 12 | Step 4686 | loss: 0.2832774949874802 | accuracy: 0.8846343873517787 \n",
      "Epoch 12 | Step 4687 | loss: 0.28321058062587195 | accuracy: 0.8845349409448819 \n",
      "Epoch 12 | Step 4688 | loss: 0.2830432864380818 | accuracy: 0.8847426470588236 \n",
      "Epoch 12 | Step 4689 | loss: 0.28312860504956916 | accuracy: 0.88470458984375 \n",
      "Epoch 12 | Step 4690 | loss: 0.28305367313702284 | accuracy: 0.8847276264591439 \n",
      "Epoch 12 | Step 4691 | loss: 0.2826282662130141 | accuracy: 0.8848716085271318 \n",
      "Epoch 12 | Step 4692 | loss: 0.2827918037599578 | accuracy: 0.8848334942084942 \n",
      "Epoch 12 | Step 4693 | loss: 0.28250648448100457 | accuracy: 0.8848557692307693 \n",
      "Epoch 12 | Step 4694 | loss: 0.2830761359340843 | accuracy: 0.8845186781609196 \n",
      "Epoch 12 | Step 4695 | loss: 0.28326088451702175 | accuracy: 0.8843034351145038 \n",
      "Epoch 12 | Step 4696 | loss: 0.28297301412988524 | accuracy: 0.8843868821292775 \n",
      "Epoch 12 | Step 4697 | loss: 0.28338459077658074 | accuracy: 0.8842329545454546 \n",
      "Epoch 12 | Step 4698 | loss: 0.2832503134911915 | accuracy: 0.8843160377358491 \n",
      "Epoch 12 | Step 4699 | loss: 0.283183951855154 | accuracy: 0.8843397556390977 \n",
      "Epoch 12 | Step 4700 | loss: 0.28290796899393705 | accuracy: 0.8845388576779026 \n",
      "Epoch 12 | Step 4701 | loss: 0.2825707748198687 | accuracy: 0.8847947761194029 \n",
      "Epoch 12 | Step 4702 | loss: 0.2825613044562393 | accuracy: 0.8848745353159851 \n",
      "Epoch 12 | Step 4703 | loss: 0.2823840503339414 | accuracy: 0.885011574074074 \n",
      "Epoch 12 | Step 4704 | loss: 0.2824930128576131 | accuracy: 0.8849169741697417 \n",
      "Epoch 12 | Step 4705 | loss: 0.28235341860529256 | accuracy: 0.8849379595588235 \n",
      "Epoch 12 | Step 4706 | loss: 0.2826255924535758 | accuracy: 0.8847298534798534 \n",
      "Epoch 12 | Step 4707 | loss: 0.2825975642152076 | accuracy: 0.8845802919708029 \n",
      "Epoch 12 | Step 4708 | loss: 0.28261425560170955 | accuracy: 0.8846022727272728 \n",
      "Epoch 12 | Step 4709 | loss: 0.2828027610329614 | accuracy: 0.8843976449275363 \n",
      "Epoch 12 | Step 4710 | loss: 0.2826338884847689 | accuracy: 0.8844765342960289 \n",
      "Epoch 12 | Step 4711 | loss: 0.2823907514270261 | accuracy: 0.8846110611510791 \n",
      "Epoch 12 | Step 4712 | loss: 0.28240008326414234 | accuracy: 0.8845206093189965 \n",
      "Epoch 12 | Step 4713 | loss: 0.2821434427052736 | accuracy: 0.884765625 \n",
      "Epoch 12 | Step 4714 | loss: 0.282660529759855 | accuracy: 0.8842860320284698 \n",
      "Epoch 12 | Step 4715 | loss: 0.28245472712508324 | accuracy: 0.8843639184397163 \n",
      "Epoch 12 | Step 4716 | loss: 0.2824631398115899 | accuracy: 0.8843308303886925 \n",
      "Epoch 12 | Step 4717 | loss: 0.2823799579391177 | accuracy: 0.8843529929577465 \n",
      "Epoch 12 | Step 4718 | loss: 0.2822140868295703 | accuracy: 0.8845394736842105 \n",
      "Epoch 12 | Step 4719 | loss: 0.28217895995903675 | accuracy: 0.8846153846153846 \n",
      "Epoch 12 | Step 4720 | loss: 0.2818968642360241 | accuracy: 0.8846907665505227 \n",
      "Epoch 12 | Step 4721 | loss: 0.2815742645826604 | accuracy: 0.8848198784722223 \n",
      "Epoch 12 | Step 4722 | loss: 0.28136996233958267 | accuracy: 0.8848940311418686 \n",
      "Epoch 12 | Step 4723 | loss: 0.28183665064902136 | accuracy: 0.884698275862069 \n",
      "Epoch 12 | Step 4724 | loss: 0.2817024783682577 | accuracy: 0.8847186426116839 \n",
      "Epoch 12 | Step 4725 | loss: 0.28179825184075796 | accuracy: 0.8847388698630136 \n",
      "Epoch 12 | Step 4726 | loss: 0.2818939369998287 | accuracy: 0.8847589590443686 \n",
      "Epoch 12 | Step 4727 | loss: 0.2815657622960149 | accuracy: 0.884938350340136 \n",
      "Epoch 12 | Step 4728 | loss: 0.2821107207718542 | accuracy: 0.8847457627118644 \n",
      "Epoch 12 | Step 4729 | loss: 0.2820092833324058 | accuracy: 0.884765625 \n",
      "Epoch 12 | Step 4730 | loss: 0.2823061160366944 | accuracy: 0.8845749158249159 \n",
      "Epoch 12 | Step 4731 | loss: 0.2822844863137942 | accuracy: 0.8844903523489933 \n",
      "Epoch 12 | Step 4732 | loss: 0.28214038315425344 | accuracy: 0.884563127090301 \n",
      "Epoch 12 | Step 4733 | loss: 0.2820953924457232 | accuracy: 0.8844791666666667 \n",
      "Epoch 12 | Step 4734 | loss: 0.28193380700987436 | accuracy: 0.8847072259136213 \n",
      "Epoch 12 | Step 4735 | loss: 0.2817749473334148 | accuracy: 0.8847268211920529 \n",
      "Epoch 12 | Step 4736 | loss: 0.28148902642844925 | accuracy: 0.8847978547854786 \n",
      "Epoch 12 | Step 4737 | loss: 0.281467182953891 | accuracy: 0.884765625 \n",
      "Epoch 12 | Step 4738 | loss: 0.28191706674997924 | accuracy: 0.8845286885245902 \n",
      "Epoch 12 | Step 4739 | loss: 0.28159330945973304 | accuracy: 0.8848039215686274 \n",
      "Epoch 12 | Step 4740 | loss: 0.28150498240894917 | accuracy: 0.8848737785016286 \n",
      "Epoch 12 | Step 4741 | loss: 0.2811863879104714 | accuracy: 0.8850446428571429 \n",
      "Epoch 12 | Step 4742 | loss: 0.28072126532835484 | accuracy: 0.8853661003236246 \n",
      "Epoch 12 | Step 4743 | loss: 0.28060326182073164 | accuracy: 0.885383064516129 \n",
      "Epoch 12 | Step 4744 | loss: 0.280427479763123 | accuracy: 0.8855506430868167 \n",
      "Epoch 12 | Step 4745 | loss: 0.2804154715476892 | accuracy: 0.8854166666666666 \n",
      "Epoch 12 | Step 4746 | loss: 0.28034627275725904 | accuracy: 0.8854333067092651 \n",
      "Epoch 12 | Step 4747 | loss: 0.2802717163684262 | accuracy: 0.8854498407643312 \n",
      "Epoch 12 | Step 4748 | loss: 0.2798061314083281 | accuracy: 0.8857638888888889 \n",
      "Epoch 12 | Step 4749 | loss: 0.2798740194190907 | accuracy: 0.8857792721518988 \n",
      "Epoch 12 | Step 4750 | loss: 0.27986627497507577 | accuracy: 0.8857452681388013 \n",
      "Epoch 12 | Step 4751 | loss: 0.2799122761817849 | accuracy: 0.8857606132075472 \n",
      "Epoch 12 | Step 4752 | loss: 0.27981737157954695 | accuracy: 0.8856778996865203 \n",
      "Epoch 12 | Step 4753 | loss: 0.27965080090798444 | accuracy: 0.885888671875 \n",
      "Epoch 12 | Step 4754 | loss: 0.2796071541736431 | accuracy: 0.8858547507788161 \n",
      "Epoch 12 | Step 4755 | loss: 0.27948710313124697 | accuracy: 0.8859666149068323 \n",
      "Epoch 12 | Step 4756 | loss: 0.2794852994912919 | accuracy: 0.8859326625386997 \n",
      "Epoch 12 | Step 4757 | loss: 0.27954647257740123 | accuracy: 0.8857542438271605 \n",
      "Epoch 12 | Step 4758 | loss: 0.27957746569926933 | accuracy: 0.8857692307692308 \n",
      "Epoch 12 | Step 4759 | loss: 0.2795763088881605 | accuracy: 0.8856882668711656 \n",
      "Epoch 12 | Step 4760 | loss: 0.279869292216199 | accuracy: 0.8854644495412844 \n",
      "Epoch 12 | Step 4761 | loss: 0.27975762512807445 | accuracy: 0.8856230945121951 \n",
      "Epoch 12 | Step 4762 | loss: 0.27946988613228674 | accuracy: 0.885733282674772 \n",
      "Epoch 12 | Step 4763 | loss: 0.2794050064502341 | accuracy: 0.8857007575757576 \n",
      "Epoch 12 | Step 4764 | loss: 0.2793618978600488 | accuracy: 0.8857156344410876 \n",
      "Epoch 12 | Step 4765 | loss: 0.27925245872283555 | accuracy: 0.8855892319277109 \n",
      "Epoch 12 | Step 4766 | loss: 0.2791658025514614 | accuracy: 0.8856043543543544 \n",
      "Epoch 12 | Step 4767 | loss: 0.27903042113531135 | accuracy: 0.8857129491017964 \n",
      "Epoch 12 | Step 4768 | loss: 0.27899168342796726 | accuracy: 0.885634328358209 \n",
      "Epoch 12 | Step 4769 | loss: 0.27890004501456306 | accuracy: 0.8856491815476191 \n",
      "Epoch 12 | Step 4770 | loss: 0.2788645127229945 | accuracy: 0.8855712166172107 \n",
      "Epoch 12 | Step 4771 | loss: 0.27867640488775525 | accuracy: 0.885678624260355 \n",
      "Epoch 12 | Step 4772 | loss: 0.2785414452485982 | accuracy: 0.8858314896755162 \n",
      "Epoch 12 | Step 4773 | loss: 0.2783695553593776 | accuracy: 0.8859834558823529 \n",
      "Epoch 12 | Step 4774 | loss: 0.2784260993391887 | accuracy: 0.8859970674486803 \n",
      "Epoch 12 | Step 4775 | loss: 0.2784228064773375 | accuracy: 0.8859649122807017 \n",
      "Epoch 12 | Step 4776 | loss: 0.27814791358073315 | accuracy: 0.8861151603498543 \n",
      "Epoch 12 | Step 4777 | loss: 0.27817060049016806 | accuracy: 0.8860828488372093 \n",
      "Epoch 12 | Step 4778 | loss: 0.277992020353027 | accuracy: 0.8861413043478261 \n",
      "Epoch 12 | Step 4779 | loss: 0.27786594215845095 | accuracy: 0.8862445809248555 \n",
      "Epoch 12 | Step 4780 | loss: 0.2776800590736378 | accuracy: 0.8863922910662824 \n",
      "Epoch 12 | Step 4781 | loss: 0.2775222065633741 | accuracy: 0.8864044540229885 \n",
      "Epoch 12 | Step 4782 | loss: 0.2774437804276759 | accuracy: 0.886416547277937 \n",
      "Epoch 12 | Step 4783 | loss: 0.2777528875214713 | accuracy: 0.8862053571428572 \n",
      "Epoch 12 | Step 4784 | loss: 0.27749836181643345 | accuracy: 0.8863514957264957 \n",
      "Epoch 12 | Step 4785 | loss: 0.2774852850389752 | accuracy: 0.88623046875 \n",
      "Epoch 12 | Step 4786 | loss: 0.2775050147565837 | accuracy: 0.8862429178470255 \n",
      "Epoch 12 | Step 4787 | loss: 0.277667648458885 | accuracy: 0.8860787429378532 \n",
      "Epoch 12 | Step 4788 | loss: 0.27750474957513144 | accuracy: 0.8861355633802817 \n",
      "Epoch 12 | Step 4789 | loss: 0.27729311970512527 | accuracy: 0.8861920646067416 \n",
      "Epoch 12 | Step 4790 | loss: 0.2775725193050396 | accuracy: 0.8861607142857143 \n",
      "Epoch 12 | Step 4791 | loss: 0.278045403224796 | accuracy: 0.8860422486033519 \n",
      "Epoch 12 | Step 4792 | loss: 0.2778213648825968 | accuracy: 0.8862291086350975 \n",
      "Epoch 12 | Step 4793 | loss: 0.27797032499478935 | accuracy: 0.8861545138888889 \n",
      "Epoch 12 | Step 4794 | loss: 0.2779195442837032 | accuracy: 0.8860370498614959 \n",
      "Epoch 12 | Step 4795 | loss: 0.2779145672588059 | accuracy: 0.886049723756906 \n",
      "Epoch 12 | Step 4796 | loss: 0.27792091922162326 | accuracy: 0.8860192837465565 \n",
      "Epoch 12 | Step 4797 | loss: 0.2774977517611051 | accuracy: 0.8862465659340659 \n",
      "Epoch 12 | Step 4798 | loss: 0.2771936324157127 | accuracy: 0.8864726027397261 \n",
      "Epoch 12 | Step 4799 | loss: 0.2773029727484685 | accuracy: 0.8864839480874317 \n",
      "Epoch 12 | Step 4800 | loss: 0.2774590783085095 | accuracy: 0.8863675068119891 \n",
      "Epoch 12 | Step 4801 | loss: 0.27728734604771366 | accuracy: 0.8865064538043478 \n",
      "Epoch 12 | Step 4802 | loss: 0.2774496719160377 | accuracy: 0.8865599593495935 \n",
      "Epoch 12 | Step 4803 | loss: 0.27735953469936914 | accuracy: 0.886570945945946 \n",
      "Epoch 12 | Step 4804 | loss: 0.27741577604790585 | accuracy: 0.8865397574123989 \n",
      "Epoch 12 | Step 4805 | loss: 0.27735188196823807 | accuracy: 0.8865087365591398 \n",
      "Epoch 12 | Step 4806 | loss: 0.2770768889593056 | accuracy: 0.8866873324396782 \n",
      "Epoch 12 | Step 4807 | loss: 0.2769479906375715 | accuracy: 0.8868231951871658 \n",
      "Epoch 12 | Step 4808 | loss: 0.2771652036706607 | accuracy: 0.8867083333333333 \n",
      "Epoch 12 | Step 4809 | loss: 0.27718455425681593 | accuracy: 0.8866771941489362 \n",
      "Epoch 12 | Step 4810 | loss: 0.2772037546775386 | accuracy: 0.886604774535809 \n",
      "Epoch 12 | Step 4811 | loss: 0.2772831509392414 | accuracy: 0.8864914021164021 \n",
      "Epoch 12 | Step 4812 | loss: 0.27708328770852036 | accuracy: 0.8864610817941952 \n",
      "Epoch 12 | Step 4813 | loss: 0.2770160014888175 | accuracy: 0.8864720394736842 \n",
      "Epoch 12 | Step 4814 | loss: 0.2766947710490604 | accuracy: 0.8866469816272966 \n",
      "Epoch 12 | Step 4815 | loss: 0.2768166225345036 | accuracy: 0.8866164921465969 \n",
      "Epoch 12 | Step 4816 | loss: 0.27687918021302327 | accuracy: 0.886545365535248 \n",
      "Epoch 12 | Step 4817 | loss: 0.27703384273142256 | accuracy: 0.8866780598958334 \n",
      "Epoch 12 | Step 4818 | loss: 0.27700601098212346 | accuracy: 0.8866477272727272 \n",
      "Epoch 12 | Step 4819 | loss: 0.27698869943387167 | accuracy: 0.8866985103626943 \n",
      "Epoch 12 | Step 4820 | loss: 0.2770105859298424 | accuracy: 0.8867086563307494 \n",
      "Epoch 12 | Step 4821 | loss: 0.2772588827599264 | accuracy: 0.8866784793814433 \n",
      "Epoch 12 | Step 4822 | loss: 0.27725434366489143 | accuracy: 0.8866484575835476 \n",
      "Epoch 12 | Step 4823 | loss: 0.27724615207467335 | accuracy: 0.8866586538461538 \n",
      "Epoch 12 | Step 4824 | loss: 0.27719361834285217 | accuracy: 0.8867087595907929 \n",
      "Epoch 12 | Step 4825 | loss: 0.2771378489667361 | accuracy: 0.88671875 \n",
      "Epoch 12 | Step 4826 | loss: 0.27700679681000834 | accuracy: 0.8867684478371501 \n",
      "Epoch 12 | Step 4827 | loss: 0.27726831213396225 | accuracy: 0.8865402918781726 \n",
      "Epoch 12 | Step 4828 | loss: 0.27705074916534794 | accuracy: 0.8866693037974683 \n",
      "Epoch 12 | Step 4829 | loss: 0.2767698598668131 | accuracy: 0.8867976641414141 \n",
      "Epoch 12 | Step 4830 | loss: 0.2767236448392761 | accuracy: 0.8868466624685138 \n",
      "Epoch 12 | Step 4831 | loss: 0.27686384352083193 | accuracy: 0.886738379396985 \n",
      "Epoch 12 | Step 4832 | loss: 0.27667790604638587 | accuracy: 0.8867481203007519 \n",
      "Epoch 12 | Step 4833 | loss: 0.27652442729100596 | accuracy: 0.88671875 \n",
      "Epoch 12 | Step 4834 | loss: 0.27668897920936136 | accuracy: 0.8866505610972568 \n",
      "Epoch 12 | Step 4835 | loss: 0.2769458962428334 | accuracy: 0.8865827114427861 \n",
      "Epoch 12 | Step 4836 | loss: 0.27680007797243 | accuracy: 0.8865218832534241 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.44359925389289856 | accuracy: 0.796875 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.39095835387706757 | accuracy: 0.8359375 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.42891427874565125 | accuracy: 0.8333333333333334 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.430708684027195 | accuracy: 0.8125 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4007298171520233 | accuracy: 0.83125 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4219425469636917 | accuracy: 0.8177083333333334 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4196627821241106 | accuracy: 0.8191964285714286 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.41265077516436577 | accuracy: 0.82421875 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4388236237896813 | accuracy: 0.8194444444444444 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4267360806465149 | accuracy: 0.825 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4275842607021332 | accuracy: 0.8238636363636364 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.41511157900094986 | accuracy: 0.8268229166666666 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4227374035578508 | accuracy: 0.8221153846153846 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4134239937577929 | accuracy: 0.8225446428571429 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.41879606048266094 | accuracy: 0.8270833333333333 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4181731678545475 | accuracy: 0.826171875 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4254322437679066 | accuracy: 0.8244485294117647 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.42425168719556594 | accuracy: 0.8255208333333334 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.41986289620399475 | accuracy: 0.8297697368421053 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4162870168685913 | accuracy: 0.83046875 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4092195090793428 | accuracy: 0.8325892857142857 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4032995795661753 | accuracy: 0.8359375 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4095357617606287 | accuracy: 0.8328804347826086 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.42499631519118947 | accuracy: 0.830078125 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.43115985274314883 | accuracy: 0.825625 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4284375481880628 | accuracy: 0.8257211538461539 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.42298530759634795 | accuracy: 0.828125 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4233584499784878 | accuracy: 0.8270089285714286 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4203089064565198 | accuracy: 0.8270474137931034 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.41766985058784484 | accuracy: 0.828125 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.41297172250286224 | accuracy: 0.8311491935483871 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4170670760795474 | accuracy: 0.82861328125 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.41730176680015796 | accuracy: 0.8276515151515151 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.42200233831125145 | accuracy: 0.8249080882352942 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.42185728890555246 | accuracy: 0.825 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4189633048242993 | accuracy: 0.8263888888888888 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4208843571108741 | accuracy: 0.8264358108108109 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4229579630650972 | accuracy: 0.8260690789473685 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.42259623454167294 | accuracy: 0.8249198717948718 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4197782039642334 | accuracy: 0.8265625 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.41745119414678433 | accuracy: 0.8262195121951219 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4142035678738639 | accuracy: 0.8277529761904762 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4139678665371828 | accuracy: 0.828125 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.41623653132807126 | accuracy: 0.8259943181818182 \n",
      "Validation | Epoch 12 | Step 4836 | loss: 0.4150678078333537 | accuracy: 0.825996376408471 \n",
      "Epoch 13 | Step 4837 | loss: 0.462609201669693 | accuracy: 0.828125 \n",
      "Epoch 13 | Step 4838 | loss: 0.3164888545870781 | accuracy: 0.8828125 \n",
      "Epoch 13 | Step 4839 | loss: 0.28962063292662305 | accuracy: 0.8958333333333334 \n",
      "Epoch 13 | Step 4840 | loss: 0.299126747995615 | accuracy: 0.890625 \n",
      "Epoch 13 | Step 4841 | loss: 0.2741019010543823 | accuracy: 0.9 \n",
      "Epoch 13 | Step 4842 | loss: 0.2687985102335612 | accuracy: 0.8984375 \n",
      "Epoch 13 | Step 4843 | loss: 0.2725369121347155 | accuracy: 0.8973214285714286 \n",
      "Epoch 13 | Step 4844 | loss: 0.26843468099832535 | accuracy: 0.90234375 \n",
      "Epoch 13 | Step 4845 | loss: 0.2740145954820845 | accuracy: 0.8975694444444444 \n",
      "Epoch 13 | Step 4846 | loss: 0.2840899407863617 | accuracy: 0.8953125 \n",
      "Epoch 13 | Step 4847 | loss: 0.27496599473736505 | accuracy: 0.8963068181818182 \n",
      "Epoch 13 | Step 4848 | loss: 0.26739533990621567 | accuracy: 0.8971354166666666 \n",
      "Epoch 13 | Step 4849 | loss: 0.2770947745213142 | accuracy: 0.8894230769230769 \n",
      "Epoch 13 | Step 4850 | loss: 0.2753397928816932 | accuracy: 0.890625 \n",
      "Epoch 13 | Step 4851 | loss: 0.2757534563541412 | accuracy: 0.890625 \n",
      "Epoch 13 | Step 4852 | loss: 0.26856437511742115 | accuracy: 0.892578125 \n",
      "Epoch 13 | Step 4853 | loss: 0.2706667360137491 | accuracy: 0.8878676470588235 \n",
      "Epoch 13 | Step 4854 | loss: 0.2694173115823004 | accuracy: 0.8897569444444444 \n",
      "Epoch 13 | Step 4855 | loss: 0.2680260546897587 | accuracy: 0.890625 \n",
      "Epoch 13 | Step 4856 | loss: 0.2694204725325108 | accuracy: 0.8890625 \n",
      "Epoch 13 | Step 4857 | loss: 0.2704283602180935 | accuracy: 0.8891369047619048 \n",
      "Epoch 13 | Step 4858 | loss: 0.27222885530103336 | accuracy: 0.8899147727272727 \n",
      "Epoch 13 | Step 4859 | loss: 0.26989582440127496 | accuracy: 0.890625 \n",
      "Epoch 13 | Step 4860 | loss: 0.2713687941431999 | accuracy: 0.8893229166666666 \n",
      "Epoch 13 | Step 4861 | loss: 0.2762164688110352 | accuracy: 0.88625 \n",
      "Epoch 13 | Step 4862 | loss: 0.2764486842430555 | accuracy: 0.8828125 \n",
      "Epoch 13 | Step 4863 | loss: 0.28060115597866203 | accuracy: 0.8813657407407407 \n",
      "Epoch 13 | Step 4864 | loss: 0.2777183375188283 | accuracy: 0.8822544642857143 \n",
      "Epoch 13 | Step 4865 | loss: 0.28085773463906916 | accuracy: 0.8814655172413793 \n",
      "Epoch 13 | Step 4866 | loss: 0.2808663378159205 | accuracy: 0.8807291666666667 \n",
      "Epoch 13 | Step 4867 | loss: 0.27802727491624896 | accuracy: 0.8810483870967742 \n",
      "Epoch 13 | Step 4868 | loss: 0.27755722776055336 | accuracy: 0.88037109375 \n",
      "Epoch 13 | Step 4869 | loss: 0.27724833831642615 | accuracy: 0.8821022727272727 \n",
      "Epoch 13 | Step 4870 | loss: 0.2735230234615943 | accuracy: 0.8846507352941176 \n",
      "Epoch 13 | Step 4871 | loss: 0.27036742057119095 | accuracy: 0.8857142857142857 \n",
      "Epoch 13 | Step 4872 | loss: 0.26931699986259144 | accuracy: 0.8862847222222222 \n",
      "Epoch 13 | Step 4873 | loss: 0.26915182978720276 | accuracy: 0.8859797297297297 \n",
      "Epoch 13 | Step 4874 | loss: 0.26925814034123163 | accuracy: 0.8852796052631579 \n",
      "Epoch 13 | Step 4875 | loss: 0.2668569833040237 | accuracy: 0.8866185897435898 \n",
      "Epoch 13 | Step 4876 | loss: 0.2645385835319757 | accuracy: 0.887890625 \n",
      "Epoch 13 | Step 4877 | loss: 0.2639943299497045 | accuracy: 0.8879573170731707 \n",
      "Epoch 13 | Step 4878 | loss: 0.2637349626138096 | accuracy: 0.8876488095238095 \n",
      "Epoch 13 | Step 4879 | loss: 0.2622871211794919 | accuracy: 0.8880813953488372 \n",
      "Epoch 13 | Step 4880 | loss: 0.2612380690195343 | accuracy: 0.8881392045454546 \n",
      "Epoch 13 | Step 4881 | loss: 0.2615352577633327 | accuracy: 0.8895833333333333 \n",
      "Epoch 13 | Step 4882 | loss: 0.26278755392717273 | accuracy: 0.889266304347826 \n",
      "Epoch 13 | Step 4883 | loss: 0.2631358986205243 | accuracy: 0.8889627659574468 \n",
      "Epoch 13 | Step 4884 | loss: 0.2631072731067737 | accuracy: 0.8889973958333334 \n",
      "Epoch 13 | Step 4885 | loss: 0.2649034158307679 | accuracy: 0.889030612244898 \n",
      "Epoch 13 | Step 4886 | loss: 0.26697685599327087 | accuracy: 0.8875 \n",
      "Epoch 13 | Step 4887 | loss: 0.2664288387579076 | accuracy: 0.8878676470588235 \n",
      "Epoch 13 | Step 4888 | loss: 0.26468925264019233 | accuracy: 0.8891225961538461 \n",
      "Epoch 13 | Step 4889 | loss: 0.2658592499089691 | accuracy: 0.8882665094339622 \n",
      "Epoch 13 | Step 4890 | loss: 0.2652731366731502 | accuracy: 0.8891782407407407 \n",
      "Epoch 13 | Step 4891 | loss: 0.2671388176354495 | accuracy: 0.8883522727272727 \n",
      "Epoch 13 | Step 4892 | loss: 0.26658214814960957 | accuracy: 0.8883928571428571 \n",
      "Epoch 13 | Step 4893 | loss: 0.2680001601315381 | accuracy: 0.8867872807017544 \n",
      "Epoch 13 | Step 4894 | loss: 0.2679101061718217 | accuracy: 0.8863146551724138 \n",
      "Epoch 13 | Step 4895 | loss: 0.2690022822658894 | accuracy: 0.8858580508474576 \n",
      "Epoch 13 | Step 4896 | loss: 0.26897249644001325 | accuracy: 0.8856770833333333 \n",
      "Epoch 13 | Step 4897 | loss: 0.26839958204597725 | accuracy: 0.8860143442622951 \n",
      "Epoch 13 | Step 4898 | loss: 0.2678322299353538 | accuracy: 0.8860887096774194 \n",
      "Epoch 13 | Step 4899 | loss: 0.2693901948985599 | accuracy: 0.8859126984126984 \n",
      "Epoch 13 | Step 4900 | loss: 0.2672351342625916 | accuracy: 0.886962890625 \n",
      "Epoch 13 | Step 4901 | loss: 0.26593383550643923 | accuracy: 0.8877403846153846 \n",
      "Epoch 13 | Step 4902 | loss: 0.2646730038704294 | accuracy: 0.8882575757575758 \n",
      "Epoch 13 | Step 4903 | loss: 0.26376680451542583 | accuracy: 0.8887593283582089 \n",
      "Epoch 13 | Step 4904 | loss: 0.26376134705017595 | accuracy: 0.8883272058823529 \n",
      "Epoch 13 | Step 4905 | loss: 0.2642591455276462 | accuracy: 0.8883605072463768 \n",
      "Epoch 13 | Step 4906 | loss: 0.26342951293502537 | accuracy: 0.8886160714285715 \n",
      "Epoch 13 | Step 4907 | loss: 0.26195978656621044 | accuracy: 0.8893045774647887 \n",
      "Epoch 13 | Step 4908 | loss: 0.2617264530724949 | accuracy: 0.8895399305555556 \n",
      "Epoch 13 | Step 4909 | loss: 0.2614461732645557 | accuracy: 0.889554794520548 \n",
      "Epoch 13 | Step 4910 | loss: 0.2614972565222431 | accuracy: 0.8889358108108109 \n",
      "Epoch 13 | Step 4911 | loss: 0.2616988541682561 | accuracy: 0.8885416666666667 \n",
      "Epoch 13 | Step 4912 | loss: 0.2618131600320339 | accuracy: 0.8887746710526315 \n",
      "Epoch 13 | Step 4913 | loss: 0.26121563803065906 | accuracy: 0.8890016233766234 \n",
      "Epoch 13 | Step 4914 | loss: 0.2619602382183075 | accuracy: 0.8880208333333334 \n",
      "Epoch 13 | Step 4915 | loss: 0.26399251290514497 | accuracy: 0.8872626582278481 \n",
      "Epoch 13 | Step 4916 | loss: 0.263924615457654 | accuracy: 0.8869140625 \n",
      "Epoch 13 | Step 4917 | loss: 0.26350518030884823 | accuracy: 0.886766975308642 \n",
      "Epoch 13 | Step 4918 | loss: 0.2627697145430053 | accuracy: 0.8871951219512195 \n",
      "Epoch 13 | Step 4919 | loss: 0.2627812503691179 | accuracy: 0.8876129518072289 \n",
      "Epoch 13 | Step 4920 | loss: 0.26248771005443167 | accuracy: 0.8876488095238095 \n",
      "Epoch 13 | Step 4921 | loss: 0.2616595857283649 | accuracy: 0.8880514705882353 \n",
      "Epoch 13 | Step 4922 | loss: 0.2614407277731009 | accuracy: 0.8878997093023255 \n",
      "Epoch 13 | Step 4923 | loss: 0.26332457877438653 | accuracy: 0.8870330459770115 \n",
      "Epoch 13 | Step 4924 | loss: 0.26335980556905275 | accuracy: 0.8870738636363636 \n",
      "Epoch 13 | Step 4925 | loss: 0.26225738160395895 | accuracy: 0.8879915730337079 \n",
      "Epoch 13 | Step 4926 | loss: 0.26274149600002505 | accuracy: 0.8880208333333334 \n",
      "Epoch 13 | Step 4927 | loss: 0.2616480960623249 | accuracy: 0.8885645604395604 \n",
      "Epoch 13 | Step 4928 | loss: 0.26087387408251356 | accuracy: 0.8890964673913043 \n",
      "Epoch 13 | Step 4929 | loss: 0.2604726256542309 | accuracy: 0.8891129032258065 \n",
      "Epoch 13 | Step 4930 | loss: 0.25976114482321644 | accuracy: 0.8897938829787234 \n",
      "Epoch 13 | Step 4931 | loss: 0.2603194970833628 | accuracy: 0.8896381578947369 \n",
      "Epoch 13 | Step 4932 | loss: 0.2618552058314284 | accuracy: 0.8889973958333334 \n",
      "Epoch 13 | Step 4933 | loss: 0.26225938686390515 | accuracy: 0.8891752577319587 \n",
      "Epoch 13 | Step 4934 | loss: 0.26334341083254137 | accuracy: 0.8888711734693877 \n",
      "Epoch 13 | Step 4935 | loss: 0.2635596578169351 | accuracy: 0.8887310606060606 \n",
      "Epoch 13 | Step 4936 | loss: 0.26275583744049075 | accuracy: 0.88921875 \n",
      "Epoch 13 | Step 4937 | loss: 0.2616315885345535 | accuracy: 0.8898514851485149 \n",
      "Epoch 13 | Step 4938 | loss: 0.26149617924409757 | accuracy: 0.8900122549019608 \n",
      "Epoch 13 | Step 4939 | loss: 0.26076270697764986 | accuracy: 0.8901699029126213 \n",
      "Epoch 13 | Step 4940 | loss: 0.26143486812137645 | accuracy: 0.8900240384615384 \n",
      "Epoch 13 | Step 4941 | loss: 0.2626660513026374 | accuracy: 0.8892857142857142 \n",
      "Epoch 13 | Step 4942 | loss: 0.26224437566860676 | accuracy: 0.8894457547169812 \n",
      "Epoch 13 | Step 4943 | loss: 0.26348842179106785 | accuracy: 0.889018691588785 \n",
      "Epoch 13 | Step 4944 | loss: 0.2649107455379434 | accuracy: 0.8883101851851852 \n",
      "Epoch 13 | Step 4945 | loss: 0.2648914321026672 | accuracy: 0.888618119266055 \n",
      "Epoch 13 | Step 4946 | loss: 0.2655144188891759 | accuracy: 0.8883522727272727 \n",
      "Epoch 13 | Step 4947 | loss: 0.26489011607728574 | accuracy: 0.888795045045045 \n",
      "Epoch 13 | Step 4948 | loss: 0.264682270985629 | accuracy: 0.8889508928571429 \n",
      "Epoch 13 | Step 4949 | loss: 0.26594175398349773 | accuracy: 0.8885508849557522 \n",
      "Epoch 13 | Step 4950 | loss: 0.2666980442509318 | accuracy: 0.8880208333333334 \n",
      "Epoch 13 | Step 4951 | loss: 0.2666084905033528 | accuracy: 0.8880434782608696 \n",
      "Epoch 13 | Step 4952 | loss: 0.2663022162842341 | accuracy: 0.8882004310344828 \n",
      "Epoch 13 | Step 4953 | loss: 0.2672431872695941 | accuracy: 0.8876869658119658 \n",
      "Epoch 13 | Step 4954 | loss: 0.2674184485764829 | accuracy: 0.8877118644067796 \n",
      "Epoch 13 | Step 4955 | loss: 0.2672420350693857 | accuracy: 0.8879989495798319 \n",
      "Epoch 13 | Step 4956 | loss: 0.2667340839902562 | accuracy: 0.88828125 \n",
      "Epoch 13 | Step 4957 | loss: 0.26662823483963666 | accuracy: 0.8881714876033058 \n",
      "Epoch 13 | Step 4958 | loss: 0.26648255486468825 | accuracy: 0.8880635245901639 \n",
      "Epoch 13 | Step 4959 | loss: 0.26631667313537 | accuracy: 0.8880843495934959 \n",
      "Epoch 13 | Step 4960 | loss: 0.266451135037407 | accuracy: 0.8879788306451613 \n",
      "Epoch 13 | Step 4961 | loss: 0.26644599246978784 | accuracy: 0.88775 \n",
      "Epoch 13 | Step 4962 | loss: 0.26630940891447547 | accuracy: 0.8880208333333334 \n",
      "Epoch 13 | Step 4963 | loss: 0.266685215037639 | accuracy: 0.8880413385826772 \n",
      "Epoch 13 | Step 4964 | loss: 0.26624417770653985 | accuracy: 0.8880615234375 \n",
      "Epoch 13 | Step 4965 | loss: 0.26604958687179797 | accuracy: 0.887718023255814 \n",
      "Epoch 13 | Step 4966 | loss: 0.26563744785694 | accuracy: 0.8879807692307692 \n",
      "Epoch 13 | Step 4967 | loss: 0.26626913909238736 | accuracy: 0.887881679389313 \n",
      "Epoch 13 | Step 4968 | loss: 0.26721219662012496 | accuracy: 0.8876657196969697 \n",
      "Epoch 13 | Step 4969 | loss: 0.26826803408619176 | accuracy: 0.8872180451127819 \n",
      "Epoch 13 | Step 4970 | loss: 0.2684728891324643 | accuracy: 0.8870102611940298 \n",
      "Epoch 13 | Step 4971 | loss: 0.26853048547550507 | accuracy: 0.8868055555555555 \n",
      "Epoch 13 | Step 4972 | loss: 0.2682289875605529 | accuracy: 0.8870634191176471 \n",
      "Epoch 13 | Step 4973 | loss: 0.2678225029559033 | accuracy: 0.8870894160583942 \n",
      "Epoch 13 | Step 4974 | loss: 0.2677561407503877 | accuracy: 0.8870018115942029 \n",
      "Epoch 13 | Step 4975 | loss: 0.2684376261217133 | accuracy: 0.8868030575539568 \n",
      "Epoch 13 | Step 4976 | loss: 0.2683291541678567 | accuracy: 0.8870535714285714 \n",
      "Epoch 13 | Step 4977 | loss: 0.26967415129039324 | accuracy: 0.8866356382978723 \n",
      "Epoch 13 | Step 4978 | loss: 0.26955251374714834 | accuracy: 0.8868838028169013 \n",
      "Epoch 13 | Step 4979 | loss: 0.27013719936350866 | accuracy: 0.8866914335664334 \n",
      "Epoch 13 | Step 4980 | loss: 0.2703931110186712 | accuracy: 0.8866102430555555 \n",
      "Epoch 13 | Step 4981 | loss: 0.2702606749945676 | accuracy: 0.8867456896551724 \n",
      "Epoch 13 | Step 4982 | loss: 0.27052078345050573 | accuracy: 0.8867722602739726 \n",
      "Epoch 13 | Step 4983 | loss: 0.2698533321116249 | accuracy: 0.8872236394557823 \n",
      "Epoch 13 | Step 4984 | loss: 0.26995973681678664 | accuracy: 0.8869298986486487 \n",
      "Epoch 13 | Step 4985 | loss: 0.26968777689757784 | accuracy: 0.8869546979865772 \n",
      "Epoch 13 | Step 4986 | loss: 0.2701102170348169 | accuracy: 0.8871875 \n",
      "Epoch 13 | Step 4987 | loss: 0.2705821320907961 | accuracy: 0.8871067880794702 \n",
      "Epoch 13 | Step 4988 | loss: 0.2714088020944284 | accuracy: 0.8868215460526315 \n",
      "Epoch 13 | Step 4989 | loss: 0.27156226668092964 | accuracy: 0.8868464052287581 \n",
      "Epoch 13 | Step 4990 | loss: 0.27125242797585297 | accuracy: 0.8870738636363636 \n",
      "Epoch 13 | Step 4991 | loss: 0.27099307169837356 | accuracy: 0.8870967741935484 \n",
      "Epoch 13 | Step 4992 | loss: 0.27024650717010884 | accuracy: 0.887520032051282 \n",
      "Epoch 13 | Step 4993 | loss: 0.27019778302141073 | accuracy: 0.8877388535031847 \n",
      "Epoch 13 | Step 4994 | loss: 0.27032820738946356 | accuracy: 0.887559335443038 \n",
      "Epoch 13 | Step 4995 | loss: 0.2706236004267101 | accuracy: 0.8872838050314465 \n",
      "Epoch 13 | Step 4996 | loss: 0.27110439492389576 | accuracy: 0.88681640625 \n",
      "Epoch 13 | Step 4997 | loss: 0.27131100757892107 | accuracy: 0.8868400621118012 \n",
      "Epoch 13 | Step 4998 | loss: 0.271208517437364 | accuracy: 0.886766975308642 \n",
      "Epoch 13 | Step 4999 | loss: 0.2721990744577597 | accuracy: 0.8861196319018405 \n",
      "Epoch 13 | Step 5000 | loss: 0.2719401911627958 | accuracy: 0.8859565548780488 \n",
      "Epoch 13 | Step 5001 | loss: 0.27185108011419146 | accuracy: 0.8859848484848485 \n",
      "Epoch 13 | Step 5002 | loss: 0.2720677186566665 | accuracy: 0.8858245481927711 \n",
      "Epoch 13 | Step 5003 | loss: 0.27174413525415775 | accuracy: 0.8861339820359282 \n",
      "Epoch 13 | Step 5004 | loss: 0.27242333158141113 | accuracy: 0.8856956845238095 \n",
      "Epoch 13 | Step 5005 | loss: 0.2721533996642696 | accuracy: 0.8860022189349113 \n",
      "Epoch 13 | Step 5006 | loss: 0.2714658104321538 | accuracy: 0.8863970588235294 \n",
      "Epoch 13 | Step 5007 | loss: 0.27129662036895774 | accuracy: 0.886421783625731 \n",
      "Epoch 13 | Step 5008 | loss: 0.27140689831833525 | accuracy: 0.8862645348837209 \n",
      "Epoch 13 | Step 5009 | loss: 0.2710939445936613 | accuracy: 0.8864703757225434 \n",
      "Epoch 13 | Step 5010 | loss: 0.271061782693041 | accuracy: 0.8866738505747126 \n",
      "Epoch 13 | Step 5011 | loss: 0.27096368210656324 | accuracy: 0.8866964285714286 \n",
      "Epoch 13 | Step 5012 | loss: 0.27122938734563934 | accuracy: 0.8865411931818182 \n",
      "Epoch 13 | Step 5013 | loss: 0.2720337555570119 | accuracy: 0.8862994350282486 \n",
      "Epoch 13 | Step 5014 | loss: 0.27257034065348396 | accuracy: 0.8858848314606742 \n",
      "Epoch 13 | Step 5015 | loss: 0.27296910655565115 | accuracy: 0.8855621508379888 \n",
      "Epoch 13 | Step 5016 | loss: 0.2727048379679522 | accuracy: 0.8855902777777778 \n",
      "Epoch 13 | Step 5017 | loss: 0.2729690673436909 | accuracy: 0.8853591160220995 \n",
      "Epoch 13 | Step 5018 | loss: 0.2725856179719444 | accuracy: 0.8854739010989011 \n",
      "Epoch 13 | Step 5019 | loss: 0.2719500767565817 | accuracy: 0.8858435792349727 \n",
      "Epoch 13 | Step 5020 | loss: 0.2714198028425809 | accuracy: 0.8862941576086957 \n",
      "Epoch 13 | Step 5021 | loss: 0.2712218568131732 | accuracy: 0.886402027027027 \n",
      "Epoch 13 | Step 5022 | loss: 0.27164676112513403 | accuracy: 0.8860047043010753 \n",
      "Epoch 13 | Step 5023 | loss: 0.27210182445572034 | accuracy: 0.885778743315508 \n",
      "Epoch 13 | Step 5024 | loss: 0.27222639290576295 | accuracy: 0.8853889627659575 \n",
      "Epoch 13 | Step 5025 | loss: 0.27196453661514974 | accuracy: 0.8854166666666666 \n",
      "Epoch 13 | Step 5026 | loss: 0.2727306350281365 | accuracy: 0.8852796052631579 \n",
      "Epoch 13 | Step 5027 | loss: 0.27213057828823317 | accuracy: 0.8855530104712042 \n",
      "Epoch 13 | Step 5028 | loss: 0.2718137186796716 | accuracy: 0.8855794270833334 \n",
      "Epoch 13 | Step 5029 | loss: 0.2714387696487299 | accuracy: 0.8859294041450777 \n",
      "Epoch 13 | Step 5030 | loss: 0.2712333220028387 | accuracy: 0.8861146907216495 \n",
      "Epoch 13 | Step 5031 | loss: 0.27100086212158214 | accuracy: 0.8862179487179487 \n",
      "Epoch 13 | Step 5032 | loss: 0.2710430526307652 | accuracy: 0.8863201530612245 \n",
      "Epoch 13 | Step 5033 | loss: 0.27121875900302456 | accuracy: 0.8863420050761421 \n",
      "Epoch 13 | Step 5034 | loss: 0.27118206761702157 | accuracy: 0.8864425505050505 \n",
      "Epoch 13 | Step 5035 | loss: 0.2709046210625664 | accuracy: 0.886699120603015 \n",
      "Epoch 13 | Step 5036 | loss: 0.27064776048064243 | accuracy: 0.886796875 \n",
      "Epoch 13 | Step 5037 | loss: 0.27127202633601527 | accuracy: 0.886738184079602 \n",
      "Epoch 13 | Step 5038 | loss: 0.2711335568144771 | accuracy: 0.8869121287128713 \n",
      "Epoch 13 | Step 5039 | loss: 0.27105119824409496 | accuracy: 0.8869304187192119 \n",
      "Epoch 13 | Step 5040 | loss: 0.2708454769031675 | accuracy: 0.8871783088235294 \n",
      "Epoch 13 | Step 5041 | loss: 0.2711526056615319 | accuracy: 0.886890243902439 \n",
      "Epoch 13 | Step 5042 | loss: 0.2718463635560379 | accuracy: 0.8867566747572816 \n",
      "Epoch 13 | Step 5043 | loss: 0.27249320276117567 | accuracy: 0.8866998792270532 \n",
      "Epoch 13 | Step 5044 | loss: 0.27237388348350167 | accuracy: 0.88671875 \n",
      "Epoch 13 | Step 5045 | loss: 0.2721290176279808 | accuracy: 0.8867374401913876 \n",
      "Epoch 13 | Step 5046 | loss: 0.2722368978318715 | accuracy: 0.8867559523809524 \n",
      "Epoch 13 | Step 5047 | loss: 0.27255944321505843 | accuracy: 0.8865521327014217 \n",
      "Epoch 13 | Step 5048 | loss: 0.27192539243765607 | accuracy: 0.886939858490566 \n",
      "Epoch 13 | Step 5049 | loss: 0.2715530280775868 | accuracy: 0.8871038732394366 \n",
      "Epoch 13 | Step 5050 | loss: 0.27172801845541633 | accuracy: 0.8872663551401869 \n",
      "Epoch 13 | Step 5051 | loss: 0.27156282781168484 | accuracy: 0.8872819767441861 \n",
      "Epoch 13 | Step 5052 | loss: 0.27158401899591655 | accuracy: 0.8872974537037037 \n",
      "Epoch 13 | Step 5053 | loss: 0.27117879778009424 | accuracy: 0.887456797235023 \n",
      "Epoch 13 | Step 5054 | loss: 0.27113224319908613 | accuracy: 0.8873996559633027 \n",
      "Epoch 13 | Step 5055 | loss: 0.2710074810268674 | accuracy: 0.8874143835616438 \n",
      "Epoch 13 | Step 5056 | loss: 0.2709192922846839 | accuracy: 0.8873579545454545 \n",
      "Epoch 13 | Step 5057 | loss: 0.27082865547001106 | accuracy: 0.8875141402714932 \n",
      "Epoch 13 | Step 5058 | loss: 0.27084356244351426 | accuracy: 0.8875281531531531 \n",
      "Epoch 13 | Step 5059 | loss: 0.2708554717590992 | accuracy: 0.8874719730941704 \n",
      "Epoch 13 | Step 5060 | loss: 0.27030434399577136 | accuracy: 0.8879045758928571 \n",
      "Epoch 13 | Step 5061 | loss: 0.2703875861565273 | accuracy: 0.8878472222222222 \n",
      "Epoch 13 | Step 5062 | loss: 0.2707126368067962 | accuracy: 0.8877212389380531 \n",
      "Epoch 13 | Step 5063 | loss: 0.2708882225373769 | accuracy: 0.8875275330396476 \n",
      "Epoch 13 | Step 5064 | loss: 0.2708152233900732 | accuracy: 0.8878152412280702 \n",
      "Epoch 13 | Step 5065 | loss: 0.270718301943296 | accuracy: 0.8876910480349345 \n",
      "Epoch 13 | Step 5066 | loss: 0.27070484077153006 | accuracy: 0.8877717391304348 \n",
      "Epoch 13 | Step 5067 | loss: 0.270453176586143 | accuracy: 0.887987012987013 \n",
      "Epoch 13 | Step 5068 | loss: 0.27023384469593403 | accuracy: 0.8879983836206896 \n",
      "Epoch 13 | Step 5069 | loss: 0.2702796273093368 | accuracy: 0.8878084763948498 \n",
      "Epoch 13 | Step 5070 | loss: 0.27026100424874555 | accuracy: 0.8879540598290598 \n",
      "Epoch 13 | Step 5071 | loss: 0.27003369305996194 | accuracy: 0.888031914893617 \n",
      "Epoch 13 | Step 5072 | loss: 0.2696933123141023 | accuracy: 0.8883077330508474 \n",
      "Epoch 13 | Step 5073 | loss: 0.26948491311023015 | accuracy: 0.8884493670886076 \n",
      "Epoch 13 | Step 5074 | loss: 0.269613721603606 | accuracy: 0.8882615546218487 \n",
      "Epoch 13 | Step 5075 | loss: 0.26948902852615064 | accuracy: 0.888336820083682 \n",
      "Epoch 13 | Step 5076 | loss: 0.269408427240948 | accuracy: 0.8882161458333333 \n",
      "Epoch 13 | Step 5077 | loss: 0.26879916145346483 | accuracy: 0.8884854771784232 \n",
      "Epoch 13 | Step 5078 | loss: 0.2684746550257542 | accuracy: 0.8885588842975206 \n",
      "Epoch 13 | Step 5079 | loss: 0.2689160142293193 | accuracy: 0.8885673868312757 \n",
      "Epoch 13 | Step 5080 | loss: 0.26936131355459586 | accuracy: 0.8885117827868853 \n",
      "Epoch 13 | Step 5081 | loss: 0.26933367416566745 | accuracy: 0.8885841836734694 \n",
      "Epoch 13 | Step 5082 | loss: 0.2692628239349622 | accuracy: 0.8885924796747967 \n",
      "Epoch 13 | Step 5083 | loss: 0.26901823125387503 | accuracy: 0.8887904858299596 \n",
      "Epoch 13 | Step 5084 | loss: 0.2692474228960854 | accuracy: 0.888671875 \n",
      "Epoch 13 | Step 5085 | loss: 0.2692167074326053 | accuracy: 0.8888052208835341 \n",
      "Epoch 13 | Step 5086 | loss: 0.26925591254234327 | accuracy: 0.888875 \n",
      "Epoch 13 | Step 5087 | loss: 0.26897057380334327 | accuracy: 0.8891309760956175 \n",
      "Epoch 13 | Step 5088 | loss: 0.26876230803983564 | accuracy: 0.8891369047619048 \n",
      "Epoch 13 | Step 5089 | loss: 0.26852069276830437 | accuracy: 0.8891427865612648 \n",
      "Epoch 13 | Step 5090 | loss: 0.26852112791434996 | accuracy: 0.8892716535433071 \n",
      "Epoch 13 | Step 5091 | loss: 0.26843363706972095 | accuracy: 0.8892769607843137 \n",
      "Epoch 13 | Step 5092 | loss: 0.26843363157240685 | accuracy: 0.88922119140625 \n",
      "Epoch 13 | Step 5093 | loss: 0.26832384590045033 | accuracy: 0.8891658560311284 \n",
      "Epoch 13 | Step 5094 | loss: 0.2680985056614692 | accuracy: 0.8891109496124031 \n",
      "Epoch 13 | Step 5095 | loss: 0.26831113900917386 | accuracy: 0.888996138996139 \n",
      "Epoch 13 | Step 5096 | loss: 0.26814978283185237 | accuracy: 0.8890024038461539 \n",
      "Epoch 13 | Step 5097 | loss: 0.2687409839867633 | accuracy: 0.8886494252873565 \n",
      "Epoch 13 | Step 5098 | loss: 0.26892050156611536 | accuracy: 0.8884780534351147 \n",
      "Epoch 13 | Step 5099 | loss: 0.26865742834348655 | accuracy: 0.8886050380228138 \n",
      "Epoch 13 | Step 5100 | loss: 0.2690799485779171 | accuracy: 0.8884351325757577 \n",
      "Epoch 13 | Step 5101 | loss: 0.26885224204018443 | accuracy: 0.888561320754717 \n",
      "Epoch 13 | Step 5102 | loss: 0.2686454289613811 | accuracy: 0.8886278195488723 \n",
      "Epoch 13 | Step 5103 | loss: 0.2683688681781963 | accuracy: 0.8888108614232211 \n",
      "Epoch 13 | Step 5104 | loss: 0.2681656826231908 | accuracy: 0.888875932835821 \n",
      "Epoch 13 | Step 5105 | loss: 0.26807733832903524 | accuracy: 0.8889405204460967 \n",
      "Epoch 13 | Step 5106 | loss: 0.2678479834287256 | accuracy: 0.8890046296296298 \n",
      "Epoch 13 | Step 5107 | loss: 0.2679638107654355 | accuracy: 0.8889529520295204 \n",
      "Epoch 13 | Step 5108 | loss: 0.2678904919063345 | accuracy: 0.888959099264706 \n",
      "Epoch 13 | Step 5109 | loss: 0.2679489896847653 | accuracy: 0.8889079670329672 \n",
      "Epoch 13 | Step 5110 | loss: 0.2679317076928426 | accuracy: 0.8889142335766425 \n",
      "Epoch 13 | Step 5111 | loss: 0.2678023820573635 | accuracy: 0.8889772727272728 \n",
      "Epoch 13 | Step 5112 | loss: 0.2680414596545525 | accuracy: 0.8887001811594204 \n",
      "Epoch 13 | Step 5113 | loss: 0.2678731656784617 | accuracy: 0.8888199458483755 \n",
      "Epoch 13 | Step 5114 | loss: 0.2676634122785048 | accuracy: 0.8890512589928059 \n",
      "Epoch 13 | Step 5115 | loss: 0.2677182910903809 | accuracy: 0.8890568996415772 \n",
      "Epoch 13 | Step 5116 | loss: 0.26751913917916176 | accuracy: 0.8891741071428573 \n",
      "Epoch 13 | Step 5117 | loss: 0.26800150835217124 | accuracy: 0.8890124555160144 \n",
      "Epoch 13 | Step 5118 | loss: 0.26780147676138183 | accuracy: 0.8890735815602838 \n",
      "Epoch 13 | Step 5119 | loss: 0.26790327576150336 | accuracy: 0.8891342756183747 \n",
      "Epoch 13 | Step 5120 | loss: 0.26777778859709367 | accuracy: 0.8891945422535212 \n",
      "Epoch 13 | Step 5121 | loss: 0.2676113787973138 | accuracy: 0.8894188596491229 \n",
      "Epoch 13 | Step 5122 | loss: 0.2677601202280373 | accuracy: 0.8893684440559442 \n",
      "Epoch 13 | Step 5123 | loss: 0.2675103523382328 | accuracy: 0.8894817073170733 \n",
      "Epoch 13 | Step 5124 | loss: 0.2672561163393161 | accuracy: 0.889594184027778 \n",
      "Epoch 13 | Step 5125 | loss: 0.26707611673843507 | accuracy: 0.8895977508650521 \n",
      "Epoch 13 | Step 5126 | loss: 0.267438225499515 | accuracy: 0.8894935344827588 \n",
      "Epoch 13 | Step 5127 | loss: 0.2672476447427397 | accuracy: 0.8895511168384882 \n",
      "Epoch 13 | Step 5128 | loss: 0.2672120440394096 | accuracy: 0.8896618150684934 \n",
      "Epoch 13 | Step 5129 | loss: 0.2673091440375756 | accuracy: 0.8896651023890787 \n",
      "Epoch 13 | Step 5130 | loss: 0.26694009726753054 | accuracy: 0.8897746598639458 \n",
      "Epoch 13 | Step 5131 | loss: 0.2675062785209237 | accuracy: 0.8895656779661019 \n",
      "Epoch 13 | Step 5132 | loss: 0.2674355608083913 | accuracy: 0.8896220439189191 \n",
      "Epoch 13 | Step 5133 | loss: 0.26779945285031304 | accuracy: 0.8893097643097645 \n",
      "Epoch 13 | Step 5134 | loss: 0.2677104300600572 | accuracy: 0.8892617449664432 \n",
      "Epoch 13 | Step 5135 | loss: 0.2675177575054776 | accuracy: 0.8892663043478263 \n",
      "Epoch 13 | Step 5136 | loss: 0.26737864211201684 | accuracy: 0.8893750000000001 \n",
      "Epoch 13 | Step 5137 | loss: 0.26720778361903486 | accuracy: 0.8895867940199338 \n",
      "Epoch 13 | Step 5138 | loss: 0.2670562969927758 | accuracy: 0.8896419701986756 \n",
      "Epoch 13 | Step 5139 | loss: 0.2668082161311664 | accuracy: 0.8897999174917494 \n",
      "Epoch 13 | Step 5140 | loss: 0.26678671089834305 | accuracy: 0.8896998355263159 \n",
      "Epoch 13 | Step 5141 | loss: 0.2673118761328402 | accuracy: 0.8893954918032789 \n",
      "Epoch 13 | Step 5142 | loss: 0.26710632511603305 | accuracy: 0.8896037581699349 \n",
      "Epoch 13 | Step 5143 | loss: 0.2670015969377389 | accuracy: 0.8897088762214985 \n",
      "Epoch 13 | Step 5144 | loss: 0.26670620556582125 | accuracy: 0.8897625811688313 \n",
      "Epoch 13 | Step 5145 | loss: 0.2663718521787899 | accuracy: 0.8898665048543691 \n",
      "Epoch 13 | Step 5146 | loss: 0.2662884176738803 | accuracy: 0.8899697580645163 \n",
      "Epoch 13 | Step 5147 | loss: 0.26612268733250005 | accuracy: 0.8901225884244375 \n",
      "Epoch 13 | Step 5148 | loss: 0.26614240084130053 | accuracy: 0.8900240384615387 \n",
      "Epoch 13 | Step 5149 | loss: 0.26602355155129803 | accuracy: 0.8900758785942494 \n",
      "Epoch 13 | Step 5150 | loss: 0.26587782947310995 | accuracy: 0.8900776273885352 \n",
      "Epoch 13 | Step 5151 | loss: 0.2654668022715858 | accuracy: 0.890277777777778 \n",
      "Epoch 13 | Step 5152 | loss: 0.26564484928982185 | accuracy: 0.8901305379746838 \n",
      "Epoch 13 | Step 5153 | loss: 0.2656267148087079 | accuracy: 0.8901813880126185 \n",
      "Epoch 13 | Step 5154 | loss: 0.2656556237606134 | accuracy: 0.8901827830188681 \n",
      "Epoch 13 | Step 5155 | loss: 0.26557789392605863 | accuracy: 0.890184169278997 \n",
      "Epoch 13 | Step 5156 | loss: 0.2654575914144518 | accuracy: 0.8903320312500002 \n",
      "Epoch 13 | Step 5157 | loss: 0.2655125365264692 | accuracy: 0.8903816199376949 \n",
      "Epoch 13 | Step 5158 | loss: 0.26533672833664834 | accuracy: 0.8905279503105592 \n",
      "Epoch 13 | Step 5159 | loss: 0.2652905356404215 | accuracy: 0.8904798761609909 \n",
      "Epoch 13 | Step 5160 | loss: 0.26525028344289775 | accuracy: 0.8903838734567903 \n",
      "Epoch 13 | Step 5161 | loss: 0.2652612347786245 | accuracy: 0.8903365384615386 \n",
      "Epoch 13 | Step 5162 | loss: 0.26536250553248136 | accuracy: 0.890241564417178 \n",
      "Epoch 13 | Step 5163 | loss: 0.26558105825284223 | accuracy: 0.8900038226299696 \n",
      "Epoch 13 | Step 5164 | loss: 0.26551808235121954 | accuracy: 0.8901009908536587 \n",
      "Epoch 13 | Step 5165 | loss: 0.26520683047981625 | accuracy: 0.8901500759878421 \n",
      "Epoch 13 | Step 5166 | loss: 0.2651758437806911 | accuracy: 0.8900568181818184 \n",
      "Epoch 13 | Step 5167 | loss: 0.2650751139282101 | accuracy: 0.8901057401812691 \n",
      "Epoch 13 | Step 5168 | loss: 0.2649561964334495 | accuracy: 0.8901073042168677 \n",
      "Epoch 13 | Step 5169 | loss: 0.26476854707922676 | accuracy: 0.8902496246246248 \n",
      "Epoch 13 | Step 5170 | loss: 0.2646420129134271 | accuracy: 0.8903443113772457 \n",
      "Epoch 13 | Step 5171 | loss: 0.26468997682208456 | accuracy: 0.8902052238805972 \n",
      "Epoch 13 | Step 5172 | loss: 0.2646870509765688 | accuracy: 0.8902064732142859 \n",
      "Epoch 13 | Step 5173 | loss: 0.26460262447684035 | accuracy: 0.8902540801186946 \n",
      "Epoch 13 | Step 5174 | loss: 0.2644250310472483 | accuracy: 0.8902551775147931 \n",
      "Epoch 13 | Step 5175 | loss: 0.2643216940241929 | accuracy: 0.8903484513274338 \n",
      "Epoch 13 | Step 5176 | loss: 0.26427849715246876 | accuracy: 0.8905330882352943 \n",
      "Epoch 13 | Step 5177 | loss: 0.26433526482050723 | accuracy: 0.8905333577712612 \n",
      "Epoch 13 | Step 5178 | loss: 0.264301122454872 | accuracy: 0.8906250000000001 \n",
      "Epoch 13 | Step 5179 | loss: 0.26402441027734447 | accuracy: 0.8907161078717203 \n",
      "Epoch 13 | Step 5180 | loss: 0.2640021837121526 | accuracy: 0.890715843023256 \n",
      "Epoch 13 | Step 5181 | loss: 0.2639607001473939 | accuracy: 0.8907155797101451 \n",
      "Epoch 13 | Step 5182 | loss: 0.26381424676648463 | accuracy: 0.8907604768786129 \n",
      "Epoch 13 | Step 5183 | loss: 0.2636866499951663 | accuracy: 0.8908051152737754 \n",
      "Epoch 13 | Step 5184 | loss: 0.26369274647414004 | accuracy: 0.8908045977011496 \n",
      "Epoch 13 | Step 5185 | loss: 0.2636202544742464 | accuracy: 0.890804083094556 \n",
      "Epoch 13 | Step 5186 | loss: 0.26389789274760656 | accuracy: 0.8905803571428573 \n",
      "Epoch 13 | Step 5187 | loss: 0.263651005690254 | accuracy: 0.8907140313390315 \n",
      "Epoch 13 | Step 5188 | loss: 0.26361071483486076 | accuracy: 0.890713778409091 \n",
      "Epoch 13 | Step 5189 | loss: 0.26371324226977805 | accuracy: 0.8906250000000001 \n",
      "Epoch 13 | Step 5190 | loss: 0.26385123813051287 | accuracy: 0.8905808615819211 \n",
      "Epoch 13 | Step 5191 | loss: 0.2637210470689854 | accuracy: 0.8906250000000001 \n",
      "Epoch 13 | Step 5192 | loss: 0.26349388531754525 | accuracy: 0.8906250000000001 \n",
      "Epoch 13 | Step 5193 | loss: 0.2637416066742745 | accuracy: 0.8905374649859945 \n",
      "Epoch 13 | Step 5194 | loss: 0.26409143775535027 | accuracy: 0.8904940642458102 \n",
      "Epoch 13 | Step 5195 | loss: 0.26390844811802117 | accuracy: 0.8906250000000001 \n",
      "Epoch 13 | Step 5196 | loss: 0.2640227978014283 | accuracy: 0.8906684027777779 \n",
      "Epoch 13 | Step 5197 | loss: 0.2640340606839372 | accuracy: 0.8905817174515237 \n",
      "Epoch 13 | Step 5198 | loss: 0.2640314606424852 | accuracy: 0.8905386740331493 \n",
      "Epoch 13 | Step 5199 | loss: 0.263922621190712 | accuracy: 0.8905389118457302 \n",
      "Epoch 13 | Step 5200 | loss: 0.2634746249724219 | accuracy: 0.8907967032967035 \n",
      "Epoch 13 | Step 5201 | loss: 0.26326652842841725 | accuracy: 0.8908818493150686 \n",
      "Epoch 13 | Step 5202 | loss: 0.26336560976472695 | accuracy: 0.8908384562841531 \n",
      "Epoch 13 | Step 5203 | loss: 0.26348466342898724 | accuracy: 0.8908378746594007 \n",
      "Epoch 13 | Step 5204 | loss: 0.26337023711074936 | accuracy: 0.8908797554347828 \n",
      "Epoch 13 | Step 5205 | loss: 0.2635021048994244 | accuracy: 0.8909214092140922 \n",
      "Epoch 13 | Step 5206 | loss: 0.2634888206784788 | accuracy: 0.8909206081081082 \n",
      "Epoch 13 | Step 5207 | loss: 0.26362419730890774 | accuracy: 0.890835579514825 \n",
      "Epoch 13 | Step 5208 | loss: 0.2636014911276036 | accuracy: 0.8908770161290324 \n",
      "Epoch 13 | Step 5209 | loss: 0.26327445875383876 | accuracy: 0.8909601206434318 \n",
      "Epoch 13 | Step 5210 | loss: 0.26312300140526185 | accuracy: 0.8910427807486633 \n",
      "Epoch 13 | Step 5211 | loss: 0.26328369625409426 | accuracy: 0.8910000000000001 \n",
      "Epoch 13 | Step 5212 | loss: 0.26319023122654295 | accuracy: 0.8909574468085107 \n",
      "Epoch 13 | Step 5213 | loss: 0.26315866363301493 | accuracy: 0.8909151193633954 \n",
      "Epoch 13 | Step 5214 | loss: 0.26311311748608057 | accuracy: 0.890997023809524 \n",
      "Epoch 13 | Step 5215 | loss: 0.26284607643345076 | accuracy: 0.8912021767810028 \n",
      "Epoch 13 | Step 5216 | loss: 0.2627355167348131 | accuracy: 0.8911595394736843 \n",
      "Epoch 13 | Step 5217 | loss: 0.26243013859264464 | accuracy: 0.8913221784776905 \n",
      "Epoch 13 | Step 5218 | loss: 0.26253563544044917 | accuracy: 0.8912794502617802 \n",
      "Epoch 13 | Step 5219 | loss: 0.2626495701759351 | accuracy: 0.891236945169713 \n",
      "Epoch 13 | Step 5220 | loss: 0.2629242301530513 | accuracy: 0.8912353515625001 \n",
      "Epoch 13 | Step 5221 | loss: 0.2628731365327709 | accuracy: 0.8912743506493508 \n",
      "Epoch 13 | Step 5222 | loss: 0.2627770407366627 | accuracy: 0.8912726683937825 \n",
      "Epoch 13 | Step 5223 | loss: 0.2627786732921302 | accuracy: 0.8913113695090441 \n",
      "Epoch 13 | Step 5224 | loss: 0.2629451312355157 | accuracy: 0.891309600515464 \n",
      "Epoch 13 | Step 5225 | loss: 0.2629276115667542 | accuracy: 0.8912676735218511 \n",
      "Epoch 13 | Step 5226 | loss: 0.26288749575614906 | accuracy: 0.891346153846154 \n",
      "Epoch 13 | Step 5227 | loss: 0.2629643309756616 | accuracy: 0.8913043478260871 \n",
      "Epoch 13 | Step 5228 | loss: 0.2628221408064874 | accuracy: 0.8913026147959185 \n",
      "Epoch 13 | Step 5229 | loss: 0.26269323285906043 | accuracy: 0.891340648854962 \n",
      "Epoch 13 | Step 5230 | loss: 0.26282927197248174 | accuracy: 0.8911405456852793 \n",
      "Epoch 13 | Step 5231 | loss: 0.2626013693930225 | accuracy: 0.8912579113924052 \n",
      "Epoch 13 | Step 5232 | loss: 0.2623908255587922 | accuracy: 0.8913746843434345 \n",
      "Epoch 13 | Step 5233 | loss: 0.26233905328611257 | accuracy: 0.8914515113350128 \n",
      "Epoch 13 | Step 5234 | loss: 0.2624352223160276 | accuracy: 0.8914886934673368 \n",
      "Epoch 13 | Step 5235 | loss: 0.2622144829509847 | accuracy: 0.8915648496240602 \n",
      "Epoch 13 | Step 5236 | loss: 0.26204487632960055 | accuracy: 0.8916015625000001 \n",
      "Epoch 13 | Step 5237 | loss: 0.26211256022911095 | accuracy: 0.8916770573566086 \n",
      "Epoch 13 | Step 5238 | loss: 0.2622640864247111 | accuracy: 0.8916744402985076 \n",
      "Epoch 13 | Step 5239 | loss: 0.2621156614338492 | accuracy: 0.8916865427499967 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4443478584289551 | accuracy: 0.765625 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.392423614859581 | accuracy: 0.8203125 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4274159073829651 | accuracy: 0.8177083333333334 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4267817959189415 | accuracy: 0.80859375 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.39558876156806944 | accuracy: 0.821875 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.42316195865472156 | accuracy: 0.8046875 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4250594547816685 | accuracy: 0.8058035714285714 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.42330512031912804 | accuracy: 0.80859375 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4455663793616825 | accuracy: 0.8055555555555556 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4287138760089874 | accuracy: 0.8140625 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.42828277295286005 | accuracy: 0.8167613636363636 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.41673073172569275 | accuracy: 0.8255208333333334 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4219999175805312 | accuracy: 0.8209134615384616 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.41094706101076944 | accuracy: 0.8258928571428571 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.414952689409256 | accuracy: 0.8302083333333333 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4155177175998688 | accuracy: 0.8291015625 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.42180896155974446 | accuracy: 0.8262867647058824 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4206206798553467 | accuracy: 0.8272569444444444 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4173975461407712 | accuracy: 0.8297697368421053 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4140657395124435 | accuracy: 0.828125 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.40886678440230234 | accuracy: 0.8296130952380952 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.40504932403564453 | accuracy: 0.8316761363636364 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.41022696443226025 | accuracy: 0.8288043478260869 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4261601542433103 | accuracy: 0.826171875 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.43345060586929324 | accuracy: 0.823125 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4300061452847261 | accuracy: 0.8245192307692307 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4230906179657689 | accuracy: 0.8275462962962963 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4243535048195294 | accuracy: 0.8275669642857143 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.42239653036512176 | accuracy: 0.8286637931034483 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4187778294086456 | accuracy: 0.83125 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4144791845352419 | accuracy: 0.8341733870967742 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.41666307114064693 | accuracy: 0.8330078125 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.416496933409662 | accuracy: 0.8328598484848485 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.420379853423904 | accuracy: 0.8304227941176471 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.42197618910244533 | accuracy: 0.8308035714285714 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4184285369184282 | accuracy: 0.8324652777777778 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4201099703440795 | accuracy: 0.8327702702702703 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4217747355762281 | accuracy: 0.8334703947368421 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.42215809302452284 | accuracy: 0.8329326923076923 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.41911419853568077 | accuracy: 0.834765625 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4160799180589071 | accuracy: 0.8346036585365854 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4126558630239396 | accuracy: 0.8351934523809523 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4125068035236625 | accuracy: 0.8361191860465116 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.4147119738838889 | accuracy: 0.8348721590909091 \n",
      "Validation | Epoch 13 | Step 5239 | loss: 0.41379436718093027 | accuracy: 0.8337107486195035 \n",
      "Epoch 14 | Step 5240 | loss: 0.3764902949333191 | accuracy: 0.875 \n",
      "Epoch 14 | Step 5241 | loss: 0.2603263556957245 | accuracy: 0.9140625 \n",
      "Epoch 14 | Step 5242 | loss: 0.2559029807647069 | accuracy: 0.9166666666666666 \n",
      "Epoch 14 | Step 5243 | loss: 0.2729699946939945 | accuracy: 0.90234375 \n",
      "Epoch 14 | Step 5244 | loss: 0.26049779951572416 | accuracy: 0.90625 \n",
      "Epoch 14 | Step 5245 | loss: 0.25134267657995224 | accuracy: 0.9036458333333334 \n",
      "Epoch 14 | Step 5246 | loss: 0.2576755774872644 | accuracy: 0.9040178571428571 \n",
      "Epoch 14 | Step 5247 | loss: 0.2540998086333275 | accuracy: 0.904296875 \n",
      "Epoch 14 | Step 5248 | loss: 0.25878271129396224 | accuracy: 0.9010416666666666 \n",
      "Epoch 14 | Step 5249 | loss: 0.2684239774942398 | accuracy: 0.896875 \n",
      "Epoch 14 | Step 5250 | loss: 0.2588845450769771 | accuracy: 0.9005681818181818 \n",
      "Epoch 14 | Step 5251 | loss: 0.2543534276386102 | accuracy: 0.9010416666666666 \n",
      "Epoch 14 | Step 5252 | loss: 0.2661550216949903 | accuracy: 0.8942307692307693 \n",
      "Epoch 14 | Step 5253 | loss: 0.26184860616922373 | accuracy: 0.8973214285714286 \n",
      "Epoch 14 | Step 5254 | loss: 0.2615119010210037 | accuracy: 0.8958333333333334 \n",
      "Epoch 14 | Step 5255 | loss: 0.2533179372549057 | accuracy: 0.900390625 \n",
      "Epoch 14 | Step 5256 | loss: 0.2540113820749171 | accuracy: 0.8970588235294118 \n",
      "Epoch 14 | Step 5257 | loss: 0.251776994102531 | accuracy: 0.8984375 \n",
      "Epoch 14 | Step 5258 | loss: 0.25120010736741516 | accuracy: 0.8988486842105263 \n",
      "Epoch 14 | Step 5259 | loss: 0.2543794684112072 | accuracy: 0.896875 \n",
      "Epoch 14 | Step 5260 | loss: 0.25291899698121206 | accuracy: 0.8980654761904762 \n",
      "Epoch 14 | Step 5261 | loss: 0.25429877503351733 | accuracy: 0.9005681818181818 \n",
      "Epoch 14 | Step 5262 | loss: 0.2530843505392904 | accuracy: 0.9008152173913043 \n",
      "Epoch 14 | Step 5263 | loss: 0.253912890329957 | accuracy: 0.8997395833333334 \n",
      "Epoch 14 | Step 5264 | loss: 0.25922673523426054 | accuracy: 0.898125 \n",
      "Epoch 14 | Step 5265 | loss: 0.26015883397597533 | accuracy: 0.8966346153846154 \n",
      "Epoch 14 | Step 5266 | loss: 0.2624353175913846 | accuracy: 0.8958333333333334 \n",
      "Epoch 14 | Step 5267 | loss: 0.2599324168903487 | accuracy: 0.8967633928571429 \n",
      "Epoch 14 | Step 5268 | loss: 0.26342855342503246 | accuracy: 0.8960129310344828 \n",
      "Epoch 14 | Step 5269 | loss: 0.26388148665428157 | accuracy: 0.8947916666666667 \n",
      "Epoch 14 | Step 5270 | loss: 0.2624703362103431 | accuracy: 0.8946572580645161 \n",
      "Epoch 14 | Step 5271 | loss: 0.26312430528923864 | accuracy: 0.89453125 \n",
      "Epoch 14 | Step 5272 | loss: 0.26289485033714405 | accuracy: 0.8958333333333334 \n",
      "Epoch 14 | Step 5273 | loss: 0.2593972380546962 | accuracy: 0.8975183823529411 \n",
      "Epoch 14 | Step 5274 | loss: 0.2558013362543923 | accuracy: 0.8991071428571429 \n",
      "Epoch 14 | Step 5275 | loss: 0.2539723242322603 | accuracy: 0.9006076388888888 \n",
      "Epoch 14 | Step 5276 | loss: 0.253258168294623 | accuracy: 0.8999155405405406 \n",
      "Epoch 14 | Step 5277 | loss: 0.2546849419411859 | accuracy: 0.8984375 \n",
      "Epoch 14 | Step 5278 | loss: 0.25252793003351254 | accuracy: 0.8994391025641025 \n",
      "Epoch 14 | Step 5279 | loss: 0.25086609385907643 | accuracy: 0.9 \n",
      "Epoch 14 | Step 5280 | loss: 0.25030889198547446 | accuracy: 0.8990091463414634 \n",
      "Epoch 14 | Step 5281 | loss: 0.25064811075017557 | accuracy: 0.8988095238095238 \n",
      "Epoch 14 | Step 5282 | loss: 0.24951629617879548 | accuracy: 0.8989825581395349 \n",
      "Epoch 14 | Step 5283 | loss: 0.24820999597961244 | accuracy: 0.8991477272727273 \n",
      "Epoch 14 | Step 5284 | loss: 0.2493159525924258 | accuracy: 0.9 \n",
      "Epoch 14 | Step 5285 | loss: 0.250220942756404 | accuracy: 0.8994565217391305 \n",
      "Epoch 14 | Step 5286 | loss: 0.25011649188843177 | accuracy: 0.898936170212766 \n",
      "Epoch 14 | Step 5287 | loss: 0.250262890321513 | accuracy: 0.8990885416666666 \n",
      "Epoch 14 | Step 5288 | loss: 0.2519616858691585 | accuracy: 0.8982780612244898 \n",
      "Epoch 14 | Step 5289 | loss: 0.25377869337797165 | accuracy: 0.898125 \n",
      "Epoch 14 | Step 5290 | loss: 0.2535215765237808 | accuracy: 0.8982843137254902 \n",
      "Epoch 14 | Step 5291 | loss: 0.2517480572255758 | accuracy: 0.8990384615384616 \n",
      "Epoch 14 | Step 5292 | loss: 0.25347851048100667 | accuracy: 0.8977004716981132 \n",
      "Epoch 14 | Step 5293 | loss: 0.25287341740396285 | accuracy: 0.8981481481481481 \n",
      "Epoch 14 | Step 5294 | loss: 0.25422281677072694 | accuracy: 0.897159090909091 \n",
      "Epoch 14 | Step 5295 | loss: 0.2534923223512513 | accuracy: 0.8973214285714286 \n",
      "Epoch 14 | Step 5296 | loss: 0.2550575058711202 | accuracy: 0.8969298245614035 \n",
      "Epoch 14 | Step 5297 | loss: 0.25484759925768286 | accuracy: 0.896551724137931 \n",
      "Epoch 14 | Step 5298 | loss: 0.2563937904976181 | accuracy: 0.8959216101694916 \n",
      "Epoch 14 | Step 5299 | loss: 0.2565194624165693 | accuracy: 0.8963541666666667 \n",
      "Epoch 14 | Step 5300 | loss: 0.25592704581432646 | accuracy: 0.8970286885245902 \n",
      "Epoch 14 | Step 5301 | loss: 0.2553381744411683 | accuracy: 0.897429435483871 \n",
      "Epoch 14 | Step 5302 | loss: 0.257340602221943 | accuracy: 0.8970734126984127 \n",
      "Epoch 14 | Step 5303 | loss: 0.25520366278942663 | accuracy: 0.898193359375 \n",
      "Epoch 14 | Step 5304 | loss: 0.25373336363297233 | accuracy: 0.8990384615384616 \n",
      "Epoch 14 | Step 5305 | loss: 0.25259092258233 | accuracy: 0.8998579545454546 \n",
      "Epoch 14 | Step 5306 | loss: 0.2514308027144687 | accuracy: 0.9004197761194029 \n",
      "Epoch 14 | Step 5307 | loss: 0.25163743239553527 | accuracy: 0.9002757352941176 \n",
      "Epoch 14 | Step 5308 | loss: 0.251825780864211 | accuracy: 0.9001358695652174 \n",
      "Epoch 14 | Step 5309 | loss: 0.25102208097066186 | accuracy: 0.9002232142857143 \n",
      "Epoch 14 | Step 5310 | loss: 0.24935083206690523 | accuracy: 0.9011883802816901 \n",
      "Epoch 14 | Step 5311 | loss: 0.24879196689774583 | accuracy: 0.9016927083333334 \n",
      "Epoch 14 | Step 5312 | loss: 0.24864091805807523 | accuracy: 0.901541095890411 \n",
      "Epoch 14 | Step 5313 | loss: 0.24899530763158917 | accuracy: 0.901393581081081 \n",
      "Epoch 14 | Step 5314 | loss: 0.24856145987908035 | accuracy: 0.9014583333333334 \n",
      "Epoch 14 | Step 5315 | loss: 0.2484137342360458 | accuracy: 0.9015213815789473 \n",
      "Epoch 14 | Step 5316 | loss: 0.2480486525924174 | accuracy: 0.9013798701298701 \n",
      "Epoch 14 | Step 5317 | loss: 0.24850530912860838 | accuracy: 0.9010416666666666 \n",
      "Epoch 14 | Step 5318 | loss: 0.2503268751728383 | accuracy: 0.9003164556962026 \n",
      "Epoch 14 | Step 5319 | loss: 0.250008242111653 | accuracy: 0.9 \n",
      "Epoch 14 | Step 5320 | loss: 0.2495009167878715 | accuracy: 0.8996913580246914 \n",
      "Epoch 14 | Step 5321 | loss: 0.24864749274239298 | accuracy: 0.8999618902439024 \n",
      "Epoch 14 | Step 5322 | loss: 0.248811579163534 | accuracy: 0.9002259036144579 \n",
      "Epoch 14 | Step 5323 | loss: 0.24833957434055343 | accuracy: 0.9002976190476191 \n",
      "Epoch 14 | Step 5324 | loss: 0.24788303471663412 | accuracy: 0.9005514705882353 \n",
      "Epoch 14 | Step 5325 | loss: 0.24719031995465582 | accuracy: 0.9002543604651163 \n",
      "Epoch 14 | Step 5326 | loss: 0.2494451640837493 | accuracy: 0.8992456896551724 \n",
      "Epoch 14 | Step 5327 | loss: 0.24968329622325564 | accuracy: 0.8995028409090909 \n",
      "Epoch 14 | Step 5328 | loss: 0.24840795533375787 | accuracy: 0.9002808988764045 \n",
      "Epoch 14 | Step 5329 | loss: 0.24923705433805776 | accuracy: 0.9 \n",
      "Epoch 14 | Step 5330 | loss: 0.24816246846547485 | accuracy: 0.9004120879120879 \n",
      "Epoch 14 | Step 5331 | loss: 0.24734549264868957 | accuracy: 0.9008152173913043 \n",
      "Epoch 14 | Step 5332 | loss: 0.2469868058318732 | accuracy: 0.9008736559139785 \n",
      "Epoch 14 | Step 5333 | loss: 0.24654733952372623 | accuracy: 0.9012632978723404 \n",
      "Epoch 14 | Step 5334 | loss: 0.24709197729825966 | accuracy: 0.9009868421052631 \n",
      "Epoch 14 | Step 5335 | loss: 0.24884747442168487 | accuracy: 0.900390625 \n",
      "Epoch 14 | Step 5336 | loss: 0.24896778465853517 | accuracy: 0.8999677835051546 \n",
      "Epoch 14 | Step 5337 | loss: 0.25031403049218404 | accuracy: 0.8995535714285714 \n",
      "Epoch 14 | Step 5338 | loss: 0.2503184017659437 | accuracy: 0.8997790404040404 \n",
      "Epoch 14 | Step 5339 | loss: 0.24945675753056995 | accuracy: 0.9003125 \n",
      "Epoch 14 | Step 5340 | loss: 0.24822645206557636 | accuracy: 0.901144801980198 \n",
      "Epoch 14 | Step 5341 | loss: 0.24804483595139834 | accuracy: 0.9013480392156863 \n",
      "Epoch 14 | Step 5342 | loss: 0.24718163075666977 | accuracy: 0.9016990291262136 \n",
      "Epoch 14 | Step 5343 | loss: 0.24805280931580517 | accuracy: 0.9015925480769231 \n",
      "Epoch 14 | Step 5344 | loss: 0.2491842518959726 | accuracy: 0.9010416666666666 \n",
      "Epoch 14 | Step 5345 | loss: 0.24835139140486712 | accuracy: 0.9015330188679245 \n",
      "Epoch 14 | Step 5346 | loss: 0.24958373919547155 | accuracy: 0.9011390186915887 \n",
      "Epoch 14 | Step 5347 | loss: 0.2511337178034914 | accuracy: 0.9008969907407407 \n",
      "Epoch 14 | Step 5348 | loss: 0.25155427717014184 | accuracy: 0.9009461009174312 \n",
      "Epoch 14 | Step 5349 | loss: 0.25219119753349906 | accuracy: 0.9004261363636363 \n",
      "Epoch 14 | Step 5350 | loss: 0.25181472804900756 | accuracy: 0.9003378378378378 \n",
      "Epoch 14 | Step 5351 | loss: 0.2517358584196439 | accuracy: 0.900390625 \n",
      "Epoch 14 | Step 5352 | loss: 0.2527197048859258 | accuracy: 0.9000276548672567 \n",
      "Epoch 14 | Step 5353 | loss: 0.2535038737482146 | accuracy: 0.8998081140350878 \n",
      "Epoch 14 | Step 5354 | loss: 0.25335873009070103 | accuracy: 0.8994565217391305 \n",
      "Epoch 14 | Step 5355 | loss: 0.25306603575831854 | accuracy: 0.8995150862068966 \n",
      "Epoch 14 | Step 5356 | loss: 0.25388986337133956 | accuracy: 0.8987713675213675 \n",
      "Epoch 14 | Step 5357 | loss: 0.25407233865836915 | accuracy: 0.8983050847457628 \n",
      "Epoch 14 | Step 5358 | loss: 0.25408084509002055 | accuracy: 0.8985031512605042 \n",
      "Epoch 14 | Step 5359 | loss: 0.25354191182802116 | accuracy: 0.8986979166666667 \n",
      "Epoch 14 | Step 5360 | loss: 0.2534032307011036 | accuracy: 0.8987603305785123 \n",
      "Epoch 14 | Step 5361 | loss: 0.2530930107612101 | accuracy: 0.8986936475409836 \n",
      "Epoch 14 | Step 5362 | loss: 0.25312429345477877 | accuracy: 0.8985010162601627 \n",
      "Epoch 14 | Step 5363 | loss: 0.25335178902793304 | accuracy: 0.8986895161290323 \n",
      "Epoch 14 | Step 5364 | loss: 0.2535460914969443 | accuracy: 0.898375 \n",
      "Epoch 14 | Step 5365 | loss: 0.25319170981409045 | accuracy: 0.8986855158730159 \n",
      "Epoch 14 | Step 5366 | loss: 0.25351127307480703 | accuracy: 0.8982529527559056 \n",
      "Epoch 14 | Step 5367 | loss: 0.2531143113155848 | accuracy: 0.8983154296875 \n",
      "Epoch 14 | Step 5368 | loss: 0.2529787243914233 | accuracy: 0.8980135658914729 \n",
      "Epoch 14 | Step 5369 | loss: 0.2526639494185263 | accuracy: 0.8981971153846153 \n",
      "Epoch 14 | Step 5370 | loss: 0.25325676622509036 | accuracy: 0.8979007633587787 \n",
      "Epoch 14 | Step 5371 | loss: 0.2542600397472128 | accuracy: 0.8977272727272727 \n",
      "Epoch 14 | Step 5372 | loss: 0.25541459040758296 | accuracy: 0.8973214285714286 \n",
      "Epoch 14 | Step 5373 | loss: 0.2556013376521529 | accuracy: 0.8969216417910447 \n",
      "Epoch 14 | Step 5374 | loss: 0.25567839371937284 | accuracy: 0.8966435185185184 \n",
      "Epoch 14 | Step 5375 | loss: 0.2553379598676281 | accuracy: 0.896829044117647 \n",
      "Epoch 14 | Step 5376 | loss: 0.25477602408967737 | accuracy: 0.896897810218978 \n",
      "Epoch 14 | Step 5377 | loss: 0.25448067167746835 | accuracy: 0.8971920289855071 \n",
      "Epoch 14 | Step 5378 | loss: 0.2549638019727287 | accuracy: 0.8969199640287768 \n",
      "Epoch 14 | Step 5379 | loss: 0.25501183936638483 | accuracy: 0.896986607142857 \n",
      "Epoch 14 | Step 5380 | loss: 0.2561587689721837 | accuracy: 0.8967198581560283 \n",
      "Epoch 14 | Step 5381 | loss: 0.2563005107074555 | accuracy: 0.8968970070422534 \n",
      "Epoch 14 | Step 5382 | loss: 0.25687034943929077 | accuracy: 0.8966346153846154 \n",
      "Epoch 14 | Step 5383 | loss: 0.2569360416899952 | accuracy: 0.896484375 \n",
      "Epoch 14 | Step 5384 | loss: 0.2568237579588231 | accuracy: 0.8964439655172414 \n",
      "Epoch 14 | Step 5385 | loss: 0.25702841615636046 | accuracy: 0.8962970890410958 \n",
      "Epoch 14 | Step 5386 | loss: 0.25615929497950735 | accuracy: 0.8967899659863946 \n",
      "Epoch 14 | Step 5387 | loss: 0.2563501412703378 | accuracy: 0.8966427364864865 \n",
      "Epoch 14 | Step 5388 | loss: 0.2560001451197086 | accuracy: 0.8969169463087249 \n",
      "Epoch 14 | Step 5389 | loss: 0.25638301566243166 | accuracy: 0.8970833333333333 \n",
      "Epoch 14 | Step 5390 | loss: 0.25651522005433275 | accuracy: 0.8971440397350994 \n",
      "Epoch 14 | Step 5391 | loss: 0.25748750150791905 | accuracy: 0.8968955592105263 \n",
      "Epoch 14 | Step 5392 | loss: 0.2577997835146056 | accuracy: 0.8970588235294118 \n",
      "Epoch 14 | Step 5393 | loss: 0.257307770335442 | accuracy: 0.8973214285714286 \n",
      "Epoch 14 | Step 5394 | loss: 0.25701501345442185 | accuracy: 0.8975806451612903 \n",
      "Epoch 14 | Step 5395 | loss: 0.25618882539371646 | accuracy: 0.8979366987179487 \n",
      "Epoch 14 | Step 5396 | loss: 0.25624717197790264 | accuracy: 0.8979896496815286 \n",
      "Epoch 14 | Step 5397 | loss: 0.2565809733977046 | accuracy: 0.897745253164557 \n",
      "Epoch 14 | Step 5398 | loss: 0.2567438264406702 | accuracy: 0.8974056603773585 \n",
      "Epoch 14 | Step 5399 | loss: 0.25704037887044245 | accuracy: 0.89736328125 \n",
      "Epoch 14 | Step 5400 | loss: 0.2572030162681704 | accuracy: 0.8972243788819876 \n",
      "Epoch 14 | Step 5401 | loss: 0.25726314279952167 | accuracy: 0.8972800925925926 \n",
      "Epoch 14 | Step 5402 | loss: 0.25821381555927314 | accuracy: 0.89704754601227 \n",
      "Epoch 14 | Step 5403 | loss: 0.25806088831911733 | accuracy: 0.8971036585365854 \n",
      "Epoch 14 | Step 5404 | loss: 0.25823764941006006 | accuracy: 0.896969696969697 \n",
      "Epoch 14 | Step 5405 | loss: 0.2584494007190309 | accuracy: 0.8968373493975904 \n",
      "Epoch 14 | Step 5406 | loss: 0.25824277321557093 | accuracy: 0.8968937125748503 \n",
      "Epoch 14 | Step 5407 | loss: 0.2591035431250931 | accuracy: 0.896484375 \n",
      "Epoch 14 | Step 5408 | loss: 0.25886551819785825 | accuracy: 0.8966346153846154 \n",
      "Epoch 14 | Step 5409 | loss: 0.2581237073768589 | accuracy: 0.8970588235294118 \n",
      "Epoch 14 | Step 5410 | loss: 0.25802273120273633 | accuracy: 0.8971125730994152 \n",
      "Epoch 14 | Step 5411 | loss: 0.25805866791931703 | accuracy: 0.8971656976744186 \n",
      "Epoch 14 | Step 5412 | loss: 0.25773957462152314 | accuracy: 0.8972182080924855 \n",
      "Epoch 14 | Step 5413 | loss: 0.257813721595482 | accuracy: 0.8974497126436781 \n",
      "Epoch 14 | Step 5414 | loss: 0.257539037508624 | accuracy: 0.8975892857142858 \n",
      "Epoch 14 | Step 5415 | loss: 0.25817752210423356 | accuracy: 0.8972833806818182 \n",
      "Epoch 14 | Step 5416 | loss: 0.25889443463019735 | accuracy: 0.8968926553672316 \n",
      "Epoch 14 | Step 5417 | loss: 0.2593995153987676 | accuracy: 0.8965063202247191 \n",
      "Epoch 14 | Step 5418 | loss: 0.25999393513915264 | accuracy: 0.8960370111731844 \n",
      "Epoch 14 | Step 5419 | loss: 0.2596714109596279 | accuracy: 0.8960069444444444 \n",
      "Epoch 14 | Step 5420 | loss: 0.25987846618363875 | accuracy: 0.8956319060773481 \n",
      "Epoch 14 | Step 5421 | loss: 0.25968395275892797 | accuracy: 0.8956902472527473 \n",
      "Epoch 14 | Step 5422 | loss: 0.2590580602568356 | accuracy: 0.896089480874317 \n",
      "Epoch 14 | Step 5423 | loss: 0.25845074277047236 | accuracy: 0.8963994565217391 \n",
      "Epoch 14 | Step 5424 | loss: 0.25824556161422996 | accuracy: 0.8965371621621622 \n",
      "Epoch 14 | Step 5425 | loss: 0.2586950934141555 | accuracy: 0.8961693548387096 \n",
      "Epoch 14 | Step 5426 | loss: 0.25909733138779273 | accuracy: 0.8959725935828877 \n",
      "Epoch 14 | Step 5427 | loss: 0.25925017770459047 | accuracy: 0.8956117021276596 \n",
      "Epoch 14 | Step 5428 | loss: 0.2591233540858542 | accuracy: 0.8957506613756614 \n",
      "Epoch 14 | Step 5429 | loss: 0.25999295370359177 | accuracy: 0.8955592105263158 \n",
      "Epoch 14 | Step 5430 | loss: 0.2593167697649976 | accuracy: 0.8958606020942408 \n",
      "Epoch 14 | Step 5431 | loss: 0.25902110117021954 | accuracy: 0.8959147135416666 \n",
      "Epoch 14 | Step 5432 | loss: 0.25874171182127204 | accuracy: 0.896211139896373 \n",
      "Epoch 14 | Step 5433 | loss: 0.2586298597611718 | accuracy: 0.8963434278350515 \n",
      "Epoch 14 | Step 5434 | loss: 0.25851133332038545 | accuracy: 0.8963141025641026 \n",
      "Epoch 14 | Step 5435 | loss: 0.25846220290630456 | accuracy: 0.8964445153061225 \n",
      "Epoch 14 | Step 5436 | loss: 0.2585162324878166 | accuracy: 0.8964149746192893 \n",
      "Epoch 14 | Step 5437 | loss: 0.2586380492782955 | accuracy: 0.8964646464646465 \n",
      "Epoch 14 | Step 5438 | loss: 0.2582804104266455 | accuracy: 0.8967493718592965 \n",
      "Epoch 14 | Step 5439 | loss: 0.25797214832156906 | accuracy: 0.896796875 \n",
      "Epoch 14 | Step 5440 | loss: 0.2585892625041863 | accuracy: 0.896610696517413 \n",
      "Epoch 14 | Step 5441 | loss: 0.2584681962017376 | accuracy: 0.8968131188118812 \n",
      "Epoch 14 | Step 5442 | loss: 0.2585417456154166 | accuracy: 0.8968596059113301 \n",
      "Epoch 14 | Step 5443 | loss: 0.25826684045879283 | accuracy: 0.8969822303921569 \n",
      "Epoch 14 | Step 5444 | loss: 0.2586680378492286 | accuracy: 0.8967987804878049 \n",
      "Epoch 14 | Step 5445 | loss: 0.2595569411455428 | accuracy: 0.8965412621359223 \n",
      "Epoch 14 | Step 5446 | loss: 0.2603816019668096 | accuracy: 0.8965126811594203 \n",
      "Epoch 14 | Step 5447 | loss: 0.2601783179964584 | accuracy: 0.896484375 \n",
      "Epoch 14 | Step 5448 | loss: 0.26002490381447324 | accuracy: 0.8966058612440191 \n",
      "Epoch 14 | Step 5449 | loss: 0.2601522735541775 | accuracy: 0.8964285714285715 \n",
      "Epoch 14 | Step 5450 | loss: 0.2604261769855757 | accuracy: 0.896252962085308 \n",
      "Epoch 14 | Step 5451 | loss: 0.2598334594787854 | accuracy: 0.8965949292452831 \n",
      "Epoch 14 | Step 5452 | loss: 0.259426125653193 | accuracy: 0.8967869718309859 \n",
      "Epoch 14 | Step 5453 | loss: 0.2594095329606087 | accuracy: 0.8969772196261683 \n",
      "Epoch 14 | Step 5454 | loss: 0.25930801799824066 | accuracy: 0.896875 \n",
      "Epoch 14 | Step 5455 | loss: 0.25934082355902144 | accuracy: 0.8968460648148148 \n",
      "Epoch 14 | Step 5456 | loss: 0.25901679155601326 | accuracy: 0.896961405529954 \n",
      "Epoch 14 | Step 5457 | loss: 0.2588056748681658 | accuracy: 0.8970756880733946 \n",
      "Epoch 14 | Step 5458 | loss: 0.2586352716638072 | accuracy: 0.8972602739726028 \n",
      "Epoch 14 | Step 5459 | loss: 0.25854036059569213 | accuracy: 0.8972301136363636 \n",
      "Epoch 14 | Step 5460 | loss: 0.25850423722110705 | accuracy: 0.8972709276018099 \n",
      "Epoch 14 | Step 5461 | loss: 0.2584425509982816 | accuracy: 0.8973817567567568 \n",
      "Epoch 14 | Step 5462 | loss: 0.2585288852520052 | accuracy: 0.8971412556053812 \n",
      "Epoch 14 | Step 5463 | loss: 0.25791780351261995 | accuracy: 0.8976004464285714 \n",
      "Epoch 14 | Step 5464 | loss: 0.2579581687847772 | accuracy: 0.8975 \n",
      "Epoch 14 | Step 5465 | loss: 0.25832358483983336 | accuracy: 0.8974004424778761 \n",
      "Epoch 14 | Step 5466 | loss: 0.2582633996193628 | accuracy: 0.8973705947136564 \n",
      "Epoch 14 | Step 5467 | loss: 0.25822449142211346 | accuracy: 0.8974780701754386 \n",
      "Epoch 14 | Step 5468 | loss: 0.2580988448129469 | accuracy: 0.8974481441048034 \n",
      "Epoch 14 | Step 5469 | loss: 0.25815322327872964 | accuracy: 0.8974864130434783 \n",
      "Epoch 14 | Step 5470 | loss: 0.25788000761430485 | accuracy: 0.8975243506493507 \n",
      "Epoch 14 | Step 5471 | loss: 0.25759048676439383 | accuracy: 0.8977640086206896 \n",
      "Epoch 14 | Step 5472 | loss: 0.25758341830943254 | accuracy: 0.8976663090128756 \n",
      "Epoch 14 | Step 5473 | loss: 0.25773519882534285 | accuracy: 0.897636217948718 \n",
      "Epoch 14 | Step 5474 | loss: 0.2575064075754042 | accuracy: 0.8977393617021276 \n",
      "Epoch 14 | Step 5475 | loss: 0.2571909956128919 | accuracy: 0.8979078389830508 \n",
      "Epoch 14 | Step 5476 | loss: 0.2569717679974397 | accuracy: 0.8979430379746836 \n",
      "Epoch 14 | Step 5477 | loss: 0.25701027313450786 | accuracy: 0.8977809873949579 \n",
      "Epoch 14 | Step 5478 | loss: 0.25697475372497985 | accuracy: 0.8977510460251046 \n",
      "Epoch 14 | Step 5479 | loss: 0.2569688616941371 | accuracy: 0.8977213541666667 \n",
      "Epoch 14 | Step 5480 | loss: 0.25645947079193526 | accuracy: 0.8978864107883817 \n",
      "Epoch 14 | Step 5481 | loss: 0.2560392828765978 | accuracy: 0.8979855371900827 \n",
      "Epoch 14 | Step 5482 | loss: 0.2565854471406817 | accuracy: 0.8978909465020576 \n",
      "Epoch 14 | Step 5483 | loss: 0.2568812926040319 | accuracy: 0.8978611680327869 \n",
      "Epoch 14 | Step 5484 | loss: 0.2568366303127637 | accuracy: 0.8978316326530612 \n",
      "Epoch 14 | Step 5485 | loss: 0.25670459945269697 | accuracy: 0.8977388211382114 \n",
      "Epoch 14 | Step 5486 | loss: 0.2563594055441225 | accuracy: 0.897963056680162 \n",
      "Epoch 14 | Step 5487 | loss: 0.2564308791751821 | accuracy: 0.8979334677419355 \n",
      "Epoch 14 | Step 5488 | loss: 0.25641373847143695 | accuracy: 0.8979041164658634 \n",
      "Epoch 14 | Step 5489 | loss: 0.25650956970453237 | accuracy: 0.8979375 \n",
      "Epoch 14 | Step 5490 | loss: 0.256167706502861 | accuracy: 0.8982196215139442 \n",
      "Epoch 14 | Step 5491 | loss: 0.2562143749424387 | accuracy: 0.8980034722222222 \n",
      "Epoch 14 | Step 5492 | loss: 0.25611358633625625 | accuracy: 0.8979125494071146 \n",
      "Epoch 14 | Step 5493 | loss: 0.2560410602238232 | accuracy: 0.8980068897637795 \n",
      "Epoch 14 | Step 5494 | loss: 0.2560035291840046 | accuracy: 0.8979779411764706 \n",
      "Epoch 14 | Step 5495 | loss: 0.25612848973833 | accuracy: 0.8978271484375 \n",
      "Epoch 14 | Step 5496 | loss: 0.255987537162313 | accuracy: 0.8977991245136187 \n",
      "Epoch 14 | Step 5497 | loss: 0.255696908390337 | accuracy: 0.897953003875969 \n",
      "Epoch 14 | Step 5498 | loss: 0.25597420375089364 | accuracy: 0.8977437258687259 \n",
      "Epoch 14 | Step 5499 | loss: 0.25569278786961824 | accuracy: 0.8977163461538461 \n",
      "Epoch 14 | Step 5500 | loss: 0.2562575805575453 | accuracy: 0.8973299808429118 \n",
      "Epoch 14 | Step 5501 | loss: 0.25649576019922266 | accuracy: 0.8971851145038168 \n",
      "Epoch 14 | Step 5502 | loss: 0.25619767560931644 | accuracy: 0.8972195817490495 \n",
      "Epoch 14 | Step 5503 | loss: 0.2567434454844754 | accuracy: 0.8970762310606061 \n",
      "Epoch 14 | Step 5504 | loss: 0.2565189513395415 | accuracy: 0.8971108490566038 \n",
      "Epoch 14 | Step 5505 | loss: 0.25637221526830695 | accuracy: 0.897203947368421 \n",
      "Epoch 14 | Step 5506 | loss: 0.256159741836094 | accuracy: 0.8972963483146067 \n",
      "Epoch 14 | Step 5507 | loss: 0.2558309958497088 | accuracy: 0.8973880597014925 \n",
      "Epoch 14 | Step 5508 | loss: 0.2558163508606664 | accuracy: 0.8973048327137546 \n",
      "Epoch 14 | Step 5509 | loss: 0.25568782957615654 | accuracy: 0.8972800925925926 \n",
      "Epoch 14 | Step 5510 | loss: 0.2558037594125717 | accuracy: 0.897140221402214 \n",
      "Epoch 14 | Step 5511 | loss: 0.25575253181159474 | accuracy: 0.8970588235294118 \n",
      "Epoch 14 | Step 5512 | loss: 0.2557396099462612 | accuracy: 0.8969207875457875 \n",
      "Epoch 14 | Step 5513 | loss: 0.25569265069317626 | accuracy: 0.8968978102189781 \n",
      "Epoch 14 | Step 5514 | loss: 0.2556894322958858 | accuracy: 0.8969318181818182 \n",
      "Epoch 14 | Step 5515 | loss: 0.2558338429400885 | accuracy: 0.8967957427536232 \n",
      "Epoch 14 | Step 5516 | loss: 0.25579365108848034 | accuracy: 0.8968862815884476 \n",
      "Epoch 14 | Step 5517 | loss: 0.25562966781125634 | accuracy: 0.8969761690647482 \n",
      "Epoch 14 | Step 5518 | loss: 0.25570919597020697 | accuracy: 0.8968413978494624 \n",
      "Epoch 14 | Step 5519 | loss: 0.25553941907627226 | accuracy: 0.8969308035714286 \n",
      "Epoch 14 | Step 5520 | loss: 0.25600785218523897 | accuracy: 0.8964635231316727 \n",
      "Epoch 14 | Step 5521 | loss: 0.2558238683334478 | accuracy: 0.8964982269503547 \n",
      "Epoch 14 | Step 5522 | loss: 0.255950776669246 | accuracy: 0.8964774734982334 \n",
      "Epoch 14 | Step 5523 | loss: 0.2557743775172971 | accuracy: 0.8966769366197185 \n",
      "Epoch 14 | Step 5524 | loss: 0.25556200167589005 | accuracy: 0.8968201754385967 \n",
      "Epoch 14 | Step 5525 | loss: 0.25559887144115406 | accuracy: 0.8967985139860142 \n",
      "Epoch 14 | Step 5526 | loss: 0.25556599829047383 | accuracy: 0.89672256097561 \n",
      "Epoch 14 | Step 5527 | loss: 0.2552669657290808 | accuracy: 0.8968641493055558 \n",
      "Epoch 14 | Step 5528 | loss: 0.2551290038135223 | accuracy: 0.896896626297578 \n",
      "Epoch 14 | Step 5529 | loss: 0.2555125527340789 | accuracy: 0.8968211206896554 \n",
      "Epoch 14 | Step 5530 | loss: 0.255261539183941 | accuracy: 0.8969609106529212 \n",
      "Epoch 14 | Step 5531 | loss: 0.2552625690012761 | accuracy: 0.8970462328767125 \n",
      "Epoch 14 | Step 5532 | loss: 0.2553743228774021 | accuracy: 0.8970243174061435 \n",
      "Epoch 14 | Step 5533 | loss: 0.25491613854153616 | accuracy: 0.8972682823129253 \n",
      "Epoch 14 | Step 5534 | loss: 0.25537145506527453 | accuracy: 0.8971398305084748 \n",
      "Epoch 14 | Step 5535 | loss: 0.2552613317463043 | accuracy: 0.8971706081081083 \n",
      "Epoch 14 | Step 5536 | loss: 0.25566474872606765 | accuracy: 0.8968329124579126 \n",
      "Epoch 14 | Step 5537 | loss: 0.25554122030735005 | accuracy: 0.8967072147651008 \n",
      "Epoch 14 | Step 5538 | loss: 0.2554573660411164 | accuracy: 0.8966868729096992 \n",
      "Epoch 14 | Step 5539 | loss: 0.25528740336497613 | accuracy: 0.8966666666666668 \n",
      "Epoch 14 | Step 5540 | loss: 0.2551609304953254 | accuracy: 0.8968023255813955 \n",
      "Epoch 14 | Step 5541 | loss: 0.2550488746916221 | accuracy: 0.8967818708609273 \n",
      "Epoch 14 | Step 5542 | loss: 0.2547317636091716 | accuracy: 0.8968131188118814 \n",
      "Epoch 14 | Step 5543 | loss: 0.25471420007708817 | accuracy: 0.8968441611842107 \n",
      "Epoch 14 | Step 5544 | loss: 0.25504621120749915 | accuracy: 0.8968237704918035 \n",
      "Epoch 14 | Step 5545 | loss: 0.254838960525257 | accuracy: 0.8970077614379087 \n",
      "Epoch 14 | Step 5546 | loss: 0.25472550851320197 | accuracy: 0.8970887622149839 \n",
      "Epoch 14 | Step 5547 | loss: 0.25443663215869416 | accuracy: 0.8971692370129872 \n",
      "Epoch 14 | Step 5548 | loss: 0.2540564797939218 | accuracy: 0.8974008899676377 \n",
      "Epoch 14 | Step 5549 | loss: 0.254034885619917 | accuracy: 0.8973790322580647 \n",
      "Epoch 14 | Step 5550 | loss: 0.2539547690912073 | accuracy: 0.8975080385852092 \n",
      "Epoch 14 | Step 5551 | loss: 0.2539899143366475 | accuracy: 0.897586137820513 \n",
      "Epoch 14 | Step 5552 | loss: 0.2537666690616179 | accuracy: 0.8976637380191695 \n",
      "Epoch 14 | Step 5553 | loss: 0.2537655730725851 | accuracy: 0.8975915605095544 \n",
      "Epoch 14 | Step 5554 | loss: 0.25336766153100915 | accuracy: 0.8977678571428573 \n",
      "Epoch 14 | Step 5555 | loss: 0.25355029318340194 | accuracy: 0.8975969145569622 \n",
      "Epoch 14 | Step 5556 | loss: 0.2534301291786908 | accuracy: 0.8976242113564671 \n",
      "Epoch 14 | Step 5557 | loss: 0.2534614978065279 | accuracy: 0.8976022012578618 \n",
      "Epoch 14 | Step 5558 | loss: 0.25339821167874094 | accuracy: 0.8976782915360504 \n",
      "Epoch 14 | Step 5559 | loss: 0.2533021171577273 | accuracy: 0.8978027343750001 \n",
      "Epoch 14 | Step 5560 | loss: 0.25333286306568376 | accuracy: 0.897829049844237 \n",
      "Epoch 14 | Step 5561 | loss: 0.253179718803915 | accuracy: 0.8980007763975157 \n",
      "Epoch 14 | Step 5562 | loss: 0.25315080620002434 | accuracy: 0.898074690402477 \n",
      "Epoch 14 | Step 5563 | loss: 0.25317694416936515 | accuracy: 0.8979552469135804 \n",
      "Epoch 14 | Step 5564 | loss: 0.25315813536827364 | accuracy: 0.8978846153846156 \n",
      "Epoch 14 | Step 5565 | loss: 0.2532365948784569 | accuracy: 0.897670628834356 \n",
      "Epoch 14 | Step 5566 | loss: 0.25335576278171756 | accuracy: 0.8975535168195721 \n",
      "Epoch 14 | Step 5567 | loss: 0.2533732404160062 | accuracy: 0.8975800304878051 \n",
      "Epoch 14 | Step 5568 | loss: 0.2530137864380258 | accuracy: 0.8977013677811552 \n",
      "Epoch 14 | Step 5569 | loss: 0.252969957617196 | accuracy: 0.8977272727272729 \n",
      "Epoch 14 | Step 5570 | loss: 0.252907087885721 | accuracy: 0.8977530211480365 \n",
      "Epoch 14 | Step 5571 | loss: 0.2527620877666644 | accuracy: 0.8977786144578315 \n",
      "Epoch 14 | Step 5572 | loss: 0.25264755244906584 | accuracy: 0.8978509759759762 \n",
      "Epoch 14 | Step 5573 | loss: 0.25254961915180335 | accuracy: 0.8979696856287427 \n",
      "Epoch 14 | Step 5574 | loss: 0.25263098367114545 | accuracy: 0.8979011194029852 \n",
      "Epoch 14 | Step 5575 | loss: 0.2526385070578681 | accuracy: 0.8978794642857144 \n",
      "Epoch 14 | Step 5576 | loss: 0.25259621291026146 | accuracy: 0.8978579376854601 \n",
      "Epoch 14 | Step 5577 | loss: 0.2524655141244977 | accuracy: 0.8978827662721895 \n",
      "Epoch 14 | Step 5578 | loss: 0.25224975358068397 | accuracy: 0.8980457227138645 \n",
      "Epoch 14 | Step 5579 | loss: 0.25211103773292354 | accuracy: 0.8982077205882355 \n",
      "Epoch 14 | Step 5580 | loss: 0.25223007400539244 | accuracy: 0.8981854838709679 \n",
      "Epoch 14 | Step 5581 | loss: 0.25213281182866326 | accuracy: 0.8982090643274856 \n",
      "Epoch 14 | Step 5582 | loss: 0.25183094868507033 | accuracy: 0.8983691690962101 \n",
      "Epoch 14 | Step 5583 | loss: 0.2518115450389855 | accuracy: 0.8983466569767443 \n",
      "Epoch 14 | Step 5584 | loss: 0.2517989251924596 | accuracy: 0.8983695652173914 \n",
      "Epoch 14 | Step 5585 | loss: 0.25164295896629363 | accuracy: 0.8984826589595377 \n",
      "Epoch 14 | Step 5586 | loss: 0.25155755224763815 | accuracy: 0.8985951008645535 \n",
      "Epoch 14 | Step 5587 | loss: 0.2513610999817134 | accuracy: 0.8986619971264369 \n",
      "Epoch 14 | Step 5588 | loss: 0.25130922541577344 | accuracy: 0.8986389684813755 \n",
      "Epoch 14 | Step 5589 | loss: 0.25146879247256676 | accuracy: 0.898482142857143 \n",
      "Epoch 14 | Step 5590 | loss: 0.25109990013291 | accuracy: 0.898593304843305 \n",
      "Epoch 14 | Step 5591 | loss: 0.25104011819613237 | accuracy: 0.8985706676136366 \n",
      "Epoch 14 | Step 5592 | loss: 0.2510092100154913 | accuracy: 0.8985481586402267 \n",
      "Epoch 14 | Step 5593 | loss: 0.25130686041830613 | accuracy: 0.8983933615819211 \n",
      "Epoch 14 | Step 5594 | loss: 0.2511130293490181 | accuracy: 0.8984595070422536 \n",
      "Epoch 14 | Step 5595 | loss: 0.2509825004453069 | accuracy: 0.8985252808988765 \n",
      "Epoch 14 | Step 5596 | loss: 0.25117903096335265 | accuracy: 0.8984156162464988 \n",
      "Epoch 14 | Step 5597 | loss: 0.2515761654137232 | accuracy: 0.8983065642458102 \n",
      "Epoch 14 | Step 5598 | loss: 0.25139438512431533 | accuracy: 0.8984157381615601 \n",
      "Epoch 14 | Step 5599 | loss: 0.2515584032982587 | accuracy: 0.8984375000000001 \n",
      "Epoch 14 | Step 5600 | loss: 0.2514033758821909 | accuracy: 0.8985457063711912 \n",
      "Epoch 14 | Step 5601 | loss: 0.251422270926652 | accuracy: 0.8984375000000001 \n",
      "Epoch 14 | Step 5602 | loss: 0.25138770314780146 | accuracy: 0.8983729338842977 \n",
      "Epoch 14 | Step 5603 | loss: 0.25102666440000243 | accuracy: 0.8985662774725276 \n",
      "Epoch 14 | Step 5604 | loss: 0.2508584247672394 | accuracy: 0.8986729452054796 \n",
      "Epoch 14 | Step 5605 | loss: 0.2510578243743852 | accuracy: 0.898565573770492 \n",
      "Epoch 14 | Step 5606 | loss: 0.25121937742918643 | accuracy: 0.8984162125340601 \n",
      "Epoch 14 | Step 5607 | loss: 0.25113041223148286 | accuracy: 0.8984799592391306 \n",
      "Epoch 14 | Step 5608 | loss: 0.25122790892676605 | accuracy: 0.8985857046070462 \n",
      "Epoch 14 | Step 5609 | loss: 0.2511031300836318 | accuracy: 0.8986486486486488 \n",
      "Epoch 14 | Step 5610 | loss: 0.25118462249355494 | accuracy: 0.8986691374663074 \n",
      "Epoch 14 | Step 5611 | loss: 0.25106585476427307 | accuracy: 0.8987315188172045 \n",
      "Epoch 14 | Step 5612 | loss: 0.2507503498695171 | accuracy: 0.8988773458445042 \n",
      "Epoch 14 | Step 5613 | loss: 0.25061190166176955 | accuracy: 0.8989806149732622 \n",
      "Epoch 14 | Step 5614 | loss: 0.25080986052751536 | accuracy: 0.8988750000000002 \n",
      "Epoch 14 | Step 5615 | loss: 0.250678116871797 | accuracy: 0.8988530585106385 \n",
      "Epoch 14 | Step 5616 | loss: 0.2505486626721503 | accuracy: 0.8988726790450929 \n",
      "Epoch 14 | Step 5617 | loss: 0.2505010745079113 | accuracy: 0.8988921957671959 \n",
      "Epoch 14 | Step 5618 | loss: 0.250230151324442 | accuracy: 0.8989528364116096 \n",
      "Epoch 14 | Step 5619 | loss: 0.2500810924133188 | accuracy: 0.899013157894737 \n",
      "Epoch 14 | Step 5620 | loss: 0.2497722079630286 | accuracy: 0.8991551837270343 \n",
      "Epoch 14 | Step 5621 | loss: 0.24982171090251487 | accuracy: 0.8991328534031415 \n",
      "Epoch 14 | Step 5622 | loss: 0.24986516676512463 | accuracy: 0.8991514360313317 \n",
      "Epoch 14 | Step 5623 | loss: 0.2502184494903001 | accuracy: 0.8991699218750001 \n",
      "Epoch 14 | Step 5624 | loss: 0.25004787625043423 | accuracy: 0.8992694805194806 \n",
      "Epoch 14 | Step 5625 | loss: 0.24995065497842478 | accuracy: 0.8993685233160623 \n",
      "Epoch 14 | Step 5626 | loss: 0.2499051049197675 | accuracy: 0.8993863049095608 \n",
      "Epoch 14 | Step 5627 | loss: 0.2500637555974968 | accuracy: 0.8993637242268042 \n",
      "Epoch 14 | Step 5628 | loss: 0.24991801478792278 | accuracy: 0.8993412596401029 \n",
      "Epoch 14 | Step 5629 | loss: 0.24989909474284222 | accuracy: 0.8993990384615386 \n",
      "Epoch 14 | Step 5630 | loss: 0.24993089609362584 | accuracy: 0.8994964833759592 \n",
      "Epoch 14 | Step 5631 | loss: 0.24981802916724463 | accuracy: 0.8995934311224492 \n",
      "Epoch 14 | Step 5632 | loss: 0.24966540532636886 | accuracy: 0.8996501272264632 \n",
      "Epoch 14 | Step 5633 | loss: 0.24985379527138574 | accuracy: 0.8994289340101524 \n",
      "Epoch 14 | Step 5634 | loss: 0.2496477918345717 | accuracy: 0.899485759493671 \n",
      "Epoch 14 | Step 5635 | loss: 0.24948898930516508 | accuracy: 0.8995817550505052 \n",
      "Epoch 14 | Step 5636 | loss: 0.24947663636817138 | accuracy: 0.8996379093198994 \n",
      "Epoch 14 | Step 5637 | loss: 0.2495618809070719 | accuracy: 0.8995367462311559 \n",
      "Epoch 14 | Step 5638 | loss: 0.2493470670249229 | accuracy: 0.8996318922305766 \n",
      "Epoch 14 | Step 5639 | loss: 0.24926012815907597 | accuracy: 0.8996484375000001 \n",
      "Epoch 14 | Step 5640 | loss: 0.24932979677160483 | accuracy: 0.8997038653366585 \n",
      "Epoch 14 | Step 5641 | loss: 0.24952506316612608 | accuracy: 0.8995646766169155 \n",
      "Epoch 14 | Step 5642 | loss: 0.24932543010850697 | accuracy: 0.8996427655220033 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.44673919677734375 | accuracy: 0.78125 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.38295988738536835 | accuracy: 0.8359375 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4238622883955638 | accuracy: 0.84375 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.42910587042570114 | accuracy: 0.82421875 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4032207906246185 | accuracy: 0.8375 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.42973901331424713 | accuracy: 0.8203125 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4310079259531839 | accuracy: 0.8236607142857143 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.42239800468087196 | accuracy: 0.828125 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4500482247935401 | accuracy: 0.8246527777777778 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4342691093683243 | accuracy: 0.8328125 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.438954315402291 | accuracy: 0.8323863636363636 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.42654165625572205 | accuracy: 0.8372395833333334 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.43282166811136097 | accuracy: 0.8329326923076923 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.42363023332187105 | accuracy: 0.8337053571428571 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4260264893372854 | accuracy: 0.8364583333333333 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.42647747322916985 | accuracy: 0.8369140625 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.43102052281884584 | accuracy: 0.8327205882352942 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.42824877467420364 | accuracy: 0.8333333333333334 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4245716066736924 | accuracy: 0.8355263157894737 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.42032462954521177 | accuracy: 0.8359375 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.41406426543281194 | accuracy: 0.8370535714285714 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4079965353012085 | accuracy: 0.8387784090909091 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4136300605276357 | accuracy: 0.8369565217391305 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4291708419720332 | accuracy: 0.8333333333333334 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4357634973526001 | accuracy: 0.83 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.432653458072589 | accuracy: 0.8305288461538461 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.42695620435255544 | accuracy: 0.8327546296296297 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.42960181513002943 | accuracy: 0.8309151785714286 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4269274514296959 | accuracy: 0.8308189655172413 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.42373804450035096 | accuracy: 0.8328125 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4199488287971866 | accuracy: 0.8356854838709677 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.42230155132710934 | accuracy: 0.83349609375 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4222210844357808 | accuracy: 0.8333333333333334 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.42628151178359985 | accuracy: 0.8308823529411765 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.42844782556806293 | accuracy: 0.8299107142857143 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4265504851937294 | accuracy: 0.8302951388888888 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.42674212278546514 | accuracy: 0.8302364864864865 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4292227163126594 | accuracy: 0.8314144736842105 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.428977363384687 | accuracy: 0.8301282051282052 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.42623931244015695 | accuracy: 0.831640625 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4236100279703373 | accuracy: 0.8315548780487805 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.41992970520541784 | accuracy: 0.8325892857142857 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4204379638960195 | accuracy: 0.8321220930232558 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4240192581306804 | accuracy: 0.8299005681818182 \n",
      "Validation | Epoch 14 | Step 5642 | loss: 0.4221187359756894 | accuracy: 0.830298912525177 \n",
      "Epoch 15 | Step 5643 | loss: 0.4188670516014099 | accuracy: 0.8125 \n",
      "Epoch 15 | Step 5644 | loss: 0.274921178817749 | accuracy: 0.8828125 \n",
      "Epoch 15 | Step 5645 | loss: 0.25564981003602344 | accuracy: 0.8958333333333334 \n",
      "Epoch 15 | Step 5646 | loss: 0.25874732807278633 | accuracy: 0.89453125 \n",
      "Epoch 15 | Step 5647 | loss: 0.23492479026317598 | accuracy: 0.90625 \n",
      "Epoch 15 | Step 5648 | loss: 0.2273396154244741 | accuracy: 0.9010416666666666 \n",
      "Epoch 15 | Step 5649 | loss: 0.23120631064687455 | accuracy: 0.9017857142857143 \n",
      "Epoch 15 | Step 5650 | loss: 0.22945643216371536 | accuracy: 0.904296875 \n",
      "Epoch 15 | Step 5651 | loss: 0.23092486626572079 | accuracy: 0.90625 \n",
      "Epoch 15 | Step 5652 | loss: 0.24100537449121476 | accuracy: 0.9046875 \n",
      "Epoch 15 | Step 5653 | loss: 0.23488402637568387 | accuracy: 0.9076704545454546 \n",
      "Epoch 15 | Step 5654 | loss: 0.2286408431828022 | accuracy: 0.91015625 \n",
      "Epoch 15 | Step 5655 | loss: 0.243060358441793 | accuracy: 0.9050480769230769 \n",
      "Epoch 15 | Step 5656 | loss: 0.2400406002998352 | accuracy: 0.9084821428571429 \n",
      "Epoch 15 | Step 5657 | loss: 0.2429346779982249 | accuracy: 0.9052083333333333 \n",
      "Epoch 15 | Step 5658 | loss: 0.23496333742514253 | accuracy: 0.91015625 \n",
      "Epoch 15 | Step 5659 | loss: 0.23779691536636913 | accuracy: 0.90625 \n",
      "Epoch 15 | Step 5660 | loss: 0.23654640507366922 | accuracy: 0.9071180555555556 \n",
      "Epoch 15 | Step 5661 | loss: 0.23518271234474683 | accuracy: 0.9070723684210527 \n",
      "Epoch 15 | Step 5662 | loss: 0.2383335042744875 | accuracy: 0.90625 \n",
      "Epoch 15 | Step 5663 | loss: 0.23893847671293078 | accuracy: 0.9069940476190477 \n",
      "Epoch 15 | Step 5664 | loss: 0.24037327719005672 | accuracy: 0.9069602272727273 \n",
      "Epoch 15 | Step 5665 | loss: 0.2384828908935837 | accuracy: 0.9082880434782609 \n",
      "Epoch 15 | Step 5666 | loss: 0.24044496410836777 | accuracy: 0.9055989583333334 \n",
      "Epoch 15 | Step 5667 | loss: 0.24478327721357346 | accuracy: 0.903125 \n",
      "Epoch 15 | Step 5668 | loss: 0.2436321758880065 | accuracy: 0.9032451923076923 \n",
      "Epoch 15 | Step 5669 | loss: 0.2465701977963801 | accuracy: 0.9021990740740741 \n",
      "Epoch 15 | Step 5670 | loss: 0.24451541661151818 | accuracy: 0.9034598214285714 \n",
      "Epoch 15 | Step 5671 | loss: 0.24720252562185813 | accuracy: 0.9030172413793104 \n",
      "Epoch 15 | Step 5672 | loss: 0.24802510316173235 | accuracy: 0.9015625 \n",
      "Epoch 15 | Step 5673 | loss: 0.24649886522562273 | accuracy: 0.9012096774193549 \n",
      "Epoch 15 | Step 5674 | loss: 0.24593087588436902 | accuracy: 0.90087890625 \n",
      "Epoch 15 | Step 5675 | loss: 0.24586409172325424 | accuracy: 0.9015151515151515 \n",
      "Epoch 15 | Step 5676 | loss: 0.2428541720351752 | accuracy: 0.9034926470588235 \n",
      "Epoch 15 | Step 5677 | loss: 0.23961426126105445 | accuracy: 0.9049107142857142 \n",
      "Epoch 15 | Step 5678 | loss: 0.23827347221473852 | accuracy: 0.9058159722222222 \n",
      "Epoch 15 | Step 5679 | loss: 0.23771226265140483 | accuracy: 0.9054054054054054 \n",
      "Epoch 15 | Step 5680 | loss: 0.23756092845609314 | accuracy: 0.9054276315789473 \n",
      "Epoch 15 | Step 5681 | loss: 0.23566784671483895 | accuracy: 0.9058493589743589 \n",
      "Epoch 15 | Step 5682 | loss: 0.23412773702293635 | accuracy: 0.90703125 \n",
      "Epoch 15 | Step 5683 | loss: 0.23401427432531263 | accuracy: 0.90625 \n",
      "Epoch 15 | Step 5684 | loss: 0.23520708527593387 | accuracy: 0.9047619047619048 \n",
      "Epoch 15 | Step 5685 | loss: 0.23374822475882465 | accuracy: 0.9051598837209303 \n",
      "Epoch 15 | Step 5686 | loss: 0.23274933936243708 | accuracy: 0.9051846590909091 \n",
      "Epoch 15 | Step 5687 | loss: 0.23385273863871892 | accuracy: 0.9059027777777777 \n",
      "Epoch 15 | Step 5688 | loss: 0.23455396407972212 | accuracy: 0.9045516304347826 \n",
      "Epoch 15 | Step 5689 | loss: 0.23492144317703045 | accuracy: 0.9049202127659575 \n",
      "Epoch 15 | Step 5690 | loss: 0.2349233765465518 | accuracy: 0.9055989583333334 \n",
      "Epoch 15 | Step 5691 | loss: 0.23715851273463698 | accuracy: 0.9049744897959183 \n",
      "Epoch 15 | Step 5692 | loss: 0.23875239565968515 | accuracy: 0.9046875 \n",
      "Epoch 15 | Step 5693 | loss: 0.23802410168390647 | accuracy: 0.9053308823529411 \n",
      "Epoch 15 | Step 5694 | loss: 0.23650763284128445 | accuracy: 0.9059495192307693 \n",
      "Epoch 15 | Step 5695 | loss: 0.2389202723806759 | accuracy: 0.9047759433962265 \n",
      "Epoch 15 | Step 5696 | loss: 0.23799858256070702 | accuracy: 0.9048032407407407 \n",
      "Epoch 15 | Step 5697 | loss: 0.24014992266893387 | accuracy: 0.9034090909090909 \n",
      "Epoch 15 | Step 5698 | loss: 0.23930248099246196 | accuracy: 0.9040178571428571 \n",
      "Epoch 15 | Step 5699 | loss: 0.2405719627675257 | accuracy: 0.9035087719298246 \n",
      "Epoch 15 | Step 5700 | loss: 0.24044168701973453 | accuracy: 0.9032866379310345 \n",
      "Epoch 15 | Step 5701 | loss: 0.24232619483087023 | accuracy: 0.903072033898305 \n",
      "Epoch 15 | Step 5702 | loss: 0.242552292222778 | accuracy: 0.903125 \n",
      "Epoch 15 | Step 5703 | loss: 0.24199537529808576 | accuracy: 0.9039446721311475 \n",
      "Epoch 15 | Step 5704 | loss: 0.24153558849807708 | accuracy: 0.9042338709677419 \n",
      "Epoch 15 | Step 5705 | loss: 0.24343412109310664 | accuracy: 0.9030257936507936 \n",
      "Epoch 15 | Step 5706 | loss: 0.241502458229661 | accuracy: 0.904296875 \n",
      "Epoch 15 | Step 5707 | loss: 0.2403127881196829 | accuracy: 0.9040865384615384 \n",
      "Epoch 15 | Step 5708 | loss: 0.23876038419477869 | accuracy: 0.9050662878787878 \n",
      "Epoch 15 | Step 5709 | loss: 0.23760238223111452 | accuracy: 0.9053171641791045 \n",
      "Epoch 15 | Step 5710 | loss: 0.2375680425149553 | accuracy: 0.9051011029411765 \n",
      "Epoch 15 | Step 5711 | loss: 0.23738551895687546 | accuracy: 0.9051177536231884 \n",
      "Epoch 15 | Step 5712 | loss: 0.2365825048514775 | accuracy: 0.9051339285714286 \n",
      "Epoch 15 | Step 5713 | loss: 0.2351393204339793 | accuracy: 0.9055897887323944 \n",
      "Epoch 15 | Step 5714 | loss: 0.23507842111090818 | accuracy: 0.9055989583333334 \n",
      "Epoch 15 | Step 5715 | loss: 0.23504629241277095 | accuracy: 0.9056078767123288 \n",
      "Epoch 15 | Step 5716 | loss: 0.23516952608888214 | accuracy: 0.9056165540540541 \n",
      "Epoch 15 | Step 5717 | loss: 0.23468307356039683 | accuracy: 0.9060416666666666 \n",
      "Epoch 15 | Step 5718 | loss: 0.23450618648999616 | accuracy: 0.9060444078947368 \n",
      "Epoch 15 | Step 5719 | loss: 0.23392712760281253 | accuracy: 0.90625 \n",
      "Epoch 15 | Step 5720 | loss: 0.23447718987098107 | accuracy: 0.9058493589743589 \n",
      "Epoch 15 | Step 5721 | loss: 0.23673211019250412 | accuracy: 0.9048655063291139 \n",
      "Epoch 15 | Step 5722 | loss: 0.2363530607894063 | accuracy: 0.9046875 \n",
      "Epoch 15 | Step 5723 | loss: 0.23569026092688242 | accuracy: 0.9048996913580247 \n",
      "Epoch 15 | Step 5724 | loss: 0.23468974959559558 | accuracy: 0.9056783536585366 \n",
      "Epoch 15 | Step 5725 | loss: 0.23459468063819838 | accuracy: 0.9060617469879518 \n",
      "Epoch 15 | Step 5726 | loss: 0.2341894090530418 | accuracy: 0.9064360119047619 \n",
      "Epoch 15 | Step 5727 | loss: 0.23364280812880572 | accuracy: 0.9066176470588235 \n",
      "Epoch 15 | Step 5728 | loss: 0.2329657734480015 | accuracy: 0.9067950581395349 \n",
      "Epoch 15 | Step 5729 | loss: 0.23514066465284633 | accuracy: 0.9060704022988506 \n",
      "Epoch 15 | Step 5730 | loss: 0.23533434403890913 | accuracy: 0.90625 \n",
      "Epoch 15 | Step 5731 | loss: 0.23418389126825867 | accuracy: 0.9069522471910112 \n",
      "Epoch 15 | Step 5732 | loss: 0.23518097317881054 | accuracy: 0.9064236111111111 \n",
      "Epoch 15 | Step 5733 | loss: 0.2340596732529965 | accuracy: 0.9067651098901099 \n",
      "Epoch 15 | Step 5734 | loss: 0.23322897145281668 | accuracy: 0.9072690217391305 \n",
      "Epoch 15 | Step 5735 | loss: 0.2330774176184849 | accuracy: 0.9069220430107527 \n",
      "Epoch 15 | Step 5736 | loss: 0.23235039191043122 | accuracy: 0.9074135638297872 \n",
      "Epoch 15 | Step 5737 | loss: 0.23255007172885694 | accuracy: 0.9074013157894737 \n",
      "Epoch 15 | Step 5738 | loss: 0.23406697530299425 | accuracy: 0.9073893229166666 \n",
      "Epoch 15 | Step 5739 | loss: 0.23413184577042295 | accuracy: 0.9073775773195877 \n",
      "Epoch 15 | Step 5740 | loss: 0.23498965480497905 | accuracy: 0.9072066326530612 \n",
      "Epoch 15 | Step 5741 | loss: 0.23512781358728504 | accuracy: 0.9071969696969697 \n",
      "Epoch 15 | Step 5742 | loss: 0.23430259317159652 | accuracy: 0.9075 \n",
      "Epoch 15 | Step 5743 | loss: 0.23295684232570157 | accuracy: 0.9082611386138614 \n",
      "Epoch 15 | Step 5744 | loss: 0.23302307973305383 | accuracy: 0.9082414215686274 \n",
      "Epoch 15 | Step 5745 | loss: 0.2321723388526046 | accuracy: 0.908373786407767 \n",
      "Epoch 15 | Step 5746 | loss: 0.23260438112685314 | accuracy: 0.9083533653846154 \n",
      "Epoch 15 | Step 5747 | loss: 0.2335691444930576 | accuracy: 0.9077380952380952 \n",
      "Epoch 15 | Step 5748 | loss: 0.23293692309339092 | accuracy: 0.9080188679245284 \n",
      "Epoch 15 | Step 5749 | loss: 0.23413674449809244 | accuracy: 0.9077102803738317 \n",
      "Epoch 15 | Step 5750 | loss: 0.23518085990239074 | accuracy: 0.9075520833333334 \n",
      "Epoch 15 | Step 5751 | loss: 0.23542165469138995 | accuracy: 0.9075401376146789 \n",
      "Epoch 15 | Step 5752 | loss: 0.23612203123894604 | accuracy: 0.9071022727272727 \n",
      "Epoch 15 | Step 5753 | loss: 0.23573118703322368 | accuracy: 0.9073761261261262 \n",
      "Epoch 15 | Step 5754 | loss: 0.23548998337771213 | accuracy: 0.9076450892857143 \n",
      "Epoch 15 | Step 5755 | loss: 0.23698330373890633 | accuracy: 0.9073561946902655 \n",
      "Epoch 15 | Step 5756 | loss: 0.23754271054477022 | accuracy: 0.9070723684210527 \n",
      "Epoch 15 | Step 5757 | loss: 0.23701481689577517 | accuracy: 0.9072010869565217 \n",
      "Epoch 15 | Step 5758 | loss: 0.23670305517213097 | accuracy: 0.9073275862068966 \n",
      "Epoch 15 | Step 5759 | loss: 0.23744054508005452 | accuracy: 0.907051282051282 \n",
      "Epoch 15 | Step 5760 | loss: 0.2377388689477565 | accuracy: 0.9065148305084746 \n",
      "Epoch 15 | Step 5761 | loss: 0.23800732383207113 | accuracy: 0.9065126050420168 \n",
      "Epoch 15 | Step 5762 | loss: 0.23765425719320774 | accuracy: 0.9065104166666667 \n",
      "Epoch 15 | Step 5763 | loss: 0.23768837749958038 | accuracy: 0.9068956611570248 \n",
      "Epoch 15 | Step 5764 | loss: 0.23788159071910578 | accuracy: 0.9065061475409836 \n",
      "Epoch 15 | Step 5765 | loss: 0.23800510180190326 | accuracy: 0.90625 \n",
      "Epoch 15 | Step 5766 | loss: 0.23815568957117297 | accuracy: 0.9065020161290323 \n",
      "Epoch 15 | Step 5767 | loss: 0.23808186721801758 | accuracy: 0.906375 \n",
      "Epoch 15 | Step 5768 | loss: 0.23794490773053395 | accuracy: 0.9063740079365079 \n",
      "Epoch 15 | Step 5769 | loss: 0.23832535919711345 | accuracy: 0.906126968503937 \n",
      "Epoch 15 | Step 5770 | loss: 0.23800275195389986 | accuracy: 0.9058837890625 \n",
      "Epoch 15 | Step 5771 | loss: 0.23801924161208693 | accuracy: 0.905765503875969 \n",
      "Epoch 15 | Step 5772 | loss: 0.23768899715863742 | accuracy: 0.9060096153846153 \n",
      "Epoch 15 | Step 5773 | loss: 0.23842679908257405 | accuracy: 0.9057729007633588 \n",
      "Epoch 15 | Step 5774 | loss: 0.23935606262900613 | accuracy: 0.9055397727272727 \n",
      "Epoch 15 | Step 5775 | loss: 0.24018527578590507 | accuracy: 0.9049577067669173 \n",
      "Epoch 15 | Step 5776 | loss: 0.2404065065419496 | accuracy: 0.9043843283582089 \n",
      "Epoch 15 | Step 5777 | loss: 0.2405893846794411 | accuracy: 0.9041666666666667 \n",
      "Epoch 15 | Step 5778 | loss: 0.2404022483045564 | accuracy: 0.904296875 \n",
      "Epoch 15 | Step 5779 | loss: 0.23992684124595057 | accuracy: 0.9043111313868614 \n",
      "Epoch 15 | Step 5780 | loss: 0.23989363111879514 | accuracy: 0.9040987318840581 \n",
      "Epoch 15 | Step 5781 | loss: 0.24042881167621064 | accuracy: 0.9037769784172663 \n",
      "Epoch 15 | Step 5782 | loss: 0.24049897396138736 | accuracy: 0.9040178571428573 \n",
      "Epoch 15 | Step 5783 | loss: 0.24178744112768918 | accuracy: 0.9034796099290782 \n",
      "Epoch 15 | Step 5784 | loss: 0.241924422412691 | accuracy: 0.9036091549295775 \n",
      "Epoch 15 | Step 5785 | loss: 0.24278242615136233 | accuracy: 0.902972027972028 \n",
      "Epoch 15 | Step 5786 | loss: 0.2428723479517632 | accuracy: 0.9027777777777778 \n",
      "Epoch 15 | Step 5787 | loss: 0.2429006161360905 | accuracy: 0.9026939655172413 \n",
      "Epoch 15 | Step 5788 | loss: 0.24326328341275044 | accuracy: 0.9023972602739726 \n",
      "Epoch 15 | Step 5789 | loss: 0.24242642253231841 | accuracy: 0.9027423469387755 \n",
      "Epoch 15 | Step 5790 | loss: 0.2426260584411589 | accuracy: 0.9024493243243243 \n",
      "Epoch 15 | Step 5791 | loss: 0.24229541605951002 | accuracy: 0.9024748322147651 \n",
      "Epoch 15 | Step 5792 | loss: 0.24278321648637455 | accuracy: 0.9023958333333333 \n",
      "Epoch 15 | Step 5793 | loss: 0.24290788395712706 | accuracy: 0.9022144039735099 \n",
      "Epoch 15 | Step 5794 | loss: 0.24397086553079517 | accuracy: 0.9018297697368421 \n",
      "Epoch 15 | Step 5795 | loss: 0.2444474872907782 | accuracy: 0.9016544117647058 \n",
      "Epoch 15 | Step 5796 | loss: 0.24395605423427247 | accuracy: 0.9018871753246753 \n",
      "Epoch 15 | Step 5797 | loss: 0.24370482953325395 | accuracy: 0.902016129032258 \n",
      "Epoch 15 | Step 5798 | loss: 0.24290549564055908 | accuracy: 0.9024439102564102 \n",
      "Epoch 15 | Step 5799 | loss: 0.24269128405744103 | accuracy: 0.9027667197452229 \n",
      "Epoch 15 | Step 5800 | loss: 0.24276386041052733 | accuracy: 0.9027887658227848 \n",
      "Epoch 15 | Step 5801 | loss: 0.2428076501537419 | accuracy: 0.9025157232704403 \n",
      "Epoch 15 | Step 5802 | loss: 0.24311302043497562 | accuracy: 0.9025390625 \n",
      "Epoch 15 | Step 5803 | loss: 0.24329902518610036 | accuracy: 0.9023680124223602 \n",
      "Epoch 15 | Step 5804 | loss: 0.24333432776692474 | accuracy: 0.9021990740740741 \n",
      "Epoch 15 | Step 5805 | loss: 0.24440080037146258 | accuracy: 0.901648773006135 \n",
      "Epoch 15 | Step 5806 | loss: 0.24438767035196468 | accuracy: 0.901391006097561 \n",
      "Epoch 15 | Step 5807 | loss: 0.24452147528980717 | accuracy: 0.9016098484848485 \n",
      "Epoch 15 | Step 5808 | loss: 0.24483865652098713 | accuracy: 0.9014495481927711 \n",
      "Epoch 15 | Step 5809 | loss: 0.24448079736289863 | accuracy: 0.9017589820359282 \n",
      "Epoch 15 | Step 5810 | loss: 0.2452409193806705 | accuracy: 0.9015997023809523 \n",
      "Epoch 15 | Step 5811 | loss: 0.24500683708303778 | accuracy: 0.901719674556213 \n",
      "Epoch 15 | Step 5812 | loss: 0.24435540998683256 | accuracy: 0.9021139705882353 \n",
      "Epoch 15 | Step 5813 | loss: 0.2442067198411763 | accuracy: 0.9024122807017544 \n",
      "Epoch 15 | Step 5814 | loss: 0.24442534677164499 | accuracy: 0.9025254360465116 \n",
      "Epoch 15 | Step 5815 | loss: 0.2441244622358697 | accuracy: 0.9026372832369942 \n",
      "Epoch 15 | Step 5816 | loss: 0.24419987484298902 | accuracy: 0.9028376436781609 \n",
      "Epoch 15 | Step 5817 | loss: 0.24398460694721766 | accuracy: 0.9029464285714286 \n",
      "Epoch 15 | Step 5818 | loss: 0.24466436644169418 | accuracy: 0.9026988636363636 \n",
      "Epoch 15 | Step 5819 | loss: 0.24542130925561076 | accuracy: 0.9024540960451978 \n",
      "Epoch 15 | Step 5820 | loss: 0.24592275264557828 | accuracy: 0.9019487359550562 \n",
      "Epoch 15 | Step 5821 | loss: 0.24636498210150437 | accuracy: 0.9016236033519553 \n",
      "Epoch 15 | Step 5822 | loss: 0.2462234569920434 | accuracy: 0.9015625 \n",
      "Epoch 15 | Step 5823 | loss: 0.24656650638053432 | accuracy: 0.9013294198895028 \n",
      "Epoch 15 | Step 5824 | loss: 0.24620633924400415 | accuracy: 0.9015281593406593 \n",
      "Epoch 15 | Step 5825 | loss: 0.24571993735318626 | accuracy: 0.9016393442622951 \n",
      "Epoch 15 | Step 5826 | loss: 0.2453198202116334 | accuracy: 0.9019191576086957 \n",
      "Epoch 15 | Step 5827 | loss: 0.24517166058759432 | accuracy: 0.902027027027027 \n",
      "Epoch 15 | Step 5828 | loss: 0.24543096149160015 | accuracy: 0.9018817204301075 \n",
      "Epoch 15 | Step 5829 | loss: 0.2458207096486168 | accuracy: 0.9014872994652406 \n",
      "Epoch 15 | Step 5830 | loss: 0.2459562507240062 | accuracy: 0.9012632978723404 \n",
      "Epoch 15 | Step 5831 | loss: 0.2457885843105417 | accuracy: 0.9013723544973545 \n",
      "Epoch 15 | Step 5832 | loss: 0.24670496943749878 | accuracy: 0.9011513157894737 \n",
      "Epoch 15 | Step 5833 | loss: 0.2461573841996218 | accuracy: 0.9014234293193717 \n",
      "Epoch 15 | Step 5834 | loss: 0.24583598924800754 | accuracy: 0.901611328125 \n",
      "Epoch 15 | Step 5835 | loss: 0.24548125645348445 | accuracy: 0.9018782383419689 \n",
      "Epoch 15 | Step 5836 | loss: 0.24523859970348397 | accuracy: 0.9019813144329897 \n",
      "Epoch 15 | Step 5837 | loss: 0.24490455014583393 | accuracy: 0.9020833333333333 \n",
      "Epoch 15 | Step 5838 | loss: 0.24501554173778514 | accuracy: 0.9021045918367347 \n",
      "Epoch 15 | Step 5839 | loss: 0.24506953562879322 | accuracy: 0.9020463197969543 \n",
      "Epoch 15 | Step 5840 | loss: 0.24518093730163093 | accuracy: 0.9019886363636364 \n",
      "Epoch 15 | Step 5841 | loss: 0.2447677469583013 | accuracy: 0.9024026381909548 \n",
      "Epoch 15 | Step 5842 | loss: 0.24440801434218884 | accuracy: 0.90265625 \n",
      "Epoch 15 | Step 5843 | loss: 0.24511451292690353 | accuracy: 0.902363184079602 \n",
      "Epoch 15 | Step 5844 | loss: 0.24519204540122855 | accuracy: 0.9023050742574258 \n",
      "Epoch 15 | Step 5845 | loss: 0.2451430067346601 | accuracy: 0.9023245073891626 \n",
      "Epoch 15 | Step 5846 | loss: 0.24498225127657255 | accuracy: 0.9024203431372549 \n",
      "Epoch 15 | Step 5847 | loss: 0.2450610968397885 | accuracy: 0.9022865853658537 \n",
      "Epoch 15 | Step 5848 | loss: 0.24593892888826074 | accuracy: 0.902002427184466 \n",
      "Epoch 15 | Step 5849 | loss: 0.2466847243660314 | accuracy: 0.901947463768116 \n",
      "Epoch 15 | Step 5850 | loss: 0.24669664725661278 | accuracy: 0.9018179086538461 \n",
      "Epoch 15 | Step 5851 | loss: 0.24658440802085912 | accuracy: 0.9017643540669856 \n",
      "Epoch 15 | Step 5852 | loss: 0.24670497306755612 | accuracy: 0.9018601190476191 \n",
      "Epoch 15 | Step 5853 | loss: 0.2470215259570081 | accuracy: 0.9017328199052133 \n",
      "Epoch 15 | Step 5854 | loss: 0.24647077552552493 | accuracy: 0.9020489386792453 \n",
      "Epoch 15 | Step 5855 | loss: 0.24613669906423685 | accuracy: 0.902068661971831 \n",
      "Epoch 15 | Step 5856 | loss: 0.2461533877894143 | accuracy: 0.9021612149532711 \n",
      "Epoch 15 | Step 5857 | loss: 0.24587147665578266 | accuracy: 0.9021075581395349 \n",
      "Epoch 15 | Step 5858 | loss: 0.24582084820226388 | accuracy: 0.9021267361111112 \n",
      "Epoch 15 | Step 5859 | loss: 0.2455601043278171 | accuracy: 0.9022177419354839 \n",
      "Epoch 15 | Step 5860 | loss: 0.24545105300638653 | accuracy: 0.9023079128440367 \n",
      "Epoch 15 | Step 5861 | loss: 0.24540314847203695 | accuracy: 0.9023259132420092 \n",
      "Epoch 15 | Step 5862 | loss: 0.24524408009919255 | accuracy: 0.9022727272727272 \n",
      "Epoch 15 | Step 5863 | loss: 0.24517030528497913 | accuracy: 0.9024321266968326 \n",
      "Epoch 15 | Step 5864 | loss: 0.24518264581759772 | accuracy: 0.9025197072072072 \n",
      "Epoch 15 | Step 5865 | loss: 0.2453053921728391 | accuracy: 0.9023262331838565 \n",
      "Epoch 15 | Step 5866 | loss: 0.24472390484463954 | accuracy: 0.9026925223214286 \n",
      "Epoch 15 | Step 5867 | loss: 0.24479099442561467 | accuracy: 0.9026388888888889 \n",
      "Epoch 15 | Step 5868 | loss: 0.24494359962048784 | accuracy: 0.9026548672566371 \n",
      "Epoch 15 | Step 5869 | loss: 0.24508836560181058 | accuracy: 0.9025330396475771 \n",
      "Epoch 15 | Step 5870 | loss: 0.24503625043782226 | accuracy: 0.9026864035087719 \n",
      "Epoch 15 | Step 5871 | loss: 0.24491471022888042 | accuracy: 0.9027701965065502 \n",
      "Epoch 15 | Step 5872 | loss: 0.2449689235052337 | accuracy: 0.9027853260869565 \n",
      "Epoch 15 | Step 5873 | loss: 0.24464362385598096 | accuracy: 0.9030032467532467 \n",
      "Epoch 15 | Step 5874 | loss: 0.24426585143624707 | accuracy: 0.9032192887931034 \n",
      "Epoch 15 | Step 5875 | loss: 0.244331733639404 | accuracy: 0.9030311158798283 \n",
      "Epoch 15 | Step 5876 | loss: 0.24442343939191255 | accuracy: 0.9031116452991453 \n",
      "Epoch 15 | Step 5877 | loss: 0.2442372201288 | accuracy: 0.9032579787234043 \n",
      "Epoch 15 | Step 5878 | loss: 0.24400027490899726 | accuracy: 0.9033368644067796 \n",
      "Epoch 15 | Step 5879 | loss: 0.2438395548659035 | accuracy: 0.9034150843881856 \n",
      "Epoch 15 | Step 5880 | loss: 0.24386097706791734 | accuracy: 0.9033613445378151 \n",
      "Epoch 15 | Step 5881 | loss: 0.24371290503061965 | accuracy: 0.9033734309623431 \n",
      "Epoch 15 | Step 5882 | loss: 0.24364550321673353 | accuracy: 0.9033203125 \n",
      "Epoch 15 | Step 5883 | loss: 0.24316343909353635 | accuracy: 0.9035269709543569 \n",
      "Epoch 15 | Step 5884 | loss: 0.24288082864782043 | accuracy: 0.9037319214876033 \n",
      "Epoch 15 | Step 5885 | loss: 0.24334928911531903 | accuracy: 0.9036136831275721 \n",
      "Epoch 15 | Step 5886 | loss: 0.24381075240671635 | accuracy: 0.9034323770491803 \n",
      "Epoch 15 | Step 5887 | loss: 0.2437895424816073 | accuracy: 0.9034438775510204 \n",
      "Epoch 15 | Step 5888 | loss: 0.243746635057335 | accuracy: 0.903391768292683 \n",
      "Epoch 15 | Step 5889 | loss: 0.2435249110404779 | accuracy: 0.9035931174089069 \n",
      "Epoch 15 | Step 5890 | loss: 0.24367757667336734 | accuracy: 0.9034148185483871 \n",
      "Epoch 15 | Step 5891 | loss: 0.24356343465516844 | accuracy: 0.9033634538152611 \n",
      "Epoch 15 | Step 5892 | loss: 0.24356696876883507 | accuracy: 0.9035 \n",
      "Epoch 15 | Step 5893 | loss: 0.2431711469335385 | accuracy: 0.9036977091633466 \n",
      "Epoch 15 | Step 5894 | loss: 0.2430179172624198 | accuracy: 0.9035838293650794 \n",
      "Epoch 15 | Step 5895 | loss: 0.24286233038888147 | accuracy: 0.9036561264822134 \n",
      "Epoch 15 | Step 5896 | loss: 0.24293713168952408 | accuracy: 0.9036663385826772 \n",
      "Epoch 15 | Step 5897 | loss: 0.24279039055109025 | accuracy: 0.9037377450980392 \n",
      "Epoch 15 | Step 5898 | loss: 0.24293684467556886 | accuracy: 0.903564453125 \n",
      "Epoch 15 | Step 5899 | loss: 0.2428606075709432 | accuracy: 0.9035141050583657 \n",
      "Epoch 15 | Step 5900 | loss: 0.2426687623699044 | accuracy: 0.9034035852713178 \n",
      "Epoch 15 | Step 5901 | loss: 0.24265530345867958 | accuracy: 0.9034145752895753 \n",
      "Epoch 15 | Step 5902 | loss: 0.24239829047941244 | accuracy: 0.9034254807692308 \n",
      "Epoch 15 | Step 5903 | loss: 0.24298680219727914 | accuracy: 0.9030172413793104 \n",
      "Epoch 15 | Step 5904 | loss: 0.24308868949763648 | accuracy: 0.9029699427480916 \n",
      "Epoch 15 | Step 5905 | loss: 0.24277828999231976 | accuracy: 0.9031012357414449 \n",
      "Epoch 15 | Step 5906 | loss: 0.24323808963438778 | accuracy: 0.9029356060606061 \n",
      "Epoch 15 | Step 5907 | loss: 0.24311672693715905 | accuracy: 0.9030070754716981 \n",
      "Epoch 15 | Step 5908 | loss: 0.24306548843370343 | accuracy: 0.9029605263157895 \n",
      "Epoch 15 | Step 5909 | loss: 0.24283430708593198 | accuracy: 0.9030898876404494 \n",
      "Epoch 15 | Step 5910 | loss: 0.24249176289052216 | accuracy: 0.9032182835820896 \n",
      "Epoch 15 | Step 5911 | loss: 0.24249255549176474 | accuracy: 0.9032876394052045 \n",
      "Epoch 15 | Step 5912 | loss: 0.2424176574581199 | accuracy: 0.9034143518518518 \n",
      "Epoch 15 | Step 5913 | loss: 0.24249220727444576 | accuracy: 0.903424815498155 \n",
      "Epoch 15 | Step 5914 | loss: 0.24242537263232997 | accuracy: 0.9033203125 \n",
      "Epoch 15 | Step 5915 | loss: 0.24248607399371955 | accuracy: 0.9031593406593407 \n",
      "Epoch 15 | Step 5916 | loss: 0.2424466456320599 | accuracy: 0.9031135948905109 \n",
      "Epoch 15 | Step 5917 | loss: 0.24243800886652686 | accuracy: 0.903125 \n",
      "Epoch 15 | Step 5918 | loss: 0.24269443801671697 | accuracy: 0.9029664855072463 \n",
      "Epoch 15 | Step 5919 | loss: 0.24269905086566396 | accuracy: 0.9029219314079422 \n",
      "Epoch 15 | Step 5920 | loss: 0.242422227566834 | accuracy: 0.9031025179856115 \n",
      "Epoch 15 | Step 5921 | loss: 0.24244671005181515 | accuracy: 0.9030577956989247 \n",
      "Epoch 15 | Step 5922 | loss: 0.24228806088545493 | accuracy: 0.9032924107142857 \n",
      "Epoch 15 | Step 5923 | loss: 0.2427881904927437 | accuracy: 0.9030249110320284 \n",
      "Epoch 15 | Step 5924 | loss: 0.24249794310394754 | accuracy: 0.9031471631205674 \n",
      "Epoch 15 | Step 5925 | loss: 0.2424224061963836 | accuracy: 0.9032133392226148 \n",
      "Epoch 15 | Step 5926 | loss: 0.24237521063588874 | accuracy: 0.9033340669014085 \n",
      "Epoch 15 | Step 5927 | loss: 0.2422247271004476 | accuracy: 0.9034539473684211 \n",
      "Epoch 15 | Step 5928 | loss: 0.24218819688979562 | accuracy: 0.9035183566433567 \n",
      "Epoch 15 | Step 5929 | loss: 0.24202916646564462 | accuracy: 0.9035823170731707 \n",
      "Epoch 15 | Step 5930 | loss: 0.24177716426654822 | accuracy: 0.9037543402777778 \n",
      "Epoch 15 | Step 5931 | loss: 0.2415988286731565 | accuracy: 0.9038170415224913 \n",
      "Epoch 15 | Step 5932 | loss: 0.24203565256862805 | accuracy: 0.9037176724137931 \n",
      "Epoch 15 | Step 5933 | loss: 0.24187029076298489 | accuracy: 0.9037263745704467 \n",
      "Epoch 15 | Step 5934 | loss: 0.24179623135658976 | accuracy: 0.9037885273972602 \n",
      "Epoch 15 | Step 5935 | loss: 0.24194140027916064 | accuracy: 0.903796928327645 \n",
      "Epoch 15 | Step 5936 | loss: 0.24159110030856262 | accuracy: 0.9039115646258503 \n",
      "Epoch 15 | Step 5937 | loss: 0.24194705145338835 | accuracy: 0.9036546610169491 \n",
      "Epoch 15 | Step 5938 | loss: 0.24186211988027836 | accuracy: 0.9036634290540541 \n",
      "Epoch 15 | Step 5939 | loss: 0.24213830201011716 | accuracy: 0.9034090909090909 \n",
      "Epoch 15 | Step 5940 | loss: 0.24207823766057923 | accuracy: 0.9033137583892618 \n",
      "Epoch 15 | Step 5941 | loss: 0.2419115670498797 | accuracy: 0.9033235785953178 \n",
      "Epoch 15 | Step 5942 | loss: 0.24177339943746726 | accuracy: 0.90328125 \n",
      "Epoch 15 | Step 5943 | loss: 0.2415343723770392 | accuracy: 0.9034468438538206 \n",
      "Epoch 15 | Step 5944 | loss: 0.24150333945818295 | accuracy: 0.9034561258278145 \n",
      "Epoch 15 | Step 5945 | loss: 0.2412080382405728 | accuracy: 0.9035684818481848 \n",
      "Epoch 15 | Step 5946 | loss: 0.2411432514996513 | accuracy: 0.9036287006578947 \n",
      "Epoch 15 | Step 5947 | loss: 0.2415023432159033 | accuracy: 0.9034323770491803 \n",
      "Epoch 15 | Step 5948 | loss: 0.24119303538616188 | accuracy: 0.9036458333333334 \n",
      "Epoch 15 | Step 5949 | loss: 0.24115141403500343 | accuracy: 0.9036543159609121 \n",
      "Epoch 15 | Step 5950 | loss: 0.2408847419133821 | accuracy: 0.9037642045454546 \n",
      "Epoch 15 | Step 5951 | loss: 0.2405305478516906 | accuracy: 0.9039239482200647 \n",
      "Epoch 15 | Step 5952 | loss: 0.24060135337133562 | accuracy: 0.9038810483870968 \n",
      "Epoch 15 | Step 5953 | loss: 0.24059805353067312 | accuracy: 0.9039389067524116 \n",
      "Epoch 15 | Step 5954 | loss: 0.24063373474069896 | accuracy: 0.9039463141025641 \n",
      "Epoch 15 | Step 5955 | loss: 0.24047791617461287 | accuracy: 0.9039536741214057 \n",
      "Epoch 15 | Step 5956 | loss: 0.2404835099579802 | accuracy: 0.9038614649681529 \n",
      "Epoch 15 | Step 5957 | loss: 0.24010114475848182 | accuracy: 0.9041170634920634 \n",
      "Epoch 15 | Step 5958 | loss: 0.24022771809485893 | accuracy: 0.9041238132911392 \n",
      "Epoch 15 | Step 5959 | loss: 0.24017791059867064 | accuracy: 0.9041305205047319 \n",
      "Epoch 15 | Step 5960 | loss: 0.24022727033252236 | accuracy: 0.9041863207547169 \n",
      "Epoch 15 | Step 5961 | loss: 0.24024172589696688 | accuracy: 0.9041438087774295 \n",
      "Epoch 15 | Step 5962 | loss: 0.24015964693389832 | accuracy: 0.904248046875 \n",
      "Epoch 15 | Step 5963 | loss: 0.24015843919318786 | accuracy: 0.9042542834890965 \n",
      "Epoch 15 | Step 5964 | loss: 0.23996760663778885 | accuracy: 0.9044060559006211 \n",
      "Epoch 15 | Step 5965 | loss: 0.23992935870269505 | accuracy: 0.9044117647058824 \n",
      "Epoch 15 | Step 5966 | loss: 0.2399690641021287 | accuracy: 0.9042245370370371 \n",
      "Epoch 15 | Step 5967 | loss: 0.2399259174328584 | accuracy: 0.9042307692307693 \n",
      "Epoch 15 | Step 5968 | loss: 0.23996899158128202 | accuracy: 0.9041411042944786 \n",
      "Epoch 15 | Step 5969 | loss: 0.24011328565782727 | accuracy: 0.9040997706422018 \n",
      "Epoch 15 | Step 5970 | loss: 0.24013993466590963 | accuracy: 0.9042016006097561 \n",
      "Epoch 15 | Step 5971 | loss: 0.23978165598263493 | accuracy: 0.9043503039513677 \n",
      "Epoch 15 | Step 5972 | loss: 0.23975885334340008 | accuracy: 0.9042613636363637 \n",
      "Epoch 15 | Step 5973 | loss: 0.23966332909924026 | accuracy: 0.9042673716012085 \n",
      "Epoch 15 | Step 5974 | loss: 0.23959867247795485 | accuracy: 0.9042262801204819 \n",
      "Epoch 15 | Step 5975 | loss: 0.23959893601255733 | accuracy: 0.9042323573573574 \n",
      "Epoch 15 | Step 5976 | loss: 0.23956136945300474 | accuracy: 0.9043319610778443 \n",
      "Epoch 15 | Step 5977 | loss: 0.23955086812154572 | accuracy: 0.9042910447761194 \n",
      "Epoch 15 | Step 5978 | loss: 0.23955083372337477 | accuracy: 0.9042038690476191 \n",
      "Epoch 15 | Step 5979 | loss: 0.2394695220520659 | accuracy: 0.9041172106824926 \n",
      "Epoch 15 | Step 5980 | loss: 0.2394213825023386 | accuracy: 0.9040310650887574 \n",
      "Epoch 15 | Step 5981 | loss: 0.23926871149061704 | accuracy: 0.9040837020648967 \n",
      "Epoch 15 | Step 5982 | loss: 0.23902430262635735 | accuracy: 0.9043198529411764 \n",
      "Epoch 15 | Step 5983 | loss: 0.23899852853716294 | accuracy: 0.9044171554252199 \n",
      "Epoch 15 | Step 5984 | loss: 0.23895810827700018 | accuracy: 0.904422514619883 \n",
      "Epoch 15 | Step 5985 | loss: 0.23871649375983647 | accuracy: 0.9046100583090378 \n",
      "Epoch 15 | Step 5986 | loss: 0.23876908867684907 | accuracy: 0.9044785610465116 \n",
      "Epoch 15 | Step 5987 | loss: 0.23868982424770577 | accuracy: 0.9044836956521739 \n",
      "Epoch 15 | Step 5988 | loss: 0.23852049064084974 | accuracy: 0.9046242774566474 \n",
      "Epoch 15 | Step 5989 | loss: 0.2384286149692123 | accuracy: 0.9047640489913544 \n",
      "Epoch 15 | Step 5990 | loss: 0.2382248747965385 | accuracy: 0.9047683189655172 \n",
      "Epoch 15 | Step 5991 | loss: 0.23816790327130893 | accuracy: 0.904817335243553 \n",
      "Epoch 15 | Step 5992 | loss: 0.23830874983753478 | accuracy: 0.9046875 \n",
      "Epoch 15 | Step 5993 | loss: 0.2380197841217715 | accuracy: 0.9048254985754985 \n",
      "Epoch 15 | Step 5994 | loss: 0.23788590771569448 | accuracy: 0.9047407670454546 \n",
      "Epoch 15 | Step 5995 | loss: 0.23799307066050196 | accuracy: 0.9046565155807366 \n",
      "Epoch 15 | Step 5996 | loss: 0.2381795050397431 | accuracy: 0.9046168785310734 \n",
      "Epoch 15 | Step 5997 | loss: 0.23804093548949334 | accuracy: 0.9046654929577465 \n",
      "Epoch 15 | Step 5998 | loss: 0.23784711567705938 | accuracy: 0.9047138342696629 \n",
      "Epoch 15 | Step 5999 | loss: 0.2380459854165379 | accuracy: 0.9046306022408963 \n",
      "Epoch 15 | Step 6000 | loss: 0.23829062012487284 | accuracy: 0.9045478351955307 \n",
      "Epoch 15 | Step 6001 | loss: 0.23817921988147214 | accuracy: 0.9046396239554317 \n",
      "Epoch 15 | Step 6002 | loss: 0.23819557800889016 | accuracy: 0.9046875 \n",
      "Epoch 15 | Step 6003 | loss: 0.2382002205399595 | accuracy: 0.9046485457063712 \n",
      "Epoch 15 | Step 6004 | loss: 0.23824015778401939 | accuracy: 0.9046529696132597 \n",
      "Epoch 15 | Step 6005 | loss: 0.238129604577033 | accuracy: 0.9047004132231405 \n",
      "Epoch 15 | Step 6006 | loss: 0.23770713345608213 | accuracy: 0.9049192994505495 \n",
      "Epoch 15 | Step 6007 | loss: 0.23747313167542627 | accuracy: 0.9050513698630137 \n",
      "Epoch 15 | Step 6008 | loss: 0.23767759286559345 | accuracy: 0.904969262295082 \n",
      "Epoch 15 | Step 6009 | loss: 0.237764894779599 | accuracy: 0.9048876021798365 \n",
      "Epoch 15 | Step 6010 | loss: 0.23770382143961993 | accuracy: 0.9050186820652174 \n",
      "Epoch 15 | Step 6011 | loss: 0.23795801726217838 | accuracy: 0.9049373306233063 \n",
      "Epoch 15 | Step 6012 | loss: 0.23794299321802886 | accuracy: 0.9048986486486487 \n",
      "Epoch 15 | Step 6013 | loss: 0.2381051425945084 | accuracy: 0.9048601752021563 \n",
      "Epoch 15 | Step 6014 | loss: 0.23798508070889982 | accuracy: 0.9048639112903226 \n",
      "Epoch 15 | Step 6015 | loss: 0.23766128211494425 | accuracy: 0.9050770777479893 \n",
      "Epoch 15 | Step 6016 | loss: 0.23745363986587778 | accuracy: 0.9051637700534759 \n",
      "Epoch 15 | Step 6017 | loss: 0.23757280361652375 | accuracy: 0.905125 \n",
      "Epoch 15 | Step 6018 | loss: 0.237453037793649 | accuracy: 0.9050864361702128 \n",
      "Epoch 15 | Step 6019 | loss: 0.2375188741427834 | accuracy: 0.9050066312997348 \n",
      "Epoch 15 | Step 6020 | loss: 0.23755858905574 | accuracy: 0.9049685846560847 \n",
      "Epoch 15 | Step 6021 | loss: 0.2373074891148897 | accuracy: 0.9051368733509235 \n",
      "Epoch 15 | Step 6022 | loss: 0.2372347245875158 | accuracy: 0.9051398026315789 \n",
      "Epoch 15 | Step 6023 | loss: 0.2369667111341096 | accuracy: 0.9052657480314961 \n",
      "Epoch 15 | Step 6024 | loss: 0.2370418784115951 | accuracy: 0.9053501308900523 \n",
      "Epoch 15 | Step 6025 | loss: 0.23707449572360234 | accuracy: 0.9053524804177546 \n",
      "Epoch 15 | Step 6026 | loss: 0.23737654466337213 | accuracy: 0.9053548177083334 \n",
      "Epoch 15 | Step 6027 | loss: 0.23725164586847478 | accuracy: 0.9054788961038961 \n",
      "Epoch 15 | Step 6028 | loss: 0.23710938766984743 | accuracy: 0.9055213730569949 \n",
      "Epoch 15 | Step 6029 | loss: 0.2372798054486282 | accuracy: 0.9054425064599483 \n",
      "Epoch 15 | Step 6030 | loss: 0.2374552339699465 | accuracy: 0.9054445876288659 \n",
      "Epoch 15 | Step 6031 | loss: 0.23732246251676262 | accuracy: 0.9054064910025706 \n",
      "Epoch 15 | Step 6032 | loss: 0.23726678662575207 | accuracy: 0.905488782051282 \n",
      "Epoch 15 | Step 6033 | loss: 0.23738225833381837 | accuracy: 0.9054907289002557 \n",
      "Epoch 15 | Step 6034 | loss: 0.2372522373892823 | accuracy: 0.9055325255102041 \n",
      "Epoch 15 | Step 6035 | loss: 0.23715537259445238 | accuracy: 0.9055741094147582 \n",
      "Epoch 15 | Step 6036 | loss: 0.2373238386312112 | accuracy: 0.905417195431472 \n",
      "Epoch 15 | Step 6037 | loss: 0.2371007866497281 | accuracy: 0.905498417721519 \n",
      "Epoch 15 | Step 6038 | loss: 0.23691235821355472 | accuracy: 0.9055792297979798 \n",
      "Epoch 15 | Step 6039 | loss: 0.2368804577090578 | accuracy: 0.9056596347607053 \n",
      "Epoch 15 | Step 6040 | loss: 0.23703624641326204 | accuracy: 0.9055826005025126 \n",
      "Epoch 15 | Step 6041 | loss: 0.23681493297704778 | accuracy: 0.9056234335839599 \n",
      "Epoch 15 | Step 6042 | loss: 0.2366962632909417 | accuracy: 0.905625 \n",
      "Epoch 15 | Step 6043 | loss: 0.23674801790952088 | accuracy: 0.9056265586034913 \n",
      "Epoch 15 | Step 6044 | loss: 0.2368950382319849 | accuracy: 0.9055115049751243 \n",
      "Epoch 15 | Step 6045 | loss: 0.23663962808051714 | accuracy: 0.9054892722785325 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.43038561940193176 | accuracy: 0.78125 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.38777491450309753 | accuracy: 0.828125 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4261167049407959 | accuracy: 0.828125 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4286733642220497 | accuracy: 0.828125 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4035823345184326 | accuracy: 0.834375 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.42999181151390076 | accuracy: 0.8255208333333334 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4245107429368155 | accuracy: 0.8348214285714286 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4173124060034752 | accuracy: 0.833984375 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.44383854998482597 | accuracy: 0.8246527777777778 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4299496799707413 | accuracy: 0.83125 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.43295190280134027 | accuracy: 0.8309659090909091 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4171641195813815 | accuracy: 0.8372395833333334 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4256158539882073 | accuracy: 0.8329326923076923 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.41585411557129454 | accuracy: 0.8325892857142857 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.42075250546137494 | accuracy: 0.8333333333333334 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4218565933406353 | accuracy: 0.8359375 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4264858505305122 | accuracy: 0.8327205882352942 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.42647285593880546 | accuracy: 0.8342013888888888 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4222283316285987 | accuracy: 0.837171052631579 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4175217181444168 | accuracy: 0.83515625 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.41186042059035527 | accuracy: 0.8363095238095238 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4073497937484221 | accuracy: 0.8380681818181818 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4134088715781336 | accuracy: 0.8369565217391305 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.43236533428231877 | accuracy: 0.8326822916666666 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.43849961161613465 | accuracy: 0.82875 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4361452001791734 | accuracy: 0.8299278846153846 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.42966972457038033 | accuracy: 0.8327546296296297 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4322712506566729 | accuracy: 0.8309151785714286 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.42904980326520986 | accuracy: 0.8318965517241379 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4245967676242193 | accuracy: 0.834375 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.41920364672137844 | accuracy: 0.8371975806451613 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4207342453300953 | accuracy: 0.83544921875 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4211712380250295 | accuracy: 0.8338068181818182 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.42506257488447075 | accuracy: 0.8313419117647058 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4280351187501635 | accuracy: 0.83125 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4262058486541112 | accuracy: 0.83203125 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.42711189550322454 | accuracy: 0.8327702702702703 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.42946765846327734 | accuracy: 0.8334703947368421 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.42827559740115434 | accuracy: 0.8333333333333334 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4249983839690685 | accuracy: 0.834765625 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4219380886089511 | accuracy: 0.834984756097561 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4180616452580407 | accuracy: 0.8359375 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4174524954585142 | accuracy: 0.8361191860465116 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.41958747600967233 | accuracy: 0.8345170454545454 \n",
      "Validation | Epoch 15 | Step 6045 | loss: 0.4191138565540314 | accuracy: 0.8333635263972812 \n",
      "Epoch 16 | Step 6046 | loss: 0.40167322754859924 | accuracy: 0.84375 \n",
      "Epoch 16 | Step 6047 | loss: 0.2796522453427315 | accuracy: 0.8984375 \n",
      "Epoch 16 | Step 6048 | loss: 0.25943007071812946 | accuracy: 0.90625 \n",
      "Epoch 16 | Step 6049 | loss: 0.270763136446476 | accuracy: 0.90234375 \n",
      "Epoch 16 | Step 6050 | loss: 0.24948303997516633 | accuracy: 0.909375 \n",
      "Epoch 16 | Step 6051 | loss: 0.23629523317019144 | accuracy: 0.9140625 \n",
      "Epoch 16 | Step 6052 | loss: 0.2434612512588501 | accuracy: 0.9107142857142857 \n",
      "Epoch 16 | Step 6053 | loss: 0.2363689597696066 | accuracy: 0.916015625 \n",
      "Epoch 16 | Step 6054 | loss: 0.2411751929256651 | accuracy: 0.9149305555555556 \n",
      "Epoch 16 | Step 6055 | loss: 0.2499002382159233 | accuracy: 0.9140625 \n",
      "Epoch 16 | Step 6056 | loss: 0.24242713370106436 | accuracy: 0.9176136363636364 \n",
      "Epoch 16 | Step 6057 | loss: 0.23483831559618315 | accuracy: 0.9192708333333334 \n",
      "Epoch 16 | Step 6058 | loss: 0.24498126942377824 | accuracy: 0.9110576923076923 \n",
      "Epoch 16 | Step 6059 | loss: 0.24080457112618855 | accuracy: 0.9140625 \n",
      "Epoch 16 | Step 6060 | loss: 0.24533486664295195 | accuracy: 0.9114583333333334 \n",
      "Epoch 16 | Step 6061 | loss: 0.23743391456082463 | accuracy: 0.916015625 \n",
      "Epoch 16 | Step 6062 | loss: 0.23926671331419663 | accuracy: 0.9108455882352942 \n",
      "Epoch 16 | Step 6063 | loss: 0.23648156680994564 | accuracy: 0.9123263888888888 \n",
      "Epoch 16 | Step 6064 | loss: 0.23523642554094917 | accuracy: 0.9111842105263158 \n",
      "Epoch 16 | Step 6065 | loss: 0.23779237307608128 | accuracy: 0.909375 \n",
      "Epoch 16 | Step 6066 | loss: 0.23718128495273136 | accuracy: 0.9092261904761905 \n",
      "Epoch 16 | Step 6067 | loss: 0.23911034146493132 | accuracy: 0.9098011363636364 \n",
      "Epoch 16 | Step 6068 | loss: 0.23613773901825366 | accuracy: 0.9103260869565217 \n",
      "Epoch 16 | Step 6069 | loss: 0.23631115226695934 | accuracy: 0.9095052083333334 \n",
      "Epoch 16 | Step 6070 | loss: 0.23918295115232469 | accuracy: 0.909375 \n",
      "Epoch 16 | Step 6071 | loss: 0.24126449313301307 | accuracy: 0.9080528846153846 \n",
      "Epoch 16 | Step 6072 | loss: 0.2458295355792399 | accuracy: 0.9068287037037037 \n",
      "Epoch 16 | Step 6073 | loss: 0.24266740759568556 | accuracy: 0.9079241071428571 \n",
      "Epoch 16 | Step 6074 | loss: 0.24536141419205174 | accuracy: 0.9073275862068966 \n",
      "Epoch 16 | Step 6075 | loss: 0.245237081994613 | accuracy: 0.9078125 \n",
      "Epoch 16 | Step 6076 | loss: 0.2430752196138905 | accuracy: 0.9067540322580645 \n",
      "Epoch 16 | Step 6077 | loss: 0.2429403371643275 | accuracy: 0.90625 \n",
      "Epoch 16 | Step 6078 | loss: 0.242353193461895 | accuracy: 0.9071969696969697 \n",
      "Epoch 16 | Step 6079 | loss: 0.2394254731343073 | accuracy: 0.9085477941176471 \n",
      "Epoch 16 | Step 6080 | loss: 0.23627691673380988 | accuracy: 0.9098214285714286 \n",
      "Epoch 16 | Step 6081 | loss: 0.2350858940432469 | accuracy: 0.9105902777777778 \n",
      "Epoch 16 | Step 6082 | loss: 0.23553307253766703 | accuracy: 0.9100506756756757 \n",
      "Epoch 16 | Step 6083 | loss: 0.23574935978180483 | accuracy: 0.9095394736842105 \n",
      "Epoch 16 | Step 6084 | loss: 0.23351427053029722 | accuracy: 0.9102564102564102 \n",
      "Epoch 16 | Step 6085 | loss: 0.2318819722160697 | accuracy: 0.910546875 \n",
      "Epoch 16 | Step 6086 | loss: 0.2310655613134547 | accuracy: 0.9108231707317073 \n",
      "Epoch 16 | Step 6087 | loss: 0.23140060458154904 | accuracy: 0.9099702380952381 \n",
      "Epoch 16 | Step 6088 | loss: 0.2297394485321156 | accuracy: 0.9102470930232558 \n",
      "Epoch 16 | Step 6089 | loss: 0.22863127375868234 | accuracy: 0.9112215909090909 \n",
      "Epoch 16 | Step 6090 | loss: 0.22954672988918093 | accuracy: 0.9118055555555555 \n",
      "Epoch 16 | Step 6091 | loss: 0.22999138822374138 | accuracy: 0.9116847826086957 \n",
      "Epoch 16 | Step 6092 | loss: 0.2298070101978931 | accuracy: 0.9115691489361702 \n",
      "Epoch 16 | Step 6093 | loss: 0.22990596123660603 | accuracy: 0.9117838541666666 \n",
      "Epoch 16 | Step 6094 | loss: 0.23197981608765467 | accuracy: 0.9107142857142857 \n",
      "Epoch 16 | Step 6095 | loss: 0.23282036557793617 | accuracy: 0.9103125 \n",
      "Epoch 16 | Step 6096 | loss: 0.23281757460505353 | accuracy: 0.9102328431372549 \n",
      "Epoch 16 | Step 6097 | loss: 0.23104675415043646 | accuracy: 0.9107572115384616 \n",
      "Epoch 16 | Step 6098 | loss: 0.23307252900218065 | accuracy: 0.9091981132075472 \n",
      "Epoch 16 | Step 6099 | loss: 0.23199135327228793 | accuracy: 0.9097222222222222 \n",
      "Epoch 16 | Step 6100 | loss: 0.23313443484631452 | accuracy: 0.9090909090909091 \n",
      "Epoch 16 | Step 6101 | loss: 0.23214103427848645 | accuracy: 0.9095982142857143 \n",
      "Epoch 16 | Step 6102 | loss: 0.23267230221576857 | accuracy: 0.9089912280701754 \n",
      "Epoch 16 | Step 6103 | loss: 0.2332095250744244 | accuracy: 0.908135775862069 \n",
      "Epoch 16 | Step 6104 | loss: 0.2346182327906964 | accuracy: 0.9078389830508474 \n",
      "Epoch 16 | Step 6105 | loss: 0.23484354031582674 | accuracy: 0.9080729166666667 \n",
      "Epoch 16 | Step 6106 | loss: 0.23424096564289 | accuracy: 0.9080430327868853 \n",
      "Epoch 16 | Step 6107 | loss: 0.2340403870949822 | accuracy: 0.9082661290322581 \n",
      "Epoch 16 | Step 6108 | loss: 0.23581450740023266 | accuracy: 0.9077380952380952 \n",
      "Epoch 16 | Step 6109 | loss: 0.23420415667351335 | accuracy: 0.90869140625 \n",
      "Epoch 16 | Step 6110 | loss: 0.23279862048534247 | accuracy: 0.9096153846153846 \n",
      "Epoch 16 | Step 6111 | loss: 0.23165544765916737 | accuracy: 0.9100378787878788 \n",
      "Epoch 16 | Step 6112 | loss: 0.23050656525501564 | accuracy: 0.9097481343283582 \n",
      "Epoch 16 | Step 6113 | loss: 0.2304865708026816 | accuracy: 0.9094669117647058 \n",
      "Epoch 16 | Step 6114 | loss: 0.2302612976535507 | accuracy: 0.9096467391304348 \n",
      "Epoch 16 | Step 6115 | loss: 0.2295475479747568 | accuracy: 0.9098214285714286 \n",
      "Epoch 16 | Step 6116 | loss: 0.22797116385379307 | accuracy: 0.9102112676056338 \n",
      "Epoch 16 | Step 6117 | loss: 0.2276003426975674 | accuracy: 0.9105902777777778 \n",
      "Epoch 16 | Step 6118 | loss: 0.22766335186076492 | accuracy: 0.9105308219178082 \n",
      "Epoch 16 | Step 6119 | loss: 0.2275606599208471 | accuracy: 0.910472972972973 \n",
      "Epoch 16 | Step 6120 | loss: 0.2266466917594274 | accuracy: 0.910625 \n",
      "Epoch 16 | Step 6121 | loss: 0.2267871920607592 | accuracy: 0.9109786184210527 \n",
      "Epoch 16 | Step 6122 | loss: 0.2261657002684358 | accuracy: 0.911323051948052 \n",
      "Epoch 16 | Step 6123 | loss: 0.22671182912129623 | accuracy: 0.9106570512820513 \n",
      "Epoch 16 | Step 6124 | loss: 0.2295625198491012 | accuracy: 0.9100079113924051 \n",
      "Epoch 16 | Step 6125 | loss: 0.22899999264627696 | accuracy: 0.9099609375 \n",
      "Epoch 16 | Step 6126 | loss: 0.22813675065099456 | accuracy: 0.9103009259259259 \n",
      "Epoch 16 | Step 6127 | loss: 0.2273217087111822 | accuracy: 0.9106326219512195 \n",
      "Epoch 16 | Step 6128 | loss: 0.22719570222389268 | accuracy: 0.9109563253012049 \n",
      "Epoch 16 | Step 6129 | loss: 0.2268120857576529 | accuracy: 0.9112723214285714 \n",
      "Epoch 16 | Step 6130 | loss: 0.22611972426666932 | accuracy: 0.9115808823529412 \n",
      "Epoch 16 | Step 6131 | loss: 0.22556540473949077 | accuracy: 0.9113372093023255 \n",
      "Epoch 16 | Step 6132 | loss: 0.22793135081214466 | accuracy: 0.9102011494252874 \n",
      "Epoch 16 | Step 6133 | loss: 0.22844466973434796 | accuracy: 0.91015625 \n",
      "Epoch 16 | Step 6134 | loss: 0.22750957745514558 | accuracy: 0.9106390449438202 \n",
      "Epoch 16 | Step 6135 | loss: 0.22824458397097058 | accuracy: 0.9104166666666667 \n",
      "Epoch 16 | Step 6136 | loss: 0.2272485478238745 | accuracy: 0.9107142857142857 \n",
      "Epoch 16 | Step 6137 | loss: 0.22652754381946896 | accuracy: 0.9111752717391305 \n",
      "Epoch 16 | Step 6138 | loss: 0.22637933620842554 | accuracy: 0.9109543010752689 \n",
      "Epoch 16 | Step 6139 | loss: 0.2253666788022569 | accuracy: 0.9114029255319149 \n",
      "Epoch 16 | Step 6140 | loss: 0.2260194874123523 | accuracy: 0.9108552631578948 \n",
      "Epoch 16 | Step 6141 | loss: 0.22762164302791157 | accuracy: 0.91064453125 \n",
      "Epoch 16 | Step 6142 | loss: 0.22785715635904333 | accuracy: 0.9102770618556701 \n",
      "Epoch 16 | Step 6143 | loss: 0.22889846365670768 | accuracy: 0.9099170918367347 \n",
      "Epoch 16 | Step 6144 | loss: 0.22917856456655444 | accuracy: 0.9098800505050505 \n",
      "Epoch 16 | Step 6145 | loss: 0.22819872349500656 | accuracy: 0.9103125 \n",
      "Epoch 16 | Step 6146 | loss: 0.22696126399949046 | accuracy: 0.9110457920792079 \n",
      "Epoch 16 | Step 6147 | loss: 0.22676382863930628 | accuracy: 0.9111519607843137 \n",
      "Epoch 16 | Step 6148 | loss: 0.22580915653300518 | accuracy: 0.9115594660194175 \n",
      "Epoch 16 | Step 6149 | loss: 0.22660406241909817 | accuracy: 0.9113581730769231 \n",
      "Epoch 16 | Step 6150 | loss: 0.22751564858924775 | accuracy: 0.9107142857142857 \n",
      "Epoch 16 | Step 6151 | loss: 0.22695861285868682 | accuracy: 0.9109669811320755 \n",
      "Epoch 16 | Step 6152 | loss: 0.2281189781622352 | accuracy: 0.9104848130841121 \n",
      "Epoch 16 | Step 6153 | loss: 0.22906764520815126 | accuracy: 0.9104456018518519 \n",
      "Epoch 16 | Step 6154 | loss: 0.22943919111009037 | accuracy: 0.9105504587155964 \n",
      "Epoch 16 | Step 6155 | loss: 0.23021851540966468 | accuracy: 0.9100852272727272 \n",
      "Epoch 16 | Step 6156 | loss: 0.22985780635127076 | accuracy: 0.9100506756756757 \n",
      "Epoch 16 | Step 6157 | loss: 0.2295373492608113 | accuracy: 0.91015625 \n",
      "Epoch 16 | Step 6158 | loss: 0.23078844036939924 | accuracy: 0.9098451327433629 \n",
      "Epoch 16 | Step 6159 | loss: 0.23124728136156736 | accuracy: 0.9098135964912281 \n",
      "Epoch 16 | Step 6160 | loss: 0.23094651783290115 | accuracy: 0.9099184782608696 \n",
      "Epoch 16 | Step 6161 | loss: 0.23109098761503039 | accuracy: 0.9094827586206896 \n",
      "Epoch 16 | Step 6162 | loss: 0.231949690124418 | accuracy: 0.9090544871794872 \n",
      "Epoch 16 | Step 6163 | loss: 0.23203255343487708 | accuracy: 0.909030720338983 \n",
      "Epoch 16 | Step 6164 | loss: 0.23225607572733856 | accuracy: 0.9091386554621849 \n",
      "Epoch 16 | Step 6165 | loss: 0.23187510389834642 | accuracy: 0.9092447916666667 \n",
      "Epoch 16 | Step 6166 | loss: 0.23144354351049612 | accuracy: 0.909478305785124 \n",
      "Epoch 16 | Step 6167 | loss: 0.23111188869740143 | accuracy: 0.9094518442622951 \n",
      "Epoch 16 | Step 6168 | loss: 0.23117932913506903 | accuracy: 0.9094258130081301 \n",
      "Epoch 16 | Step 6169 | loss: 0.23121212356753887 | accuracy: 0.9096522177419355 \n",
      "Epoch 16 | Step 6170 | loss: 0.23113233357667923 | accuracy: 0.909375 \n",
      "Epoch 16 | Step 6171 | loss: 0.23136472045665696 | accuracy: 0.9093501984126984 \n",
      "Epoch 16 | Step 6172 | loss: 0.23179136586236201 | accuracy: 0.9092027559055118 \n",
      "Epoch 16 | Step 6173 | loss: 0.23123666498577222 | accuracy: 0.9091796875 \n",
      "Epoch 16 | Step 6174 | loss: 0.23104754662097887 | accuracy: 0.909156976744186 \n",
      "Epoch 16 | Step 6175 | loss: 0.2307160093807257 | accuracy: 0.909375 \n",
      "Epoch 16 | Step 6176 | loss: 0.23132883984851474 | accuracy: 0.9091125954198473 \n",
      "Epoch 16 | Step 6177 | loss: 0.23187843964181162 | accuracy: 0.9090909090909091 \n",
      "Epoch 16 | Step 6178 | loss: 0.23262160260202294 | accuracy: 0.9088345864661654 \n",
      "Epoch 16 | Step 6179 | loss: 0.23291767894554494 | accuracy: 0.9081156716417911 \n",
      "Epoch 16 | Step 6180 | loss: 0.23316808149770454 | accuracy: 0.9076388888888889 \n",
      "Epoch 16 | Step 6181 | loss: 0.23276711140266237 | accuracy: 0.9077435661764706 \n",
      "Epoch 16 | Step 6182 | loss: 0.2323353642421047 | accuracy: 0.9079607664233577 \n",
      "Epoch 16 | Step 6183 | loss: 0.2321670770753121 | accuracy: 0.9080615942028986 \n",
      "Epoch 16 | Step 6184 | loss: 0.23246107604220617 | accuracy: 0.9078237410071942 \n",
      "Epoch 16 | Step 6185 | loss: 0.2323444575603519 | accuracy: 0.9078125 \n",
      "Epoch 16 | Step 6186 | loss: 0.23377116885802424 | accuracy: 0.9073581560283688 \n",
      "Epoch 16 | Step 6187 | loss: 0.23391034784661213 | accuracy: 0.9074603873239436 \n",
      "Epoch 16 | Step 6188 | loss: 0.23429422783893306 | accuracy: 0.9071241258741258 \n",
      "Epoch 16 | Step 6189 | loss: 0.23421307792887092 | accuracy: 0.9071180555555556 \n",
      "Epoch 16 | Step 6190 | loss: 0.23406682903396672 | accuracy: 0.9072198275862069 \n",
      "Epoch 16 | Step 6191 | loss: 0.23434669784691237 | accuracy: 0.9072131849315068 \n",
      "Epoch 16 | Step 6192 | loss: 0.23359832456525492 | accuracy: 0.9076318027210885 \n",
      "Epoch 16 | Step 6193 | loss: 0.23361312643297621 | accuracy: 0.9077280405405406 \n",
      "Epoch 16 | Step 6194 | loss: 0.2332506365324027 | accuracy: 0.9078229865771812 \n",
      "Epoch 16 | Step 6195 | loss: 0.23347891762852668 | accuracy: 0.9079166666666667 \n",
      "Epoch 16 | Step 6196 | loss: 0.23389552459614166 | accuracy: 0.9078021523178808 \n",
      "Epoch 16 | Step 6197 | loss: 0.2352824177298891 | accuracy: 0.9072779605263158 \n",
      "Epoch 16 | Step 6198 | loss: 0.23589536796013513 | accuracy: 0.9070669934640523 \n",
      "Epoch 16 | Step 6199 | loss: 0.23546007367504107 | accuracy: 0.9074675324675324 \n",
      "Epoch 16 | Step 6200 | loss: 0.2351010010607781 | accuracy: 0.9078629032258064 \n",
      "Epoch 16 | Step 6201 | loss: 0.234313238841983 | accuracy: 0.9082532051282052 \n",
      "Epoch 16 | Step 6202 | loss: 0.23404165328877746 | accuracy: 0.9083399681528662 \n",
      "Epoch 16 | Step 6203 | loss: 0.23415716148064106 | accuracy: 0.9081289556962026 \n",
      "Epoch 16 | Step 6204 | loss: 0.2342026725223979 | accuracy: 0.9078223270440252 \n",
      "Epoch 16 | Step 6205 | loss: 0.23470016294158996 | accuracy: 0.907421875 \n",
      "Epoch 16 | Step 6206 | loss: 0.2350277384708387 | accuracy: 0.907123447204969 \n",
      "Epoch 16 | Step 6207 | loss: 0.23500972963225694 | accuracy: 0.9071180555555556 \n",
      "Epoch 16 | Step 6208 | loss: 0.2359758768619204 | accuracy: 0.9068251533742331 \n",
      "Epoch 16 | Step 6209 | loss: 0.23591491021215916 | accuracy: 0.9067263719512195 \n",
      "Epoch 16 | Step 6210 | loss: 0.2357850698359085 | accuracy: 0.9067234848484849 \n",
      "Epoch 16 | Step 6211 | loss: 0.23600655152316552 | accuracy: 0.9066265060240963 \n",
      "Epoch 16 | Step 6212 | loss: 0.23557521166380294 | accuracy: 0.906811377245509 \n",
      "Epoch 16 | Step 6213 | loss: 0.23628077128281197 | accuracy: 0.9067150297619048 \n",
      "Epoch 16 | Step 6214 | loss: 0.23599417820661026 | accuracy: 0.9067122781065089 \n",
      "Epoch 16 | Step 6215 | loss: 0.23528612681171474 | accuracy: 0.9069852941176471 \n",
      "Epoch 16 | Step 6216 | loss: 0.23515363529934522 | accuracy: 0.9069809941520468 \n",
      "Epoch 16 | Step 6217 | loss: 0.23531361578335597 | accuracy: 0.9069767441860465 \n",
      "Epoch 16 | Step 6218 | loss: 0.23480854355703198 | accuracy: 0.9070628612716763 \n",
      "Epoch 16 | Step 6219 | loss: 0.2348999254748054 | accuracy: 0.9071479885057471 \n",
      "Epoch 16 | Step 6220 | loss: 0.2346695529988834 | accuracy: 0.9073214285714286 \n",
      "Epoch 16 | Step 6221 | loss: 0.2353191898543049 | accuracy: 0.9071377840909091 \n",
      "Epoch 16 | Step 6222 | loss: 0.23586701450206465 | accuracy: 0.9068679378531074 \n",
      "Epoch 16 | Step 6223 | loss: 0.2364718744510345 | accuracy: 0.9066011235955056 \n",
      "Epoch 16 | Step 6224 | loss: 0.23686218557244573 | accuracy: 0.9061627094972067 \n",
      "Epoch 16 | Step 6225 | loss: 0.2366247757855389 | accuracy: 0.90625 \n",
      "Epoch 16 | Step 6226 | loss: 0.23667261255544852 | accuracy: 0.9060773480662984 \n",
      "Epoch 16 | Step 6227 | loss: 0.23649012890982105 | accuracy: 0.9061641483516484 \n",
      "Epoch 16 | Step 6228 | loss: 0.2359707346949421 | accuracy: 0.9063353825136612 \n",
      "Epoch 16 | Step 6229 | loss: 0.2354135009986551 | accuracy: 0.9065896739130435 \n",
      "Epoch 16 | Step 6230 | loss: 0.23519549349675306 | accuracy: 0.9067567567567567 \n",
      "Epoch 16 | Step 6231 | loss: 0.2356343669516425 | accuracy: 0.9066700268817204 \n",
      "Epoch 16 | Step 6232 | loss: 0.23593469669315267 | accuracy: 0.9065842245989305 \n",
      "Epoch 16 | Step 6233 | loss: 0.23599744481133653 | accuracy: 0.9065824468085106 \n",
      "Epoch 16 | Step 6234 | loss: 0.23570915926543493 | accuracy: 0.9066633597883598 \n",
      "Epoch 16 | Step 6235 | loss: 0.23622427751359187 | accuracy: 0.9064144736842106 \n",
      "Epoch 16 | Step 6236 | loss: 0.23568414608065372 | accuracy: 0.90657722513089 \n",
      "Epoch 16 | Step 6237 | loss: 0.23542365552081415 | accuracy: 0.90673828125 \n",
      "Epoch 16 | Step 6238 | loss: 0.2351165886756052 | accuracy: 0.9069786269430051 \n",
      "Epoch 16 | Step 6239 | loss: 0.2350416084002588 | accuracy: 0.9069748711340206 \n",
      "Epoch 16 | Step 6240 | loss: 0.2348096625545086 | accuracy: 0.907051282051282 \n",
      "Epoch 16 | Step 6241 | loss: 0.23487060193960763 | accuracy: 0.9070471938775511 \n",
      "Epoch 16 | Step 6242 | loss: 0.2348788488410451 | accuracy: 0.9070431472081218 \n",
      "Epoch 16 | Step 6243 | loss: 0.23498963109321064 | accuracy: 0.9070391414141414 \n",
      "Epoch 16 | Step 6244 | loss: 0.23477431281876923 | accuracy: 0.9073492462311558 \n",
      "Epoch 16 | Step 6245 | loss: 0.23459330249577762 | accuracy: 0.907421875 \n",
      "Epoch 16 | Step 6246 | loss: 0.23507424747914224 | accuracy: 0.9071828358208955 \n",
      "Epoch 16 | Step 6247 | loss: 0.2350923527069021 | accuracy: 0.9073329207920792 \n",
      "Epoch 16 | Step 6248 | loss: 0.23509972263586346 | accuracy: 0.9074045566502463 \n",
      "Epoch 16 | Step 6249 | loss: 0.2348858013237808 | accuracy: 0.9074754901960784 \n",
      "Epoch 16 | Step 6250 | loss: 0.23513476910387598 | accuracy: 0.9070884146341464 \n",
      "Epoch 16 | Step 6251 | loss: 0.23575611777820635 | accuracy: 0.9068567961165048 \n",
      "Epoch 16 | Step 6252 | loss: 0.23661999559200905 | accuracy: 0.9068538647342995 \n",
      "Epoch 16 | Step 6253 | loss: 0.236492933311428 | accuracy: 0.9069260817307693 \n",
      "Epoch 16 | Step 6254 | loss: 0.23633662019477505 | accuracy: 0.9069976076555024 \n",
      "Epoch 16 | Step 6255 | loss: 0.23638711475900243 | accuracy: 0.9069940476190477 \n",
      "Epoch 16 | Step 6256 | loss: 0.23660704539426694 | accuracy: 0.9066943127962085 \n",
      "Epoch 16 | Step 6257 | loss: 0.2360724351316128 | accuracy: 0.9070607311320755 \n",
      "Epoch 16 | Step 6258 | loss: 0.2356968771823695 | accuracy: 0.9072036384976526 \n",
      "Epoch 16 | Step 6259 | loss: 0.23580183611016406 | accuracy: 0.9072721962616822 \n",
      "Epoch 16 | Step 6260 | loss: 0.23553857013236645 | accuracy: 0.9073401162790697 \n",
      "Epoch 16 | Step 6261 | loss: 0.23549179015336213 | accuracy: 0.9073350694444444 \n",
      "Epoch 16 | Step 6262 | loss: 0.23507947471284646 | accuracy: 0.9076180875576036 \n",
      "Epoch 16 | Step 6263 | loss: 0.2351295228945006 | accuracy: 0.9075401376146789 \n",
      "Epoch 16 | Step 6264 | loss: 0.23499410983906488 | accuracy: 0.9075342465753424 \n",
      "Epoch 16 | Step 6265 | loss: 0.2348994253711267 | accuracy: 0.9075994318181818 \n",
      "Epoch 16 | Step 6266 | loss: 0.23485472414018882 | accuracy: 0.9077347285067874 \n",
      "Epoch 16 | Step 6267 | loss: 0.2347950965568826 | accuracy: 0.9077984234234234 \n",
      "Epoch 16 | Step 6268 | loss: 0.23481715146468893 | accuracy: 0.9077214125560538 \n",
      "Epoch 16 | Step 6269 | loss: 0.23427160496690444 | accuracy: 0.9081333705357143 \n",
      "Epoch 16 | Step 6270 | loss: 0.23442478815714518 | accuracy: 0.9080555555555555 \n",
      "Epoch 16 | Step 6271 | loss: 0.23457940740395436 | accuracy: 0.9079784292035398 \n",
      "Epoch 16 | Step 6272 | loss: 0.2346288710176157 | accuracy: 0.9079708149779736 \n",
      "Epoch 16 | Step 6273 | loss: 0.23471064747948395 | accuracy: 0.9081688596491229 \n",
      "Epoch 16 | Step 6274 | loss: 0.2346092042183772 | accuracy: 0.908228711790393 \n",
      "Epoch 16 | Step 6275 | loss: 0.2345947794292284 | accuracy: 0.9083559782608696 \n",
      "Epoch 16 | Step 6276 | loss: 0.23447173556466122 | accuracy: 0.9084821428571429 \n",
      "Epoch 16 | Step 6277 | loss: 0.23408085024305458 | accuracy: 0.9087419181034483 \n",
      "Epoch 16 | Step 6278 | loss: 0.23415943385449603 | accuracy: 0.9084629828326181 \n",
      "Epoch 16 | Step 6279 | loss: 0.23423073237013614 | accuracy: 0.9085202991452992 \n",
      "Epoch 16 | Step 6280 | loss: 0.23404117467555594 | accuracy: 0.9085771276595744 \n",
      "Epoch 16 | Step 6281 | loss: 0.2337569792013047 | accuracy: 0.9087658898305084 \n",
      "Epoch 16 | Step 6282 | loss: 0.2336003460964573 | accuracy: 0.9088212025316456 \n",
      "Epoch 16 | Step 6283 | loss: 0.2337474136793313 | accuracy: 0.9087447478991597 \n",
      "Epoch 16 | Step 6284 | loss: 0.23369232717917054 | accuracy: 0.9087996861924686 \n",
      "Epoch 16 | Step 6285 | loss: 0.23366492198159297 | accuracy: 0.9087239583333333 \n",
      "Epoch 16 | Step 6286 | loss: 0.2331321019973003 | accuracy: 0.9089730290456431 \n",
      "Epoch 16 | Step 6287 | loss: 0.23277051863837833 | accuracy: 0.9091554752066116 \n",
      "Epoch 16 | Step 6288 | loss: 0.23319446310830214 | accuracy: 0.9090792181069959 \n",
      "Epoch 16 | Step 6289 | loss: 0.23365121695106147 | accuracy: 0.9090035860655737 \n",
      "Epoch 16 | Step 6290 | loss: 0.23347300345800362 | accuracy: 0.9090561224489796 \n",
      "Epoch 16 | Step 6291 | loss: 0.23347034462826038 | accuracy: 0.909108231707317 \n",
      "Epoch 16 | Step 6292 | loss: 0.23324832066833248 | accuracy: 0.9092864372469636 \n",
      "Epoch 16 | Step 6293 | loss: 0.23349692083654866 | accuracy: 0.909148185483871 \n",
      "Epoch 16 | Step 6294 | loss: 0.23324014150713343 | accuracy: 0.9091365461847389 \n",
      "Epoch 16 | Step 6295 | loss: 0.23316161012649536 | accuracy: 0.9091875 \n",
      "Epoch 16 | Step 6296 | loss: 0.2328349886781191 | accuracy: 0.9094248007968128 \n",
      "Epoch 16 | Step 6297 | loss: 0.23282970180587162 | accuracy: 0.9092881944444444 \n",
      "Epoch 16 | Step 6298 | loss: 0.23265110474565756 | accuracy: 0.909276185770751 \n",
      "Epoch 16 | Step 6299 | loss: 0.23260803203883135 | accuracy: 0.9092642716535433 \n",
      "Epoch 16 | Step 6300 | loss: 0.2326004539634667 | accuracy: 0.9093137254901961 \n",
      "Epoch 16 | Step 6301 | loss: 0.23263763613067567 | accuracy: 0.90936279296875 \n",
      "Epoch 16 | Step 6302 | loss: 0.23244697644088982 | accuracy: 0.9094722762645915 \n",
      "Epoch 16 | Step 6303 | loss: 0.23216014701959697 | accuracy: 0.9093992248062015 \n",
      "Epoch 16 | Step 6304 | loss: 0.232277109988868 | accuracy: 0.9092664092664092 \n",
      "Epoch 16 | Step 6305 | loss: 0.2319974993283932 | accuracy: 0.909375 \n",
      "Epoch 16 | Step 6306 | loss: 0.23245733439693964 | accuracy: 0.9090636973180076 \n",
      "Epoch 16 | Step 6307 | loss: 0.2325700535119035 | accuracy: 0.9088740458015268 \n",
      "Epoch 16 | Step 6308 | loss: 0.23228153416412411 | accuracy: 0.9088640684410646 \n",
      "Epoch 16 | Step 6309 | loss: 0.23261698166077788 | accuracy: 0.9087357954545454 \n",
      "Epoch 16 | Step 6310 | loss: 0.232521823217284 | accuracy: 0.9087264150943396 \n",
      "Epoch 16 | Step 6311 | loss: 0.23235318384000234 | accuracy: 0.9087758458646616 \n",
      "Epoch 16 | Step 6312 | loss: 0.2320641636401973 | accuracy: 0.909000468164794 \n",
      "Epoch 16 | Step 6313 | loss: 0.23183415996939388 | accuracy: 0.9091068097014925 \n",
      "Epoch 16 | Step 6314 | loss: 0.23177539842501005 | accuracy: 0.9092123605947955 \n",
      "Epoch 16 | Step 6315 | loss: 0.23156095290625536 | accuracy: 0.9093171296296296 \n",
      "Epoch 16 | Step 6316 | loss: 0.23156078478726955 | accuracy: 0.9092481549815498 \n",
      "Epoch 16 | Step 6317 | loss: 0.23136233368559794 | accuracy: 0.9092371323529411 \n",
      "Epoch 16 | Step 6318 | loss: 0.23153579950114309 | accuracy: 0.9089972527472527 \n",
      "Epoch 16 | Step 6319 | loss: 0.23145947496603875 | accuracy: 0.9090442518248175 \n",
      "Epoch 16 | Step 6320 | loss: 0.2313934371688149 | accuracy: 0.9090909090909091 \n",
      "Epoch 16 | Step 6321 | loss: 0.23162488822919736 | accuracy: 0.9088541666666666 \n",
      "Epoch 16 | Step 6322 | loss: 0.23153032432394338 | accuracy: 0.9088447653429603 \n",
      "Epoch 16 | Step 6323 | loss: 0.23137296409272462 | accuracy: 0.90900404676259 \n",
      "Epoch 16 | Step 6324 | loss: 0.23138917095985892 | accuracy: 0.9088821684587813 \n",
      "Epoch 16 | Step 6325 | loss: 0.2312277707138232 | accuracy: 0.9090959821428571 \n",
      "Epoch 16 | Step 6326 | loss: 0.23163189460586397 | accuracy: 0.9089746441281139 \n",
      "Epoch 16 | Step 6327 | loss: 0.2314845325147852 | accuracy: 0.909020390070922 \n",
      "Epoch 16 | Step 6328 | loss: 0.2314856573676052 | accuracy: 0.9091210247349824 \n",
      "Epoch 16 | Step 6329 | loss: 0.23130048307734477 | accuracy: 0.9092759683098591 \n",
      "Epoch 16 | Step 6330 | loss: 0.23116628956376462 | accuracy: 0.9094298245614035 \n",
      "Epoch 16 | Step 6331 | loss: 0.23133250758364485 | accuracy: 0.9093094405594405 \n",
      "Epoch 16 | Step 6332 | loss: 0.2312434388889253 | accuracy: 0.9092443379790941 \n",
      "Epoch 16 | Step 6333 | loss: 0.230921789796816 | accuracy: 0.9093424479166666 \n",
      "Epoch 16 | Step 6334 | loss: 0.2306656534799655 | accuracy: 0.9094398788927336 \n",
      "Epoch 16 | Step 6335 | loss: 0.23106485589824874 | accuracy: 0.909375 \n",
      "Epoch 16 | Step 6336 | loss: 0.2309368433514002 | accuracy: 0.9094179553264605 \n",
      "Epoch 16 | Step 6337 | loss: 0.23081074859181497 | accuracy: 0.9094606164383562 \n",
      "Epoch 16 | Step 6338 | loss: 0.23081605655137996 | accuracy: 0.909556313993174 \n",
      "Epoch 16 | Step 6339 | loss: 0.23040751844239074 | accuracy: 0.9097045068027211 \n",
      "Epoch 16 | Step 6340 | loss: 0.23077606523441055 | accuracy: 0.9095338983050848 \n",
      "Epoch 16 | Step 6341 | loss: 0.23072092456592097 | accuracy: 0.9096283783783784 \n",
      "Epoch 16 | Step 6342 | loss: 0.23093845677696895 | accuracy: 0.9094065656565656 \n",
      "Epoch 16 | Step 6343 | loss: 0.2308465750925493 | accuracy: 0.9093435402684564 \n",
      "Epoch 16 | Step 6344 | loss: 0.23069951207342754 | accuracy: 0.9093854515050167 \n",
      "Epoch 16 | Step 6345 | loss: 0.23052196472883224 | accuracy: 0.90953125 \n",
      "Epoch 16 | Step 6346 | loss: 0.23035471606690225 | accuracy: 0.909624169435216 \n",
      "Epoch 16 | Step 6347 | loss: 0.23026198242476445 | accuracy: 0.9095612582781457 \n",
      "Epoch 16 | Step 6348 | loss: 0.23000812456749453 | accuracy: 0.909601897689769 \n",
      "Epoch 16 | Step 6349 | loss: 0.23002094187234579 | accuracy: 0.9095908717105263 \n",
      "Epoch 16 | Step 6350 | loss: 0.23035379433241046 | accuracy: 0.909375 \n",
      "Epoch 16 | Step 6351 | loss: 0.2301315009301784 | accuracy: 0.9095690359477124 \n",
      "Epoch 16 | Step 6352 | loss: 0.23000560259197744 | accuracy: 0.9097618078175895 \n",
      "Epoch 16 | Step 6353 | loss: 0.2296647314320911 | accuracy: 0.9099025974025974 \n",
      "Epoch 16 | Step 6354 | loss: 0.22923638505264393 | accuracy: 0.9100930420711975 \n",
      "Epoch 16 | Step 6355 | loss: 0.2291993629067175 | accuracy: 0.9100302419354839 \n",
      "Epoch 16 | Step 6356 | loss: 0.22909545735530915 | accuracy: 0.9101185691318328 \n",
      "Epoch 16 | Step 6357 | loss: 0.2291338129494435 | accuracy: 0.9100560897435898 \n",
      "Epoch 16 | Step 6358 | loss: 0.22886576410680534 | accuracy: 0.9100938498402555 \n",
      "Epoch 16 | Step 6359 | loss: 0.22885272139386767 | accuracy: 0.9099820859872612 \n",
      "Epoch 16 | Step 6360 | loss: 0.2284234941715286 | accuracy: 0.910218253968254 \n",
      "Epoch 16 | Step 6361 | loss: 0.2284985287232867 | accuracy: 0.9102056962025317 \n",
      "Epoch 16 | Step 6362 | loss: 0.22836914792515878 | accuracy: 0.9101932176656151 \n",
      "Epoch 16 | Step 6363 | loss: 0.22833387335797525 | accuracy: 0.9102299528301887 \n",
      "Epoch 16 | Step 6364 | loss: 0.22825738874068455 | accuracy: 0.9103644200626959 \n",
      "Epoch 16 | Step 6365 | loss: 0.22815500746946782 | accuracy: 0.91044921875 \n",
      "Epoch 16 | Step 6366 | loss: 0.22826063277843955 | accuracy: 0.910436137071651 \n",
      "Epoch 16 | Step 6367 | loss: 0.2281275092398528 | accuracy: 0.9105687111801242 \n",
      "Epoch 16 | Step 6368 | loss: 0.22814236140749403 | accuracy: 0.9106037151702786 \n",
      "Epoch 16 | Step 6369 | loss: 0.22811109358789744 | accuracy: 0.9104456018518519 \n",
      "Epoch 16 | Step 6370 | loss: 0.22814645659465055 | accuracy: 0.9103846153846153 \n",
      "Epoch 16 | Step 6371 | loss: 0.22805948539471332 | accuracy: 0.9104198619631901 \n",
      "Epoch 16 | Step 6372 | loss: 0.22819333186299065 | accuracy: 0.9103593272171254 \n",
      "Epoch 16 | Step 6373 | loss: 0.22827117410829154 | accuracy: 0.9103944359756098 \n",
      "Epoch 16 | Step 6374 | loss: 0.22789569407429738 | accuracy: 0.9105718085106383 \n",
      "Epoch 16 | Step 6375 | loss: 0.22772806413245925 | accuracy: 0.9106534090909091 \n",
      "Epoch 16 | Step 6376 | loss: 0.22775133872500358 | accuracy: 0.9106401057401813 \n",
      "Epoch 16 | Step 6377 | loss: 0.22764749856418873 | accuracy: 0.9105798192771084 \n",
      "Epoch 16 | Step 6378 | loss: 0.22764702978076878 | accuracy: 0.9106137387387387 \n",
      "Epoch 16 | Step 6379 | loss: 0.2275651467149843 | accuracy: 0.9106474550898204 \n",
      "Epoch 16 | Step 6380 | loss: 0.2276313078492435 | accuracy: 0.9106343283582089 \n",
      "Epoch 16 | Step 6381 | loss: 0.2276584053678172 | accuracy: 0.9106212797619048 \n",
      "Epoch 16 | Step 6382 | loss: 0.22751976173780084 | accuracy: 0.9106546735905044 \n",
      "Epoch 16 | Step 6383 | loss: 0.22743758074277956 | accuracy: 0.9106416420118343 \n",
      "Epoch 16 | Step 6384 | loss: 0.22726367594218183 | accuracy: 0.9107208702064897 \n",
      "Epoch 16 | Step 6385 | loss: 0.22715378149467355 | accuracy: 0.9108455882352942 \n",
      "Epoch 16 | Step 6386 | loss: 0.22723606482279265 | accuracy: 0.9108321114369502 \n",
      "Epoch 16 | Step 6387 | loss: 0.2272027892588872 | accuracy: 0.9108644005847953 \n",
      "Epoch 16 | Step 6388 | loss: 0.22703073758078038 | accuracy: 0.910942055393586 \n",
      "Epoch 16 | Step 6389 | loss: 0.22717779770840046 | accuracy: 0.9109284156976745 \n",
      "Epoch 16 | Step 6390 | loss: 0.22722910681496497 | accuracy: 0.9108242753623188 \n",
      "Epoch 16 | Step 6391 | loss: 0.22711555707144598 | accuracy: 0.9109013728323699 \n",
      "Epoch 16 | Step 6392 | loss: 0.22704913121479045 | accuracy: 0.9109780259365994 \n",
      "Epoch 16 | Step 6393 | loss: 0.2269078886628836 | accuracy: 0.9109195402298851 \n",
      "Epoch 16 | Step 6394 | loss: 0.22685380630131097 | accuracy: 0.9109061604584527 \n",
      "Epoch 16 | Step 6395 | loss: 0.22714780343430382 | accuracy: 0.9107589285714286 \n",
      "Epoch 16 | Step 6396 | loss: 0.22692284408288124 | accuracy: 0.910835113960114 \n",
      "Epoch 16 | Step 6397 | loss: 0.22685139960694042 | accuracy: 0.9107776988636364 \n",
      "Epoch 16 | Step 6398 | loss: 0.22682901651258172 | accuracy: 0.9107206090651558 \n",
      "Epoch 16 | Step 6399 | loss: 0.22694583750714017 | accuracy: 0.9106638418079096 \n",
      "Epoch 16 | Step 6400 | loss: 0.2267629106699581 | accuracy: 0.9106514084507042 \n",
      "Epoch 16 | Step 6401 | loss: 0.22661476188831114 | accuracy: 0.9106829353932584 \n",
      "Epoch 16 | Step 6402 | loss: 0.2267611368196685 | accuracy: 0.9106267507002801 \n",
      "Epoch 16 | Step 6403 | loss: 0.22710353618893545 | accuracy: 0.9105708798882681 \n",
      "Epoch 16 | Step 6404 | loss: 0.2269733429453167 | accuracy: 0.9107329387186629 \n",
      "Epoch 16 | Step 6405 | loss: 0.22701427501936752 | accuracy: 0.9107638888888889 \n",
      "Epoch 16 | Step 6406 | loss: 0.22683962634725915 | accuracy: 0.9108379501385041 \n",
      "Epoch 16 | Step 6407 | loss: 0.2268772144179318 | accuracy: 0.9107821132596685 \n",
      "Epoch 16 | Step 6408 | loss: 0.22679572887000302 | accuracy: 0.9107696280991735 \n",
      "Epoch 16 | Step 6409 | loss: 0.22637734996093498 | accuracy: 0.9109718406593407 \n",
      "Epoch 16 | Step 6410 | loss: 0.2261577651517032 | accuracy: 0.9110445205479452 \n",
      "Epoch 16 | Step 6411 | loss: 0.22625723037400533 | accuracy: 0.9109887295081968 \n",
      "Epoch 16 | Step 6412 | loss: 0.22637204890842333 | accuracy: 0.9108906675749319 \n",
      "Epoch 16 | Step 6413 | loss: 0.22624975159440353 | accuracy: 0.9110478940217391 \n",
      "Epoch 16 | Step 6414 | loss: 0.2262411449094452 | accuracy: 0.911034891598916 \n",
      "Epoch 16 | Step 6415 | loss: 0.22618524859080444 | accuracy: 0.9110219594594594 \n",
      "Epoch 16 | Step 6416 | loss: 0.22624513422543147 | accuracy: 0.9110090970350404 \n",
      "Epoch 16 | Step 6417 | loss: 0.2260508272516471 | accuracy: 0.9110383064516129 \n",
      "Epoch 16 | Step 6418 | loss: 0.2258023654407854 | accuracy: 0.9110673592493298 \n",
      "Epoch 16 | Step 6419 | loss: 0.22565439024711037 | accuracy: 0.9111380347593583 \n",
      "Epoch 16 | Step 6420 | loss: 0.22570979444185893 | accuracy: 0.911125 \n",
      "Epoch 16 | Step 6421 | loss: 0.22563165584777264 | accuracy: 0.9111535904255319 \n",
      "Epoch 16 | Step 6422 | loss: 0.22558161106444796 | accuracy: 0.9110162466843501 \n",
      "Epoch 16 | Step 6423 | loss: 0.22555645279310368 | accuracy: 0.9110863095238095 \n",
      "Epoch 16 | Step 6424 | loss: 0.22536428555806898 | accuracy: 0.9111972295514512 \n",
      "Epoch 16 | Step 6425 | loss: 0.2252625919094211 | accuracy: 0.9112253289473684 \n",
      "Epoch 16 | Step 6426 | loss: 0.22504390787890577 | accuracy: 0.9112942913385826 \n",
      "Epoch 16 | Step 6427 | loss: 0.22511207854560533 | accuracy: 0.9113219895287958 \n",
      "Epoch 16 | Step 6428 | loss: 0.2252387455798316 | accuracy: 0.9113087467362925 \n",
      "Epoch 16 | Step 6429 | loss: 0.22548380075022578 | accuracy: 0.9113362630208334 \n",
      "Epoch 16 | Step 6430 | loss: 0.225336741781854 | accuracy: 0.9114042207792208 \n",
      "Epoch 16 | Step 6431 | loss: 0.22525608354281884 | accuracy: 0.9114313471502591 \n",
      "Epoch 16 | Step 6432 | loss: 0.22524910626177333 | accuracy: 0.9113775839793282 \n",
      "Epoch 16 | Step 6433 | loss: 0.22550467547682143 | accuracy: 0.9113240979381443 \n",
      "Epoch 16 | Step 6434 | loss: 0.2253740384676769 | accuracy: 0.9112708868894601 \n",
      "Epoch 16 | Step 6435 | loss: 0.22524880659885896 | accuracy: 0.9113782051282051 \n",
      "Epoch 16 | Step 6436 | loss: 0.22532996161819419 | accuracy: 0.9113251278772379 \n",
      "Epoch 16 | Step 6437 | loss: 0.22521712178630487 | accuracy: 0.9113919005102041 \n",
      "Epoch 16 | Step 6438 | loss: 0.2251106568496039 | accuracy: 0.9113788167938931 \n",
      "Epoch 16 | Step 6439 | loss: 0.22531793485892002 | accuracy: 0.9111675126903553 \n",
      "Epoch 16 | Step 6440 | loss: 0.22511567220657686 | accuracy: 0.9112341772151898 \n",
      "Epoch 16 | Step 6441 | loss: 0.22482153353742276 | accuracy: 0.9113794191919192 \n",
      "Epoch 16 | Step 6442 | loss: 0.2248584504429279 | accuracy: 0.9114058564231738 \n",
      "Epoch 16 | Step 6443 | loss: 0.2249778976579707 | accuracy: 0.9114321608040201 \n",
      "Epoch 16 | Step 6444 | loss: 0.22476364745009214 | accuracy: 0.9114974937343359 \n",
      "Epoch 16 | Step 6445 | loss: 0.22458535218611358 | accuracy: 0.9115234375 \n",
      "Epoch 16 | Step 6446 | loss: 0.22461968587892608 | accuracy: 0.9115492518703242 \n",
      "Epoch 16 | Step 6447 | loss: 0.22491942340535903 | accuracy: 0.9114972014925373 \n",
      "Epoch 16 | Step 6448 | loss: 0.22472422869492406 | accuracy: 0.9115456811547575 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4886395037174225 | accuracy: 0.78125 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.41103826463222504 | accuracy: 0.8203125 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4539223213990529 | accuracy: 0.8125 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.44491589069366455 | accuracy: 0.8125 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.41215904951095583 | accuracy: 0.828125 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4502321680386861 | accuracy: 0.8125 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.44748341185706003 | accuracy: 0.8147321428571429 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4394043907523155 | accuracy: 0.814453125 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.46824102269278634 | accuracy: 0.8107638888888888 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4483333945274353 | accuracy: 0.8203125 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4542464559728449 | accuracy: 0.8210227272727273 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4411251023411751 | accuracy: 0.8255208333333334 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.45270474369709307 | accuracy: 0.8209134615384616 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.43892933428287506 | accuracy: 0.8258928571428571 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4430611789226532 | accuracy: 0.8270833333333333 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4418475702404976 | accuracy: 0.8271484375 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4456263394916759 | accuracy: 0.8244485294117647 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.44444957541094887 | accuracy: 0.8263888888888888 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.44341078557466207 | accuracy: 0.8289473684210527 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.43831835985183715 | accuracy: 0.82890625 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.43125514898981365 | accuracy: 0.8303571428571429 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.42479593645442615 | accuracy: 0.8338068181818182 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.43199113659236743 | accuracy: 0.8315217391304348 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4497005765636762 | accuracy: 0.828125 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4559377789497375 | accuracy: 0.825 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.45235581466784847 | accuracy: 0.8257211538461539 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.44554292051880445 | accuracy: 0.828125 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.44665209523269106 | accuracy: 0.8275669642857143 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.44395958555155784 | accuracy: 0.8286637931034483 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.44091766476631167 | accuracy: 0.8307291666666666 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4353317695279275 | accuracy: 0.8336693548387096 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4377623684704304 | accuracy: 0.83203125 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.43804205276749353 | accuracy: 0.8304924242424242 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4413538478753146 | accuracy: 0.8276654411764706 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4431812022413526 | accuracy: 0.8276785714285714 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.44013603528340656 | accuracy: 0.8294270833333333 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4405713379383087 | accuracy: 0.8293918918918918 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.44395508970084946 | accuracy: 0.8297697368421052 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4447794694166917 | accuracy: 0.828926282051282 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4409447893500328 | accuracy: 0.83046875 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4368775167116305 | accuracy: 0.8319359756097561 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4329399452323005 | accuracy: 0.8333333333333334 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.43299896980440894 | accuracy: 0.8324854651162791 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4352157705209472 | accuracy: 0.8316761363636364 \n",
      "Validation | Epoch 16 | Step 6448 | loss: 0.4352143208185832 | accuracy: 0.831068840291765 \n",
      "Epoch 17 | Step 6449 | loss: 0.39715123176574707 | accuracy: 0.84375 \n",
      "Epoch 17 | Step 6450 | loss: 0.27665502578020096 | accuracy: 0.8984375 \n",
      "Epoch 17 | Step 6451 | loss: 0.2600233455499013 | accuracy: 0.90625 \n",
      "Epoch 17 | Step 6452 | loss: 0.2543519139289856 | accuracy: 0.90625 \n",
      "Epoch 17 | Step 6453 | loss: 0.23530831933021545 | accuracy: 0.90625 \n",
      "Epoch 17 | Step 6454 | loss: 0.22325372695922852 | accuracy: 0.90625 \n",
      "Epoch 17 | Step 6455 | loss: 0.2268755521093096 | accuracy: 0.90625 \n",
      "Epoch 17 | Step 6456 | loss: 0.2248007282614708 | accuracy: 0.908203125 \n",
      "Epoch 17 | Step 6457 | loss: 0.23146197530958387 | accuracy: 0.9079861111111112 \n",
      "Epoch 17 | Step 6458 | loss: 0.23445091247558594 | accuracy: 0.90625 \n",
      "Epoch 17 | Step 6459 | loss: 0.22676068950783124 | accuracy: 0.9105113636363636 \n",
      "Epoch 17 | Step 6460 | loss: 0.22063694894313812 | accuracy: 0.9127604166666666 \n",
      "Epoch 17 | Step 6461 | loss: 0.23177806459940398 | accuracy: 0.90625 \n",
      "Epoch 17 | Step 6462 | loss: 0.22825712923492705 | accuracy: 0.9095982142857143 \n",
      "Epoch 17 | Step 6463 | loss: 0.22997982998689015 | accuracy: 0.909375 \n",
      "Epoch 17 | Step 6464 | loss: 0.22241707565262914 | accuracy: 0.9130859375 \n",
      "Epoch 17 | Step 6465 | loss: 0.22516249952947393 | accuracy: 0.9117647058823529 \n",
      "Epoch 17 | Step 6466 | loss: 0.22235420470436415 | accuracy: 0.9131944444444444 \n",
      "Epoch 17 | Step 6467 | loss: 0.2204907218876638 | accuracy: 0.912828947368421 \n",
      "Epoch 17 | Step 6468 | loss: 0.22295778207480907 | accuracy: 0.9109375 \n",
      "Epoch 17 | Step 6469 | loss: 0.22193017921277455 | accuracy: 0.9107142857142857 \n",
      "Epoch 17 | Step 6470 | loss: 0.22498654675754634 | accuracy: 0.9105113636363636 \n",
      "Epoch 17 | Step 6471 | loss: 0.2218229482355325 | accuracy: 0.9123641304347826 \n",
      "Epoch 17 | Step 6472 | loss: 0.22243446949869394 | accuracy: 0.9108072916666666 \n",
      "Epoch 17 | Step 6473 | loss: 0.22664736717939377 | accuracy: 0.909375 \n",
      "Epoch 17 | Step 6474 | loss: 0.2258495788734693 | accuracy: 0.9080528846153846 \n",
      "Epoch 17 | Step 6475 | loss: 0.2314602299420922 | accuracy: 0.9068287037037037 \n",
      "Epoch 17 | Step 6476 | loss: 0.22834326193800994 | accuracy: 0.9084821428571429 \n",
      "Epoch 17 | Step 6477 | loss: 0.2327259848343915 | accuracy: 0.9073275862068966 \n",
      "Epoch 17 | Step 6478 | loss: 0.23178406779964764 | accuracy: 0.9072916666666667 \n",
      "Epoch 17 | Step 6479 | loss: 0.22989794107214098 | accuracy: 0.9067540322580645 \n",
      "Epoch 17 | Step 6480 | loss: 0.23051731777377427 | accuracy: 0.90576171875 \n",
      "Epoch 17 | Step 6481 | loss: 0.2301442941481417 | accuracy: 0.9071969696969697 \n",
      "Epoch 17 | Step 6482 | loss: 0.22664611874257817 | accuracy: 0.9085477941176471 \n",
      "Epoch 17 | Step 6483 | loss: 0.22301095383507866 | accuracy: 0.9102678571428572 \n",
      "Epoch 17 | Step 6484 | loss: 0.22134878072473738 | accuracy: 0.9110243055555556 \n",
      "Epoch 17 | Step 6485 | loss: 0.22080438563952576 | accuracy: 0.910472972972973 \n",
      "Epoch 17 | Step 6486 | loss: 0.2217378769265978 | accuracy: 0.9103618421052632 \n",
      "Epoch 17 | Step 6487 | loss: 0.22071082316912138 | accuracy: 0.9106570512820513 \n",
      "Epoch 17 | Step 6488 | loss: 0.21878080181777476 | accuracy: 0.912109375 \n",
      "Epoch 17 | Step 6489 | loss: 0.21766315436944728 | accuracy: 0.9123475609756098 \n",
      "Epoch 17 | Step 6490 | loss: 0.21821545454717817 | accuracy: 0.9118303571428571 \n",
      "Epoch 17 | Step 6491 | loss: 0.21677166015602822 | accuracy: 0.9120639534883721 \n",
      "Epoch 17 | Step 6492 | loss: 0.2156484489413825 | accuracy: 0.9129971590909091 \n",
      "Epoch 17 | Step 6493 | loss: 0.2163732326693005 | accuracy: 0.9138888888888889 \n",
      "Epoch 17 | Step 6494 | loss: 0.2173224956445072 | accuracy: 0.9137228260869565 \n",
      "Epoch 17 | Step 6495 | loss: 0.2170020988646974 | accuracy: 0.9142287234042553 \n",
      "Epoch 17 | Step 6496 | loss: 0.21674285425494114 | accuracy: 0.9147135416666666 \n",
      "Epoch 17 | Step 6497 | loss: 0.21796147829415846 | accuracy: 0.9145408163265306 \n",
      "Epoch 17 | Step 6498 | loss: 0.21909423261880875 | accuracy: 0.914375 \n",
      "Epoch 17 | Step 6499 | loss: 0.21903635882863812 | accuracy: 0.9142156862745098 \n",
      "Epoch 17 | Step 6500 | loss: 0.21694310267384237 | accuracy: 0.9149639423076923 \n",
      "Epoch 17 | Step 6501 | loss: 0.21880415953555196 | accuracy: 0.9133254716981132 \n",
      "Epoch 17 | Step 6502 | loss: 0.21717326756980684 | accuracy: 0.9146412037037037 \n",
      "Epoch 17 | Step 6503 | loss: 0.2185245543718338 | accuracy: 0.9139204545454546 \n",
      "Epoch 17 | Step 6504 | loss: 0.21761766794536794 | accuracy: 0.9143415178571429 \n",
      "Epoch 17 | Step 6505 | loss: 0.21926315128803253 | accuracy: 0.9136513157894737 \n",
      "Epoch 17 | Step 6506 | loss: 0.21930671303436675 | accuracy: 0.9135237068965517 \n",
      "Epoch 17 | Step 6507 | loss: 0.22057451939178727 | accuracy: 0.9134004237288136 \n",
      "Epoch 17 | Step 6508 | loss: 0.22104169602195423 | accuracy: 0.91328125 \n",
      "Epoch 17 | Step 6509 | loss: 0.22098421122207015 | accuracy: 0.9131659836065574 \n",
      "Epoch 17 | Step 6510 | loss: 0.22023134294056124 | accuracy: 0.9133064516129032 \n",
      "Epoch 17 | Step 6511 | loss: 0.2213073597540931 | accuracy: 0.9126984126984127 \n",
      "Epoch 17 | Step 6512 | loss: 0.21961109328549355 | accuracy: 0.91357421875 \n",
      "Epoch 17 | Step 6513 | loss: 0.21783385735291702 | accuracy: 0.9141826923076923 \n",
      "Epoch 17 | Step 6514 | loss: 0.21666955947875977 | accuracy: 0.9147727272727273 \n",
      "Epoch 17 | Step 6515 | loss: 0.21578678221844916 | accuracy: 0.9148787313432836 \n",
      "Epoch 17 | Step 6516 | loss: 0.2158988034900497 | accuracy: 0.9147518382352942 \n",
      "Epoch 17 | Step 6517 | loss: 0.21618998784949814 | accuracy: 0.9148550724637681 \n",
      "Epoch 17 | Step 6518 | loss: 0.21549743243626185 | accuracy: 0.9151785714285714 \n",
      "Epoch 17 | Step 6519 | loss: 0.21395057523754282 | accuracy: 0.9159330985915493 \n",
      "Epoch 17 | Step 6520 | loss: 0.21366777353816563 | accuracy: 0.9162326388888888 \n",
      "Epoch 17 | Step 6521 | loss: 0.21361014716429252 | accuracy: 0.916095890410959 \n",
      "Epoch 17 | Step 6522 | loss: 0.21375792856151993 | accuracy: 0.9155405405405406 \n",
      "Epoch 17 | Step 6523 | loss: 0.21369907875855765 | accuracy: 0.915 \n",
      "Epoch 17 | Step 6524 | loss: 0.2137967050075531 | accuracy: 0.9155016447368421 \n",
      "Epoch 17 | Step 6525 | loss: 0.21321846835024946 | accuracy: 0.9155844155844156 \n",
      "Epoch 17 | Step 6526 | loss: 0.21390066009301406 | accuracy: 0.9152644230769231 \n",
      "Epoch 17 | Step 6527 | loss: 0.2164078215255013 | accuracy: 0.9143591772151899 \n",
      "Epoch 17 | Step 6528 | loss: 0.21584271024912596 | accuracy: 0.9142578125 \n",
      "Epoch 17 | Step 6529 | loss: 0.21552512012881997 | accuracy: 0.9139660493827161 \n",
      "Epoch 17 | Step 6530 | loss: 0.21478087127935597 | accuracy: 0.9142530487804879 \n",
      "Epoch 17 | Step 6531 | loss: 0.21469553838293237 | accuracy: 0.9143448795180723 \n",
      "Epoch 17 | Step 6532 | loss: 0.21424070674748646 | accuracy: 0.9144345238095238 \n",
      "Epoch 17 | Step 6533 | loss: 0.21374841525274166 | accuracy: 0.9147058823529411 \n",
      "Epoch 17 | Step 6534 | loss: 0.21334912541300752 | accuracy: 0.9147892441860465 \n",
      "Epoch 17 | Step 6535 | loss: 0.215381501049831 | accuracy: 0.9141522988505747 \n",
      "Epoch 17 | Step 6536 | loss: 0.2157710140401667 | accuracy: 0.9140625 \n",
      "Epoch 17 | Step 6537 | loss: 0.21468062414212175 | accuracy: 0.9146769662921348 \n",
      "Epoch 17 | Step 6538 | loss: 0.21553623146480985 | accuracy: 0.9142361111111111 \n",
      "Epoch 17 | Step 6539 | loss: 0.2146808331484323 | accuracy: 0.9144917582417582 \n",
      "Epoch 17 | Step 6540 | loss: 0.21402448772088342 | accuracy: 0.9145720108695652 \n",
      "Epoch 17 | Step 6541 | loss: 0.21346155241612466 | accuracy: 0.9148185483870968 \n",
      "Epoch 17 | Step 6542 | loss: 0.21293969864540913 | accuracy: 0.9150598404255319 \n",
      "Epoch 17 | Step 6543 | loss: 0.21394647767669275 | accuracy: 0.9146381578947368 \n",
      "Epoch 17 | Step 6544 | loss: 0.21537536227454743 | accuracy: 0.9142252604166666 \n",
      "Epoch 17 | Step 6545 | loss: 0.21551978803172553 | accuracy: 0.9139819587628866 \n",
      "Epoch 17 | Step 6546 | loss: 0.21655624192588183 | accuracy: 0.9139030612244898 \n",
      "Epoch 17 | Step 6547 | loss: 0.2165835721023155 | accuracy: 0.9141414141414141 \n",
      "Epoch 17 | Step 6548 | loss: 0.21580937430262565 | accuracy: 0.9146875 \n",
      "Epoch 17 | Step 6549 | loss: 0.21453452884855836 | accuracy: 0.9153774752475248 \n",
      "Epoch 17 | Step 6550 | loss: 0.21434314716972558 | accuracy: 0.9155943627450981 \n",
      "Epoch 17 | Step 6551 | loss: 0.21340961739854905 | accuracy: 0.9158070388349514 \n",
      "Epoch 17 | Step 6552 | loss: 0.2139013257737343 | accuracy: 0.9157151442307693 \n",
      "Epoch 17 | Step 6553 | loss: 0.21494956328755332 | accuracy: 0.9151785714285714 \n",
      "Epoch 17 | Step 6554 | loss: 0.21411163950303816 | accuracy: 0.9155365566037735 \n",
      "Epoch 17 | Step 6555 | loss: 0.2157293367330159 | accuracy: 0.9148656542056075 \n",
      "Epoch 17 | Step 6556 | loss: 0.2164271094456867 | accuracy: 0.9150752314814815 \n",
      "Epoch 17 | Step 6557 | loss: 0.21662503221166243 | accuracy: 0.9148509174311926 \n",
      "Epoch 17 | Step 6558 | loss: 0.21724832667545838 | accuracy: 0.9144886363636363 \n",
      "Epoch 17 | Step 6559 | loss: 0.21691666852246533 | accuracy: 0.9144144144144144 \n",
      "Epoch 17 | Step 6560 | loss: 0.21674875023641757 | accuracy: 0.9146205357142857 \n",
      "Epoch 17 | Step 6561 | loss: 0.21771244124501152 | accuracy: 0.9142699115044248 \n",
      "Epoch 17 | Step 6562 | loss: 0.2180938201776722 | accuracy: 0.9141995614035088 \n",
      "Epoch 17 | Step 6563 | loss: 0.2175201406945353 | accuracy: 0.9142663043478261 \n",
      "Epoch 17 | Step 6564 | loss: 0.21732490946506633 | accuracy: 0.9141971982758621 \n",
      "Epoch 17 | Step 6565 | loss: 0.21810423283495456 | accuracy: 0.9138621794871795 \n",
      "Epoch 17 | Step 6566 | loss: 0.21802960538257987 | accuracy: 0.9139300847457628 \n",
      "Epoch 17 | Step 6567 | loss: 0.2181468023722913 | accuracy: 0.9142594537815126 \n",
      "Epoch 17 | Step 6568 | loss: 0.21762817166745663 | accuracy: 0.9143229166666667 \n",
      "Epoch 17 | Step 6569 | loss: 0.21763124483183396 | accuracy: 0.9142561983471075 \n",
      "Epoch 17 | Step 6570 | loss: 0.2176772335269412 | accuracy: 0.9141905737704918 \n",
      "Epoch 17 | Step 6571 | loss: 0.2176689506788564 | accuracy: 0.9139989837398373 \n",
      "Epoch 17 | Step 6572 | loss: 0.21799306463330023 | accuracy: 0.9140625 \n",
      "Epoch 17 | Step 6573 | loss: 0.21791302537918092 | accuracy: 0.913875 \n",
      "Epoch 17 | Step 6574 | loss: 0.2180536583302513 | accuracy: 0.9138144841269841 \n",
      "Epoch 17 | Step 6575 | loss: 0.2182129899582525 | accuracy: 0.9138779527559056 \n",
      "Epoch 17 | Step 6576 | loss: 0.2177989745978266 | accuracy: 0.9139404296875 \n",
      "Epoch 17 | Step 6577 | loss: 0.21750577602737634 | accuracy: 0.9137596899224806 \n",
      "Epoch 17 | Step 6578 | loss: 0.2171764564055663 | accuracy: 0.9138221153846153 \n",
      "Epoch 17 | Step 6579 | loss: 0.21780953357237895 | accuracy: 0.9135257633587787 \n",
      "Epoch 17 | Step 6580 | loss: 0.21891173313964496 | accuracy: 0.9131155303030303 \n",
      "Epoch 17 | Step 6581 | loss: 0.21939189743278617 | accuracy: 0.9129464285714286 \n",
      "Epoch 17 | Step 6582 | loss: 0.21953041629115147 | accuracy: 0.9130130597014925 \n",
      "Epoch 17 | Step 6583 | loss: 0.21968089640140534 | accuracy: 0.9128472222222223 \n",
      "Epoch 17 | Step 6584 | loss: 0.21951889213831985 | accuracy: 0.9127987132352942 \n",
      "Epoch 17 | Step 6585 | loss: 0.21915659351940572 | accuracy: 0.9130930656934306 \n",
      "Epoch 17 | Step 6586 | loss: 0.21910308193469394 | accuracy: 0.9132699275362319 \n",
      "Epoch 17 | Step 6587 | loss: 0.21961912405576636 | accuracy: 0.9128821942446043 \n",
      "Epoch 17 | Step 6588 | loss: 0.21984206054891858 | accuracy: 0.9128348214285713 \n",
      "Epoch 17 | Step 6589 | loss: 0.22104343328070133 | accuracy: 0.9124556737588653 \n",
      "Epoch 17 | Step 6590 | loss: 0.22112531456309306 | accuracy: 0.9126320422535211 \n",
      "Epoch 17 | Step 6591 | loss: 0.22151400596945436 | accuracy: 0.9125874125874126 \n",
      "Epoch 17 | Step 6592 | loss: 0.22139115476359925 | accuracy: 0.9127604166666666 \n",
      "Epoch 17 | Step 6593 | loss: 0.22127132107471598 | accuracy: 0.912823275862069 \n",
      "Epoch 17 | Step 6594 | loss: 0.2217422170590048 | accuracy: 0.9125642123287672 \n",
      "Epoch 17 | Step 6595 | loss: 0.22087481298616954 | accuracy: 0.9130527210884354 \n",
      "Epoch 17 | Step 6596 | loss: 0.22104427525521936 | accuracy: 0.9130067567567568 \n",
      "Epoch 17 | Step 6597 | loss: 0.22068563638717537 | accuracy: 0.9129614093959731 \n",
      "Epoch 17 | Step 6598 | loss: 0.22110623116294542 | accuracy: 0.913125 \n",
      "Epoch 17 | Step 6599 | loss: 0.22139191523885096 | accuracy: 0.9128725165562914 \n",
      "Epoch 17 | Step 6600 | loss: 0.22234948641179422 | accuracy: 0.9125205592105263 \n",
      "Epoch 17 | Step 6601 | loss: 0.22307378905855751 | accuracy: 0.9122753267973857 \n",
      "Epoch 17 | Step 6602 | loss: 0.22258495950660148 | accuracy: 0.9126420454545454 \n",
      "Epoch 17 | Step 6603 | loss: 0.22239449634667366 | accuracy: 0.9126008064516129 \n",
      "Epoch 17 | Step 6604 | loss: 0.22154822955146813 | accuracy: 0.9129607371794872 \n",
      "Epoch 17 | Step 6605 | loss: 0.2212327385594131 | accuracy: 0.9132165605095541 \n",
      "Epoch 17 | Step 6606 | loss: 0.22132758305797093 | accuracy: 0.9128757911392406 \n",
      "Epoch 17 | Step 6607 | loss: 0.22138605037200376 | accuracy: 0.9125393081761006 \n",
      "Epoch 17 | Step 6608 | loss: 0.22164049642160535 | accuracy: 0.91240234375 \n",
      "Epoch 17 | Step 6609 | loss: 0.22178199702168103 | accuracy: 0.9123641304347826 \n",
      "Epoch 17 | Step 6610 | loss: 0.2216873480765908 | accuracy: 0.9123263888888888 \n",
      "Epoch 17 | Step 6611 | loss: 0.22290421016742848 | accuracy: 0.9120015337423313 \n",
      "Epoch 17 | Step 6612 | loss: 0.22270083745441785 | accuracy: 0.9120617378048781 \n",
      "Epoch 17 | Step 6613 | loss: 0.22251149876551193 | accuracy: 0.9122159090909091 \n",
      "Epoch 17 | Step 6614 | loss: 0.22287039970418057 | accuracy: 0.9118975903614458 \n",
      "Epoch 17 | Step 6615 | loss: 0.2225720315814732 | accuracy: 0.9121444610778443 \n",
      "Epoch 17 | Step 6616 | loss: 0.22318249985220887 | accuracy: 0.9120163690476191 \n",
      "Epoch 17 | Step 6617 | loss: 0.22298014481392134 | accuracy: 0.9119822485207101 \n",
      "Epoch 17 | Step 6618 | loss: 0.2222735480788876 | accuracy: 0.9124080882352941 \n",
      "Epoch 17 | Step 6619 | loss: 0.2221994607856399 | accuracy: 0.9122807017543859 \n",
      "Epoch 17 | Step 6620 | loss: 0.22245096419613028 | accuracy: 0.9120639534883721 \n",
      "Epoch 17 | Step 6621 | loss: 0.22202545477648003 | accuracy: 0.9123013005780347 \n",
      "Epoch 17 | Step 6622 | loss: 0.22217270881793966 | accuracy: 0.9125359195402298 \n",
      "Epoch 17 | Step 6623 | loss: 0.22207727087395532 | accuracy: 0.9124107142857143 \n",
      "Epoch 17 | Step 6624 | loss: 0.22266584935344078 | accuracy: 0.9122869318181818 \n",
      "Epoch 17 | Step 6625 | loss: 0.22344894947136862 | accuracy: 0.9120762711864406 \n",
      "Epoch 17 | Step 6626 | loss: 0.2241750568402617 | accuracy: 0.9115168539325843 \n",
      "Epoch 17 | Step 6627 | loss: 0.22469045209318567 | accuracy: 0.9112255586592178 \n",
      "Epoch 17 | Step 6628 | loss: 0.2242704925023847 | accuracy: 0.9113715277777777 \n",
      "Epoch 17 | Step 6629 | loss: 0.22457960268575183 | accuracy: 0.9110842541436464 \n",
      "Epoch 17 | Step 6630 | loss: 0.22449661738106183 | accuracy: 0.9110576923076923 \n",
      "Epoch 17 | Step 6631 | loss: 0.22393627831193266 | accuracy: 0.9113729508196722 \n",
      "Epoch 17 | Step 6632 | loss: 0.22354304417967796 | accuracy: 0.9116847826086957 \n",
      "Epoch 17 | Step 6633 | loss: 0.2233101366339503 | accuracy: 0.9118243243243244 \n",
      "Epoch 17 | Step 6634 | loss: 0.22359462226590804 | accuracy: 0.9116263440860215 \n",
      "Epoch 17 | Step 6635 | loss: 0.22407929176952748 | accuracy: 0.9114304812834224 \n",
      "Epoch 17 | Step 6636 | loss: 0.22429703017498584 | accuracy: 0.9111535904255319 \n",
      "Epoch 17 | Step 6637 | loss: 0.22405626565691025 | accuracy: 0.9112929894179894 \n",
      "Epoch 17 | Step 6638 | loss: 0.2247801274061203 | accuracy: 0.9111842105263158 \n",
      "Epoch 17 | Step 6639 | loss: 0.2242937728528577 | accuracy: 0.9114856020942408 \n",
      "Epoch 17 | Step 6640 | loss: 0.22396599998076758 | accuracy: 0.91162109375 \n",
      "Epoch 17 | Step 6641 | loss: 0.22360849588955004 | accuracy: 0.9117551813471503 \n",
      "Epoch 17 | Step 6642 | loss: 0.2234118928767971 | accuracy: 0.9119684278350515 \n",
      "Epoch 17 | Step 6643 | loss: 0.22296752524681582 | accuracy: 0.9121794871794872 \n",
      "Epoch 17 | Step 6644 | loss: 0.22310043787773776 | accuracy: 0.9120695153061225 \n",
      "Epoch 17 | Step 6645 | loss: 0.2230946564583609 | accuracy: 0.9120399746192893 \n",
      "Epoch 17 | Step 6646 | loss: 0.22317180180489415 | accuracy: 0.9120896464646465 \n",
      "Epoch 17 | Step 6647 | loss: 0.2228742635729325 | accuracy: 0.9123743718592965 \n",
      "Epoch 17 | Step 6648 | loss: 0.22271895423531532 | accuracy: 0.91234375 \n",
      "Epoch 17 | Step 6649 | loss: 0.22315363148551676 | accuracy: 0.9120802238805971 \n",
      "Epoch 17 | Step 6650 | loss: 0.2231186020492327 | accuracy: 0.9122834158415841 \n",
      "Epoch 17 | Step 6651 | loss: 0.2231710148709161 | accuracy: 0.912176724137931 \n",
      "Epoch 17 | Step 6652 | loss: 0.22300489816595526 | accuracy: 0.9123008578431373 \n",
      "Epoch 17 | Step 6653 | loss: 0.22322672503750499 | accuracy: 0.9121951219512195 \n",
      "Epoch 17 | Step 6654 | loss: 0.22407152178218065 | accuracy: 0.911938713592233 \n",
      "Epoch 17 | Step 6655 | loss: 0.22488816363224085 | accuracy: 0.9118357487922706 \n",
      "Epoch 17 | Step 6656 | loss: 0.22484624543442175 | accuracy: 0.9118840144230769 \n",
      "Epoch 17 | Step 6657 | loss: 0.22477069924892992 | accuracy: 0.9117822966507177 \n",
      "Epoch 17 | Step 6658 | loss: 0.22478405521029518 | accuracy: 0.9119047619047619 \n",
      "Epoch 17 | Step 6659 | loss: 0.2250462520461512 | accuracy: 0.9116558056872038 \n",
      "Epoch 17 | Step 6660 | loss: 0.22448219713877957 | accuracy: 0.9119988207547169 \n",
      "Epoch 17 | Step 6661 | loss: 0.22411273045579033 | accuracy: 0.9121919014084507 \n",
      "Epoch 17 | Step 6662 | loss: 0.22416177868982343 | accuracy: 0.9122371495327103 \n",
      "Epoch 17 | Step 6663 | loss: 0.22397266394177148 | accuracy: 0.9122093023255814 \n",
      "Epoch 17 | Step 6664 | loss: 0.22391777102731997 | accuracy: 0.912109375 \n",
      "Epoch 17 | Step 6665 | loss: 0.22362812148398517 | accuracy: 0.9122263824884793 \n",
      "Epoch 17 | Step 6666 | loss: 0.22341449985947084 | accuracy: 0.9122706422018348 \n",
      "Epoch 17 | Step 6667 | loss: 0.2231857429968712 | accuracy: 0.912314497716895 \n",
      "Epoch 17 | Step 6668 | loss: 0.22314734489402988 | accuracy: 0.9124289772727273 \n",
      "Epoch 17 | Step 6669 | loss: 0.22307124528275357 | accuracy: 0.9124010180995475 \n",
      "Epoch 17 | Step 6670 | loss: 0.22315771860985067 | accuracy: 0.9124436936936937 \n",
      "Epoch 17 | Step 6671 | loss: 0.2233185174419741 | accuracy: 0.9121356502242153 \n",
      "Epoch 17 | Step 6672 | loss: 0.22272277793048748 | accuracy: 0.9125279017857143 \n",
      "Epoch 17 | Step 6673 | loss: 0.22289591706461376 | accuracy: 0.9124305555555555 \n",
      "Epoch 17 | Step 6674 | loss: 0.22327248498269942 | accuracy: 0.9123340707964602 \n",
      "Epoch 17 | Step 6675 | loss: 0.22326424097568454 | accuracy: 0.9123072687224669 \n",
      "Epoch 17 | Step 6676 | loss: 0.22323092939168737 | accuracy: 0.9124177631578947 \n",
      "Epoch 17 | Step 6677 | loss: 0.22319701122014282 | accuracy: 0.9123908296943232 \n",
      "Epoch 17 | Step 6678 | loss: 0.2231611688175927 | accuracy: 0.9124320652173913 \n",
      "Epoch 17 | Step 6679 | loss: 0.22293849305544064 | accuracy: 0.9126082251082251 \n",
      "Epoch 17 | Step 6680 | loss: 0.2227123430769505 | accuracy: 0.9127155172413793 \n",
      "Epoch 17 | Step 6681 | loss: 0.22266730854823355 | accuracy: 0.9126877682403434 \n",
      "Epoch 17 | Step 6682 | loss: 0.22280495680677584 | accuracy: 0.9127270299145299 \n",
      "Epoch 17 | Step 6683 | loss: 0.22253437768271628 | accuracy: 0.9128324468085106 \n",
      "Epoch 17 | Step 6684 | loss: 0.22227560428870938 | accuracy: 0.912936970338983 \n",
      "Epoch 17 | Step 6685 | loss: 0.222132594807993 | accuracy: 0.913040611814346 \n",
      "Epoch 17 | Step 6686 | loss: 0.22208587953648648 | accuracy: 0.9131433823529411 \n",
      "Epoch 17 | Step 6687 | loss: 0.22196458644822054 | accuracy: 0.9131799163179917 \n",
      "Epoch 17 | Step 6688 | loss: 0.22197311418130994 | accuracy: 0.9130208333333333 \n",
      "Epoch 17 | Step 6689 | loss: 0.22142705216200026 | accuracy: 0.913316908713693 \n",
      "Epoch 17 | Step 6690 | loss: 0.221190574247975 | accuracy: 0.9134168388429752 \n",
      "Epoch 17 | Step 6691 | loss: 0.22173784066129615 | accuracy: 0.913258744855967 \n",
      "Epoch 17 | Step 6692 | loss: 0.2223368686486463 | accuracy: 0.9132300204918032 \n",
      "Epoch 17 | Step 6693 | loss: 0.22209260305579828 | accuracy: 0.913329081632653 \n",
      "Epoch 17 | Step 6694 | loss: 0.22208107680809208 | accuracy: 0.9133003048780488 \n",
      "Epoch 17 | Step 6695 | loss: 0.22179596759529732 | accuracy: 0.9135247975708503 \n",
      "Epoch 17 | Step 6696 | loss: 0.22192738036955556 | accuracy: 0.9134324596774194 \n",
      "Epoch 17 | Step 6697 | loss: 0.22168451038948503 | accuracy: 0.9135291164658634 \n",
      "Epoch 17 | Step 6698 | loss: 0.2216626011133194 | accuracy: 0.9135 \n",
      "Epoch 17 | Step 6699 | loss: 0.22134146515829153 | accuracy: 0.9137201195219123 \n",
      "Epoch 17 | Step 6700 | loss: 0.22147238035760228 | accuracy: 0.9135044642857143 \n",
      "Epoch 17 | Step 6701 | loss: 0.2213160793771857 | accuracy: 0.913475790513834 \n",
      "Epoch 17 | Step 6702 | loss: 0.22133912193024252 | accuracy: 0.9134473425196851 \n",
      "Epoch 17 | Step 6703 | loss: 0.22135242761350146 | accuracy: 0.9134191176470589 \n",
      "Epoch 17 | Step 6704 | loss: 0.22153306915424764 | accuracy: 0.91326904296875 \n",
      "Epoch 17 | Step 6705 | loss: 0.22135916705957182 | accuracy: 0.9133025291828794 \n",
      "Epoch 17 | Step 6706 | loss: 0.22107513208490934 | accuracy: 0.9132751937984496 \n",
      "Epoch 17 | Step 6707 | loss: 0.22115915104689285 | accuracy: 0.913067084942085 \n",
      "Epoch 17 | Step 6708 | loss: 0.2209770292043686 | accuracy: 0.9130408653846154 \n",
      "Epoch 17 | Step 6709 | loss: 0.2213427563736722 | accuracy: 0.9127155172413793 \n",
      "Epoch 17 | Step 6710 | loss: 0.22167943395276107 | accuracy: 0.9124522900763359 \n",
      "Epoch 17 | Step 6711 | loss: 0.2213718727967585 | accuracy: 0.9124881178707225 \n",
      "Epoch 17 | Step 6712 | loss: 0.22177432658094348 | accuracy: 0.9123461174242424 \n",
      "Epoch 17 | Step 6713 | loss: 0.22172771973429986 | accuracy: 0.9123231132075472 \n",
      "Epoch 17 | Step 6714 | loss: 0.221687567917476 | accuracy: 0.9122415413533834 \n",
      "Epoch 17 | Step 6715 | loss: 0.22148615702261193 | accuracy: 0.9122191011235955 \n",
      "Epoch 17 | Step 6716 | loss: 0.22128833379985682 | accuracy: 0.9123717350746269 \n",
      "Epoch 17 | Step 6717 | loss: 0.2212030253888949 | accuracy: 0.9124651486988847 \n",
      "Epoch 17 | Step 6718 | loss: 0.22115996640037608 | accuracy: 0.9124421296296297 \n",
      "Epoch 17 | Step 6719 | loss: 0.22115026150462372 | accuracy: 0.9124192804428044 \n",
      "Epoch 17 | Step 6720 | loss: 0.22119099674198558 | accuracy: 0.9122242647058824 \n",
      "Epoch 17 | Step 6721 | loss: 0.22138269758704818 | accuracy: 0.9119162087912088 \n",
      "Epoch 17 | Step 6722 | loss: 0.22128941319937254 | accuracy: 0.9119525547445255 \n",
      "Epoch 17 | Step 6723 | loss: 0.22109881103038787 | accuracy: 0.9119318181818182 \n",
      "Epoch 17 | Step 6724 | loss: 0.22143566235899922 | accuracy: 0.9116281702898551 \n",
      "Epoch 17 | Step 6725 | loss: 0.22133099925216781 | accuracy: 0.9116087545126353 \n",
      "Epoch 17 | Step 6726 | loss: 0.2210641150637496 | accuracy: 0.9117018884892086 \n",
      "Epoch 17 | Step 6727 | loss: 0.22101420879791284 | accuracy: 0.9117383512544803 \n",
      "Epoch 17 | Step 6728 | loss: 0.2209428976689066 | accuracy: 0.9117745535714286 \n",
      "Epoch 17 | Step 6729 | loss: 0.22156068597824122 | accuracy: 0.9115324733096085 \n",
      "Epoch 17 | Step 6730 | loss: 0.22140116228702217 | accuracy: 0.9116799645390071 \n",
      "Epoch 17 | Step 6731 | loss: 0.22125655986605597 | accuracy: 0.9117712014134276 \n",
      "Epoch 17 | Step 6732 | loss: 0.22109636213158215 | accuracy: 0.9118617957746479 \n",
      "Epoch 17 | Step 6733 | loss: 0.22097648230561037 | accuracy: 0.9119517543859649 \n",
      "Epoch 17 | Step 6734 | loss: 0.22088656751634356 | accuracy: 0.911986451048951 \n",
      "Epoch 17 | Step 6735 | loss: 0.22070945004968276 | accuracy: 0.912020905923345 \n",
      "Epoch 17 | Step 6736 | loss: 0.22043074853718278 | accuracy: 0.9121636284722222 \n",
      "Epoch 17 | Step 6737 | loss: 0.22024403847625096 | accuracy: 0.91219723183391 \n",
      "Epoch 17 | Step 6738 | loss: 0.22069169231529895 | accuracy: 0.9120689655172414 \n",
      "Epoch 17 | Step 6739 | loss: 0.2205215943433165 | accuracy: 0.9119952749140894 \n",
      "Epoch 17 | Step 6740 | loss: 0.2205300112701442 | accuracy: 0.9120826198630136 \n",
      "Epoch 17 | Step 6741 | loss: 0.22057240992886215 | accuracy: 0.9121160409556314 \n",
      "Epoch 17 | Step 6742 | loss: 0.22022706508433737 | accuracy: 0.9122555272108843 \n",
      "Epoch 17 | Step 6743 | loss: 0.22053127748481297 | accuracy: 0.9120762711864406 \n",
      "Epoch 17 | Step 6744 | loss: 0.2203828963778309 | accuracy: 0.912109375 \n",
      "Epoch 17 | Step 6745 | loss: 0.22063528543168848 | accuracy: 0.9118792087542088 \n",
      "Epoch 17 | Step 6746 | loss: 0.22047390878800577 | accuracy: 0.9119651845637584 \n",
      "Epoch 17 | Step 6747 | loss: 0.22039777229860874 | accuracy: 0.9119983277591973 \n",
      "Epoch 17 | Step 6748 | loss: 0.22030596350630124 | accuracy: 0.9121354166666666 \n",
      "Epoch 17 | Step 6749 | loss: 0.22014654187665034 | accuracy: 0.9122715946843853 \n",
      "Epoch 17 | Step 6750 | loss: 0.2199923001377788 | accuracy: 0.9123551324503312 \n",
      "Epoch 17 | Step 6751 | loss: 0.2197048753598342 | accuracy: 0.9124381188118812 \n",
      "Epoch 17 | Step 6752 | loss: 0.2196965194062183 | accuracy: 0.9124691611842105 \n",
      "Epoch 17 | Step 6753 | loss: 0.22011059708282596 | accuracy: 0.9122438524590164 \n",
      "Epoch 17 | Step 6754 | loss: 0.2198827836443396 | accuracy: 0.9124285130718954 \n",
      "Epoch 17 | Step 6755 | loss: 0.21981078468821336 | accuracy: 0.9125610749185668 \n",
      "Epoch 17 | Step 6756 | loss: 0.21948002344118311 | accuracy: 0.9127435064935064 \n",
      "Epoch 17 | Step 6757 | loss: 0.21906708622152365 | accuracy: 0.9130258899676376 \n",
      "Epoch 17 | Step 6758 | loss: 0.21908828666613947 | accuracy: 0.913054435483871 \n",
      "Epoch 17 | Step 6759 | loss: 0.21894834861398893 | accuracy: 0.913133038585209 \n",
      "Epoch 17 | Step 6760 | loss: 0.21895337990747812 | accuracy: 0.9130608974358975 \n",
      "Epoch 17 | Step 6761 | loss: 0.21877459984141798 | accuracy: 0.9130890575079872 \n",
      "Epoch 17 | Step 6762 | loss: 0.21878426249144942 | accuracy: 0.9130175159235668 \n",
      "Epoch 17 | Step 6763 | loss: 0.2183791276717943 | accuracy: 0.9131448412698413 \n",
      "Epoch 17 | Step 6764 | loss: 0.2183942971397427 | accuracy: 0.9131724683544303 \n",
      "Epoch 17 | Step 6765 | loss: 0.21829551719246604 | accuracy: 0.9132492113564669 \n",
      "Epoch 17 | Step 6766 | loss: 0.21839983234146856 | accuracy: 0.9132272012578616 \n",
      "Epoch 17 | Step 6767 | loss: 0.2183063164540219 | accuracy: 0.9133032915360502 \n",
      "Epoch 17 | Step 6768 | loss: 0.21823875268455595 | accuracy: 0.91337890625 \n",
      "Epoch 17 | Step 6769 | loss: 0.21830822525087545 | accuracy: 0.9134053738317757 \n",
      "Epoch 17 | Step 6770 | loss: 0.21816883613326535 | accuracy: 0.913480201863354 \n",
      "Epoch 17 | Step 6771 | loss: 0.21811513074503594 | accuracy: 0.9134578173374613 \n",
      "Epoch 17 | Step 6772 | loss: 0.21799079524238169 | accuracy: 0.9134355709876543 \n",
      "Epoch 17 | Step 6773 | loss: 0.2179790069735967 | accuracy: 0.9134615384615384 \n",
      "Epoch 17 | Step 6774 | loss: 0.2180336043924276 | accuracy: 0.9133435582822086 \n",
      "Epoch 17 | Step 6775 | loss: 0.2181212050606716 | accuracy: 0.9132740825688074 \n",
      "Epoch 17 | Step 6776 | loss: 0.21820271994191698 | accuracy: 0.9133003048780488 \n",
      "Epoch 17 | Step 6777 | loss: 0.21789330010809072 | accuracy: 0.9133738601823708 \n",
      "Epoch 17 | Step 6778 | loss: 0.21772127429192717 | accuracy: 0.9134469696969697 \n",
      "Epoch 17 | Step 6779 | loss: 0.21773001486351123 | accuracy: 0.9134252265861027 \n",
      "Epoch 17 | Step 6780 | loss: 0.21763875090842505 | accuracy: 0.9134036144578314 \n",
      "Epoch 17 | Step 6781 | loss: 0.21756877817280657 | accuracy: 0.9134290540540541 \n",
      "Epoch 17 | Step 6782 | loss: 0.2176661514816527 | accuracy: 0.9134543413173652 \n",
      "Epoch 17 | Step 6783 | loss: 0.21768616008669583 | accuracy: 0.9133861940298508 \n",
      "Epoch 17 | Step 6784 | loss: 0.21774105113443165 | accuracy: 0.9133649553571429 \n",
      "Epoch 17 | Step 6785 | loss: 0.21764689562317172 | accuracy: 0.9133438427299704 \n",
      "Epoch 17 | Step 6786 | loss: 0.21751643141963073 | accuracy: 0.9133228550295858 \n",
      "Epoch 17 | Step 6787 | loss: 0.2173298619094148 | accuracy: 0.9134402654867256 \n",
      "Epoch 17 | Step 6788 | loss: 0.21724375396528664 | accuracy: 0.9135110294117647 \n",
      "Epoch 17 | Step 6789 | loss: 0.2173672017594936 | accuracy: 0.9134439149560117 \n",
      "Epoch 17 | Step 6790 | loss: 0.21735430367247402 | accuracy: 0.9133771929824561 \n",
      "Epoch 17 | Step 6791 | loss: 0.2171355202880962 | accuracy: 0.9135386297376094 \n",
      "Epoch 17 | Step 6792 | loss: 0.21700915224243736 | accuracy: 0.913562863372093 \n",
      "Epoch 17 | Step 6793 | loss: 0.21699540634518083 | accuracy: 0.9135416666666667 \n",
      "Epoch 17 | Step 6794 | loss: 0.21682162050997592 | accuracy: 0.9136109104046243 \n",
      "Epoch 17 | Step 6795 | loss: 0.21674085137909357 | accuracy: 0.9137247838616714 \n",
      "Epoch 17 | Step 6796 | loss: 0.21654781067594028 | accuracy: 0.9137931034482759 \n",
      "Epoch 17 | Step 6797 | loss: 0.21654234145551834 | accuracy: 0.9138162607449857 \n",
      "Epoch 17 | Step 6798 | loss: 0.21673159682324955 | accuracy: 0.9135714285714286 \n",
      "Epoch 17 | Step 6799 | loss: 0.21644840325809953 | accuracy: 0.9136841168091168 \n",
      "Epoch 17 | Step 6800 | loss: 0.21640590533868156 | accuracy: 0.9137073863636364 \n",
      "Epoch 17 | Step 6801 | loss: 0.21656680999919983 | accuracy: 0.9135977337110481 \n",
      "Epoch 17 | Step 6802 | loss: 0.21673733827337033 | accuracy: 0.9134887005649718 \n",
      "Epoch 17 | Step 6803 | loss: 0.2166036983401003 | accuracy: 0.913556338028169 \n",
      "Epoch 17 | Step 6804 | loss: 0.2164720372830549 | accuracy: 0.9135797050561798 \n",
      "Epoch 17 | Step 6805 | loss: 0.21678154940615182 | accuracy: 0.9135591736694678 \n",
      "Epoch 17 | Step 6806 | loss: 0.21713806478587608 | accuracy: 0.9134951117318436 \n",
      "Epoch 17 | Step 6807 | loss: 0.2169974705925559 | accuracy: 0.9136055013927576 \n",
      "Epoch 17 | Step 6808 | loss: 0.2170872072999676 | accuracy: 0.9137152777777777 \n",
      "Epoch 17 | Step 6809 | loss: 0.21697064984455663 | accuracy: 0.9137378808864266 \n",
      "Epoch 17 | Step 6810 | loss: 0.2169297778598182 | accuracy: 0.9137171961325967 \n",
      "Epoch 17 | Step 6811 | loss: 0.21677963199612194 | accuracy: 0.9137827134986226 \n",
      "Epoch 17 | Step 6812 | loss: 0.21639086027721782 | accuracy: 0.9139766483516484 \n",
      "Epoch 17 | Step 6813 | loss: 0.21619346043834947 | accuracy: 0.9140410958904109 \n",
      "Epoch 17 | Step 6814 | loss: 0.21626661156044633 | accuracy: 0.9140198087431693 \n",
      "Epoch 17 | Step 6815 | loss: 0.21638580888753367 | accuracy: 0.9139560626702997 \n",
      "Epoch 17 | Step 6816 | loss: 0.21628018614390623 | accuracy: 0.9139775815217391 \n",
      "Epoch 17 | Step 6817 | loss: 0.21646196974648368 | accuracy: 0.9139989837398373 \n",
      "Epoch 17 | Step 6818 | loss: 0.2163652908157658 | accuracy: 0.9140625 \n",
      "Epoch 17 | Step 6819 | loss: 0.21647968607128792 | accuracy: 0.9140414420485176 \n",
      "Epoch 17 | Step 6820 | loss: 0.21630148673730512 | accuracy: 0.9141465053763441 \n",
      "Epoch 17 | Step 6821 | loss: 0.21600708685036318 | accuracy: 0.9143347855227882 \n",
      "Epoch 17 | Step 6822 | loss: 0.2158057939480333 | accuracy: 0.9143967245989305 \n",
      "Epoch 17 | Step 6823 | loss: 0.21585420560836793 | accuracy: 0.914375 \n",
      "Epoch 17 | Step 6824 | loss: 0.2157301955083583 | accuracy: 0.9143533909574468 \n",
      "Epoch 17 | Step 6825 | loss: 0.2156589087345872 | accuracy: 0.914290450928382 \n",
      "Epoch 17 | Step 6826 | loss: 0.2156911955939399 | accuracy: 0.9143105158730159 \n",
      "Epoch 17 | Step 6827 | loss: 0.2154877781867981 | accuracy: 0.9143717018469657 \n",
      "Epoch 17 | Step 6828 | loss: 0.21536419379868005 | accuracy: 0.914391447368421 \n",
      "Epoch 17 | Step 6829 | loss: 0.21514774995838876 | accuracy: 0.9144520997375328 \n",
      "Epoch 17 | Step 6830 | loss: 0.21517993739918265 | accuracy: 0.9144715314136126 \n",
      "Epoch 17 | Step 6831 | loss: 0.2152128665083071 | accuracy: 0.9144500652741514 \n",
      "Epoch 17 | Step 6832 | loss: 0.21563104171461114 | accuracy: 0.9144287109375 \n",
      "Epoch 17 | Step 6833 | loss: 0.2155551498199438 | accuracy: 0.9144480519480519 \n",
      "Epoch 17 | Step 6834 | loss: 0.21544118341386628 | accuracy: 0.9145482512953368 \n",
      "Epoch 17 | Step 6835 | loss: 0.21552749771326396 | accuracy: 0.914405684754522 \n",
      "Epoch 17 | Step 6836 | loss: 0.21571985036902822 | accuracy: 0.9143443943298969 \n",
      "Epoch 17 | Step 6837 | loss: 0.21558951557755163 | accuracy: 0.9144039203084833 \n",
      "Epoch 17 | Step 6838 | loss: 0.21557132043899635 | accuracy: 0.9145032051282052 \n",
      "Epoch 17 | Step 6839 | loss: 0.2157722538541955 | accuracy: 0.9144820971867008 \n",
      "Epoch 17 | Step 6840 | loss: 0.2156707245324339 | accuracy: 0.9145408163265306 \n",
      "Epoch 17 | Step 6841 | loss: 0.21564816552719088 | accuracy: 0.9145594783715013 \n",
      "Epoch 17 | Step 6842 | loss: 0.21585571436863865 | accuracy: 0.9143401015228426 \n",
      "Epoch 17 | Step 6843 | loss: 0.21565266821203352 | accuracy: 0.9143591772151899 \n",
      "Epoch 17 | Step 6844 | loss: 0.21551152815421423 | accuracy: 0.9144176136363636 \n",
      "Epoch 17 | Step 6845 | loss: 0.2154845164089419 | accuracy: 0.9145151133501259 \n",
      "Epoch 17 | Step 6846 | loss: 0.2155553303921043 | accuracy: 0.9144943467336684 \n",
      "Epoch 17 | Step 6847 | loss: 0.2153288737723702 | accuracy: 0.9145911654135338 \n",
      "Epoch 17 | Step 6848 | loss: 0.2152017407491803 | accuracy: 0.914609375 \n",
      "Epoch 17 | Step 6849 | loss: 0.21531730202813992 | accuracy: 0.914627493765586 \n",
      "Epoch 17 | Step 6850 | loss: 0.21548484677254265 | accuracy: 0.9145677860696517 \n",
      "Epoch 17 | Step 6851 | loss: 0.21532140235894962 | accuracy: 0.9146086464153034 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.49742481112480164 | accuracy: 0.796875 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.40767964720726013 | accuracy: 0.84375 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4716549714406331 | accuracy: 0.8385416666666666 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4652888923883438 | accuracy: 0.8359375 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.436195433139801 | accuracy: 0.846875 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4690425892670949 | accuracy: 0.8307291666666666 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.45631798676082064 | accuracy: 0.8348214285714286 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4479120150208473 | accuracy: 0.830078125 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.48311812347835964 | accuracy: 0.8229166666666666 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4654538184404373 | accuracy: 0.83125 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4734273850917816 | accuracy: 0.8267045454545454 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.45880062133073807 | accuracy: 0.83203125 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4708424829519712 | accuracy: 0.8269230769230769 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.45536776312759947 | accuracy: 0.8325892857142857 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.46173125704129536 | accuracy: 0.834375 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4582001809030771 | accuracy: 0.833984375 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4607570504440981 | accuracy: 0.8318014705882353 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4602675504154629 | accuracy: 0.8307291666666666 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4537357687950134 | accuracy: 0.834703947368421 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4469388112425804 | accuracy: 0.83515625 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4380279268537249 | accuracy: 0.8377976190476191 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.43361181427132 | accuracy: 0.8373579545454546 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4386059291984724 | accuracy: 0.8355978260869565 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4589545714358489 | accuracy: 0.83203125 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.46599290013313294 | accuracy: 0.829375 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4625575588299678 | accuracy: 0.8311298076923077 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.45538107995633725 | accuracy: 0.8339120370370371 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4587702027388981 | accuracy: 0.8314732142857143 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.45711420836119815 | accuracy: 0.8324353448275862 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4537707765897115 | accuracy: 0.8338541666666667 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.44864964485168457 | accuracy: 0.8366935483870968 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.45157808251678944 | accuracy: 0.8349609375 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.45245545199423126 | accuracy: 0.8333333333333334 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.45669134224162383 | accuracy: 0.8318014705882353 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.45967202867780416 | accuracy: 0.8308035714285714 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.456999765502082 | accuracy: 0.8328993055555556 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4575446312491958 | accuracy: 0.8319256756756757 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.46098404495339645 | accuracy: 0.8322368421052632 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.46036964425673854 | accuracy: 0.8313301282051282 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4562609203159809 | accuracy: 0.833203125 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4527959678231216 | accuracy: 0.8334603658536586 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.44831148854323793 | accuracy: 0.8344494047619048 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.44768549952396125 | accuracy: 0.8353924418604651 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.44959458844228223 | accuracy: 0.8348721590909091 \n",
      "Validation | Epoch 17 | Step 6851 | loss: 0.4483521560827891 | accuracy: 0.8346769319640266 \n",
      "Epoch 18 | Step 6852 | loss: 0.3441865146160126 | accuracy: 0.859375 \n",
      "Epoch 18 | Step 6853 | loss: 0.23889904469251633 | accuracy: 0.90625 \n",
      "Epoch 18 | Step 6854 | loss: 0.21543030440807343 | accuracy: 0.9166666666666666 \n",
      "Epoch 18 | Step 6855 | loss: 0.2256723903119564 | accuracy: 0.9140625 \n",
      "Epoch 18 | Step 6856 | loss: 0.20910974442958832 | accuracy: 0.91875 \n",
      "Epoch 18 | Step 6857 | loss: 0.2022551173965136 | accuracy: 0.9166666666666666 \n",
      "Epoch 18 | Step 6858 | loss: 0.20363078372819082 | accuracy: 0.9151785714285714 \n",
      "Epoch 18 | Step 6859 | loss: 0.2033926248550415 | accuracy: 0.91796875 \n",
      "Epoch 18 | Step 6860 | loss: 0.20951485633850098 | accuracy: 0.9201388888888888 \n",
      "Epoch 18 | Step 6861 | loss: 0.21804890036582947 | accuracy: 0.9171875 \n",
      "Epoch 18 | Step 6862 | loss: 0.21103668483820828 | accuracy: 0.921875 \n",
      "Epoch 18 | Step 6863 | loss: 0.20523298159241676 | accuracy: 0.9192708333333334 \n",
      "Epoch 18 | Step 6864 | loss: 0.21958430111408234 | accuracy: 0.9122596153846154 \n",
      "Epoch 18 | Step 6865 | loss: 0.2167954444885254 | accuracy: 0.9140625 \n",
      "Epoch 18 | Step 6866 | loss: 0.21953594088554382 | accuracy: 0.9125 \n",
      "Epoch 18 | Step 6867 | loss: 0.21238734247162938 | accuracy: 0.916015625 \n",
      "Epoch 18 | Step 6868 | loss: 0.21246887261376662 | accuracy: 0.9145220588235294 \n",
      "Epoch 18 | Step 6869 | loss: 0.21082138477100265 | accuracy: 0.9166666666666666 \n",
      "Epoch 18 | Step 6870 | loss: 0.20879558316971125 | accuracy: 0.915296052631579 \n",
      "Epoch 18 | Step 6871 | loss: 0.2105041090399027 | accuracy: 0.9140625 \n",
      "Epoch 18 | Step 6872 | loss: 0.21116045578604653 | accuracy: 0.9136904761904762 \n",
      "Epoch 18 | Step 6873 | loss: 0.21455738388679244 | accuracy: 0.9133522727272727 \n",
      "Epoch 18 | Step 6874 | loss: 0.21156121434076972 | accuracy: 0.9150815217391305 \n",
      "Epoch 18 | Step 6875 | loss: 0.21206178609281778 | accuracy: 0.9147135416666666 \n",
      "Epoch 18 | Step 6876 | loss: 0.2163214036822319 | accuracy: 0.91125 \n",
      "Epoch 18 | Step 6877 | loss: 0.2147350233907883 | accuracy: 0.9116586538461539 \n",
      "Epoch 18 | Step 6878 | loss: 0.22093213515149224 | accuracy: 0.9103009259259259 \n",
      "Epoch 18 | Step 6879 | loss: 0.21823845085288798 | accuracy: 0.9112723214285714 \n",
      "Epoch 18 | Step 6880 | loss: 0.2211245383168089 | accuracy: 0.9105603448275862 \n",
      "Epoch 18 | Step 6881 | loss: 0.2203954391181469 | accuracy: 0.9098958333333333 \n",
      "Epoch 18 | Step 6882 | loss: 0.21849771348699445 | accuracy: 0.9107862903225806 \n",
      "Epoch 18 | Step 6883 | loss: 0.21854057000018656 | accuracy: 0.91064453125 \n",
      "Epoch 18 | Step 6884 | loss: 0.2181055493878596 | accuracy: 0.9114583333333334 \n",
      "Epoch 18 | Step 6885 | loss: 0.215324554592371 | accuracy: 0.9131433823529411 \n",
      "Epoch 18 | Step 6886 | loss: 0.21219909957477023 | accuracy: 0.9147321428571429 \n",
      "Epoch 18 | Step 6887 | loss: 0.20973319415416983 | accuracy: 0.9157986111111112 \n",
      "Epoch 18 | Step 6888 | loss: 0.20951055131248525 | accuracy: 0.9151182432432432 \n",
      "Epoch 18 | Step 6889 | loss: 0.20906261805641024 | accuracy: 0.9148848684210527 \n",
      "Epoch 18 | Step 6890 | loss: 0.20737765824947602 | accuracy: 0.9154647435897436 \n",
      "Epoch 18 | Step 6891 | loss: 0.20554765593260527 | accuracy: 0.916796875 \n",
      "Epoch 18 | Step 6892 | loss: 0.20477652967703053 | accuracy: 0.9161585365853658 \n",
      "Epoch 18 | Step 6893 | loss: 0.20561620504373596 | accuracy: 0.9151785714285714 \n",
      "Epoch 18 | Step 6894 | loss: 0.20379063435072123 | accuracy: 0.9160610465116279 \n",
      "Epoch 18 | Step 6895 | loss: 0.2023416579785672 | accuracy: 0.9172585227272727 \n",
      "Epoch 18 | Step 6896 | loss: 0.2026280563738611 | accuracy: 0.9180555555555555 \n",
      "Epoch 18 | Step 6897 | loss: 0.20385671973876332 | accuracy: 0.9181385869565217 \n",
      "Epoch 18 | Step 6898 | loss: 0.20359905840868645 | accuracy: 0.9185505319148937 \n",
      "Epoch 18 | Step 6899 | loss: 0.20397471931452552 | accuracy: 0.9189453125 \n",
      "Epoch 18 | Step 6900 | loss: 0.20496219807133384 | accuracy: 0.9190051020408163 \n",
      "Epoch 18 | Step 6901 | loss: 0.20589461490511896 | accuracy: 0.918125 \n",
      "Epoch 18 | Step 6902 | loss: 0.20582703822383694 | accuracy: 0.9175857843137255 \n",
      "Epoch 18 | Step 6903 | loss: 0.2039158774109987 | accuracy: 0.9182692307692307 \n",
      "Epoch 18 | Step 6904 | loss: 0.20536480253597475 | accuracy: 0.9180424528301887 \n",
      "Epoch 18 | Step 6905 | loss: 0.20427912501273332 | accuracy: 0.9184027777777778 \n",
      "Epoch 18 | Step 6906 | loss: 0.20632808343930678 | accuracy: 0.9176136363636364 \n",
      "Epoch 18 | Step 6907 | loss: 0.2055231010807412 | accuracy: 0.91796875 \n",
      "Epoch 18 | Step 6908 | loss: 0.2065022590390423 | accuracy: 0.9174890350877193 \n",
      "Epoch 18 | Step 6909 | loss: 0.20707499467093368 | accuracy: 0.9167564655172413 \n",
      "Epoch 18 | Step 6910 | loss: 0.20846147911023286 | accuracy: 0.9157838983050848 \n",
      "Epoch 18 | Step 6911 | loss: 0.20920001914103825 | accuracy: 0.9161458333333333 \n",
      "Epoch 18 | Step 6912 | loss: 0.20908720571486678 | accuracy: 0.9162397540983607 \n",
      "Epoch 18 | Step 6913 | loss: 0.2083771675825119 | accuracy: 0.9165826612903226 \n",
      "Epoch 18 | Step 6914 | loss: 0.2096848762224591 | accuracy: 0.9154265873015873 \n",
      "Epoch 18 | Step 6915 | loss: 0.20820837479550391 | accuracy: 0.916015625 \n",
      "Epoch 18 | Step 6916 | loss: 0.20655304468595065 | accuracy: 0.916826923076923 \n",
      "Epoch 18 | Step 6917 | loss: 0.20577643698815143 | accuracy: 0.9169034090909091 \n",
      "Epoch 18 | Step 6918 | loss: 0.2047791859107231 | accuracy: 0.9172108208955224 \n",
      "Epoch 18 | Step 6919 | loss: 0.204745845102212 | accuracy: 0.9172794117647058 \n",
      "Epoch 18 | Step 6920 | loss: 0.20436376700366754 | accuracy: 0.9173460144927537 \n",
      "Epoch 18 | Step 6921 | loss: 0.20337131853614535 | accuracy: 0.9176339285714286 \n",
      "Epoch 18 | Step 6922 | loss: 0.20187625341432194 | accuracy: 0.918794014084507 \n",
      "Epoch 18 | Step 6923 | loss: 0.20195576000130838 | accuracy: 0.9190538194444444 \n",
      "Epoch 18 | Step 6924 | loss: 0.2022635594826855 | accuracy: 0.9184503424657534 \n",
      "Epoch 18 | Step 6925 | loss: 0.20249526998078501 | accuracy: 0.9180743243243243 \n",
      "Epoch 18 | Step 6926 | loss: 0.2022425694266955 | accuracy: 0.918125 \n",
      "Epoch 18 | Step 6927 | loss: 0.20258097928997718 | accuracy: 0.9181743421052632 \n",
      "Epoch 18 | Step 6928 | loss: 0.20237477288230674 | accuracy: 0.9180194805194806 \n",
      "Epoch 18 | Step 6929 | loss: 0.2028643273963378 | accuracy: 0.9176682692307693 \n",
      "Epoch 18 | Step 6930 | loss: 0.20497518504344964 | accuracy: 0.9175237341772152 \n",
      "Epoch 18 | Step 6931 | loss: 0.20461848387494683 | accuracy: 0.9173828125 \n",
      "Epoch 18 | Step 6932 | loss: 0.2038789670224543 | accuracy: 0.9178240740740741 \n",
      "Epoch 18 | Step 6933 | loss: 0.2031022587382212 | accuracy: 0.9182545731707317 \n",
      "Epoch 18 | Step 6934 | loss: 0.20292191054806652 | accuracy: 0.9188629518072289 \n",
      "Epoch 18 | Step 6935 | loss: 0.20269592842530637 | accuracy: 0.9188988095238095 \n",
      "Epoch 18 | Step 6936 | loss: 0.20204557715093388 | accuracy: 0.9193014705882353 \n",
      "Epoch 18 | Step 6937 | loss: 0.20164812070339225 | accuracy: 0.9195130813953488 \n",
      "Epoch 18 | Step 6938 | loss: 0.20408023165902872 | accuracy: 0.9186422413793104 \n",
      "Epoch 18 | Step 6939 | loss: 0.20427980536425655 | accuracy: 0.9186789772727273 \n",
      "Epoch 18 | Step 6940 | loss: 0.20317233956596825 | accuracy: 0.9190660112359551 \n",
      "Epoch 18 | Step 6941 | loss: 0.20387349733048016 | accuracy: 0.9190972222222222 \n",
      "Epoch 18 | Step 6942 | loss: 0.2028410011431673 | accuracy: 0.9194711538461539 \n",
      "Epoch 18 | Step 6943 | loss: 0.20239673660177251 | accuracy: 0.9198369565217391 \n",
      "Epoch 18 | Step 6944 | loss: 0.20229601948171533 | accuracy: 0.9195228494623656 \n",
      "Epoch 18 | Step 6945 | loss: 0.20145924801522114 | accuracy: 0.9198803191489362 \n",
      "Epoch 18 | Step 6946 | loss: 0.20183900798621932 | accuracy: 0.9197368421052632 \n",
      "Epoch 18 | Step 6947 | loss: 0.20338307212417325 | accuracy: 0.91943359375 \n",
      "Epoch 18 | Step 6948 | loss: 0.2031984363020081 | accuracy: 0.9194587628865979 \n",
      "Epoch 18 | Step 6949 | loss: 0.20441604177562558 | accuracy: 0.9193239795918368 \n",
      "Epoch 18 | Step 6950 | loss: 0.20446299678749508 | accuracy: 0.9198232323232324 \n",
      "Epoch 18 | Step 6951 | loss: 0.20361471757292748 | accuracy: 0.9203125 \n",
      "Epoch 18 | Step 6952 | loss: 0.20251909606527574 | accuracy: 0.9209467821782178 \n",
      "Epoch 18 | Step 6953 | loss: 0.20248330968852138 | accuracy: 0.921109068627451 \n",
      "Epoch 18 | Step 6954 | loss: 0.2015025311882056 | accuracy: 0.9214199029126213 \n",
      "Epoch 18 | Step 6955 | loss: 0.20224420869579682 | accuracy: 0.9211237980769231 \n",
      "Epoch 18 | Step 6956 | loss: 0.2036163378329504 | accuracy: 0.9208333333333333 \n",
      "Epoch 18 | Step 6957 | loss: 0.20283340149611798 | accuracy: 0.9212853773584906 \n",
      "Epoch 18 | Step 6958 | loss: 0.20365894488363623 | accuracy: 0.9208528037383178 \n",
      "Epoch 18 | Step 6959 | loss: 0.20463377934087207 | accuracy: 0.9208622685185185 \n",
      "Epoch 18 | Step 6960 | loss: 0.20478741503363357 | accuracy: 0.9208715596330275 \n",
      "Epoch 18 | Step 6961 | loss: 0.20536891729994253 | accuracy: 0.920596590909091 \n",
      "Epoch 18 | Step 6962 | loss: 0.20474422910997458 | accuracy: 0.9208896396396397 \n",
      "Epoch 18 | Step 6963 | loss: 0.20451200161395328 | accuracy: 0.9211774553571429 \n",
      "Epoch 18 | Step 6964 | loss: 0.2053031031932451 | accuracy: 0.9210453539823009 \n",
      "Epoch 18 | Step 6965 | loss: 0.2053161400059859 | accuracy: 0.9211896929824561 \n",
      "Epoch 18 | Step 6966 | loss: 0.20491264792888061 | accuracy: 0.9211956521739131 \n",
      "Epoch 18 | Step 6967 | loss: 0.20479997035501332 | accuracy: 0.9212015086206896 \n",
      "Epoch 18 | Step 6968 | loss: 0.205659936572242 | accuracy: 0.9206730769230769 \n",
      "Epoch 18 | Step 6969 | loss: 0.2055741734802723 | accuracy: 0.9206832627118644 \n",
      "Epoch 18 | Step 6970 | loss: 0.20589500609315745 | accuracy: 0.9208245798319328 \n",
      "Epoch 18 | Step 6971 | loss: 0.20560950705160697 | accuracy: 0.9208333333333333 \n",
      "Epoch 18 | Step 6972 | loss: 0.20562018509492402 | accuracy: 0.9208419421487604 \n",
      "Epoch 18 | Step 6973 | loss: 0.20541416896415537 | accuracy: 0.920594262295082 \n",
      "Epoch 18 | Step 6974 | loss: 0.20531201925946446 | accuracy: 0.9204776422764228 \n",
      "Epoch 18 | Step 6975 | loss: 0.20531391502628404 | accuracy: 0.9207409274193549 \n",
      "Epoch 18 | Step 6976 | loss: 0.20544168573617935 | accuracy: 0.920625 \n",
      "Epoch 18 | Step 6977 | loss: 0.20554702427415622 | accuracy: 0.9206349206349206 \n",
      "Epoch 18 | Step 6978 | loss: 0.2061766488697585 | accuracy: 0.9203986220472441 \n",
      "Epoch 18 | Step 6979 | loss: 0.20577535108895972 | accuracy: 0.9202880859375 \n",
      "Epoch 18 | Step 6980 | loss: 0.20568550967199858 | accuracy: 0.9201792635658915 \n",
      "Epoch 18 | Step 6981 | loss: 0.205333022830578 | accuracy: 0.9201923076923076 \n",
      "Epoch 18 | Step 6982 | loss: 0.20596568201106924 | accuracy: 0.9198473282442748 \n",
      "Epoch 18 | Step 6983 | loss: 0.2067323075889638 | accuracy: 0.919625946969697 \n",
      "Epoch 18 | Step 6984 | loss: 0.2072283302370767 | accuracy: 0.9194078947368421 \n",
      "Epoch 18 | Step 6985 | loss: 0.20747816579332992 | accuracy: 0.9189598880597015 \n",
      "Epoch 18 | Step 6986 | loss: 0.20769604251340584 | accuracy: 0.9185185185185185 \n",
      "Epoch 18 | Step 6987 | loss: 0.2075660000281299 | accuracy: 0.9186580882352942 \n",
      "Epoch 18 | Step 6988 | loss: 0.20713556122823354 | accuracy: 0.9187956204379562 \n",
      "Epoch 18 | Step 6989 | loss: 0.20714720905474995 | accuracy: 0.9188179347826086 \n",
      "Epoch 18 | Step 6990 | loss: 0.20741644410563886 | accuracy: 0.918839928057554 \n",
      "Epoch 18 | Step 6991 | loss: 0.2074807071792228 | accuracy: 0.9188616071428571 \n",
      "Epoch 18 | Step 6992 | loss: 0.20846446867741592 | accuracy: 0.9185505319148937 \n",
      "Epoch 18 | Step 6993 | loss: 0.20852171876271006 | accuracy: 0.918794014084507 \n",
      "Epoch 18 | Step 6994 | loss: 0.20898407348594467 | accuracy: 0.9187062937062938 \n",
      "Epoch 18 | Step 6995 | loss: 0.20905829743585652 | accuracy: 0.9186197916666666 \n",
      "Epoch 18 | Step 6996 | loss: 0.2089157247851635 | accuracy: 0.91875 \n",
      "Epoch 18 | Step 6997 | loss: 0.20924999876177475 | accuracy: 0.9184503424657534 \n",
      "Epoch 18 | Step 6998 | loss: 0.20838591608465934 | accuracy: 0.9190051020408163 \n",
      "Epoch 18 | Step 6999 | loss: 0.2083606803538026 | accuracy: 0.9191300675675675 \n",
      "Epoch 18 | Step 7000 | loss: 0.2079932051617027 | accuracy: 0.91935822147651 \n",
      "Epoch 18 | Step 7001 | loss: 0.208465762535731 | accuracy: 0.9192708333333334 \n",
      "Epoch 18 | Step 7002 | loss: 0.20887785301303233 | accuracy: 0.9191846026490066 \n",
      "Epoch 18 | Step 7003 | loss: 0.21026596623031715 | accuracy: 0.9188939144736842 \n",
      "Epoch 18 | Step 7004 | loss: 0.21054415843066046 | accuracy: 0.9189133986928104 \n",
      "Epoch 18 | Step 7005 | loss: 0.2100714704433045 | accuracy: 0.919237012987013 \n",
      "Epoch 18 | Step 7006 | loss: 0.20986165423547068 | accuracy: 0.9193548387096774 \n",
      "Epoch 18 | Step 7007 | loss: 0.20922508974296924 | accuracy: 0.9195713141025641 \n",
      "Epoch 18 | Step 7008 | loss: 0.20902748334749488 | accuracy: 0.9197850318471338 \n",
      "Epoch 18 | Step 7009 | loss: 0.20914601784529566 | accuracy: 0.919501582278481 \n",
      "Epoch 18 | Step 7010 | loss: 0.20933589334570388 | accuracy: 0.9190251572327044 \n",
      "Epoch 18 | Step 7011 | loss: 0.20954527850262822 | accuracy: 0.91884765625 \n",
      "Epoch 18 | Step 7012 | loss: 0.209666290499779 | accuracy: 0.9187694099378882 \n",
      "Epoch 18 | Step 7013 | loss: 0.20949699973434577 | accuracy: 0.9188850308641975 \n",
      "Epoch 18 | Step 7014 | loss: 0.21078186875289204 | accuracy: 0.9183282208588958 \n",
      "Epoch 18 | Step 7015 | loss: 0.2107052618137947 | accuracy: 0.9182545731707317 \n",
      "Epoch 18 | Step 7016 | loss: 0.21049327836795287 | accuracy: 0.9183712121212121 \n",
      "Epoch 18 | Step 7017 | loss: 0.21092459653694945 | accuracy: 0.9181099397590361 \n",
      "Epoch 18 | Step 7018 | loss: 0.21071858539017374 | accuracy: 0.9182260479041916 \n",
      "Epoch 18 | Step 7019 | loss: 0.2112979976282943 | accuracy: 0.91796875 \n",
      "Epoch 18 | Step 7020 | loss: 0.21096249387638102 | accuracy: 0.9180843195266272 \n",
      "Epoch 18 | Step 7021 | loss: 0.2102132370805039 | accuracy: 0.9184742647058823 \n",
      "Epoch 18 | Step 7022 | loss: 0.21017395521987947 | accuracy: 0.9185855263157895 \n",
      "Epoch 18 | Step 7023 | loss: 0.21030127122824968 | accuracy: 0.9183321220930233 \n",
      "Epoch 18 | Step 7024 | loss: 0.20993452019601888 | accuracy: 0.9186235549132948 \n",
      "Epoch 18 | Step 7025 | loss: 0.21022655716401406 | accuracy: 0.9186422413793104 \n",
      "Epoch 18 | Step 7026 | loss: 0.21015098133257457 | accuracy: 0.9188392857142857 \n",
      "Epoch 18 | Step 7027 | loss: 0.21084920710630037 | accuracy: 0.9185901988636364 \n",
      "Epoch 18 | Step 7028 | loss: 0.21152057692324375 | accuracy: 0.9184322033898306 \n",
      "Epoch 18 | Step 7029 | loss: 0.21194382652305485 | accuracy: 0.9181004213483146 \n",
      "Epoch 18 | Step 7030 | loss: 0.21247474895009782 | accuracy: 0.9179469273743017 \n",
      "Epoch 18 | Step 7031 | loss: 0.21221732079154915 | accuracy: 0.91796875 \n",
      "Epoch 18 | Step 7032 | loss: 0.2123516754797809 | accuracy: 0.9177313535911602 \n",
      "Epoch 18 | Step 7033 | loss: 0.21217071973196752 | accuracy: 0.9177541208791209 \n",
      "Epoch 18 | Step 7034 | loss: 0.21161966001401183 | accuracy: 0.9178620218579235 \n",
      "Epoch 18 | Step 7035 | loss: 0.21119123948333057 | accuracy: 0.9180536684782609 \n",
      "Epoch 18 | Step 7036 | loss: 0.21091000204150742 | accuracy: 0.9180743243243243 \n",
      "Epoch 18 | Step 7037 | loss: 0.21112110930424866 | accuracy: 0.917926747311828 \n",
      "Epoch 18 | Step 7038 | loss: 0.21167141047709767 | accuracy: 0.917697192513369 \n",
      "Epoch 18 | Step 7039 | loss: 0.211850929529743 | accuracy: 0.917470079787234 \n",
      "Epoch 18 | Step 7040 | loss: 0.2116990318847081 | accuracy: 0.9174107142857143 \n",
      "Epoch 18 | Step 7041 | loss: 0.21250962764024733 | accuracy: 0.9170230263157895 \n",
      "Epoch 18 | Step 7042 | loss: 0.2119851549258407 | accuracy: 0.9172938481675392 \n",
      "Epoch 18 | Step 7043 | loss: 0.211798130068928 | accuracy: 0.9173990885416666 \n",
      "Epoch 18 | Step 7044 | loss: 0.21144502428529177 | accuracy: 0.9176651554404145 \n",
      "Epoch 18 | Step 7045 | loss: 0.21127312154192285 | accuracy: 0.9177673969072165 \n",
      "Epoch 18 | Step 7046 | loss: 0.21091641577390524 | accuracy: 0.9178685897435898 \n",
      "Epoch 18 | Step 7047 | loss: 0.21085341259533044 | accuracy: 0.9178093112244898 \n",
      "Epoch 18 | Step 7048 | loss: 0.21088212032608575 | accuracy: 0.9178299492385786 \n",
      "Epoch 18 | Step 7049 | loss: 0.2110530303584205 | accuracy: 0.9177714646464646 \n",
      "Epoch 18 | Step 7050 | loss: 0.2109718705391764 | accuracy: 0.917949120603015 \n",
      "Epoch 18 | Step 7051 | loss: 0.21079151675105096 | accuracy: 0.91796875 \n",
      "Epoch 18 | Step 7052 | loss: 0.21128100972270492 | accuracy: 0.9177549751243781 \n",
      "Epoch 18 | Step 7053 | loss: 0.2113082130799199 | accuracy: 0.9178527227722773 \n",
      "Epoch 18 | Step 7054 | loss: 0.21127150226109134 | accuracy: 0.9179495073891626 \n",
      "Epoch 18 | Step 7055 | loss: 0.21114598141581403 | accuracy: 0.9180453431372549 \n",
      "Epoch 18 | Step 7056 | loss: 0.21132844279452068 | accuracy: 0.9178353658536585 \n",
      "Epoch 18 | Step 7057 | loss: 0.21210360064089878 | accuracy: 0.917627427184466 \n",
      "Epoch 18 | Step 7058 | loss: 0.21299693132368264 | accuracy: 0.917572463768116 \n",
      "Epoch 18 | Step 7059 | loss: 0.21298885323966926 | accuracy: 0.9175180288461539 \n",
      "Epoch 18 | Step 7060 | loss: 0.21286634758613895 | accuracy: 0.9176136363636364 \n",
      "Epoch 18 | Step 7061 | loss: 0.21299896772418703 | accuracy: 0.9177827380952381 \n",
      "Epoch 18 | Step 7062 | loss: 0.2133194936254013 | accuracy: 0.9177280805687204 \n",
      "Epoch 18 | Step 7063 | loss: 0.21279170979165807 | accuracy: 0.91796875 \n",
      "Epoch 18 | Step 7064 | loss: 0.21239031903760533 | accuracy: 0.9181338028169014 \n",
      "Epoch 18 | Step 7065 | loss: 0.21238666400313377 | accuracy: 0.9182242990654206 \n",
      "Epoch 18 | Step 7066 | loss: 0.21214662156132766 | accuracy: 0.9183866279069768 \n",
      "Epoch 18 | Step 7067 | loss: 0.21207925253030327 | accuracy: 0.9184751157407407 \n",
      "Epoch 18 | Step 7068 | loss: 0.21176827966754888 | accuracy: 0.9185627880184332 \n",
      "Epoch 18 | Step 7069 | loss: 0.2116452034802065 | accuracy: 0.9186496559633027 \n",
      "Epoch 18 | Step 7070 | loss: 0.21166699624633137 | accuracy: 0.9186643835616438 \n",
      "Epoch 18 | Step 7071 | loss: 0.21156099563972516 | accuracy: 0.9186789772727273 \n",
      "Epoch 18 | Step 7072 | loss: 0.21157291022495986 | accuracy: 0.9187641402714932 \n",
      "Epoch 18 | Step 7073 | loss: 0.21158428077359456 | accuracy: 0.918848536036036 \n",
      "Epoch 18 | Step 7074 | loss: 0.21163413319486138 | accuracy: 0.9187219730941704 \n",
      "Epoch 18 | Step 7075 | loss: 0.21105620700732938 | accuracy: 0.9190848214285714 \n",
      "Epoch 18 | Step 7076 | loss: 0.21117225372129017 | accuracy: 0.9188888888888889 \n",
      "Epoch 18 | Step 7077 | loss: 0.2113805338410677 | accuracy: 0.9186946902654868 \n",
      "Epoch 18 | Step 7078 | loss: 0.21149585737399593 | accuracy: 0.9186398678414097 \n",
      "Epoch 18 | Step 7079 | loss: 0.21165062843315435 | accuracy: 0.9186540570175439 \n",
      "Epoch 18 | Step 7080 | loss: 0.2115603678546618 | accuracy: 0.9187363537117904 \n",
      "Epoch 18 | Step 7081 | loss: 0.21152524789390356 | accuracy: 0.91875 \n",
      "Epoch 18 | Step 7082 | loss: 0.21132765016901545 | accuracy: 0.9189664502164502 \n",
      "Epoch 18 | Step 7083 | loss: 0.21098225322905287 | accuracy: 0.9190463362068966 \n",
      "Epoch 18 | Step 7084 | loss: 0.21087672721290793 | accuracy: 0.9189243562231759 \n",
      "Epoch 18 | Step 7085 | loss: 0.21088874597962087 | accuracy: 0.9190037393162394 \n",
      "Epoch 18 | Step 7086 | loss: 0.21070778810597482 | accuracy: 0.9190824468085106 \n",
      "Epoch 18 | Step 7087 | loss: 0.21044670806219012 | accuracy: 0.9192266949152542 \n",
      "Epoch 18 | Step 7088 | loss: 0.21030911284534237 | accuracy: 0.9192378691983122 \n",
      "Epoch 18 | Step 7089 | loss: 0.2103168347365215 | accuracy: 0.9192489495798319 \n",
      "Epoch 18 | Step 7090 | loss: 0.21039960115649212 | accuracy: 0.9191291841004184 \n",
      "Epoch 18 | Step 7091 | loss: 0.21041713322823247 | accuracy: 0.9190104166666667 \n",
      "Epoch 18 | Step 7092 | loss: 0.2099678180029778 | accuracy: 0.9191519709543569 \n",
      "Epoch 18 | Step 7093 | loss: 0.209767267723714 | accuracy: 0.9192277892561983 \n",
      "Epoch 18 | Step 7094 | loss: 0.2102383528471974 | accuracy: 0.9191100823045267 \n",
      "Epoch 18 | Step 7095 | loss: 0.2105903261509098 | accuracy: 0.9189933401639344 \n",
      "Epoch 18 | Step 7096 | loss: 0.2103833730123481 | accuracy: 0.9190688775510204 \n",
      "Epoch 18 | Step 7097 | loss: 0.21037714740609734 | accuracy: 0.919016768292683 \n",
      "Epoch 18 | Step 7098 | loss: 0.21002706408741986 | accuracy: 0.9191548582995951 \n",
      "Epoch 18 | Step 7099 | loss: 0.2101668898136385 | accuracy: 0.9191028225806451 \n",
      "Epoch 18 | Step 7100 | loss: 0.20992558195169672 | accuracy: 0.9191767068273092 \n",
      "Epoch 18 | Step 7101 | loss: 0.20997658514976503 | accuracy: 0.91925 \n",
      "Epoch 18 | Step 7102 | loss: 0.20968960421493804 | accuracy: 0.9194472111553785 \n",
      "Epoch 18 | Step 7103 | loss: 0.20960692434556902 | accuracy: 0.9193948412698413 \n",
      "Epoch 18 | Step 7104 | loss: 0.20945857318022507 | accuracy: 0.9195281620553359 \n",
      "Epoch 18 | Step 7105 | loss: 0.20947185364060514 | accuracy: 0.9196604330708661 \n",
      "Epoch 18 | Step 7106 | loss: 0.2094845538630205 | accuracy: 0.9196691176470588 \n",
      "Epoch 18 | Step 7107 | loss: 0.2096916119917296 | accuracy: 0.9195556640625 \n",
      "Epoch 18 | Step 7108 | loss: 0.20943337371609091 | accuracy: 0.9197470817120622 \n",
      "Epoch 18 | Step 7109 | loss: 0.20913253250972244 | accuracy: 0.9197553294573644 \n",
      "Epoch 18 | Step 7110 | loss: 0.20934699734665713 | accuracy: 0.919582528957529 \n",
      "Epoch 18 | Step 7111 | loss: 0.2091307373574147 | accuracy: 0.91953125 \n",
      "Epoch 18 | Step 7112 | loss: 0.20954730484449086 | accuracy: 0.9192409003831418 \n",
      "Epoch 18 | Step 7113 | loss: 0.20974742359559953 | accuracy: 0.9190720419847328 \n",
      "Epoch 18 | Step 7114 | loss: 0.20953721567251835 | accuracy: 0.919023288973384 \n",
      "Epoch 18 | Step 7115 | loss: 0.2100872845586502 | accuracy: 0.9187973484848485 \n",
      "Epoch 18 | Step 7116 | loss: 0.20995337608850226 | accuracy: 0.91875 \n",
      "Epoch 18 | Step 7117 | loss: 0.2099958052088443 | accuracy: 0.918703007518797 \n",
      "Epoch 18 | Step 7118 | loss: 0.20982006850760526 | accuracy: 0.9187148876404494 \n",
      "Epoch 18 | Step 7119 | loss: 0.20958821008454506 | accuracy: 0.9188432835820896 \n",
      "Epoch 18 | Step 7120 | loss: 0.2095339263903607 | accuracy: 0.9188545539033457 \n",
      "Epoch 18 | Step 7121 | loss: 0.20935057037406496 | accuracy: 0.9189236111111111 \n",
      "Epoch 18 | Step 7122 | loss: 0.20929432954515476 | accuracy: 0.9189345018450185 \n",
      "Epoch 18 | Step 7123 | loss: 0.20919753326212656 | accuracy: 0.9189453125 \n",
      "Epoch 18 | Step 7124 | loss: 0.20943715840905575 | accuracy: 0.9186698717948718 \n",
      "Epoch 18 | Step 7125 | loss: 0.20936786318129863 | accuracy: 0.9186245437956204 \n",
      "Epoch 18 | Step 7126 | loss: 0.20930881749499924 | accuracy: 0.9185795454545455 \n",
      "Epoch 18 | Step 7127 | loss: 0.2094879390104957 | accuracy: 0.918365036231884 \n",
      "Epoch 18 | Step 7128 | loss: 0.20942472486289396 | accuracy: 0.9183777075812274 \n",
      "Epoch 18 | Step 7129 | loss: 0.20936905592679972 | accuracy: 0.9184464928057554 \n",
      "Epoch 18 | Step 7130 | loss: 0.20931026104530548 | accuracy: 0.918290770609319 \n",
      "Epoch 18 | Step 7131 | loss: 0.2091801383133445 | accuracy: 0.9184151785714286 \n",
      "Epoch 18 | Step 7132 | loss: 0.20973654791341553 | accuracy: 0.9180938612099644 \n",
      "Epoch 18 | Step 7133 | loss: 0.20955965456599035 | accuracy: 0.9181626773049646 \n",
      "Epoch 18 | Step 7134 | loss: 0.20944873351511598 | accuracy: 0.9182862190812721 \n",
      "Epoch 18 | Step 7135 | loss: 0.2093126206645663 | accuracy: 0.9183538732394366 \n",
      "Epoch 18 | Step 7136 | loss: 0.20908730803874495 | accuracy: 0.918530701754386 \n",
      "Epoch 18 | Step 7137 | loss: 0.20912979782878097 | accuracy: 0.9184331293706294 \n",
      "Epoch 18 | Step 7138 | loss: 0.2090586960211863 | accuracy: 0.9184451219512195 \n",
      "Epoch 18 | Step 7139 | loss: 0.20880430098623032 | accuracy: 0.9185655381944444 \n",
      "Epoch 18 | Step 7140 | loss: 0.20860617981650006 | accuracy: 0.9185769896193772 \n",
      "Epoch 18 | Step 7141 | loss: 0.20894585190148185 | accuracy: 0.9184806034482759 \n",
      "Epoch 18 | Step 7142 | loss: 0.20878559366329424 | accuracy: 0.9185996563573883 \n",
      "Epoch 18 | Step 7143 | loss: 0.20884423973421523 | accuracy: 0.9186108732876712 \n",
      "Epoch 18 | Step 7144 | loss: 0.20886951028893827 | accuracy: 0.9186753412969283 \n",
      "Epoch 18 | Step 7145 | loss: 0.20853720985505042 | accuracy: 0.9187925170068028 \n",
      "Epoch 18 | Step 7146 | loss: 0.20874226482237795 | accuracy: 0.918697033898305 \n",
      "Epoch 18 | Step 7147 | loss: 0.20874736780250389 | accuracy: 0.9186021959459459 \n",
      "Epoch 18 | Step 7148 | loss: 0.2090705596035979 | accuracy: 0.9184027777777778 \n",
      "Epoch 18 | Step 7149 | loss: 0.2089024491658146 | accuracy: 0.9184668624161074 \n",
      "Epoch 18 | Step 7150 | loss: 0.20874292999007624 | accuracy: 0.9184782608695652 \n",
      "Epoch 18 | Step 7151 | loss: 0.20870973363518708 | accuracy: 0.9184895833333333 \n",
      "Epoch 18 | Step 7152 | loss: 0.20852520680704775 | accuracy: 0.9186046511627907 \n",
      "Epoch 18 | Step 7153 | loss: 0.20842553443269218 | accuracy: 0.9185637417218543 \n",
      "Epoch 18 | Step 7154 | loss: 0.20818896980175478 | accuracy: 0.9186262376237624 \n",
      "Epoch 18 | Step 7155 | loss: 0.20808817931499912 | accuracy: 0.9186369243421053 \n",
      "Epoch 18 | Step 7156 | loss: 0.2084504031255596 | accuracy: 0.9184426229508197 \n",
      "Epoch 18 | Step 7157 | loss: 0.20824694988969095 | accuracy: 0.9186580882352942 \n",
      "Epoch 18 | Step 7158 | loss: 0.20810452016246425 | accuracy: 0.9188212540716613 \n",
      "Epoch 18 | Step 7159 | loss: 0.20780129002576514 | accuracy: 0.9189833603896104 \n",
      "Epoch 18 | Step 7160 | loss: 0.20745094846270992 | accuracy: 0.9191444174757282 \n",
      "Epoch 18 | Step 7161 | loss: 0.20742057309516004 | accuracy: 0.919203629032258 \n",
      "Epoch 18 | Step 7162 | loss: 0.20730782285859722 | accuracy: 0.9193127009646302 \n",
      "Epoch 18 | Step 7163 | loss: 0.20727095349381358 | accuracy: 0.9193209134615384 \n",
      "Epoch 18 | Step 7164 | loss: 0.207062530750855 | accuracy: 0.9194289137380192 \n",
      "Epoch 18 | Step 7165 | loss: 0.2069927628395283 | accuracy: 0.9193869426751592 \n",
      "Epoch 18 | Step 7166 | loss: 0.20661291770991816 | accuracy: 0.9195436507936507 \n",
      "Epoch 18 | Step 7167 | loss: 0.20669191719704783 | accuracy: 0.9196004746835443 \n",
      "Epoch 18 | Step 7168 | loss: 0.20658034868890923 | accuracy: 0.919558359621451 \n",
      "Epoch 18 | Step 7169 | loss: 0.2066027453438665 | accuracy: 0.9196147798742138 \n",
      "Epoch 18 | Step 7170 | loss: 0.20647229480799453 | accuracy: 0.9196218652037618 \n",
      "Epoch 18 | Step 7171 | loss: 0.20626061793882391 | accuracy: 0.9197265625 \n",
      "Epoch 18 | Step 7172 | loss: 0.20632815414407163 | accuracy: 0.9197332554517134 \n",
      "Epoch 18 | Step 7173 | loss: 0.20626973825859718 | accuracy: 0.9198854813664596 \n",
      "Epoch 18 | Step 7174 | loss: 0.20627129080218048 | accuracy: 0.919891640866873 \n",
      "Epoch 18 | Step 7175 | loss: 0.20621029432449067 | accuracy: 0.9198495370370371 \n",
      "Epoch 18 | Step 7176 | loss: 0.20623440162493623 | accuracy: 0.9198076923076923 \n",
      "Epoch 18 | Step 7177 | loss: 0.20643722505931464 | accuracy: 0.919670245398773 \n",
      "Epoch 18 | Step 7178 | loss: 0.2065626017134123 | accuracy: 0.9195336391437309 \n",
      "Epoch 18 | Step 7179 | loss: 0.20662461927660347 | accuracy: 0.9195884146341463 \n",
      "Epoch 18 | Step 7180 | loss: 0.20634307026138413 | accuracy: 0.9197378419452887 \n",
      "Epoch 18 | Step 7181 | loss: 0.2062397234367601 | accuracy: 0.9196969696969697 \n",
      "Epoch 18 | Step 7182 | loss: 0.20623072369581255 | accuracy: 0.9196091389728097 \n",
      "Epoch 18 | Step 7183 | loss: 0.20613799657089155 | accuracy: 0.9196630271084337 \n",
      "Epoch 18 | Step 7184 | loss: 0.20606484924171772 | accuracy: 0.9197635135135135 \n",
      "Epoch 18 | Step 7185 | loss: 0.20604943948056162 | accuracy: 0.9198166167664671 \n",
      "Epoch 18 | Step 7186 | loss: 0.20604600457113173 | accuracy: 0.9198227611940298 \n",
      "Epoch 18 | Step 7187 | loss: 0.20612499880648785 | accuracy: 0.9197823660714286 \n",
      "Epoch 18 | Step 7188 | loss: 0.20600121673915073 | accuracy: 0.9198813056379822 \n",
      "Epoch 18 | Step 7189 | loss: 0.20589036128577387 | accuracy: 0.919840976331361 \n",
      "Epoch 18 | Step 7190 | loss: 0.20566997578186264 | accuracy: 0.9199391592920354 \n",
      "Epoch 18 | Step 7191 | loss: 0.2055555619299411 | accuracy: 0.9200367647058824 \n",
      "Epoch 18 | Step 7192 | loss: 0.20565519964764886 | accuracy: 0.9199963343108505 \n",
      "Epoch 18 | Step 7193 | loss: 0.20561792906264803 | accuracy: 0.9199561403508771 \n",
      "Epoch 18 | Step 7194 | loss: 0.20546282658424037 | accuracy: 0.9200983965014577 \n",
      "Epoch 18 | Step 7195 | loss: 0.20540339395750393 | accuracy: 0.9200581395348837 \n",
      "Epoch 18 | Step 7196 | loss: 0.20529414847277205 | accuracy: 0.9201086956521739 \n",
      "Epoch 18 | Step 7197 | loss: 0.20518469082654547 | accuracy: 0.9202492774566474 \n",
      "Epoch 18 | Step 7198 | loss: 0.20512509380362554 | accuracy: 0.9203440201729106 \n",
      "Epoch 18 | Step 7199 | loss: 0.2049292264741727 | accuracy: 0.9204382183908046 \n",
      "Epoch 18 | Step 7200 | loss: 0.20492021987123946 | accuracy: 0.920487106017192 \n",
      "Epoch 18 | Step 7201 | loss: 0.20500455681766774 | accuracy: 0.9203125 \n",
      "Epoch 18 | Step 7202 | loss: 0.20471725487641113 | accuracy: 0.9204504985754985 \n",
      "Epoch 18 | Step 7203 | loss: 0.20466392212124027 | accuracy: 0.92041015625 \n",
      "Epoch 18 | Step 7204 | loss: 0.20474330882512806 | accuracy: 0.9202372521246459 \n",
      "Epoch 18 | Step 7205 | loss: 0.20477376802492941 | accuracy: 0.9202418785310734 \n",
      "Epoch 18 | Step 7206 | loss: 0.20460528769123715 | accuracy: 0.9202464788732394 \n",
      "Epoch 18 | Step 7207 | loss: 0.20444835136445713 | accuracy: 0.9202949438202247 \n",
      "Epoch 18 | Step 7208 | loss: 0.20472665151962038 | accuracy: 0.9202118347338936 \n",
      "Epoch 18 | Step 7209 | loss: 0.20507875301318454 | accuracy: 0.9199982541899442 \n",
      "Epoch 18 | Step 7210 | loss: 0.20493164031784505 | accuracy: 0.9200470055710307 \n",
      "Epoch 18 | Step 7211 | loss: 0.205001022790869 | accuracy: 0.9200086805555555 \n",
      "Epoch 18 | Step 7212 | loss: 0.20488279797859132 | accuracy: 0.9200138504155124 \n",
      "Epoch 18 | Step 7213 | loss: 0.20483345291397181 | accuracy: 0.9200189917127072 \n",
      "Epoch 18 | Step 7214 | loss: 0.20483022135972312 | accuracy: 0.9200671487603306 \n",
      "Epoch 18 | Step 7215 | loss: 0.20445157538403513 | accuracy: 0.9202438186813187 \n",
      "Epoch 18 | Step 7216 | loss: 0.2042174427068396 | accuracy: 0.9203767123287672 \n",
      "Epoch 18 | Step 7217 | loss: 0.20439262627089602 | accuracy: 0.9202527322404371 \n",
      "Epoch 18 | Step 7218 | loss: 0.20454898659312426 | accuracy: 0.9202145776566758 \n",
      "Epoch 18 | Step 7219 | loss: 0.2044950063623811 | accuracy: 0.920304008152174 \n",
      "Epoch 18 | Step 7220 | loss: 0.20470901249546983 | accuracy: 0.920265921409214 \n",
      "Epoch 18 | Step 7221 | loss: 0.20460793976042713 | accuracy: 0.9203125 \n",
      "Epoch 18 | Step 7222 | loss: 0.20471982750288553 | accuracy: 0.9203588274932615 \n",
      "Epoch 18 | Step 7223 | loss: 0.2046147673841445 | accuracy: 0.9203209005376344 \n",
      "Epoch 18 | Step 7224 | loss: 0.20429653292846417 | accuracy: 0.9204926273458445 \n",
      "Epoch 18 | Step 7225 | loss: 0.20413553033442414 | accuracy: 0.9205798796791443 \n",
      "Epoch 18 | Step 7226 | loss: 0.20428520111242923 | accuracy: 0.9205 \n",
      "Epoch 18 | Step 7227 | loss: 0.20417405660957724 | accuracy: 0.9205452127659575 \n",
      "Epoch 18 | Step 7228 | loss: 0.2041222028612141 | accuracy: 0.9204658488063661 \n",
      "Epoch 18 | Step 7229 | loss: 0.20402638850704063 | accuracy: 0.9205109126984127 \n",
      "Epoch 18 | Step 7230 | loss: 0.2038403708969382 | accuracy: 0.9206381926121372 \n",
      "Epoch 18 | Step 7231 | loss: 0.2037139302021578 | accuracy: 0.920641447368421 \n",
      "Epoch 18 | Step 7232 | loss: 0.2034795305586549 | accuracy: 0.9206856955380578 \n",
      "Epoch 18 | Step 7233 | loss: 0.2035204110306282 | accuracy: 0.9207706151832461 \n",
      "Epoch 18 | Step 7234 | loss: 0.20358069223539008 | accuracy: 0.9207327023498695 \n",
      "Epoch 18 | Step 7235 | loss: 0.20388725774440286 | accuracy: 0.9207763671875 \n",
      "Epoch 18 | Step 7236 | loss: 0.2037268812199691 | accuracy: 0.9208603896103896 \n",
      "Epoch 18 | Step 7237 | loss: 0.20363030545992547 | accuracy: 0.9209034974093264 \n",
      "Epoch 18 | Step 7238 | loss: 0.20350989974669392 | accuracy: 0.9208252583979328 \n",
      "Epoch 18 | Step 7239 | loss: 0.2037477436254626 | accuracy: 0.9208279639175257 \n",
      "Epoch 18 | Step 7240 | loss: 0.20357744864985378 | accuracy: 0.920870822622108 \n",
      "Epoch 18 | Step 7241 | loss: 0.20346189792721692 | accuracy: 0.9209935897435897 \n",
      "Epoch 18 | Step 7242 | loss: 0.20352301921914598 | accuracy: 0.9209159207161125 \n",
      "Epoch 18 | Step 7243 | loss: 0.20340413058518747 | accuracy: 0.9209582270408163 \n",
      "Epoch 18 | Step 7244 | loss: 0.20325877445420532 | accuracy: 0.9210003180661578 \n",
      "Epoch 18 | Step 7245 | loss: 0.20334262641023856 | accuracy: 0.9209232233502538 \n",
      "Epoch 18 | Step 7246 | loss: 0.20307783163801016 | accuracy: 0.9210443037974684 \n",
      "Epoch 18 | Step 7247 | loss: 0.20289515075508988 | accuracy: 0.9211253156565656 \n",
      "Epoch 18 | Step 7248 | loss: 0.20290137102982253 | accuracy: 0.9211665617128464 \n",
      "Epoch 18 | Step 7249 | loss: 0.20291639871932746 | accuracy: 0.9211683417085427 \n",
      "Epoch 18 | Step 7250 | loss: 0.20269211452631716 | accuracy: 0.9212092731829574 \n",
      "Epoch 18 | Step 7251 | loss: 0.2025915070809423 | accuracy: 0.92125 \n",
      "Epoch 18 | Step 7252 | loss: 0.20270096770768742 | accuracy: 0.9212515586034913 \n",
      "Epoch 18 | Step 7253 | loss: 0.2029748443161966 | accuracy: 0.9210976368159204 \n",
      "Epoch 18 | Step 7254 | loss: 0.20274788588655196 | accuracy: 0.9212078591138494 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.5115439295768738 | accuracy: 0.796875 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.41338834166526794 | accuracy: 0.84375 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.453676958878835 | accuracy: 0.8333333333333334 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.44606075435876846 | accuracy: 0.8203125 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4263895690441132 | accuracy: 0.83125 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.46914926668008167 | accuracy: 0.8125 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.45826220512390137 | accuracy: 0.8191964285714286 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4492444097995758 | accuracy: 0.818359375 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4858779311180115 | accuracy: 0.8125 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.46437907218933105 | accuracy: 0.821875 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4660747024145993 | accuracy: 0.8224431818181818 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4522646640737851 | accuracy: 0.8307291666666666 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4662727094613589 | accuracy: 0.8257211538461539 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4509161093405315 | accuracy: 0.8325892857142857 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.45673261682192484 | accuracy: 0.8354166666666667 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.45504917204380035 | accuracy: 0.8349609375 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4615757851039662 | accuracy: 0.8308823529411765 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4591372195217345 | accuracy: 0.8324652777777778 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4540842253910868 | accuracy: 0.8355263157894737 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4467617139220238 | accuracy: 0.8359375 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4396558276244572 | accuracy: 0.8370535714285714 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4332294491204349 | accuracy: 0.8401988636363636 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4434900568879169 | accuracy: 0.8389945652173914 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.46357859174410504 | accuracy: 0.8352864583333334 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.472511568069458 | accuracy: 0.833125 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4691918824727719 | accuracy: 0.8335336538461539 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4614116770249826 | accuracy: 0.8362268518518519 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4638605522257941 | accuracy: 0.8348214285714286 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.46102866633185025 | accuracy: 0.8356681034482759 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.45709068377812706 | accuracy: 0.8380208333333333 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.45199912305801143 | accuracy: 0.8402217741935484 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4557556351646781 | accuracy: 0.837890625 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4568415952451301 | accuracy: 0.8361742424242424 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4608893289285548 | accuracy: 0.8331801470588235 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4639307277543204 | accuracy: 0.8334821428571428 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4609826132655144 | accuracy: 0.8346354166666666 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4623891461539913 | accuracy: 0.8340371621621622 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4627918875531146 | accuracy: 0.834703947368421 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4636310537656148 | accuracy: 0.8337339743589743 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.459059451520443 | accuracy: 0.83515625 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4554605840182886 | accuracy: 0.8357469512195121 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.44962106538670404 | accuracy: 0.8374255952380952 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.4495555380749148 | accuracy: 0.8375726744186046 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.45191085304726253 | accuracy: 0.8366477272727273 \n",
      "Validation | Epoch 18 | Step 7254 | loss: 0.45043736265765294 | accuracy: 0.8368961347473992 \n",
      "Epoch 19 | Step 7255 | loss: 0.35835278034210205 | accuracy: 0.875 \n",
      "Epoch 19 | Step 7256 | loss: 0.2345866784453392 | accuracy: 0.921875 \n",
      "Epoch 19 | Step 7257 | loss: 0.2204339305559794 | accuracy: 0.9322916666666666 \n",
      "Epoch 19 | Step 7258 | loss: 0.22477628663182259 | accuracy: 0.921875 \n",
      "Epoch 19 | Step 7259 | loss: 0.20045410543680192 | accuracy: 0.93125 \n",
      "Epoch 19 | Step 7260 | loss: 0.19071685150265694 | accuracy: 0.9296875 \n",
      "Epoch 19 | Step 7261 | loss: 0.19355943479708262 | accuracy: 0.9285714285714286 \n",
      "Epoch 19 | Step 7262 | loss: 0.19260405655950308 | accuracy: 0.93359375 \n",
      "Epoch 19 | Step 7263 | loss: 0.19515014439821243 | accuracy: 0.9322916666666666 \n",
      "Epoch 19 | Step 7264 | loss: 0.20430784597992896 | accuracy: 0.93125 \n",
      "Epoch 19 | Step 7265 | loss: 0.19744449379769238 | accuracy: 0.9332386363636364 \n",
      "Epoch 19 | Step 7266 | loss: 0.19096266105771065 | accuracy: 0.9348958333333334 \n",
      "Epoch 19 | Step 7267 | loss: 0.20028389761081108 | accuracy: 0.9314903846153846 \n",
      "Epoch 19 | Step 7268 | loss: 0.19809623381921224 | accuracy: 0.9330357142857143 \n",
      "Epoch 19 | Step 7269 | loss: 0.20195231338342032 | accuracy: 0.9302083333333333 \n",
      "Epoch 19 | Step 7270 | loss: 0.1952650099992752 | accuracy: 0.9326171875 \n",
      "Epoch 19 | Step 7271 | loss: 0.1967403134878944 | accuracy: 0.9292279411764706 \n",
      "Epoch 19 | Step 7272 | loss: 0.19478908015622032 | accuracy: 0.9305555555555556 \n",
      "Epoch 19 | Step 7273 | loss: 0.19507932976672523 | accuracy: 0.9292763157894737 \n",
      "Epoch 19 | Step 7274 | loss: 0.19804497063159943 | accuracy: 0.928125 \n",
      "Epoch 19 | Step 7275 | loss: 0.19839265303952353 | accuracy: 0.9270833333333334 \n",
      "Epoch 19 | Step 7276 | loss: 0.20087316564538263 | accuracy: 0.9261363636363636 \n",
      "Epoch 19 | Step 7277 | loss: 0.1996991718592851 | accuracy: 0.9259510869565217 \n",
      "Epoch 19 | Step 7278 | loss: 0.19922126705447832 | accuracy: 0.92578125 \n",
      "Epoch 19 | Step 7279 | loss: 0.20267268180847167 | accuracy: 0.924375 \n",
      "Epoch 19 | Step 7280 | loss: 0.20268264011694834 | accuracy: 0.9236778846153846 \n",
      "Epoch 19 | Step 7281 | loss: 0.20864460589709105 | accuracy: 0.9212962962962963 \n",
      "Epoch 19 | Step 7282 | loss: 0.20519295308206761 | accuracy: 0.9229910714285714 \n",
      "Epoch 19 | Step 7283 | loss: 0.21011468639661526 | accuracy: 0.9213362068965517 \n",
      "Epoch 19 | Step 7284 | loss: 0.20926914388934773 | accuracy: 0.9213541666666667 \n",
      "Epoch 19 | Step 7285 | loss: 0.20778033257492126 | accuracy: 0.9203629032258065 \n",
      "Epoch 19 | Step 7286 | loss: 0.2076233692932874 | accuracy: 0.9208984375 \n",
      "Epoch 19 | Step 7287 | loss: 0.20696678057764517 | accuracy: 0.921875 \n",
      "Epoch 19 | Step 7288 | loss: 0.20331148737493684 | accuracy: 0.9232536764705882 \n",
      "Epoch 19 | Step 7289 | loss: 0.20032765716314316 | accuracy: 0.9236607142857143 \n",
      "Epoch 19 | Step 7290 | loss: 0.1993196356213755 | accuracy: 0.9244791666666666 \n",
      "Epoch 19 | Step 7291 | loss: 0.1994313966180827 | accuracy: 0.9244087837837838 \n",
      "Epoch 19 | Step 7292 | loss: 0.19913796551133456 | accuracy: 0.9247532894736842 \n",
      "Epoch 19 | Step 7293 | loss: 0.196628050162242 | accuracy: 0.9254807692307693 \n",
      "Epoch 19 | Step 7294 | loss: 0.1950552590191364 | accuracy: 0.9265625 \n",
      "Epoch 19 | Step 7295 | loss: 0.19347053184741878 | accuracy: 0.9275914634146342 \n",
      "Epoch 19 | Step 7296 | loss: 0.19317079406409032 | accuracy: 0.9270833333333334 \n",
      "Epoch 19 | Step 7297 | loss: 0.1912623915907948 | accuracy: 0.9280523255813954 \n",
      "Epoch 19 | Step 7298 | loss: 0.1899912474168972 | accuracy: 0.9289772727272727 \n",
      "Epoch 19 | Step 7299 | loss: 0.19112751268678238 | accuracy: 0.9295138888888889 \n",
      "Epoch 19 | Step 7300 | loss: 0.1928564671265042 | accuracy: 0.9290081521739131 \n",
      "Epoch 19 | Step 7301 | loss: 0.1923355382490665 | accuracy: 0.9295212765957447 \n",
      "Epoch 19 | Step 7302 | loss: 0.19253716291859743 | accuracy: 0.9296875 \n",
      "Epoch 19 | Step 7303 | loss: 0.19447536903376478 | accuracy: 0.9292091836734694 \n",
      "Epoch 19 | Step 7304 | loss: 0.19549652650952334 | accuracy: 0.92875 \n",
      "Epoch 19 | Step 7305 | loss: 0.19573189157481283 | accuracy: 0.9283088235294118 \n",
      "Epoch 19 | Step 7306 | loss: 0.1937475284704795 | accuracy: 0.9287860576923077 \n",
      "Epoch 19 | Step 7307 | loss: 0.19556486662828693 | accuracy: 0.9280660377358491 \n",
      "Epoch 19 | Step 7308 | loss: 0.19447963160497167 | accuracy: 0.9285300925925926 \n",
      "Epoch 19 | Step 7309 | loss: 0.1963378483598882 | accuracy: 0.9275568181818182 \n",
      "Epoch 19 | Step 7310 | loss: 0.1952689071851117 | accuracy: 0.9280133928571429 \n",
      "Epoch 19 | Step 7311 | loss: 0.19688732425371802 | accuracy: 0.9270833333333334 \n",
      "Epoch 19 | Step 7312 | loss: 0.19679840499984805 | accuracy: 0.9272629310344828 \n",
      "Epoch 19 | Step 7313 | loss: 0.198679576738406 | accuracy: 0.926906779661017 \n",
      "Epoch 19 | Step 7314 | loss: 0.19938333084185916 | accuracy: 0.9268229166666667 \n",
      "Epoch 19 | Step 7315 | loss: 0.19902729279682282 | accuracy: 0.9267418032786885 \n",
      "Epoch 19 | Step 7316 | loss: 0.19872062773473798 | accuracy: 0.9271673387096774 \n",
      "Epoch 19 | Step 7317 | loss: 0.20044806505006454 | accuracy: 0.9263392857142857 \n",
      "Epoch 19 | Step 7318 | loss: 0.1985663392115384 | accuracy: 0.927001953125 \n",
      "Epoch 19 | Step 7319 | loss: 0.19702985561811004 | accuracy: 0.9278846153846154 \n",
      "Epoch 19 | Step 7320 | loss: 0.19601000439036972 | accuracy: 0.9285037878787878 \n",
      "Epoch 19 | Step 7321 | loss: 0.1951324572758888 | accuracy: 0.9286380597014925 \n",
      "Epoch 19 | Step 7322 | loss: 0.19562812960323162 | accuracy: 0.9285386029411765 \n",
      "Epoch 19 | Step 7323 | loss: 0.19570137668347007 | accuracy: 0.9282155797101449 \n",
      "Epoch 19 | Step 7324 | loss: 0.19526257089206145 | accuracy: 0.9279017857142857 \n",
      "Epoch 19 | Step 7325 | loss: 0.19364151578973712 | accuracy: 0.9286971830985915 \n",
      "Epoch 19 | Step 7326 | loss: 0.19384723953488794 | accuracy: 0.9288194444444444 \n",
      "Epoch 19 | Step 7327 | loss: 0.1937590042409831 | accuracy: 0.9285102739726028 \n",
      "Epoch 19 | Step 7328 | loss: 0.19367437920457603 | accuracy: 0.9284206081081081 \n",
      "Epoch 19 | Step 7329 | loss: 0.19323266198237732 | accuracy: 0.92875 \n",
      "Epoch 19 | Step 7330 | loss: 0.1934746071500213 | accuracy: 0.9286595394736842 \n",
      "Epoch 19 | Step 7331 | loss: 0.1928965339993501 | accuracy: 0.9285714285714286 \n",
      "Epoch 19 | Step 7332 | loss: 0.19304254450477082 | accuracy: 0.9284855769230769 \n",
      "Epoch 19 | Step 7333 | loss: 0.19561569590734526 | accuracy: 0.9278085443037974 \n",
      "Epoch 19 | Step 7334 | loss: 0.1949365883134305 | accuracy: 0.928125 \n",
      "Epoch 19 | Step 7335 | loss: 0.19452727898771377 | accuracy: 0.9282407407407407 \n",
      "Epoch 19 | Step 7336 | loss: 0.1935218151022748 | accuracy: 0.928734756097561 \n",
      "Epoch 19 | Step 7337 | loss: 0.19330882415714035 | accuracy: 0.9292168674698795 \n",
      "Epoch 19 | Step 7338 | loss: 0.1930301652422973 | accuracy: 0.9293154761904762 \n",
      "Epoch 19 | Step 7339 | loss: 0.19274616434293634 | accuracy: 0.9292279411764706 \n",
      "Epoch 19 | Step 7340 | loss: 0.19198264978652776 | accuracy: 0.9300508720930233 \n",
      "Epoch 19 | Step 7341 | loss: 0.19443675053530726 | accuracy: 0.9292385057471264 \n",
      "Epoch 19 | Step 7342 | loss: 0.1949227757074616 | accuracy: 0.9293323863636364 \n",
      "Epoch 19 | Step 7343 | loss: 0.1939331858178203 | accuracy: 0.9297752808988764 \n",
      "Epoch 19 | Step 7344 | loss: 0.19416559611757597 | accuracy: 0.9295138888888889 \n",
      "Epoch 19 | Step 7345 | loss: 0.1932490879854003 | accuracy: 0.9296016483516484 \n",
      "Epoch 19 | Step 7346 | loss: 0.19279262010494005 | accuracy: 0.9298573369565217 \n",
      "Epoch 19 | Step 7347 | loss: 0.19231676823028954 | accuracy: 0.9301075268817204 \n",
      "Epoch 19 | Step 7348 | loss: 0.19167597758326124 | accuracy: 0.9303523936170213 \n",
      "Epoch 19 | Step 7349 | loss: 0.19241907416205656 | accuracy: 0.9300986842105263 \n",
      "Epoch 19 | Step 7350 | loss: 0.19372202494802573 | accuracy: 0.9298502604166666 \n",
      "Epoch 19 | Step 7351 | loss: 0.19367499718653788 | accuracy: 0.9297680412371134 \n",
      "Epoch 19 | Step 7352 | loss: 0.19510528042304273 | accuracy: 0.9292091836734694 \n",
      "Epoch 19 | Step 7353 | loss: 0.19549933550032703 | accuracy: 0.9292929292929293 \n",
      "Epoch 19 | Step 7354 | loss: 0.19470675431191922 | accuracy: 0.92953125 \n",
      "Epoch 19 | Step 7355 | loss: 0.19357669294470609 | accuracy: 0.9300742574257426 \n",
      "Epoch 19 | Step 7356 | loss: 0.19342154673501558 | accuracy: 0.9301470588235294 \n",
      "Epoch 19 | Step 7357 | loss: 0.19240544960626121 | accuracy: 0.930370145631068 \n",
      "Epoch 19 | Step 7358 | loss: 0.19297399550962907 | accuracy: 0.9302884615384616 \n",
      "Epoch 19 | Step 7359 | loss: 0.1939127096817607 | accuracy: 0.9299107142857143 \n",
      "Epoch 19 | Step 7360 | loss: 0.1930977744313906 | accuracy: 0.9304245283018868 \n",
      "Epoch 19 | Step 7361 | loss: 0.1939039659277301 | accuracy: 0.9299065420560748 \n",
      "Epoch 19 | Step 7362 | loss: 0.19513462125151246 | accuracy: 0.9293981481481481 \n",
      "Epoch 19 | Step 7363 | loss: 0.19558105036753035 | accuracy: 0.929329128440367 \n",
      "Epoch 19 | Step 7364 | loss: 0.19602746679024263 | accuracy: 0.9288352272727273 \n",
      "Epoch 19 | Step 7365 | loss: 0.19575143236297746 | accuracy: 0.9289132882882883 \n",
      "Epoch 19 | Step 7366 | loss: 0.1953345253797514 | accuracy: 0.9289899553571429 \n",
      "Epoch 19 | Step 7367 | loss: 0.19645365848477964 | accuracy: 0.9286504424778761 \n",
      "Epoch 19 | Step 7368 | loss: 0.1966905187357936 | accuracy: 0.9285910087719298 \n",
      "Epoch 19 | Step 7369 | loss: 0.19652650382207787 | accuracy: 0.9286684782608695 \n",
      "Epoch 19 | Step 7370 | loss: 0.19631633419415045 | accuracy: 0.9286099137931034 \n",
      "Epoch 19 | Step 7371 | loss: 0.19679605935373876 | accuracy: 0.9280181623931624 \n",
      "Epoch 19 | Step 7372 | loss: 0.19653726482795456 | accuracy: 0.927833686440678 \n",
      "Epoch 19 | Step 7373 | loss: 0.1966436213555456 | accuracy: 0.9277836134453782 \n",
      "Epoch 19 | Step 7374 | loss: 0.19595598727464675 | accuracy: 0.9279947916666667 \n",
      "Epoch 19 | Step 7375 | loss: 0.19574762548296903 | accuracy: 0.9279442148760331 \n",
      "Epoch 19 | Step 7376 | loss: 0.1957213463353329 | accuracy: 0.9277663934426229 \n",
      "Epoch 19 | Step 7377 | loss: 0.1956725929810749 | accuracy: 0.9277184959349594 \n",
      "Epoch 19 | Step 7378 | loss: 0.19571269784242876 | accuracy: 0.9277973790322581 \n",
      "Epoch 19 | Step 7379 | loss: 0.19531349408626555 | accuracy: 0.927875 \n",
      "Epoch 19 | Step 7380 | loss: 0.19519207981370745 | accuracy: 0.9279513888888888 \n",
      "Epoch 19 | Step 7381 | loss: 0.1958286904209242 | accuracy: 0.9276574803149606 \n",
      "Epoch 19 | Step 7382 | loss: 0.19540827942546457 | accuracy: 0.9276123046875 \n",
      "Epoch 19 | Step 7383 | loss: 0.19504054433615634 | accuracy: 0.9275678294573644 \n",
      "Epoch 19 | Step 7384 | loss: 0.19480777245301467 | accuracy: 0.9277644230769231 \n",
      "Epoch 19 | Step 7385 | loss: 0.19524574120536106 | accuracy: 0.9273616412213741 \n",
      "Epoch 19 | Step 7386 | loss: 0.19613364700115088 | accuracy: 0.9269649621212122 \n",
      "Epoch 19 | Step 7387 | loss: 0.19665858933800145 | accuracy: 0.9266917293233082 \n",
      "Epoch 19 | Step 7388 | loss: 0.19660266599993206 | accuracy: 0.9267723880597015 \n",
      "Epoch 19 | Step 7389 | loss: 0.19657928579383427 | accuracy: 0.9266203703703704 \n",
      "Epoch 19 | Step 7390 | loss: 0.19647868887028275 | accuracy: 0.9268152573529411 \n",
      "Epoch 19 | Step 7391 | loss: 0.1960216181991744 | accuracy: 0.927007299270073 \n",
      "Epoch 19 | Step 7392 | loss: 0.19582562980012613 | accuracy: 0.9270833333333334 \n",
      "Epoch 19 | Step 7393 | loss: 0.19633528193552713 | accuracy: 0.9272706834532374 \n",
      "Epoch 19 | Step 7394 | loss: 0.19650679337126864 | accuracy: 0.9272321428571428 \n",
      "Epoch 19 | Step 7395 | loss: 0.19772003601628832 | accuracy: 0.9268617021276596 \n",
      "Epoch 19 | Step 7396 | loss: 0.19791193810147295 | accuracy: 0.9269366197183099 \n",
      "Epoch 19 | Step 7397 | loss: 0.19825840329790445 | accuracy: 0.9266826923076923 \n",
      "Epoch 19 | Step 7398 | loss: 0.19814416155632994 | accuracy: 0.9267578125 \n",
      "Epoch 19 | Step 7399 | loss: 0.19801997943171135 | accuracy: 0.9267241379310345 \n",
      "Epoch 19 | Step 7400 | loss: 0.19845823545570238 | accuracy: 0.9264768835616438 \n",
      "Epoch 19 | Step 7401 | loss: 0.197687336123314 | accuracy: 0.9267644557823129 \n",
      "Epoch 19 | Step 7402 | loss: 0.19781831667028565 | accuracy: 0.9268369932432432 \n",
      "Epoch 19 | Step 7403 | loss: 0.19735162615176013 | accuracy: 0.9271182885906041 \n",
      "Epoch 19 | Step 7404 | loss: 0.1979438438514868 | accuracy: 0.9270833333333334 \n",
      "Epoch 19 | Step 7405 | loss: 0.19835882219455095 | accuracy: 0.9270488410596026 \n",
      "Epoch 19 | Step 7406 | loss: 0.1995977920627123 | accuracy: 0.9267064144736842 \n",
      "Epoch 19 | Step 7407 | loss: 0.2001485316679368 | accuracy: 0.9265727124183006 \n",
      "Epoch 19 | Step 7408 | loss: 0.1997135033371386 | accuracy: 0.926948051948052 \n",
      "Epoch 19 | Step 7409 | loss: 0.19936457992561396 | accuracy: 0.9269153225806451 \n",
      "Epoch 19 | Step 7410 | loss: 0.19883658770376283 | accuracy: 0.9270833333333334 \n",
      "Epoch 19 | Step 7411 | loss: 0.19871279450169027 | accuracy: 0.9271496815286624 \n",
      "Epoch 19 | Step 7412 | loss: 0.19884797765672954 | accuracy: 0.9269185126582279 \n",
      "Epoch 19 | Step 7413 | loss: 0.19881028775711473 | accuracy: 0.9265919811320755 \n",
      "Epoch 19 | Step 7414 | loss: 0.1989998146425932 | accuracy: 0.92646484375 \n",
      "Epoch 19 | Step 7415 | loss: 0.1991696748766839 | accuracy: 0.9264363354037267 \n",
      "Epoch 19 | Step 7416 | loss: 0.19903536872179411 | accuracy: 0.9264081790123457 \n",
      "Epoch 19 | Step 7417 | loss: 0.20029053361686452 | accuracy: 0.9258052147239264 \n",
      "Epoch 19 | Step 7418 | loss: 0.2002281306266057 | accuracy: 0.9255907012195121 \n",
      "Epoch 19 | Step 7419 | loss: 0.20028226551684458 | accuracy: 0.9254734848484848 \n",
      "Epoch 19 | Step 7420 | loss: 0.2004302128341542 | accuracy: 0.9251694277108434 \n",
      "Epoch 19 | Step 7421 | loss: 0.20003980233105348 | accuracy: 0.9252432634730539 \n",
      "Epoch 19 | Step 7422 | loss: 0.20076317637271815 | accuracy: 0.9249441964285714 \n",
      "Epoch 19 | Step 7423 | loss: 0.20068954552948115 | accuracy: 0.9248335798816568 \n",
      "Epoch 19 | Step 7424 | loss: 0.19998399983434106 | accuracy: 0.9251838235294118 \n",
      "Epoch 19 | Step 7425 | loss: 0.1998802853955162 | accuracy: 0.9252558479532164 \n",
      "Epoch 19 | Step 7426 | loss: 0.2001680509988651 | accuracy: 0.9248728197674418 \n",
      "Epoch 19 | Step 7427 | loss: 0.1999136266336275 | accuracy: 0.924945809248555 \n",
      "Epoch 19 | Step 7428 | loss: 0.19997579630078932 | accuracy: 0.9251077586206896 \n",
      "Epoch 19 | Step 7429 | loss: 0.19997743461813236 | accuracy: 0.925 \n",
      "Epoch 19 | Step 7430 | loss: 0.200751394287429 | accuracy: 0.9247159090909091 \n",
      "Epoch 19 | Step 7431 | loss: 0.20138153273843767 | accuracy: 0.9244350282485876 \n",
      "Epoch 19 | Step 7432 | loss: 0.2018976120299167 | accuracy: 0.9239817415730337 \n",
      "Epoch 19 | Step 7433 | loss: 0.20224883111828523 | accuracy: 0.9238826815642458 \n",
      "Epoch 19 | Step 7434 | loss: 0.20196799172295457 | accuracy: 0.9237847222222222 \n",
      "Epoch 19 | Step 7435 | loss: 0.20207718418118695 | accuracy: 0.9236015193370166 \n",
      "Epoch 19 | Step 7436 | loss: 0.20192839352639158 | accuracy: 0.923592032967033 \n",
      "Epoch 19 | Step 7437 | loss: 0.20144261574484604 | accuracy: 0.9235826502732241 \n",
      "Epoch 19 | Step 7438 | loss: 0.20098675908925734 | accuracy: 0.923828125 \n",
      "Epoch 19 | Step 7439 | loss: 0.2008761907751495 | accuracy: 0.9238175675675676 \n",
      "Epoch 19 | Step 7440 | loss: 0.2012895806342042 | accuracy: 0.9235551075268817 \n",
      "Epoch 19 | Step 7441 | loss: 0.2017759343678938 | accuracy: 0.9232118983957219 \n",
      "Epoch 19 | Step 7442 | loss: 0.20187945307252247 | accuracy: 0.9231216755319149 \n",
      "Epoch 19 | Step 7443 | loss: 0.20169646683193382 | accuracy: 0.9232804232804233 \n",
      "Epoch 19 | Step 7444 | loss: 0.2025349911890531 | accuracy: 0.9231907894736842 \n",
      "Epoch 19 | Step 7445 | loss: 0.20197515002407945 | accuracy: 0.9235111256544503 \n",
      "Epoch 19 | Step 7446 | loss: 0.20176943608870102 | accuracy: 0.923583984375 \n",
      "Epoch 19 | Step 7447 | loss: 0.20160278361387196 | accuracy: 0.9236560880829016 \n",
      "Epoch 19 | Step 7448 | loss: 0.20143686972328062 | accuracy: 0.9237274484536082 \n",
      "Epoch 19 | Step 7449 | loss: 0.20109837933992722 | accuracy: 0.9238782051282052 \n",
      "Epoch 19 | Step 7450 | loss: 0.20119026767051942 | accuracy: 0.9237882653061225 \n",
      "Epoch 19 | Step 7451 | loss: 0.20116675890944324 | accuracy: 0.9237785532994924 \n",
      "Epoch 19 | Step 7452 | loss: 0.20116629534297512 | accuracy: 0.9237689393939394 \n",
      "Epoch 19 | Step 7453 | loss: 0.200892618478243 | accuracy: 0.9240734924623115 \n",
      "Epoch 19 | Step 7454 | loss: 0.20072410404682153 | accuracy: 0.923984375 \n",
      "Epoch 19 | Step 7455 | loss: 0.20108685090174122 | accuracy: 0.923896144278607 \n",
      "Epoch 19 | Step 7456 | loss: 0.2010205489131483 | accuracy: 0.9239634900990099 \n",
      "Epoch 19 | Step 7457 | loss: 0.20100795018849107 | accuracy: 0.9238762315270936 \n",
      "Epoch 19 | Step 7458 | loss: 0.20082876319978746 | accuracy: 0.9240196078431373 \n",
      "Epoch 19 | Step 7459 | loss: 0.20107731164955506 | accuracy: 0.9237804878048781 \n",
      "Epoch 19 | Step 7460 | loss: 0.20185749406374767 | accuracy: 0.9235436893203883 \n",
      "Epoch 19 | Step 7461 | loss: 0.20244923032424295 | accuracy: 0.9235356280193237 \n",
      "Epoch 19 | Step 7462 | loss: 0.2025020171959812 | accuracy: 0.9234525240384616 \n",
      "Epoch 19 | Step 7463 | loss: 0.20242697941629503 | accuracy: 0.9235197368421053 \n",
      "Epoch 19 | Step 7464 | loss: 0.2024982639011882 | accuracy: 0.9236607142857143 \n",
      "Epoch 19 | Step 7465 | loss: 0.2027743545612452 | accuracy: 0.9234300947867299 \n",
      "Epoch 19 | Step 7466 | loss: 0.20223109677152806 | accuracy: 0.9237175707547169 \n",
      "Epoch 19 | Step 7467 | loss: 0.2018593513349971 | accuracy: 0.9237089201877934 \n",
      "Epoch 19 | Step 7468 | loss: 0.2019956413412762 | accuracy: 0.9236273364485982 \n",
      "Epoch 19 | Step 7469 | loss: 0.20188206378803691 | accuracy: 0.9236191860465116 \n",
      "Epoch 19 | Step 7470 | loss: 0.2017827970148236 | accuracy: 0.9236111111111112 \n",
      "Epoch 19 | Step 7471 | loss: 0.20144041555543094 | accuracy: 0.9238191244239631 \n",
      "Epoch 19 | Step 7472 | loss: 0.20130748315415245 | accuracy: 0.923881880733945 \n",
      "Epoch 19 | Step 7473 | loss: 0.20109670653462947 | accuracy: 0.9238727168949772 \n",
      "Epoch 19 | Step 7474 | loss: 0.2011097892441532 | accuracy: 0.9239346590909091 \n",
      "Epoch 19 | Step 7475 | loss: 0.20109253690253548 | accuracy: 0.9239253393665159 \n",
      "Epoch 19 | Step 7476 | loss: 0.2011334762514174 | accuracy: 0.9239161036036037 \n",
      "Epoch 19 | Step 7477 | loss: 0.20129404247074378 | accuracy: 0.9237668161434978 \n",
      "Epoch 19 | Step 7478 | loss: 0.20077624800615007 | accuracy: 0.9241071428571429 \n",
      "Epoch 19 | Step 7479 | loss: 0.20105852024422746 | accuracy: 0.9240277777777778 \n",
      "Epoch 19 | Step 7480 | loss: 0.20119556365946747 | accuracy: 0.9239491150442478 \n",
      "Epoch 19 | Step 7481 | loss: 0.20133993571156442 | accuracy: 0.9238023127753304 \n",
      "Epoch 19 | Step 7482 | loss: 0.2013724085858516 | accuracy: 0.9239309210526315 \n",
      "Epoch 19 | Step 7483 | loss: 0.20118087155980308 | accuracy: 0.9240584061135371 \n",
      "Epoch 19 | Step 7484 | loss: 0.20109020500727315 | accuracy: 0.9241847826086956 \n",
      "Epoch 19 | Step 7485 | loss: 0.20087437786452175 | accuracy: 0.9243777056277056 \n",
      "Epoch 19 | Step 7486 | loss: 0.20050595858102208 | accuracy: 0.9246363146551724 \n",
      "Epoch 19 | Step 7487 | loss: 0.20042866471627233 | accuracy: 0.9245574034334764 \n",
      "Epoch 19 | Step 7488 | loss: 0.20051568323093596 | accuracy: 0.9245459401709402 \n",
      "Epoch 19 | Step 7489 | loss: 0.2003813317164461 | accuracy: 0.9246675531914894 \n",
      "Epoch 19 | Step 7490 | loss: 0.20014798619105648 | accuracy: 0.9247881355932204 \n",
      "Epoch 19 | Step 7491 | loss: 0.19998399199689987 | accuracy: 0.9249077004219409 \n",
      "Epoch 19 | Step 7492 | loss: 0.19989069316442268 | accuracy: 0.924829306722689 \n",
      "Epoch 19 | Step 7493 | loss: 0.19970949926261616 | accuracy: 0.9248823221757322 \n",
      "Epoch 19 | Step 7494 | loss: 0.19973171567544334 | accuracy: 0.9248046875 \n",
      "Epoch 19 | Step 7495 | loss: 0.19930610042142663 | accuracy: 0.9249870331950207 \n",
      "Epoch 19 | Step 7496 | loss: 0.19907893074199182 | accuracy: 0.9250387396694215 \n",
      "Epoch 19 | Step 7497 | loss: 0.19960098140278956 | accuracy: 0.9249614197530864 \n",
      "Epoch 19 | Step 7498 | loss: 0.20004508100816454 | accuracy: 0.9247566598360656 \n",
      "Epoch 19 | Step 7499 | loss: 0.19991967209747855 | accuracy: 0.9247448979591837 \n",
      "Epoch 19 | Step 7500 | loss: 0.19993236769990216 | accuracy: 0.9245426829268293 \n",
      "Epoch 19 | Step 7501 | loss: 0.19975001922985797 | accuracy: 0.9245951417004049 \n",
      "Epoch 19 | Step 7502 | loss: 0.19989006647900223 | accuracy: 0.9245211693548387 \n",
      "Epoch 19 | Step 7503 | loss: 0.1997065365194795 | accuracy: 0.9245732931726908 \n",
      "Epoch 19 | Step 7504 | loss: 0.19980214691162104 | accuracy: 0.9245 \n",
      "Epoch 19 | Step 7505 | loss: 0.1995138094363459 | accuracy: 0.9246762948207171 \n",
      "Epoch 19 | Step 7506 | loss: 0.19951326228559957 | accuracy: 0.9245411706349206 \n",
      "Epoch 19 | Step 7507 | loss: 0.1994074496473719 | accuracy: 0.9245923913043478 \n",
      "Epoch 19 | Step 7508 | loss: 0.19936926316792566 | accuracy: 0.9246432086614174 \n",
      "Epoch 19 | Step 7509 | loss: 0.19927894864596568 | accuracy: 0.9246936274509804 \n",
      "Epoch 19 | Step 7510 | loss: 0.19947592465905467 | accuracy: 0.92462158203125 \n",
      "Epoch 19 | Step 7511 | loss: 0.19934925286222518 | accuracy: 0.9247324902723736 \n",
      "Epoch 19 | Step 7512 | loss: 0.19902137776677917 | accuracy: 0.9248425387596899 \n",
      "Epoch 19 | Step 7513 | loss: 0.19910046533037792 | accuracy: 0.924831081081081 \n",
      "Epoch 19 | Step 7514 | loss: 0.19895037315212757 | accuracy: 0.9248798076923077 \n",
      "Epoch 19 | Step 7515 | loss: 0.1992579341734049 | accuracy: 0.9246886973180076 \n",
      "Epoch 19 | Step 7516 | loss: 0.19928507740033485 | accuracy: 0.9245586832061069 \n",
      "Epoch 19 | Step 7517 | loss: 0.19902593129714627 | accuracy: 0.9246078897338403 \n",
      "Epoch 19 | Step 7518 | loss: 0.19948731966768246 | accuracy: 0.9244199810606061 \n",
      "Epoch 19 | Step 7519 | loss: 0.19936045756879836 | accuracy: 0.9244693396226416 \n",
      "Epoch 19 | Step 7520 | loss: 0.1993342894584612 | accuracy: 0.9244008458646616 \n",
      "Epoch 19 | Step 7521 | loss: 0.1992241783758227 | accuracy: 0.9243913857677902 \n",
      "Epoch 19 | Step 7522 | loss: 0.19895710557031981 | accuracy: 0.9245569029850746 \n",
      "Epoch 19 | Step 7523 | loss: 0.1989625820883144 | accuracy: 0.9246050185873605 \n",
      "Epoch 19 | Step 7524 | loss: 0.19878118739083955 | accuracy: 0.9247106481481482 \n",
      "Epoch 19 | Step 7525 | loss: 0.19872297846963038 | accuracy: 0.9245848708487084 \n",
      "Epoch 19 | Step 7526 | loss: 0.19858842304743382 | accuracy: 0.9246323529411765 \n",
      "Epoch 19 | Step 7527 | loss: 0.19870363514283632 | accuracy: 0.9244505494505495 \n",
      "Epoch 19 | Step 7528 | loss: 0.19878524846404133 | accuracy: 0.9243841240875912 \n",
      "Epoch 19 | Step 7529 | loss: 0.1987044035304676 | accuracy: 0.924375 \n",
      "Epoch 19 | Step 7530 | loss: 0.1988146178208399 | accuracy: 0.9242527173913042 \n",
      "Epoch 19 | Step 7531 | loss: 0.1988157627276995 | accuracy: 0.9241313176895306 \n",
      "Epoch 19 | Step 7532 | loss: 0.19870208107310225 | accuracy: 0.9242356115107914 \n",
      "Epoch 19 | Step 7533 | loss: 0.19856997298937965 | accuracy: 0.9242271505376344 \n",
      "Epoch 19 | Step 7534 | loss: 0.1984881572957549 | accuracy: 0.9243303571428572 \n",
      "Epoch 19 | Step 7535 | loss: 0.19902812994459762 | accuracy: 0.9239879893238434 \n",
      "Epoch 19 | Step 7536 | loss: 0.1987779257779425 | accuracy: 0.9240913120567376 \n",
      "Epoch 19 | Step 7537 | loss: 0.1987602089403374 | accuracy: 0.9241386925795053 \n",
      "Epoch 19 | Step 7538 | loss: 0.19870467221652952 | accuracy: 0.9242407570422535 \n",
      "Epoch 19 | Step 7539 | loss: 0.1985168274034533 | accuracy: 0.9244517543859649 \n",
      "Epoch 19 | Step 7540 | loss: 0.19853517585075814 | accuracy: 0.9244427447552448 \n",
      "Epoch 19 | Step 7541 | loss: 0.19837004969136635 | accuracy: 0.9244882404181185 \n",
      "Epoch 19 | Step 7542 | loss: 0.19812578992504207 | accuracy: 0.9245876736111112 \n",
      "Epoch 19 | Step 7543 | loss: 0.19783030117774913 | accuracy: 0.9246864186851211 \n",
      "Epoch 19 | Step 7544 | loss: 0.19828923706864485 | accuracy: 0.9245689655172413 \n",
      "Epoch 19 | Step 7545 | loss: 0.1981197587147201 | accuracy: 0.9246134020618557 \n",
      "Epoch 19 | Step 7546 | loss: 0.1981446300824619 | accuracy: 0.9246040239726028 \n",
      "Epoch 19 | Step 7547 | loss: 0.1980637410852689 | accuracy: 0.9247013651877133 \n",
      "Epoch 19 | Step 7548 | loss: 0.19776847033577707 | accuracy: 0.9247980442176871 \n",
      "Epoch 19 | Step 7549 | loss: 0.19806643348124062 | accuracy: 0.9246822033898305 \n",
      "Epoch 19 | Step 7550 | loss: 0.19801390636712307 | accuracy: 0.9247255067567568 \n",
      "Epoch 19 | Step 7551 | loss: 0.1981986317821223 | accuracy: 0.9245580808080808 \n",
      "Epoch 19 | Step 7552 | loss: 0.19808321023647416 | accuracy: 0.9246015100671141 \n",
      "Epoch 19 | Step 7553 | loss: 0.19790059684411337 | accuracy: 0.9245923913043478 \n",
      "Epoch 19 | Step 7554 | loss: 0.19790525761743386 | accuracy: 0.9245833333333333 \n",
      "Epoch 19 | Step 7555 | loss: 0.19772094540124716 | accuracy: 0.9246781561461794 \n",
      "Epoch 19 | Step 7556 | loss: 0.1975571561777434 | accuracy: 0.9247206125827815 \n",
      "Epoch 19 | Step 7557 | loss: 0.19743216782808304 | accuracy: 0.9247112211221122 \n",
      "Epoch 19 | Step 7558 | loss: 0.19746354033582306 | accuracy: 0.9247018914473685 \n",
      "Epoch 19 | Step 7559 | loss: 0.19781632372101798 | accuracy: 0.9244364754098361 \n",
      "Epoch 19 | Step 7560 | loss: 0.1976429850009142 | accuracy: 0.9246323529411765 \n",
      "Epoch 19 | Step 7561 | loss: 0.19754037792500143 | accuracy: 0.9248269543973942 \n",
      "Epoch 19 | Step 7562 | loss: 0.1972169583639154 | accuracy: 0.9250710227272727 \n",
      "Epoch 19 | Step 7563 | loss: 0.1968618241714428 | accuracy: 0.9252629449838188 \n",
      "Epoch 19 | Step 7564 | loss: 0.19689813621582522 | accuracy: 0.9253024193548387 \n",
      "Epoch 19 | Step 7565 | loss: 0.19676128825190747 | accuracy: 0.9253918810289389 \n",
      "Epoch 19 | Step 7566 | loss: 0.19681856079170335 | accuracy: 0.9253305288461539 \n",
      "Epoch 19 | Step 7567 | loss: 0.19652340601617915 | accuracy: 0.9253694089456869 \n",
      "Epoch 19 | Step 7568 | loss: 0.19651750280598923 | accuracy: 0.9252587579617835 \n",
      "Epoch 19 | Step 7569 | loss: 0.19621035345490015 | accuracy: 0.9254464285714286 \n",
      "Epoch 19 | Step 7570 | loss: 0.19623176147571844 | accuracy: 0.9254845727848101 \n",
      "Epoch 19 | Step 7571 | loss: 0.19604234098918052 | accuracy: 0.925522476340694 \n",
      "Epoch 19 | Step 7572 | loss: 0.19614709021066717 | accuracy: 0.925560141509434 \n",
      "Epoch 19 | Step 7573 | loss: 0.19605743373542742 | accuracy: 0.9256955329153606 \n",
      "Epoch 19 | Step 7574 | loss: 0.19589489565696566 | accuracy: 0.925830078125 \n",
      "Epoch 19 | Step 7575 | loss: 0.19592583251426524 | accuracy: 0.9258177570093458 \n",
      "Epoch 19 | Step 7576 | loss: 0.19581318288023428 | accuracy: 0.9258540372670807 \n",
      "Epoch 19 | Step 7577 | loss: 0.1957627613062829 | accuracy: 0.9258900928792569 \n",
      "Epoch 19 | Step 7578 | loss: 0.19580624360637164 | accuracy: 0.9258777006172839 \n",
      "Epoch 19 | Step 7579 | loss: 0.19568075943451663 | accuracy: 0.9259134615384615 \n",
      "Epoch 19 | Step 7580 | loss: 0.19583302002651562 | accuracy: 0.9258052147239264 \n",
      "Epoch 19 | Step 7581 | loss: 0.19600651577251768 | accuracy: 0.925697629969419 \n",
      "Epoch 19 | Step 7582 | loss: 0.19615835853193592 | accuracy: 0.9256383384146342 \n",
      "Epoch 19 | Step 7583 | loss: 0.19577444985644796 | accuracy: 0.9258168693009119 \n",
      "Epoch 19 | Step 7584 | loss: 0.19572472260756926 | accuracy: 0.9257102272727272 \n",
      "Epoch 19 | Step 7585 | loss: 0.19575346308532438 | accuracy: 0.9256514350453172 \n",
      "Epoch 19 | Step 7586 | loss: 0.19562850331506096 | accuracy: 0.9256400602409639 \n",
      "Epoch 19 | Step 7587 | loss: 0.19552387999700713 | accuracy: 0.9257695195195195 \n",
      "Epoch 19 | Step 7588 | loss: 0.19552437064355005 | accuracy: 0.9258046407185628 \n",
      "Epoch 19 | Step 7589 | loss: 0.19551782674753843 | accuracy: 0.9257929104477612 \n",
      "Epoch 19 | Step 7590 | loss: 0.19552355481400377 | accuracy: 0.9257347470238095 \n",
      "Epoch 19 | Step 7591 | loss: 0.19544918428365837 | accuracy: 0.925723293768546 \n",
      "Epoch 19 | Step 7592 | loss: 0.19538121106180215 | accuracy: 0.9256656804733728 \n",
      "Epoch 19 | Step 7593 | loss: 0.195137316520411 | accuracy: 0.9258388643067846 \n",
      "Epoch 19 | Step 7594 | loss: 0.19497288612320143 | accuracy: 0.9259650735294118 \n",
      "Epoch 19 | Step 7595 | loss: 0.1949876390200906 | accuracy: 0.9259530791788856 \n",
      "Epoch 19 | Step 7596 | loss: 0.1949611930775712 | accuracy: 0.9259411549707602 \n",
      "Epoch 19 | Step 7597 | loss: 0.1947643253572133 | accuracy: 0.9260204081632653 \n",
      "Epoch 19 | Step 7598 | loss: 0.19466748445966217 | accuracy: 0.9260083575581395 \n",
      "Epoch 19 | Step 7599 | loss: 0.19459432059008142 | accuracy: 0.9260416666666667 \n",
      "Epoch 19 | Step 7600 | loss: 0.19441093334314452 | accuracy: 0.9261651011560693 \n",
      "Epoch 19 | Step 7601 | loss: 0.1944499126815315 | accuracy: 0.9261977665706052 \n",
      "Epoch 19 | Step 7602 | loss: 0.19422961664439617 | accuracy: 0.9263200431034483 \n",
      "Epoch 19 | Step 7603 | loss: 0.194162059094981 | accuracy: 0.9264416189111748 \n",
      "Epoch 19 | Step 7604 | loss: 0.19429547718593052 | accuracy: 0.9262053571428571 \n",
      "Epoch 19 | Step 7605 | loss: 0.19403921863716891 | accuracy: 0.9263710826210826 \n",
      "Epoch 19 | Step 7606 | loss: 0.19405580555427482 | accuracy: 0.9263139204545454 \n",
      "Epoch 19 | Step 7607 | loss: 0.19405511078601517 | accuracy: 0.9262570821529745 \n",
      "Epoch 19 | Step 7608 | loss: 0.19425878886364947 | accuracy: 0.9262005649717514 \n",
      "Epoch 19 | Step 7609 | loss: 0.1941120861491687 | accuracy: 0.9262764084507042 \n",
      "Epoch 19 | Step 7610 | loss: 0.19399344278604128 | accuracy: 0.9263079353932584 \n",
      "Epoch 19 | Step 7611 | loss: 0.19429419815790752 | accuracy: 0.9262079831932774 \n",
      "Epoch 19 | Step 7612 | loss: 0.19474612045304734 | accuracy: 0.9260649441340782 \n",
      "Epoch 19 | Step 7613 | loss: 0.19461940284974064 | accuracy: 0.9260967966573816 \n",
      "Epoch 19 | Step 7614 | loss: 0.19470832014663353 | accuracy: 0.926171875 \n",
      "Epoch 19 | Step 7615 | loss: 0.19456231406273275 | accuracy: 0.9262465373961218 \n",
      "Epoch 19 | Step 7616 | loss: 0.19452168712217505 | accuracy: 0.9262344613259669 \n",
      "Epoch 19 | Step 7617 | loss: 0.19442413909458262 | accuracy: 0.9263515840220385 \n",
      "Epoch 19 | Step 7618 | loss: 0.19408893116473497 | accuracy: 0.926510989010989 \n",
      "Epoch 19 | Step 7619 | loss: 0.19392330223975116 | accuracy: 0.926583904109589 \n",
      "Epoch 19 | Step 7620 | loss: 0.19413572356430558 | accuracy: 0.9265283469945356 \n",
      "Epoch 19 | Step 7621 | loss: 0.1941208210684948 | accuracy: 0.926600817438692 \n",
      "Epoch 19 | Step 7622 | loss: 0.19409035601774635 | accuracy: 0.9267153532608695 \n",
      "Epoch 19 | Step 7623 | loss: 0.1942463234713084 | accuracy: 0.9267022357723578 \n",
      "Epoch 19 | Step 7624 | loss: 0.19418160985853222 | accuracy: 0.926731418918919 \n",
      "Epoch 19 | Step 7625 | loss: 0.1942570656738834 | accuracy: 0.9267183288409704 \n",
      "Epoch 19 | Step 7626 | loss: 0.1941630423509626 | accuracy: 0.926789314516129 \n",
      "Epoch 19 | Step 7627 | loss: 0.1938615601120302 | accuracy: 0.9269436997319035 \n",
      "Epoch 19 | Step 7628 | loss: 0.19367957501647307 | accuracy: 0.9270137032085561 \n",
      "Epoch 19 | Step 7629 | loss: 0.19372811114788055 | accuracy: 0.927 \n",
      "Epoch 19 | Step 7630 | loss: 0.1935677395222035 | accuracy: 0.926986369680851 \n",
      "Epoch 19 | Step 7631 | loss: 0.19343132658093298 | accuracy: 0.9269728116710876 \n",
      "Epoch 19 | Step 7632 | loss: 0.19335219287683095 | accuracy: 0.9270006613756614 \n",
      "Epoch 19 | Step 7633 | loss: 0.19312326214952016 | accuracy: 0.9271108179419525 \n",
      "Epoch 19 | Step 7634 | loss: 0.19295525317521472 | accuracy: 0.9271381578947369 \n",
      "Epoch 19 | Step 7635 | loss: 0.19274904133062662 | accuracy: 0.927247375328084 \n",
      "Epoch 19 | Step 7636 | loss: 0.19277302661413298 | accuracy: 0.9273151178010471 \n",
      "Epoch 19 | Step 7637 | loss: 0.19290012590022995 | accuracy: 0.9272601174934726 \n",
      "Epoch 19 | Step 7638 | loss: 0.19327684478291 | accuracy: 0.92724609375 \n",
      "Epoch 19 | Step 7639 | loss: 0.1931193425090282 | accuracy: 0.9273133116883117 \n",
      "Epoch 19 | Step 7640 | loss: 0.1930384800571543 | accuracy: 0.9273397020725389 \n",
      "Epoch 19 | Step 7641 | loss: 0.19302767351539252 | accuracy: 0.9273255813953488 \n",
      "Epoch 19 | Step 7642 | loss: 0.19325362981210664 | accuracy: 0.9273115335051546 \n",
      "Epoch 19 | Step 7643 | loss: 0.1931595286512436 | accuracy: 0.9273377249357326 \n",
      "Epoch 19 | Step 7644 | loss: 0.1931223014035286 | accuracy: 0.927363782051282 \n",
      "Epoch 19 | Step 7645 | loss: 0.19314214025083407 | accuracy: 0.9273497442455243 \n",
      "Epoch 19 | Step 7646 | loss: 0.19302896172644532 | accuracy: 0.9273357780612245 \n",
      "Epoch 19 | Step 7647 | loss: 0.19289559996082584 | accuracy: 0.927321882951654 \n",
      "Epoch 19 | Step 7648 | loss: 0.19306191240394782 | accuracy: 0.9271097715736041 \n",
      "Epoch 19 | Step 7649 | loss: 0.19290183550572093 | accuracy: 0.9270965189873418 \n",
      "Epoch 19 | Step 7650 | loss: 0.1926680567552044 | accuracy: 0.9272017045454546 \n",
      "Epoch 19 | Step 7651 | loss: 0.19274104296485484 | accuracy: 0.9272276448362721 \n",
      "Epoch 19 | Step 7652 | loss: 0.19270549323316197 | accuracy: 0.9272141959798995 \n",
      "Epoch 19 | Step 7653 | loss: 0.19243500687947548 | accuracy: 0.9273574561403509 \n",
      "Epoch 19 | Step 7654 | loss: 0.1923585028387606 | accuracy: 0.9273046875 \n",
      "Epoch 19 | Step 7655 | loss: 0.19246431741111 | accuracy: 0.9273301122194514 \n",
      "Epoch 19 | Step 7656 | loss: 0.19273879258564455 | accuracy: 0.9272388059701493 \n",
      "Epoch 19 | Step 7657 | loss: 0.19257468892903837 | accuracy: 0.9273337896349413 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5131174325942993 | accuracy: 0.796875 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.4360167384147644 | accuracy: 0.8359375 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.4773384928703308 | accuracy: 0.828125 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.46566735208034515 | accuracy: 0.83203125 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.4381673693656921 | accuracy: 0.84375 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.48702601591746014 | accuracy: 0.828125 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.4803853758743831 | accuracy: 0.8348214285714286 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.47275298461318016 | accuracy: 0.828125 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.5060966047975752 | accuracy: 0.8194444444444444 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.48736662566661837 | accuracy: 0.828125 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.48898651654070074 | accuracy: 0.828125 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.4750885193546613 | accuracy: 0.83203125 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.4915830882696005 | accuracy: 0.8293269230769231 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.4742222162229674 | accuracy: 0.8348214285714286 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.4813879519701004 | accuracy: 0.8354166666666667 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.4804586926475167 | accuracy: 0.8359375 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.48231661758002115 | accuracy: 0.8327205882352942 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.47932441780964535 | accuracy: 0.8324652777777778 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.4711274371335381 | accuracy: 0.8363486842105263 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.46415210142731667 | accuracy: 0.83671875 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.45716979177225203 | accuracy: 0.8377976190476191 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.4492922391403805 | accuracy: 0.8401988636363636 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.4566603115071421 | accuracy: 0.8383152173913043 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.478414594506224 | accuracy: 0.833984375 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.48554166495800016 | accuracy: 0.83125 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.48086383652228576 | accuracy: 0.8323317307692307 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.47376748202023683 | accuracy: 0.8333333333333334 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.47750585047262056 | accuracy: 0.8309151785714286 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.4757138793838435 | accuracy: 0.8318965517241379 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.47085612962643303 | accuracy: 0.8348958333333333 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.46696885314679915 | accuracy: 0.8382056451612904 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.4699797066859901 | accuracy: 0.8359375 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.46989632510777674 | accuracy: 0.8338068181818182 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.47267618556233015 | accuracy: 0.8318014705882353 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.47623598192419325 | accuracy: 0.8308035714285714 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.47430749361713725 | accuracy: 0.8324652777777778 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.4768684615154524 | accuracy: 0.8327702702702703 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.4798232313049467 | accuracy: 0.8334703947368421 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.4801684675308374 | accuracy: 0.8321314102564102 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.475474550947547 | accuracy: 0.833984375 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.4719477364929711 | accuracy: 0.8342225609756098 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.4676589621674447 | accuracy: 0.8355654761904762 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.46648794170035873 | accuracy: 0.8353924418604651 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.46799861334941606 | accuracy: 0.8348721590909091 \n",
      "Validation | Epoch 19 | Step 7657 | loss: 0.4656700117720498 | accuracy: 0.8346769319640266 \n",
      "Epoch 20 | Step 7658 | loss: 0.3143281042575836 | accuracy: 0.875 \n",
      "Epoch 20 | Step 7659 | loss: 0.21087555587291718 | accuracy: 0.90625 \n",
      "Epoch 20 | Step 7660 | loss: 0.19830630222956339 | accuracy: 0.9114583333333334 \n",
      "Epoch 20 | Step 7661 | loss: 0.20259523019194603 | accuracy: 0.91015625 \n",
      "Epoch 20 | Step 7662 | loss: 0.18420321941375734 | accuracy: 0.91875 \n",
      "Epoch 20 | Step 7663 | loss: 0.17569377024968466 | accuracy: 0.9270833333333334 \n",
      "Epoch 20 | Step 7664 | loss: 0.18246694334915706 | accuracy: 0.9263392857142857 \n",
      "Epoch 20 | Step 7665 | loss: 0.18483282625675201 | accuracy: 0.9296875 \n",
      "Epoch 20 | Step 7666 | loss: 0.18680785430802238 | accuracy: 0.9305555555555556 \n",
      "Epoch 20 | Step 7667 | loss: 0.193622162938118 | accuracy: 0.93125 \n",
      "Epoch 20 | Step 7668 | loss: 0.1906214640899138 | accuracy: 0.9318181818181818 \n",
      "Epoch 20 | Step 7669 | loss: 0.18624250714977583 | accuracy: 0.9296875 \n",
      "Epoch 20 | Step 7670 | loss: 0.19908769657978645 | accuracy: 0.9230769230769231 \n",
      "Epoch 20 | Step 7671 | loss: 0.19854923444134848 | accuracy: 0.9241071428571429 \n",
      "Epoch 20 | Step 7672 | loss: 0.1985974262158076 | accuracy: 0.925 \n",
      "Epoch 20 | Step 7673 | loss: 0.19191142776980996 | accuracy: 0.927734375 \n",
      "Epoch 20 | Step 7674 | loss: 0.19276205450296402 | accuracy: 0.9255514705882353 \n",
      "Epoch 20 | Step 7675 | loss: 0.19001303820146453 | accuracy: 0.9270833333333334 \n",
      "Epoch 20 | Step 7676 | loss: 0.1908962244265958 | accuracy: 0.9268092105263158 \n",
      "Epoch 20 | Step 7677 | loss: 0.19299442060291766 | accuracy: 0.92578125 \n",
      "Epoch 20 | Step 7678 | loss: 0.1928877592796371 | accuracy: 0.9263392857142857 \n",
      "Epoch 20 | Step 7679 | loss: 0.1948614279654893 | accuracy: 0.9268465909090909 \n",
      "Epoch 20 | Step 7680 | loss: 0.19063395715278128 | accuracy: 0.9286684782608695 \n",
      "Epoch 20 | Step 7681 | loss: 0.19022473444541296 | accuracy: 0.9290364583333334 \n",
      "Epoch 20 | Step 7682 | loss: 0.19256560504436493 | accuracy: 0.92875 \n",
      "Epoch 20 | Step 7683 | loss: 0.1902500454049844 | accuracy: 0.9296875 \n",
      "Epoch 20 | Step 7684 | loss: 0.19529927604728275 | accuracy: 0.9270833333333334 \n",
      "Epoch 20 | Step 7685 | loss: 0.1920623393463237 | accuracy: 0.9285714285714286 \n",
      "Epoch 20 | Step 7686 | loss: 0.19589145301744856 | accuracy: 0.927801724137931 \n",
      "Epoch 20 | Step 7687 | loss: 0.19541715557376543 | accuracy: 0.9270833333333334 \n",
      "Epoch 20 | Step 7688 | loss: 0.1944672217772853 | accuracy: 0.9264112903225806 \n",
      "Epoch 20 | Step 7689 | loss: 0.19437401997856796 | accuracy: 0.92626953125 \n",
      "Epoch 20 | Step 7690 | loss: 0.1940690421245315 | accuracy: 0.9270833333333334 \n",
      "Epoch 20 | Step 7691 | loss: 0.19040389819180265 | accuracy: 0.9283088235294118 \n",
      "Epoch 20 | Step 7692 | loss: 0.18745039871760777 | accuracy: 0.9294642857142857 \n",
      "Epoch 20 | Step 7693 | loss: 0.18580173783832127 | accuracy: 0.9301215277777778 \n",
      "Epoch 20 | Step 7694 | loss: 0.18625357948444984 | accuracy: 0.9298986486486487 \n",
      "Epoch 20 | Step 7695 | loss: 0.1850947988660712 | accuracy: 0.930921052631579 \n",
      "Epoch 20 | Step 7696 | loss: 0.1833406088825984 | accuracy: 0.9310897435897436 \n",
      "Epoch 20 | Step 7697 | loss: 0.1819484917446971 | accuracy: 0.932421875 \n",
      "Epoch 20 | Step 7698 | loss: 0.1803032108923284 | accuracy: 0.9333079268292683 \n",
      "Epoch 20 | Step 7699 | loss: 0.18031592667102814 | accuracy: 0.9330357142857143 \n",
      "Epoch 20 | Step 7700 | loss: 0.1790032010785369 | accuracy: 0.9335029069767442 \n",
      "Epoch 20 | Step 7701 | loss: 0.17794195274737748 | accuracy: 0.9343039772727273 \n",
      "Epoch 20 | Step 7702 | loss: 0.1790579049123658 | accuracy: 0.934375 \n",
      "Epoch 20 | Step 7703 | loss: 0.18003977171104887 | accuracy: 0.9341032608695652 \n",
      "Epoch 20 | Step 7704 | loss: 0.17983628064393997 | accuracy: 0.9341755319148937 \n",
      "Epoch 20 | Step 7705 | loss: 0.18029096055155 | accuracy: 0.9342447916666666 \n",
      "Epoch 20 | Step 7706 | loss: 0.18196727198605633 | accuracy: 0.9336734693877551 \n",
      "Epoch 20 | Step 7707 | loss: 0.1833628536760807 | accuracy: 0.933125 \n",
      "Epoch 20 | Step 7708 | loss: 0.18386374983717413 | accuracy: 0.9325980392156863 \n",
      "Epoch 20 | Step 7709 | loss: 0.18212008848786354 | accuracy: 0.9332932692307693 \n",
      "Epoch 20 | Step 7710 | loss: 0.18321687123685512 | accuracy: 0.9327830188679245 \n",
      "Epoch 20 | Step 7711 | loss: 0.1819726234232938 | accuracy: 0.9334490740740741 \n",
      "Epoch 20 | Step 7712 | loss: 0.18382099704308943 | accuracy: 0.9323863636363636 \n",
      "Epoch 20 | Step 7713 | loss: 0.1826841872451561 | accuracy: 0.9330357142857143 \n",
      "Epoch 20 | Step 7714 | loss: 0.18361479579879528 | accuracy: 0.9328399122807017 \n",
      "Epoch 20 | Step 7715 | loss: 0.18386665538981042 | accuracy: 0.9321120689655172 \n",
      "Epoch 20 | Step 7716 | loss: 0.18502695669057007 | accuracy: 0.9319385593220338 \n",
      "Epoch 20 | Step 7717 | loss: 0.18621431924402715 | accuracy: 0.9317708333333333 \n",
      "Epoch 20 | Step 7718 | loss: 0.18568715856212084 | accuracy: 0.9316086065573771 \n",
      "Epoch 20 | Step 7719 | loss: 0.18561119742451176 | accuracy: 0.9314516129032258 \n",
      "Epoch 20 | Step 7720 | loss: 0.18642621037978974 | accuracy: 0.9308035714285714 \n",
      "Epoch 20 | Step 7721 | loss: 0.1847495351685211 | accuracy: 0.931396484375 \n",
      "Epoch 20 | Step 7722 | loss: 0.1836006142772161 | accuracy: 0.9317307692307693 \n",
      "Epoch 20 | Step 7723 | loss: 0.1822647223192634 | accuracy: 0.9318181818181818 \n",
      "Epoch 20 | Step 7724 | loss: 0.18140352094796167 | accuracy: 0.9321361940298507 \n",
      "Epoch 20 | Step 7725 | loss: 0.1816848002593307 | accuracy: 0.9319852941176471 \n",
      "Epoch 20 | Step 7726 | loss: 0.18158158627541168 | accuracy: 0.931838768115942 \n",
      "Epoch 20 | Step 7727 | loss: 0.1812022731772491 | accuracy: 0.9314732142857143 \n",
      "Epoch 20 | Step 7728 | loss: 0.17978849933600763 | accuracy: 0.9317781690140845 \n",
      "Epoch 20 | Step 7729 | loss: 0.17951787356287244 | accuracy: 0.9318576388888888 \n",
      "Epoch 20 | Step 7730 | loss: 0.17957893656949478 | accuracy: 0.9315068493150684 \n",
      "Epoch 20 | Step 7731 | loss: 0.17968367291866125 | accuracy: 0.9313766891891891 \n",
      "Epoch 20 | Step 7732 | loss: 0.1795748908321063 | accuracy: 0.9314583333333334 \n",
      "Epoch 20 | Step 7733 | loss: 0.17958768937540684 | accuracy: 0.9315378289473685 \n",
      "Epoch 20 | Step 7734 | loss: 0.17945974687864255 | accuracy: 0.9316152597402597 \n",
      "Epoch 20 | Step 7735 | loss: 0.17990867153574258 | accuracy: 0.9312900641025641 \n",
      "Epoch 20 | Step 7736 | loss: 0.18189236342529708 | accuracy: 0.9309731012658228 \n",
      "Epoch 20 | Step 7737 | loss: 0.18123392267152666 | accuracy: 0.9310546875 \n",
      "Epoch 20 | Step 7738 | loss: 0.18042152200216127 | accuracy: 0.9315200617283951 \n",
      "Epoch 20 | Step 7739 | loss: 0.17957770479161564 | accuracy: 0.9317835365853658 \n",
      "Epoch 20 | Step 7740 | loss: 0.1795587354754827 | accuracy: 0.9322289156626506 \n",
      "Epoch 20 | Step 7741 | loss: 0.17919003324849264 | accuracy: 0.9324776785714286 \n",
      "Epoch 20 | Step 7742 | loss: 0.17857103943824768 | accuracy: 0.9329044117647058 \n",
      "Epoch 20 | Step 7743 | loss: 0.17828670144081116 | accuracy: 0.9331395348837209 \n",
      "Epoch 20 | Step 7744 | loss: 0.18076998577720818 | accuracy: 0.9322916666666666 \n",
      "Epoch 20 | Step 7745 | loss: 0.18139696663076227 | accuracy: 0.9323508522727273 \n",
      "Epoch 20 | Step 7746 | loss: 0.18062335311361913 | accuracy: 0.9327598314606742 \n",
      "Epoch 20 | Step 7747 | loss: 0.1811187287999524 | accuracy: 0.9324652777777778 \n",
      "Epoch 20 | Step 7748 | loss: 0.18030836744295373 | accuracy: 0.9325206043956044 \n",
      "Epoch 20 | Step 7749 | loss: 0.17956870486554893 | accuracy: 0.9329144021739131 \n",
      "Epoch 20 | Step 7750 | loss: 0.17960293671136263 | accuracy: 0.9324596774193549 \n",
      "Epoch 20 | Step 7751 | loss: 0.1787937585502229 | accuracy: 0.9330119680851063 \n",
      "Epoch 20 | Step 7752 | loss: 0.17928369209954614 | accuracy: 0.9328947368421052 \n",
      "Epoch 20 | Step 7753 | loss: 0.18056481898141405 | accuracy: 0.9327799479166666 \n",
      "Epoch 20 | Step 7754 | loss: 0.1803558912012995 | accuracy: 0.9329896907216495 \n",
      "Epoch 20 | Step 7755 | loss: 0.1819194105966967 | accuracy: 0.9322385204081632 \n",
      "Epoch 20 | Step 7756 | loss: 0.1825333647806235 | accuracy: 0.93197601010101 \n",
      "Epoch 20 | Step 7757 | loss: 0.18164576403796673 | accuracy: 0.93265625 \n",
      "Epoch 20 | Step 7758 | loss: 0.18073002337524208 | accuracy: 0.9330136138613861 \n",
      "Epoch 20 | Step 7759 | loss: 0.18064850488421963 | accuracy: 0.9330575980392157 \n",
      "Epoch 20 | Step 7760 | loss: 0.17963665246384816 | accuracy: 0.9334041262135923 \n",
      "Epoch 20 | Step 7761 | loss: 0.1800587299064948 | accuracy: 0.9332932692307693 \n",
      "Epoch 20 | Step 7762 | loss: 0.18122536696138836 | accuracy: 0.9328869047619047 \n",
      "Epoch 20 | Step 7763 | loss: 0.18038912215885125 | accuracy: 0.9330778301886793 \n",
      "Epoch 20 | Step 7764 | loss: 0.18144360282153726 | accuracy: 0.9328271028037384 \n",
      "Epoch 20 | Step 7765 | loss: 0.18262829921311802 | accuracy: 0.9325810185185185 \n",
      "Epoch 20 | Step 7766 | loss: 0.1830620393840545 | accuracy: 0.9324827981651376 \n",
      "Epoch 20 | Step 7767 | loss: 0.18364611755717886 | accuracy: 0.9321022727272728 \n",
      "Epoch 20 | Step 7768 | loss: 0.18320540063553029 | accuracy: 0.9324324324324325 \n",
      "Epoch 20 | Step 7769 | loss: 0.1832843695634178 | accuracy: 0.9324776785714286 \n",
      "Epoch 20 | Step 7770 | loss: 0.18432547125668652 | accuracy: 0.9321073008849557 \n",
      "Epoch 20 | Step 7771 | loss: 0.18428794085456615 | accuracy: 0.9320175438596491 \n",
      "Epoch 20 | Step 7772 | loss: 0.18390764425630154 | accuracy: 0.9322010869565217 \n",
      "Epoch 20 | Step 7773 | loss: 0.18394267751738944 | accuracy: 0.9319773706896551 \n",
      "Epoch 20 | Step 7774 | loss: 0.18487853639655644 | accuracy: 0.9312232905982906 \n",
      "Epoch 20 | Step 7775 | loss: 0.18439653389534708 | accuracy: 0.931541313559322 \n",
      "Epoch 20 | Step 7776 | loss: 0.1844225590970336 | accuracy: 0.9314600840336135 \n",
      "Epoch 20 | Step 7777 | loss: 0.18373691532760858 | accuracy: 0.9315104166666667 \n",
      "Epoch 20 | Step 7778 | loss: 0.18379486179795146 | accuracy: 0.931301652892562 \n",
      "Epoch 20 | Step 7779 | loss: 0.18372371175982913 | accuracy: 0.9310963114754098 \n",
      "Epoch 20 | Step 7780 | loss: 0.18343018255824964 | accuracy: 0.9311483739837398 \n",
      "Epoch 20 | Step 7781 | loss: 0.1836384180933237 | accuracy: 0.9311995967741935 \n",
      "Epoch 20 | Step 7782 | loss: 0.18304761922359467 | accuracy: 0.931625 \n",
      "Epoch 20 | Step 7783 | loss: 0.18303183265148648 | accuracy: 0.9315476190476191 \n",
      "Epoch 20 | Step 7784 | loss: 0.18359291553497314 | accuracy: 0.9312253937007874 \n",
      "Epoch 20 | Step 7785 | loss: 0.18322181818075478 | accuracy: 0.9312744140625 \n",
      "Epoch 20 | Step 7786 | loss: 0.18284253545047702 | accuracy: 0.9312015503875969 \n",
      "Epoch 20 | Step 7787 | loss: 0.1826019009718528 | accuracy: 0.9311298076923077 \n",
      "Epoch 20 | Step 7788 | loss: 0.18315734094335834 | accuracy: 0.9308206106870229 \n",
      "Epoch 20 | Step 7789 | loss: 0.1839703940080874 | accuracy: 0.9305160984848485 \n",
      "Epoch 20 | Step 7790 | loss: 0.1844790098362399 | accuracy: 0.9302161654135338 \n",
      "Epoch 20 | Step 7791 | loss: 0.1846457653081239 | accuracy: 0.9302705223880597 \n",
      "Epoch 20 | Step 7792 | loss: 0.18477591927404757 | accuracy: 0.9300925925925926 \n",
      "Epoch 20 | Step 7793 | loss: 0.18466640559627728 | accuracy: 0.9301470588235294 \n",
      "Epoch 20 | Step 7794 | loss: 0.1843174503449976 | accuracy: 0.9303147810218978 \n",
      "Epoch 20 | Step 7795 | loss: 0.18419086922338043 | accuracy: 0.9305932971014492 \n",
      "Epoch 20 | Step 7796 | loss: 0.18442696354372037 | accuracy: 0.9306429856115108 \n",
      "Epoch 20 | Step 7797 | loss: 0.1847130859536784 | accuracy: 0.9308035714285714 \n",
      "Epoch 20 | Step 7798 | loss: 0.18601721810533645 | accuracy: 0.9304078014184397 \n",
      "Epoch 20 | Step 7799 | loss: 0.18631294621548183 | accuracy: 0.9304577464788732 \n",
      "Epoch 20 | Step 7800 | loss: 0.18676620367523675 | accuracy: 0.9302884615384616 \n",
      "Epoch 20 | Step 7801 | loss: 0.1865809445993768 | accuracy: 0.9301215277777778 \n",
      "Epoch 20 | Step 7802 | loss: 0.18643709369774522 | accuracy: 0.9301724137931034 \n",
      "Epoch 20 | Step 7803 | loss: 0.1870792876571825 | accuracy: 0.9299015410958904 \n",
      "Epoch 20 | Step 7804 | loss: 0.18626721350311423 | accuracy: 0.9302721088435374 \n",
      "Epoch 20 | Step 7805 | loss: 0.1864011620448248 | accuracy: 0.9302153716216216 \n",
      "Epoch 20 | Step 7806 | loss: 0.18592655613718417 | accuracy: 0.9304739932885906 \n",
      "Epoch 20 | Step 7807 | loss: 0.18625993217031162 | accuracy: 0.930625 \n",
      "Epoch 20 | Step 7808 | loss: 0.18657189326373158 | accuracy: 0.9304635761589404 \n",
      "Epoch 20 | Step 7809 | loss: 0.1883668261825254 | accuracy: 0.9298930921052632 \n",
      "Epoch 20 | Step 7810 | loss: 0.18917819696898555 | accuracy: 0.9294321895424836 \n",
      "Epoch 20 | Step 7811 | loss: 0.18872282450849362 | accuracy: 0.929788961038961 \n",
      "Epoch 20 | Step 7812 | loss: 0.1883998702610693 | accuracy: 0.9299395161290323 \n",
      "Epoch 20 | Step 7813 | loss: 0.18785277180946794 | accuracy: 0.9301883012820513 \n",
      "Epoch 20 | Step 7814 | loss: 0.187526601230263 | accuracy: 0.9304339171974523 \n",
      "Epoch 20 | Step 7815 | loss: 0.1875950910056694 | accuracy: 0.930379746835443 \n",
      "Epoch 20 | Step 7816 | loss: 0.187731165274884 | accuracy: 0.9298349056603774 \n",
      "Epoch 20 | Step 7817 | loss: 0.18797912616282705 | accuracy: 0.9296875 \n",
      "Epoch 20 | Step 7818 | loss: 0.1883209668886588 | accuracy: 0.9295419254658385 \n",
      "Epoch 20 | Step 7819 | loss: 0.1880968073267996 | accuracy: 0.9296875 \n",
      "Epoch 20 | Step 7820 | loss: 0.18934790671237411 | accuracy: 0.9293519938650306 \n",
      "Epoch 20 | Step 7821 | loss: 0.189099743598845 | accuracy: 0.9291158536585366 \n",
      "Epoch 20 | Step 7822 | loss: 0.18907074973438728 | accuracy: 0.9290719696969697 \n",
      "Epoch 20 | Step 7823 | loss: 0.18926999466605934 | accuracy: 0.9290286144578314 \n",
      "Epoch 20 | Step 7824 | loss: 0.18903985806924853 | accuracy: 0.9289857784431138 \n",
      "Epoch 20 | Step 7825 | loss: 0.1895900825482039 | accuracy: 0.9286644345238095 \n",
      "Epoch 20 | Step 7826 | loss: 0.18935741254916558 | accuracy: 0.9287167159763313 \n",
      "Epoch 20 | Step 7827 | loss: 0.18876321885515662 | accuracy: 0.9290441176470589 \n",
      "Epoch 20 | Step 7828 | loss: 0.1887349824459232 | accuracy: 0.929093567251462 \n",
      "Epoch 20 | Step 7829 | loss: 0.18913065226272094 | accuracy: 0.9290515988372093 \n",
      "Epoch 20 | Step 7830 | loss: 0.18878055876390093 | accuracy: 0.9291004335260116 \n",
      "Epoch 20 | Step 7831 | loss: 0.1890545329828372 | accuracy: 0.9292385057471264 \n",
      "Epoch 20 | Step 7832 | loss: 0.1889117089339665 | accuracy: 0.9291964285714286 \n",
      "Epoch 20 | Step 7833 | loss: 0.18958028304305943 | accuracy: 0.9291548295454546 \n",
      "Epoch 20 | Step 7834 | loss: 0.1900576287406986 | accuracy: 0.9291137005649718 \n",
      "Epoch 20 | Step 7835 | loss: 0.19042045313320802 | accuracy: 0.928809691011236 \n",
      "Epoch 20 | Step 7836 | loss: 0.19092785246545377 | accuracy: 0.9285090782122905 \n",
      "Epoch 20 | Step 7837 | loss: 0.19065501358773973 | accuracy: 0.9284722222222223 \n",
      "Epoch 20 | Step 7838 | loss: 0.1908000434301176 | accuracy: 0.9283494475138122 \n",
      "Epoch 20 | Step 7839 | loss: 0.19054220403943742 | accuracy: 0.9283997252747253 \n",
      "Epoch 20 | Step 7840 | loss: 0.19005537167435788 | accuracy: 0.9286202185792349 \n",
      "Epoch 20 | Step 7841 | loss: 0.18973570701706668 | accuracy: 0.9288383152173914 \n",
      "Epoch 20 | Step 7842 | loss: 0.18944798832809603 | accuracy: 0.9289695945945946 \n",
      "Epoch 20 | Step 7843 | loss: 0.18988013407716187 | accuracy: 0.928763440860215 \n",
      "Epoch 20 | Step 7844 | loss: 0.1901565425615897 | accuracy: 0.9285594919786097 \n",
      "Epoch 20 | Step 7845 | loss: 0.1901702166316991 | accuracy: 0.9284408244680851 \n",
      "Epoch 20 | Step 7846 | loss: 0.1898315753492098 | accuracy: 0.9285714285714286 \n",
      "Epoch 20 | Step 7847 | loss: 0.19060854813770245 | accuracy: 0.928453947368421 \n",
      "Epoch 20 | Step 7848 | loss: 0.19004196697036632 | accuracy: 0.9286649214659686 \n",
      "Epoch 20 | Step 7849 | loss: 0.18988397954187045 | accuracy: 0.9287923177083334 \n",
      "Epoch 20 | Step 7850 | loss: 0.18947972422899978 | accuracy: 0.9289993523316062 \n",
      "Epoch 20 | Step 7851 | loss: 0.18922955592729382 | accuracy: 0.9290431701030928 \n",
      "Epoch 20 | Step 7852 | loss: 0.18877931443544535 | accuracy: 0.9291666666666667 \n",
      "Epoch 20 | Step 7853 | loss: 0.18894022049344317 | accuracy: 0.9291294642857143 \n",
      "Epoch 20 | Step 7854 | loss: 0.18902143026669013 | accuracy: 0.9290133248730964 \n",
      "Epoch 20 | Step 7855 | loss: 0.18919883194294843 | accuracy: 0.9290561868686869 \n",
      "Epoch 20 | Step 7856 | loss: 0.18899637221091956 | accuracy: 0.9293341708542714 \n",
      "Epoch 20 | Step 7857 | loss: 0.1889112625271082 | accuracy: 0.929296875 \n",
      "Epoch 20 | Step 7858 | loss: 0.18921650204788987 | accuracy: 0.9291822139303483 \n",
      "Epoch 20 | Step 7859 | loss: 0.18923904820538984 | accuracy: 0.9292233910891089 \n",
      "Epoch 20 | Step 7860 | loss: 0.18910857176252185 | accuracy: 0.9292641625615764 \n",
      "Epoch 20 | Step 7861 | loss: 0.18901384709512487 | accuracy: 0.9293811274509803 \n",
      "Epoch 20 | Step 7862 | loss: 0.18917325785974176 | accuracy: 0.9292682926829269 \n",
      "Epoch 20 | Step 7863 | loss: 0.19009219435522856 | accuracy: 0.9289290048543689 \n",
      "Epoch 20 | Step 7864 | loss: 0.19097057064086342 | accuracy: 0.928743961352657 \n",
      "Epoch 20 | Step 7865 | loss: 0.19090695435611102 | accuracy: 0.9286358173076923 \n",
      "Epoch 20 | Step 7866 | loss: 0.19082478822418378 | accuracy: 0.9286782296650717 \n",
      "Epoch 20 | Step 7867 | loss: 0.19084687978029252 | accuracy: 0.9287946428571429 \n",
      "Epoch 20 | Step 7868 | loss: 0.19099986291892157 | accuracy: 0.9285396919431279 \n",
      "Epoch 20 | Step 7869 | loss: 0.1903844413189393 | accuracy: 0.9288767688679245 \n",
      "Epoch 20 | Step 7870 | loss: 0.18996968872390443 | accuracy: 0.9289906103286385 \n",
      "Epoch 20 | Step 7871 | loss: 0.19009966807109174 | accuracy: 0.9290303738317757 \n",
      "Epoch 20 | Step 7872 | loss: 0.18997451538263366 | accuracy: 0.9290697674418604 \n",
      "Epoch 20 | Step 7873 | loss: 0.18997068972223335 | accuracy: 0.9289641203703703 \n",
      "Epoch 20 | Step 7874 | loss: 0.18975006819870066 | accuracy: 0.929147465437788 \n",
      "Epoch 20 | Step 7875 | loss: 0.18957527699547078 | accuracy: 0.9292574541284404 \n",
      "Epoch 20 | Step 7876 | loss: 0.18935820385473504 | accuracy: 0.929295091324201 \n",
      "Epoch 20 | Step 7877 | loss: 0.18927250131964685 | accuracy: 0.9292613636363637 \n",
      "Epoch 20 | Step 7878 | loss: 0.18942383720594294 | accuracy: 0.9292986425339367 \n",
      "Epoch 20 | Step 7879 | loss: 0.18945318131564973 | accuracy: 0.9293355855855856 \n",
      "Epoch 20 | Step 7880 | loss: 0.18972034812508143 | accuracy: 0.9291619955156951 \n",
      "Epoch 20 | Step 7881 | loss: 0.18918264740412788 | accuracy: 0.9294782366071429 \n",
      "Epoch 20 | Step 7882 | loss: 0.18955073333448835 | accuracy: 0.9290972222222222 \n",
      "Epoch 20 | Step 7883 | loss: 0.18972272877540208 | accuracy: 0.9290652654867256 \n",
      "Epoch 20 | Step 7884 | loss: 0.18993947320178742 | accuracy: 0.9289647577092511 \n",
      "Epoch 20 | Step 7885 | loss: 0.19002625362522768 | accuracy: 0.9290021929824561 \n",
      "Epoch 20 | Step 7886 | loss: 0.18981444077590667 | accuracy: 0.9291075327510917 \n",
      "Epoch 20 | Step 7887 | loss: 0.18999723043778668 | accuracy: 0.9290081521739131 \n",
      "Epoch 20 | Step 7888 | loss: 0.1899119419775484 | accuracy: 0.9291125541125541 \n",
      "Epoch 20 | Step 7889 | loss: 0.18952395587131896 | accuracy: 0.9292834051724138 \n",
      "Epoch 20 | Step 7890 | loss: 0.1896633045995696 | accuracy: 0.9290504291845494 \n",
      "Epoch 20 | Step 7891 | loss: 0.18987927713200578 | accuracy: 0.9290197649572649 \n",
      "Epoch 20 | Step 7892 | loss: 0.18977104913681112 | accuracy: 0.9291223404255319 \n",
      "Epoch 20 | Step 7893 | loss: 0.1895551070949789 | accuracy: 0.9291578389830508 \n",
      "Epoch 20 | Step 7894 | loss: 0.18941145720361155 | accuracy: 0.9291930379746836 \n",
      "Epoch 20 | Step 7895 | loss: 0.18940318319476954 | accuracy: 0.9290309873949579 \n",
      "Epoch 20 | Step 7896 | loss: 0.18933439429335017 | accuracy: 0.9290010460251046 \n",
      "Epoch 20 | Step 7897 | loss: 0.1894117218752702 | accuracy: 0.92890625 \n",
      "Epoch 20 | Step 7898 | loss: 0.18894956041421138 | accuracy: 0.9291364107883817 \n",
      "Epoch 20 | Step 7899 | loss: 0.18879129084920096 | accuracy: 0.9291709710743802 \n",
      "Epoch 20 | Step 7900 | loss: 0.18907375658245243 | accuracy: 0.9290123456790124 \n",
      "Epoch 20 | Step 7901 | loss: 0.1895657216549897 | accuracy: 0.9289190573770492 \n",
      "Epoch 20 | Step 7902 | loss: 0.1893843378339495 | accuracy: 0.928954081632653 \n",
      "Epoch 20 | Step 7903 | loss: 0.18947304918514035 | accuracy: 0.9287982723577236 \n",
      "Epoch 20 | Step 7904 | loss: 0.1893001361052517 | accuracy: 0.9288967611336032 \n",
      "Epoch 20 | Step 7905 | loss: 0.1892935142762238 | accuracy: 0.9288684475806451 \n",
      "Epoch 20 | Step 7906 | loss: 0.18914519651347853 | accuracy: 0.9289031124497992 \n",
      "Epoch 20 | Step 7907 | loss: 0.18925964760780334 | accuracy: 0.9289375 \n",
      "Epoch 20 | Step 7908 | loss: 0.18899262245314055 | accuracy: 0.9290961155378487 \n",
      "Epoch 20 | Step 7909 | loss: 0.1892946350373446 | accuracy: 0.9286954365079365 \n",
      "Epoch 20 | Step 7910 | loss: 0.18909180897615643 | accuracy: 0.9288537549407114 \n",
      "Epoch 20 | Step 7911 | loss: 0.18905226331878835 | accuracy: 0.9290108267716536 \n",
      "Epoch 20 | Step 7912 | loss: 0.18892536551928987 | accuracy: 0.9290441176470589 \n",
      "Epoch 20 | Step 7913 | loss: 0.18900831017526798 | accuracy: 0.928955078125 \n",
      "Epoch 20 | Step 7914 | loss: 0.18885515720116025 | accuracy: 0.9288667315175098 \n",
      "Epoch 20 | Step 7915 | loss: 0.18859949453856595 | accuracy: 0.9289001937984496 \n",
      "Epoch 20 | Step 7916 | loss: 0.1886493059083762 | accuracy: 0.9288127413127413 \n",
      "Epoch 20 | Step 7917 | loss: 0.18842284255302869 | accuracy: 0.9287860576923077 \n",
      "Epoch 20 | Step 7918 | loss: 0.1887492244042656 | accuracy: 0.9285799808429118 \n",
      "Epoch 20 | Step 7919 | loss: 0.18882126145007957 | accuracy: 0.9284351145038168 \n",
      "Epoch 20 | Step 7920 | loss: 0.18874394412049778 | accuracy: 0.9284101711026616 \n",
      "Epoch 20 | Step 7921 | loss: 0.18916901827535848 | accuracy: 0.9282078598484849 \n",
      "Epoch 20 | Step 7922 | loss: 0.18903965837550615 | accuracy: 0.9280660377358491 \n",
      "Epoch 20 | Step 7923 | loss: 0.189141412482674 | accuracy: 0.927984022556391 \n",
      "Epoch 20 | Step 7924 | loss: 0.18902219770552964 | accuracy: 0.9279611423220974 \n",
      "Epoch 20 | Step 7925 | loss: 0.18873381033650977 | accuracy: 0.9281133395522388 \n",
      "Epoch 20 | Step 7926 | loss: 0.18875861242690498 | accuracy: 0.9281482342007435 \n",
      "Epoch 20 | Step 7927 | loss: 0.18853654301276915 | accuracy: 0.9282407407407408 \n",
      "Epoch 20 | Step 7928 | loss: 0.18846320729304067 | accuracy: 0.9282749077490776 \n",
      "Epoch 20 | Step 7929 | loss: 0.18839562292594247 | accuracy: 0.928366268382353 \n",
      "Epoch 20 | Step 7930 | loss: 0.18858639860437035 | accuracy: 0.9281707875457876 \n",
      "Epoch 20 | Step 7931 | loss: 0.18857095251879558 | accuracy: 0.9281478102189782 \n",
      "Epoch 20 | Step 7932 | loss: 0.18861416207118473 | accuracy: 0.9281250000000001 \n",
      "Epoch 20 | Step 7933 | loss: 0.1888131762490325 | accuracy: 0.9278759057971014 \n",
      "Epoch 20 | Step 7934 | loss: 0.18881028963232735 | accuracy: 0.9278542418772563 \n",
      "Epoch 20 | Step 7935 | loss: 0.188714314573746 | accuracy: 0.9278889388489209 \n",
      "Epoch 20 | Step 7936 | loss: 0.18874521497436755 | accuracy: 0.9278673835125448 \n",
      "Epoch 20 | Step 7937 | loss: 0.1886487671573248 | accuracy: 0.9279575892857143 \n",
      "Epoch 20 | Step 7938 | loss: 0.18925410257221548 | accuracy: 0.9276579181494662 \n",
      "Epoch 20 | Step 7939 | loss: 0.18913276908351181 | accuracy: 0.9276928191489362 \n",
      "Epoch 20 | Step 7940 | loss: 0.18898191629471298 | accuracy: 0.9277826855123675 \n",
      "Epoch 20 | Step 7941 | loss: 0.18881434787222204 | accuracy: 0.9278169014084507 \n",
      "Epoch 20 | Step 7942 | loss: 0.18867326025900094 | accuracy: 0.9279605263157895 \n",
      "Epoch 20 | Step 7943 | loss: 0.1887607335054375 | accuracy: 0.9277753496503497 \n",
      "Epoch 20 | Step 7944 | loss: 0.1886464071034971 | accuracy: 0.9278092334494773 \n",
      "Epoch 20 | Step 7945 | loss: 0.1883831195688497 | accuracy: 0.9278971354166666 \n",
      "Epoch 20 | Step 7946 | loss: 0.1881356781999546 | accuracy: 0.9279303633217993 \n",
      "Epoch 20 | Step 7947 | loss: 0.18857299122830926 | accuracy: 0.9278556034482759 \n",
      "Epoch 20 | Step 7948 | loss: 0.188388616333098 | accuracy: 0.927942439862543 \n",
      "Epoch 20 | Step 7949 | loss: 0.1883373588884939 | accuracy: 0.9279751712328768 \n",
      "Epoch 20 | Step 7950 | loss: 0.18836841671234925 | accuracy: 0.9280610068259386 \n",
      "Epoch 20 | Step 7951 | loss: 0.1880142175066634 | accuracy: 0.9281994047619048 \n",
      "Epoch 20 | Step 7952 | loss: 0.18823199668678192 | accuracy: 0.928125 \n",
      "Epoch 20 | Step 7953 | loss: 0.18811550794320336 | accuracy: 0.9282622466216216 \n",
      "Epoch 20 | Step 7954 | loss: 0.1884319719792617 | accuracy: 0.928030303030303 \n",
      "Epoch 20 | Step 7955 | loss: 0.18831101987485924 | accuracy: 0.9279572147651006 \n",
      "Epoch 20 | Step 7956 | loss: 0.18812609020383866 | accuracy: 0.927936872909699 \n",
      "Epoch 20 | Step 7957 | loss: 0.18809717881182836 | accuracy: 0.9280208333333333 \n",
      "Epoch 20 | Step 7958 | loss: 0.18790364723367953 | accuracy: 0.9281042358803987 \n",
      "Epoch 20 | Step 7959 | loss: 0.1877068993419607 | accuracy: 0.9280836092715232 \n",
      "Epoch 20 | Step 7960 | loss: 0.18750015857687885 | accuracy: 0.9281662541254125 \n",
      "Epoch 20 | Step 7961 | loss: 0.18753877573793662 | accuracy: 0.9280941611842105 \n",
      "Epoch 20 | Step 7962 | loss: 0.18782198143298515 | accuracy: 0.9280225409836066 \n",
      "Epoch 20 | Step 7963 | loss: 0.18770061055916593 | accuracy: 0.9281045751633987 \n",
      "Epoch 20 | Step 7964 | loss: 0.18756955636343667 | accuracy: 0.9282369706840391 \n",
      "Epoch 20 | Step 7965 | loss: 0.18726385684756497 | accuracy: 0.9283685064935064 \n",
      "Epoch 20 | Step 7966 | loss: 0.18691796339252628 | accuracy: 0.9285497572815534 \n",
      "Epoch 20 | Step 7967 | loss: 0.18685555054295458 | accuracy: 0.9285786290322581 \n",
      "Epoch 20 | Step 7968 | loss: 0.18676356104025899 | accuracy: 0.9285570739549839 \n",
      "Epoch 20 | Step 7969 | loss: 0.18676402023396443 | accuracy: 0.928535657051282 \n",
      "Epoch 20 | Step 7970 | loss: 0.18650210696382657 | accuracy: 0.9286142172523961 \n",
      "Epoch 20 | Step 7971 | loss: 0.186556978376618 | accuracy: 0.9284932324840764 \n",
      "Epoch 20 | Step 7972 | loss: 0.18618669287552922 | accuracy: 0.9287202380952381 \n",
      "Epoch 20 | Step 7973 | loss: 0.18619907831278043 | accuracy: 0.9287480221518988 \n",
      "Epoch 20 | Step 7974 | loss: 0.18620423540143952 | accuracy: 0.9286770504731862 \n",
      "Epoch 20 | Step 7975 | loss: 0.18626927097076157 | accuracy: 0.9286556603773585 \n",
      "Epoch 20 | Step 7976 | loss: 0.1862122374922506 | accuracy: 0.9287813479623824 \n",
      "Epoch 20 | Step 7977 | loss: 0.1861910369712861 | accuracy: 0.92890625 \n",
      "Epoch 20 | Step 7978 | loss: 0.18632077771555244 | accuracy: 0.9289330218068536 \n",
      "Epoch 20 | Step 7979 | loss: 0.1862498064589058 | accuracy: 0.9290081521739131 \n",
      "Epoch 20 | Step 7980 | loss: 0.18616286935082918 | accuracy: 0.9290344427244582 \n",
      "Epoch 20 | Step 7981 | loss: 0.18613371929084832 | accuracy: 0.9290123456790124 \n",
      "Epoch 20 | Step 7982 | loss: 0.1861061321772064 | accuracy: 0.9290384615384616 \n",
      "Epoch 20 | Step 7983 | loss: 0.18618718676406204 | accuracy: 0.9290164877300614 \n",
      "Epoch 20 | Step 7984 | loss: 0.1862814215436261 | accuracy: 0.9289468654434251 \n",
      "Epoch 20 | Step 7985 | loss: 0.18640131662349896 | accuracy: 0.9289253048780488 \n",
      "Epoch 20 | Step 7986 | loss: 0.18602634094497011 | accuracy: 0.9290938449848024 \n",
      "Epoch 20 | Step 7987 | loss: 0.18602822592312662 | accuracy: 0.9290246212121213 \n",
      "Epoch 20 | Step 7988 | loss: 0.18607432201639787 | accuracy: 0.9289558157099698 \n",
      "Epoch 20 | Step 7989 | loss: 0.18587341657783635 | accuracy: 0.9290756777108434 \n",
      "Epoch 20 | Step 7990 | loss: 0.1858481439473753 | accuracy: 0.929100975975976 \n",
      "Epoch 20 | Step 7991 | loss: 0.18579999625147484 | accuracy: 0.929126122754491 \n",
      "Epoch 20 | Step 7992 | loss: 0.18580458871464253 | accuracy: 0.9291511194029851 \n",
      "Epoch 20 | Step 7993 | loss: 0.1858677776264295 | accuracy: 0.9290829613095238 \n",
      "Epoch 20 | Step 7994 | loss: 0.18572275486473536 | accuracy: 0.9291543026706232 \n",
      "Epoch 20 | Step 7995 | loss: 0.18575516202040698 | accuracy: 0.9291327662721893 \n",
      "Epoch 20 | Step 7996 | loss: 0.18568238769836504 | accuracy: 0.9291113569321534 \n",
      "Epoch 20 | Step 7997 | loss: 0.18554389437331895 | accuracy: 0.9292279411764706 \n",
      "Epoch 20 | Step 7998 | loss: 0.18567978973088048 | accuracy: 0.9291605571847508 \n",
      "Epoch 20 | Step 7999 | loss: 0.1856869044795373 | accuracy: 0.929093567251462 \n",
      "Epoch 20 | Step 8000 | loss: 0.18551460282100557 | accuracy: 0.9291636297376094 \n",
      "Epoch 20 | Step 8001 | loss: 0.18536496236054034 | accuracy: 0.9291424418604651 \n",
      "Epoch 20 | Step 8002 | loss: 0.185225185795107 | accuracy: 0.9292119565217392 \n",
      "Epoch 20 | Step 8003 | loss: 0.18508161638858026 | accuracy: 0.9293262283236994 \n",
      "Epoch 20 | Step 8004 | loss: 0.1849840888458304 | accuracy: 0.9294848703170029 \n",
      "Epoch 20 | Step 8005 | loss: 0.1847586854221837 | accuracy: 0.9295977011494253 \n",
      "Epoch 20 | Step 8006 | loss: 0.18480888660196612 | accuracy: 0.9295755730659025 \n",
      "Epoch 20 | Step 8007 | loss: 0.18487016705530054 | accuracy: 0.9294642857142857 \n",
      "Epoch 20 | Step 8008 | loss: 0.18455824682600502 | accuracy: 0.9296207264957265 \n",
      "Epoch 20 | Step 8009 | loss: 0.1845433914991606 | accuracy: 0.9295987215909091 \n",
      "Epoch 20 | Step 8010 | loss: 0.1846243520676248 | accuracy: 0.9295768413597734 \n",
      "Epoch 20 | Step 8011 | loss: 0.1846017643262103 | accuracy: 0.9295992231638418 \n",
      "Epoch 20 | Step 8012 | loss: 0.18439435522321268 | accuracy: 0.9296214788732394 \n",
      "Epoch 20 | Step 8013 | loss: 0.18423833664548556 | accuracy: 0.9296875 \n",
      "Epoch 20 | Step 8014 | loss: 0.18450401143199613 | accuracy: 0.9296218487394958 \n",
      "Epoch 20 | Step 8015 | loss: 0.18507756484287435 | accuracy: 0.9293819832402235 \n",
      "Epoch 20 | Step 8016 | loss: 0.18498627301876283 | accuracy: 0.9294045961002786 \n",
      "Epoch 20 | Step 8017 | loss: 0.18507111900382595 | accuracy: 0.9293836805555555 \n",
      "Epoch 20 | Step 8018 | loss: 0.1849581086569548 | accuracy: 0.9294494459833795 \n",
      "Epoch 20 | Step 8019 | loss: 0.18506684825235992 | accuracy: 0.9294285220994475 \n",
      "Epoch 20 | Step 8020 | loss: 0.1849893123404056 | accuracy: 0.9294938016528925 \n",
      "Epoch 20 | Step 8021 | loss: 0.1846093184590997 | accuracy: 0.9296875 \n",
      "Epoch 20 | Step 8022 | loss: 0.18440654998364536 | accuracy: 0.9297517123287671 \n",
      "Epoch 20 | Step 8023 | loss: 0.18454714821743207 | accuracy: 0.9296875 \n",
      "Epoch 20 | Step 8024 | loss: 0.18458501878892392 | accuracy: 0.9296662125340599 \n",
      "Epoch 20 | Step 8025 | loss: 0.18448026516758254 | accuracy: 0.9297724184782609 \n",
      "Epoch 20 | Step 8026 | loss: 0.18460970497147525 | accuracy: 0.9297933604336044 \n",
      "Epoch 20 | Step 8027 | loss: 0.18449909717247315 | accuracy: 0.9298564189189189 \n",
      "Epoch 20 | Step 8028 | loss: 0.184668587083926 | accuracy: 0.9298349056603774 \n",
      "Epoch 20 | Step 8029 | loss: 0.18449991396678414 | accuracy: 0.9298975134408602 \n",
      "Epoch 20 | Step 8030 | loss: 0.18423065035816194 | accuracy: 0.9300435656836461 \n",
      "Epoch 20 | Step 8031 | loss: 0.18399693392575767 | accuracy: 0.930105280748663 \n",
      "Epoch 20 | Step 8032 | loss: 0.18407227665185952 | accuracy: 0.93 \n",
      "Epoch 20 | Step 8033 | loss: 0.1839245924567608 | accuracy: 0.9300199468085106 \n",
      "Epoch 20 | Step 8034 | loss: 0.18371960133393206 | accuracy: 0.930164124668435 \n",
      "Epoch 20 | Step 8035 | loss: 0.18366101833563026 | accuracy: 0.9302248677248677 \n",
      "Epoch 20 | Step 8036 | loss: 0.18348487902992971 | accuracy: 0.930285290237467 \n",
      "Epoch 20 | Step 8037 | loss: 0.1833102656430322 | accuracy: 0.9303453947368421 \n",
      "Epoch 20 | Step 8038 | loss: 0.1831730692561845 | accuracy: 0.9304051837270341 \n",
      "Epoch 20 | Step 8039 | loss: 0.18322316377730916 | accuracy: 0.9304646596858639 \n",
      "Epoch 20 | Step 8040 | loss: 0.18326722606822055 | accuracy: 0.9304830287206266 \n",
      "Epoch 20 | Step 8041 | loss: 0.18360419163946085 | accuracy: 0.9304606119791666 \n",
      "Epoch 20 | Step 8042 | loss: 0.18343207251715993 | accuracy: 0.9305600649350649 \n",
      "Epoch 20 | Step 8043 | loss: 0.1833371606129441 | accuracy: 0.9306590025906736 \n",
      "Epoch 20 | Step 8044 | loss: 0.18319388496321323 | accuracy: 0.9307170542635659 \n",
      "Epoch 20 | Step 8045 | loss: 0.1835404363720075 | accuracy: 0.9306539948453608 \n",
      "Epoch 20 | Step 8046 | loss: 0.18338959233160212 | accuracy: 0.9307117609254498 \n",
      "Epoch 20 | Step 8047 | loss: 0.183303222862574 | accuracy: 0.9307692307692308 \n",
      "Epoch 20 | Step 8048 | loss: 0.18343427727746864 | accuracy: 0.9306665601023018 \n",
      "Epoch 20 | Step 8049 | loss: 0.18330268094278135 | accuracy: 0.9307238520408163 \n",
      "Epoch 20 | Step 8050 | loss: 0.18314702319734902 | accuracy: 0.9307410941475827 \n",
      "Epoch 20 | Step 8051 | loss: 0.18327278401797215 | accuracy: 0.9306392766497462 \n",
      "Epoch 20 | Step 8052 | loss: 0.18302908637855647 | accuracy: 0.9307357594936709 \n",
      "Epoch 20 | Step 8053 | loss: 0.1827546058580131 | accuracy: 0.9308712121212122 \n",
      "Epoch 20 | Step 8054 | loss: 0.18291852133400216 | accuracy: 0.9308485516372796 \n",
      "Epoch 20 | Step 8055 | loss: 0.1830599799976878 | accuracy: 0.9307867462311558 \n",
      "Epoch 20 | Step 8056 | loss: 0.18281554107677989 | accuracy: 0.9308818922305765 \n",
      "Epoch 20 | Step 8057 | loss: 0.18267615586519262 | accuracy: 0.9309375 \n",
      "Epoch 20 | Step 8058 | loss: 0.18285562688870344 | accuracy: 0.9309538653366584 \n",
      "Epoch 20 | Step 8059 | loss: 0.18305679355094703 | accuracy: 0.9308146766169154 \n",
      "Epoch 20 | Step 8060 | loss: 0.1828678998144036 | accuracy: 0.9309007871535516 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.47104042768478394 | accuracy: 0.78125 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.4247952103614807 | accuracy: 0.8125 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5142540534337362 | accuracy: 0.8177083333333334 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5073301717638969 | accuracy: 0.82421875 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.46916704773902895 | accuracy: 0.834375 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.514834905664126 | accuracy: 0.8177083333333334 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5096074513026646 | accuracy: 0.8191964285714286 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.4950162395834923 | accuracy: 0.822265625 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5285179615020752 | accuracy: 0.8125 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5095438838005066 | accuracy: 0.821875 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5207518935203552 | accuracy: 0.8210227272727273 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5069393813610077 | accuracy: 0.8255208333333334 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5165356260079604 | accuracy: 0.8221153846153846 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.49891874619892673 | accuracy: 0.8247767857142857 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5025406042734782 | accuracy: 0.8270833333333333 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.49801190756261354 | accuracy: 0.828125 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.4989239415701698 | accuracy: 0.8272058823529411 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.4985971947511037 | accuracy: 0.8272569444444444 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.49233216360995646 | accuracy: 0.8305921052631579 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.48188656121492385 | accuracy: 0.8328125 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.473282318739664 | accuracy: 0.8348214285714286 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.4665286121043292 | accuracy: 0.8366477272727273 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.4751664205737736 | accuracy: 0.8362771739130435 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.49763598665595055 | accuracy: 0.8326822916666666 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5069305503368378 | accuracy: 0.828125 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.5017800766688126 | accuracy: 0.8299278846153846 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.4942278001043531 | accuracy: 0.8321759259259259 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.49711799408708296 | accuracy: 0.8314732142857143 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.4950598776340484 | accuracy: 0.8308189655172413 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.4917044818401336 | accuracy: 0.8333333333333334 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.48755004809748737 | accuracy: 0.8361895161290323 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.4904748378321528 | accuracy: 0.8349609375 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.48980475375146576 | accuracy: 0.8323863636363636 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.4923161583788255 | accuracy: 0.8308823529411765 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.4939809662955148 | accuracy: 0.8303571428571429 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.49121662477652234 | accuracy: 0.8315972222222222 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.49198783249468414 | accuracy: 0.831081081081081 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.4949214395723845 | accuracy: 0.8326480263157894 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.4938322527286334 | accuracy: 0.8313301282051282 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.4881586000323296 | accuracy: 0.833203125 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.48342352669413496 | accuracy: 0.8334603658536586 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.47804354911758784 | accuracy: 0.8348214285714286 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.478627692821414 | accuracy: 0.8339389534883721 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.4790108346126296 | accuracy: 0.8352272727272727 \n",
      "Validation | Epoch 20 | Step 8060 | loss: 0.47632525695694816 | accuracy: 0.8345410625139872 \n",
      "Epoch 21 | Step 8061 | loss: 0.30119115114212036 | accuracy: 0.90625 \n",
      "Epoch 21 | Step 8062 | loss: 0.20231802016496658 | accuracy: 0.921875 \n",
      "Epoch 21 | Step 8063 | loss: 0.1828054835398992 | accuracy: 0.9322916666666666 \n",
      "Epoch 21 | Step 8064 | loss: 0.18313400819897652 | accuracy: 0.9296875 \n",
      "Epoch 21 | Step 8065 | loss: 0.16920967102050782 | accuracy: 0.934375 \n",
      "Epoch 21 | Step 8066 | loss: 0.16856520374615988 | accuracy: 0.9348958333333334 \n",
      "Epoch 21 | Step 8067 | loss: 0.17444946936198644 | accuracy: 0.9352678571428571 \n",
      "Epoch 21 | Step 8068 | loss: 0.17508439719676971 | accuracy: 0.9375 \n",
      "Epoch 21 | Step 8069 | loss: 0.17419545849164328 | accuracy: 0.9375 \n",
      "Epoch 21 | Step 8070 | loss: 0.1843010276556015 | accuracy: 0.9375 \n",
      "Epoch 21 | Step 8071 | loss: 0.17720772325992584 | accuracy: 0.9375 \n",
      "Epoch 21 | Step 8072 | loss: 0.17235503531992435 | accuracy: 0.9375 \n",
      "Epoch 21 | Step 8073 | loss: 0.18168533937289164 | accuracy: 0.9314903846153846 \n",
      "Epoch 21 | Step 8074 | loss: 0.18205822525279863 | accuracy: 0.9330357142857143 \n",
      "Epoch 21 | Step 8075 | loss: 0.1849870299299558 | accuracy: 0.9291666666666667 \n",
      "Epoch 21 | Step 8076 | loss: 0.17920624185353518 | accuracy: 0.9326171875 \n",
      "Epoch 21 | Step 8077 | loss: 0.17832021941156947 | accuracy: 0.9301470588235294 \n",
      "Epoch 21 | Step 8078 | loss: 0.17599530352486503 | accuracy: 0.9314236111111112 \n",
      "Epoch 21 | Step 8079 | loss: 0.17581648340350703 | accuracy: 0.9317434210526315 \n",
      "Epoch 21 | Step 8080 | loss: 0.17757080644369125 | accuracy: 0.93359375 \n",
      "Epoch 21 | Step 8081 | loss: 0.17817120041166032 | accuracy: 0.9330357142857143 \n",
      "Epoch 21 | Step 8082 | loss: 0.1812748075886206 | accuracy: 0.9325284090909091 \n",
      "Epoch 21 | Step 8083 | loss: 0.1787785903915115 | accuracy: 0.9327445652173914 \n",
      "Epoch 21 | Step 8084 | loss: 0.1788947976504763 | accuracy: 0.931640625 \n",
      "Epoch 21 | Step 8085 | loss: 0.18360612124204637 | accuracy: 0.92875 \n",
      "Epoch 21 | Step 8086 | loss: 0.1824580617249012 | accuracy: 0.9290865384615384 \n",
      "Epoch 21 | Step 8087 | loss: 0.18889703932735655 | accuracy: 0.9276620370370371 \n",
      "Epoch 21 | Step 8088 | loss: 0.18662220053374767 | accuracy: 0.9280133928571429 \n",
      "Epoch 21 | Step 8089 | loss: 0.19024395351779871 | accuracy: 0.9256465517241379 \n",
      "Epoch 21 | Step 8090 | loss: 0.18974110558629037 | accuracy: 0.9255208333333333 \n",
      "Epoch 21 | Step 8091 | loss: 0.18793909612201876 | accuracy: 0.9259072580645161 \n",
      "Epoch 21 | Step 8092 | loss: 0.18741014623083174 | accuracy: 0.92529296875 \n",
      "Epoch 21 | Step 8093 | loss: 0.18657003185062698 | accuracy: 0.9261363636363636 \n",
      "Epoch 21 | Step 8094 | loss: 0.18340440949096398 | accuracy: 0.9269301470588235 \n",
      "Epoch 21 | Step 8095 | loss: 0.18116781349693026 | accuracy: 0.928125 \n",
      "Epoch 21 | Step 8096 | loss: 0.1795644863612122 | accuracy: 0.9283854166666666 \n",
      "Epoch 21 | Step 8097 | loss: 0.18020068229855718 | accuracy: 0.9273648648648649 \n",
      "Epoch 21 | Step 8098 | loss: 0.17921126516241775 | accuracy: 0.9272203947368421 \n",
      "Epoch 21 | Step 8099 | loss: 0.17695382122810072 | accuracy: 0.9282852564102564 \n",
      "Epoch 21 | Step 8100 | loss: 0.17575812526047233 | accuracy: 0.9296875 \n",
      "Epoch 21 | Step 8101 | loss: 0.17458211794132142 | accuracy: 0.9298780487804879 \n",
      "Epoch 21 | Step 8102 | loss: 0.17424624448730835 | accuracy: 0.9300595238095238 \n",
      "Epoch 21 | Step 8103 | loss: 0.1731511156919391 | accuracy: 0.9298691860465116 \n",
      "Epoch 21 | Step 8104 | loss: 0.172571635381742 | accuracy: 0.9303977272727273 \n",
      "Epoch 21 | Step 8105 | loss: 0.1741008238659965 | accuracy: 0.9305555555555556 \n",
      "Epoch 21 | Step 8106 | loss: 0.17470103405092077 | accuracy: 0.9303668478260869 \n",
      "Epoch 21 | Step 8107 | loss: 0.17390848664527248 | accuracy: 0.9308510638297872 \n",
      "Epoch 21 | Step 8108 | loss: 0.17403175588697198 | accuracy: 0.9313151041666666 \n",
      "Epoch 21 | Step 8109 | loss: 0.17468496974633668 | accuracy: 0.9317602040816326 \n",
      "Epoch 21 | Step 8110 | loss: 0.17618303120136264 | accuracy: 0.930625 \n",
      "Epoch 21 | Step 8111 | loss: 0.17652212930660624 | accuracy: 0.9301470588235294 \n",
      "Epoch 21 | Step 8112 | loss: 0.1746475629221935 | accuracy: 0.9308894230769231 \n",
      "Epoch 21 | Step 8113 | loss: 0.1754659286366319 | accuracy: 0.9304245283018868 \n",
      "Epoch 21 | Step 8114 | loss: 0.1742017663739346 | accuracy: 0.9314236111111112 \n",
      "Epoch 21 | Step 8115 | loss: 0.17565483315424488 | accuracy: 0.9306818181818182 \n",
      "Epoch 21 | Step 8116 | loss: 0.17495446519127916 | accuracy: 0.9313616071428571 \n",
      "Epoch 21 | Step 8117 | loss: 0.1764965974970868 | accuracy: 0.9311951754385965 \n",
      "Epoch 21 | Step 8118 | loss: 0.17668216213070115 | accuracy: 0.9310344827586207 \n",
      "Epoch 21 | Step 8119 | loss: 0.1774965618121422 | accuracy: 0.9308792372881356 \n",
      "Epoch 21 | Step 8120 | loss: 0.17872768367330236 | accuracy: 0.9307291666666667 \n",
      "Epoch 21 | Step 8121 | loss: 0.17868463719477423 | accuracy: 0.930327868852459 \n",
      "Epoch 21 | Step 8122 | loss: 0.17819534097948383 | accuracy: 0.930695564516129 \n",
      "Epoch 21 | Step 8123 | loss: 0.17974826977366495 | accuracy: 0.9300595238095238 \n",
      "Epoch 21 | Step 8124 | loss: 0.1783233708702028 | accuracy: 0.9306640625 \n",
      "Epoch 21 | Step 8125 | loss: 0.1770062986474771 | accuracy: 0.93125 \n",
      "Epoch 21 | Step 8126 | loss: 0.17592932374188397 | accuracy: 0.9320549242424242 \n",
      "Epoch 21 | Step 8127 | loss: 0.17520003554536337 | accuracy: 0.9321361940298507 \n",
      "Epoch 21 | Step 8128 | loss: 0.17553050816059115 | accuracy: 0.9317555147058824 \n",
      "Epoch 21 | Step 8129 | loss: 0.1755227172288342 | accuracy: 0.9320652173913043 \n",
      "Epoch 21 | Step 8130 | loss: 0.17503871215241298 | accuracy: 0.9321428571428572 \n",
      "Epoch 21 | Step 8131 | loss: 0.17381792998229956 | accuracy: 0.9326584507042254 \n",
      "Epoch 21 | Step 8132 | loss: 0.17347408365458253 | accuracy: 0.9327256944444444 \n",
      "Epoch 21 | Step 8133 | loss: 0.1737011863964878 | accuracy: 0.9325770547945206 \n",
      "Epoch 21 | Step 8134 | loss: 0.17354480630239927 | accuracy: 0.9328547297297297 \n",
      "Epoch 21 | Step 8135 | loss: 0.17364331831534707 | accuracy: 0.9327083333333334 \n",
      "Epoch 21 | Step 8136 | loss: 0.1739101797146233 | accuracy: 0.9329769736842105 \n",
      "Epoch 21 | Step 8137 | loss: 0.17343595943280635 | accuracy: 0.9332386363636364 \n",
      "Epoch 21 | Step 8138 | loss: 0.17357861527647733 | accuracy: 0.9332932692307693 \n",
      "Epoch 21 | Step 8139 | loss: 0.17595837189804153 | accuracy: 0.932753164556962 \n",
      "Epoch 21 | Step 8140 | loss: 0.17530405521392828 | accuracy: 0.933203125 \n",
      "Epoch 21 | Step 8141 | loss: 0.1745830697961796 | accuracy: 0.9334490740740741 \n",
      "Epoch 21 | Step 8142 | loss: 0.17360151613630903 | accuracy: 0.9342606707317073 \n",
      "Epoch 21 | Step 8143 | loss: 0.1740188042083419 | accuracy: 0.9344879518072289 \n",
      "Epoch 21 | Step 8144 | loss: 0.17388519006116054 | accuracy: 0.9345238095238095 \n",
      "Epoch 21 | Step 8145 | loss: 0.17358549605397622 | accuracy: 0.935110294117647 \n",
      "Epoch 21 | Step 8146 | loss: 0.17295415621510776 | accuracy: 0.9356831395348837 \n",
      "Epoch 21 | Step 8147 | loss: 0.17521121918127458 | accuracy: 0.9351652298850575 \n",
      "Epoch 21 | Step 8148 | loss: 0.17599062596193774 | accuracy: 0.9350142045454546 \n",
      "Epoch 21 | Step 8149 | loss: 0.1753152172719495 | accuracy: 0.9352176966292135 \n",
      "Epoch 21 | Step 8150 | loss: 0.17552266509996525 | accuracy: 0.9348958333333334 \n",
      "Epoch 21 | Step 8151 | loss: 0.17459423103175326 | accuracy: 0.9350961538461539 \n",
      "Epoch 21 | Step 8152 | loss: 0.17382164129420472 | accuracy: 0.9354619565217391 \n",
      "Epoch 21 | Step 8153 | loss: 0.17358457521405274 | accuracy: 0.9356518817204301 \n",
      "Epoch 21 | Step 8154 | loss: 0.17318528201034733 | accuracy: 0.9356715425531915 \n",
      "Epoch 21 | Step 8155 | loss: 0.17352838963270192 | accuracy: 0.9353618421052632 \n",
      "Epoch 21 | Step 8156 | loss: 0.17462680465541783 | accuracy: 0.93505859375 \n",
      "Epoch 21 | Step 8157 | loss: 0.17452364553188543 | accuracy: 0.9349226804123711 \n",
      "Epoch 21 | Step 8158 | loss: 0.17569099283035924 | accuracy: 0.9347895408163265 \n",
      "Epoch 21 | Step 8159 | loss: 0.1761147711764683 | accuracy: 0.9348169191919192 \n",
      "Epoch 21 | Step 8160 | loss: 0.17530363641679292 | accuracy: 0.9353125 \n",
      "Epoch 21 | Step 8161 | loss: 0.1743358817726079 | accuracy: 0.9357982673267327 \n",
      "Epoch 21 | Step 8162 | loss: 0.17413784359015674 | accuracy: 0.9358149509803921 \n",
      "Epoch 21 | Step 8163 | loss: 0.17342927060948995 | accuracy: 0.9359830097087378 \n",
      "Epoch 21 | Step 8164 | loss: 0.17354810273704624 | accuracy: 0.9358473557692307 \n",
      "Epoch 21 | Step 8165 | loss: 0.1742714270949364 | accuracy: 0.9357142857142857 \n",
      "Epoch 21 | Step 8166 | loss: 0.17339615066939934 | accuracy: 0.9360259433962265 \n",
      "Epoch 21 | Step 8167 | loss: 0.17403169428912282 | accuracy: 0.9357476635514018 \n",
      "Epoch 21 | Step 8168 | loss: 0.17502106526107702 | accuracy: 0.9354745370370371 \n",
      "Epoch 21 | Step 8169 | loss: 0.17510863489240686 | accuracy: 0.9352064220183486 \n",
      "Epoch 21 | Step 8170 | loss: 0.17564570897004825 | accuracy: 0.9349431818181818 \n",
      "Epoch 21 | Step 8171 | loss: 0.17545852810144427 | accuracy: 0.9351069819819819 \n",
      "Epoch 21 | Step 8172 | loss: 0.17538856176127285 | accuracy: 0.9351283482142857 \n",
      "Epoch 21 | Step 8173 | loss: 0.17699791102019036 | accuracy: 0.9345962389380531 \n",
      "Epoch 21 | Step 8174 | loss: 0.17708074125020132 | accuracy: 0.9347587719298246 \n",
      "Epoch 21 | Step 8175 | loss: 0.17685746362675794 | accuracy: 0.9346467391304348 \n",
      "Epoch 21 | Step 8176 | loss: 0.17641616477791608 | accuracy: 0.9346713362068966 \n",
      "Epoch 21 | Step 8177 | loss: 0.17724251078489503 | accuracy: 0.9341613247863247 \n",
      "Epoch 21 | Step 8178 | loss: 0.17702314756431825 | accuracy: 0.9341896186440678 \n",
      "Epoch 21 | Step 8179 | loss: 0.1771982151294957 | accuracy: 0.9342174369747899 \n",
      "Epoch 21 | Step 8180 | loss: 0.17688877824693922 | accuracy: 0.9342447916666666 \n",
      "Epoch 21 | Step 8181 | loss: 0.1770032385040906 | accuracy: 0.934271694214876 \n",
      "Epoch 21 | Step 8182 | loss: 0.17684152166618677 | accuracy: 0.9342981557377049 \n",
      "Epoch 21 | Step 8183 | loss: 0.17689708826260842 | accuracy: 0.9341971544715447 \n",
      "Epoch 21 | Step 8184 | loss: 0.17682031343781182 | accuracy: 0.9343497983870968 \n",
      "Epoch 21 | Step 8185 | loss: 0.17637799578905108 | accuracy: 0.934625 \n",
      "Epoch 21 | Step 8186 | loss: 0.17647509365564304 | accuracy: 0.9345238095238095 \n",
      "Epoch 21 | Step 8187 | loss: 0.1771056700761863 | accuracy: 0.9341781496062992 \n",
      "Epoch 21 | Step 8188 | loss: 0.17686167982174086 | accuracy: 0.93408203125 \n",
      "Epoch 21 | Step 8189 | loss: 0.17642749372378802 | accuracy: 0.9341085271317829 \n",
      "Epoch 21 | Step 8190 | loss: 0.17596645767872152 | accuracy: 0.9341346153846154 \n",
      "Epoch 21 | Step 8191 | loss: 0.17639707222239664 | accuracy: 0.9339217557251909 \n",
      "Epoch 21 | Step 8192 | loss: 0.17736579906759842 | accuracy: 0.93359375 \n",
      "Epoch 21 | Step 8193 | loss: 0.17795290601880928 | accuracy: 0.9331531954887218 \n",
      "Epoch 21 | Step 8194 | loss: 0.1782397563332942 | accuracy: 0.9329524253731343 \n",
      "Epoch 21 | Step 8195 | loss: 0.17826297724688495 | accuracy: 0.9329861111111111 \n",
      "Epoch 21 | Step 8196 | loss: 0.17799543282564947 | accuracy: 0.9331341911764706 \n",
      "Epoch 21 | Step 8197 | loss: 0.17742683830922537 | accuracy: 0.9333941605839416 \n",
      "Epoch 21 | Step 8198 | loss: 0.1776476382561352 | accuracy: 0.9334239130434783 \n",
      "Epoch 21 | Step 8199 | loss: 0.1778333012363036 | accuracy: 0.9334532374100719 \n",
      "Epoch 21 | Step 8200 | loss: 0.17785872859614235 | accuracy: 0.9334821428571428 \n",
      "Epoch 21 | Step 8201 | loss: 0.17917941605791132 | accuracy: 0.9330673758865248 \n",
      "Epoch 21 | Step 8202 | loss: 0.1793911605024002 | accuracy: 0.9330985915492958 \n",
      "Epoch 21 | Step 8203 | loss: 0.17936610425268854 | accuracy: 0.9332386363636364 \n",
      "Epoch 21 | Step 8204 | loss: 0.17930444630069864 | accuracy: 0.9332682291666666 \n",
      "Epoch 21 | Step 8205 | loss: 0.1792200307393896 | accuracy: 0.9331896551724138 \n",
      "Epoch 21 | Step 8206 | loss: 0.17956834123150944 | accuracy: 0.9330051369863014 \n",
      "Epoch 21 | Step 8207 | loss: 0.1787407997564799 | accuracy: 0.9334608843537415 \n",
      "Epoch 21 | Step 8208 | loss: 0.17878210899495595 | accuracy: 0.93359375 \n",
      "Epoch 21 | Step 8209 | loss: 0.17844678264036273 | accuracy: 0.9337248322147651 \n",
      "Epoch 21 | Step 8210 | loss: 0.17881138903399307 | accuracy: 0.9338541666666667 \n",
      "Epoch 21 | Step 8211 | loss: 0.17930347815353348 | accuracy: 0.933671357615894 \n",
      "Epoch 21 | Step 8212 | loss: 0.18078399295183387 | accuracy: 0.9331825657894737 \n",
      "Epoch 21 | Step 8213 | loss: 0.18122118343812185 | accuracy: 0.9331086601307189 \n",
      "Epoch 21 | Step 8214 | loss: 0.18080523709294855 | accuracy: 0.9332386363636364 \n",
      "Epoch 21 | Step 8215 | loss: 0.18068530206238068 | accuracy: 0.933266129032258 \n",
      "Epoch 21 | Step 8216 | loss: 0.1801870727720551 | accuracy: 0.9334935897435898 \n",
      "Epoch 21 | Step 8217 | loss: 0.17993353864854308 | accuracy: 0.933718152866242 \n",
      "Epoch 21 | Step 8218 | loss: 0.1798703805130871 | accuracy: 0.9335443037974683 \n",
      "Epoch 21 | Step 8219 | loss: 0.17985587578805737 | accuracy: 0.933372641509434 \n",
      "Epoch 21 | Step 8220 | loss: 0.18000192621257155 | accuracy: 0.93310546875 \n",
      "Epoch 21 | Step 8221 | loss: 0.1803939631960777 | accuracy: 0.9331327639751553 \n",
      "Epoch 21 | Step 8222 | loss: 0.18008579219472998 | accuracy: 0.9332561728395061 \n",
      "Epoch 21 | Step 8223 | loss: 0.18141183327952046 | accuracy: 0.9326111963190185 \n",
      "Epoch 21 | Step 8224 | loss: 0.18142164014734147 | accuracy: 0.932641006097561 \n",
      "Epoch 21 | Step 8225 | loss: 0.18131440938873725 | accuracy: 0.9326704545454545 \n",
      "Epoch 21 | Step 8226 | loss: 0.18179666392325636 | accuracy: 0.9324171686746988 \n",
      "Epoch 21 | Step 8227 | loss: 0.18160182404928576 | accuracy: 0.9324476047904192 \n",
      "Epoch 21 | Step 8228 | loss: 0.18234056649020028 | accuracy: 0.9321056547619048 \n",
      "Epoch 21 | Step 8229 | loss: 0.18211139683451877 | accuracy: 0.9322300295857988 \n",
      "Epoch 21 | Step 8230 | loss: 0.18150772169670637 | accuracy: 0.9325367647058823 \n",
      "Epoch 21 | Step 8231 | loss: 0.18134562538294066 | accuracy: 0.9324744152046783 \n",
      "Epoch 21 | Step 8232 | loss: 0.18142743908995113 | accuracy: 0.9324127906976745 \n",
      "Epoch 21 | Step 8233 | loss: 0.18104801789959732 | accuracy: 0.9326228323699421 \n",
      "Epoch 21 | Step 8234 | loss: 0.18120536775510201 | accuracy: 0.9326508620689655 \n",
      "Epoch 21 | Step 8235 | loss: 0.18112451810921942 | accuracy: 0.9326785714285715 \n",
      "Epoch 21 | Step 8236 | loss: 0.18192575450732626 | accuracy: 0.9324396306818182 \n",
      "Epoch 21 | Step 8237 | loss: 0.1825112651844146 | accuracy: 0.932468220338983 \n",
      "Epoch 21 | Step 8238 | loss: 0.18305245529483544 | accuracy: 0.9317942415730337 \n",
      "Epoch 21 | Step 8239 | loss: 0.18351966311229007 | accuracy: 0.9314769553072626 \n",
      "Epoch 21 | Step 8240 | loss: 0.1832120393920276 | accuracy: 0.9315104166666667 \n",
      "Epoch 21 | Step 8241 | loss: 0.18344367639218245 | accuracy: 0.9312845303867403 \n",
      "Epoch 21 | Step 8242 | loss: 0.18317929984858403 | accuracy: 0.9312328296703297 \n",
      "Epoch 21 | Step 8243 | loss: 0.18265083426090536 | accuracy: 0.9314378415300546 \n",
      "Epoch 21 | Step 8244 | loss: 0.18224709859603774 | accuracy: 0.9317255434782609 \n",
      "Epoch 21 | Step 8245 | loss: 0.18199701927400924 | accuracy: 0.9318412162162162 \n",
      "Epoch 21 | Step 8246 | loss: 0.18222178404610004 | accuracy: 0.931619623655914 \n",
      "Epoch 21 | Step 8247 | loss: 0.18264119030240386 | accuracy: 0.9314839572192514 \n",
      "Epoch 21 | Step 8248 | loss: 0.18282638543701552 | accuracy: 0.9312666223404256 \n",
      "Epoch 21 | Step 8249 | loss: 0.18249703882626755 | accuracy: 0.9313822751322751 \n",
      "Epoch 21 | Step 8250 | loss: 0.18333555281554398 | accuracy: 0.9311677631578947 \n",
      "Epoch 21 | Step 8251 | loss: 0.18276722707751533 | accuracy: 0.931446335078534 \n",
      "Epoch 21 | Step 8252 | loss: 0.18278943283560997 | accuracy: 0.9315592447916666 \n",
      "Epoch 21 | Step 8253 | loss: 0.18262786647893603 | accuracy: 0.9315900259067358 \n",
      "Epoch 21 | Step 8254 | loss: 0.1823435932897108 | accuracy: 0.9317815721649485 \n",
      "Epoch 21 | Step 8255 | loss: 0.18192866236353533 | accuracy: 0.9319711538461538 \n",
      "Epoch 21 | Step 8256 | loss: 0.1820631824547843 | accuracy: 0.9319196428571429 \n",
      "Epoch 21 | Step 8257 | loss: 0.18209045351988773 | accuracy: 0.9319479695431472 \n",
      "Epoch 21 | Step 8258 | loss: 0.1821076888591051 | accuracy: 0.93197601010101 \n",
      "Epoch 21 | Step 8259 | loss: 0.18195077842429055 | accuracy: 0.9322393216080402 \n",
      "Epoch 21 | Step 8260 | loss: 0.18185177078470588 | accuracy: 0.9321875 \n",
      "Epoch 21 | Step 8261 | loss: 0.18216625328606634 | accuracy: 0.9319807213930348 \n",
      "Epoch 21 | Step 8262 | loss: 0.18240562116376835 | accuracy: 0.9320080445544554 \n",
      "Epoch 21 | Step 8263 | loss: 0.18250657564827374 | accuracy: 0.931881157635468 \n",
      "Epoch 21 | Step 8264 | loss: 0.18231998382172748 | accuracy: 0.9320618872549019 \n",
      "Epoch 21 | Step 8265 | loss: 0.18264327607140307 | accuracy: 0.931935975609756 \n",
      "Epoch 21 | Step 8266 | loss: 0.18364676144154904 | accuracy: 0.9315078883495146 \n",
      "Epoch 21 | Step 8267 | loss: 0.184476424296553 | accuracy: 0.9314613526570048 \n",
      "Epoch 21 | Step 8268 | loss: 0.184520795278681 | accuracy: 0.9314903846153846 \n",
      "Epoch 21 | Step 8269 | loss: 0.18438962870166062 | accuracy: 0.9316686602870813 \n",
      "Epoch 21 | Step 8270 | loss: 0.18436091100530966 | accuracy: 0.9317708333333333 \n",
      "Epoch 21 | Step 8271 | loss: 0.18466346924550725 | accuracy: 0.9315758293838863 \n",
      "Epoch 21 | Step 8272 | loss: 0.18415418985949936 | accuracy: 0.9318985849056604 \n",
      "Epoch 21 | Step 8273 | loss: 0.18380385495617357 | accuracy: 0.9319982394366197 \n",
      "Epoch 21 | Step 8274 | loss: 0.18403123818755707 | accuracy: 0.9320239485981309 \n",
      "Epoch 21 | Step 8275 | loss: 0.18393261340814968 | accuracy: 0.9319767441860465 \n",
      "Epoch 21 | Step 8276 | loss: 0.1838673447534718 | accuracy: 0.9319299768518519 \n",
      "Epoch 21 | Step 8277 | loss: 0.18351796535508974 | accuracy: 0.9320276497695853 \n",
      "Epoch 21 | Step 8278 | loss: 0.18349120333585717 | accuracy: 0.9319810779816514 \n",
      "Epoch 21 | Step 8279 | loss: 0.18332990308262442 | accuracy: 0.9320776255707762 \n",
      "Epoch 21 | Step 8280 | loss: 0.18321785809980198 | accuracy: 0.9321022727272728 \n",
      "Epoch 21 | Step 8281 | loss: 0.183370115109024 | accuracy: 0.9320559954751131 \n",
      "Epoch 21 | Step 8282 | loss: 0.1833120249379594 | accuracy: 0.9320805180180181 \n",
      "Epoch 21 | Step 8283 | loss: 0.1835111924718581 | accuracy: 0.9320347533632287 \n",
      "Epoch 21 | Step 8284 | loss: 0.18295249840178127 | accuracy: 0.9323381696428571 \n",
      "Epoch 21 | Step 8285 | loss: 0.18336169817381434 | accuracy: 0.9320833333333334 \n",
      "Epoch 21 | Step 8286 | loss: 0.18356780758935265 | accuracy: 0.9319690265486725 \n",
      "Epoch 21 | Step 8287 | loss: 0.18368183160077634 | accuracy: 0.9317868942731278 \n",
      "Epoch 21 | Step 8288 | loss: 0.18373205308524662 | accuracy: 0.9318804824561403 \n",
      "Epoch 21 | Step 8289 | loss: 0.18366911934127453 | accuracy: 0.9319050218340611 \n",
      "Epoch 21 | Step 8290 | loss: 0.1835444378302149 | accuracy: 0.9319972826086956 \n",
      "Epoch 21 | Step 8291 | loss: 0.18343213463435956 | accuracy: 0.9320211038961039 \n",
      "Epoch 21 | Step 8292 | loss: 0.18307042239105392 | accuracy: 0.9322467672413793 \n",
      "Epoch 21 | Step 8293 | loss: 0.18311558198583483 | accuracy: 0.9320681330472103 \n",
      "Epoch 21 | Step 8294 | loss: 0.1832503908369531 | accuracy: 0.9320913461538461 \n",
      "Epoch 21 | Step 8295 | loss: 0.18317643957252197 | accuracy: 0.9321808510638298 \n",
      "Epoch 21 | Step 8296 | loss: 0.18284842395618306 | accuracy: 0.9323358050847458 \n",
      "Epoch 21 | Step 8297 | loss: 0.18273194201825038 | accuracy: 0.932423523206751 \n",
      "Epoch 21 | Step 8298 | loss: 0.18274576634857334 | accuracy: 0.9324448529411765 \n",
      "Epoch 21 | Step 8299 | loss: 0.1826608746339836 | accuracy: 0.9324660041841004 \n",
      "Epoch 21 | Step 8300 | loss: 0.18267317810095846 | accuracy: 0.932421875 \n",
      "Epoch 21 | Step 8301 | loss: 0.18221907779821717 | accuracy: 0.9325726141078838 \n",
      "Epoch 21 | Step 8302 | loss: 0.18196528114009003 | accuracy: 0.932657541322314 \n",
      "Epoch 21 | Step 8303 | loss: 0.18245567410509772 | accuracy: 0.9324845679012346 \n",
      "Epoch 21 | Step 8304 | loss: 0.18284752120676098 | accuracy: 0.9323770491803278 \n",
      "Epoch 21 | Step 8305 | loss: 0.18256026152141241 | accuracy: 0.9324617346938775 \n",
      "Epoch 21 | Step 8306 | loss: 0.18262806957269587 | accuracy: 0.9323551829268293 \n",
      "Epoch 21 | Step 8307 | loss: 0.18249776505446627 | accuracy: 0.9325025303643725 \n",
      "Epoch 21 | Step 8308 | loss: 0.18265796102763665 | accuracy: 0.9323966733870968 \n",
      "Epoch 21 | Step 8309 | loss: 0.18264839691988916 | accuracy: 0.9324171686746988 \n",
      "Epoch 21 | Step 8310 | loss: 0.1826432071775198 | accuracy: 0.9325 \n",
      "Epoch 21 | Step 8311 | loss: 0.18245942918843483 | accuracy: 0.9325821713147411 \n",
      "Epoch 21 | Step 8312 | loss: 0.18234440576403388 | accuracy: 0.9324776785714286 \n",
      "Epoch 21 | Step 8313 | loss: 0.1821950569071553 | accuracy: 0.9324357707509882 \n",
      "Epoch 21 | Step 8314 | loss: 0.1823592345398946 | accuracy: 0.9324557086614174 \n",
      "Epoch 21 | Step 8315 | loss: 0.18232875745378288 | accuracy: 0.9324754901960784 \n",
      "Epoch 21 | Step 8316 | loss: 0.182407487576711 | accuracy: 0.93243408203125 \n",
      "Epoch 21 | Step 8317 | loss: 0.18222553638110828 | accuracy: 0.932453793774319 \n",
      "Epoch 21 | Step 8318 | loss: 0.18195032402006692 | accuracy: 0.9325339147286822 \n",
      "Epoch 21 | Step 8319 | loss: 0.1821091723229204 | accuracy: 0.9324324324324325 \n",
      "Epoch 21 | Step 8320 | loss: 0.18199470076136864 | accuracy: 0.932451923076923 \n",
      "Epoch 21 | Step 8321 | loss: 0.18230262739847902 | accuracy: 0.9321719348659003 \n",
      "Epoch 21 | Step 8322 | loss: 0.18242974725786512 | accuracy: 0.9320133587786259 \n",
      "Epoch 21 | Step 8323 | loss: 0.1821775301129419 | accuracy: 0.9320936311787072 \n",
      "Epoch 21 | Step 8324 | loss: 0.18260805530360702 | accuracy: 0.9319957386363636 \n",
      "Epoch 21 | Step 8325 | loss: 0.18256759363806474 | accuracy: 0.9318396226415094 \n",
      "Epoch 21 | Step 8326 | loss: 0.18243367041468175 | accuracy: 0.9318021616541353 \n",
      "Epoch 21 | Step 8327 | loss: 0.18224900733498153 | accuracy: 0.931940543071161 \n",
      "Epoch 21 | Step 8328 | loss: 0.18201529969975577 | accuracy: 0.9320195895522388 \n",
      "Epoch 21 | Step 8329 | loss: 0.1819068326521319 | accuracy: 0.9320399628252788 \n",
      "Epoch 21 | Step 8330 | loss: 0.18183478228747849 | accuracy: 0.9320601851851852 \n",
      "Epoch 21 | Step 8331 | loss: 0.1818248002868957 | accuracy: 0.9319649446494465 \n",
      "Epoch 21 | Step 8332 | loss: 0.18171545634429687 | accuracy: 0.9319278492647058 \n",
      "Epoch 21 | Step 8333 | loss: 0.1818682558070391 | accuracy: 0.9318337912087912 \n",
      "Epoch 21 | Step 8334 | loss: 0.18179218390834162 | accuracy: 0.9317974452554745 \n",
      "Epoch 21 | Step 8335 | loss: 0.18169494619423698 | accuracy: 0.9318181818181818 \n",
      "Epoch 21 | Step 8336 | loss: 0.18195046377840687 | accuracy: 0.9316689311594203 \n",
      "Epoch 21 | Step 8337 | loss: 0.1819695069821088 | accuracy: 0.9316899819494585 \n",
      "Epoch 21 | Step 8338 | loss: 0.1819341533931254 | accuracy: 0.931710881294964 \n",
      "Epoch 21 | Step 8339 | loss: 0.18191790523334647 | accuracy: 0.9315636200716846 \n",
      "Epoch 21 | Step 8340 | loss: 0.18183767658525285 | accuracy: 0.9315848214285715 \n",
      "Epoch 21 | Step 8341 | loss: 0.18243030436151397 | accuracy: 0.931327846975089 \n",
      "Epoch 21 | Step 8342 | loss: 0.18227006089444284 | accuracy: 0.9313497340425532 \n",
      "Epoch 21 | Step 8343 | loss: 0.18222478633687272 | accuracy: 0.9313714664310954 \n",
      "Epoch 21 | Step 8344 | loss: 0.18211965537039748 | accuracy: 0.9314480633802817 \n",
      "Epoch 21 | Step 8345 | loss: 0.18196806987388095 | accuracy: 0.9316337719298246 \n",
      "Epoch 21 | Step 8346 | loss: 0.18200723583308553 | accuracy: 0.9315996503496503 \n",
      "Epoch 21 | Step 8347 | loss: 0.18189537137071848 | accuracy: 0.9315113240418118 \n",
      "Epoch 21 | Step 8348 | loss: 0.18169219573287088 | accuracy: 0.9315863715277778 \n",
      "Epoch 21 | Step 8349 | loss: 0.18144215557041052 | accuracy: 0.9316608996539792 \n",
      "Epoch 21 | Step 8350 | loss: 0.1818469459769027 | accuracy: 0.931573275862069 \n",
      "Epoch 21 | Step 8351 | loss: 0.1817645000044218 | accuracy: 0.9315399484536082 \n",
      "Epoch 21 | Step 8352 | loss: 0.1817642444336455 | accuracy: 0.9316138698630136 \n",
      "Epoch 21 | Step 8353 | loss: 0.18185317837998727 | accuracy: 0.9316339590443686 \n",
      "Epoch 21 | Step 8354 | loss: 0.18146855752839114 | accuracy: 0.931813350340136 \n",
      "Epoch 21 | Step 8355 | loss: 0.1814993648584616 | accuracy: 0.9317266949152543 \n",
      "Epoch 21 | Step 8356 | loss: 0.18140010685483746 | accuracy: 0.931640625 \n",
      "Epoch 21 | Step 8357 | loss: 0.18157469883862165 | accuracy: 0.9314499158249159 \n",
      "Epoch 21 | Step 8358 | loss: 0.1815007856403221 | accuracy: 0.9314177852348994 \n",
      "Epoch 21 | Step 8359 | loss: 0.18127563950857986 | accuracy: 0.9315426421404682 \n",
      "Epoch 21 | Step 8360 | loss: 0.1811379363760352 | accuracy: 0.9315625 \n",
      "Epoch 21 | Step 8361 | loss: 0.1810387540918054 | accuracy: 0.9316341362126246 \n",
      "Epoch 21 | Step 8362 | loss: 0.18081813721319304 | accuracy: 0.9317052980132451 \n",
      "Epoch 21 | Step 8363 | loss: 0.18067404038884458 | accuracy: 0.9316728547854786 \n",
      "Epoch 21 | Step 8364 | loss: 0.18065853197568732 | accuracy: 0.931640625 \n",
      "Epoch 21 | Step 8365 | loss: 0.1809532343974856 | accuracy: 0.9315061475409836 \n",
      "Epoch 21 | Step 8366 | loss: 0.18086571724829717 | accuracy: 0.9316278594771242 \n",
      "Epoch 21 | Step 8367 | loss: 0.1806640087077788 | accuracy: 0.9316978827361564 \n",
      "Epoch 21 | Step 8368 | loss: 0.18038529746669835 | accuracy: 0.9318181818181818 \n",
      "Epoch 21 | Step 8369 | loss: 0.18006844409895167 | accuracy: 0.9318871359223301 \n",
      "Epoch 21 | Step 8370 | loss: 0.1800954978913068 | accuracy: 0.9318044354838709 \n",
      "Epoch 21 | Step 8371 | loss: 0.18004555186897606 | accuracy: 0.9318227491961415 \n",
      "Epoch 21 | Step 8372 | loss: 0.18023924592834628 | accuracy: 0.9317407852564102 \n",
      "Epoch 21 | Step 8373 | loss: 0.18000101913421293 | accuracy: 0.9318091054313099 \n",
      "Epoch 21 | Step 8374 | loss: 0.17992969287950894 | accuracy: 0.9317774681528662 \n",
      "Epoch 21 | Step 8375 | loss: 0.17961686704130392 | accuracy: 0.9319444444444445 \n",
      "Epoch 21 | Step 8376 | loss: 0.17966158679816155 | accuracy: 0.9319620253164557 \n",
      "Epoch 21 | Step 8377 | loss: 0.1795307146003381 | accuracy: 0.9319302050473186 \n",
      "Epoch 21 | Step 8378 | loss: 0.17955706222861437 | accuracy: 0.9318985849056604 \n",
      "Epoch 21 | Step 8379 | loss: 0.17946273047582104 | accuracy: 0.9320141065830722 \n",
      "Epoch 21 | Step 8380 | loss: 0.1793048670631833 | accuracy: 0.93212890625 \n",
      "Epoch 21 | Step 8381 | loss: 0.17926591134563408 | accuracy: 0.9321456386292835 \n",
      "Epoch 21 | Step 8382 | loss: 0.17912009461372158 | accuracy: 0.9322107919254659 \n",
      "Epoch 21 | Step 8383 | loss: 0.17903099410904813 | accuracy: 0.9322755417956656 \n",
      "Epoch 21 | Step 8384 | loss: 0.1789753640898399 | accuracy: 0.9322916666666666 \n",
      "Epoch 21 | Step 8385 | loss: 0.17888674741754157 | accuracy: 0.9323557692307692 \n",
      "Epoch 21 | Step 8386 | loss: 0.1789486800988941 | accuracy: 0.9322756901840491 \n",
      "Epoch 21 | Step 8387 | loss: 0.17897022974646046 | accuracy: 0.9322438837920489 \n",
      "Epoch 21 | Step 8388 | loss: 0.1791491757101583 | accuracy: 0.9322122713414634 \n",
      "Epoch 21 | Step 8389 | loss: 0.1787447813094386 | accuracy: 0.9324183130699089 \n",
      "Epoch 21 | Step 8390 | loss: 0.17867629624000092 | accuracy: 0.9323863636363636 \n",
      "Epoch 21 | Step 8391 | loss: 0.17874988586025647 | accuracy: 0.9323546072507553 \n",
      "Epoch 21 | Step 8392 | loss: 0.17863432076725966 | accuracy: 0.9324642319277109 \n",
      "Epoch 21 | Step 8393 | loss: 0.1786893440281843 | accuracy: 0.9325731981981982 \n",
      "Epoch 21 | Step 8394 | loss: 0.1786212649107157 | accuracy: 0.9326347305389222 \n",
      "Epoch 21 | Step 8395 | loss: 0.17865559802348926 | accuracy: 0.9327425373134328 \n",
      "Epoch 21 | Step 8396 | loss: 0.17873148887329504 | accuracy: 0.9326636904761905 \n",
      "Epoch 21 | Step 8397 | loss: 0.17861408703802947 | accuracy: 0.9327707715133531 \n",
      "Epoch 21 | Step 8398 | loss: 0.1786389823606204 | accuracy: 0.9326923076923077 \n",
      "Epoch 21 | Step 8399 | loss: 0.17836681802847737 | accuracy: 0.9328447640117994 \n",
      "Epoch 21 | Step 8400 | loss: 0.17832590647260926 | accuracy: 0.9329503676470589 \n",
      "Epoch 21 | Step 8401 | loss: 0.17837677527863602 | accuracy: 0.9329178885630498 \n",
      "Epoch 21 | Step 8402 | loss: 0.17836291341884436 | accuracy: 0.9328855994152047 \n",
      "Epoch 21 | Step 8403 | loss: 0.1782516477298284 | accuracy: 0.9329446064139941 \n",
      "Epoch 21 | Step 8404 | loss: 0.17814698073536497 | accuracy: 0.9329578488372093 \n",
      "Epoch 21 | Step 8405 | loss: 0.17812735195393142 | accuracy: 0.9329257246376812 \n",
      "Epoch 21 | Step 8406 | loss: 0.17806273766637187 | accuracy: 0.9330292630057804 \n",
      "Epoch 21 | Step 8407 | loss: 0.17802994592002552 | accuracy: 0.9330871757925072 \n",
      "Epoch 21 | Step 8408 | loss: 0.1777326770276687 | accuracy: 0.9332345545977011 \n",
      "Epoch 21 | Step 8409 | loss: 0.17772395335628852 | accuracy: 0.933291547277937 \n",
      "Epoch 21 | Step 8410 | loss: 0.177888888195157 | accuracy: 0.9332142857142857 \n",
      "Epoch 21 | Step 8411 | loss: 0.17760421965069575 | accuracy: 0.9333600427350427 \n",
      "Epoch 21 | Step 8412 | loss: 0.17754521967038844 | accuracy: 0.9334161931818182 \n",
      "Epoch 21 | Step 8413 | loss: 0.17755805070989525 | accuracy: 0.9333392351274787 \n",
      "Epoch 21 | Step 8414 | loss: 0.17764477289707978 | accuracy: 0.9333068502824858 \n",
      "Epoch 21 | Step 8415 | loss: 0.17748038062537214 | accuracy: 0.933274647887324 \n",
      "Epoch 21 | Step 8416 | loss: 0.17729357013667227 | accuracy: 0.9333304073033708 \n",
      "Epoch 21 | Step 8417 | loss: 0.17752826742890496 | accuracy: 0.9332545518207283 \n",
      "Epoch 21 | Step 8418 | loss: 0.17795102675991678 | accuracy: 0.9331354748603352 \n",
      "Epoch 21 | Step 8419 | loss: 0.1778649990667373 | accuracy: 0.9331476323119777 \n",
      "Epoch 21 | Step 8420 | loss: 0.17790277636506482 | accuracy: 0.9331597222222222 \n",
      "Epoch 21 | Step 8421 | loss: 0.17768632873397447 | accuracy: 0.9333015927977839 \n",
      "Epoch 21 | Step 8422 | loss: 0.17770814491199188 | accuracy: 0.9332700276243094 \n",
      "Epoch 21 | Step 8423 | loss: 0.17761255216787333 | accuracy: 0.9333677685950413 \n",
      "Epoch 21 | Step 8424 | loss: 0.1773159371811773 | accuracy: 0.9335078983516484 \n",
      "Epoch 21 | Step 8425 | loss: 0.1771397546239911 | accuracy: 0.9336044520547945 \n",
      "Epoch 21 | Step 8426 | loss: 0.1772482728717919 | accuracy: 0.9335297131147541 \n",
      "Epoch 21 | Step 8427 | loss: 0.1771767479786268 | accuracy: 0.93358310626703 \n",
      "Epoch 21 | Step 8428 | loss: 0.17707873472903402 | accuracy: 0.9336362092391305 \n",
      "Epoch 21 | Step 8429 | loss: 0.1772113853616281 | accuracy: 0.9335619918699187 \n",
      "Epoch 21 | Step 8430 | loss: 0.17713418918082835 | accuracy: 0.9335726351351351 \n",
      "Epoch 21 | Step 8431 | loss: 0.17715420653275396 | accuracy: 0.9335832210242587 \n",
      "Epoch 21 | Step 8432 | loss: 0.17699738829246445 | accuracy: 0.933635752688172 \n",
      "Epoch 21 | Step 8433 | loss: 0.17676205296898329 | accuracy: 0.9337298927613941 \n",
      "Epoch 21 | Step 8434 | loss: 0.17657190651936638 | accuracy: 0.9337817513368984 \n",
      "Epoch 21 | Step 8435 | loss: 0.176652443041404 | accuracy: 0.9337083333333334 \n",
      "Epoch 21 | Step 8436 | loss: 0.17647105018469558 | accuracy: 0.9337599734042553 \n",
      "Epoch 21 | Step 8437 | loss: 0.1764531221626133 | accuracy: 0.9337698938992043 \n",
      "Epoch 21 | Step 8438 | loss: 0.17638056507462224 | accuracy: 0.9337384259259259 \n",
      "Epoch 21 | Step 8439 | loss: 0.17616429908255152 | accuracy: 0.9338720316622692 \n",
      "Epoch 21 | Step 8440 | loss: 0.17607654371347858 | accuracy: 0.9338815789473685 \n",
      "Epoch 21 | Step 8441 | loss: 0.17586959864249999 | accuracy: 0.9339730971128609 \n",
      "Epoch 21 | Step 8442 | loss: 0.17594254665388792 | accuracy: 0.9340232329842932 \n",
      "Epoch 21 | Step 8443 | loss: 0.17604237889224175 | accuracy: 0.9339915143603134 \n",
      "Epoch 21 | Step 8444 | loss: 0.17632162688338812 | accuracy: 0.9340006510416666 \n",
      "Epoch 21 | Step 8445 | loss: 0.17620151070998855 | accuracy: 0.9340097402597403 \n",
      "Epoch 21 | Step 8446 | loss: 0.17602674052157852 | accuracy: 0.9340997409326425 \n",
      "Epoch 21 | Step 8447 | loss: 0.17588306506205276 | accuracy: 0.9341489018087855 \n",
      "Epoch 21 | Step 8448 | loss: 0.1761100729351344 | accuracy: 0.9341172680412371 \n",
      "Epoch 21 | Step 8449 | loss: 0.17595112294073575 | accuracy: 0.9341661311053985 \n",
      "Epoch 21 | Step 8450 | loss: 0.17585984633710133 | accuracy: 0.9342147435897435 \n",
      "Epoch 21 | Step 8451 | loss: 0.17585566858082163 | accuracy: 0.9341831841432225 \n",
      "Epoch 21 | Step 8452 | loss: 0.175772174252007 | accuracy: 0.9342315051020408 \n",
      "Epoch 21 | Step 8453 | loss: 0.17573497166653315 | accuracy: 0.9343193384223919 \n",
      "Epoch 21 | Step 8454 | loss: 0.17576030086782674 | accuracy: 0.9342877538071066 \n",
      "Epoch 21 | Step 8455 | loss: 0.17548538130484043 | accuracy: 0.9344541139240506 \n",
      "Epoch 21 | Step 8456 | loss: 0.17523991355126847 | accuracy: 0.9345801767676768 \n",
      "Epoch 21 | Step 8457 | loss: 0.17536699457530402 | accuracy: 0.9346268891687658 \n",
      "Epoch 21 | Step 8458 | loss: 0.17546806564021045 | accuracy: 0.9345555904522613 \n",
      "Epoch 21 | Step 8459 | loss: 0.17525405648694295 | accuracy: 0.934641290726817 \n",
      "Epoch 21 | Step 8460 | loss: 0.17514974699355654 | accuracy: 0.9346875 \n",
      "Epoch 21 | Step 8461 | loss: 0.17530910824042298 | accuracy: 0.9346945137157108 \n",
      "Epoch 21 | Step 8462 | loss: 0.1756835084742129 | accuracy: 0.9345071517412935 \n",
      "Epoch 21 | Step 8463 | loss: 0.175479868329858 | accuracy: 0.9345840998086385 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.5014612674713135 | accuracy: 0.8125 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.4137459248304367 | accuracy: 0.8359375 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.4798972507317861 | accuracy: 0.8333333333333334 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.4728957340121269 | accuracy: 0.828125 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.4456027805805206 | accuracy: 0.8375 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.49266084531943005 | accuracy: 0.8177083333333334 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.4893429492201124 | accuracy: 0.8169642857142857 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.48522548004984856 | accuracy: 0.814453125 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.5259859396351708 | accuracy: 0.8072916666666666 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.5061990022659302 | accuracy: 0.8171875 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.5076017488132823 | accuracy: 0.8196022727272727 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.49536468585332233 | accuracy: 0.8268229166666666 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.5081942906746497 | accuracy: 0.8221153846153846 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.4892475413424628 | accuracy: 0.8270089285714286 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.4965141435464223 | accuracy: 0.8270833333333333 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.4922721441835165 | accuracy: 0.8271484375 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.4935594849726733 | accuracy: 0.8262867647058824 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.4892236491044362 | accuracy: 0.8263888888888888 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.4820022065388529 | accuracy: 0.8273026315789473 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.473810638487339 | accuracy: 0.828125 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.46680184914952233 | accuracy: 0.8303571428571429 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.46181942928921094 | accuracy: 0.8309659090909091 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.4741118109744528 | accuracy: 0.829483695652174 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.5005667358636856 | accuracy: 0.826171875 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.5109304332733154 | accuracy: 0.821875 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.5065427605922406 | accuracy: 0.8239182692307693 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.4989164857952683 | accuracy: 0.8263888888888888 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.5015419987695557 | accuracy: 0.8247767857142857 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.5023251576670285 | accuracy: 0.8254310344827587 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.497249033053716 | accuracy: 0.8276041666666667 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.49153296216841663 | accuracy: 0.8311491935483871 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.49417427182197565 | accuracy: 0.8291015625 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.49448905207894067 | accuracy: 0.8262310606060606 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.4982414175482357 | accuracy: 0.8235294117647058 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.5001556958471026 | accuracy: 0.8236607142857143 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.4982743635773659 | accuracy: 0.8255208333333334 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.49927735409221136 | accuracy: 0.8255912162162162 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.5022657897911573 | accuracy: 0.8264802631578947 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.5041313912623968 | accuracy: 0.8245192307692307 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.4988004855811596 | accuracy: 0.826171875 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.4939964101081941 | accuracy: 0.8273628048780488 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.4886822388285682 | accuracy: 0.828125 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.4896376548811447 | accuracy: 0.8277616279069767 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.4901711737567728 | accuracy: 0.8277698863636364 \n",
      "Validation | Epoch 21 | Step 8463 | loss: 0.48825286428133646 | accuracy: 0.826766304175059 \n",
      "Epoch 22 | Step 8464 | loss: 0.2702791690826416 | accuracy: 0.90625 \n",
      "Epoch 22 | Step 8465 | loss: 0.17312971502542496 | accuracy: 0.9296875 \n",
      "Epoch 22 | Step 8466 | loss: 0.1637332538763682 | accuracy: 0.9375 \n",
      "Epoch 22 | Step 8467 | loss: 0.17410241067409515 | accuracy: 0.93359375 \n",
      "Epoch 22 | Step 8468 | loss: 0.15335184782743455 | accuracy: 0.946875 \n",
      "Epoch 22 | Step 8469 | loss: 0.14932619159420332 | accuracy: 0.9479166666666666 \n",
      "Epoch 22 | Step 8470 | loss: 0.15530014570270265 | accuracy: 0.9441964285714286 \n",
      "Epoch 22 | Step 8471 | loss: 0.1568500166758895 | accuracy: 0.9453125 \n",
      "Epoch 22 | Step 8472 | loss: 0.1641970897714297 | accuracy: 0.9427083333333334 \n",
      "Epoch 22 | Step 8473 | loss: 0.17489910647273063 | accuracy: 0.9390625 \n",
      "Epoch 22 | Step 8474 | loss: 0.16968068006363782 | accuracy: 0.9403409090909091 \n",
      "Epoch 22 | Step 8475 | loss: 0.16384873849650225 | accuracy: 0.9401041666666666 \n",
      "Epoch 22 | Step 8476 | loss: 0.1752980357179275 | accuracy: 0.9350961538461539 \n",
      "Epoch 22 | Step 8477 | loss: 0.1764197482594422 | accuracy: 0.9352678571428571 \n",
      "Epoch 22 | Step 8478 | loss: 0.17618653227885564 | accuracy: 0.934375 \n",
      "Epoch 22 | Step 8479 | loss: 0.16981489025056362 | accuracy: 0.9375 \n",
      "Epoch 22 | Step 8480 | loss: 0.17076790858717525 | accuracy: 0.9375 \n",
      "Epoch 22 | Step 8481 | loss: 0.16697239586048657 | accuracy: 0.9383680555555556 \n",
      "Epoch 22 | Step 8482 | loss: 0.16781809886819438 | accuracy: 0.9383223684210527 \n",
      "Epoch 22 | Step 8483 | loss: 0.17038417123258115 | accuracy: 0.9390625 \n",
      "Epoch 22 | Step 8484 | loss: 0.1690560824104718 | accuracy: 0.9404761904761905 \n",
      "Epoch 22 | Step 8485 | loss: 0.17071586881171574 | accuracy: 0.9389204545454546 \n",
      "Epoch 22 | Step 8486 | loss: 0.16855115119529807 | accuracy: 0.9402173913043478 \n",
      "Epoch 22 | Step 8487 | loss: 0.1672689135496815 | accuracy: 0.9401041666666666 \n",
      "Epoch 22 | Step 8488 | loss: 0.16890939086675644 | accuracy: 0.938125 \n",
      "Epoch 22 | Step 8489 | loss: 0.16758938448933455 | accuracy: 0.9387019230769231 \n",
      "Epoch 22 | Step 8490 | loss: 0.1752382712783637 | accuracy: 0.9363425925925926 \n",
      "Epoch 22 | Step 8491 | loss: 0.17239441217056342 | accuracy: 0.9375 \n",
      "Epoch 22 | Step 8492 | loss: 0.17565434580219202 | accuracy: 0.9369612068965517 \n",
      "Epoch 22 | Step 8493 | loss: 0.17532352482279143 | accuracy: 0.9369791666666667 \n",
      "Epoch 22 | Step 8494 | loss: 0.1741151336220003 | accuracy: 0.9375 \n",
      "Epoch 22 | Step 8495 | loss: 0.17435492970980704 | accuracy: 0.9365234375 \n",
      "Epoch 22 | Step 8496 | loss: 0.17415496729540103 | accuracy: 0.9370265151515151 \n",
      "Epoch 22 | Step 8497 | loss: 0.17115742055808797 | accuracy: 0.9379595588235294 \n",
      "Epoch 22 | Step 8498 | loss: 0.16816917892013278 | accuracy: 0.9397321428571429 \n",
      "Epoch 22 | Step 8499 | loss: 0.16647818332744968 | accuracy: 0.9401041666666666 \n",
      "Epoch 22 | Step 8500 | loss: 0.1664785833374874 | accuracy: 0.9396114864864865 \n",
      "Epoch 22 | Step 8501 | loss: 0.165192913656172 | accuracy: 0.9403782894736842 \n",
      "Epoch 22 | Step 8502 | loss: 0.16303766385102883 | accuracy: 0.9411057692307693 \n",
      "Epoch 22 | Step 8503 | loss: 0.16161339543759823 | accuracy: 0.9421875 \n",
      "Epoch 22 | Step 8504 | loss: 0.15986530791695525 | accuracy: 0.9428353658536586 \n",
      "Epoch 22 | Step 8505 | loss: 0.1595930050881136 | accuracy: 0.9423363095238095 \n",
      "Epoch 22 | Step 8506 | loss: 0.15918582972399023 | accuracy: 0.9422238372093024 \n",
      "Epoch 22 | Step 8507 | loss: 0.1582483381710269 | accuracy: 0.9424715909090909 \n",
      "Epoch 22 | Step 8508 | loss: 0.16011788249015807 | accuracy: 0.9420138888888889 \n",
      "Epoch 22 | Step 8509 | loss: 0.16107132285833356 | accuracy: 0.9415760869565217 \n",
      "Epoch 22 | Step 8510 | loss: 0.16048768860228516 | accuracy: 0.9418218085106383 \n",
      "Epoch 22 | Step 8511 | loss: 0.1601915427794059 | accuracy: 0.9423828125 \n",
      "Epoch 22 | Step 8512 | loss: 0.1625457953433601 | accuracy: 0.9416454081632653 \n",
      "Epoch 22 | Step 8513 | loss: 0.16368475943803787 | accuracy: 0.9403125 \n",
      "Epoch 22 | Step 8514 | loss: 0.16413000401328592 | accuracy: 0.9402573529411765 \n",
      "Epoch 22 | Step 8515 | loss: 0.1625808569101187 | accuracy: 0.9405048076923077 \n",
      "Epoch 22 | Step 8516 | loss: 0.16399896538482522 | accuracy: 0.9398584905660378 \n",
      "Epoch 22 | Step 8517 | loss: 0.16300536195437113 | accuracy: 0.9406828703703703 \n",
      "Epoch 22 | Step 8518 | loss: 0.16522832837971774 | accuracy: 0.9392045454545455 \n",
      "Epoch 22 | Step 8519 | loss: 0.1641700700191515 | accuracy: 0.9400111607142857 \n",
      "Epoch 22 | Step 8520 | loss: 0.16485467147931718 | accuracy: 0.9396929824561403 \n",
      "Epoch 22 | Step 8521 | loss: 0.165619274023278 | accuracy: 0.9391163793103449 \n",
      "Epoch 22 | Step 8522 | loss: 0.16667320453009363 | accuracy: 0.939353813559322 \n",
      "Epoch 22 | Step 8523 | loss: 0.16798508130013942 | accuracy: 0.9393229166666667 \n",
      "Epoch 22 | Step 8524 | loss: 0.16768218002846982 | accuracy: 0.9392930327868853 \n",
      "Epoch 22 | Step 8525 | loss: 0.16739249601960182 | accuracy: 0.9395161290322581 \n",
      "Epoch 22 | Step 8526 | loss: 0.16942533602317175 | accuracy: 0.9384920634920635 \n",
      "Epoch 22 | Step 8527 | loss: 0.1679623668314889 | accuracy: 0.93896484375 \n",
      "Epoch 22 | Step 8528 | loss: 0.16653144795161026 | accuracy: 0.9396634615384616 \n",
      "Epoch 22 | Step 8529 | loss: 0.1651702725300283 | accuracy: 0.9403409090909091 \n",
      "Epoch 22 | Step 8530 | loss: 0.16445159411697247 | accuracy: 0.9400652985074627 \n",
      "Epoch 22 | Step 8531 | loss: 0.16466410797746742 | accuracy: 0.9397977941176471 \n",
      "Epoch 22 | Step 8532 | loss: 0.164388216600038 | accuracy: 0.9397644927536232 \n",
      "Epoch 22 | Step 8533 | loss: 0.16349858258451735 | accuracy: 0.9401785714285714 \n",
      "Epoch 22 | Step 8534 | loss: 0.1621902845275234 | accuracy: 0.940580985915493 \n",
      "Epoch 22 | Step 8535 | loss: 0.16212963933746016 | accuracy: 0.9403211805555556 \n",
      "Epoch 22 | Step 8536 | loss: 0.16216415452630548 | accuracy: 0.9402825342465754 \n",
      "Epoch 22 | Step 8537 | loss: 0.1626310177348755 | accuracy: 0.9400337837837838 \n",
      "Epoch 22 | Step 8538 | loss: 0.16233223776022587 | accuracy: 0.94 \n",
      "Epoch 22 | Step 8539 | loss: 0.16217792543925733 | accuracy: 0.9403782894736842 \n",
      "Epoch 22 | Step 8540 | loss: 0.16177522303996145 | accuracy: 0.9403409090909091 \n",
      "Epoch 22 | Step 8541 | loss: 0.16237725183749807 | accuracy: 0.9401041666666666 \n",
      "Epoch 22 | Step 8542 | loss: 0.16532293999496891 | accuracy: 0.9394778481012658 \n",
      "Epoch 22 | Step 8543 | loss: 0.16442697439342735 | accuracy: 0.93984375 \n",
      "Epoch 22 | Step 8544 | loss: 0.1636674012298937 | accuracy: 0.9403935185185185 \n",
      "Epoch 22 | Step 8545 | loss: 0.16300307886629567 | accuracy: 0.9409298780487805 \n",
      "Epoch 22 | Step 8546 | loss: 0.16296221944222966 | accuracy: 0.9410768072289156 \n",
      "Epoch 22 | Step 8547 | loss: 0.16284962654823346 | accuracy: 0.9412202380952381 \n",
      "Epoch 22 | Step 8548 | loss: 0.16271142977125502 | accuracy: 0.9409926470588236 \n",
      "Epoch 22 | Step 8549 | loss: 0.1620745595631211 | accuracy: 0.9411337209302325 \n",
      "Epoch 22 | Step 8550 | loss: 0.164514637455858 | accuracy: 0.9400143678160919 \n",
      "Epoch 22 | Step 8551 | loss: 0.16493925985626198 | accuracy: 0.9401633522727273 \n",
      "Epoch 22 | Step 8552 | loss: 0.16388826934474238 | accuracy: 0.9406601123595506 \n",
      "Epoch 22 | Step 8553 | loss: 0.16394522628850408 | accuracy: 0.9404513888888889 \n",
      "Epoch 22 | Step 8554 | loss: 0.16294033980959066 | accuracy: 0.9405906593406593 \n",
      "Epoch 22 | Step 8555 | loss: 0.16230050830737405 | accuracy: 0.9407269021739131 \n",
      "Epoch 22 | Step 8556 | loss: 0.16185433730002374 | accuracy: 0.9410282258064516 \n",
      "Epoch 22 | Step 8557 | loss: 0.1611325797882486 | accuracy: 0.9413231382978723 \n",
      "Epoch 22 | Step 8558 | loss: 0.1615256107167194 | accuracy: 0.9411184210526315 \n",
      "Epoch 22 | Step 8559 | loss: 0.16255716343099874 | accuracy: 0.9407552083333334 \n",
      "Epoch 22 | Step 8560 | loss: 0.16225390627826614 | accuracy: 0.9410438144329897 \n",
      "Epoch 22 | Step 8561 | loss: 0.163350266309417 | accuracy: 0.9405293367346939 \n",
      "Epoch 22 | Step 8562 | loss: 0.16355130738682216 | accuracy: 0.9406565656565656 \n",
      "Epoch 22 | Step 8563 | loss: 0.16299131967127323 | accuracy: 0.94078125 \n",
      "Epoch 22 | Step 8564 | loss: 0.16214812746142396 | accuracy: 0.9409034653465347 \n",
      "Epoch 22 | Step 8565 | loss: 0.16171251215478954 | accuracy: 0.9411764705882353 \n",
      "Epoch 22 | Step 8566 | loss: 0.16090176464284509 | accuracy: 0.9415958737864077 \n",
      "Epoch 22 | Step 8567 | loss: 0.1611592872784688 | accuracy: 0.94140625 \n",
      "Epoch 22 | Step 8568 | loss: 0.16254021184785025 | accuracy: 0.9412202380952381 \n",
      "Epoch 22 | Step 8569 | loss: 0.16201358738372912 | accuracy: 0.9413325471698113 \n",
      "Epoch 22 | Step 8570 | loss: 0.16235491048509829 | accuracy: 0.9411507009345794 \n",
      "Epoch 22 | Step 8571 | loss: 0.16341228258830529 | accuracy: 0.9406828703703703 \n",
      "Epoch 22 | Step 8572 | loss: 0.1636270299690579 | accuracy: 0.9406536697247706 \n",
      "Epoch 22 | Step 8573 | loss: 0.16397539485584606 | accuracy: 0.9404829545454545 \n",
      "Epoch 22 | Step 8574 | loss: 0.16358276872753022 | accuracy: 0.9405968468468469 \n",
      "Epoch 22 | Step 8575 | loss: 0.1636201017536223 | accuracy: 0.9407087053571429 \n",
      "Epoch 22 | Step 8576 | loss: 0.1648208134337864 | accuracy: 0.9402654867256637 \n",
      "Epoch 22 | Step 8577 | loss: 0.1648092897968334 | accuracy: 0.9403782894736842 \n",
      "Epoch 22 | Step 8578 | loss: 0.1644792259387348 | accuracy: 0.9404891304347827 \n",
      "Epoch 22 | Step 8579 | loss: 0.16429311518782172 | accuracy: 0.9403286637931034 \n",
      "Epoch 22 | Step 8580 | loss: 0.1648082338974007 | accuracy: 0.9399038461538461 \n",
      "Epoch 22 | Step 8581 | loss: 0.16468147055829985 | accuracy: 0.9398834745762712 \n",
      "Epoch 22 | Step 8582 | loss: 0.16502980844062917 | accuracy: 0.9399947478991597 \n",
      "Epoch 22 | Step 8583 | loss: 0.16445912718772887 | accuracy: 0.940234375 \n",
      "Epoch 22 | Step 8584 | loss: 0.16462862011322305 | accuracy: 0.9402117768595041 \n",
      "Epoch 22 | Step 8585 | loss: 0.164501782812056 | accuracy: 0.9401895491803278 \n",
      "Epoch 22 | Step 8586 | loss: 0.16425898925560276 | accuracy: 0.9402947154471545 \n",
      "Epoch 22 | Step 8587 | loss: 0.16436065913688752 | accuracy: 0.9402721774193549 \n",
      "Epoch 22 | Step 8588 | loss: 0.16410459971427918 | accuracy: 0.940375 \n",
      "Epoch 22 | Step 8589 | loss: 0.16376305170475491 | accuracy: 0.9404761904761905 \n",
      "Epoch 22 | Step 8590 | loss: 0.16484188071386083 | accuracy: 0.9400836614173228 \n",
      "Epoch 22 | Step 8591 | loss: 0.16467912693042308 | accuracy: 0.93994140625 \n",
      "Epoch 22 | Step 8592 | loss: 0.16410737675289774 | accuracy: 0.9401647286821705 \n",
      "Epoch 22 | Step 8593 | loss: 0.16379442323858923 | accuracy: 0.940264423076923 \n",
      "Epoch 22 | Step 8594 | loss: 0.1639104961552693 | accuracy: 0.9400047709923665 \n",
      "Epoch 22 | Step 8595 | loss: 0.1650642498085896 | accuracy: 0.939749053030303 \n",
      "Epoch 22 | Step 8596 | loss: 0.16535223163384244 | accuracy: 0.9396146616541353 \n",
      "Epoch 22 | Step 8597 | loss: 0.16557641099415607 | accuracy: 0.9395988805970149 \n",
      "Epoch 22 | Step 8598 | loss: 0.1655536146627532 | accuracy: 0.9394675925925926 \n",
      "Epoch 22 | Step 8599 | loss: 0.16527202106354869 | accuracy: 0.939453125 \n",
      "Epoch 22 | Step 8600 | loss: 0.1650003047428862 | accuracy: 0.9396669708029197 \n",
      "Epoch 22 | Step 8601 | loss: 0.16513013272829677 | accuracy: 0.9397644927536232 \n",
      "Epoch 22 | Step 8602 | loss: 0.16556056974817523 | accuracy: 0.9399730215827338 \n",
      "Epoch 22 | Step 8603 | loss: 0.16553511252360684 | accuracy: 0.9400669642857142 \n",
      "Epoch 22 | Step 8604 | loss: 0.16670940314412963 | accuracy: 0.9398271276595744 \n",
      "Epoch 22 | Step 8605 | loss: 0.16681411133055957 | accuracy: 0.9400308098591549 \n",
      "Epoch 22 | Step 8606 | loss: 0.16726040782836768 | accuracy: 0.9397945804195804 \n",
      "Epoch 22 | Step 8607 | loss: 0.16708036651834846 | accuracy: 0.9397786458333334 \n",
      "Epoch 22 | Step 8608 | loss: 0.16696718196416724 | accuracy: 0.9398706896551724 \n",
      "Epoch 22 | Step 8609 | loss: 0.16735027633505326 | accuracy: 0.939533390410959 \n",
      "Epoch 22 | Step 8610 | loss: 0.1665902269281903 | accuracy: 0.9399447278911565 \n",
      "Epoch 22 | Step 8611 | loss: 0.16668033597336426 | accuracy: 0.9397170608108109 \n",
      "Epoch 22 | Step 8612 | loss: 0.16641461206662572 | accuracy: 0.9398070469798657 \n",
      "Epoch 22 | Step 8613 | loss: 0.1670502410084009 | accuracy: 0.9397916666666667 \n",
      "Epoch 22 | Step 8614 | loss: 0.16740600860967542 | accuracy: 0.9395695364238411 \n",
      "Epoch 22 | Step 8615 | loss: 0.1686271667039316 | accuracy: 0.9392475328947368 \n",
      "Epoch 22 | Step 8616 | loss: 0.16897784248968356 | accuracy: 0.9391339869281046 \n",
      "Epoch 22 | Step 8617 | loss: 0.1686213475881846 | accuracy: 0.9393262987012987 \n",
      "Epoch 22 | Step 8618 | loss: 0.1684152200097038 | accuracy: 0.9394153225806452 \n",
      "Epoch 22 | Step 8619 | loss: 0.16789401563791892 | accuracy: 0.9396033653846154 \n",
      "Epoch 22 | Step 8620 | loss: 0.1677093912319393 | accuracy: 0.9396894904458599 \n",
      "Epoch 22 | Step 8621 | loss: 0.16738761124448687 | accuracy: 0.9397745253164557 \n",
      "Epoch 22 | Step 8622 | loss: 0.1674883982529805 | accuracy: 0.9395636792452831 \n",
      "Epoch 22 | Step 8623 | loss: 0.16779129758942873 | accuracy: 0.939453125 \n",
      "Epoch 22 | Step 8624 | loss: 0.16819698000268907 | accuracy: 0.9390527950310559 \n",
      "Epoch 22 | Step 8625 | loss: 0.16788423850120585 | accuracy: 0.9391396604938271 \n",
      "Epoch 22 | Step 8626 | loss: 0.16890937215620022 | accuracy: 0.9385544478527608 \n",
      "Epoch 22 | Step 8627 | loss: 0.16882199582802812 | accuracy: 0.938548018292683 \n",
      "Epoch 22 | Step 8628 | loss: 0.16902807361700317 | accuracy: 0.9384469696969697 \n",
      "Epoch 22 | Step 8629 | loss: 0.1693351978593203 | accuracy: 0.9383471385542169 \n",
      "Epoch 22 | Step 8630 | loss: 0.16897779317226952 | accuracy: 0.9385291916167665 \n",
      "Epoch 22 | Step 8631 | loss: 0.1697167332638942 | accuracy: 0.9382440476190477 \n",
      "Epoch 22 | Step 8632 | loss: 0.1695313901370446 | accuracy: 0.9382396449704142 \n",
      "Epoch 22 | Step 8633 | loss: 0.16890339945607322 | accuracy: 0.9385110294117647 \n",
      "Epoch 22 | Step 8634 | loss: 0.16895681661036274 | accuracy: 0.9385051169590644 \n",
      "Epoch 22 | Step 8635 | loss: 0.16907303197699225 | accuracy: 0.938499273255814 \n",
      "Epoch 22 | Step 8636 | loss: 0.1688335393851547 | accuracy: 0.9384934971098265 \n",
      "Epoch 22 | Step 8637 | loss: 0.16900859317132105 | accuracy: 0.9383979885057471 \n",
      "Epoch 22 | Step 8638 | loss: 0.16895346971494804 | accuracy: 0.9383928571428571 \n",
      "Epoch 22 | Step 8639 | loss: 0.1699541470840234 | accuracy: 0.9381214488636364 \n",
      "Epoch 22 | Step 8640 | loss: 0.1706318482125209 | accuracy: 0.9380296610169492 \n",
      "Epoch 22 | Step 8641 | loss: 0.17103951455753166 | accuracy: 0.9376755617977528 \n",
      "Epoch 22 | Step 8642 | loss: 0.17162898555397985 | accuracy: 0.9373254189944135 \n",
      "Epoch 22 | Step 8643 | loss: 0.17140844205601347 | accuracy: 0.9373263888888889 \n",
      "Epoch 22 | Step 8644 | loss: 0.17172632294382836 | accuracy: 0.9369820441988951 \n",
      "Epoch 22 | Step 8645 | loss: 0.1715105988781203 | accuracy: 0.9368990384615384 \n",
      "Epoch 22 | Step 8646 | loss: 0.17110504513311253 | accuracy: 0.9369877049180327 \n",
      "Epoch 22 | Step 8647 | loss: 0.17076763407448708 | accuracy: 0.9371603260869565 \n",
      "Epoch 22 | Step 8648 | loss: 0.17051305595684693 | accuracy: 0.9371621621621622 \n",
      "Epoch 22 | Step 8649 | loss: 0.1707980866113337 | accuracy: 0.9369119623655914 \n",
      "Epoch 22 | Step 8650 | loss: 0.17129801151985152 | accuracy: 0.9364137700534759 \n",
      "Epoch 22 | Step 8651 | loss: 0.17132811004573362 | accuracy: 0.9362533244680851 \n",
      "Epoch 22 | Step 8652 | loss: 0.17101522769640992 | accuracy: 0.9364252645502645 \n",
      "Epoch 22 | Step 8653 | loss: 0.1718021829857638 | accuracy: 0.9363486842105263 \n",
      "Epoch 22 | Step 8654 | loss: 0.17134115835212912 | accuracy: 0.9366001308900523 \n",
      "Epoch 22 | Step 8655 | loss: 0.1711994933624131 | accuracy: 0.9366048177083334 \n",
      "Epoch 22 | Step 8656 | loss: 0.17089155827856434 | accuracy: 0.9368523316062176 \n",
      "Epoch 22 | Step 8657 | loss: 0.17068464602775796 | accuracy: 0.9369362113402062 \n",
      "Epoch 22 | Step 8658 | loss: 0.17030510686528988 | accuracy: 0.9370192307692308 \n",
      "Epoch 22 | Step 8659 | loss: 0.1705183725690051 | accuracy: 0.9370216836734694 \n",
      "Epoch 22 | Step 8660 | loss: 0.17043848379236187 | accuracy: 0.9370241116751269 \n",
      "Epoch 22 | Step 8661 | loss: 0.1707257665129322 | accuracy: 0.9368686868686869 \n",
      "Epoch 22 | Step 8662 | loss: 0.1705933168867425 | accuracy: 0.9370288944723618 \n",
      "Epoch 22 | Step 8663 | loss: 0.17060391834005714 | accuracy: 0.936953125 \n",
      "Epoch 22 | Step 8664 | loss: 0.1709966307960043 | accuracy: 0.9368781094527363 \n",
      "Epoch 22 | Step 8665 | loss: 0.17104387805234678 | accuracy: 0.9367264851485149 \n",
      "Epoch 22 | Step 8666 | loss: 0.17113087350144762 | accuracy: 0.9368072660098522 \n",
      "Epoch 22 | Step 8667 | loss: 0.17106158781212336 | accuracy: 0.9368106617647058 \n",
      "Epoch 22 | Step 8668 | loss: 0.17137008859980396 | accuracy: 0.9366615853658536 \n",
      "Epoch 22 | Step 8669 | loss: 0.17231127343059166 | accuracy: 0.9362864077669902 \n",
      "Epoch 22 | Step 8670 | loss: 0.17331727502354677 | accuracy: 0.9362167874396136 \n",
      "Epoch 22 | Step 8671 | loss: 0.17345534621451336 | accuracy: 0.9360727163461539 \n",
      "Epoch 22 | Step 8672 | loss: 0.17340792449966572 | accuracy: 0.9360795454545454 \n",
      "Epoch 22 | Step 8673 | loss: 0.17332661746158487 | accuracy: 0.936235119047619 \n",
      "Epoch 22 | Step 8674 | loss: 0.1734245580342991 | accuracy: 0.9360189573459715 \n",
      "Epoch 22 | Step 8675 | loss: 0.17289934860858716 | accuracy: 0.9363207547169812 \n",
      "Epoch 22 | Step 8676 | loss: 0.17259091486883277 | accuracy: 0.936399647887324 \n",
      "Epoch 22 | Step 8677 | loss: 0.1727509357069976 | accuracy: 0.9363317757009346 \n",
      "Epoch 22 | Step 8678 | loss: 0.17256816561485447 | accuracy: 0.9363372093023256 \n",
      "Epoch 22 | Step 8679 | loss: 0.17247834620583388 | accuracy: 0.9364149305555556 \n",
      "Epoch 22 | Step 8680 | loss: 0.17223703447506175 | accuracy: 0.936491935483871 \n",
      "Epoch 22 | Step 8681 | loss: 0.1722183363392539 | accuracy: 0.9363532110091743 \n",
      "Epoch 22 | Step 8682 | loss: 0.17224128787580145 | accuracy: 0.9363584474885844 \n",
      "Epoch 22 | Step 8683 | loss: 0.1720858821645379 | accuracy: 0.9363636363636364 \n",
      "Epoch 22 | Step 8684 | loss: 0.17218338807716088 | accuracy: 0.936368778280543 \n",
      "Epoch 22 | Step 8685 | loss: 0.17231136659445526 | accuracy: 0.936303490990991 \n",
      "Epoch 22 | Step 8686 | loss: 0.17251055836343446 | accuracy: 0.9360285874439462 \n",
      "Epoch 22 | Step 8687 | loss: 0.17203326305441027 | accuracy: 0.9363141741071429 \n",
      "Epoch 22 | Step 8688 | loss: 0.1724637446966436 | accuracy: 0.9361111111111111 \n",
      "Epoch 22 | Step 8689 | loss: 0.17259533230248278 | accuracy: 0.9361172566371682 \n",
      "Epoch 22 | Step 8690 | loss: 0.17280567869018879 | accuracy: 0.9359168502202643 \n",
      "Epoch 22 | Step 8691 | loss: 0.1730382521718479 | accuracy: 0.9359237938596491 \n",
      "Epoch 22 | Step 8692 | loss: 0.17287882812744146 | accuracy: 0.9359306768558951 \n",
      "Epoch 22 | Step 8693 | loss: 0.17274431905344775 | accuracy: 0.9360733695652174 \n",
      "Epoch 22 | Step 8694 | loss: 0.17268408526912396 | accuracy: 0.9361471861471862 \n",
      "Epoch 22 | Step 8695 | loss: 0.17228163732215762 | accuracy: 0.9363550646551724 \n",
      "Epoch 22 | Step 8696 | loss: 0.1723119960418331 | accuracy: 0.936024678111588 \n",
      "Epoch 22 | Step 8697 | loss: 0.17245366499146336 | accuracy: 0.9359642094017094 \n",
      "Epoch 22 | Step 8698 | loss: 0.17231899193943814 | accuracy: 0.9361037234042553 \n",
      "Epoch 22 | Step 8699 | loss: 0.17202580623896951 | accuracy: 0.9363082627118644 \n",
      "Epoch 22 | Step 8700 | loss: 0.17187707797321589 | accuracy: 0.9365110759493671 \n",
      "Epoch 22 | Step 8701 | loss: 0.1717512613052831 | accuracy: 0.936515231092437 \n",
      "Epoch 22 | Step 8702 | loss: 0.17174889245479674 | accuracy: 0.9364539748953975 \n",
      "Epoch 22 | Step 8703 | loss: 0.17178664913711447 | accuracy: 0.9363932291666667 \n",
      "Epoch 22 | Step 8704 | loss: 0.17137479728002766 | accuracy: 0.936527489626556 \n",
      "Epoch 22 | Step 8705 | loss: 0.171223033019457 | accuracy: 0.9365315082644629 \n",
      "Epoch 22 | Step 8706 | loss: 0.17157280342385112 | accuracy: 0.9363425925925926 \n",
      "Epoch 22 | Step 8707 | loss: 0.17192689923294743 | accuracy: 0.9363473360655737 \n",
      "Epoch 22 | Step 8708 | loss: 0.17176949833424723 | accuracy: 0.9364158163265306 \n",
      "Epoch 22 | Step 8709 | loss: 0.17185386235454703 | accuracy: 0.9362931910569106 \n",
      "Epoch 22 | Step 8710 | loss: 0.17168944991129612 | accuracy: 0.9363613360323887 \n",
      "Epoch 22 | Step 8711 | loss: 0.1716567219775771 | accuracy: 0.9363029233870968 \n",
      "Epoch 22 | Step 8712 | loss: 0.1715708257832441 | accuracy: 0.9363077309236948 \n",
      "Epoch 22 | Step 8713 | loss: 0.1716829432398081 | accuracy: 0.93625 \n",
      "Epoch 22 | Step 8714 | loss: 0.1714809452484091 | accuracy: 0.9362549800796812 \n",
      "Epoch 22 | Step 8715 | loss: 0.17146402767430696 | accuracy: 0.9360739087301587 \n",
      "Epoch 22 | Step 8716 | loss: 0.17137473213519502 | accuracy: 0.936141304347826 \n",
      "Epoch 22 | Step 8717 | loss: 0.1714155164026604 | accuracy: 0.9360851377952756 \n",
      "Epoch 22 | Step 8718 | loss: 0.1714903987944126 | accuracy: 0.9360294117647059 \n",
      "Epoch 22 | Step 8719 | loss: 0.17158061706868466 | accuracy: 0.93585205078125 \n",
      "Epoch 22 | Step 8720 | loss: 0.17136166051957857 | accuracy: 0.9359192607003891 \n",
      "Epoch 22 | Step 8721 | loss: 0.17116827484537928 | accuracy: 0.9359859496124031 \n",
      "Epoch 22 | Step 8722 | loss: 0.17108247260847148 | accuracy: 0.9359917953667953 \n",
      "Epoch 22 | Step 8723 | loss: 0.17088066871063068 | accuracy: 0.9360576923076923 \n",
      "Epoch 22 | Step 8724 | loss: 0.17112314277167978 | accuracy: 0.9357638888888888 \n",
      "Epoch 22 | Step 8725 | loss: 0.1711796523704556 | accuracy: 0.9357108778625954 \n",
      "Epoch 22 | Step 8726 | loss: 0.17098530122705738 | accuracy: 0.935717680608365 \n",
      "Epoch 22 | Step 8727 | loss: 0.17144080018624663 | accuracy: 0.9356060606060606 \n",
      "Epoch 22 | Step 8728 | loss: 0.17135471610246963 | accuracy: 0.9355542452830189 \n",
      "Epoch 22 | Step 8729 | loss: 0.17140141038462184 | accuracy: 0.935561560150376 \n",
      "Epoch 22 | Step 8730 | loss: 0.17131213708484216 | accuracy: 0.93562734082397 \n",
      "Epoch 22 | Step 8731 | loss: 0.17097551268594924 | accuracy: 0.9358092350746269 \n",
      "Epoch 22 | Step 8732 | loss: 0.17092665485677666 | accuracy: 0.9358155204460966 \n",
      "Epoch 22 | Step 8733 | loss: 0.17089307980129012 | accuracy: 0.9358217592592593 \n",
      "Epoch 22 | Step 8734 | loss: 0.17084272572860068 | accuracy: 0.9357702952029521 \n",
      "Epoch 22 | Step 8735 | loss: 0.17082638987887871 | accuracy: 0.9357766544117647 \n",
      "Epoch 22 | Step 8736 | loss: 0.1709292805429562 | accuracy: 0.9356684981684982 \n",
      "Epoch 22 | Step 8737 | loss: 0.1708993557024829 | accuracy: 0.9356751824817519 \n",
      "Epoch 22 | Step 8738 | loss: 0.17084605351090434 | accuracy: 0.9356818181818182 \n",
      "Epoch 22 | Step 8739 | loss: 0.17105907200417228 | accuracy: 0.9354619565217391 \n",
      "Epoch 22 | Step 8740 | loss: 0.1710059882582095 | accuracy: 0.9355821299638989 \n",
      "Epoch 22 | Step 8741 | loss: 0.1708853752787808 | accuracy: 0.9357576438848921 \n",
      "Epoch 22 | Step 8742 | loss: 0.17090933066275388 | accuracy: 0.9355958781362007 \n",
      "Epoch 22 | Step 8743 | loss: 0.17094763249957137 | accuracy: 0.9356026785714285 \n",
      "Epoch 22 | Step 8744 | loss: 0.17125098909718714 | accuracy: 0.935442615658363 \n",
      "Epoch 22 | Step 8745 | loss: 0.1711048989933222 | accuracy: 0.9355053191489362 \n",
      "Epoch 22 | Step 8746 | loss: 0.1709862129611388 | accuracy: 0.9355675795053003 \n",
      "Epoch 22 | Step 8747 | loss: 0.17093499968956477 | accuracy: 0.9356294014084507 \n",
      "Epoch 22 | Step 8748 | loss: 0.17082910750780192 | accuracy: 0.9357456140350877 \n",
      "Epoch 22 | Step 8749 | loss: 0.1707914571010775 | accuracy: 0.9356971153846154 \n",
      "Epoch 22 | Step 8750 | loss: 0.17064415046925746 | accuracy: 0.9357033972125436 \n",
      "Epoch 22 | Step 8751 | loss: 0.17044313977627706 | accuracy: 0.9358181423611112 \n",
      "Epoch 22 | Step 8752 | loss: 0.17019212430272138 | accuracy: 0.935878027681661 \n",
      "Epoch 22 | Step 8753 | loss: 0.17066754913278698 | accuracy: 0.9357758620689656 \n",
      "Epoch 22 | Step 8754 | loss: 0.1705717740778866 | accuracy: 0.9358354810996563 \n",
      "Epoch 22 | Step 8755 | loss: 0.17051548575854875 | accuracy: 0.935894691780822 \n",
      "Epoch 22 | Step 8756 | loss: 0.17057997576968664 | accuracy: 0.9359534982935154 \n",
      "Epoch 22 | Step 8757 | loss: 0.17025139176470488 | accuracy: 0.9361181972789115 \n",
      "Epoch 22 | Step 8758 | loss: 0.17040488688369929 | accuracy: 0.9359110169491526 \n",
      "Epoch 22 | Step 8759 | loss: 0.1703162499250391 | accuracy: 0.9359163851351351 \n",
      "Epoch 22 | Step 8760 | loss: 0.1704551385282868 | accuracy: 0.9358164983164983 \n",
      "Epoch 22 | Step 8761 | loss: 0.17034630066146386 | accuracy: 0.9357697147651006 \n",
      "Epoch 22 | Step 8762 | loss: 0.17019799729204896 | accuracy: 0.9358277591973244 \n",
      "Epoch 22 | Step 8763 | loss: 0.17004460559537013 | accuracy: 0.9358854166666667 \n",
      "Epoch 22 | Step 8764 | loss: 0.1699182030890273 | accuracy: 0.9359426910299004 \n",
      "Epoch 22 | Step 8765 | loss: 0.1697373939493042 | accuracy: 0.9359995860927153 \n",
      "Epoch 22 | Step 8766 | loss: 0.16954426894044325 | accuracy: 0.9360045379537953 \n",
      "Epoch 22 | Step 8767 | loss: 0.16952257062994727 | accuracy: 0.9359580592105263 \n",
      "Epoch 22 | Step 8768 | loss: 0.16982389530930364 | accuracy: 0.9357581967213114 \n",
      "Epoch 22 | Step 8769 | loss: 0.1696504882956837 | accuracy: 0.9359170751633987 \n",
      "Epoch 22 | Step 8770 | loss: 0.1695066326046029 | accuracy: 0.9360749185667753 \n",
      "Epoch 22 | Step 8771 | loss: 0.16919677983969453 | accuracy: 0.9361810064935064 \n",
      "Epoch 22 | Step 8772 | loss: 0.16883936701613725 | accuracy: 0.9363369741100324 \n",
      "Epoch 22 | Step 8773 | loss: 0.1689307200692354 | accuracy: 0.9362399193548387 \n",
      "Epoch 22 | Step 8774 | loss: 0.16888972219690634 | accuracy: 0.9362942122186495 \n",
      "Epoch 22 | Step 8775 | loss: 0.1689103729425906 | accuracy: 0.9362980769230769 \n",
      "Epoch 22 | Step 8776 | loss: 0.1686946010223022 | accuracy: 0.9363019169329073 \n",
      "Epoch 22 | Step 8777 | loss: 0.16869971881009596 | accuracy: 0.9362062101910829 \n",
      "Epoch 22 | Step 8778 | loss: 0.16843564334133318 | accuracy: 0.9363591269841269 \n",
      "Epoch 22 | Step 8779 | loss: 0.16849831424512066 | accuracy: 0.9363627373417721 \n",
      "Epoch 22 | Step 8780 | loss: 0.16832976335841776 | accuracy: 0.936464905362776 \n",
      "Epoch 22 | Step 8781 | loss: 0.16821478908213808 | accuracy: 0.9364681603773585 \n",
      "Epoch 22 | Step 8782 | loss: 0.16821553706422127 | accuracy: 0.936471394984326 \n",
      "Epoch 22 | Step 8783 | loss: 0.16804722211090853 | accuracy: 0.936572265625 \n",
      "Epoch 22 | Step 8784 | loss: 0.16800812619079686 | accuracy: 0.936623831775701 \n",
      "Epoch 22 | Step 8785 | loss: 0.1678947770146665 | accuracy: 0.9367236024844721 \n",
      "Epoch 22 | Step 8786 | loss: 0.16789007808540263 | accuracy: 0.9367743808049536 \n",
      "Epoch 22 | Step 8787 | loss: 0.16775457343707487 | accuracy: 0.9368248456790124 \n",
      "Epoch 22 | Step 8788 | loss: 0.1676490638691646 | accuracy: 0.936875 \n",
      "Epoch 22 | Step 8789 | loss: 0.1678070506320958 | accuracy: 0.9367810582822086 \n",
      "Epoch 22 | Step 8790 | loss: 0.16790299275918474 | accuracy: 0.9366876911314985 \n",
      "Epoch 22 | Step 8791 | loss: 0.16810834243121306 | accuracy: 0.9366425304878049 \n",
      "Epoch 22 | Step 8792 | loss: 0.16780001610109868 | accuracy: 0.9367401215805471 \n",
      "Epoch 22 | Step 8793 | loss: 0.16773625775945908 | accuracy: 0.9366477272727273 \n",
      "Epoch 22 | Step 8794 | loss: 0.16777441991645042 | accuracy: 0.9366030966767371 \n",
      "Epoch 22 | Step 8795 | loss: 0.16767545283424207 | accuracy: 0.9366999246987951 \n",
      "Epoch 22 | Step 8796 | loss: 0.16769351075227193 | accuracy: 0.9367492492492493 \n",
      "Epoch 22 | Step 8797 | loss: 0.16764008799222055 | accuracy: 0.936751497005988 \n",
      "Epoch 22 | Step 8798 | loss: 0.16760465788529877 | accuracy: 0.9368470149253731 \n",
      "Epoch 22 | Step 8799 | loss: 0.16759566121202493 | accuracy: 0.9368489583333334 \n",
      "Epoch 22 | Step 8800 | loss: 0.1674814793869897 | accuracy: 0.9369899851632048 \n",
      "Epoch 22 | Step 8801 | loss: 0.16745596838641094 | accuracy: 0.9368990384615384 \n",
      "Epoch 22 | Step 8802 | loss: 0.16735517122620677 | accuracy: 0.936808628318584 \n",
      "Epoch 22 | Step 8803 | loss: 0.16721646530444131 | accuracy: 0.9369025735294118 \n",
      "Epoch 22 | Step 8804 | loss: 0.16729733303101882 | accuracy: 0.9369043255131965 \n",
      "Epoch 22 | Step 8805 | loss: 0.16731855032518944 | accuracy: 0.9368146929824561 \n",
      "Epoch 22 | Step 8806 | loss: 0.16706690564751628 | accuracy: 0.9369077988338192 \n",
      "Epoch 22 | Step 8807 | loss: 0.16689715721796075 | accuracy: 0.9369549418604651 \n",
      "Epoch 22 | Step 8808 | loss: 0.1668243822952112 | accuracy: 0.936911231884058 \n",
      "Epoch 22 | Step 8809 | loss: 0.1666493421323555 | accuracy: 0.9370484104046243 \n",
      "Epoch 22 | Step 8810 | loss: 0.16655534504770553 | accuracy: 0.9371397694524496 \n",
      "Epoch 22 | Step 8811 | loss: 0.16628071078067205 | accuracy: 0.9372755028735632 \n",
      "Epoch 22 | Step 8812 | loss: 0.166262202701374 | accuracy: 0.9372761461318052 \n",
      "Epoch 22 | Step 8813 | loss: 0.16633041321166933 | accuracy: 0.9371875 \n",
      "Epoch 22 | Step 8814 | loss: 0.1660510239501795 | accuracy: 0.9372774216524217 \n",
      "Epoch 22 | Step 8815 | loss: 0.1660457213557411 | accuracy: 0.9371892755681818 \n",
      "Epoch 22 | Step 8816 | loss: 0.16607248119313398 | accuracy: 0.9371458923512748 \n",
      "Epoch 22 | Step 8817 | loss: 0.1661363449368606 | accuracy: 0.9371468926553672 \n",
      "Epoch 22 | Step 8818 | loss: 0.1660535083585223 | accuracy: 0.9371038732394367 \n",
      "Epoch 22 | Step 8819 | loss: 0.16593500043610857 | accuracy: 0.9371488764044944 \n",
      "Epoch 22 | Step 8820 | loss: 0.16618537361256228 | accuracy: 0.937062324929972 \n",
      "Epoch 22 | Step 8821 | loss: 0.16660384243801665 | accuracy: 0.9369326117318436 \n",
      "Epoch 22 | Step 8822 | loss: 0.16654398009015006 | accuracy: 0.9369341922005571 \n",
      "Epoch 22 | Step 8823 | loss: 0.16661712213729832 | accuracy: 0.9369791666666667 \n",
      "Epoch 22 | Step 8824 | loss: 0.16646005230803582 | accuracy: 0.937023891966759 \n",
      "Epoch 22 | Step 8825 | loss: 0.16648685920839493 | accuracy: 0.9370252071823204 \n",
      "Epoch 22 | Step 8826 | loss: 0.16645501949118857 | accuracy: 0.9370265151515151 \n",
      "Epoch 22 | Step 8827 | loss: 0.16613855050201284 | accuracy: 0.9371995192307693 \n",
      "Epoch 22 | Step 8828 | loss: 0.16593322712060535 | accuracy: 0.9373287671232877 \n",
      "Epoch 22 | Step 8829 | loss: 0.16601120805764796 | accuracy: 0.937286543715847 \n",
      "Epoch 22 | Step 8830 | loss: 0.1659982629039146 | accuracy: 0.9372871253405994 \n",
      "Epoch 22 | Step 8831 | loss: 0.16595079501807378 | accuracy: 0.9373726222826086 \n",
      "Epoch 22 | Step 8832 | loss: 0.16614136280527295 | accuracy: 0.9373729674796748 \n",
      "Epoch 22 | Step 8833 | loss: 0.16600043462539052 | accuracy: 0.9374155405405405 \n",
      "Epoch 22 | Step 8834 | loss: 0.16605977010172665 | accuracy: 0.9374157681940701 \n",
      "Epoch 22 | Step 8835 | loss: 0.16591494789807718 | accuracy: 0.9375 \n",
      "Epoch 22 | Step 8836 | loss: 0.16564712872174417 | accuracy: 0.9376256702412868 \n",
      "Epoch 22 | Step 8837 | loss: 0.1655036369089616 | accuracy: 0.9376671122994652 \n",
      "Epoch 22 | Step 8838 | loss: 0.1656248920261861 | accuracy: 0.9376666666666666 \n",
      "Epoch 22 | Step 8839 | loss: 0.16542588109943154 | accuracy: 0.937749335106383 \n",
      "Epoch 22 | Step 8840 | loss: 0.16523069476298702 | accuracy: 0.9378730106100795 \n",
      "Epoch 22 | Step 8841 | loss: 0.16506925689440882 | accuracy: 0.9379546957671958 \n",
      "Epoch 22 | Step 8842 | loss: 0.1648866717942001 | accuracy: 0.9380359498680739 \n",
      "Epoch 22 | Step 8843 | loss: 0.1647704263953003 | accuracy: 0.9380345394736842 \n",
      "Epoch 22 | Step 8844 | loss: 0.1645987478629968 | accuracy: 0.9380741469816273 \n",
      "Epoch 22 | Step 8845 | loss: 0.1647480789923076 | accuracy: 0.9380726439790575 \n",
      "Epoch 22 | Step 8846 | loss: 0.16485276344589722 | accuracy: 0.9380303524804178 \n",
      "Epoch 22 | Step 8847 | loss: 0.16520690600737006 | accuracy: 0.9380289713541666 \n",
      "Epoch 22 | Step 8848 | loss: 0.16497950539379932 | accuracy: 0.9381493506493507 \n",
      "Epoch 22 | Step 8849 | loss: 0.16488047813697498 | accuracy: 0.9382286269430051 \n",
      "Epoch 22 | Step 8850 | loss: 0.16483213551323242 | accuracy: 0.9381863695090439 \n",
      "Epoch 22 | Step 8851 | loss: 0.16509652599577138 | accuracy: 0.9381443298969072 \n",
      "Epoch 22 | Step 8852 | loss: 0.16499990348376167 | accuracy: 0.9381025064267352 \n",
      "Epoch 22 | Step 8853 | loss: 0.16490776199751947 | accuracy: 0.9381810897435897 \n",
      "Epoch 22 | Step 8854 | loss: 0.16497240431816385 | accuracy: 0.9382193094629157 \n",
      "Epoch 22 | Step 8855 | loss: 0.1648718675275391 | accuracy: 0.9382971938775511 \n",
      "Epoch 22 | Step 8856 | loss: 0.1648514306518717 | accuracy: 0.938295165394402 \n",
      "Epoch 22 | Step 8857 | loss: 0.16489157996844828 | accuracy: 0.9382534898477157 \n",
      "Epoch 22 | Step 8858 | loss: 0.1646506921117065 | accuracy: 0.9384098101265823 \n",
      "Epoch 22 | Step 8859 | loss: 0.16440257739576736 | accuracy: 0.9385258838383839 \n",
      "Epoch 22 | Step 8860 | loss: 0.16452616390300645 | accuracy: 0.9384839420654912 \n",
      "Epoch 22 | Step 8861 | loss: 0.16456563138969288 | accuracy: 0.9384422110552764 \n",
      "Epoch 22 | Step 8862 | loss: 0.1643092417365926 | accuracy: 0.9385573308270677 \n",
      "Epoch 22 | Step 8863 | loss: 0.16423439277336008 | accuracy: 0.93859375 \n",
      "Epoch 22 | Step 8864 | loss: 0.16437548902489604 | accuracy: 0.9385910224438903 \n",
      "Epoch 22 | Step 8865 | loss: 0.16461866914262233 | accuracy: 0.9384717039800995 \n",
      "Epoch 22 | Step 8866 | loss: 0.16443729237942195 | accuracy: 0.938538814448837 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.5716328024864197 | accuracy: 0.8125 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.49941159784793854 | accuracy: 0.828125 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.572996566692988 | accuracy: 0.828125 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.5428764894604683 | accuracy: 0.828125 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.5066005706787109 | accuracy: 0.84375 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.5347485442956289 | accuracy: 0.8307291666666666 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.527111108813967 | accuracy: 0.8325892857142857 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.5137069076299667 | accuracy: 0.83203125 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.5569394032160441 | accuracy: 0.8229166666666666 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.5344364613294601 | accuracy: 0.83125 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.5292573598298159 | accuracy: 0.8323863636363636 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.5140358780821165 | accuracy: 0.8359375 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.5288491272009336 | accuracy: 0.8305288461538461 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.5083644028220858 | accuracy: 0.8337053571428571 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.5131396512190501 | accuracy: 0.8354166666666667 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.5059022605419159 | accuracy: 0.8349609375 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.5054128695936764 | accuracy: 0.8345588235294118 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.501491634382142 | accuracy: 0.8350694444444444 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.49218370883088364 | accuracy: 0.8388157894736842 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.48388765305280684 | accuracy: 0.840625 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.47435731831051053 | accuracy: 0.8415178571428571 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.46744360707022925 | accuracy: 0.8416193181818182 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.4784586481426073 | accuracy: 0.8396739130434783 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.5045127471288046 | accuracy: 0.8359375 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.5158689928054809 | accuracy: 0.833125 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.5098397812018027 | accuracy: 0.8353365384615384 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.5014495176297648 | accuracy: 0.8373842592592593 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.5044619962573053 | accuracy: 0.8359375 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.5021177951631877 | accuracy: 0.8367456896551724 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.49933544794718443 | accuracy: 0.8385416666666666 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.49367306213225104 | accuracy: 0.8412298387096774 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.49808921758085506 | accuracy: 0.83935546875 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.49918080008391197 | accuracy: 0.8357007575757576 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.4992560244658416 | accuracy: 0.8340992647058824 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.5018030379499709 | accuracy: 0.8339285714285715 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.4987934446997115 | accuracy: 0.8355034722222222 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.49954798737087786 | accuracy: 0.8357263513513513 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.5027598550445157 | accuracy: 0.8363486842105263 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.5043355776713446 | accuracy: 0.8341346153846154 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.4988296873867514 | accuracy: 0.835546875 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.4945760209385943 | accuracy: 0.8353658536585366 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.4885649276631221 | accuracy: 0.8370535714285714 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.48767943368401656 | accuracy: 0.8368459302325582 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.48842458223754726 | accuracy: 0.8373579545454546 \n",
      "Validation | Epoch 22 | Step 8866 | loss: 0.48842733502388014 | accuracy: 0.836141304175059 \n",
      "Epoch 23 | Step 8867 | loss: 0.3129916787147522 | accuracy: 0.90625 \n",
      "Epoch 23 | Step 8868 | loss: 0.19742025062441826 | accuracy: 0.9375 \n",
      "Epoch 23 | Step 8869 | loss: 0.17212573935588202 | accuracy: 0.9479166666666666 \n",
      "Epoch 23 | Step 8870 | loss: 0.17610382474958897 | accuracy: 0.9453125 \n",
      "Epoch 23 | Step 8871 | loss: 0.16633536368608476 | accuracy: 0.95 \n",
      "Epoch 23 | Step 8872 | loss: 0.15522035211324692 | accuracy: 0.9505208333333334 \n",
      "Epoch 23 | Step 8873 | loss: 0.16465461679867335 | accuracy: 0.9486607142857143 \n",
      "Epoch 23 | Step 8874 | loss: 0.16098816320300102 | accuracy: 0.951171875 \n",
      "Epoch 23 | Step 8875 | loss: 0.16523430579238468 | accuracy: 0.9513888888888888 \n",
      "Epoch 23 | Step 8876 | loss: 0.1704835534095764 | accuracy: 0.95 \n",
      "Epoch 23 | Step 8877 | loss: 0.16529537466439334 | accuracy: 0.9517045454545454 \n",
      "Epoch 23 | Step 8878 | loss: 0.15918352951606116 | accuracy: 0.953125 \n",
      "Epoch 23 | Step 8879 | loss: 0.17516672840485206 | accuracy: 0.9471153846153846 \n",
      "Epoch 23 | Step 8880 | loss: 0.17417148500680923 | accuracy: 0.9486607142857143 \n",
      "Epoch 23 | Step 8881 | loss: 0.17629404465357462 | accuracy: 0.9458333333333333 \n",
      "Epoch 23 | Step 8882 | loss: 0.16940489644184709 | accuracy: 0.9482421875 \n",
      "Epoch 23 | Step 8883 | loss: 0.17081395799622817 | accuracy: 0.9439338235294118 \n",
      "Epoch 23 | Step 8884 | loss: 0.1685091070830822 | accuracy: 0.9435763888888888 \n",
      "Epoch 23 | Step 8885 | loss: 0.16779386879582153 | accuracy: 0.9432565789473685 \n",
      "Epoch 23 | Step 8886 | loss: 0.16904116980731487 | accuracy: 0.94453125 \n",
      "Epoch 23 | Step 8887 | loss: 0.16851017695097698 | accuracy: 0.9441964285714286 \n",
      "Epoch 23 | Step 8888 | loss: 0.1704582778567618 | accuracy: 0.9438920454545454 \n",
      "Epoch 23 | Step 8889 | loss: 0.16665458517230078 | accuracy: 0.9442934782608695 \n",
      "Epoch 23 | Step 8890 | loss: 0.1659841708218058 | accuracy: 0.943359375 \n",
      "Epoch 23 | Step 8891 | loss: 0.16799860030412675 | accuracy: 0.941875 \n",
      "Epoch 23 | Step 8892 | loss: 0.16631468012928963 | accuracy: 0.9411057692307693 \n",
      "Epoch 23 | Step 8893 | loss: 0.17390552852992658 | accuracy: 0.9386574074074074 \n",
      "Epoch 23 | Step 8894 | loss: 0.17019863719386713 | accuracy: 0.9402901785714286 \n",
      "Epoch 23 | Step 8895 | loss: 0.17251957516218053 | accuracy: 0.9396551724137931 \n",
      "Epoch 23 | Step 8896 | loss: 0.1726948616405328 | accuracy: 0.9390625 \n",
      "Epoch 23 | Step 8897 | loss: 0.17224954717582272 | accuracy: 0.9390120967741935 \n",
      "Epoch 23 | Step 8898 | loss: 0.17202102742157876 | accuracy: 0.93896484375 \n",
      "Epoch 23 | Step 8899 | loss: 0.1715339415452697 | accuracy: 0.9389204545454546 \n",
      "Epoch 23 | Step 8900 | loss: 0.16815976973842173 | accuracy: 0.9402573529411765 \n",
      "Epoch 23 | Step 8901 | loss: 0.1650794230401516 | accuracy: 0.9419642857142857 \n",
      "Epoch 23 | Step 8902 | loss: 0.16334474097109503 | accuracy: 0.9422743055555556 \n",
      "Epoch 23 | Step 8903 | loss: 0.16336780111934687 | accuracy: 0.941722972972973 \n",
      "Epoch 23 | Step 8904 | loss: 0.16149319188767358 | accuracy: 0.9420230263157895 \n",
      "Epoch 23 | Step 8905 | loss: 0.1593137858196711 | accuracy: 0.9423076923076923 \n",
      "Epoch 23 | Step 8906 | loss: 0.15821614237502218 | accuracy: 0.94296875 \n",
      "Epoch 23 | Step 8907 | loss: 0.1561766178687898 | accuracy: 0.9439786585365854 \n",
      "Epoch 23 | Step 8908 | loss: 0.1561526818467038 | accuracy: 0.9430803571428571 \n",
      "Epoch 23 | Step 8909 | loss: 0.15494065861715828 | accuracy: 0.9433139534883721 \n",
      "Epoch 23 | Step 8910 | loss: 0.15416000470180402 | accuracy: 0.9435369318181818 \n",
      "Epoch 23 | Step 8911 | loss: 0.1562837609814273 | accuracy: 0.9427083333333334 \n",
      "Epoch 23 | Step 8912 | loss: 0.15653199726796668 | accuracy: 0.9429347826086957 \n",
      "Epoch 23 | Step 8913 | loss: 0.15553881045668683 | accuracy: 0.9434840425531915 \n",
      "Epoch 23 | Step 8914 | loss: 0.1550684084650129 | accuracy: 0.9440104166666666 \n",
      "Epoch 23 | Step 8915 | loss: 0.15683637262911213 | accuracy: 0.9429209183673469 \n",
      "Epoch 23 | Step 8916 | loss: 0.1570741368085146 | accuracy: 0.943125 \n",
      "Epoch 23 | Step 8917 | loss: 0.15766331034840322 | accuracy: 0.9427083333333334 \n",
      "Epoch 23 | Step 8918 | loss: 0.1564665582174292 | accuracy: 0.9432091346153846 \n",
      "Epoch 23 | Step 8919 | loss: 0.15793803270976497 | accuracy: 0.9428066037735849 \n",
      "Epoch 23 | Step 8920 | loss: 0.15673363063898352 | accuracy: 0.9435763888888888 \n",
      "Epoch 23 | Step 8921 | loss: 0.15772468197074804 | accuracy: 0.9428977272727272 \n",
      "Epoch 23 | Step 8922 | loss: 0.1570270836486348 | accuracy: 0.943359375 \n",
      "Epoch 23 | Step 8923 | loss: 0.15785675515469752 | accuracy: 0.9429824561403509 \n",
      "Epoch 23 | Step 8924 | loss: 0.15865545572134956 | accuracy: 0.9428879310344828 \n",
      "Epoch 23 | Step 8925 | loss: 0.16008042891399335 | accuracy: 0.9427966101694916 \n",
      "Epoch 23 | Step 8926 | loss: 0.1616113613670071 | accuracy: 0.9424479166666667 \n",
      "Epoch 23 | Step 8927 | loss: 0.16076646372675896 | accuracy: 0.9423668032786885 \n",
      "Epoch 23 | Step 8928 | loss: 0.16032854221280543 | accuracy: 0.9427923387096774 \n",
      "Epoch 23 | Step 8929 | loss: 0.16240111531482804 | accuracy: 0.9417162698412699 \n",
      "Epoch 23 | Step 8930 | loss: 0.16090378985973075 | accuracy: 0.9423828125 \n",
      "Epoch 23 | Step 8931 | loss: 0.15934791112175353 | accuracy: 0.9432692307692307 \n",
      "Epoch 23 | Step 8932 | loss: 0.15815204534340987 | accuracy: 0.9438920454545454 \n",
      "Epoch 23 | Step 8933 | loss: 0.15773184814337474 | accuracy: 0.9437966417910447 \n",
      "Epoch 23 | Step 8934 | loss: 0.15818295885315714 | accuracy: 0.9437040441176471 \n",
      "Epoch 23 | Step 8935 | loss: 0.15807238323748976 | accuracy: 0.9436141304347826 \n",
      "Epoch 23 | Step 8936 | loss: 0.157839804195932 | accuracy: 0.9430803571428571 \n",
      "Epoch 23 | Step 8937 | loss: 0.1565091287271238 | accuracy: 0.9436619718309859 \n",
      "Epoch 23 | Step 8938 | loss: 0.15663086027941772 | accuracy: 0.9435763888888888 \n",
      "Epoch 23 | Step 8939 | loss: 0.15659275349892984 | accuracy: 0.9430650684931506 \n",
      "Epoch 23 | Step 8940 | loss: 0.1567493415865544 | accuracy: 0.9429898648648649 \n",
      "Epoch 23 | Step 8941 | loss: 0.15693509841958683 | accuracy: 0.9429166666666666 \n",
      "Epoch 23 | Step 8942 | loss: 0.15705663186350938 | accuracy: 0.9430509868421053 \n",
      "Epoch 23 | Step 8943 | loss: 0.15655288492123803 | accuracy: 0.9429788961038961 \n",
      "Epoch 23 | Step 8944 | loss: 0.15704019391574922 | accuracy: 0.9427083333333334 \n",
      "Epoch 23 | Step 8945 | loss: 0.1596158779214455 | accuracy: 0.9420490506329114 \n",
      "Epoch 23 | Step 8946 | loss: 0.1589283643756062 | accuracy: 0.9421875 \n",
      "Epoch 23 | Step 8947 | loss: 0.15839476924803525 | accuracy: 0.9423225308641975 \n",
      "Epoch 23 | Step 8948 | loss: 0.15745986975366025 | accuracy: 0.9428353658536586 \n",
      "Epoch 23 | Step 8949 | loss: 0.15759061828973783 | accuracy: 0.9429593373493976 \n",
      "Epoch 23 | Step 8950 | loss: 0.15708733691523474 | accuracy: 0.9430803571428571 \n",
      "Epoch 23 | Step 8951 | loss: 0.1566121845122646 | accuracy: 0.9435661764705883 \n",
      "Epoch 23 | Step 8952 | loss: 0.15625018162956072 | accuracy: 0.9436773255813954 \n",
      "Epoch 23 | Step 8953 | loss: 0.1579798080198381 | accuracy: 0.9432471264367817 \n",
      "Epoch 23 | Step 8954 | loss: 0.15886241625147784 | accuracy: 0.9430042613636364 \n",
      "Epoch 23 | Step 8955 | loss: 0.15814416072844117 | accuracy: 0.9434691011235955 \n",
      "Epoch 23 | Step 8956 | loss: 0.15840463269915844 | accuracy: 0.9434027777777778 \n",
      "Epoch 23 | Step 8957 | loss: 0.15750317156806096 | accuracy: 0.9436813186813187 \n",
      "Epoch 23 | Step 8958 | loss: 0.1568086546967211 | accuracy: 0.943953804347826 \n",
      "Epoch 23 | Step 8959 | loss: 0.15656124115470918 | accuracy: 0.9438844086021505 \n",
      "Epoch 23 | Step 8960 | loss: 0.1561255537845353 | accuracy: 0.9439827127659575 \n",
      "Epoch 23 | Step 8961 | loss: 0.1562262552741327 | accuracy: 0.9439144736842106 \n",
      "Epoch 23 | Step 8962 | loss: 0.15815115801524374 | accuracy: 0.9435221354166666 \n",
      "Epoch 23 | Step 8963 | loss: 0.15780007988982597 | accuracy: 0.9437822164948454 \n",
      "Epoch 23 | Step 8964 | loss: 0.15907202687646665 | accuracy: 0.943718112244898 \n",
      "Epoch 23 | Step 8965 | loss: 0.15962293348980677 | accuracy: 0.9438131313131313 \n",
      "Epoch 23 | Step 8966 | loss: 0.15904892850667243 | accuracy: 0.94421875 \n",
      "Epoch 23 | Step 8967 | loss: 0.15810009877723047 | accuracy: 0.9446163366336634 \n",
      "Epoch 23 | Step 8968 | loss: 0.15795599840873603 | accuracy: 0.9446997549019608 \n",
      "Epoch 23 | Step 8969 | loss: 0.15703390686980737 | accuracy: 0.9450849514563107 \n",
      "Epoch 23 | Step 8970 | loss: 0.15722340864774134 | accuracy: 0.9450120192307693 \n",
      "Epoch 23 | Step 8971 | loss: 0.15853911755340447 | accuracy: 0.9446428571428571 \n",
      "Epoch 23 | Step 8972 | loss: 0.15763369726263135 | accuracy: 0.9450176886792453 \n",
      "Epoch 23 | Step 8973 | loss: 0.15801429835574657 | accuracy: 0.9448014018691588 \n",
      "Epoch 23 | Step 8974 | loss: 0.1590074196250903 | accuracy: 0.9441550925925926 \n",
      "Epoch 23 | Step 8975 | loss: 0.1594878568083322 | accuracy: 0.9440940366972477 \n",
      "Epoch 23 | Step 8976 | loss: 0.16003523404625336 | accuracy: 0.94375 \n",
      "Epoch 23 | Step 8977 | loss: 0.15975797662998112 | accuracy: 0.9439752252252253 \n",
      "Epoch 23 | Step 8978 | loss: 0.15972374356351798 | accuracy: 0.9440569196428571 \n",
      "Epoch 23 | Step 8979 | loss: 0.1609710581864404 | accuracy: 0.9435840707964602 \n",
      "Epoch 23 | Step 8980 | loss: 0.16095750063265632 | accuracy: 0.9436677631578947 \n",
      "Epoch 23 | Step 8981 | loss: 0.1605362819264765 | accuracy: 0.94375 \n",
      "Epoch 23 | Step 8982 | loss: 0.16029217270813118 | accuracy: 0.9438308189655172 \n",
      "Epoch 23 | Step 8983 | loss: 0.16090544150807926 | accuracy: 0.9432425213675214 \n",
      "Epoch 23 | Step 8984 | loss: 0.1604863974439391 | accuracy: 0.9431938559322034 \n",
      "Epoch 23 | Step 8985 | loss: 0.16068793554641625 | accuracy: 0.9432773109243697 \n",
      "Epoch 23 | Step 8986 | loss: 0.1603225021002194 | accuracy: 0.9432291666666667 \n",
      "Epoch 23 | Step 8987 | loss: 0.16031735085628254 | accuracy: 0.9431818181818182 \n",
      "Epoch 23 | Step 8988 | loss: 0.16018598621375255 | accuracy: 0.9431352459016393 \n",
      "Epoch 23 | Step 8989 | loss: 0.15986449958953436 | accuracy: 0.943089430894309 \n",
      "Epoch 23 | Step 8990 | loss: 0.15983376907364982 | accuracy: 0.9431703629032258 \n",
      "Epoch 23 | Step 8991 | loss: 0.1593576544821263 | accuracy: 0.943375 \n",
      "Epoch 23 | Step 8992 | loss: 0.15948221232328155 | accuracy: 0.943328373015873 \n",
      "Epoch 23 | Step 8993 | loss: 0.16049133959834974 | accuracy: 0.9427903543307087 \n",
      "Epoch 23 | Step 8994 | loss: 0.16035679509514017 | accuracy: 0.9425048828125 \n",
      "Epoch 23 | Step 8995 | loss: 0.15995787456631666 | accuracy: 0.9424660852713178 \n",
      "Epoch 23 | Step 8996 | loss: 0.159736487412682 | accuracy: 0.9426682692307692 \n",
      "Epoch 23 | Step 8997 | loss: 0.1601619627468914 | accuracy: 0.9423902671755725 \n",
      "Epoch 23 | Step 8998 | loss: 0.16114356416757364 | accuracy: 0.9423532196969697 \n",
      "Epoch 23 | Step 8999 | loss: 0.16145905519002368 | accuracy: 0.9420817669172933 \n",
      "Epoch 23 | Step 9000 | loss: 0.1616801679857187 | accuracy: 0.9420475746268657 \n",
      "Epoch 23 | Step 9001 | loss: 0.16154558804851996 | accuracy: 0.9418981481481481 \n",
      "Epoch 23 | Step 9002 | loss: 0.16123259168885215 | accuracy: 0.9419806985294118 \n",
      "Epoch 23 | Step 9003 | loss: 0.16082535632444128 | accuracy: 0.9421760948905109 \n",
      "Epoch 23 | Step 9004 | loss: 0.1607694450117972 | accuracy: 0.9423686594202898 \n",
      "Epoch 23 | Step 9005 | loss: 0.1611734061843629 | accuracy: 0.9423336330935251 \n",
      "Epoch 23 | Step 9006 | loss: 0.16120240275881126 | accuracy: 0.9424107142857143 \n",
      "Epoch 23 | Step 9007 | loss: 0.16235362122773284 | accuracy: 0.9420434397163121 \n",
      "Epoch 23 | Step 9008 | loss: 0.16268800579431197 | accuracy: 0.9421214788732394 \n",
      "Epoch 23 | Step 9009 | loss: 0.16300330079206224 | accuracy: 0.9420891608391608 \n",
      "Epoch 23 | Step 9010 | loss: 0.16269070926743254 | accuracy: 0.9422743055555556 \n",
      "Epoch 23 | Step 9011 | loss: 0.16247248015013238 | accuracy: 0.9423491379310345 \n",
      "Epoch 23 | Step 9012 | loss: 0.16291065822827494 | accuracy: 0.9421018835616438 \n",
      "Epoch 23 | Step 9013 | loss: 0.16210874431088673 | accuracy: 0.9424957482993197 \n",
      "Epoch 23 | Step 9014 | loss: 0.1621740604624958 | accuracy: 0.9425675675675675 \n",
      "Epoch 23 | Step 9015 | loss: 0.1616676222507986 | accuracy: 0.9429530201342282 \n",
      "Epoch 23 | Step 9016 | loss: 0.1620721374700467 | accuracy: 0.9429166666666666 \n",
      "Epoch 23 | Step 9017 | loss: 0.16238315933883588 | accuracy: 0.9427773178807947 \n",
      "Epoch 23 | Step 9018 | loss: 0.16364290062828285 | accuracy: 0.9425370065789473 \n",
      "Epoch 23 | Step 9019 | loss: 0.16432977275423757 | accuracy: 0.9424019607843137 \n",
      "Epoch 23 | Step 9020 | loss: 0.163944501647508 | accuracy: 0.942674512987013 \n",
      "Epoch 23 | Step 9021 | loss: 0.16380655830425603 | accuracy: 0.942641129032258 \n",
      "Epoch 23 | Step 9022 | loss: 0.16323264442288726 | accuracy: 0.9428084935897436 \n",
      "Epoch 23 | Step 9023 | loss: 0.16287739302037632 | accuracy: 0.9429737261146497 \n",
      "Epoch 23 | Step 9024 | loss: 0.1626161592246234 | accuracy: 0.9431368670886076 \n",
      "Epoch 23 | Step 9025 | loss: 0.1626192909319821 | accuracy: 0.9429048742138365 \n",
      "Epoch 23 | Step 9026 | loss: 0.16267843123059725 | accuracy: 0.9427734375 \n",
      "Epoch 23 | Step 9027 | loss: 0.1629446696559465 | accuracy: 0.9427406832298136 \n",
      "Epoch 23 | Step 9028 | loss: 0.1626453684114012 | accuracy: 0.9428047839506173 \n",
      "Epoch 23 | Step 9029 | loss: 0.16378802602733572 | accuracy: 0.942101226993865 \n",
      "Epoch 23 | Step 9030 | loss: 0.16358955888213908 | accuracy: 0.9419778963414634 \n",
      "Epoch 23 | Step 9031 | loss: 0.16347386478023096 | accuracy: 0.9419507575757575 \n",
      "Epoch 23 | Step 9032 | loss: 0.16354053783937392 | accuracy: 0.9417356927710844 \n",
      "Epoch 23 | Step 9033 | loss: 0.1631738638315729 | accuracy: 0.9416167664670658 \n",
      "Epoch 23 | Step 9034 | loss: 0.16377167157562716 | accuracy: 0.9413132440476191 \n",
      "Epoch 23 | Step 9035 | loss: 0.16350322033791148 | accuracy: 0.9412906804733728 \n",
      "Epoch 23 | Step 9036 | loss: 0.16289312789107072 | accuracy: 0.9416360294117647 \n",
      "Epoch 23 | Step 9037 | loss: 0.1629212999945147 | accuracy: 0.941703216374269 \n",
      "Epoch 23 | Step 9038 | loss: 0.16306236968917212 | accuracy: 0.9416787790697675 \n",
      "Epoch 23 | Step 9039 | loss: 0.16272540663966556 | accuracy: 0.9417449421965318 \n",
      "Epoch 23 | Step 9040 | loss: 0.16294312766142963 | accuracy: 0.9418103448275862 \n",
      "Epoch 23 | Step 9041 | loss: 0.16277302807995253 | accuracy: 0.941875 \n",
      "Epoch 23 | Step 9042 | loss: 0.16344900884326888 | accuracy: 0.9416725852272727 \n",
      "Epoch 23 | Step 9043 | loss: 0.16391591691953988 | accuracy: 0.9415607344632768 \n",
      "Epoch 23 | Step 9044 | loss: 0.1644320957404509 | accuracy: 0.9410990168539326 \n",
      "Epoch 23 | Step 9045 | loss: 0.1648970341840603 | accuracy: 0.9409043296089385 \n",
      "Epoch 23 | Step 9046 | loss: 0.16464072828077608 | accuracy: 0.9409722222222222 \n",
      "Epoch 23 | Step 9047 | loss: 0.16507639186405346 | accuracy: 0.9406940607734806 \n",
      "Epoch 23 | Step 9048 | loss: 0.16505586509439316 | accuracy: 0.940676510989011 \n",
      "Epoch 23 | Step 9049 | loss: 0.1647328947940485 | accuracy: 0.9408299180327869 \n",
      "Epoch 23 | Step 9050 | loss: 0.16418978841165485 | accuracy: 0.9411514945652174 \n",
      "Epoch 23 | Step 9051 | loss: 0.16397525049947403 | accuracy: 0.9412162162162162 \n",
      "Epoch 23 | Step 9052 | loss: 0.16434363870611113 | accuracy: 0.9409442204301075 \n",
      "Epoch 23 | Step 9053 | loss: 0.16470206550815525 | accuracy: 0.9406751336898396 \n",
      "Epoch 23 | Step 9054 | loss: 0.16480060652928782 | accuracy: 0.940658244680851 \n",
      "Epoch 23 | Step 9055 | loss: 0.16448522392640666 | accuracy: 0.9408068783068783 \n",
      "Epoch 23 | Step 9056 | loss: 0.16505866087973114 | accuracy: 0.940625 \n",
      "Epoch 23 | Step 9057 | loss: 0.1647012850259923 | accuracy: 0.940854057591623 \n",
      "Epoch 23 | Step 9058 | loss: 0.16453656191394353 | accuracy: 0.9407552083333334 \n",
      "Epoch 23 | Step 9059 | loss: 0.1642538633178244 | accuracy: 0.9409002590673575 \n",
      "Epoch 23 | Step 9060 | loss: 0.16406145574736228 | accuracy: 0.9409632731958762 \n",
      "Epoch 23 | Step 9061 | loss: 0.16363729091408927 | accuracy: 0.9411057692307693 \n",
      "Epoch 23 | Step 9062 | loss: 0.16384661074119564 | accuracy: 0.9409279336734694 \n",
      "Epoch 23 | Step 9063 | loss: 0.1637465933214892 | accuracy: 0.9410691624365483 \n",
      "Epoch 23 | Step 9064 | loss: 0.1639697222659985 | accuracy: 0.9410511363636364 \n",
      "Epoch 23 | Step 9065 | loss: 0.16387066535239841 | accuracy: 0.9411903266331658 \n",
      "Epoch 23 | Step 9066 | loss: 0.1638597418926656 | accuracy: 0.94109375 \n",
      "Epoch 23 | Step 9067 | loss: 0.16424439059783572 | accuracy: 0.9409203980099502 \n",
      "Epoch 23 | Step 9068 | loss: 0.164437731875494 | accuracy: 0.9409034653465347 \n",
      "Epoch 23 | Step 9069 | loss: 0.16453459306523718 | accuracy: 0.9408866995073891 \n",
      "Epoch 23 | Step 9070 | loss: 0.16430324244805994 | accuracy: 0.9410232843137255 \n",
      "Epoch 23 | Step 9071 | loss: 0.16475684789986145 | accuracy: 0.9407774390243903 \n",
      "Epoch 23 | Step 9072 | loss: 0.16569948574365342 | accuracy: 0.9403822815533981 \n",
      "Epoch 23 | Step 9073 | loss: 0.16670911239037192 | accuracy: 0.9404438405797102 \n",
      "Epoch 23 | Step 9074 | loss: 0.16694457565720838 | accuracy: 0.9402043269230769 \n",
      "Epoch 23 | Step 9075 | loss: 0.1667542840625966 | accuracy: 0.9402661483253588 \n",
      "Epoch 23 | Step 9076 | loss: 0.16655654270379316 | accuracy: 0.9404761904761905 \n",
      "Epoch 23 | Step 9077 | loss: 0.16665919698880746 | accuracy: 0.9404620853080569 \n",
      "Epoch 23 | Step 9078 | loss: 0.16613413693980789 | accuracy: 0.9407429245283019 \n",
      "Epoch 23 | Step 9079 | loss: 0.16576115075201495 | accuracy: 0.9409477699530516 \n",
      "Epoch 23 | Step 9080 | loss: 0.165780069619835 | accuracy: 0.9410046728971962 \n",
      "Epoch 23 | Step 9081 | loss: 0.16587812528014184 | accuracy: 0.9409156976744186 \n",
      "Epoch 23 | Step 9082 | loss: 0.1658291144951902 | accuracy: 0.9408998842592593 \n",
      "Epoch 23 | Step 9083 | loss: 0.16548217347209354 | accuracy: 0.9411002304147466 \n",
      "Epoch 23 | Step 9084 | loss: 0.16545429444709503 | accuracy: 0.9410837155963303 \n",
      "Epoch 23 | Step 9085 | loss: 0.16518288376192525 | accuracy: 0.9412100456621004 \n",
      "Epoch 23 | Step 9086 | loss: 0.1651265308430249 | accuracy: 0.9411221590909091 \n",
      "Epoch 23 | Step 9087 | loss: 0.16511260581569434 | accuracy: 0.9411057692307693 \n",
      "Epoch 23 | Step 9088 | loss: 0.16509029358155555 | accuracy: 0.941089527027027 \n",
      "Epoch 23 | Step 9089 | loss: 0.16523095612902813 | accuracy: 0.9409332959641256 \n",
      "Epoch 23 | Step 9090 | loss: 0.16474318273165928 | accuracy: 0.9411969866071429 \n",
      "Epoch 23 | Step 9091 | loss: 0.16491629026002355 | accuracy: 0.9411805555555556 \n",
      "Epoch 23 | Step 9092 | loss: 0.1649968617686392 | accuracy: 0.941233407079646 \n",
      "Epoch 23 | Step 9093 | loss: 0.16514934909566908 | accuracy: 0.941079295154185 \n",
      "Epoch 23 | Step 9094 | loss: 0.1653993765807204 | accuracy: 0.9410635964912281 \n",
      "Epoch 23 | Step 9095 | loss: 0.1652306898224562 | accuracy: 0.9411844978165939 \n",
      "Epoch 23 | Step 9096 | loss: 0.16507485206036465 | accuracy: 0.941304347826087 \n",
      "Epoch 23 | Step 9097 | loss: 0.1652336765193578 | accuracy: 0.9413555194805194 \n",
      "Epoch 23 | Step 9098 | loss: 0.1648309761497738 | accuracy: 0.9415409482758621 \n",
      "Epoch 23 | Step 9099 | loss: 0.16488856692746473 | accuracy: 0.9414565450643777 \n",
      "Epoch 23 | Step 9100 | loss: 0.1650293226329944 | accuracy: 0.9414396367521367 \n",
      "Epoch 23 | Step 9101 | loss: 0.16491294124342026 | accuracy: 0.9415558510638298 \n",
      "Epoch 23 | Step 9102 | loss: 0.16466434134201982 | accuracy: 0.9417372881355932 \n",
      "Epoch 23 | Step 9103 | loss: 0.16458903716774934 | accuracy: 0.9418512658227848 \n",
      "Epoch 23 | Step 9104 | loss: 0.16446475776992425 | accuracy: 0.9418986344537815 \n",
      "Epoch 23 | Step 9105 | loss: 0.1643409901551871 | accuracy: 0.941880230125523 \n",
      "Epoch 23 | Step 9106 | loss: 0.16444057547487317 | accuracy: 0.9418619791666667 \n",
      "Epoch 23 | Step 9107 | loss: 0.16409699651277412 | accuracy: 0.9419735477178424 \n",
      "Epoch 23 | Step 9108 | loss: 0.16399717350944507 | accuracy: 0.942084194214876 \n",
      "Epoch 23 | Step 9109 | loss: 0.16453234288734173 | accuracy: 0.9419367283950617 \n",
      "Epoch 23 | Step 9110 | loss: 0.1648517442317527 | accuracy: 0.9418545081967213 \n",
      "Epoch 23 | Step 9111 | loss: 0.16464080742123174 | accuracy: 0.9419005102040816 \n",
      "Epoch 23 | Step 9112 | loss: 0.16454881355469306 | accuracy: 0.9417555894308943 \n",
      "Epoch 23 | Step 9113 | loss: 0.1643421316164949 | accuracy: 0.9418648785425101 \n",
      "Epoch 23 | Step 9114 | loss: 0.16446199753291665 | accuracy: 0.9416582661290323 \n",
      "Epoch 23 | Step 9115 | loss: 0.16419946251205172 | accuracy: 0.9417670682730924 \n",
      "Epoch 23 | Step 9116 | loss: 0.16450988610088826 | accuracy: 0.94175 \n",
      "Epoch 23 | Step 9117 | loss: 0.1643873482378593 | accuracy: 0.9417953187250996 \n",
      "Epoch 23 | Step 9118 | loss: 0.16430555279588416 | accuracy: 0.9418402777777778 \n",
      "Epoch 23 | Step 9119 | loss: 0.16426761402737483 | accuracy: 0.9418231225296443 \n",
      "Epoch 23 | Step 9120 | loss: 0.1643927005361619 | accuracy: 0.9417445866141733 \n",
      "Epoch 23 | Step 9121 | loss: 0.16448299278523407 | accuracy: 0.9417279411764706 \n",
      "Epoch 23 | Step 9122 | loss: 0.16461940367298666 | accuracy: 0.94171142578125 \n",
      "Epoch 23 | Step 9123 | loss: 0.16445897245627433 | accuracy: 0.9418774319066148 \n",
      "Epoch 23 | Step 9124 | loss: 0.1642559213318335 | accuracy: 0.9419210271317829 \n",
      "Epoch 23 | Step 9125 | loss: 0.16440472143439713 | accuracy: 0.9418436293436293 \n",
      "Epoch 23 | Step 9126 | loss: 0.16416889685564318 | accuracy: 0.9419471153846154 \n",
      "Epoch 23 | Step 9127 | loss: 0.16447070736252484 | accuracy: 0.9416906130268199 \n",
      "Epoch 23 | Step 9128 | loss: 0.16444789696456363 | accuracy: 0.9416149809160306 \n",
      "Epoch 23 | Step 9129 | loss: 0.16420708626452052 | accuracy: 0.9416587452471483 \n",
      "Epoch 23 | Step 9130 | loss: 0.16467082208361136 | accuracy: 0.9415246212121212 \n",
      "Epoch 23 | Step 9131 | loss: 0.16444767574375527 | accuracy: 0.9415683962264151 \n",
      "Epoch 23 | Step 9132 | loss: 0.16440343113153946 | accuracy: 0.9414943609022557 \n",
      "Epoch 23 | Step 9133 | loss: 0.16433786699890196 | accuracy: 0.9414794007490637 \n",
      "Epoch 23 | Step 9134 | loss: 0.1640838689184678 | accuracy: 0.941581156716418 \n",
      "Epoch 23 | Step 9135 | loss: 0.16395629564348646 | accuracy: 0.9416240706319703 \n",
      "Epoch 23 | Step 9136 | loss: 0.16381132054936 | accuracy: 0.9415509259259259 \n",
      "Epoch 23 | Step 9137 | loss: 0.16373803330468514 | accuracy: 0.9414783210332104 \n",
      "Epoch 23 | Step 9138 | loss: 0.16370829270111725 | accuracy: 0.94140625 \n",
      "Epoch 23 | Step 9139 | loss: 0.1637873409295475 | accuracy: 0.941334706959707 \n",
      "Epoch 23 | Step 9140 | loss: 0.1637218022841389 | accuracy: 0.9413207116788321 \n",
      "Epoch 23 | Step 9141 | loss: 0.1636201460659504 | accuracy: 0.9413068181818182 \n",
      "Epoch 23 | Step 9142 | loss: 0.1638801632772969 | accuracy: 0.9411231884057971 \n",
      "Epoch 23 | Step 9143 | loss: 0.16400537243119642 | accuracy: 0.9410537003610109 \n",
      "Epoch 23 | Step 9144 | loss: 0.16398254099884904 | accuracy: 0.9410971223021583 \n",
      "Epoch 23 | Step 9145 | loss: 0.16395037189980557 | accuracy: 0.9411402329749103 \n",
      "Epoch 23 | Step 9146 | loss: 0.1638900220261088 | accuracy: 0.9411830357142857 \n",
      "Epoch 23 | Step 9147 | loss: 0.16432176640396434 | accuracy: 0.9409475088967971 \n",
      "Epoch 23 | Step 9148 | loss: 0.16421883367002002 | accuracy: 0.9409352836879432 \n",
      "Epoch 23 | Step 9149 | loss: 0.16411321748429802 | accuracy: 0.9410335689045937 \n",
      "Epoch 23 | Step 9150 | loss: 0.16404518436535556 | accuracy: 0.9409661091549296 \n",
      "Epoch 23 | Step 9151 | loss: 0.16385270604177518 | accuracy: 0.9411184210526315 \n",
      "Epoch 23 | Step 9152 | loss: 0.16387194182749804 | accuracy: 0.9409965034965035 \n",
      "Epoch 23 | Step 9153 | loss: 0.1637505973179788 | accuracy: 0.941038763066202 \n",
      "Epoch 23 | Step 9154 | loss: 0.16357079449678866 | accuracy: 0.9410807291666666 \n",
      "Epoch 23 | Step 9155 | loss: 0.16325380726617503 | accuracy: 0.9412305363321799 \n",
      "Epoch 23 | Step 9156 | loss: 0.16367015189908693 | accuracy: 0.9410560344827587 \n",
      "Epoch 23 | Step 9157 | loss: 0.16357567090912364 | accuracy: 0.9410975085910653 \n",
      "Epoch 23 | Step 9158 | loss: 0.16372792411289386 | accuracy: 0.9410316780821918 \n",
      "Epoch 23 | Step 9159 | loss: 0.16380390391364022 | accuracy: 0.9410196245733788 \n",
      "Epoch 23 | Step 9160 | loss: 0.16356296504081097 | accuracy: 0.9411139455782312 \n",
      "Epoch 23 | Step 9161 | loss: 0.163627329834942 | accuracy: 0.9409427966101694 \n",
      "Epoch 23 | Step 9162 | loss: 0.16360829439567945 | accuracy: 0.9408255912162162 \n",
      "Epoch 23 | Step 9163 | loss: 0.16382025921033677 | accuracy: 0.9406039562289562 \n",
      "Epoch 23 | Step 9164 | loss: 0.16374849174296685 | accuracy: 0.9405935402684564 \n",
      "Epoch 23 | Step 9165 | loss: 0.16366606433704534 | accuracy: 0.9405831939799331 \n",
      "Epoch 23 | Step 9166 | loss: 0.16349116733918576 | accuracy: 0.9406770833333333 \n",
      "Epoch 23 | Step 9167 | loss: 0.16338027574344716 | accuracy: 0.940718438538206 \n",
      "Epoch 23 | Step 9168 | loss: 0.16318743835073815 | accuracy: 0.9407595198675497 \n",
      "Epoch 23 | Step 9169 | loss: 0.1630004164778162 | accuracy: 0.9407487623762376 \n",
      "Epoch 23 | Step 9170 | loss: 0.1629424657746168 | accuracy: 0.940686677631579 \n",
      "Epoch 23 | Step 9171 | loss: 0.16323578483501408 | accuracy: 0.9405225409836065 \n",
      "Epoch 23 | Step 9172 | loss: 0.16310949612628 | accuracy: 0.9406147875816994 \n",
      "Epoch 23 | Step 9173 | loss: 0.16297792404259057 | accuracy: 0.9407064332247557 \n",
      "Epoch 23 | Step 9174 | loss: 0.16265066773570194 | accuracy: 0.9408482142857143 \n",
      "Epoch 23 | Step 9175 | loss: 0.16232922890232596 | accuracy: 0.9409890776699029 \n",
      "Epoch 23 | Step 9176 | loss: 0.16234264195926718 | accuracy: 0.9409778225806451 \n",
      "Epoch 23 | Step 9177 | loss: 0.16233954858933222 | accuracy: 0.9409666398713826 \n",
      "Epoch 23 | Step 9178 | loss: 0.16245939081104893 | accuracy: 0.9409054487179487 \n",
      "Epoch 23 | Step 9179 | loss: 0.16220444112349613 | accuracy: 0.9410443290734825 \n",
      "Epoch 23 | Step 9180 | loss: 0.1622569264879651 | accuracy: 0.9410330414012739 \n",
      "Epoch 23 | Step 9181 | loss: 0.16196845102877835 | accuracy: 0.9412202380952381 \n",
      "Epoch 23 | Step 9182 | loss: 0.16195914455795582 | accuracy: 0.9412579113924051 \n",
      "Epoch 23 | Step 9183 | loss: 0.16181168331520782 | accuracy: 0.9411967665615142 \n",
      "Epoch 23 | Step 9184 | loss: 0.1619865988035621 | accuracy: 0.9410868710691824 \n",
      "Epoch 23 | Step 9185 | loss: 0.16181749964956194 | accuracy: 0.9411246081504702 \n",
      "Epoch 23 | Step 9186 | loss: 0.16179775111377226 | accuracy: 0.9412109375 \n",
      "Epoch 23 | Step 9187 | loss: 0.1617477010250833 | accuracy: 0.9412480529595015 \n",
      "Epoch 23 | Step 9188 | loss: 0.16164704680627903 | accuracy: 0.9412849378881988 \n",
      "Epoch 23 | Step 9189 | loss: 0.16159073703982865 | accuracy: 0.9412732198142415 \n",
      "Epoch 23 | Step 9190 | loss: 0.16152506390655466 | accuracy: 0.941358024691358 \n",
      "Epoch 23 | Step 9191 | loss: 0.16145208170780753 | accuracy: 0.9413942307692308 \n",
      "Epoch 23 | Step 9192 | loss: 0.16146936802410625 | accuracy: 0.9413822852760736 \n",
      "Epoch 23 | Step 9193 | loss: 0.1615235322021197 | accuracy: 0.941322629969419 \n",
      "Epoch 23 | Step 9194 | loss: 0.1617383273636421 | accuracy: 0.9412157012195121 \n",
      "Epoch 23 | Step 9195 | loss: 0.16138674011935203 | accuracy: 0.9413943768996961 \n",
      "Epoch 23 | Step 9196 | loss: 0.16136122726355526 | accuracy: 0.9412878787878788 \n",
      "Epoch 23 | Step 9197 | loss: 0.1614091535101663 | accuracy: 0.9412292296072508 \n",
      "Epoch 23 | Step 9198 | loss: 0.16134715422494209 | accuracy: 0.9413121234939759 \n",
      "Epoch 23 | Step 9199 | loss: 0.16129857920356325 | accuracy: 0.9413945195195195 \n",
      "Epoch 23 | Step 9200 | loss: 0.16134331184634532 | accuracy: 0.9413360778443114 \n",
      "Epoch 23 | Step 9201 | loss: 0.16131453808786247 | accuracy: 0.9413246268656716 \n",
      "Epoch 23 | Step 9202 | loss: 0.1613971705969776 | accuracy: 0.9412202380952381 \n",
      "Epoch 23 | Step 9203 | loss: 0.16120241512751704 | accuracy: 0.941348293768546 \n",
      "Epoch 23 | Step 9204 | loss: 0.16113093950559737 | accuracy: 0.9412906804733728 \n",
      "Epoch 23 | Step 9205 | loss: 0.16093084386448225 | accuracy: 0.9413255899705014 \n",
      "Epoch 23 | Step 9206 | loss: 0.1609261480653109 | accuracy: 0.94140625 \n",
      "Epoch 23 | Step 9207 | loss: 0.16092345952069986 | accuracy: 0.9414406158357771 \n",
      "Epoch 23 | Step 9208 | loss: 0.16096512349159028 | accuracy: 0.9413834064327485 \n",
      "Epoch 23 | Step 9209 | loss: 0.16081706383442024 | accuracy: 0.9414631924198251 \n",
      "Epoch 23 | Step 9210 | loss: 0.16062670808588675 | accuracy: 0.9414970930232558 \n",
      "Epoch 23 | Step 9211 | loss: 0.1607101566657638 | accuracy: 0.9414402173913043 \n",
      "Epoch 23 | Step 9212 | loss: 0.16052772799194528 | accuracy: 0.9415191473988439 \n",
      "Epoch 23 | Step 9213 | loss: 0.16043113194599254 | accuracy: 0.9415976224783862 \n",
      "Epoch 23 | Step 9214 | loss: 0.16022513769352895 | accuracy: 0.9416756465517241 \n",
      "Epoch 23 | Step 9215 | loss: 0.16015992615702823 | accuracy: 0.941753223495702 \n",
      "Epoch 23 | Step 9216 | loss: 0.16016673744789173 | accuracy: 0.9416517857142858 \n",
      "Epoch 23 | Step 9217 | loss: 0.1599065295800013 | accuracy: 0.9417735042735043 \n",
      "Epoch 23 | Step 9218 | loss: 0.1598483591911974 | accuracy: 0.9418057528409091 \n",
      "Epoch 23 | Step 9219 | loss: 0.1597692249580245 | accuracy: 0.9417935552407932 \n",
      "Epoch 23 | Step 9220 | loss: 0.15987221310493954 | accuracy: 0.9417372881355932 \n",
      "Epoch 23 | Step 9221 | loss: 0.1598021253628628 | accuracy: 0.941681338028169 \n",
      "Epoch 23 | Step 9222 | loss: 0.1596831415120636 | accuracy: 0.9416695926966292 \n",
      "Epoch 23 | Step 9223 | loss: 0.1598783338583315 | accuracy: 0.9415703781512605 \n",
      "Epoch 23 | Step 9224 | loss: 0.160150634374615 | accuracy: 0.9414717178770949 \n",
      "Epoch 23 | Step 9225 | loss: 0.16013104324345778 | accuracy: 0.9414606545961003 \n",
      "Epoch 23 | Step 9226 | loss: 0.16020385050732205 | accuracy: 0.9414496527777778 \n",
      "Epoch 23 | Step 9227 | loss: 0.16010528605771834 | accuracy: 0.9415252770083102 \n",
      "Epoch 23 | Step 9228 | loss: 0.16016288341450075 | accuracy: 0.9414709944751382 \n",
      "Epoch 23 | Step 9229 | loss: 0.16004708266660506 | accuracy: 0.9415461432506887 \n",
      "Epoch 23 | Step 9230 | loss: 0.15974466701212142 | accuracy: 0.9417067307692307 \n",
      "Epoch 23 | Step 9231 | loss: 0.15953725433512886 | accuracy: 0.9418236301369863 \n",
      "Epoch 23 | Step 9232 | loss: 0.15953982686573015 | accuracy: 0.9418118169398907 \n",
      "Epoch 23 | Step 9233 | loss: 0.1596363443850819 | accuracy: 0.941800068119891 \n",
      "Epoch 23 | Step 9234 | loss: 0.15960531252557794 | accuracy: 0.9418733016304348 \n",
      "Epoch 23 | Step 9235 | loss: 0.15971605919887033 | accuracy: 0.9418614498644986 \n",
      "Epoch 23 | Step 9236 | loss: 0.15957034145658058 | accuracy: 0.9418496621621621 \n",
      "Epoch 23 | Step 9237 | loss: 0.15957714199537834 | accuracy: 0.9418379380053908 \n",
      "Epoch 23 | Step 9238 | loss: 0.1594503732217894 | accuracy: 0.9418682795698925 \n",
      "Epoch 23 | Step 9239 | loss: 0.15923108841634606 | accuracy: 0.9419822386058981 \n",
      "Epoch 23 | Step 9240 | loss: 0.1590359631507471 | accuracy: 0.9420120320855615 \n",
      "Epoch 23 | Step 9241 | loss: 0.15909064191579797 | accuracy: 0.9419583333333333 \n",
      "Epoch 23 | Step 9242 | loss: 0.1588706063265177 | accuracy: 0.9421126994680851 \n",
      "Epoch 23 | Step 9243 | loss: 0.15877227297433155 | accuracy: 0.9421004641909815 \n",
      "Epoch 23 | Step 9244 | loss: 0.1586035580901555 | accuracy: 0.9421709656084656 \n",
      "Epoch 23 | Step 9245 | loss: 0.15845709419895265 | accuracy: 0.9422410949868074 \n",
      "Epoch 23 | Step 9246 | loss: 0.15830580831358285 | accuracy: 0.9423519736842105 \n",
      "Epoch 23 | Step 9247 | loss: 0.1582123842530361 | accuracy: 0.9422572178477691 \n",
      "Epoch 23 | Step 9248 | loss: 0.1583030997380534 | accuracy: 0.942285667539267 \n",
      "Epoch 23 | Step 9249 | loss: 0.15839619136977112 | accuracy: 0.9422731723237598 \n",
      "Epoch 23 | Step 9250 | loss: 0.15869911496217032 | accuracy: 0.9423014322916666 \n",
      "Epoch 23 | Step 9251 | loss: 0.15853858994586106 | accuracy: 0.9424107142857143 \n",
      "Epoch 23 | Step 9252 | loss: 0.15838782720924022 | accuracy: 0.9424789507772021 \n",
      "Epoch 23 | Step 9253 | loss: 0.158231544479227 | accuracy: 0.942546834625323 \n",
      "Epoch 23 | Step 9254 | loss: 0.1584918575803027 | accuracy: 0.9425338273195877 \n",
      "Epoch 23 | Step 9255 | loss: 0.15834339365248182 | accuracy: 0.9426012210796915 \n",
      "Epoch 23 | Step 9256 | loss: 0.15832051317661217 | accuracy: 0.9426282051282051 \n",
      "Epoch 23 | Step 9257 | loss: 0.1583346218023152 | accuracy: 0.9426150895140665 \n",
      "Epoch 23 | Step 9258 | loss: 0.15831415267775234 | accuracy: 0.9426419005102041 \n",
      "Epoch 23 | Step 9259 | loss: 0.15831209514432262 | accuracy: 0.9425493002544529 \n",
      "Epoch 23 | Step 9260 | loss: 0.15825418454741447 | accuracy: 0.9425761421319797 \n",
      "Epoch 23 | Step 9261 | loss: 0.1580283383591264 | accuracy: 0.9426819620253165 \n",
      "Epoch 23 | Step 9262 | loss: 0.1577470479344929 | accuracy: 0.9427872474747475 \n",
      "Epoch 23 | Step 9263 | loss: 0.1578879248191336 | accuracy: 0.9428132871536524 \n",
      "Epoch 23 | Step 9264 | loss: 0.15786049536536972 | accuracy: 0.9428391959798995 \n",
      "Epoch 23 | Step 9265 | loss: 0.15763114522535684 | accuracy: 0.9429041353383458 \n",
      "Epoch 23 | Step 9266 | loss: 0.15754166002385303 | accuracy: 0.9429296875 \n",
      "Epoch 23 | Step 9267 | loss: 0.15760561633399878 | accuracy: 0.9429551122194514 \n",
      "Epoch 23 | Step 9268 | loss: 0.1577947527744727 | accuracy: 0.9429415422885572 \n",
      "Epoch 23 | Step 9269 | loss: 0.1575931576785466 | accuracy: 0.9429975613471 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5664632320404053 | accuracy: 0.796875 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.4642135202884674 | accuracy: 0.828125 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5357316335042318 | accuracy: 0.8229166666666666 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.522261880338192 | accuracy: 0.83203125 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.49031174182891846 | accuracy: 0.84375 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.531948983669281 | accuracy: 0.8307291666666666 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5249765855925423 | accuracy: 0.8325892857142857 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5172820128500462 | accuracy: 0.830078125 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5593569046921201 | accuracy: 0.8211805555555556 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5363644748926163 | accuracy: 0.8296875 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5421009253371846 | accuracy: 0.8295454545454546 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5291677042841911 | accuracy: 0.8346354166666666 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5467894283624796 | accuracy: 0.8317307692307693 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.530491903424263 | accuracy: 0.8359375 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5396435360113779 | accuracy: 0.8364583333333333 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5360130574554205 | accuracy: 0.8330078125 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5362466100384208 | accuracy: 0.8318014705882353 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5361042833990521 | accuracy: 0.8324652777777778 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5281714561738466 | accuracy: 0.8338815789473685 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.51638972312212 | accuracy: 0.83515625 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5094668169816335 | accuracy: 0.8363095238095238 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5025563930923288 | accuracy: 0.8366477272727273 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5116055283857428 | accuracy: 0.8355978260869565 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5368961902956167 | accuracy: 0.8313802083333334 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5499784719944 | accuracy: 0.829375 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5451762985724669 | accuracy: 0.8305288461538461 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5374746311593938 | accuracy: 0.8333333333333334 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5389805106180053 | accuracy: 0.8314732142857143 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5357797844656581 | accuracy: 0.8318965517241379 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5311848113934198 | accuracy: 0.8338541666666667 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5249340188118718 | accuracy: 0.8366935483870968 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5277600027620791 | accuracy: 0.83544921875 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5287702535137985 | accuracy: 0.8333333333333334 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.532350307001787 | accuracy: 0.8304227941176471 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5336690476962497 | accuracy: 0.8299107142857143 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5303640729851192 | accuracy: 0.8315972222222222 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5325203972893792 | accuracy: 0.8306587837837838 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5363593211299493 | accuracy: 0.8305921052631579 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5377783561364197 | accuracy: 0.8293269230769231 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5313188150525091 | accuracy: 0.830859375 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5268455104130069 | accuracy: 0.8307926829268293 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5202422890634762 | accuracy: 0.8322172619047619 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5210663548042607 | accuracy: 0.8317587209302325 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5225457965650341 | accuracy: 0.8323863636363636 \n",
      "Validation | Epoch 23 | Step 9269 | loss: 0.5229576677083968 | accuracy: 0.832246376408471 \n",
      "Epoch 24 | Step 9270 | loss: 0.2760393023490906 | accuracy: 0.90625 \n",
      "Epoch 24 | Step 9271 | loss: 0.17916548252105713 | accuracy: 0.9296875 \n",
      "Epoch 24 | Step 9272 | loss: 0.16019484400749207 | accuracy: 0.9427083333333334 \n",
      "Epoch 24 | Step 9273 | loss: 0.16443413123488426 | accuracy: 0.9375 \n",
      "Epoch 24 | Step 9274 | loss: 0.15043602138757706 | accuracy: 0.94375 \n",
      "Epoch 24 | Step 9275 | loss: 0.14409704630573592 | accuracy: 0.9479166666666666 \n",
      "Epoch 24 | Step 9276 | loss: 0.152953744999 | accuracy: 0.9441964285714286 \n",
      "Epoch 24 | Step 9277 | loss: 0.14977440889924765 | accuracy: 0.9453125 \n",
      "Epoch 24 | Step 9278 | loss: 0.15665320472584832 | accuracy: 0.9444444444444444 \n",
      "Epoch 24 | Step 9279 | loss: 0.16381978169083594 | accuracy: 0.94375 \n",
      "Epoch 24 | Step 9280 | loss: 0.15686666084961456 | accuracy: 0.9474431818181818 \n",
      "Epoch 24 | Step 9281 | loss: 0.1507345829159021 | accuracy: 0.94921875 \n",
      "Epoch 24 | Step 9282 | loss: 0.1621576587741191 | accuracy: 0.9435096153846154 \n",
      "Epoch 24 | Step 9283 | loss: 0.16236707940697667 | accuracy: 0.9441964285714286 \n",
      "Epoch 24 | Step 9284 | loss: 0.16441676268974936 | accuracy: 0.9416666666666667 \n",
      "Epoch 24 | Step 9285 | loss: 0.1578661426901817 | accuracy: 0.943359375 \n",
      "Epoch 24 | Step 9286 | loss: 0.15528561832273705 | accuracy: 0.9448529411764706 \n",
      "Epoch 24 | Step 9287 | loss: 0.15262703473369277 | accuracy: 0.9444444444444444 \n",
      "Epoch 24 | Step 9288 | loss: 0.1542495830278647 | accuracy: 0.944078947368421 \n",
      "Epoch 24 | Step 9289 | loss: 0.1576358679682016 | accuracy: 0.94453125 \n",
      "Epoch 24 | Step 9290 | loss: 0.15800219171103974 | accuracy: 0.9441964285714286 \n",
      "Epoch 24 | Step 9291 | loss: 0.1603770882568576 | accuracy: 0.9446022727272727 \n",
      "Epoch 24 | Step 9292 | loss: 0.15700983061738635 | accuracy: 0.9456521739130435 \n",
      "Epoch 24 | Step 9293 | loss: 0.15624600804100433 | accuracy: 0.9453125 \n",
      "Epoch 24 | Step 9294 | loss: 0.15820221871137619 | accuracy: 0.944375 \n",
      "Epoch 24 | Step 9295 | loss: 0.15807987090486747 | accuracy: 0.9435096153846154 \n",
      "Epoch 24 | Step 9296 | loss: 0.1648947157793575 | accuracy: 0.9415509259259259 \n",
      "Epoch 24 | Step 9297 | loss: 0.16155885319624627 | accuracy: 0.9430803571428571 \n",
      "Epoch 24 | Step 9298 | loss: 0.16469900207272892 | accuracy: 0.9407327586206896 \n",
      "Epoch 24 | Step 9299 | loss: 0.1652774731318156 | accuracy: 0.9395833333333333 \n",
      "Epoch 24 | Step 9300 | loss: 0.1652347517590369 | accuracy: 0.9380040322580645 \n",
      "Epoch 24 | Step 9301 | loss: 0.16566606471315026 | accuracy: 0.9375 \n",
      "Epoch 24 | Step 9302 | loss: 0.16503167829730295 | accuracy: 0.9375 \n",
      "Epoch 24 | Step 9303 | loss: 0.16157191345358596 | accuracy: 0.9393382352941176 \n",
      "Epoch 24 | Step 9304 | loss: 0.15965306322489467 | accuracy: 0.9401785714285714 \n",
      "Epoch 24 | Step 9305 | loss: 0.15771376869330803 | accuracy: 0.9405381944444444 \n",
      "Epoch 24 | Step 9306 | loss: 0.15794026801312291 | accuracy: 0.9400337837837838 \n",
      "Epoch 24 | Step 9307 | loss: 0.15666342458050503 | accuracy: 0.9412006578947368 \n",
      "Epoch 24 | Step 9308 | loss: 0.15472332913524064 | accuracy: 0.9419070512820513 \n",
      "Epoch 24 | Step 9309 | loss: 0.15277183121070265 | accuracy: 0.94296875 \n",
      "Epoch 24 | Step 9310 | loss: 0.15109751818747055 | accuracy: 0.9432164634146342 \n",
      "Epoch 24 | Step 9311 | loss: 0.15041340257795083 | accuracy: 0.9438244047619048 \n",
      "Epoch 24 | Step 9312 | loss: 0.14994943635754804 | accuracy: 0.9436773255813954 \n",
      "Epoch 24 | Step 9313 | loss: 0.14975029204718088 | accuracy: 0.9442471590909091 \n",
      "Epoch 24 | Step 9314 | loss: 0.15150972646143698 | accuracy: 0.9444444444444444 \n",
      "Epoch 24 | Step 9315 | loss: 0.15216749234367968 | accuracy: 0.9442934782608695 \n",
      "Epoch 24 | Step 9316 | loss: 0.1513201772691087 | accuracy: 0.9444813829787234 \n",
      "Epoch 24 | Step 9317 | loss: 0.1515308619321634 | accuracy: 0.9446614583333334 \n",
      "Epoch 24 | Step 9318 | loss: 0.15330764993417015 | accuracy: 0.9441964285714286 \n",
      "Epoch 24 | Step 9319 | loss: 0.1531848860532045 | accuracy: 0.94375 \n",
      "Epoch 24 | Step 9320 | loss: 0.15318436518895853 | accuracy: 0.9433210784313726 \n",
      "Epoch 24 | Step 9321 | loss: 0.15149719375543863 | accuracy: 0.9438100961538461 \n",
      "Epoch 24 | Step 9322 | loss: 0.15181820593633735 | accuracy: 0.9436910377358491 \n",
      "Epoch 24 | Step 9323 | loss: 0.1506336140273897 | accuracy: 0.9441550925925926 \n",
      "Epoch 24 | Step 9324 | loss: 0.15205990204756903 | accuracy: 0.9434659090909091 \n",
      "Epoch 24 | Step 9325 | loss: 0.15123046715078603 | accuracy: 0.9441964285714286 \n",
      "Epoch 24 | Step 9326 | loss: 0.15233443984598438 | accuracy: 0.9443530701754386 \n",
      "Epoch 24 | Step 9327 | loss: 0.15307509995483112 | accuracy: 0.9439655172413793 \n",
      "Epoch 24 | Step 9328 | loss: 0.15351509309168584 | accuracy: 0.9438559322033898 \n",
      "Epoch 24 | Step 9329 | loss: 0.15520008870710925 | accuracy: 0.94375 \n",
      "Epoch 24 | Step 9330 | loss: 0.15460727821852335 | accuracy: 0.9439036885245902 \n",
      "Epoch 24 | Step 9331 | loss: 0.1545810142471905 | accuracy: 0.9440524193548387 \n",
      "Epoch 24 | Step 9332 | loss: 0.1560606214380453 | accuracy: 0.9434523809523809 \n",
      "Epoch 24 | Step 9333 | loss: 0.15462553995894263 | accuracy: 0.94384765625 \n",
      "Epoch 24 | Step 9334 | loss: 0.15332458151074552 | accuracy: 0.9444711538461539 \n",
      "Epoch 24 | Step 9335 | loss: 0.1519397150612238 | accuracy: 0.9450757575757576 \n",
      "Epoch 24 | Step 9336 | loss: 0.1511133798022768 | accuracy: 0.945195895522388 \n",
      "Epoch 24 | Step 9337 | loss: 0.15160943699233667 | accuracy: 0.9448529411764706 \n",
      "Epoch 24 | Step 9338 | loss: 0.15151827253293296 | accuracy: 0.9445199275362319 \n",
      "Epoch 24 | Step 9339 | loss: 0.1513936477048056 | accuracy: 0.9439732142857142 \n",
      "Epoch 24 | Step 9340 | loss: 0.1501219239558132 | accuracy: 0.9445422535211268 \n",
      "Epoch 24 | Step 9341 | loss: 0.14999733415121827 | accuracy: 0.9448784722222222 \n",
      "Epoch 24 | Step 9342 | loss: 0.15000741025560516 | accuracy: 0.944777397260274 \n",
      "Epoch 24 | Step 9343 | loss: 0.15012912034384296 | accuracy: 0.9448902027027027 \n",
      "Epoch 24 | Step 9344 | loss: 0.14999818051854763 | accuracy: 0.945 \n",
      "Epoch 24 | Step 9345 | loss: 0.15047869208808 | accuracy: 0.9449013157894737 \n",
      "Epoch 24 | Step 9346 | loss: 0.150629864352477 | accuracy: 0.9448051948051948 \n",
      "Epoch 24 | Step 9347 | loss: 0.15100541868462006 | accuracy: 0.9447115384615384 \n",
      "Epoch 24 | Step 9348 | loss: 0.1537202887614316 | accuracy: 0.9440268987341772 \n",
      "Epoch 24 | Step 9349 | loss: 0.1531542254146188 | accuracy: 0.9443359375 \n",
      "Epoch 24 | Step 9350 | loss: 0.15249335568076292 | accuracy: 0.9444444444444444 \n",
      "Epoch 24 | Step 9351 | loss: 0.1517395277666609 | accuracy: 0.9447408536585366 \n",
      "Epoch 24 | Step 9352 | loss: 0.15158341237040882 | accuracy: 0.9448418674698795 \n",
      "Epoch 24 | Step 9353 | loss: 0.1509242930139104 | accuracy: 0.9447544642857143 \n",
      "Epoch 24 | Step 9354 | loss: 0.15029076193185406 | accuracy: 0.9450367647058824 \n",
      "Epoch 24 | Step 9355 | loss: 0.1496951024286275 | accuracy: 0.9453125 \n",
      "Epoch 24 | Step 9356 | loss: 0.1521153996816311 | accuracy: 0.9445043103448276 \n",
      "Epoch 24 | Step 9357 | loss: 0.1526968931694599 | accuracy: 0.9446022727272727 \n",
      "Epoch 24 | Step 9358 | loss: 0.15231669874171186 | accuracy: 0.9445224719101124 \n",
      "Epoch 24 | Step 9359 | loss: 0.15217587057914994 | accuracy: 0.9444444444444444 \n",
      "Epoch 24 | Step 9360 | loss: 0.15148229196995167 | accuracy: 0.9447115384615384 \n",
      "Epoch 24 | Step 9361 | loss: 0.1507887845534993 | accuracy: 0.9448029891304348 \n",
      "Epoch 24 | Step 9362 | loss: 0.1504821200124038 | accuracy: 0.9447244623655914 \n",
      "Epoch 24 | Step 9363 | loss: 0.14983892603281962 | accuracy: 0.944813829787234 \n",
      "Epoch 24 | Step 9364 | loss: 0.15005430787017468 | accuracy: 0.9445723684210526 \n",
      "Epoch 24 | Step 9365 | loss: 0.15172462991904465 | accuracy: 0.9444986979166666 \n",
      "Epoch 24 | Step 9366 | loss: 0.15114437546773052 | accuracy: 0.9447487113402062 \n",
      "Epoch 24 | Step 9367 | loss: 0.1521609026786624 | accuracy: 0.9443558673469388 \n",
      "Epoch 24 | Step 9368 | loss: 0.15260019473204708 | accuracy: 0.9444444444444444 \n",
      "Epoch 24 | Step 9369 | loss: 0.1519952605292201 | accuracy: 0.9446875 \n",
      "Epoch 24 | Step 9370 | loss: 0.15125828557232818 | accuracy: 0.9450804455445545 \n",
      "Epoch 24 | Step 9371 | loss: 0.15114624904212998 | accuracy: 0.9451593137254902 \n",
      "Epoch 24 | Step 9372 | loss: 0.15031639692708126 | accuracy: 0.9453883495145631 \n",
      "Epoch 24 | Step 9373 | loss: 0.15065558193824613 | accuracy: 0.9453125 \n",
      "Epoch 24 | Step 9374 | loss: 0.15166550927928515 | accuracy: 0.9452380952380952 \n",
      "Epoch 24 | Step 9375 | loss: 0.1508341551459623 | accuracy: 0.9457547169811321 \n",
      "Epoch 24 | Step 9376 | loss: 0.15136397988578984 | accuracy: 0.945677570093458 \n",
      "Epoch 24 | Step 9377 | loss: 0.15202710946538933 | accuracy: 0.9454571759259259 \n",
      "Epoch 24 | Step 9378 | loss: 0.1522320224946245 | accuracy: 0.9455275229357798 \n",
      "Epoch 24 | Step 9379 | loss: 0.15284198864617132 | accuracy: 0.9450284090909091 \n",
      "Epoch 24 | Step 9380 | loss: 0.15286814001900656 | accuracy: 0.9451013513513513 \n",
      "Epoch 24 | Step 9381 | loss: 0.15292419004254043 | accuracy: 0.9451729910714286 \n",
      "Epoch 24 | Step 9382 | loss: 0.15361290843745248 | accuracy: 0.9449668141592921 \n",
      "Epoch 24 | Step 9383 | loss: 0.15341727138219172 | accuracy: 0.9451754385964912 \n",
      "Epoch 24 | Step 9384 | loss: 0.15302752745540246 | accuracy: 0.9453804347826087 \n",
      "Epoch 24 | Step 9385 | loss: 0.15277889913654533 | accuracy: 0.9453125 \n",
      "Epoch 24 | Step 9386 | loss: 0.1535561027753557 | accuracy: 0.9447115384615384 \n",
      "Epoch 24 | Step 9387 | loss: 0.15330876381594247 | accuracy: 0.9447828389830508 \n",
      "Epoch 24 | Step 9388 | loss: 0.15350778998822726 | accuracy: 0.9448529411764706 \n",
      "Epoch 24 | Step 9389 | loss: 0.15314557033901413 | accuracy: 0.9450520833333333 \n",
      "Epoch 24 | Step 9390 | loss: 0.1533063101189688 | accuracy: 0.9449896694214877 \n",
      "Epoch 24 | Step 9391 | loss: 0.15357363947712985 | accuracy: 0.9448002049180327 \n",
      "Epoch 24 | Step 9392 | loss: 0.15330875922388176 | accuracy: 0.9448678861788617 \n",
      "Epoch 24 | Step 9393 | loss: 0.15304164885873756 | accuracy: 0.9449344758064516 \n",
      "Epoch 24 | Step 9394 | loss: 0.15257150277495385 | accuracy: 0.945125 \n",
      "Epoch 24 | Step 9395 | loss: 0.15275555148365952 | accuracy: 0.9449404761904762 \n",
      "Epoch 24 | Step 9396 | loss: 0.15359392113924966 | accuracy: 0.9446358267716536 \n",
      "Epoch 24 | Step 9397 | loss: 0.15332681438303553 | accuracy: 0.9444580078125 \n",
      "Epoch 24 | Step 9398 | loss: 0.15298130926351214 | accuracy: 0.9444040697674418 \n",
      "Epoch 24 | Step 9399 | loss: 0.15273562643963556 | accuracy: 0.9443509615384615 \n",
      "Epoch 24 | Step 9400 | loss: 0.1534283080116938 | accuracy: 0.9441793893129771 \n",
      "Epoch 24 | Step 9401 | loss: 0.15474757921853752 | accuracy: 0.9438920454545454 \n",
      "Epoch 24 | Step 9402 | loss: 0.15537136767927864 | accuracy: 0.9437265037593985 \n",
      "Epoch 24 | Step 9403 | loss: 0.15547452007990276 | accuracy: 0.9437966417910447 \n",
      "Epoch 24 | Step 9404 | loss: 0.15571455334623654 | accuracy: 0.9437499999999999 \n",
      "Epoch 24 | Step 9405 | loss: 0.15554006964735248 | accuracy: 0.9437040441176471 \n",
      "Epoch 24 | Step 9406 | loss: 0.1552175118377174 | accuracy: 0.9440009124087592 \n",
      "Epoch 24 | Step 9407 | loss: 0.15539218272096006 | accuracy: 0.9438405797101449 \n",
      "Epoch 24 | Step 9408 | loss: 0.15572909659726156 | accuracy: 0.9439073741007195 \n",
      "Epoch 24 | Step 9409 | loss: 0.15605382293994938 | accuracy: 0.9439732142857142 \n",
      "Epoch 24 | Step 9410 | loss: 0.1571865550222549 | accuracy: 0.9434840425531915 \n",
      "Epoch 24 | Step 9411 | loss: 0.1574803536469248 | accuracy: 0.9435519366197183 \n",
      "Epoch 24 | Step 9412 | loss: 0.15770594194739848 | accuracy: 0.943291083916084 \n",
      "Epoch 24 | Step 9413 | loss: 0.1572351080313739 | accuracy: 0.9434678819444444 \n",
      "Epoch 24 | Step 9414 | loss: 0.15703887325422516 | accuracy: 0.9436422413793103 \n",
      "Epoch 24 | Step 9415 | loss: 0.15709311721769914 | accuracy: 0.9434931506849316 \n",
      "Epoch 24 | Step 9416 | loss: 0.15644185414829223 | accuracy: 0.9437712585034014 \n",
      "Epoch 24 | Step 9417 | loss: 0.15644806188002633 | accuracy: 0.9439400337837838 \n",
      "Epoch 24 | Step 9418 | loss: 0.15604470782732005 | accuracy: 0.9442114093959731 \n",
      "Epoch 24 | Step 9419 | loss: 0.15665845019121968 | accuracy: 0.9441666666666667 \n",
      "Epoch 24 | Step 9420 | loss: 0.15701540034042294 | accuracy: 0.9440190397350994 \n",
      "Epoch 24 | Step 9421 | loss: 0.15826273859037385 | accuracy: 0.9436677631578947 \n",
      "Epoch 24 | Step 9422 | loss: 0.1587035867562092 | accuracy: 0.9434232026143791 \n",
      "Epoch 24 | Step 9423 | loss: 0.15818029804179426 | accuracy: 0.9436891233766234 \n",
      "Epoch 24 | Step 9424 | loss: 0.15797350634970977 | accuracy: 0.943649193548387 \n",
      "Epoch 24 | Step 9425 | loss: 0.15750979672735324 | accuracy: 0.9438100961538461 \n",
      "Epoch 24 | Step 9426 | loss: 0.15704296042869811 | accuracy: 0.9440684713375797 \n",
      "Epoch 24 | Step 9427 | loss: 0.15694037445266798 | accuracy: 0.9442246835443038 \n",
      "Epoch 24 | Step 9428 | loss: 0.15683761864619444 | accuracy: 0.9439858490566038 \n",
      "Epoch 24 | Step 9429 | loss: 0.15699515573214748 | accuracy: 0.94365234375 \n",
      "Epoch 24 | Step 9430 | loss: 0.1572413792289933 | accuracy: 0.9436141304347826 \n",
      "Epoch 24 | Step 9431 | loss: 0.15673218761789218 | accuracy: 0.9438657407407407 \n",
      "Epoch 24 | Step 9432 | loss: 0.15813482047681435 | accuracy: 0.9432515337423313 \n",
      "Epoch 24 | Step 9433 | loss: 0.158254247544924 | accuracy: 0.9430259146341463 \n",
      "Epoch 24 | Step 9434 | loss: 0.15820188958084952 | accuracy: 0.9429924242424242 \n",
      "Epoch 24 | Step 9435 | loss: 0.15829315577375608 | accuracy: 0.9428652108433735 \n",
      "Epoch 24 | Step 9436 | loss: 0.15787231888688974 | accuracy: 0.9430202095808383 \n",
      "Epoch 24 | Step 9437 | loss: 0.15829179012438377 | accuracy: 0.9427083333333334 \n",
      "Epoch 24 | Step 9438 | loss: 0.15802554166793123 | accuracy: 0.9427699704142012 \n",
      "Epoch 24 | Step 9439 | loss: 0.15744575231390845 | accuracy: 0.9431066176470588 \n",
      "Epoch 24 | Step 9440 | loss: 0.15758815368539414 | accuracy: 0.9429824561403509 \n",
      "Epoch 24 | Step 9441 | loss: 0.15791815445693433 | accuracy: 0.942859738372093 \n",
      "Epoch 24 | Step 9442 | loss: 0.15755163034090422 | accuracy: 0.9430093930635838 \n",
      "Epoch 24 | Step 9443 | loss: 0.15768877823633715 | accuracy: 0.9430675287356322 \n",
      "Epoch 24 | Step 9444 | loss: 0.15763708374329982 | accuracy: 0.9430357142857143 \n",
      "Epoch 24 | Step 9445 | loss: 0.15851396207951693 | accuracy: 0.9427379261363636 \n",
      "Epoch 24 | Step 9446 | loss: 0.158857049620421 | accuracy: 0.9427966101694916 \n",
      "Epoch 24 | Step 9447 | loss: 0.15930349032363203 | accuracy: 0.9423279494382022 \n",
      "Epoch 24 | Step 9448 | loss: 0.15982598128764997 | accuracy: 0.9420391061452514 \n",
      "Epoch 24 | Step 9449 | loss: 0.1595835338450141 | accuracy: 0.9421006944444444 \n",
      "Epoch 24 | Step 9450 | loss: 0.15977501379356868 | accuracy: 0.9419026243093923 \n",
      "Epoch 24 | Step 9451 | loss: 0.15973103091448226 | accuracy: 0.9418784340659341 \n",
      "Epoch 24 | Step 9452 | loss: 0.15932788659151795 | accuracy: 0.9420252732240437 \n",
      "Epoch 24 | Step 9453 | loss: 0.15879787458106884 | accuracy: 0.9422554347826086 \n",
      "Epoch 24 | Step 9454 | loss: 0.1584659065547828 | accuracy: 0.9423986486486486 \n",
      "Epoch 24 | Step 9455 | loss: 0.1587796481826934 | accuracy: 0.9422043010752689 \n",
      "Epoch 24 | Step 9456 | loss: 0.15915566266459583 | accuracy: 0.9420955882352942 \n",
      "Epoch 24 | Step 9457 | loss: 0.15907678061581043 | accuracy: 0.9420711436170213 \n",
      "Epoch 24 | Step 9458 | loss: 0.15884778157822674 | accuracy: 0.9422123015873016 \n",
      "Epoch 24 | Step 9459 | loss: 0.1594455857222018 | accuracy: 0.9420230263157895 \n",
      "Epoch 24 | Step 9460 | loss: 0.1590239261886525 | accuracy: 0.9422447643979057 \n",
      "Epoch 24 | Step 9461 | loss: 0.15887443921140712 | accuracy: 0.9422200520833334 \n",
      "Epoch 24 | Step 9462 | loss: 0.15848615960522028 | accuracy: 0.9424384715025906 \n",
      "Epoch 24 | Step 9463 | loss: 0.15822177674122087 | accuracy: 0.942493556701031 \n",
      "Epoch 24 | Step 9464 | loss: 0.15786268514318352 | accuracy: 0.9426282051282051 \n",
      "Epoch 24 | Step 9465 | loss: 0.15810041542031944 | accuracy: 0.9426020408163265 \n",
      "Epoch 24 | Step 9466 | loss: 0.1582298952953768 | accuracy: 0.9425761421319797 \n",
      "Epoch 24 | Step 9467 | loss: 0.15843073634261443 | accuracy: 0.9427083333333334 \n",
      "Epoch 24 | Step 9468 | loss: 0.15840758085625262 | accuracy: 0.9428391959798995 \n",
      "Epoch 24 | Step 9469 | loss: 0.15848050983622675 | accuracy: 0.94265625 \n",
      "Epoch 24 | Step 9470 | loss: 0.15888329282106456 | accuracy: 0.9425528606965174 \n",
      "Epoch 24 | Step 9471 | loss: 0.15911392522699175 | accuracy: 0.942450495049505 \n",
      "Epoch 24 | Step 9472 | loss: 0.15902470435782023 | accuracy: 0.942503078817734 \n",
      "Epoch 24 | Step 9473 | loss: 0.15905982192021378 | accuracy: 0.9424019607843137 \n",
      "Epoch 24 | Step 9474 | loss: 0.1595325907010858 | accuracy: 0.9422256097560976 \n",
      "Epoch 24 | Step 9475 | loss: 0.1604280594229988 | accuracy: 0.9418234223300971 \n",
      "Epoch 24 | Step 9476 | loss: 0.16128543805744916 | accuracy: 0.9418780193236715 \n",
      "Epoch 24 | Step 9477 | loss: 0.16151144808659762 | accuracy: 0.9417818509615384 \n",
      "Epoch 24 | Step 9478 | loss: 0.16141451975446572 | accuracy: 0.9418361244019139 \n",
      "Epoch 24 | Step 9479 | loss: 0.1612632638109582 | accuracy: 0.9418898809523809 \n",
      "Epoch 24 | Step 9480 | loss: 0.16144982864859547 | accuracy: 0.9417950236966824 \n",
      "Epoch 24 | Step 9481 | loss: 0.16089563925732986 | accuracy: 0.9420695754716981 \n",
      "Epoch 24 | Step 9482 | loss: 0.16049173463818056 | accuracy: 0.9422681924882629 \n",
      "Epoch 24 | Step 9483 | loss: 0.1605502448836777 | accuracy: 0.9423189252336449 \n",
      "Epoch 24 | Step 9484 | loss: 0.16057665185179826 | accuracy: 0.942296511627907 \n",
      "Epoch 24 | Step 9485 | loss: 0.16059838604457954 | accuracy: 0.9422019675925926 \n",
      "Epoch 24 | Step 9486 | loss: 0.16035861010375663 | accuracy: 0.9421802995391705 \n",
      "Epoch 24 | Step 9487 | loss: 0.160164600973009 | accuracy: 0.9423021788990825 \n",
      "Epoch 24 | Step 9488 | loss: 0.16000351350601408 | accuracy: 0.9422802511415526 \n",
      "Epoch 24 | Step 9489 | loss: 0.1600056954405525 | accuracy: 0.9421164772727273 \n",
      "Epoch 24 | Step 9490 | loss: 0.16012751611109777 | accuracy: 0.942024886877828 \n",
      "Epoch 24 | Step 9491 | loss: 0.15999728105626668 | accuracy: 0.9421452702702703 \n",
      "Epoch 24 | Step 9492 | loss: 0.16000054950404063 | accuracy: 0.9421945067264574 \n",
      "Epoch 24 | Step 9493 | loss: 0.15956517470268802 | accuracy: 0.9423828125 \n",
      "Epoch 24 | Step 9494 | loss: 0.15989153770936862 | accuracy: 0.9422222222222222 \n",
      "Epoch 24 | Step 9495 | loss: 0.16005924576481362 | accuracy: 0.9420630530973452 \n",
      "Epoch 24 | Step 9496 | loss: 0.16016425692890712 | accuracy: 0.9419741189427313 \n",
      "Epoch 24 | Step 9497 | loss: 0.16036593105251856 | accuracy: 0.9420230263157895 \n",
      "Epoch 24 | Step 9498 | loss: 0.1601138919364157 | accuracy: 0.9421397379912664 \n",
      "Epoch 24 | Step 9499 | loss: 0.15986211495878908 | accuracy: 0.9423233695652173 \n",
      "Epoch 24 | Step 9500 | loss: 0.15970079466958587 | accuracy: 0.9424377705627706 \n",
      "Epoch 24 | Step 9501 | loss: 0.15932267437014602 | accuracy: 0.9425511853448276 \n",
      "Epoch 24 | Step 9502 | loss: 0.1592838102432024 | accuracy: 0.9425965665236051 \n",
      "Epoch 24 | Step 9503 | loss: 0.15952477860463485 | accuracy: 0.9425080128205128 \n",
      "Epoch 24 | Step 9504 | loss: 0.15951360953932117 | accuracy: 0.9424867021276596 \n",
      "Epoch 24 | Step 9505 | loss: 0.15939725697103702 | accuracy: 0.9425979872881356 \n",
      "Epoch 24 | Step 9506 | loss: 0.15937927329150436 | accuracy: 0.9426424050632911 \n",
      "Epoch 24 | Step 9507 | loss: 0.15931241560195178 | accuracy: 0.9425551470588235 \n",
      "Epoch 24 | Step 9508 | loss: 0.15923388540807132 | accuracy: 0.9425339958158996 \n",
      "Epoch 24 | Step 9509 | loss: 0.15917361380221945 | accuracy: 0.9425130208333333 \n",
      "Epoch 24 | Step 9510 | loss: 0.15882876306710406 | accuracy: 0.942621887966805 \n",
      "Epoch 24 | Step 9511 | loss: 0.15876400527690562 | accuracy: 0.9427298553719008 \n",
      "Epoch 24 | Step 9512 | loss: 0.15919460271918237 | accuracy: 0.9426440329218106 \n",
      "Epoch 24 | Step 9513 | loss: 0.15968953324939875 | accuracy: 0.9424308401639344 \n",
      "Epoch 24 | Step 9514 | loss: 0.15944044892581144 | accuracy: 0.9424744897959184 \n",
      "Epoch 24 | Step 9515 | loss: 0.15942332934497336 | accuracy: 0.9423907520325203 \n",
      "Epoch 24 | Step 9516 | loss: 0.15910588444666826 | accuracy: 0.9424974696356275 \n",
      "Epoch 24 | Step 9517 | loss: 0.15925675731212385 | accuracy: 0.9425403225806451 \n",
      "Epoch 24 | Step 9518 | loss: 0.15901345360171368 | accuracy: 0.9427083333333334 \n",
      "Epoch 24 | Step 9519 | loss: 0.15917159406840803 | accuracy: 0.94275 \n",
      "Epoch 24 | Step 9520 | loss: 0.15894443771813024 | accuracy: 0.9428535856573705 \n",
      "Epoch 24 | Step 9521 | loss: 0.1588775052112483 | accuracy: 0.9428323412698413 \n",
      "Epoch 24 | Step 9522 | loss: 0.15879718854787794 | accuracy: 0.9428112648221344 \n",
      "Epoch 24 | Step 9523 | loss: 0.15888725451421085 | accuracy: 0.9427903543307087 \n",
      "Epoch 24 | Step 9524 | loss: 0.15902108808650692 | accuracy: 0.9427696078431372 \n",
      "Epoch 24 | Step 9525 | loss: 0.15925022588635332 | accuracy: 0.94268798828125 \n",
      "Epoch 24 | Step 9526 | loss: 0.15898635984916634 | accuracy: 0.9427893968871596 \n",
      "Epoch 24 | Step 9527 | loss: 0.158763470705743 | accuracy: 0.9428294573643411 \n",
      "Epoch 24 | Step 9528 | loss: 0.15883013118475564 | accuracy: 0.9428088803088803 \n",
      "Epoch 24 | Step 9529 | loss: 0.1586119660821099 | accuracy: 0.9428485576923077 \n",
      "Epoch 24 | Step 9530 | loss: 0.15902933317068896 | accuracy: 0.9425287356321839 \n",
      "Epoch 24 | Step 9531 | loss: 0.1590344415451507 | accuracy: 0.9423902671755725 \n",
      "Epoch 24 | Step 9532 | loss: 0.158888297261734 | accuracy: 0.9423716730038023 \n",
      "Epoch 24 | Step 9533 | loss: 0.15917031177686475 | accuracy: 0.9422940340909091 \n",
      "Epoch 24 | Step 9534 | loss: 0.15887749843158813 | accuracy: 0.9423938679245283 \n",
      "Epoch 24 | Step 9535 | loss: 0.1587652420779144 | accuracy: 0.9424342105263158 \n",
      "Epoch 24 | Step 9536 | loss: 0.15859741917096273 | accuracy: 0.9425327715355806 \n",
      "Epoch 24 | Step 9537 | loss: 0.1583040518296966 | accuracy: 0.9426888992537313 \n",
      "Epoch 24 | Step 9538 | loss: 0.15824423928409262 | accuracy: 0.9427276951672863 \n",
      "Epoch 24 | Step 9539 | loss: 0.15808064922414444 | accuracy: 0.9427662037037037 \n",
      "Epoch 24 | Step 9540 | loss: 0.15798677488941548 | accuracy: 0.9428044280442804 \n",
      "Epoch 24 | Step 9541 | loss: 0.15789975008160315 | accuracy: 0.9428423713235294 \n",
      "Epoch 24 | Step 9542 | loss: 0.15793509406102446 | accuracy: 0.9428228021978022 \n",
      "Epoch 24 | Step 9543 | loss: 0.158008240503225 | accuracy: 0.9427463503649635 \n",
      "Epoch 24 | Step 9544 | loss: 0.1578965900838375 | accuracy: 0.9427840909090909 \n",
      "Epoch 24 | Step 9545 | loss: 0.15820661064345334 | accuracy: 0.9426517210144928 \n",
      "Epoch 24 | Step 9546 | loss: 0.15818919205116883 | accuracy: 0.942576714801444 \n",
      "Epoch 24 | Step 9547 | loss: 0.15815034268839326 | accuracy: 0.94255845323741 \n",
      "Epoch 24 | Step 9548 | loss: 0.15802078730156344 | accuracy: 0.9425963261648745 \n",
      "Epoch 24 | Step 9549 | loss: 0.1579974107045148 | accuracy: 0.9426339285714286 \n",
      "Epoch 24 | Step 9550 | loss: 0.15827112765551887 | accuracy: 0.9424488434163701 \n",
      "Epoch 24 | Step 9551 | loss: 0.1580618543695685 | accuracy: 0.942542109929078 \n",
      "Epoch 24 | Step 9552 | loss: 0.15790114890086357 | accuracy: 0.9426347173144877 \n",
      "Epoch 24 | Step 9553 | loss: 0.15778572341873193 | accuracy: 0.9426716549295775 \n",
      "Epoch 24 | Step 9554 | loss: 0.15771249541849422 | accuracy: 0.9427631578947369 \n",
      "Epoch 24 | Step 9555 | loss: 0.1577503066770472 | accuracy: 0.9426901223776224 \n",
      "Epoch 24 | Step 9556 | loss: 0.15757189736497115 | accuracy: 0.9427264808362369 \n",
      "Epoch 24 | Step 9557 | loss: 0.15737175640080958 | accuracy: 0.9427625868055556 \n",
      "Epoch 24 | Step 9558 | loss: 0.15710994311218449 | accuracy: 0.9428525086505191 \n",
      "Epoch 24 | Step 9559 | loss: 0.1575398570376224 | accuracy: 0.9427262931034482 \n",
      "Epoch 24 | Step 9560 | loss: 0.1574496906314724 | accuracy: 0.9428157216494846 \n",
      "Epoch 24 | Step 9561 | loss: 0.15739624823558418 | accuracy: 0.9429045376712328 \n",
      "Epoch 24 | Step 9562 | loss: 0.15739438918009152 | accuracy: 0.9429394197952219 \n",
      "Epoch 24 | Step 9563 | loss: 0.15720564333506593 | accuracy: 0.9429209183673469 \n",
      "Epoch 24 | Step 9564 | loss: 0.15729682449314558 | accuracy: 0.9427436440677966 \n",
      "Epoch 24 | Step 9565 | loss: 0.15728539836316097 | accuracy: 0.9427259290540541 \n",
      "Epoch 24 | Step 9566 | loss: 0.1573739375304494 | accuracy: 0.9427083333333334 \n",
      "Epoch 24 | Step 9567 | loss: 0.157331128435947 | accuracy: 0.942690855704698 \n",
      "Epoch 24 | Step 9568 | loss: 0.15736022027190716 | accuracy: 0.9426734949832776 \n",
      "Epoch 24 | Step 9569 | loss: 0.15716850080837808 | accuracy: 0.9427604166666667 \n",
      "Epoch 24 | Step 9570 | loss: 0.15702522223029425 | accuracy: 0.9427948504983389 \n",
      "Epoch 24 | Step 9571 | loss: 0.1568132992587145 | accuracy: 0.9428290562913907 \n",
      "Epoch 24 | Step 9572 | loss: 0.1566905401056946 | accuracy: 0.9428114686468647 \n",
      "Epoch 24 | Step 9573 | loss: 0.15658553475268971 | accuracy: 0.9427425986842105 \n",
      "Epoch 24 | Step 9574 | loss: 0.15692811795189734 | accuracy: 0.9426229508196722 \n",
      "Epoch 24 | Step 9575 | loss: 0.15686031588006255 | accuracy: 0.9427083333333334 \n",
      "Epoch 24 | Step 9576 | loss: 0.15673258098552206 | accuracy: 0.9428440553745928 \n",
      "Epoch 24 | Step 9577 | loss: 0.15645940070850897 | accuracy: 0.9429788961038961 \n",
      "Epoch 24 | Step 9578 | loss: 0.15616575494697954 | accuracy: 0.9431128640776699 \n",
      "Epoch 24 | Step 9579 | loss: 0.15610094588370096 | accuracy: 0.9431451612903226 \n",
      "Epoch 24 | Step 9580 | loss: 0.1560764259919285 | accuracy: 0.9431772508038585 \n",
      "Epoch 24 | Step 9581 | loss: 0.15611897388664198 | accuracy: 0.9431590544871795 \n",
      "Epoch 24 | Step 9582 | loss: 0.15582818358232042 | accuracy: 0.9432907348242812 \n",
      "Epoch 24 | Step 9583 | loss: 0.1558700988697968 | accuracy: 0.943172770700637 \n",
      "Epoch 24 | Step 9584 | loss: 0.1555878620180819 | accuracy: 0.9433531746031746 \n",
      "Epoch 24 | Step 9585 | loss: 0.15569693136583027 | accuracy: 0.9434335443037974 \n",
      "Epoch 24 | Step 9586 | loss: 0.15551087787897808 | accuracy: 0.9434641167192429 \n",
      "Epoch 24 | Step 9587 | loss: 0.15570866341157907 | accuracy: 0.9433470911949685 \n",
      "Epoch 24 | Step 9588 | loss: 0.1555977429038492 | accuracy: 0.9433777429467085 \n",
      "Epoch 24 | Step 9589 | loss: 0.15546823838958518 | accuracy: 0.94345703125 \n",
      "Epoch 24 | Step 9590 | loss: 0.15543177882876724 | accuracy: 0.9434871495327103 \n",
      "Epoch 24 | Step 9591 | loss: 0.15530199047340001 | accuracy: 0.9436141304347826 \n",
      "Epoch 24 | Step 9592 | loss: 0.15515997614884527 | accuracy: 0.9436919504643962 \n",
      "Epoch 24 | Step 9593 | loss: 0.15503560421689427 | accuracy: 0.9437692901234568 \n",
      "Epoch 24 | Step 9594 | loss: 0.15491104681904502 | accuracy: 0.9437980769230769 \n",
      "Epoch 24 | Step 9595 | loss: 0.154927499877986 | accuracy: 0.9438266871165644 \n",
      "Epoch 24 | Step 9596 | loss: 0.1549465792646649 | accuracy: 0.9438073394495413 \n",
      "Epoch 24 | Step 9597 | loss: 0.15513879043708856 | accuracy: 0.9437404725609756 \n",
      "Epoch 24 | Step 9598 | loss: 0.15479968481422562 | accuracy: 0.943863981762918 \n",
      "Epoch 24 | Step 9599 | loss: 0.15475527149709792 | accuracy: 0.943844696969697 \n",
      "Epoch 24 | Step 9600 | loss: 0.15485808885799798 | accuracy: 0.9437783232628398 \n",
      "Epoch 24 | Step 9601 | loss: 0.15474795707198516 | accuracy: 0.9438535391566265 \n",
      "Epoch 24 | Step 9602 | loss: 0.15471739301810397 | accuracy: 0.9439283033033034 \n",
      "Epoch 24 | Step 9603 | loss: 0.15473899602176192 | accuracy: 0.9439558383233533 \n",
      "Epoch 24 | Step 9604 | loss: 0.15464946787748768 | accuracy: 0.9439832089552239 \n",
      "Epoch 24 | Step 9605 | loss: 0.15466974844180406 | accuracy: 0.9439639136904762 \n",
      "Epoch 24 | Step 9606 | loss: 0.1546150454339359 | accuracy: 0.9439910979228486 \n",
      "Epoch 24 | Step 9607 | loss: 0.15455997514830544 | accuracy: 0.9438794378698225 \n",
      "Epoch 24 | Step 9608 | loss: 0.1544019929339401 | accuracy: 0.9439067109144543 \n",
      "Epoch 24 | Step 9609 | loss: 0.15425974235815168 | accuracy: 0.9439797794117647 \n",
      "Epoch 24 | Step 9610 | loss: 0.1543909632914927 | accuracy: 0.9439607771260997 \n",
      "Epoch 24 | Step 9611 | loss: 0.15428386907479924 | accuracy: 0.9440332602339181 \n",
      "Epoch 24 | Step 9612 | loss: 0.1541374328141658 | accuracy: 0.9441053206997084 \n",
      "Epoch 24 | Step 9613 | loss: 0.15397999507136825 | accuracy: 0.9441315406976745 \n",
      "Epoch 24 | Step 9614 | loss: 0.15396846362214167 | accuracy: 0.9440217391304347 \n",
      "Epoch 24 | Step 9615 | loss: 0.15383074542432174 | accuracy: 0.9440932080924855 \n",
      "Epoch 24 | Step 9616 | loss: 0.15382955828815797 | accuracy: 0.944164265129683 \n",
      "Epoch 24 | Step 9617 | loss: 0.1535752647310154 | accuracy: 0.9442798132183908 \n",
      "Epoch 24 | Step 9618 | loss: 0.15360845834614567 | accuracy: 0.9443051575931232 \n",
      "Epoch 24 | Step 9619 | loss: 0.15382185378244956 | accuracy: 0.9441517857142857 \n",
      "Epoch 24 | Step 9620 | loss: 0.15362043744563386 | accuracy: 0.9442218660968661 \n",
      "Epoch 24 | Step 9621 | loss: 0.15356854842552414 | accuracy: 0.9442027698863636 \n",
      "Epoch 24 | Step 9622 | loss: 0.15348587413094208 | accuracy: 0.9441837818696884 \n",
      "Epoch 24 | Step 9623 | loss: 0.1535590524853624 | accuracy: 0.9440766242937854 \n",
      "Epoch 24 | Step 9624 | loss: 0.15345791261380837 | accuracy: 0.9441461267605634 \n",
      "Epoch 24 | Step 9625 | loss: 0.1534131301378602 | accuracy: 0.9441274578651685 \n",
      "Epoch 24 | Step 9626 | loss: 0.15369065408529697 | accuracy: 0.9440651260504201 \n",
      "Epoch 24 | Step 9627 | loss: 0.15401398442560743 | accuracy: 0.9439158519553073 \n",
      "Epoch 24 | Step 9628 | loss: 0.15396307933878445 | accuracy: 0.9438979805013927 \n",
      "Epoch 24 | Step 9629 | loss: 0.15406462717801345 | accuracy: 0.9439236111111111 \n",
      "Epoch 24 | Step 9630 | loss: 0.15387294637529486 | accuracy: 0.9440356648199446 \n",
      "Epoch 24 | Step 9631 | loss: 0.15394944199541008 | accuracy: 0.9439744475138122 \n",
      "Epoch 24 | Step 9632 | loss: 0.15386106303736538 | accuracy: 0.9440426997245179 \n",
      "Epoch 24 | Step 9633 | loss: 0.15359336526675552 | accuracy: 0.9441964285714286 \n",
      "Epoch 24 | Step 9634 | loss: 0.15337153464964004 | accuracy: 0.9443493150684932 \n",
      "Epoch 24 | Step 9635 | loss: 0.15335207200441217 | accuracy: 0.9443732923497268 \n",
      "Epoch 24 | Step 9636 | loss: 0.15331204621278635 | accuracy: 0.9444397138964578 \n",
      "Epoch 24 | Step 9637 | loss: 0.15332891820403557 | accuracy: 0.9445057744565217 \n",
      "Epoch 24 | Step 9638 | loss: 0.1534692557038978 | accuracy: 0.9444444444444444 \n",
      "Epoch 24 | Step 9639 | loss: 0.15331026527124494 | accuracy: 0.9445523648648648 \n",
      "Epoch 24 | Step 9640 | loss: 0.15344336578707823 | accuracy: 0.9445754716981132 \n",
      "Epoch 24 | Step 9641 | loss: 0.153309797427507 | accuracy: 0.9445984543010753 \n",
      "Epoch 24 | Step 9642 | loss: 0.15304832160472884 | accuracy: 0.9447050938337802 \n",
      "Epoch 24 | Step 9643 | loss: 0.15289696202399272 | accuracy: 0.9447276069518716 \n",
      "Epoch 24 | Step 9644 | loss: 0.15286892978350336 | accuracy: 0.9447083333333334 \n",
      "Epoch 24 | Step 9645 | loss: 0.15264683525930076 | accuracy: 0.944813829787234 \n",
      "Epoch 24 | Step 9646 | loss: 0.15260189491020287 | accuracy: 0.944835875331565 \n",
      "Epoch 24 | Step 9647 | loss: 0.1524422769705771 | accuracy: 0.9448991402116402 \n",
      "Epoch 24 | Step 9648 | loss: 0.1523739037578214 | accuracy: 0.9448383905013192 \n",
      "Epoch 24 | Step 9649 | loss: 0.15225386441146083 | accuracy: 0.9448601973684211 \n",
      "Epoch 24 | Step 9650 | loss: 0.15216680318899364 | accuracy: 0.9447588582677166 \n",
      "Epoch 24 | Step 9651 | loss: 0.152140069089791 | accuracy: 0.9447807591623036 \n",
      "Epoch 24 | Step 9652 | loss: 0.15220925108804412 | accuracy: 0.9447209530026109 \n",
      "Epoch 24 | Step 9653 | loss: 0.15265748461630824 | accuracy: 0.9447021484375 \n",
      "Epoch 24 | Step 9654 | loss: 0.1525172576308251 | accuracy: 0.9447240259740259 \n",
      "Epoch 24 | Step 9655 | loss: 0.15247539930779086 | accuracy: 0.944705310880829 \n",
      "Epoch 24 | Step 9656 | loss: 0.15233881804293137 | accuracy: 0.9447674418604651 \n",
      "Epoch 24 | Step 9657 | loss: 0.15256356987526126 | accuracy: 0.9447487113402062 \n",
      "Epoch 24 | Step 9658 | loss: 0.15241321172459882 | accuracy: 0.944810411311054 \n",
      "Epoch 24 | Step 9659 | loss: 0.1523610704029218 | accuracy: 0.9448717948717948 \n",
      "Epoch 24 | Step 9660 | loss: 0.1524807047241789 | accuracy: 0.9448929028132992 \n",
      "Epoch 24 | Step 9661 | loss: 0.15240556545251485 | accuracy: 0.9448740433673469 \n",
      "Epoch 24 | Step 9662 | loss: 0.15242483294343825 | accuracy: 0.944895038167939 \n",
      "Epoch 24 | Step 9663 | loss: 0.15250662460847553 | accuracy: 0.9449555837563451 \n",
      "Epoch 24 | Step 9664 | loss: 0.15233157835429226 | accuracy: 0.9450553797468354 \n",
      "Epoch 24 | Step 9665 | loss: 0.15207353582361127 | accuracy: 0.9451546717171717 \n",
      "Epoch 24 | Step 9666 | loss: 0.15220439068091005 | accuracy: 0.9451353904282116 \n",
      "Epoch 24 | Step 9667 | loss: 0.1522365241830972 | accuracy: 0.9450769472361809 \n",
      "Epoch 24 | Step 9668 | loss: 0.15201459970689357 | accuracy: 0.9451754385964912 \n",
      "Epoch 24 | Step 9669 | loss: 0.15185950711369514 | accuracy: 0.945234375 \n",
      "Epoch 24 | Step 9670 | loss: 0.1520473849297759 | accuracy: 0.9452150872817955 \n",
      "Epoch 24 | Step 9671 | loss: 0.1523339987097688 | accuracy: 0.9451181592039801 \n",
      "Epoch 24 | Step 9672 | loss: 0.15207585624000866 | accuracy: 0.9452543424317618 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5675545334815979 | accuracy: 0.828125 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.4990478903055191 | accuracy: 0.8359375 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.576128234465917 | accuracy: 0.8333333333333334 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5634774342179298 | accuracy: 0.83203125 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5286101341247559 | accuracy: 0.840625 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5716965993245443 | accuracy: 0.8203125 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.555737921169826 | accuracy: 0.8236607142857143 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5390310846269131 | accuracy: 0.822265625 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5797050694624583 | accuracy: 0.8125 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5557653933763504 | accuracy: 0.821875 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5620814805681055 | accuracy: 0.8238636363636364 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5479987810055414 | accuracy: 0.8294270833333334 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5696194309454697 | accuracy: 0.8245192307692307 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5489234243120465 | accuracy: 0.8292410714285714 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.556553594271342 | accuracy: 0.8302083333333333 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.55497981980443 | accuracy: 0.8271484375 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5507894386263454 | accuracy: 0.8272058823529411 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5468966762224833 | accuracy: 0.828125 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5387951167006242 | accuracy: 0.8305921052631579 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.525272385776043 | accuracy: 0.83515625 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5173391728174119 | accuracy: 0.8370535714285714 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5086747055703944 | accuracy: 0.8373579545454546 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5203255052151888 | accuracy: 0.8349184782608695 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5468101650476457 | accuracy: 0.8307291666666666 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5552975177764894 | accuracy: 0.82875 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5534408963643589 | accuracy: 0.8299278846153846 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5442868835396238 | accuracy: 0.8327546296296297 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5477935150265695 | accuracy: 0.8303571428571429 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5460076342368949 | accuracy: 0.8308189655172413 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5433462689320248 | accuracy: 0.8328125 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.53735303109692 | accuracy: 0.8356854838709677 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5397512111812831 | accuracy: 0.833984375 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5414166432438475 | accuracy: 0.8314393939393939 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5444722946952372 | accuracy: 0.8295036764705882 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5478593145098006 | accuracy: 0.828125 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5442123429642785 | accuracy: 0.8298611111111112 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5453502841897914 | accuracy: 0.8293918918918919 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5509444443803085 | accuracy: 0.8297697368421053 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.553875044370309 | accuracy: 0.828926282051282 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5482229731976986 | accuracy: 0.830859375 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5442713230121426 | accuracy: 0.8315548780487805 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5380242999110904 | accuracy: 0.8333333333333334 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5412709068420323 | accuracy: 0.8335755813953488 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5423799678683282 | accuracy: 0.8341619318181818 \n",
      "Validation | Epoch 24 | Step 9672 | loss: 0.5431140469180213 | accuracy: 0.8334993958473206 \n",
      "Epoch 25 | Step 9673 | loss: 0.24068723618984222 | accuracy: 0.90625 \n",
      "Epoch 25 | Step 9674 | loss: 0.14666582643985748 | accuracy: 0.9453125 \n",
      "Epoch 25 | Step 9675 | loss: 0.12287286669015884 | accuracy: 0.9583333333333334 \n",
      "Epoch 25 | Step 9676 | loss: 0.12913587875664234 | accuracy: 0.953125 \n",
      "Epoch 25 | Step 9677 | loss: 0.12196783870458602 | accuracy: 0.95625 \n",
      "Epoch 25 | Step 9678 | loss: 0.11815329889456432 | accuracy: 0.9583333333333334 \n",
      "Epoch 25 | Step 9679 | loss: 0.1280340084007808 | accuracy: 0.9575892857142857 \n",
      "Epoch 25 | Step 9680 | loss: 0.1299541611224413 | accuracy: 0.9609375 \n",
      "Epoch 25 | Step 9681 | loss: 0.13974582155545553 | accuracy: 0.9565972222222222 \n",
      "Epoch 25 | Step 9682 | loss: 0.1518597424030304 | accuracy: 0.953125 \n",
      "Epoch 25 | Step 9683 | loss: 0.14818158407102933 | accuracy: 0.953125 \n",
      "Epoch 25 | Step 9684 | loss: 0.14099863295753798 | accuracy: 0.95703125 \n",
      "Epoch 25 | Step 9685 | loss: 0.15163087042478415 | accuracy: 0.9507211538461539 \n",
      "Epoch 25 | Step 9686 | loss: 0.15135108679533005 | accuracy: 0.9508928571428571 \n",
      "Epoch 25 | Step 9687 | loss: 0.15234940350055695 | accuracy: 0.9510416666666667 \n",
      "Epoch 25 | Step 9688 | loss: 0.14743531309068203 | accuracy: 0.9521484375 \n",
      "Epoch 25 | Step 9689 | loss: 0.14675761145703933 | accuracy: 0.9522058823529411 \n",
      "Epoch 25 | Step 9690 | loss: 0.14477447420358658 | accuracy: 0.9513888888888888 \n",
      "Epoch 25 | Step 9691 | loss: 0.14425207596076162 | accuracy: 0.9514802631578947 \n",
      "Epoch 25 | Step 9692 | loss: 0.145675727725029 | accuracy: 0.95 \n",
      "Epoch 25 | Step 9693 | loss: 0.1470299121879396 | accuracy: 0.9494047619047619 \n",
      "Epoch 25 | Step 9694 | loss: 0.14889089289036664 | accuracy: 0.9495738636363636 \n",
      "Epoch 25 | Step 9695 | loss: 0.14620518943537836 | accuracy: 0.9497282608695652 \n",
      "Epoch 25 | Step 9696 | loss: 0.14482482181241116 | accuracy: 0.9505208333333334 \n",
      "Epoch 25 | Step 9697 | loss: 0.1465079578757286 | accuracy: 0.95 \n",
      "Epoch 25 | Step 9698 | loss: 0.14546193125156254 | accuracy: 0.9507211538461539 \n",
      "Epoch 25 | Step 9699 | loss: 0.15114666521549225 | accuracy: 0.9479166666666666 \n",
      "Epoch 25 | Step 9700 | loss: 0.14786807061838253 | accuracy: 0.94921875 \n",
      "Epoch 25 | Step 9701 | loss: 0.15027735035481124 | accuracy: 0.9482758620689655 \n",
      "Epoch 25 | Step 9702 | loss: 0.15113457230230173 | accuracy: 0.9473958333333333 \n",
      "Epoch 25 | Step 9703 | loss: 0.15030158611555253 | accuracy: 0.9475806451612904 \n",
      "Epoch 25 | Step 9704 | loss: 0.15068907325621694 | accuracy: 0.9462890625 \n",
      "Epoch 25 | Step 9705 | loss: 0.15004323501930092 | accuracy: 0.946969696969697 \n",
      "Epoch 25 | Step 9706 | loss: 0.14688582367756786 | accuracy: 0.9480698529411765 \n",
      "Epoch 25 | Step 9707 | loss: 0.14435098277670996 | accuracy: 0.9491071428571428 \n",
      "Epoch 25 | Step 9708 | loss: 0.14285777798957294 | accuracy: 0.9496527777777778 \n",
      "Epoch 25 | Step 9709 | loss: 0.14272781682981028 | accuracy: 0.9493243243243243 \n",
      "Epoch 25 | Step 9710 | loss: 0.14097963351952403 | accuracy: 0.9498355263157895 \n",
      "Epoch 25 | Step 9711 | loss: 0.13901388339507273 | accuracy: 0.9507211538461539 \n",
      "Epoch 25 | Step 9712 | loss: 0.13769361488521098 | accuracy: 0.9515625 \n",
      "Epoch 25 | Step 9713 | loss: 0.13587030913771653 | accuracy: 0.9523628048780488 \n",
      "Epoch 25 | Step 9714 | loss: 0.13580881520396187 | accuracy: 0.9523809523809523 \n",
      "Epoch 25 | Step 9715 | loss: 0.13423627909532812 | accuracy: 0.9527616279069767 \n",
      "Epoch 25 | Step 9716 | loss: 0.13343752446499735 | accuracy: 0.953125 \n",
      "Epoch 25 | Step 9717 | loss: 0.13546274569299482 | accuracy: 0.9527777777777777 \n",
      "Epoch 25 | Step 9718 | loss: 0.13618646983219226 | accuracy: 0.9527853260869565 \n",
      "Epoch 25 | Step 9719 | loss: 0.13530111566502995 | accuracy: 0.953125 \n",
      "Epoch 25 | Step 9720 | loss: 0.1357955156515042 | accuracy: 0.9534505208333334 \n",
      "Epoch 25 | Step 9721 | loss: 0.13664729954028615 | accuracy: 0.9534438775510204 \n",
      "Epoch 25 | Step 9722 | loss: 0.1378931951522827 | accuracy: 0.9525 \n",
      "Epoch 25 | Step 9723 | loss: 0.13843908029444077 | accuracy: 0.9522058823529411 \n",
      "Epoch 25 | Step 9724 | loss: 0.13722042825359565 | accuracy: 0.9528245192307693 \n",
      "Epoch 25 | Step 9725 | loss: 0.13772473301527635 | accuracy: 0.9525353773584906 \n",
      "Epoch 25 | Step 9726 | loss: 0.13667816213435596 | accuracy: 0.9528356481481481 \n",
      "Epoch 25 | Step 9727 | loss: 0.13805791315707294 | accuracy: 0.9519886363636364 \n",
      "Epoch 25 | Step 9728 | loss: 0.13728966497417008 | accuracy: 0.9525669642857143 \n",
      "Epoch 25 | Step 9729 | loss: 0.13826596854548706 | accuracy: 0.9525767543859649 \n",
      "Epoch 25 | Step 9730 | loss: 0.13950548462312798 | accuracy: 0.9520474137931034 \n",
      "Epoch 25 | Step 9731 | loss: 0.14020446107044057 | accuracy: 0.9518008474576272 \n",
      "Epoch 25 | Step 9732 | loss: 0.14184372710684937 | accuracy: 0.9515625 \n",
      "Epoch 25 | Step 9733 | loss: 0.1407852546601999 | accuracy: 0.951844262295082 \n",
      "Epoch 25 | Step 9734 | loss: 0.1409342488454234 | accuracy: 0.9518649193548387 \n",
      "Epoch 25 | Step 9735 | loss: 0.14175974163744184 | accuracy: 0.9513888888888888 \n",
      "Epoch 25 | Step 9736 | loss: 0.14072098745964468 | accuracy: 0.95166015625 \n",
      "Epoch 25 | Step 9737 | loss: 0.13952052478606886 | accuracy: 0.9521634615384615 \n",
      "Epoch 25 | Step 9738 | loss: 0.13863390119689883 | accuracy: 0.9526515151515151 \n",
      "Epoch 25 | Step 9739 | loss: 0.1377662180075005 | accuracy: 0.9528917910447762 \n",
      "Epoch 25 | Step 9740 | loss: 0.13807663518716307 | accuracy: 0.9524356617647058 \n",
      "Epoch 25 | Step 9741 | loss: 0.13783316519381345 | accuracy: 0.9524456521739131 \n",
      "Epoch 25 | Step 9742 | loss: 0.1380422256886959 | accuracy: 0.9522321428571429 \n",
      "Epoch 25 | Step 9743 | loss: 0.13729867066296053 | accuracy: 0.9524647887323944 \n",
      "Epoch 25 | Step 9744 | loss: 0.136963055572576 | accuracy: 0.9524739583333334 \n",
      "Epoch 25 | Step 9745 | loss: 0.1370372664030284 | accuracy: 0.952054794520548 \n",
      "Epoch 25 | Step 9746 | loss: 0.13698432211940353 | accuracy: 0.9520692567567568 \n",
      "Epoch 25 | Step 9747 | loss: 0.13701598326365153 | accuracy: 0.9520833333333333 \n",
      "Epoch 25 | Step 9748 | loss: 0.13722112755242147 | accuracy: 0.9523026315789473 \n",
      "Epoch 25 | Step 9749 | loss: 0.13688520138913934 | accuracy: 0.9523133116883117 \n",
      "Epoch 25 | Step 9750 | loss: 0.13699477891891432 | accuracy: 0.952323717948718 \n",
      "Epoch 25 | Step 9751 | loss: 0.13941278318061104 | accuracy: 0.9517405063291139 \n",
      "Epoch 25 | Step 9752 | loss: 0.138874926045537 | accuracy: 0.9521484375 \n",
      "Epoch 25 | Step 9753 | loss: 0.13820440423341446 | accuracy: 0.9523533950617284 \n",
      "Epoch 25 | Step 9754 | loss: 0.13778816390691734 | accuracy: 0.9523628048780488 \n",
      "Epoch 25 | Step 9755 | loss: 0.13822018947586956 | accuracy: 0.9523719879518072 \n",
      "Epoch 25 | Step 9756 | loss: 0.13796863563003994 | accuracy: 0.9523809523809523 \n",
      "Epoch 25 | Step 9757 | loss: 0.13756969387040419 | accuracy: 0.9525735294117647 \n",
      "Epoch 25 | Step 9758 | loss: 0.1372197114450987 | accuracy: 0.9529433139534884 \n",
      "Epoch 25 | Step 9759 | loss: 0.13977150156580168 | accuracy: 0.9520474137931034 \n",
      "Epoch 25 | Step 9760 | loss: 0.140618390657685 | accuracy: 0.9520596590909091 \n",
      "Epoch 25 | Step 9761 | loss: 0.13994850419210583 | accuracy: 0.9524227528089888 \n",
      "Epoch 25 | Step 9762 | loss: 0.1394067525035805 | accuracy: 0.9526041666666667 \n",
      "Epoch 25 | Step 9763 | loss: 0.1385358466388105 | accuracy: 0.9529532967032966 \n",
      "Epoch 25 | Step 9764 | loss: 0.1380035875608092 | accuracy: 0.953125 \n",
      "Epoch 25 | Step 9765 | loss: 0.13749725403644708 | accuracy: 0.9534610215053764 \n",
      "Epoch 25 | Step 9766 | loss: 0.1368067802742441 | accuracy: 0.953623670212766 \n",
      "Epoch 25 | Step 9767 | loss: 0.13719512937884584 | accuracy: 0.953453947368421 \n",
      "Epoch 25 | Step 9768 | loss: 0.13850268434422713 | accuracy: 0.9529622395833334 \n",
      "Epoch 25 | Step 9769 | loss: 0.13813880831003192 | accuracy: 0.9529639175257731 \n",
      "Epoch 25 | Step 9770 | loss: 0.13945575795915666 | accuracy: 0.9524872448979592 \n",
      "Epoch 25 | Step 9771 | loss: 0.1402471143037382 | accuracy: 0.9524936868686869 \n",
      "Epoch 25 | Step 9772 | loss: 0.13950359471142296 | accuracy: 0.95296875 \n",
      "Epoch 25 | Step 9773 | loss: 0.13876402850198277 | accuracy: 0.9532797029702971 \n",
      "Epoch 25 | Step 9774 | loss: 0.13841777309483178 | accuracy: 0.9534313725490197 \n",
      "Epoch 25 | Step 9775 | loss: 0.13756242061702956 | accuracy: 0.9537317961165048 \n",
      "Epoch 25 | Step 9776 | loss: 0.13773523314067956 | accuracy: 0.9535757211538461 \n",
      "Epoch 25 | Step 9777 | loss: 0.138745471409389 | accuracy: 0.953422619047619 \n",
      "Epoch 25 | Step 9778 | loss: 0.13800631625191226 | accuracy: 0.9535672169811321 \n",
      "Epoch 25 | Step 9779 | loss: 0.13857455739629607 | accuracy: 0.9532710280373832 \n",
      "Epoch 25 | Step 9780 | loss: 0.13967269058856702 | accuracy: 0.9526909722222222 \n",
      "Epoch 25 | Step 9781 | loss: 0.1404129982404753 | accuracy: 0.9525516055045872 \n",
      "Epoch 25 | Step 9782 | loss: 0.14090779498219494 | accuracy: 0.9519886363636364 \n",
      "Epoch 25 | Step 9783 | loss: 0.14066592590497423 | accuracy: 0.9519988738738738 \n",
      "Epoch 25 | Step 9784 | loss: 0.14060276287740897 | accuracy: 0.9520089285714286 \n",
      "Epoch 25 | Step 9785 | loss: 0.1416627998768756 | accuracy: 0.9516039823008849 \n",
      "Epoch 25 | Step 9786 | loss: 0.14110493398549268 | accuracy: 0.9517543859649122 \n",
      "Epoch 25 | Step 9787 | loss: 0.14093950300113017 | accuracy: 0.951766304347826 \n",
      "Epoch 25 | Step 9788 | loss: 0.1407589780744808 | accuracy: 0.9516433189655172 \n",
      "Epoch 25 | Step 9789 | loss: 0.14186274336698732 | accuracy: 0.9508547008547008 \n",
      "Epoch 25 | Step 9790 | loss: 0.1414580167728966 | accuracy: 0.9508739406779662 \n",
      "Epoch 25 | Step 9791 | loss: 0.14127450724359322 | accuracy: 0.9508928571428571 \n",
      "Epoch 25 | Step 9792 | loss: 0.14085827028999728 | accuracy: 0.9510416666666667 \n",
      "Epoch 25 | Step 9793 | loss: 0.14076860612335287 | accuracy: 0.9510588842975206 \n",
      "Epoch 25 | Step 9794 | loss: 0.14083590902021675 | accuracy: 0.9509477459016393 \n",
      "Epoch 25 | Step 9795 | loss: 0.14064124947398662 | accuracy: 0.9508384146341463 \n",
      "Epoch 25 | Step 9796 | loss: 0.14039883005522916 | accuracy: 0.9509828629032258 \n",
      "Epoch 25 | Step 9797 | loss: 0.13992953300476077 | accuracy: 0.95125 \n",
      "Epoch 25 | Step 9798 | loss: 0.13984493402734638 | accuracy: 0.951140873015873 \n",
      "Epoch 25 | Step 9799 | loss: 0.14112449806975572 | accuracy: 0.9506643700787402 \n",
      "Epoch 25 | Step 9800 | loss: 0.14079816057346764 | accuracy: 0.95068359375 \n",
      "Epoch 25 | Step 9801 | loss: 0.14064079141894054 | accuracy: 0.9508236434108527 \n",
      "Epoch 25 | Step 9802 | loss: 0.14031275757230247 | accuracy: 0.9510817307692307 \n",
      "Epoch 25 | Step 9803 | loss: 0.141204291343234 | accuracy: 0.9508587786259542 \n",
      "Epoch 25 | Step 9804 | loss: 0.1419988645409996 | accuracy: 0.9507575757575758 \n",
      "Epoch 25 | Step 9805 | loss: 0.142425236005084 | accuracy: 0.9504229323308271 \n",
      "Epoch 25 | Step 9806 | loss: 0.14256774239353284 | accuracy: 0.9503264925373134 \n",
      "Epoch 25 | Step 9807 | loss: 0.14276867172232385 | accuracy: 0.9502314814814815 \n",
      "Epoch 25 | Step 9808 | loss: 0.14262861994040368 | accuracy: 0.9503676470588235 \n",
      "Epoch 25 | Step 9809 | loss: 0.14240052425948377 | accuracy: 0.9505018248175182 \n",
      "Epoch 25 | Step 9810 | loss: 0.14231787665166723 | accuracy: 0.9506340579710145 \n",
      "Epoch 25 | Step 9811 | loss: 0.14243887225500976 | accuracy: 0.9507643884892086 \n",
      "Epoch 25 | Step 9812 | loss: 0.14271612944347523 | accuracy: 0.95078125 \n",
      "Epoch 25 | Step 9813 | loss: 0.14381959875847436 | accuracy: 0.9505762411347518 \n",
      "Epoch 25 | Step 9814 | loss: 0.1443240214401568 | accuracy: 0.9505941901408451 \n",
      "Epoch 25 | Step 9815 | loss: 0.14469763261454927 | accuracy: 0.9502840909090909 \n",
      "Epoch 25 | Step 9816 | loss: 0.1445387521655196 | accuracy: 0.9501953125 \n",
      "Epoch 25 | Step 9817 | loss: 0.14458426160031357 | accuracy: 0.9502155172413793 \n",
      "Epoch 25 | Step 9818 | loss: 0.14496096626740618 | accuracy: 0.9501284246575342 \n",
      "Epoch 25 | Step 9819 | loss: 0.14419186442178128 | accuracy: 0.95046768707483 \n",
      "Epoch 25 | Step 9820 | loss: 0.14418123624715456 | accuracy: 0.9505912162162162 \n",
      "Epoch 25 | Step 9821 | loss: 0.14366056137537 | accuracy: 0.9509228187919463 \n",
      "Epoch 25 | Step 9822 | loss: 0.14418861490984763 | accuracy: 0.9509375 \n",
      "Epoch 25 | Step 9823 | loss: 0.14462110254642194 | accuracy: 0.9507450331125827 \n",
      "Epoch 25 | Step 9824 | loss: 0.14603609113806962 | accuracy: 0.9505550986842105 \n",
      "Epoch 25 | Step 9825 | loss: 0.14660593119809057 | accuracy: 0.9503676470588235 \n",
      "Epoch 25 | Step 9826 | loss: 0.146105901205114 | accuracy: 0.950588474025974 \n",
      "Epoch 25 | Step 9827 | loss: 0.14605162165337998 | accuracy: 0.9504032258064516 \n",
      "Epoch 25 | Step 9828 | loss: 0.14561601797453108 | accuracy: 0.9505208333333334 \n",
      "Epoch 25 | Step 9829 | loss: 0.14530667071794254 | accuracy: 0.9505374203821656 \n",
      "Epoch 25 | Step 9830 | loss: 0.14504673716293864 | accuracy: 0.9505537974683544 \n",
      "Epoch 25 | Step 9831 | loss: 0.14507266689302792 | accuracy: 0.950373427672956 \n",
      "Epoch 25 | Step 9832 | loss: 0.145378730702214 | accuracy: 0.95 \n",
      "Epoch 25 | Step 9833 | loss: 0.14555373813332242 | accuracy: 0.9498253105590062 \n",
      "Epoch 25 | Step 9834 | loss: 0.14520766381404288 | accuracy: 0.9499421296296297 \n",
      "Epoch 25 | Step 9835 | loss: 0.14689396026949944 | accuracy: 0.9493865030674846 \n",
      "Epoch 25 | Step 9836 | loss: 0.14664056004456633 | accuracy: 0.9494092987804879 \n",
      "Epoch 25 | Step 9837 | loss: 0.14656877434163385 | accuracy: 0.9496212121212121 \n",
      "Epoch 25 | Step 9838 | loss: 0.14683693304029577 | accuracy: 0.9494540662650602 \n",
      "Epoch 25 | Step 9839 | loss: 0.14640136275016621 | accuracy: 0.9495696107784432 \n",
      "Epoch 25 | Step 9840 | loss: 0.14702950105337162 | accuracy: 0.94921875 \n",
      "Epoch 25 | Step 9841 | loss: 0.14677840658634375 | accuracy: 0.9493343195266272 \n",
      "Epoch 25 | Step 9842 | loss: 0.1461860415470951 | accuracy: 0.9496323529411764 \n",
      "Epoch 25 | Step 9843 | loss: 0.14619398045173868 | accuracy: 0.9496527777777778 \n",
      "Epoch 25 | Step 9844 | loss: 0.14650057306036704 | accuracy: 0.9495821220930233 \n",
      "Epoch 25 | Step 9845 | loss: 0.1462093041509907 | accuracy: 0.9496929190751445 \n",
      "Epoch 25 | Step 9846 | loss: 0.1465616092813769 | accuracy: 0.9496228448275862 \n",
      "Epoch 25 | Step 9847 | loss: 0.14653556314962254 | accuracy: 0.9494642857142858 \n",
      "Epoch 25 | Step 9848 | loss: 0.14731325634585868 | accuracy: 0.9491299715909091 \n",
      "Epoch 25 | Step 9849 | loss: 0.14752426669843458 | accuracy: 0.9490642655367232 \n",
      "Epoch 25 | Step 9850 | loss: 0.1477057118638513 | accuracy: 0.9489115168539326 \n",
      "Epoch 25 | Step 9851 | loss: 0.14808278645300335 | accuracy: 0.9487604748603352 \n",
      "Epoch 25 | Step 9852 | loss: 0.1478931685495708 | accuracy: 0.9487847222222222 \n",
      "Epoch 25 | Step 9853 | loss: 0.14804996263997333 | accuracy: 0.9488950276243094 \n",
      "Epoch 25 | Step 9854 | loss: 0.14790851522523626 | accuracy: 0.9488324175824175 \n",
      "Epoch 25 | Step 9855 | loss: 0.14769897074565866 | accuracy: 0.948941256830601 \n",
      "Epoch 25 | Step 9856 | loss: 0.14735173982689567 | accuracy: 0.9489639945652174 \n",
      "Epoch 25 | Step 9857 | loss: 0.1471814874660325 | accuracy: 0.948902027027027 \n",
      "Epoch 25 | Step 9858 | loss: 0.14748188378589774 | accuracy: 0.9486727150537635 \n",
      "Epoch 25 | Step 9859 | loss: 0.147927047316244 | accuracy: 0.9484458556149733 \n",
      "Epoch 25 | Step 9860 | loss: 0.1479750984804111 | accuracy: 0.9483876329787234 \n",
      "Epoch 25 | Step 9861 | loss: 0.14764111936486596 | accuracy: 0.9484953703703703 \n",
      "Epoch 25 | Step 9862 | loss: 0.14820578429651898 | accuracy: 0.9484375 \n",
      "Epoch 25 | Step 9863 | loss: 0.14784365703220154 | accuracy: 0.9486256544502618 \n",
      "Epoch 25 | Step 9864 | loss: 0.1477541619872986 | accuracy: 0.948486328125 \n",
      "Epoch 25 | Step 9865 | loss: 0.14729982840350883 | accuracy: 0.9486722797927462 \n",
      "Epoch 25 | Step 9866 | loss: 0.147052368533212 | accuracy: 0.9487757731958762 \n",
      "Epoch 25 | Step 9867 | loss: 0.1467035597524583 | accuracy: 0.9488782051282051 \n",
      "Epoch 25 | Step 9868 | loss: 0.1469646961219154 | accuracy: 0.9486607142857143 \n",
      "Epoch 25 | Step 9869 | loss: 0.14676128405377964 | accuracy: 0.9486833756345178 \n",
      "Epoch 25 | Step 9870 | loss: 0.14678081036592386 | accuracy: 0.9487847222222222 \n",
      "Epoch 25 | Step 9871 | loss: 0.1467119111824576 | accuracy: 0.948963567839196 \n",
      "Epoch 25 | Step 9872 | loss: 0.14668313274160039 | accuracy: 0.94890625 \n",
      "Epoch 25 | Step 9873 | loss: 0.14692934311518632 | accuracy: 0.9488495024875622 \n",
      "Epoch 25 | Step 9874 | loss: 0.14703086175319593 | accuracy: 0.9488706683168316 \n",
      "Epoch 25 | Step 9875 | loss: 0.14700858127968078 | accuracy: 0.9488916256157636 \n",
      "Epoch 25 | Step 9876 | loss: 0.14694815196608224 | accuracy: 0.9489123774509803 \n",
      "Epoch 25 | Step 9877 | loss: 0.1473419656295603 | accuracy: 0.9488567073170732 \n",
      "Epoch 25 | Step 9878 | loss: 0.14821325678342187 | accuracy: 0.9484223300970874 \n",
      "Epoch 25 | Step 9879 | loss: 0.1493192286487076 | accuracy: 0.9482940821256038 \n",
      "Epoch 25 | Step 9880 | loss: 0.1495192587698023 | accuracy: 0.9480919471153846 \n",
      "Epoch 25 | Step 9881 | loss: 0.1494873538435077 | accuracy: 0.9479665071770335 \n",
      "Epoch 25 | Step 9882 | loss: 0.14932267234793742 | accuracy: 0.9479910714285714 \n",
      "Epoch 25 | Step 9883 | loss: 0.14976996891377106 | accuracy: 0.9475710900473934 \n",
      "Epoch 25 | Step 9884 | loss: 0.14927606565772372 | accuracy: 0.9478183962264151 \n",
      "Epoch 25 | Step 9885 | loss: 0.14892834603366728 | accuracy: 0.9479166666666666 \n",
      "Epoch 25 | Step 9886 | loss: 0.14906328216752168 | accuracy: 0.9479410046728972 \n",
      "Epoch 25 | Step 9887 | loss: 0.1490458552574003 | accuracy: 0.9478924418604651 \n",
      "Epoch 25 | Step 9888 | loss: 0.14913945717530125 | accuracy: 0.9478443287037037 \n",
      "Epoch 25 | Step 9889 | loss: 0.148868225308882 | accuracy: 0.9478686635944701 \n",
      "Epoch 25 | Step 9890 | loss: 0.1487072373338796 | accuracy: 0.9479644495412844 \n",
      "Epoch 25 | Step 9891 | loss: 0.14856929437482744 | accuracy: 0.9479166666666666 \n",
      "Epoch 25 | Step 9892 | loss: 0.14842949482527654 | accuracy: 0.947940340909091 \n",
      "Epoch 25 | Step 9893 | loss: 0.1485234463916106 | accuracy: 0.9478930995475113 \n",
      "Epoch 25 | Step 9894 | loss: 0.1484863146602571 | accuracy: 0.9478462837837838 \n",
      "Epoch 25 | Step 9895 | loss: 0.14859550015274192 | accuracy: 0.9475896860986547 \n",
      "Epoch 25 | Step 9896 | loss: 0.14819654044029976 | accuracy: 0.9478236607142857 \n",
      "Epoch 25 | Step 9897 | loss: 0.1485806450578902 | accuracy: 0.9476388888888889 \n",
      "Epoch 25 | Step 9898 | loss: 0.14867154100036206 | accuracy: 0.9475248893805309 \n",
      "Epoch 25 | Step 9899 | loss: 0.1488973316510869 | accuracy: 0.9474118942731278 \n",
      "Epoch 25 | Step 9900 | loss: 0.14911131410483736 | accuracy: 0.9473684210526315 \n",
      "Epoch 25 | Step 9901 | loss: 0.14900488029010436 | accuracy: 0.9473935589519651 \n",
      "Epoch 25 | Step 9902 | loss: 0.148929248912179 | accuracy: 0.9474184782608696 \n",
      "Epoch 25 | Step 9903 | loss: 0.14895122646640396 | accuracy: 0.9474431818181818 \n",
      "Epoch 25 | Step 9904 | loss: 0.1485936515161704 | accuracy: 0.9476023706896551 \n",
      "Epoch 25 | Step 9905 | loss: 0.14860281373809853 | accuracy: 0.9474919527896996 \n",
      "Epoch 25 | Step 9906 | loss: 0.14901418926624158 | accuracy: 0.9473157051282052 \n",
      "Epoch 25 | Step 9907 | loss: 0.1489507046785761 | accuracy: 0.9472739361702127 \n",
      "Epoch 25 | Step 9908 | loss: 0.14888768125388588 | accuracy: 0.9474311440677966 \n",
      "Epoch 25 | Step 9909 | loss: 0.14872586189568804 | accuracy: 0.9475870253164557 \n",
      "Epoch 25 | Step 9910 | loss: 0.14858523192776357 | accuracy: 0.9475446428571429 \n",
      "Epoch 25 | Step 9911 | loss: 0.148494310147094 | accuracy: 0.9474372384937239 \n",
      "Epoch 25 | Step 9912 | loss: 0.14848808298508331 | accuracy: 0.9473307291666667 \n",
      "Epoch 25 | Step 9913 | loss: 0.14815727135947143 | accuracy: 0.9474844398340249 \n",
      "Epoch 25 | Step 9914 | loss: 0.1480778891685581 | accuracy: 0.9475723140495868 \n",
      "Epoch 25 | Step 9915 | loss: 0.14850973518787594 | accuracy: 0.9474022633744856 \n",
      "Epoch 25 | Step 9916 | loss: 0.1489461154722777 | accuracy: 0.9472336065573771 \n",
      "Epoch 25 | Step 9917 | loss: 0.14886292359050446 | accuracy: 0.9472576530612244 \n",
      "Epoch 25 | Step 9918 | loss: 0.1488747619758777 | accuracy: 0.9471544715447154 \n",
      "Epoch 25 | Step 9919 | loss: 0.1486373753984448 | accuracy: 0.9472419028340081 \n",
      "Epoch 25 | Step 9920 | loss: 0.14868171161581437 | accuracy: 0.947265625 \n",
      "Epoch 25 | Step 9921 | loss: 0.14842778845245105 | accuracy: 0.9473519076305221 \n",
      "Epoch 25 | Step 9922 | loss: 0.1485651577711106 | accuracy: 0.947375 \n",
      "Epoch 25 | Step 9923 | loss: 0.14845251199971163 | accuracy: 0.9473979083665338 \n",
      "Epoch 25 | Step 9924 | loss: 0.14845607967840307 | accuracy: 0.947296626984127 \n",
      "Epoch 25 | Step 9925 | loss: 0.1483130016522446 | accuracy: 0.9473814229249012 \n",
      "Epoch 25 | Step 9926 | loss: 0.14849412326854988 | accuracy: 0.9472810039370079 \n",
      "Epoch 25 | Step 9927 | loss: 0.1485891882987584 | accuracy: 0.9472426470588236 \n",
      "Epoch 25 | Step 9928 | loss: 0.14871247563860385 | accuracy: 0.947265625 \n",
      "Epoch 25 | Step 9929 | loss: 0.1485162593627255 | accuracy: 0.9472884241245136 \n",
      "Epoch 25 | Step 9930 | loss: 0.14823106298035435 | accuracy: 0.9474321705426356 \n",
      "Epoch 25 | Step 9931 | loss: 0.14836036293087784 | accuracy: 0.9472128378378378 \n",
      "Epoch 25 | Step 9932 | loss: 0.14821903032179068 | accuracy: 0.9472355769230769 \n",
      "Epoch 25 | Step 9933 | loss: 0.148491712793765 | accuracy: 0.9469588122605364 \n",
      "Epoch 25 | Step 9934 | loss: 0.1484271506601163 | accuracy: 0.946863072519084 \n",
      "Epoch 25 | Step 9935 | loss: 0.14820252132279796 | accuracy: 0.9468274714828897 \n",
      "Epoch 25 | Step 9936 | loss: 0.14857369136403914 | accuracy: 0.9467329545454546 \n",
      "Epoch 25 | Step 9937 | loss: 0.14842854094392854 | accuracy: 0.9467570754716981 \n",
      "Epoch 25 | Step 9938 | loss: 0.14845349536018268 | accuracy: 0.9467222744360902 \n",
      "Epoch 25 | Step 9939 | loss: 0.14828852622696526 | accuracy: 0.946746254681648 \n",
      "Epoch 25 | Step 9940 | loss: 0.14805982314717417 | accuracy: 0.9467700559701493 \n",
      "Epoch 25 | Step 9941 | loss: 0.1479499577423454 | accuracy: 0.9467936802973977 \n",
      "Epoch 25 | Step 9942 | loss: 0.14789735307848015 | accuracy: 0.9467013888888889 \n",
      "Epoch 25 | Step 9943 | loss: 0.14788500098614676 | accuracy: 0.9466674354243543 \n",
      "Epoch 25 | Step 9944 | loss: 0.14781556768781123 | accuracy: 0.9466911764705882 \n",
      "Epoch 25 | Step 9945 | loss: 0.14790441617096736 | accuracy: 0.9466575091575091 \n",
      "Epoch 25 | Step 9946 | loss: 0.14796071067234895 | accuracy: 0.9466240875912408 \n",
      "Epoch 25 | Step 9947 | loss: 0.1478773129257289 | accuracy: 0.9466477272727273 \n",
      "Epoch 25 | Step 9948 | loss: 0.1480880221217007 | accuracy: 0.9465013586956522 \n",
      "Epoch 25 | Step 9949 | loss: 0.14822932402687383 | accuracy: 0.9464124548736462 \n",
      "Epoch 25 | Step 9950 | loss: 0.1482167325163488 | accuracy: 0.9464366007194245 \n",
      "Epoch 25 | Step 9951 | loss: 0.14812585142671422 | accuracy: 0.9464045698924731 \n",
      "Epoch 25 | Step 9952 | loss: 0.14799925211284842 | accuracy: 0.946484375 \n",
      "Epoch 25 | Step 9953 | loss: 0.14826212584760265 | accuracy: 0.9463411921708185 \n",
      "Epoch 25 | Step 9954 | loss: 0.14812875816479643 | accuracy: 0.9463098404255319 \n",
      "Epoch 25 | Step 9955 | loss: 0.1480468274900433 | accuracy: 0.9464443462897526 \n",
      "Epoch 25 | Step 9956 | loss: 0.14798731742505455 | accuracy: 0.946412852112676 \n",
      "Epoch 25 | Step 9957 | loss: 0.14776916381037025 | accuracy: 0.946546052631579 \n",
      "Epoch 25 | Step 9958 | loss: 0.14775086644958782 | accuracy: 0.9465144230769231 \n",
      "Epoch 25 | Step 9959 | loss: 0.1476271164178433 | accuracy: 0.9465374564459931 \n",
      "Epoch 25 | Step 9960 | loss: 0.14736227075465852 | accuracy: 0.9466145833333334 \n",
      "Epoch 25 | Step 9961 | loss: 0.1470560483170422 | accuracy: 0.9467993079584776 \n",
      "Epoch 25 | Step 9962 | loss: 0.14743423894818486 | accuracy: 0.9466594827586207 \n",
      "Epoch 25 | Step 9963 | loss: 0.1473472818757865 | accuracy: 0.9467353951890034 \n",
      "Epoch 25 | Step 9964 | loss: 0.14740519382518857 | accuracy: 0.9467037671232876 \n",
      "Epoch 25 | Step 9965 | loss: 0.14758575515688077 | accuracy: 0.9466723549488054 \n",
      "Epoch 25 | Step 9966 | loss: 0.14734614857149367 | accuracy: 0.9468005952380952 \n",
      "Epoch 25 | Step 9967 | loss: 0.14727189337550584 | accuracy: 0.9467690677966102 \n",
      "Epoch 25 | Step 9968 | loss: 0.14727581492499323 | accuracy: 0.9467905405405406 \n",
      "Epoch 25 | Step 9969 | loss: 0.14744456878766066 | accuracy: 0.946601430976431 \n",
      "Epoch 25 | Step 9970 | loss: 0.1473450960853956 | accuracy: 0.9465708892617449 \n",
      "Epoch 25 | Step 9971 | loss: 0.14731778081095337 | accuracy: 0.9465405518394648 \n",
      "Epoch 25 | Step 9972 | loss: 0.14722850187371173 | accuracy: 0.9465625 \n",
      "Epoch 25 | Step 9973 | loss: 0.14707453535294213 | accuracy: 0.9465843023255814 \n",
      "Epoch 25 | Step 9974 | loss: 0.14692582499655268 | accuracy: 0.9466059602649006 \n",
      "Epoch 25 | Step 9975 | loss: 0.14686284756453907 | accuracy: 0.946575907590759 \n",
      "Epoch 25 | Step 9976 | loss: 0.1469028641004115 | accuracy: 0.9464432565789473 \n",
      "Epoch 25 | Step 9977 | loss: 0.1472672178974894 | accuracy: 0.9462602459016394 \n",
      "Epoch 25 | Step 9978 | loss: 0.1472191563107414 | accuracy: 0.9462826797385621 \n",
      "Epoch 25 | Step 9979 | loss: 0.14706154879947048 | accuracy: 0.9464067589576547 \n",
      "Epoch 25 | Step 9980 | loss: 0.1468056063107275 | accuracy: 0.946479301948052 \n",
      "Epoch 25 | Step 9981 | loss: 0.14652871053581482 | accuracy: 0.9466019417475728 \n",
      "Epoch 25 | Step 9982 | loss: 0.14649377128770272 | accuracy: 0.9466229838709678 \n",
      "Epoch 25 | Step 9983 | loss: 0.14641986974182616 | accuracy: 0.9467443729903537 \n",
      "Epoch 25 | Step 9984 | loss: 0.14650759884180165 | accuracy: 0.9466646634615384 \n",
      "Epoch 25 | Step 9985 | loss: 0.14627919398462427 | accuracy: 0.9467352236421726 \n",
      "Epoch 25 | Step 9986 | loss: 0.14622103581857526 | accuracy: 0.9467555732484076 \n",
      "Epoch 25 | Step 9987 | loss: 0.1460436958878759 | accuracy: 0.946875 \n",
      "Epoch 25 | Step 9988 | loss: 0.14613485928106154 | accuracy: 0.9468947784810127 \n",
      "Epoch 25 | Step 9989 | loss: 0.14601666710636216 | accuracy: 0.9469637223974764 \n",
      "Epoch 25 | Step 9990 | loss: 0.14605635121089855 | accuracy: 0.9468848270440252 \n",
      "Epoch 25 | Step 9991 | loss: 0.14588711695704712 | accuracy: 0.9469533699059561 \n",
      "Epoch 25 | Step 9992 | loss: 0.14572376664727923 | accuracy: 0.947021484375 \n",
      "Epoch 25 | Step 9993 | loss: 0.14581292695902587 | accuracy: 0.9469918224299065 \n",
      "Epoch 25 | Step 9994 | loss: 0.14574734450127025 | accuracy: 0.9470108695652174 \n",
      "Epoch 25 | Step 9995 | loss: 0.14564536421937468 | accuracy: 0.947078173374613 \n",
      "Epoch 25 | Step 9996 | loss: 0.14551445588837433 | accuracy: 0.9471450617283951 \n",
      "Epoch 25 | Step 9997 | loss: 0.1454888361233931 | accuracy: 0.9471634615384615 \n",
      "Epoch 25 | Step 9998 | loss: 0.14564163393221016 | accuracy: 0.9470858895705522 \n",
      "Epoch 25 | Step 9999 | loss: 0.14576537948135934 | accuracy: 0.9470087920489296 \n",
      "Epoch 25 | Step 10000 | loss: 0.14590815918111216 | accuracy: 0.9469321646341463 \n",
      "Epoch 25 | Step 10001 | loss: 0.1455918179773994 | accuracy: 0.9470934650455927 \n",
      "Epoch 25 | Step 10002 | loss: 0.14546976184303106 | accuracy: 0.9472064393939394 \n",
      "Epoch 25 | Step 10003 | loss: 0.14555513746248627 | accuracy: 0.9470827039274925 \n",
      "Epoch 25 | Step 10004 | loss: 0.14551196597426766 | accuracy: 0.9471009036144579 \n",
      "Epoch 25 | Step 10005 | loss: 0.14566267440626926 | accuracy: 0.9471659159159159 \n",
      "Epoch 25 | Step 10006 | loss: 0.14568588516847814 | accuracy: 0.9471369760479041 \n",
      "Epoch 25 | Step 10007 | loss: 0.14575055566296646 | accuracy: 0.9471082089552239 \n",
      "Epoch 25 | Step 10008 | loss: 0.14596326325443526 | accuracy: 0.9470331101190477 \n",
      "Epoch 25 | Step 10009 | loss: 0.1458094768248255 | accuracy: 0.9471439169139466 \n",
      "Epoch 25 | Step 10010 | loss: 0.14576509229001205 | accuracy: 0.9471616124260355 \n",
      "Epoch 25 | Step 10011 | loss: 0.1455569621340363 | accuracy: 0.9472713864306784 \n",
      "Epoch 25 | Step 10012 | loss: 0.14556369656587345 | accuracy: 0.9473345588235295 \n",
      "Epoch 25 | Step 10013 | loss: 0.14552664024826367 | accuracy: 0.9472598973607038 \n",
      "Epoch 25 | Step 10014 | loss: 0.14552547479843533 | accuracy: 0.947139985380117 \n",
      "Epoch 25 | Step 10015 | loss: 0.14537149876269237 | accuracy: 0.9472029883381924 \n",
      "Epoch 25 | Step 10016 | loss: 0.145270595630241 | accuracy: 0.9471747819767442 \n",
      "Epoch 25 | Step 10017 | loss: 0.14537845577882683 | accuracy: 0.9470561594202899 \n",
      "Epoch 25 | Step 10018 | loss: 0.14519548084522257 | accuracy: 0.9471640173410405 \n",
      "Epoch 25 | Step 10019 | loss: 0.14519470367548445 | accuracy: 0.9472262247838616 \n",
      "Epoch 25 | Step 10020 | loss: 0.14497050319680538 | accuracy: 0.9473778735632183 \n",
      "Epoch 25 | Step 10021 | loss: 0.1449804791705656 | accuracy: 0.9473047994269341 \n",
      "Epoch 25 | Step 10022 | loss: 0.14509953062449182 | accuracy: 0.9471875 \n",
      "Epoch 25 | Step 10023 | loss: 0.14497763801504066 | accuracy: 0.947204415954416 \n",
      "Epoch 25 | Step 10024 | loss: 0.14496643858199773 | accuracy: 0.9471768465909091 \n",
      "Epoch 25 | Step 10025 | loss: 0.1449583094704253 | accuracy: 0.947149433427762 \n",
      "Epoch 25 | Step 10026 | loss: 0.14513301849365237 | accuracy: 0.9470780367231638 \n",
      "Epoch 25 | Step 10027 | loss: 0.14511160073985518 | accuracy: 0.9469630281690141 \n",
      "Epoch 25 | Step 10028 | loss: 0.14494412078448898 | accuracy: 0.9470242275280899 \n",
      "Epoch 25 | Step 10029 | loss: 0.1450904145294211 | accuracy: 0.946953781512605 \n",
      "Epoch 25 | Step 10030 | loss: 0.1453805244085509 | accuracy: 0.9468837290502793 \n",
      "Epoch 25 | Step 10031 | loss: 0.14532213685074225 | accuracy: 0.9468575905292479 \n",
      "Epoch 25 | Step 10032 | loss: 0.14531223538021246 | accuracy: 0.9469184027777777 \n",
      "Epoch 25 | Step 10033 | loss: 0.14518170151601537 | accuracy: 0.9469788781163435 \n",
      "Epoch 25 | Step 10034 | loss: 0.1452968927995605 | accuracy: 0.9469526933701657 \n",
      "Epoch 25 | Step 10035 | loss: 0.14523111209889086 | accuracy: 0.947012741046832 \n",
      "Epoch 25 | Step 10036 | loss: 0.14495344305472385 | accuracy: 0.9471583104395604 \n",
      "Epoch 25 | Step 10037 | loss: 0.1449172291547468 | accuracy: 0.9471318493150684 \n",
      "Epoch 25 | Step 10038 | loss: 0.14500995372203201 | accuracy: 0.9470628415300546 \n",
      "Epoch 25 | Step 10039 | loss: 0.1449240188974613 | accuracy: 0.9471219346049047 \n",
      "Epoch 25 | Step 10040 | loss: 0.14497119948551382 | accuracy: 0.9471382472826086 \n",
      "Epoch 25 | Step 10041 | loss: 0.14533635972920794 | accuracy: 0.9470274390243902 \n",
      "Epoch 25 | Step 10042 | loss: 0.1451372124556754 | accuracy: 0.9471283783783784 \n",
      "Epoch 25 | Step 10043 | loss: 0.14515666291117668 | accuracy: 0.9471866576819407 \n",
      "Epoch 25 | Step 10044 | loss: 0.14505997261092549 | accuracy: 0.9472026209677419 \n",
      "Epoch 25 | Step 10045 | loss: 0.14492579011231582 | accuracy: 0.9473022788203753 \n",
      "Epoch 25 | Step 10046 | loss: 0.1447826560467163 | accuracy: 0.9473178475935828 \n",
      "Epoch 25 | Step 10047 | loss: 0.14486416799823446 | accuracy: 0.9472916666666666 \n",
      "Epoch 25 | Step 10048 | loss: 0.14469761485630211 | accuracy: 0.9473487367021277 \n",
      "Epoch 25 | Step 10049 | loss: 0.14464494654172613 | accuracy: 0.9472811671087533 \n",
      "Epoch 25 | Step 10050 | loss: 0.14445723745991632 | accuracy: 0.947379298941799 \n",
      "Epoch 25 | Step 10051 | loss: 0.14433338136306542 | accuracy: 0.9474356860158312 \n",
      "Epoch 25 | Step 10052 | loss: 0.1442239907129031 | accuracy: 0.9474917763157895 \n",
      "Epoch 25 | Step 10053 | loss: 0.14403980022926974 | accuracy: 0.9475475721784777 \n",
      "Epoch 25 | Step 10054 | loss: 0.14405600733430915 | accuracy: 0.9476030759162304 \n",
      "Epoch 25 | Step 10055 | loss: 0.14408882517688584 | accuracy: 0.9475766971279374 \n",
      "Epoch 25 | Step 10056 | loss: 0.14455216454613648 | accuracy: 0.947509765625 \n",
      "Epoch 25 | Step 10057 | loss: 0.14436385330635235 | accuracy: 0.9476055194805195 \n",
      "Epoch 25 | Step 10058 | loss: 0.14418193544478308 | accuracy: 0.9477007772020726 \n",
      "Epoch 25 | Step 10059 | loss: 0.14406249834855092 | accuracy: 0.9477147932816538 \n",
      "Epoch 25 | Step 10060 | loss: 0.1442517667298311 | accuracy: 0.9476884664948454 \n",
      "Epoch 25 | Step 10061 | loss: 0.14409930219725348 | accuracy: 0.9477426092544987 \n",
      "Epoch 25 | Step 10062 | loss: 0.14403706822448814 | accuracy: 0.9477564102564102 \n",
      "Epoch 25 | Step 10063 | loss: 0.14406343771482977 | accuracy: 0.9477701406649617 \n",
      "Epoch 25 | Step 10064 | loss: 0.1439970331551621 | accuracy: 0.9477838010204082 \n",
      "Epoch 25 | Step 10065 | loss: 0.14391765776670917 | accuracy: 0.9477973918575063 \n",
      "Epoch 25 | Step 10066 | loss: 0.14394954732869783 | accuracy: 0.9477712563451777 \n",
      "Epoch 25 | Step 10067 | loss: 0.1437369256551507 | accuracy: 0.9478639240506329 \n",
      "Epoch 25 | Step 10068 | loss: 0.14349736363598792 | accuracy: 0.9479166666666666 \n",
      "Epoch 25 | Step 10069 | loss: 0.14356326163565777 | accuracy: 0.9478904282115869 \n",
      "Epoch 25 | Step 10070 | loss: 0.14362066733327936 | accuracy: 0.9478643216080402 \n",
      "Epoch 25 | Step 10071 | loss: 0.14345606692826232 | accuracy: 0.9479558270676691 \n",
      "Epoch 25 | Step 10072 | loss: 0.14335064655169838 | accuracy: 0.94796875 \n",
      "Epoch 25 | Step 10073 | loss: 0.14351733695910748 | accuracy: 0.9479426433915212 \n",
      "Epoch 25 | Step 10074 | loss: 0.14379392751487918 | accuracy: 0.9478389303482587 \n",
      "Epoch 25 | Step 10075 | loss: 0.14360502097875832 | accuracy: 0.9479683622828784 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.6041461825370789 | accuracy: 0.828125 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.4851644039154053 | accuracy: 0.84375 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5762137174606323 | accuracy: 0.828125 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5615249425172806 | accuracy: 0.828125 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5264074563980102 | accuracy: 0.8375 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5734422008196512 | accuracy: 0.8229166666666666 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5650041273662022 | accuracy: 0.8258928571428571 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5609105676412582 | accuracy: 0.8203125 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.6001268890168932 | accuracy: 0.8125 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5833207786083221 | accuracy: 0.821875 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5852093208919872 | accuracy: 0.8252840909090909 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5797689209381739 | accuracy: 0.8268229166666666 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.6003948312539321 | accuracy: 0.8209134615384616 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5769546244825635 | accuracy: 0.8258928571428571 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5816281040509542 | accuracy: 0.828125 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5805810801684856 | accuracy: 0.826171875 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5752327670069302 | accuracy: 0.8244485294117647 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5711075183418062 | accuracy: 0.8255208333333334 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5617841654702237 | accuracy: 0.8297697368421053 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5515708535909652 | accuracy: 0.83046875 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5438098566872733 | accuracy: 0.8318452380952381 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5350023833188143 | accuracy: 0.8323863636363636 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5457164593364882 | accuracy: 0.8308423913043478 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5735200320680937 | accuracy: 0.8255208333333334 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5846493458747863 | accuracy: 0.823125 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5784400965158756 | accuracy: 0.8251201923076923 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5676274928781722 | accuracy: 0.828125 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5703025832772255 | accuracy: 0.8275669642857143 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5674048353885782 | accuracy: 0.8292025862068966 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5638100743293762 | accuracy: 0.83125 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5589210093021393 | accuracy: 0.8341733870967742 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5619367556646466 | accuracy: 0.8330078125 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5640092916560896 | accuracy: 0.8314393939393939 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5676343852982801 | accuracy: 0.8285845588235294 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5708034438746316 | accuracy: 0.8276785714285714 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5674837571051384 | accuracy: 0.8289930555555555 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5675866305828093 | accuracy: 0.8285472972972971 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5717197774272215 | accuracy: 0.8289473684210524 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5753682462068703 | accuracy: 0.8277243589743588 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5682254634797572 | accuracy: 0.8292968749999998 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5625049900717851 | accuracy: 0.8304115853658535 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5556508678765524 | accuracy: 0.8322172619047618 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5546112150646919 | accuracy: 0.8324854651162789 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5564730512824926 | accuracy: 0.8327414772727271 \n",
      "Validation | Epoch 25 | Step 10075 | loss: 0.5573707083861034 | accuracy: 0.8321105069584315 \n"
     ]
    }
   ],
   "source": [
    "trainer.start_train(num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nano-seq-r7R1Yrai-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
