import argparse
import os
from tqdm import tqdm
import yaml

import torch
from nano_seq.data.collator import LanguagePairCollator
from nano_seq.data.dataset import LanguagePairDataset, MonolingualDataset
from nano_seq.model.translation import TranslationModel

from nano_seq.task.translation import TranslationConfig, TranslationTask, load_langpair_dictionary


def prepare_eval(cfg: TranslationConfig, data_path: str, dict_path: str, bsz: int):
    src_dict, tgt_dict = load_langpair_dictionary(dict_path, cfg.src_lang, cfg.tgt_lang, cfg.shared_dict)
    src_dataset = MonolingualDataset.from_text_file(data_path, cfg.src_lang, src_dict)
    collator = LanguagePairCollator(LanguagePairDataset(src_dataset, src_dataset, False), bsz)
    model = TranslationModel.from_cfg(cfg, len(src_dict), len(tgt_dict))

    return collator, model, tgt_dict


def main(args):
    # Read config
    with open(args.config, "rt", encoding="utf-8") as f:
        config_dict = yaml.safe_load(f)
        cfg = TranslationConfig(**config_dict["task"])

    if not os.path.exists(args.output):
        os.mkdir(args.output)

    if torch.cuda.is_available():
        torch.set_default_device("cuda")

    collator, model, tgt_dict = prepare_eval(cfg, args.data_path, args.dict_path, args.batch_size)
    task = TranslationTask(cfg)

    state_dict = torch.load(args.chkpt)
    model.load_state_dict(state_dict["model"])

    with open(os.path.join(args.output), "wt", encoding="utf-8") as pred_f:
        for batch in tqdm(iter(collator)):
            pred_sents = task.decode(model, tgt_dict, batch)
            for pred_sent in pred_sents:
                pred_f.write(pred_sent + "\n")
            pred_f.flush()


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", "-c", type=str, help="YAML config file")
    parser.add_argument("--chkpt", type=str, required=True, help="Path to pytorch .pt file")
    parser.add_argument("--decode", type=str, choices=["greedy", "beam"], default="greedy")
    parser.add_argument(
        "--data-path",
        "-D",
        type=str,
        help="Path to directory containing language pair text files. This predict script does not use paths specified in training config",
    )
    parser.add_argument(
        "--dict-path",
        "-d",
        type=str,
        help="Path to directory containing dictionary files. This predict script does not use paths specified in training config",
    )
    parser.add_argument(
        "--batch-size",
        "-b",
        type=int,
        help="Batch size. This predict script does not use bsz specified in training config",
    )
    parser.add_argument("--max-len", "-m", type=int, help="Max length of the sentence generated by the model")
    parser.add_argument("--output", "-o", help="Output file")
